ID,Title,Content,Country,Geo From:,Date,Month
803c5837007ca201fefd4d53d121c924490a3eee,Adaptive social contact rates induce complex dynamics during epidemics,"a1111111111 a1111111111 a1111111111 a1111111111 a1111111111Adapting to a changing landscape of risk during an infectious disease epidemic may pose a significant dilemma for a susceptible individual or for a governing body responsible for the health of susceptible individuals. On the one hand, changing behavior (e.g. through social distancing) can reduce the reproduction number (R 0 ) of an epidemic and save many from death or morbidity [1, 2] . On the other hand, behavior change can reduce an individual's ability to make a living or, for a group of people, can hamper or cause a recession in the economy through decreased production, sales, and investment and increased unemployment, inflation, and debt [3] . This dilemma introduces a behavior change tradeoff for the decision-maker, a balancing act between epidemiological interests and economic interests.There is growing interest in the role of behavior in infectious disease dynamics (see Funk et al., 2010 [4] for a general review). Behavior relevant to epidemic outcomes is known to change in response to perceived risk during epidemics (e.g. measles-mumps-rubella (MMR) vaccination choices [5] , condom purchases in HIV-affected communities [6] , and social distancing in influenza outbreaks [7] and during the ongoing COVID-19 pandemic [8] ). Although behavior is difficult to measure, quantify, and predict [9] , modelers have adopted a variety of strategies to investigate its role in epidemic outcomes. These strategies include agent-based modeling [10] , network structures that model behavior as a social contagion process [11] or that replace central nodes when sick [12] , and game theoretic descriptions of rational choice under changing incentives, as in the case of vaccination [7, 13, 14] . A common approach to incorporating behavior into epidemic models is to track co-evolving dynamics of behavior and infection [11, [15] [16] [17] .In epidemic response policy, it is typical to think of behavior change as an exogenouslyinduced intervention without considering associated incentives for the individual or the collective. Due to the interactive relationship between behavior and epidemic dynamics, adaptive behavior should instead be thought of as endogenous to an infectious disease system because it is, in part, a consequence of the prevalence of the disease, which in turn responds to changes in behavior [9, 18 ]. An epidemic system with adaptive behavior responds to the conditions it itself creates, and is thus a complex, adaptive system [19] , subject to the properties and tendencies of such systems.The interaction between behavioral incentives and epidemic dynamics introduces a negative feedback into the epidemic system. In an important early expansion of Kermack and McKendrick's seminal Susceptible-Infectious-Removed (SIR) model [20] , Capasso and Serio built a self-iterative epidemic model by making the transmission parameter (β) a negative function of the number of infected because ""in the presence of a very large number of infectives the population may tend to reduce the number of contacts per unit time."" [21] A negative feedback such as this may lead to an endemic equilibrium [22] . This happens because, at low levels of prevalence, the cost of behavior change to avoid disease relative to the risk of infection may not be justified, even though the collective, public benefit in the long-term may be greater. Conversely, as prevalence increases, the probability of infection also increases, thus increasing incentives to adopt protective behavior [13] . If responses are based on outdated information, a negative feedback between prevalence and social contact can produce sustained oscillations in time-series data [23] .Such periodicity (i.e. multi-peak dynamics) has long been documented empirically in epidemiology [24, 25] . Periodicity can be driven by seasonal contact rate changes (e.g. when children are in school) [26] , seasonality in the climate or ecology [27] , sexual and social behavior change [23, 28] , and host immunity cycling through new births of susceptibles or a decay of immunity over time. Some papers in nonlinear dynamics have studied delay differential equations in the context of epidemic dynamics and found periodic solutions as well [29] . Although it is atypical to include delay in modeling, delay is an important feature of epidemics. Delays of information acquisition, behavioral response, scientific investigation, and those inherent in natural biological processes can affect epidemic outcomes. In the ongoing COVID-19 pandemic, for example, there have been delays in the international recognition of the outbreak [30] , delays in the identification of the virus, delays in the acquisition of reliable information on suspected and confirmed cases [31] , and delays in the development and deployment of competent diagnostics [32] .Although infectious disease modelers have begun to incorporate adaptive behavior into their models, few studies in the literature capture the competing economic and public health incentives that drive delayed behavioral responses in both individual and group settings during epidemics [33, 34] . Here we develop a theoretical model using both discrete and continuous time and both SIR and SIS compartmental epidemic structures. The model, which is designed to be strategic rather than tactical (sensu Holling [35] ), is adjusted on the principle of endogenous behavior change through an adaptive social-contact rate that can be thought of as either individually motivated or institutionally imposed. We introduce a novel utility function that motivates the population's effective contact rate at a particular time period. This utility function is based on information about the epidemic size that may not be current. This leads to a time delay in the contact function that increases the complexity of the population dynamics of the infection. Results from the discrete-time model show that the system approaches an equilibrium in many cases, although small parameter perturbations can lead the dynamics to enter qualitatively distinct regimes. The analogous continuous-time model retains periodicities for some sets of parameters, but numerical investigation shows that the continuous time version is much better behaved than the discrete-time model. This behavior is similar to that in models of ecological population dynamics, and a useful mathematical parallel can be drawn between these systems.To represent endogenous behavior change, we start with the classical discrete-time susceptible-infected-susceptible (SIS) model [20] , which, when incidence is relatively small compared to the total population [36, 37] , can be written in terms of the recursionswhere at time t, S t represents the number of susceptible individuals, I t the infected individuals, and N t the number of individuals that make up the population, which is assumed fixed in a closed population. We can therefore write N for the constant population size. Here γ, with 0 < γ < 1, is the rate of removal from I to S due to recovery. This model in its simplest form assumes random mixing, where the parameter b represents a composite of the average contact rate and the disease-specific transmissibility given a contact event. In order to introduce human behavior, we substitute for b a time-dependent b t , which is a function of both b 0 , the probability that disease transmission takes place on contact, and a dynamic social contact rate c t whose optimal value, c � t , is the number of contacts per unit time that maximize utility for the individual. c � t is determined at each time t as in economic epidemiological models [34] ,where c � t represents the optimal contact rate, defined as the number of contacts per unit time that maximize utility for the individual. Here, c � t is a function of the number of infected in the population according to the perceived risks and benefits of social contacts, which we model as a utility function. We assume that there is a constant utility independent of contact, a utility loss associated with infection, and a utility derived from the choice of number of daily contacts with a penalty for deviating from the choice of contacts which would yield the most utility.This utility function is assumed to take the formHere U represents utility for an individual at time t given a particular number of contacts per unit time c, α 0 is a constant that represents maximum potential utility achieved at a target contact rateĉ. The second term, À a 1 ðc ÀĉÞ 2 , is a concave function that represents the penalty for deviating fromĉ. The third term,, is the cost of infection (i.e. morbidity), α 2 , multiplied by the probability of infection over the course of the time unit. The time-delay Δ represents the delay in information acquisition and the speed of response to that information. We note that 1 À I N b 0 À � c can be approximated bywhen I N b 0 is small and c I N b 0 � 1: We thus assume I N ðb 0 Þ is small, that is, prevalence is low, and approximate U(c) in Eq 5 using Eq 6. Eq 5 assumes a strictly negative relationship between number of infecteds and contact.We assume an individual or government will balance the cost of infection, the probability of infection, and the cost of deviating from the target contact rateĉ to select an optimal contact rate c � t , namely the number of contacts, which takes into account the risk of infection and the penalty for deviating from the target contact rate. This captures the idea that individuals trade off how many people they want to interact with versus their risk of becoming infected, or that authorities want to reopen the economy during a pandemic and have to trade off morbidity and mortality from increasing infections with the need to allow additional social contacts to help the economy restart. This optimal contact rate can be calculated by finding the maximum of U with respect to c from Eq 5 with substitution from Eq 6, namelyDifferentiating, we havewhich vanishes at the optimal contact rate, c � , which we write as c � t to show its dependence on time. Thenwhich we assume to be positive. Therefore, total utility will decrease as I t increases and c � t also decreases. Utility is maximized at each time step, rather than over the course of lifetime expectations. In addition, Eq 9 assumes a strictly negative relationship between number of infecteds at time t − Δ and c � t . While behavior at high degrees of prevalence has been shown to be nonlinear and fatalistic [38, 39] , in this model, prevalence (i.e., b 0 I t N ) is assumed to be small, consistent with Eq 6.We introduce the new parameter a ¼ a 2 2a 1 b 0 , so thatWe can now rewrite the recursion from Eq 2, using Eq 4 and replacing c t with c � t as defined by Eq 10, asWhen Δ = 0 and there is no time delay, f(�) is a cubic polynomial, given byFor the susceptible-infected-removed (SIR) version of the model, we include the removed category and write the (discrete-time) recursion system as [20] . The inclusion of the removed category entails thatĨ ¼ 0 is the only equilibrium of the system Eqs 13-15; unlike the SIS model, there is no equilibrium with infecteds present. In general, since c � t includes the delay Δ, the dynamic approach toĨ ¼ 0 is expected to be quite complex. Numerical analysis of this SIR model shows strong similarity between the SIS and SIR models for several hundred time steps before the SIR model converges toĨ ¼ 0. In the section ""Numerical Iteration and Continuous-Time Analog"" we compare the numerical iteration of the SIS (Eq 11) and SIR (Eqs 13-15) and integration of the continuous-time (differential equation) versions of the SIS and SIR models.To determine the dynamic trajectories of (11) without time delay, we first solve for the fixed point(s) of the recursion (11) (i.e., value or values of I such that f(I t+1 ) = I t = I t−Δ ). That is, we solveFrom Eq 16, it is clear that I = 0 is an equilibrium as no new infections can occur in the next time-step if none exist in the current one. This is the disease-free equilibrium denoted byĨ. Other equilibria are the solutions ofnamely a þĉ � ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ða ÀĉÞWe label the solution with the + sign I � and the one with the − signÎ. I � > 0 but I � � N if 4αγ/Nb 0 � 0, which is impossible under our assumptions that α and γ are positive. Hence I � is not feasible. Further, under these same conditions,Î � N, andÎ > 0 ifIt is important to note that under these conditionsÎ is an equilibrium of the recursion (11) for any Δ � 0. Recall that for the SIR version of this model the only equilibrium isĨ ¼ 0.Assessing global asymptotic stability in epidemic models is an important task of mathematical epidemiology [40, 41] . The three equilibria of the SIS recursion (11) are qualitatively different. I ¼ 0 corresponds to a disease-free population; I � is greater than N and is therefore not feasible;Î is the only positive feasible equilibrium ifĉb 0 > g=N (this is equivalent to R 0 > 1, where R 0 ¼ Nĉb 0 þ 1 À g) and is, therefore, the most interesting for the asymptotic stability behavior of the epidemic. Mathematical stability analysis of recursion (11) is complicated because of the delay term Δ. However, from (11), if Nĉb 0 > g, the disease-free equilibriumĨ ¼ 0 is locally unstable, and in this caseÎ is indeed feasible.Local stability ofÎ in (18) is discussed in detail in S1 Appendix. First, in the absence of delay (i.e., Δ = 0),Î is locally stable if j d dI f ðIÞj I¼Î < 1, and the condition for this to hold whenÎ is legitimate is b 0Î ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffi ffiIf inequalities (20) and Nĉb 0 > g hold, thenÎ is locally stable. However, even if both of these inequalities hold, the number of infecteds may not converge toÎ. It is well known that iterations of discrete-time recursive relations, of which (12) is an example (i.e., with Δ = 0), may produce cycles or chaos depending on the parameters and the starting frequency I 0 of infecteds.We begin with numerical analysis of the discrete-time SIS recursion (11) , which includes the delay parameter Δ. Local stability properties of the equilibrium stateÎ, with 0 <Î < N, are shown in the Appendix under the assumption Nĉb 0 > g, which also entails that the diseasefree equilibriumĨ ¼ 0 is locally unstable. In the recursion (11), the number of infecteds at time t will not, in general, be integers, but can be interpreted as the expected number of infected in the population. Further, the dynamics of I t under such a recursion can be very sensitive to the starting condition I 0 , the size of the time delay Δ, and the parameters: N; b 0 ; g;ĉ; and α. The local stability ofÎ, namely whether I t converges toÎ from a starting number of infecteds close toÎ, may tell you little about the actual trajectory of I t from other starting conditions. Table 1 reports an array of dynamic trajectories without delay (Δ = 0) for some choices of parameters. In seven cases, I 0 = 1, and in two cases the numerical iteration of Eq 12 was initiated with I 0 6 ¼ 1. The first three rows show three sets of parameters for which the equilibrium values ofÎ are very similar but the trajectories of I t are different: a two-point cycle, a fourpoint cycle, and apparently chaotic cycling above and belowÎ. In all of these cases, df ðIÞ=dIj I¼Î < À 1. Clearly the dynamics are sensitive to the target contact rateĉ in these cases. The fourth and eighth rows show that I t becomes unbounded (tends to + 1) from I 0 = 1, but a two-point cycle is approached if I 0 is close enough toÎ : df ðIÞ=dIj I¼Î < À 1 in these cases. For the parameters in the ninth row, if I 0 is close enough toÎ there is damped oscillation intoÎ: here À 1 < df ðIÞ=dIj I¼Î < 0. In the case marked � ,Î is locally stable and with a large enough initial number of infecteds, there is damped oscillatory convergence toÎ. In the case marked �� , with I 0 = 1 the number of infecteds becomes unbounded, but in this case,Î is locally unstable (df ðIÞ=dIj I¼Î < À 1), and starting from I 0 close toÎ a stable two-point cycle is approached. (11) with Δ = 0 and the other parameters from the first three lines of Table 1 . Asĉ increases, first there is convergence toÎ, then period doubling to chaos and finally passage to negative infinity.Stability analysis of the SIS model is more complicated when Δ 6 ¼ 0, and in S1 Appendix we outline the procedure for local analysis of the recursion (11) nearÎ. Local stability is sensitive to the delay time Δ as can be seen from the numerical iteration of (11) for the specific set of parameters shown in Table 2 . Some analytical details related to Table 2 are in S1 Appendix.The fifth and sixth rows of Table 1 exemplify another interesting dynamic starting from I 0 = 1. I t becomes larger thanÎ (overshoots) and then converges monotonically down toÎ; in each case 0 < df ðIÞ=dtj I¼Î < 1. For the parameters in the seventh row, there is oscillatory convergence toÎ from I 0 = 1 (À 1 < df ðIÞ=dIj I¼Î < 0), while in the last row there is straightforward monotone convergence toÎ. The dependence of the dynamics for recursion (11) on the delay Δ and target contact rateĉ is illustrated for Δ = 0, 1, 2 in S6 Fig. The bifurcation diagram for each Δ shows the shift, summarized in Table 2 , from convergence to period doubling, chaos, and negative infinity, which occurs for smaller values ofĉ as Δ increases.A continuous-time analog of the discrete-time recursion (11) , in the form of a differential equation, substitutes dI/dt for I t+1 − I t in (11) . We then solve the resulting delay differential equation numerically using the VODE differential equation integrator in SciPy [42, 43] (source code available at https://github.com/yoavram/SanJose). Using the parameters in Table 2 , Figs 1-4 compare the effect of the parameters on the trajectories of the discrete-time and continuous-time SIS model specified in (11) . The number of time steps used in the In Fig 1, with no delay (Δ = 0) and a one-unit delay (Δ = 1), the discrete and continuous dynamics are very similar, both converging toÎ. However, with Δ = 2 the differential equation oscillates intoÎ while the discrete-time recursion enters a regime of inexact cycling aroundÎ, which appears to be a state of chaos. For Δ = 3 and Δ = 4, the discrete recursion ""collapses"". In other words, I t becomes negative and appears to go off to −1; in Fig 1, this is cut off at I = 0. It is worth noting that if the total population size of N decreases over time, for example, if we take N(t) = Nexp(−zt), with z ¼ 50b 0ĉ g, then the short-term dynamics of the SIS model in (11) begins to closely resemble the SIR version. This is illustrated in S9 Fig, where b 0 ;ĉ; g are, as in S8 Fig, the same as in Fig 2A. With N decreasing to zero, both S and I will approach zero in the SIS model, which explain its apparent similarity to the SIR model.This simple epidemic model with adaptive social contact produces two possible equilibria, one with zero infecteds, where the disease is eradicated, and one between zero and N, the population size, where the disease is endemic. These equilibria are locally stable under different conditions. Dynamics produced by this model are complex and subject to regime shifts across thresholds in the initial conditions and parameter settings. These dynamics include damped oscillation to the equilibrium, periodic oscillation, chaotic oscillation, and regression to positive or negative infinity. Our stability analysis is carried out in the neighborhood of the equilibria. Although global asymptotic stability analysis of some epidemic models has been possible [29, 40, 41] , the inclusion of the delay Δ seems to make global analysis extremely difficult in general [29] .Our model makes a number of simplifying assumptions. We assume that all individuals in the population will respond in the same fashion to government policy and that governments or individuals choose a uniform contact rate according to an optimized utility function, which is homogeneous across all individuals in the population. This contact rate will, in practice, vary across the population according to a variety of drivers including, but not limited to, disease state, cultural and religious practices, political affiliation, housing density, occupation, risk tolerance, and age. Finally, we assume that the utility function is symmetric around the optimal number of contacts so that increasing or decreasing contacts above or below the target contact rate, respectively, yield the same reduction in utility. These assumptions allowed us to create the simplest possible model that includes adaptive behavior trade-offs and time delay.Convergence to an endemic equilibrium when economic and public health trade-offs are included in an epidemic model is consistent with both theory [22] and other models [33] . Our results show certain parameter sets can lead to limit-cycle dynamics, consistent with other behavior change models [23, 44] and negative feedback mechanisms with time delays [45, 46] . This is because the system is reacting to conditions that were true in the past, but not necessarily true in the present. The time scale and the meaning of the delay, Δ, can influence the qualitative dynamics of the epidemic and, under certain conditions, can lead to a stable cyclic epidemic even in the continuous-time version of our model. We note that these distinct dynamical trajectories as seen in our computational experiments come from a purely deterministic recursion. This means that oscillations and even erratic, near-chaotic dynamics and collapse in an epidemic may not necessarily be due to seasonality, complex agent-based interactions, changing or stochastic parameter values, demographic change, host immunity, or socio-cultural idiosyncrasies. In our discrete-time model, there is the added complexity that the non-zero equilibrium may be locally stable but not attained from a wide range of initial conditions, including the most natural one, namely a single infected individual.This dynamical behavior in number of infecteds can result from mathematical properties of a simple deterministic system with homogeneous endogenous behavior change, similar to complex population dynamics of biological organisms [47] . The mathematical consistency with population dynamics suggests a parallel in ecology, that the indifference point for human behavior functions in a similar way to a carrying capacity in ecology, below which a population will tend to grow and above which a population will tend to shrink. For example, the Ricker Equation [48] , commonly used in population dynamics to describe the growth of fish populations, exhibits similar complex dynamics and qualitative state thresholds. These ecological models are typically structured mathematically in discrete time, while continuous time models are more commonly used in modeling epidemics. There is no a priori reason to prefer the continuous time framework over that in discrete time. It is not clear which strategic approach is more realistic as transmission from an infected to a susceptible individual may happen at anytime, but epidemiologists do tend to frame their thinking in discrete time-steps of days and weeks.Observed epidemic curves of many transient disease outbreaks typically inflect and go extinct, as opposed to this model that may oscillate perpetually or converge monotonically or cyclically to an endemic disease equilibrium. Including institutional and public efforts that are further incentivized to eradicate, rather than to optimize short-term utility trade-offs, would alter the dynamics to look more like real-world epidemic curves. Beyond infectious diseases that remain endemic to society, outbreaks may also flare up once or multiple times, such as the double-peaked outbreaks of SARS in three countries in 2003 [49] , and surges in fluctuations in COVID-19 cases globally in 2020 [50] . There may be many causes for such double-peaked outbreaks, one of which may be a lapse in behavior change after the epidemic begins to die down due to decreasing incentives [11] , as represented in our simple theoretical model. This is consistent with findings that voluntary vaccination programs suffer from decreasing incentives to participate as prevalence decreases [51, 52] . A recent analysis [53] that incorporated epidemiclike transmission of sentiment opposed to vaccination against an infection found that the transient dynamics of the anti-vaccine sentiment could induce complex dynamics of the disease epidemic. However, this analysis did not incorporate a time delay in the manifestation of the anti-vaccine sentiment. The relation between the spread of the sentiment and of the infection is, therefore, somewhat different from that seen here between an adaptive contact rate and the epidemic dynamics.One of the responsibilities of infectious disease modelers is to predict and project forward what epidemics will do in the future in order to better assist in the proper and strategic allocation of preventative resources. However, there are limits to the power and precision of such modeling. In our model, allowing for adaptive behavior change leads to a system that is qualitatively sensitive to small differences in values of key parameters. These parameters are very hard to measure precisely; they change depending on the disease system and context and their inference is generally subject to large errors. Further, we don't know how policy-makers weight the economic trade-offs against the public health priorities (i.e., the ratio between α 1 and α 2 in our model) to arrive at new policy recommendations. Geographic and/or cultural variation in our parameter c � t (and concomitant variation in the delay Δ) are likely to affect how epidemic dynamics are affected by such trade-offs.In our model, complex dynamic regimes occur more often when there is a time delay. If behavior change arises from fear and fear is triggered by high local mortality and high local prevalence, such delays are biologically inherent because death and incubation periods are lagging epidemiological indicators. Lags, whether social, environmental, or biological, mean that people can respond inappropriately to an unfolding epidemic crisis, but they also mean that people can abandon protective behaviors prematurely as conditions improve. Developing approaches to reduce lags or to incentivize protective behavior throughout the duration of any lag introduced by the natural history of the infection (or otherwise) should be a priority in applied research. Policy-makers should also consider the benefit of the long-term utility of early-stage overreaction to outbreaks and consider overriding short-term incentives. In light of the COVID-19 crisis, understanding endogenous delayed behavior change and economic incentives is of crucial importance to outbreak response and epidemic management. We anticipate further developments along these lines that could incorporate long incubation periods and other delays, recognition of asymptomatic transmission, influential heterogeneous drivers, and meta-population dynamics of simultaneous, connected epidemics.Supporting information S1 Appendix. Local stability of the endemic equilibriumÎ. Conditions are given for various values of the delay time Δ and the parameters in Table 2 Table 1 on the x-axis and its corresponding reproduction number R 0 . The dotted horizontal line delineates the total population size (N = 250). Dynamics exhibit convergence to the endemic equilibrium (including monotonic, overshooting, and damped oscillation) and period doubling to chaos, followed by passage to negative infinity. Table 2 with varying target contact rateĉ. Dynamics progress from convergence to chaos to negative infinity. As Δ increases, transitions between dynamic regimes begin at smaller values ofĉ. ",United States of America,first author,2021-02-10,02
e1c4e260575a3e364160ab3b1b7fbe78a174f56d,The practice of dentistry amidst the COVID-19 pandemic,"COVID-19, a novel coronavirus, was first reported in Wuhan, China in December 2019. It has since spread rapidly across all continents except Antarctica. As of December 1st, 2020, the World Health Organization (WHO), reports cases of COVID-19 have been confirmed in 235 countries and territories, causing 62,844,837 confirmed cases and 1,465,144 confirmed deaths.About 80% of cases present with mild to no symptoms, which increases both the rate of undiagnosed cases and the spread of COVID-19. The virus is most transmissible when patients are most symptomatic, however, the transmission of the virus can occur prior to the presentation of any symptoms. According to Ather et al., the transmission has been shown to occur through aerosol Symptoms Symptoms for COVID-19 patients may appear 2-14 days after exposure and can range from mild, flu-like symptoms to pneumonia, multiple organ failure, and acute respiratory distress. The outlier incubation period of the virus has been reported from up to 24- Office preparations:• A hand sanitization station should be available at the entrance, with a notice of mandatory mask requirement in the office. Other patient education material may also be placed throughout the office. Hand hygiene notices may also help patients and staff apply proper hygiene at required times and places. • Supplies (tissues, alcohol-based hand sanitizer, trash cans) should be readily available to facilitate maintenance and hygiene of common spaces. • Installation of the clear barrier for the front desk. Alternatively, front desk staff may wear face shields, in addition to face masks. • Encourage physical distancing by arranging seating in waiting rooms and employee spaces so patients and employees can sit at least 6 feet apart. Also, consider outdoor spaces seating for staff breaks. • Remove objects that are difficult to disinfect such as magazines, toys, excess/surplus furniture, and other objects that may be touched by others from waiting and office areas. • When applicable, replace high-touch communal items with pre-packaged, singleserving items (e.g. bottled water, pre-packaged snacks), and high-touch surfaces with no-touch alternatives (e.g. faucets, soap, hand sanitizer) • Request staff to wipe down contact areas routinely after use. • Separate staff from patient bathroom Scheduling considerations: 4 Page 4 of 15• When scheduling patients, inform them that only patients will be allowed in the waiting area. Only patients that require caregivers (children, mentally or physically disabled, elderly, and patients who need an interpreter) will be allowed a companion to the appointment. • Establish a template for scheduling patients to allow for social distancing by eliminating waiting time in the office. Employee scheduling should also maximize distancing by reducing number of employees using the same office spaces at any given time.• Make patient safety the first priority. • Understand how to identify vulnerable patients and take appropriate steps to protect them. • Establish a dialogue and make sure the patient understands how the remote consultation is going to work. • Explain that:• The dental provider can only prescribe if it is safe to do so. • Sufficient information about the patient's health is necessary prior to prescribing. • It may be unsafe if relevant information is not shared with other healthcare providers involved in their care. • Remote care may be unsuitable to meet all patient's needs.• Provide patients with all the options available to them, including declining treatment, in a way they can understand. • Make appropriate arrangements for aftercare and, unless the patient objects, share all relevant information with colleagues and other health and social care providers involved in their care to support ongoing monitoring and treatment. • Keep notes that fully explain and justify the decisions they make. • Stay up to date with relevant training, support and guidance for providing healthcare in a remote context.The French Minister of Solidarity and Health, Oliver Veran, released a statement in early March suggesting that the use of Ibuprofen, and other such NSAIDs, should be avoided in COVID-19 positive patients due to the potential of worsening or prolonging the infection. This advice follows an article published on March 11th, 2020 in the Lancet medical journal, where it was hypothesized that NSAIDs increase angiotensin-converting enzyme 2 (ACE-2) and can lead to an aggravation of COVID-19 symptoms. The rise in concern is due to COVID-19's mechanism of action. Coronavirus targets cells of the lungs, intestines, kidneys, and blood vessels by binding to these target cells through ACE-2 receptors. Ibuprofen increases the expression of ACE-2. The Lancet hypothesized that this increase in ACE-2 could exacerbate the symptoms of COVID-19. On March 19th, 2020, the WHO rescinded their previous statement and currently does not recommend avoiding Ibuprofen for treatment of COVID-19 due to a lack of scientific evidence. Concurrently, the United States Food and Drug Administration (FDA) also believes that there is not enough scientific evidence to support that Ibuprofen will increase the severity of COVID-19 symptoms. However, the UK National Health Service (NHS) and the BMJ journal, both recommend against it even though there is no strong evidence of a connection between ibuprofen and an exacerbation of COVID-19 symptoms, it is best to take paracetamol to manage symptoms of COVID-19 until further research can be conducted.The ADA has put out a statement regarding interim guidance to minimize the exposure of COVID-19 while managing emergent and urgent dental care needs. The ADA makes it apparent that these algorithms are a guide to help dental providers minimize the risk and exposure of COVID-19 and are not directives.• Telecommunication: Algorithm 1-triage:• Speak to the patient over the phone or through video conference to determine the urgency for a dental visit. • Ensure that the provider has informed consent from the patient to triage on the phone. • Postpone elective procedures and concentrate efforts on managing dental emergencies. • Remote consultations and prescribing can be used to manage emergencies.• Patient interview and assessment: Algorithm 2-screening:• A proper medical history, dental history and travel history should be required prior to clinically evaluating the patient as well as taking the patient's temperature. • An example of a screening form that can be given to patients prior to a clinical exam has been included below. • This screening questionnaire can be a reference point for dentists when determining patient treatment (Table 1 ). • If a patient answers no to the first question, considerations can be made to postpone treatment. • If a patient answers yes to any of the above questions (except the first), or presents with any of the symptoms mentioned above, it is recommended that non-emergent dental procedures be postponed for 2-3 weeks. • However, if a patient has a dental complication that is potentially life-threatening, requires immediate treatment to stop ongoing tissue bleeding or alleviates severe pain or infection, the ADA recommends the patient must be seen as these are considered a dental emergency. • Procedures that do not generate aerosols may be performed safely with standard precautions. • Procedures that generate aerosols create a risk to DHCP and patients and must be postponed unless equipped to perform procedures under airborne precautions (e.g. airborne infection isolation room (AIIR), N95 respirator, and other appropriate PPE). Otherwise, it is best to refer patients to facilities, such as hospitals, that are equipped to do so (Fig. 1 ).• Tables 2 and 3 outline guidelines by both the American and Australian Dental Association for treating Dental Emergencies during the COVID-19 Pandemic.• Standard precaution personal protective equipment (PPE) including: (Fig. 2 Have you or anyone you live with tested positive for COVID-19?In the past 14 days, have you or any household member had any contact with a known COVID-19 patient?Do you or any household member have symptoms over the past week: -Loss of taste or smell -Rashes on fingers or toes -New difficulty breathing -New cough -Unusual fatigue -Vomiting or diarrhea -Loss of appetite?Have you had any history of fever in the last 14 days of over 100.4 F or 38 C?American Dental Association case selection As an Isolation precaution for all patients, patients must wear a facemask immediately as they enter the office, regardless if they are symptomatic or asymptomatic. For patients that are symptomatic, escort the patient to an isolated operatory to minimize spread of the virus. COVID-19 positive patients should be taken to an AIIR if available.• A protocol for PPE donning is recommended by the American Centers for Disease Control (CDC).• Donning is done in this order: hand hygiene-full coverage gown-respirator (and mask over it)-face shield-gloves • Preprocedural mouth rinse 1.5% hydrogen peroxide or 0.2% povidone for 30 s, two times.• Chlorhexidine alone is not recommended • Avoid/limit aerosol-generating procedures.• If aerosols are to be produced, a N95 mask and full-face shield should be worn. • If N95 masks are in short supply, the CDC has approved to wear a level 3 mask over the N95 mask to increase the life span. • Rubber dam application to minimize droplet production. • Use of 4-handed technique to control splash, splatter, and aerosols. • Use of high-volume evacuators.• Backflow can occur when using saliva ejector.• Use of anti-retraction functions of handpieces may reduce cross-contamination. • Minimize use of 3 in 1 syringe (air-water) that can generate droplets.• If the patient is COVID-19 positive:• Defer elective treatment for three weeks. • If emergent care is indicated, the following must be executed.• Negative pressure room. • PPE, including use of N95 mask (per CDC guidelines). • All other precautions are mentioned above.• PPE doffing • Doffing: remove soiled gloves and discard-remove face shield and place in receptacle for disinfecting-remove gown and place in laundry or dispose of disposable-remove mask-perform hand hygiene • Wet hands with clean, running water, and apply soap. • Lather soap between hands, ensuring coverage of the backs of your hands, between your fingers, and under the nails. • Scrub your hands together for at least 20 s. • Rinse your hands under clean, running water. • Dry your hands by air drying or using a clean towel or paper towel.• Antimicrobial soap and water • Instructions for plain soap and water apply here as well.• Alcohol-based hand rub with alcohol concentration of 70-90%• Per the CDC, alcohol-based hand rubs are more effective at killing bacteria and viruses. However, if hands are visibly soiled, soap and water must be used.• If using lotion, use a water-based lotion, as petroleum-based lotions have been shown to weaken the properties of gloves.• DHCPs should change from scrubs to personal clothing before returning home.Upon arriving home, DHCPs should take off shoes, remove and wash clothing (separately from other household residents), and immediately shower.There are some similarities between COVID-19 symptoms and other upper respiratory illnesses. It is critical that until a patient is tested and diagnosed with COVID-19, individuals who present with such symptoms should be kept in quarantine to prevent spread. These are outlined in Table 4 .Due to the nature of the virus, and not being able to determine if an individual is COVID-19 positive but asymptomatic or pre-symptomatic, dental professionals could be exposed to the virus without knowing. A question that many dental professionals have is what steps need to be taken if they unknowingly treated a COVID-19 positive patient. The World Health Organization (WHO) has reported guidelines to follow if and when health care workers (HCW) have been exposed to the COVID-19 virus. The management of HCW exposed to COVID-19 varies according to the risk categorization.• Recommendations for HCWs at high risk of exposure (see Fig. 1 ):• Stop all health care interactions with patients for a period of 14 days after the last day of exposure to a confirmed COVID-19 patient. • Be tested for COVID-19. • Provide psychosocial support to HCW during quarantine, or throughout the duration of illness if HCW is confirmed to have COVID-19. • Provide compensation for the period of quarantine and for the duration of illness (if not on a monthly salary) or contract extension for the duration of quarantine/illness. • Provide a review of infection protection and control training for the health care facility staff, including HCWs at high risk for infection after a 14-day quarantine period.• Recommendations for health workers at low risk of exposure (see Fig. 1 ):• Self-monitor temperature and respiratory symptoms daily for 14 days after the last day of exposure to a COVID-19 patient. • HCWs should call the health care facility if they develop any symptoms suggestive of COVID-19. • Reinforce contact and droplet precautions when caring for all patients with acute respiratory illness and standard precautions for all patients • Reinforce airborne precautions for aerosol-generating procedures on all suspected and confirmed COVID-19 patients. • Reinforce the rational, correct, and consistent use of personal protective equipment. • Apply WHO's ""My 5 Moments for Hand Hygiene"" before touching a patient, before any clean or aseptic procedure, after exposure to body fluid, or touching a patient, and after touching a patient's surroundings. • Practice respiratory etiquette at all times.Funding No funding was obtained for this article.Conflict of interest No conflicts of interest to declare with the writing of this article.",USA,first author,2021-02-04,02
328f9952814645dca0b2345b5f46a5204f3ab824,"COVID-19, Intimate Partner Violence, and Communication Ecologies","IPV is a pernicious and preventable social and public health problem, where approximately 25% of women and 10% of men in the United States experience some form of IPV in their lifetime (Center for Disease Control and Prevention, 2020) . According to U.S. crime reports, approximately 16% of all homicide victims are killed by an unique to the situation caused by COVID-19 is that there is no place for IPV victims to go to escape the abuse. They may call a hotline number and receive psychological assistance over the phone, but police are being strongly encouraged to not make arrests for anything other than felonies. Also due to COVID-19, IPV shelters are not open or being staffed for those fleeing abusive relationships (Brooks, 2020; Elinson & Chapman, 2020; Mock, 2020; Taub, 2020) . Recent media coverage further suggests that IPV is increasing globally, with reports from Wuhan Province, China that IPV rates were 3 times higher in February 2020 than the same time period the previous year (Wanqing, 2020) , with similar reports in Spain, Italy, and Brazil (Kelly, 2020) . Because of the similarities and differences of COVID-19 to other disasters, more research is necessary to understand how disaster response and recovery strategies can be leveraged in response to COVID-19 and reduce IPV victimization.A communication ecology is a conceptual model used to analyze and visualize relationships among social interactions, discourses, and communication materials that individuals depend on to achieve a goal (Broad et al., 2013; Shah et al., 2017; Turner et al., 2010) . Communication ecologies have been defined as ""a network of communication resource relations constructed by individuals in pursuit of a goal and in context of their communication environment"" (Ball-Rokeach et al., 2012, p. 4) . Recently, communication ecologies have been applied in the context of disasters to construct a framework toward understanding how communication resources are utilized across multiple systems (e.g., micro, meso, macro) to cope with challenges occurring before, during, and after disasters (Houston, 2012; Perreault et al., 2014; Spialek & Houston, 2018) . For example, disaster communication ecologies can encompass various systems and sectors such as individuals, community organizations, media (e.g., traditional and social), disaster warning systems, and governmental organizations (Houston, Hawthorne, et al., 2015) . Within these various systems and sectors, disaster communication resources fulfill important functions such as receiving information about a disaster (Perreault et al., 2014) , creating and sustaining social support (Houston, Spialek, et al., 2015) , and engaging in disaster coping (Spialek & Houston, 2019; Spialek et al., 2016) . Disaster communication ecologies, therefore, provide an important role in understanding how various communicative systems, resources, and relationships assist in coping with the challenges before, during, and after disaster.In the context of IPV and disaster, scholars have highlighted the importance of communication systems and resources to cultivate and promote safety for IPV victims before, during, and after disaster. For example, Buttell and Carney (2009) examined the capacity of the New Orleans Police Department to respond to IPV calls before and after Hurricane Katrina. Their study highlights the centrality of communication resources being available between law enforcement and individuals to help ameliorate IPV effects during disaster. Likewise, First et al. (2017) outline an IPV and disaster framework for IPV professionals to cultivate various capacities that promote IPV victim safety and well-being before, during, and after a disaster. Each of the capacities in the IPV and disaster framework include several components of communication. For instance, capacities include communicative processes such as disseminating disaster and IPV risk information, education, and planning; coordinating disaster and IPV responses; enhancing social support; and constructing survivor narratives (First et al., 2017) . While scholars have highlighted the important role of communication resources to cope with disaster and IPV (Buttell & Carney, 2009; First et al., 2017; Lauve-Moon & Ferreira, 2017) , IPV has yet to be included within disaster communication ecology scholarship. Victims of IPV face compounding stressors and needs during disasters and research into the structure of IPV communication ecologies would provide guidance for developing effective IPV response and recovery strategies in communities experiencing disaster.The overall purpose of this study is to determine levels of perceived stress related to the COVID 19/Coronavirus Pandemic among non-IPV and IPV respondents who experienced the first 10 weeks of the stay at home orders/lockdown during the COVID-19 pandemic and the role of family, friends, neighbors, and government and nongovernment resources in coping with IPV and COVID-19. The guiding research question was to investigate how much of the variance in experiencing IPV can be explained by individual experiences related to the COVID-19 pandemic. More specifically, the purpose of this study is threefold and aims to (a) investigate the role of perceived stress, individual-level stressors, and perceived reliance on resources experienced during the COVID-19 outbreak; (b) present findings from a study active during the COVID-19 pandemic; and (c) add to the literature on how research can better support communication to ameliorate IPV effects during disaster.This study utilizes a cross-sectional design. Data for the study were collected over a 2-month period from an online survey launched the first week of April, 2020. The study was approved by the Tulane University Socio-Behavioral Institutional Review Board. The self-administered online survey was distributed through one of the authors' personal social media accounts (e.g., Facebook, Instagram, and LinkedIn) and advertised on the Tulane University School of Social Work's social media outlets and website for a period of 2 months. The main inclusion criteria for the online survey required participants to be older than 18 years and have direct access to the survey link. Exclusion criteria included those who were younger than 18 years. The survey focus was on participants' (a) previous disaster experience, (b) perceived stress (i.e., PSS), (c) current situation as it relates to COVID-19, (d) experienced IPV, and (e) personal and household demographics. The online Qualtrics survey took approximately 10 minutes to complete.The study sample consisted of individuals having access to the online Qualtrics survey link. Participants were recruited for participation in the study through a mixture of purposive snow-ball sampling with one study author requesting and encouraging participants to share the survey link on their own personal social media accounts, as well as having the survey link displayed on the school's home page and advertised in media outlets for the school. The sample for this study includes 374 adults who completed the online survey. Data analysis was conducted using SPSS 26.Intimate partner violence exposure. The study outcome variable was a binary variable assessing whether an individual experienced IPV (referent).Perceived Stress Scale. The PSS is regarded as a classic stress assessment instrument and shows a correlation with a variety of health-related measures that include stress measures, self-reported health and health services measures, health behavior measures, smoking status, and health-seeking behaviors (Cohen, 1988 (Cohen, , 1994 . Scores on the PSS can range from 0 to 40, with higher values on the PSS indicating greater perceived stress. Scores ranging from 0 to 13 are considered low, 14 to 26 are considered moderate, and 27 to 40 are considered as high. The PSS has been shown to have excellent psychometric properties across a wide range of studies investigating stress (e.g., Lee, 2012; Roberti et al., 2006) .Experiences. The study included several questions related to exposure to COVID-19. The following predictor variables and response categories were included (a) has the COVID-19/Coronavirus lead to you losing your job (1 = yes; 0 = no); (b); has the COVID-19/Coronavirus lead to you losing income (1 = yes; 0 = no); (c) What is your residential status? (1 = renter; 0 = homeowner); (d) How often would you say you are worried or stressed about having enough money to pay your rent/mortgage? (1 = always, 2 = usually, 3= sometimes, 4 = rarely, 5 = never); (e) How often would you say you are worried or stressed about having enough money to buy nutritious meals? (1 = always, 2 = usually, 3= sometimes, 4 = rarely, 5 = never); (f) do you think you will need help and cooperation from others (e.g., family, friends, or neighbors) to recover from the impact of COVID-19/Coronavirus? (1 = very little help, 2 = little help, 3 = neither very little help nor very much help, 4 = much help, 5 = very much help); (g) do you think you will need help and cooperation from others (e.g., government or nongovernmental organizations) to recover from the impact of COVID-19/Coronavirus? (1 = very little help, 2 = little help, 3 = neither very little help nor very much help, 4 = much help, 5 = very much help); (h) how many days have you spent in ""stay at home/lockdown.""The sample of 374 participants had a mean age of 47.01 years (SD = 14.67) and was composed of 74.6% women (n = 279) and 25.4% men (n = 95). The majority of the sample identified as White (86.1%; n = 322). Regarding relationship status, the majority of participants were in a relationship, 55.9% (n = 209). The majority of the sample were employed, with 63.4% (n = 237) reporting being employed at the time of study participation. Regarding education, only 1.3% of respondents had less than a high school diploma (n = 5), while 3.5% had a high school diploma or GED (n = 13), followed by 12.8% (n = 48) with some college, 4.5% (n = 17) held an associate's degree, 25.7% held a bachelor's degree (n = 96), and the majority of the sample held a graduate degree 52.1% (n = 195). The majority of the sample spoke English at home 71.1% (n = 268). Nearly two-thirds of the sample reported owning their home (63.9%; n=239). Of the total sample, 10.4% (n = 39) reported having experienced IPV. Of respondents, 22.9% (n = 86) expressed having stress related to nutrition access. As it relates to mortgage and rent stress, roughly one third (33.6%; n = 126) of respondents expressed stress related to being able to meet mortgage or rent obligations.The subsample of 39 participants who experienced IPV had a mean age of 46.97 years (SD = 14.5), and 74.4% identified as women (n = 29) and 25.6% as men (n = 10). The majority of IPV survivors identified as White 84.6% (n = 33). Roughly half of IPV-reporter were employed (55.1%, n = 20). Regarding education, one third of IPV survivors had a graduate degree (35.9%; n = 14). The majority of IPV-reporters spoke English at home (66.7%; n = 26). Nearly three-quarters (74.4%, n = 29) reported owning their home. Half of the IPV-reporters group expressed experiencing stress as it relates to nutrition access 48.7% (n = 19). Regarding mortgage and rent stress, 56.4% (n = 22) of participants expressed stress related to being able to meet mortgage or rent obligations. Table 1 provides a detailed description of the demographic characteristics for the total sample and the IPV-reporter group.In order to investigate how much of the variance in experiences of IPV can be explained by perceived stress and personal experiences related to the COVID-19 pandemic, one binary logistic regression model was performed along with one independent t test analysis and two Wilcoxon-Mann-Whitney U tests. The regression model focused on experiences related to COVID-19 as predictors of experiences of IPV group membership and a t test tested whether there was a statistically significant difference between the IPV-experienced group and non-IPV experienced group with respect to perceived stress (i.e., total PSS score). To test communication ecology insights elaborated above, we used two Wilcoxon-Mann-Whitney U tests to investigate whether the IPVexperiences group rated the need for communication resources from specifically (a) family, friends, neighbors, and (b) government and nongovernment sources to recover from the impact of COVID-19 higher than the non-IPV experiences group.A logistic regression was performed to investigate how well COVID-19 experiences (i.e., has COVID-19 lead to you losing your job; has COVID-19 lead to you losing income, renter, mortgage/rent stress, nutritional stress, and do you think you will need help and cooperation from others) predicts group membership based on IPV experiences. The model consisted of six predictors and allowed for simultaneous entry of all the independent variables. 1 All assumptions of logistic regression were met. The odds ratios of the logistic regression model are presented in Table 2 .A test of the full model against a constant-only model was statistically significant (χ 2 = 24.22, degrees of freedom [df] = 6, p = .001). The model R² indicates that the model accounted for 13.3% of the total variance. Prediction success for the cases used in the development of the model were high, with an overall success rate of 89.9%. This suggests that the set of predictors successfully discriminates between group membership based on experiences of IPV.Three of the predictor variables, loss of income due to COVID-19 (Wald χ 2 = 3.882, df = 1, p = .049, 95% CI [0.227, 0.996]), renter status (Wald χ 2 = 3.954, df = 1, p = .047, 95% CI [0.191, 0.988]), and nutritional stress (Wald χ 2 = 6.267, df = 1, p = .012, 95% CI [1.288, 7.991]) were statistically significant predictors of group membership based on IPV experiences. Based on the model, respondents who reported income loss due to COVID-19 were 47.2% more likely than those who did not lose income to report IPV-experience. Similarly, renters were 43.5% more likely than homeowners to belong to the IPV-experiences group. Respondents who reported nutritional stress were 3.2 times more likely to belong in the IPV-reporters group than respondents who did not report nutritional stress.An independent sample t test was performed to determine if there was a difference between the non-IPV (did not experience IPV) and experienced IPV subsamples on the PSS. The mean PSS score for the non-IPV group was 16.02 (SD = 5.99) and for the experienced IPV group was 19.33 (SD = 7.75), indicating that the experienced IPV had higher levels of perceived stress compared with the non-IPV group. This difference was significant, t (365) = −3.148, p = .002) with a small effect size (Cohen's d = .4779). Results are presented in Table 3 . Note. n = 355. Degrees of freedom = 6. IPV = intimate partner violence; CI = confidence interval; LL = lower limit CI; UL = upper limit CI; SE = standard error. *p < .05. **p < .01. ***p < .001.A Wilcoxon-Mann-Whitney U test was performed to determine if those in the IPV experiences group rated a need for help and cooperation from family, friends, and neighbors to recover from the impact of COVID-19 higher than those in the non-IPV group. The mean rank for the IPV experiences group was 220.85 and for the non-IPV experiences group was 183.62, indicating that the IPV experiences group rated their need for help from others greater than the non-IPV experiences group. This difference is significant (U = 5232; p = .03). A second Wilcoxon-Mann-Whitney U test was performed to determine if those in the IPV experiences group rated a need for help and cooperation from government and nongovernment resources to recover from the impact of COVID-19 higher than those in the non-IPV group. The results were not significant. Results are presented in Table 4 .The results of this study are important because they represent one of the first assessments of the relationships among the COVID-19 pandemic, IPV, and stress. This study found that although only 10% of the sample reported experiencing IPV during the pandemic, the people that had experienced IPV reported more stress globally than the segment of the sample that had not experienced IPV. Furthermore, the results of the t test indicate that as perceived stress increases, as measured by the PSS, participants are more likely to end up in the IPV subgroup. Importantly, these data do not suggest causality and there is no way to determine if IPV was present in those relationships prior to the pandemic. What the data do suggest, however, is that experiencing IPV is related to reporting more exposure to stress. The results of the logistic regression equation help flesh out the relationship between stress exposure and experiencing IPV in a little more detail. That model suggests that as respondents were more likely to be renters, suffer a loss of income and be worried about adequate nutrition, they were more likely to experience IPV. This finding makes intuitive sense and is consistent with the extant literature on IPV and external stressors (e.g., Barton & Bryant, 2016; Capaldi et al., 2012; DeMaris et al., 2003; Neal & Edwards, 2017; Schwab-Reese et al., 2016) . In brief, as people find themselves in a more tenuous financial situation due to COVID-19, there are more things to worry about and subsequently argue about. In many instances, that type of situation leads to an occasion for IPV. In our sample's case, as people lost their jobs and suffered financial losses, they also likely increased their worry about eviction. This conclusion makes sense, as homeowners have been far more likely to receive accommodations from lenders who want to avoid another housing collapse like the one in 2008 (Goodman & Magder, 2020) . However, many landlords still want their rent and the media has covered the issue of eviction moratoriums and the end of those protections (e.g., Goldstein, 2020) . Consequently, throughout the pandemic many renters have feared they will be forced to leave when they can no longer pay rent. In fact, in a recent analysis of the relationship between concerns about housing and loss of income during the years following the great recession in 2008, Schneider et al. (2016) found that unemployment and economic hardship at the individual household level were positively related to abusive behavior. In essence, as people suffer from a lack of income and worry about paying their rent, there are more opportunities for relational conflict as uncertainly and anticipatory anxiety either exacerbate existing IPV or create the first occasion of IPV in a relationship. The data generated for this study was collected during a 2-month period of the early pandemic, April and May 2020. It is notable that even that early in the pandemic, respondents were reporting a moderate level of stress. Apart from the timing of the data collection, the overall sample was White (86.1%), women (74.6%), employed (63.4%), and homeowners (63.9%) with either a college or graduate education (77.8%). Almost all of these attributes serve as protective factors in resilience models and yet the total sample reported experiencing moderate levels of stress at the beginning of the pandemic. One can only speculate on what the level of reported stress might be now, more than 6 months into the pandemic. Of particular concern for this study was the finding that the subset of the sample who reported experiencing IPV were significantly more stressed at the time of study participation than the non-IPV group. Although not captured in the data for this study, it seems reasonable to conclude that the overall level of stress experienced by this sample has increased dramatically since the time of study participation and that this increase has had a disproportionate negative impact of the subsample that experienced IPV.The findings from this study have important implications for expanding communication ecology research related to IPV and disasters. The findings suggest that in pandemic disasters, the efforts to corral and contain the virus might inadvertently contribute to a dramatic rise in IPV. Therefore, to address the increased risk of IPV during a pandemic, IPV risk information, education, and planning should be foregrounded in conversations about public safety precautions in a pandemic (Bradley et al., 2020; Moreira & da Costa, 2020) . For instance, in our survey, we used two questions to measure perceived resource needs from family and friends and a second question regarding government and nongovernment resources. Of the subsample that did not report IPV experiences, approximately 12% reported they anticipated needing help or much help from friends, families, or neighbors, while 25% of those in the IPV subsample reported the same. This is more than a twofold increase in terms of perceived reliance on others for help during a pandemic for those who are experiencing IPV. Moreover, given the results of the Wilcoxon-Mann-Whitney U test, we found that the IPV experiences group was significantly more likely to anticipate needing more help and cooperation from family, friends, and neighbors than the non-IPV experiences group. Prior studies in disasters and IPV have noted the protective role of social support for those experiencing both disaster and IPV (Kaniasty, 2012; Voth Schrag et al., 2020) . Our survey asked respondents to indicate how much help they were likely to need from government and nongovernment resources. Of the subsample with no reported experiences of IPV, almost one fifth (19.5%) thought they would need much or very much help from these resources. This is contrasted with almost a third (30.8%) of the subsample who reported IPV experiences that indicated they thought they would need much or very much help from government and nongovernment agencies. Although the statistical test proved not significant, these differences are descriptive but informative. The difference in the two subsamples is telling in that those affected by IPV may be more likely to need help from government and nongovernment agencies. During the pandemic this help may refer to unemployment, rent or mortgage assistance, and nutrition assistance. Whatever help this form may take is an opportunity for government and nongovernment agencies to communicate with individuals affected by IPV about potential resources available to them, particularly in times of crisis, such as the pandemic. These other forms of assistance could serve as a site of connection to IPV-related resources through affective communication. Similar to how medical professionals ask their patients if, ""they feel safe at home,"" COVID-19 testing sites could partner with IPV organizations to incorporate screenings for IPV during COVID-19 testing (Anurudran et al., 2020) and provide information handouts and hang posters, so that the general public can be aware of IPV resources that are available.In addition, greater efforts in public awareness campaigns should be expended to raise awareness about the increased risk for IPV and the service availability for IPV protection during a pandemic (Jarnecke & Flanagan, 2020) . As our findings show, experiences of IPV might prompt a need for more communication resources from their families and potentially from government and nongovernment sources for support and information. This could be the case because of the strain of IPV increases the need for such resources or it could be the case that IPV survivors start with lower levels of resources. Our analysis cannot say definitely, but our findings do point toward the need for more communication resources for IPV-reporters. This is particularly important given that those affected by IPV are more likely to need help from their friends, families, and neighbors during the ongoing pandemic. Furthermore, as research has suggested in other disaster contexts (First et al., 2017; Lauve-Moon & Ferreira, 2017) , by providing public awareness on resources to the broader community, community members, trusted friends, neighbors, and family members may be better able to connect those affected by IPV with resources, such as shelters, treatment intervention program, and therapeutic professionals (e.g., social workers, psychologists, etc.). Likewise, government agencies and nonprofits that address IPV as a normal function of their missions should be included in policy decisions related to coordinating IPV responses and resources in a pandemic, to ensure that affirmative steps are taken to protect the members of this vulnerable population during the pandemic.It is necessary to note some important limitations of this discussion. First, there may be other factors for why a greater number of those in the IPV subsample expressed needing help from neighbors, family, and friends and government and nongovernment agencies than the non-IPV subsample. Second, we did not ask on the survey how likely they were to utilize these resources, only if they anticipated needing help and cooperation from these sources. More research (suggested below in the research agenda section) is necessary to better determine the relationships between IPV, disasters, and effective communication strategies to reduce IPV in disaster contexts. Third, this sample was overrepresented by White participants and women and had high levels of education and differs from more U.S. representative samples.In the current study, we highlight key predictors of stress related to IPV during COVID-19 and explore the importance of communicating these risk factors to increase protective responses for individuals experiencing IPV. By understanding predictors of stress related to IPV, we can extrapolate how communication resources can be improved and implemented to promote protective behaviors and coping during disasters like the COVID-19 pandemic. However, more research is needed to inform COVID-19 communication ecology focused on IPV. Below we highlight additional areas for research focused on IPV communication ecologies during COVID-19.First, future research should examine the protective role of online IPV interventions and digital services (e.g., video conferencing and digital communication platforms) during COVID-19. IPV health information and IPV-related services have been widely accessed through internet-based interventions and mobile phone applications during COVID-19. Communicating with IPV survivors through technology (e.g., chat, video, text) comes with benefits and risks (e.g., safety, loss of privacy, and confidentiality) and more research is needed to further understand these benefits and risks during pandemics.Second, future research should examine the role of social media in IPV communication ecologies for providing social support for IPV survivors. While prior research has long examined the important role of social support for individuals experiencing IPV, more research is needed to understand benefits and risks of seeking support online during COVID-19. For example, social media could be a platform for receiving emotional and informational support for IPV survivors (Chu et al., 2020) . However, social media could also induce nonsupportive and victim-blaming messages (Whiting et al., 2019) and more research is needed to further understand the risks and benefits of social media in IPV communication ecologies.Finally, research on IPV and disaster/pandemics is often considered a homogeneous category, thus implicitly assumes that individuals experiencing IPV essentially share the same life experiences. However, in reality, various dimensions of social inequality (e.g., gender race and ethnicity, migration, class, physical ability) can intersect to create unique challenges for individuals experiencing IPV during a pandemic. Future research should examine various dimensions of social vulnerability and IPV risk from an intersectional framework to further inform what factors constrain or facilitate the inclusion of different IPV communication resources during COVID-19.This study adds to the scant literature on IPV, communication ecologies, and pandemics. We endeavored to identify key predictors related to stressors due to COVID-19 of IPV. Given findings from this study, governments must do more to communicate the multiple stressors resulting from the pandemic, such as rent and nutrition stress, which likely exacerbate IPV. In addition to strengthening communication strategies alerting the public to these additional stressors and their potential to add to relationship stress, governments must do more to alleviate these stresses in the form of rental and nutrition assistance. Doing so will most likely reduce the exacerbated prevalence of IPV. Last, we have identified key areas for future research to extend knowledge into communication ecologies, IPV, and disasters to help inform decision makers on how to best communicate risk factors and coping strategies. Fred Buttell has extensive experience in providing social work intervention services to clients in community-based correction programs and in evaluating the effectiveness of these social work interventions. His latest research interests focus on improving family functioning through the elimination of domestic violence and his primary research interest is on improving the effectiveness of batterer intervention programs. Most recently, he has been publishing on the intersection between IPV and LGBTQ offenders and ethical considerations of conducting research in a postdisaster context. Jennifer First is an assistant professor in the College of Social Work at the University of Tennessee, Knoxville. Her research focuses on human experiences with disaster events and the consequences of collective trauma. Her research aims to improve the mental health and wellbeing of individuals and communities experiencing environmental threats while addressing issues of equity and social justice.",USA,first author,2021-02-06,02
6c913d26a2c084806872bc9916ab61e2ba64663f,"COVID-19 Communication Ecologies: Using Interpersonal, Organizational, and Mediated Communication Resources to Cope With a Pandemic","as individuals have experienced increased anxiety, depression, and grief reactions (Eisma & Tamminga, 2020; First et al., 2020) . These mental health reactions are often related to knowing someone affected by COVID-19 (e.g., experiencing the death of a family member related to , worrying about keeping oneself and family members safe, experiencing uncertainty about the severity of and susceptibility to the disease, attempting to cope with financial impacts resulting from the pandemic, and being disconnected from others as a consequence of isolation, quarantine, and lockdowns.A variety of resources are needed for individuals to successfully cope with a public health emergency like the COVID-19 pandemic. Specifically, people need health care, economic, social welfare, and communication resources. In the case of COVID-19, health care resources include vaccines to prevent the disease and medical treatment for individuals who are ill. Economic resources include financial assistance and resources for people whose ability to work and earn money has been interrupted by the pandemic. Social welfare resources include assistance with food and housing for individuals affected by the pandemic and the continuation of education despite ongoing social lockdowns. Communication resources include sources of information and support than can help individuals gain information related to the pandemic and stay connected with others.The current issue of American Behavioral Scientist focuses specifically on exploring the role of communication resources during the COVID-19 pandemic. In approaching this topic, contributing authors take a broad, ecological approach to communication resources. A communication ecology perspective considers interpersonal, organizational, and mediated communication resources. Insights from the research included in this issue can be utilized as the world continues to respond to the current pandemic, and can be applied to future public health emergencies and disasters. To begin, a brief overview of the concept of communication ecology is provided and applied to the COVID-19 pandemic.Communication ecologies are ""the networks of communication connections that groups or individuals depend upon in order to achieve a goal"" (Broad et al., 2013, p. 328) . Thus, communication ecologies are goal-specific, so that different ecologies likely exist for varied purposes. Similar to conceptualizations of a disaster communication ecology (see, e.g., Spialek & Houston, 2019) , individuals are likely to construct a COVID-19 communication ecology to meet the goal of coping with the threat and negative impact of the COVID-19 pandemic. Communication resources are included in a communication ecology to the extent that a resource provides utility in meeting the relevant goal (Ball-Rokeach, 1985) .Specifically, individuals may utilize a COVID-19 communication ecology to seek and share information about the pandemic and to gain and provide support (see Figure  1 ). In the modern communication and media environment, individuals can function as both users and producers of information within a communication ecology (Houston et al., 2015) . For example, a person can use a social media site like Twitter to find out article, the authors introduce the communication ecology network (CEN) model, which posits that similar communication resources will cluster together within a communication ecology. Their analysis identifies five communication clusters within the overall network, and they note that the most frequently used communication cluster (television news) was least integrated into the overall ecology. They also assess how communication resource use is associated with belief in COVID-19 misinformation and identify several important relationships. Liu et al. (this issue) analyze social media communication of government and disaster management agencies in the U.S. state of Texas and find that the pattern of communication across the COVID-19 crisis is relatively consistent. Additionally, they find that state and federal agencies function as agenda setters within the communication ecology during the COVID-19 crisis. Tagliacozzo et al. (this issue) explore the communication of public health agencies in three countries (Italy, Sweden, the United States) during the early period of the COVID-19 pandemic. They find that the public health agencies relied on their own scientific expertise and coordinated primarily with other government agencies. Across countries, the authors found public health agency information to be lacking for many vulnerable groups (e.g., pregnant women, individuals with disabilities, immigrants, homeless populations).Hernandez and Colaner (this issue) conducted interviews to understand how children manage chronic uncertainty about COVID-19 in communication with their parents. Their results indicate that children use family communication with parents to navigate uncertainty related to COVID-19, media, politics, and time. The authors also Note. In a community ecology, communication resources are potentially connected directly (via interpersonal interactions that occur in person) and through mediated interactions (via traditional or social media).find that that families most often reference macro communication resources as important sources of information to help with COVID-19 uncertainty. Perreault and Perreault (this issue) examine the role of journalists and news organizations during the COVID-19 pandemic. Journalists and news organizations function as both an important source of information during a public health emergency like COVID-19 and also draw from other resources in the communication ecology to inform their reporting. Perreault and Perreault interview journalists and find journalists' connections with other communication resources in the ecology to be strained as a result of the health threats resulting from COVID-19 and the economic threats to journalism that predate the pandemic.Cannon et al. (this issue) consider the specific stressors that are associated with the occurrence of intimate partner violence (IPV) during COVID-19. They find that income loss, nutritional stress, and housing characteristics are related to an increased prevalence of IPV during the pandemic. The authors discuss the communication resources needed to support individuals experiencing IPV given these results.Each of these articles examine one or more specific aspects of COVID-19 communication ecologies to expand our understanding of how a variety of communication resources can foster individual and collective coping with a public health crisis like the COVID-19 pandemic.The author declared no potential conflicts of interest with respect to the research, authorship, and/or publication of this article.The author disclosed receipt of the following financial support for the research, authorship, and/or publication of this article: The topic for this special issue was identified through a COVID-19 Communication Ecology Working Group that was supported by the National Science Foundation-funded Social Science Extreme Events Research (SSEER) network and the CONVERGE facility at the Natural Hazards Center at the University of Colorado Boulder (NSF Award #1841338).",USA,first author,2021-02-09,02
c945f27b62b57ff58369f3aadd20a539ec488837,"U.S. Children ""Learning Online"" during COVID-19 without the Internet or a Computer: Visualizing the Gradient by Race/Ethnicity and Parental Educational Attainment","The coronavirus disease 2019 (COVID-19) pandemic has caused unprecedented disruptions to education globally and in the United States, with a large proportion of schooling moving to distance-learning formats that require access to the Internet and computer technology. We use data from the weekly Household Pulse Survey (U.S. Census Bureau 2020), a rapidly deployed, representative sample of the U.S. population, describing early trends in the fall 2020 school period (August 19 to October 26). We estimate that 58.1 percent (95 percent confidence interval [CI] = 57.5 percent to 58.7 percent) of U.S. children participated in online learning. Of these, 10.1 percent (95 percent CI = 9.6 percent to 10.6 percent) did not have adequate access to both the Internet and a computer or other electronic device used for educational purposes (Figure 1 ; see supplement for sample sizes and confidence intervals).Lack of adequate access varied nearly 20-fold across the gradient of parental race/ethnicity and education, ranging from 1.9 percent (95 percent CI = 1.2 percent to 2.7 percent) for children of Asian parents with graduate degrees to 35.5 percent (95 percent CI = 24.1 percent to 47.0 percent) among children of Black parents with less than a high school education ( Figure 1 ). These rates varied fourfold by race/ethnicity, ranging from 3.8 percent (95 percent CI = 2.8 percent to 4.9 percent) for Asian parents to 15.6 percent (95 percent CI = 13.5 percent to 17.7 percent) for Black parents, and fivefold by parental education, ranging from 3.9 percent (95 percent CI = 3.5 percent to 4.3 percent) for parents with graduate degrees to 20.3 percent (95 percent CI = 16.5 percent to 24.2 percent) for parents with less than high school education.Even before COVID-19, the United States had profound and persistent disparities in educational attainment and learning by race and social class (York 2020) . The results presented here concur with those of recent studies suggesting that COVID-19 may be further exacerbating existing gaps in schooling (Bacher-Hicks, Goodman, and Mulhern 2020) and extends them to the fall 2020 school period. Children expected to participate in online learning without adequate technology are highly unlikely to achieve significant learning compared with their peers to whom more resources are available. Falling behind in learning goals, they may also be more likely to leave school entirely.By visualizing the gradient by parental race/ethnicity and education, we highlight that COVID-19 is likely potentiating the intergenerational propagation of gaps in educational outcomes and moreover in a differential manner by race/ethnicity. These findings therefore demonstrate that disparities in remote learning during COVID-19 must be examined in an intersectional fashion (Bhopal and Preston 2012) . Stratification by parental race and education revealed disparities along both dimensions, with specific subgroups exposed to large magnitude disparities. Future studies should examine how racial/ethnic and social class differences also may vary by geography, potentially reflecting the diversity of educational approaches taken by municipal and state government in response to COVID-19-related disruptions.As education is a key social determinant of health, and a driver of economic opportunities, the implications of these widening education gaps are myriad and may ripple out into disparities in numerous sectors of society (Lim et al. 2018) . These trends highlight a need for renewed investments in ensuring universal access to distance-learning resources for all children in the United States and may have implications for school districts and states making decisions regarding school closures.The author(s) disclosed receipt of the following financial support for the research, authorship, and/or publication of this article: This work was primarily supported by the Bill and Melinda Gates Foundation (OPP1152504). JF received support from the UCLA Medical Scientist Training Program (NIGMS training grant GM008042).Joseph Friedman https://orcid.org/0000-0002-5225-3267 Figure 1 . Percentage of children (ages 0-18 years) learning online whose parents reported that they had inadequate access to the Internet or a computer or other electronic device used for educational purposes in the fall 2020 school period (August 19 to October 26), shown by parental race and parental education gradient. All intersections are shown as well as marginal values. All percentages represent survey-weighted values. See the supplement for confidence intervals and more details regarding methodology.",United States,abstract,2021-02-17,02
9b0608c384429011121234a20df480de3749d49e,Incorporating Near Peers for Teaching and Fast Feedback in a Rapidly Developed Virtual Pediatric Clerkship Curriculum in Response to the COVID Pandemic,"Asynchronous and hybrid learning curricula have been emerging as practical and effective alternatives to traditional learning modalities. However, staffing and logistical challenges have precluded universal uptake. In March 2020, New York City became the epicenter of the COVID pandemic, and medical students were removed from the clinical environment, first in front-line areas and then entirely. As students were in the middle of their Pediatric rotation of their major clinical year, the remainder of the clerkship needed to be revamped and completed remotely. Additionally, given clinical needs, limited faculty were available for engagement in this remote curriculum. This need precipitated the rapid development of a virtual curriculum based in hybrid learning principles and near peer teaching, designed to replace the remaining weeks of the clerkship but with applications for future teaching.To address the need for curriculum modifications, the clerkship director (CD) and resident as teacher (RAT) curriculum director developed a hybrid learning curriculum using near peers to deliver parts of the curriculum and supplement clinical experiences. Near peers included the ""Teach Resident"" (TR), a resident on a rotation designed to develop their teaching skills, and the senior medical student liaisons (SMSL), who are two 4th year students facilitating feedback between the clerkship students and CD.A backward design and student-centered design framework allowed us to center the principles of identifying the desired results for student learning, determine acceptable results and plan learning experiences and instruction accordingly [1, 2] . In terms of curricular material, a variety of learning modalities and curricular elements were organized into daily themes and adapted for virtual use or newly developed. Teaching tools included virtually adapted existing elements of the clerkship, curated external resources, and novel virtual internal resources. Virtual, asynchronous elements were supplemented with interactive teaching from the TR and SMSLs to enhance learning and skills. Curricular elements were organized into thematic modules for students to complete daily. Modules included high yield pediatric topics including neonatal jaundice, abdominal pain, and the newborn physical exam. Adapted clerkship didactics included virtual interactive lectures, team-based learning over Zoom using breakout rooms (e.g., common infections), and resident conferences and existing outside online pediatric education resources, such as Aquifer asynchronous pediatrics cases, education videos from OPENPediatrics, and podcasts from Peds Cases. The curriculum also included novel internal resources such as pediatric elements from a residency preparation curriculum for graduating students, local student-developed highyield online learning modules, and additional didactics created by the TR and SMSLs. The TRs taught interactive case-based chalk talks designed to enhance both clinical reasoning and review pediatric pathology. The SMSLs taught via educational gaming and a personalized shelf review session. Additionally, both the TR and SMSLs provided direct feedback to the CD on the new curriculum and students' experiences to the CD to ensure student wellness, engagement, and satisfaction, further supported by CD-scheduled end-of-day check-in calls with 4 students per day.To evaluate success of the novel curriculum, student evaluations, NBME shelf exam scores, and videoconference attendance were assessed. Student end of clerkship evaluations across six categories, including those relating to teaching, learning, and overall quality, did not differ significantly between the pandemic-impacted rotation and the prior five rotations ( Table 1 ). The mean score of the NBME shelf exam was within 1 standard deviation of the national mean for quarter 1. Students remained consistently engaged in the curriculum, with 85 to 90% of students attending virtual sessions and always communicating when they had to miss. Students remained engaged even after the clerkship ended, attending general and shelf review sessions with the TR, CD, and SMSLs.Given the positive outcomes of these curricular changes and the ability to continue using virtual resources, some elements of this curriculum will be incorporated into the clerkship going forward to improve access to educational opportunities. The TR had provided near peer education for students on the inpatient portion of their clerkship, and virtual technology can now include outpatient students and those on services or at affiliate hospitals without a TR. The continued use of this hybrid learning expands teaching availability and opportunities, regardless of students' individual clinical encounters. Additionally, the SMSLs and TR, as near peers who are close to the content and level of the students, provided support and directed guidance on high yield educational topics and resources [3, 4] . The use of near peers also distributes teaching hours among multiple training levels, reducing the dependence on faculty [5] . Finally, using the SMSLs and TR as a source of confidential and collective feedback allows for more rapid cycle changes than can be implemented when using rotation evaluations, and this drives further innovation and curricular advancement. Combining self-directed asynchronous and hybrid educational approaches incorporating near peers will serve clinical learners in this new COVID reality. ",USA,first author,2021-02-23,02
6a6a233c8eadea8d15ab359b56b23a260a5123a2,"Trends in Educational Technology: What Facebook, Twitter, and Scopus Can Tell us about Current Research and Practice","vernacular to articulate our experiences and struggles-such as ""lockdown,"" ""crisis teaching,"" and ""Zoom fatigue""-and though the novel virus introduced many new challenges, it also served as an accelerant of many existing trends and challenges facing the field. This is especially noteworthy as it casts attention upon insidious tensions within our research and practices involving inequity, scalability, sustainability, privacy, and practicality (Dwivedi et al. 2020; Williamson et al. 2020) .Exactly how this past year shaped educational technology and its future as a field is a complex question; nevertheless, in this editorial, we will continue our ongoing efforts to use large-scale public data sources to illustrate emergent trends and trajectories (Kimmons 2020) and articulate some takeaways that should guide us in moving forward. Building off of previous studies that have analyzed many of these data sources for several years Trust et al. 2020 ), we will focus the current analysis on three data sources:(1) posts on U.S. school and district Facebook pages (n = 17.9 million posts by 15,728 institutions), (2) original Twitter posts with the #EdTech hashtag (n = 131,760 tweets by 24,561 users), and (3) research article titles and abstracts provided by the Scopus API for top educational technology journals (n = 29,636 articles from 34 journals).Such broad-scope analyses are essential for the field as they allow us to see the big picture of what has been happening over time, enable us to step out of our insulated experiences as singular researchers and practitioners, and help us to consider where our collective attentions are focused and where missing links might exist (Bodily et al. 2019; Kimmons 2020; Lin et al. 2019) . These analyses rely wholly upon public data sources available through the internet , and though not exhaustive or representative of all contexts, they open up a window to view current trends in their complexity and from different angles, thereby offering implications for research and practice and suggesting ongoing course corrections into the future.Facebook is a social networking platform that is actively used by many individuals, schools, and districts throughout the U.S. and worldwide. We previously estimated that 44% of schools in the U.S. use the service , and it is estimated currently that 69% of adults in the U.S. also use Facebook (Perrin and Anderson 2019) . Such ubiquity means that schools can use Facebook as a low-stakes, highimpact communication medium to share information and engage with many parents and community members quickly.Starting with identifiers provided by the National Center for Education Statistics (2019), we accessed the contents of the homepage for each U.S. school district and public school and identified all of the external links from these pages using the R statistical software (R Core Team 2021). Among these links, we selected those linking to Facebook pages of any kind and identified 7744 unique districts and 7984 schools 1 with pages (for a total of 15,728 unique K-12 educational institutions). These were associated with a total of 13,127 unique Facebook pages, as some districts and schools linked to the same page. We then applied for and gained access to the CrowdTangle platform (CrowdTangle Team 2020), which is owned by Facebook and provides access to the posts of public pages and groups on Facebook to academics and journalists, and uploaded all of the Facebook links we identified. Finally, we used the historical access feature to download all of the posts from the identified pages for 2005-2020, which resulted in downloading the data for 17,979,285 posts, including their date and time, message (text) content, and the number of reactions and comments for each post (see Fig. 1 ).Analyses revealed significant variation between and within years, with a general pattern of more posts in each subsequent year and more posts in the Spring and Fall relative to the summer (and to the time coinciding with the winter holidays). This trend may represent increased technology tool use for school-home communication within the years and a typical pattern of school activities and related communication across the U.S. academic year. While we cannot say based on this figure alone, the events of 2020 may suggest interpretation for the pattern found in school Facebook activity across 2020. A great deal of activity in Spring 2020 is possibly due to districts and schools responding to the pandemic; then in the later part of the year, the lower activity than expected may have resulted from fewer posts about typical topics and activities (i.e., athletics) that occurred at lower rates due to pandemic restrictions.To understand trends in posts about educational technology-related topics over time, we considered the technologies identified by Weller (2020) in his history of the past 25 years of educational technology. From Weller's list, we searched for keywords associated with each technology (e.g., ""LMS"" for ""learning management system"") in posts and organized results by year to see how mentions of technologies aligned with Weller's timeline (see Table 1 ).Our results-presented by year-indicate that a number of topics were posted about relatively frequently, including videos, blogs, Twitter and social media, the web, and e-learning, each of which was posted more than 10,000 times, with videos and blogs included in more than 300,000 and 200,000 posts, respectively. Wikis and learning management systems were also referenced in many posts, with each being posted about more than 1000 times. While it may be that reference to some of these topics was in the context of using a feature of the Facebook platform itself (e.g., sharing a video), others, such as e-learning, are probably independent of any functionality of Facebook, and, even knowing that districts and schools posted more than 100,000 videos in 2020 (relative to less than 10,000 in the period from 2010 to 2012) suggests marked increase in use and interest in the technology. Conversely, many topics that one might expect to be posted about with some degree of frequency were included only infrequently (e.g., digital badges, open textbooks), while some were posted relatively infrequently, but perhaps more than one would expect given that these were posts by Facebook accounts associated strictly with districts and schools (e.g., artificial intelligence, second life, and virtual worlds).Next, we focused on the domains of links that districts and schools posted. We chose to focus on the most recent three years of activity (2018-2020, n = 9,868,611 posts) and used the urltools R package (Keyes et al. 2019) to extract the domain (e.g., dreambox.com) from the URL, which was often directing the reader to a specific page (or resource) on a larger domain. Finally, we aggregated the data at the district and school level and examined whether the district or school posted a link to a specific domain in 2018, 2019, and 2020. We also manually removed links to URL shorteners (e.g., bit.ly, t.co) and other social media platforms, inferring that many of these were crosspostings between or across platforms. Links from these pages, we inferred, could speak to what resources, tools, and platforms districts and schools both communicated about and therefore used in a way that was not otherwise practical to determine at such a scale. Organizing these links by domain and year allowed us to determine the most-shared external resources over the course of the three years (see Table 2 ). Note that this table represents the number of unique institutions sharing one or more links for each of the analyzed years (rather than the number of posts including a link or links to the domain).Results indicated that Google-owned domains (YouTube, Docs, Search, Drive, Sites, and Accounts) represented the top four most-linked-to domains for all three years (see Table 1 ). This is not surprising as these domains support school and district communication by finding, sharing, and managing documents, videos, and other files. Scheduling and survey tools (such as Survey Monkey, EventBrite, and Signup Genius) were also commonly posted each year, as was the communication tool Smore, a tool for education-related products (Scholastic). Notably, Zoom was the fifth most-shared domain in 2020 but was not among the top-25 in 2018 or 2019. Also, notably, Center for Disease Control links were common in 2020 but were much less common in previous years.These results support previous studies on links provided on K-12 school websites (Kimmons 2020; ) and show that schools use Facebook as a way of coordinating various efforts and disseminating information from a variety of sources primarily for communication purposes to support school management processes and typically utilize free generic, non-pedagogical tools. Furthermore, though 2020 saw a greater emphasis on a few specific tools (such as Zoom) and information sources (such as the CDC) as well as increased activity overall, the general nature of the activity did not change much, with most tools that were being used in previous years also being used in 2020 and in similar orders of frequency. Furthermore, the frequency of communication clearly represented the schools and districts' responses to communication and other needs across a typical academic year (years 2010-2019) as well as showed clear evidence of rapid responsiveness to exceptional events (2020).From this analysis of school Facebook pages, we conclude that (a) schools are increasingly using the social medium as a means of communication, (b) the degree of use generally increased in conjunction with the pandemic but the type of use did not meaningfully change, (c) schools are increasingly sharing more media, information, and productivity tools (e.g., forms, scheduling) as time progresses, and (d) some of these activities align with Weller's historical observations while others do not. Note. The number of institutions sharing one or more links in 2017 was 12,927, with 13,719 in 2019 and 14,982 in 2020. The number of institutions sharing one or more links can aid in the interpretation of the above frequencies; for example, the 10,217 institutions sharing links to Google Docs in 2020 made up 66.7% of districts sharing one or more links #EdTech on TwitterTwitter is also a popular social networking platform that is estimated to be used by 22% of adults (Perrin and Anderson 2019) and 40% of schools in the U.S. . Like Facebook, Twitter is generally a public platform that schools use to broadcast information to their communities ), but it also allows for discussions surrounding various topics to emerge organically via hashtags as users openly participate in ""affinity spaces"" with others who are interested in similar topics (Carpenter et al. 2019; Gee 2004; Trust et al. 2016 Trust et al. , 2020 . In our field, #EdTech has emerged as a popular affinity space on Twitter for schools, teachers, businesses, and thought leaders to discuss matters of interest and to share resources freely with one another. To post to the hashtag, users do not need to be accepted to a group or meet any other vetting criterion, which means that the space is an open one and reflects diverse perspectives, opinions, and lives of those who are merely interested in participating in the broad #EdTech conversation.To identify trending topics, we used a custom PHP/ MySQL collector to constantly query the Twitter Search API from February to December 2020, collecting all English-language original tweets using the hashtag #EdTech. Because the collection mechanism relied on persistent monitoring of the Twitter API, there were some instances of lapses or errors in the data collection. Overall, however, collected tweets generally represented most weeks of the studied year with the only major gaps occurring before March. The final dataset represented tweets from 311 out of the 365 days in 2020 (or 85.2% of days) with an average of 424 tweets per day (SD = 175.4) by 289 distinct users per day (SD = 120.8).This provided a dataset of 131,760 original tweets representing 24,561 distinct users. We calculated descriptive statistics of results and found that users exhibited a highly positive skew in their posting activities. This behavior was expected (based on previous studies done on Twitter, such as Veletsianos and Kimmons 2016) and led us to follow Van Mierlo's (2014) 90-9-1 principle to classify users into relative activity groups as either: Superusers (top 1% posting content), Contributors (next 9% contributing content), or Lurkers (the remaining 90%; see also Mockus et al. 2002) . Results indicated that Superusers posted almost as much as the remaining 99% of users (representing 45.9% of all tweets), out-tweeting Contributors at a rate of 16-to-1 and Lurkers at a rate of 144-to-1 (see Table 3 ).We then extracted co-occurring hashtags from tweets, which consisted of additional hashtags that were included in #EdTech tweets, revealing the thematic categories, topics, or descriptors that authors assigned to their tweets or showing us what they were sharing or thinking in relation to their educational technology tweets. Table 4 provides the top 15 most common co-occurring hashtags, with #education, #edchat, and #remotelearning being the three most common. Of these, #education and #edchat are expected to be consistent across years given the general nature of the #education hashtag and the prevalence of #edchat as an affinity space closely related to #edtech. Notably, however, ranked hashtags 3 through 6 were all related to remote, online, or distance learning, which was certainly influenced by the onset of #covid19 (ranked as #7 in the list) early in the year. To illustrate this relationship, #remotelearning tweets spiked in April with #covid [related] tweets (outperforming the other related hashtags) and then dwindled significantly by September, suggesting that as the COVID-19 pandemic continued, #remotelearning information, resources, and activities became more normalized or replaced (at least in name) by #elearning and #onlinelearning (see Fig. 2 ).We then parsed tweet texts into individual words and bigrams (i.e., two words in succession, such as ""online learning""), as we expected these to augment the co-occurring hashtag data with more implicit topics that users might not have felt merited topical tagging (e.g., ""Google"", ""privacy""). These were constructed into word trees around the two most common words-""education"" and ""learning""-to reveal how common words were used in relation to one another with relative size differences representing frequencies (see Figs. 3 and 4). Of these, common phrases like ""higher education,"" ""online education,"" ""online learning,"" and ""distance learning"" were expectedly found, but so too were more unique and unexpected bigrams, such as ""democratise education,"" ""learning group,"" and ""emotional learning,"" revealing specific topics important to #EdTech tweeters. Furthermore, to show the prevalence of K-12 vs. higher education interaction in this space, a keyword search revealed that many more tweets referenced a variant of ""K-12"" (n = 3892) than did ""higher"" (n = 2997), suggesting the K-12 community was slightly dominant.Finally, we collected all referenced hyperlinks to determine what external resources authors linked to in their tweets. Overall, 92.1% of all tweets included a link of some kind (including links to images), revealing that the #EdTech hashtag was heavily used for sharing resources or images and organizing discussion around these resources rather than simply stating ideas, beliefs, or attitudes (as might be visible with other broad hashtags like #education). Of these, links to the news site EdSurge were the most universally shared by community members, followed by YouTube videos and Paper.li content (see Table 5 ). Other sites that made the list included influencer websites (like Shake Up Learning), education news sites (like EdSurge, EdTechMagazine, and Edutopia), social media (like LinkedIn and Instagram), generic news sites (like Forbes and New York Times), tools (like Google Docs), and others. Some of these results were similar to those found on Facebook (e.g., the prevalence of YouTube), but the preponderance of news sites suggests that the #EdTech affinity space was much more focused on sharing information and news while the Facebook pages were being used more for communication and collaboration purposes.From these Twitter #EdTech results, we conclude that (a) COVID-19 both explicitly and implicitly shaped the #EdTech affinity space in 2020 with most discussions revolving around remote, online, distance, and blended learning, (b) ""remote learning"" emerged in conjunction with COVID-19 in April but then became normalized as ""elearning"" or ""online learning"" shortly thereafter, (c) shared resources are heavily informational (e.g., news sites) or media-based (e.g., video sharing), and (d) though the #EdTech affinity space is broad and involves many people, trends are heavily directed by a relatively small group of Superusers.And finally, to see how these trends connected to patterns in the educational technology research literature, we also extracted all article titles and abstracts from the Elsevier article search database, using the Scopus Search API (Elsevier, n.d.), for many of the top educational technology journals. We identified journals by referring to Google Scholar (n.d.) h-indices for journals organized in the ""Educational Technology"" category and further supplemented this by a popular list of educational technology journals by Perkins and Lowenthal (n.d.), covering the years 2000 to 2020. In total, our list included 34 journals with 27,219 articles with titles and abstracts (or 29,636 articles with only titles), representing 1296 articles per year (SD = 881.9) and 801 articles per journal (SD = 1059.2).Querying the Scopus API, we used a series of cURL commands using PHP and analyzed and stored title and abstract word frequency results in a relational MySQL database, organized by journal identifier and year of publication. We then considered word and word-pair (bigram) frequencies in both article titles and abstracts to better understand topics for each year. To improve the accuracy of word counts, we used PHP to remove stopwords (e.g., ""a,"" ""an,"" ""the""), numbers, capitalization, and punctuation and to reduce words to their stems (e.g., converting ""learn,"" ""learns,"" and ""learning"" to ""learn*"").The most common keywords in titles included generic keyword stems like ""learn,"" ""education,"" ""teach,"" and ""technology"" but also included specific modalities or technologies like ""online,"" ""computer,"" etc. (see Table 6 ). ""Student*"" was the second most-common word and (combined with ""learner"" being grouped with the top word ""learn*"") suggests the literature is largely student-or learner-centric in this regard. However, without context, it was difficult to glean much from single terms, because each could be used in diverse settings to reflect various meanings (such as ""social"" being used for a technology like ""social media,"" an outcome like ""social-emotional health,"" a classroom strategy like ""social interaction,"" etc.). Title bigrams were a bit more helpful in this regard and revealed that titles included common references to (a) educational settings, such as ""higher education"" or ""high school,"" (b) modalities, such as ""learning environment"" or ""online learning,"" (c) pedagogical approaches, such as ""project/problem/game-based learning"" or ""collaborative learning,"" (d) specific technologies, such as ""social network"" or ""social media,"" (e) research subjects, such as ""school student"" or ""preservice [teachers] ,"" (f) learning outcomes, such as ""problem solving"" or ""language learning,"" or (g) research methods, such as ""student perception"" or ""learning analytics"" (see Table 7 ). Identical analyses of abstracts revealed similar results, with generic words like ""learn,"" ""student,"" ""result,"" and ""education"" being the most common. Removing common distractors like ""results show,"" bigrams were again more instructive and yielded similar results to titles but also provided greater representation of specific research methods, such as ""structural equation,"" ""mixed method,"" ""quasi-experimental,"" and ""randomly assigned."" Notably, all of these most popular methodological bigrams were either quantitative (e.g., ""structural equation"") or had a quantitative component (e.g., ""mixed methods""), suggesting that the research literature in these journals is largely quantitative or that qualitative methodological identifiers (e.g., ""grounded theory"", ""phenomenology"") are more varied or less likely to be mentioned in abstracts.Because the word stem ""learn"" (and specifically the full word ""learning"") was found to be the most common word in both titles and abstracts, we then constructed a series of word trees showing its common relationship to other words (excluding stopwords) for both the 2001-2010 and 2011-2020 timeframe (see Figs. 5 and 6). These word trees showed that ""learning"" was most often used in contexts like ""online learning,"" ""collaborative learning,"" ""language learning,"" ""learning environment,"" ""learning performance,"" and ""learning management."" Comparing the two timeframes showed subtle changes between the decades, with ""self-regulated"" and ""game-based learning"" becoming more common and emphasis increasing on ""learning management"" and ""performance"" in later years.Because ""online"" was the most common co-occurring word with ""learning,"" and because of its relative importance during 2020 with the shifts resulting from COVID-19, we also constructed word trees showing its common relationships to other words for 2001 -2010 and 2011 . These word trees showed that ""online"" was most often used in contexts like ""open online,"" ""multiplayer online,"" ""learning online,"" ""online learning,"" ""online course,"" and ""online social."" Comparing the two timeframes showed subtle TechTrends changes between the two decades, with ""open"" and ""social"" contexts of ""online"" jumping to the top of the list.As with the analysis of the Facebook data, we also used keyword searches for each of Weller's (2020) identified technologies and topics against article abstracts to determine their prevalence in the research literature (see Table 8 ). Generally speaking, most identified items saw a sizable uptick in representation in the years following Weller's identified year-suggesting a slight delay between when a technology or topic had come on the educational technology scene and when it became represented in the literature. However, a few notable exceptions to this pattern included blockchain, open textbooks, personal learning environments, connectivism, and elearning standards, as all of these topics seemed to remain rarely represented in the literature. This might reflect the difference between the permeation of an idea versus its suitability Note. Asterisks indicate that the term could be identified with any ending. For example, learn* would identify the inclusion of learns, learning, and learned Note. Asterisks indicate that the term could be identified with any ending. For example, ""high* + education*"" would identify the inclusion of ""higher education"" and ""higher educational"" as a topic of targeted empirical study, as in the case of connectivism, but it also might represent simple delays between practice and research, as in the case of blogs and wikis, which did not see a sizable increase in article representation until 5-10 years after Weller's identification. Such a lag might explain lack of blockchain research (given its relative infancy), but there do seem to be some technologies and topics that have been of interest in educational technology for 7+ years that still remain largely underrepresented in the literature, such as e-learning standards, open textbooks, and personal learning environments. From these analyses of Scopus-provided research articles, we conclude that (a) online learning remains preeminent as the most-researched area in educational technology, (b) the past decade has seen a shift to connecting this to tools and activities that are more ""open"" and ""social,"" and (c) there seems to remain a lag or disconnect between technologies that are actually being used in educational institutions and the research base supporting or guiding their use (cf., Kimmons 2020), with some topics not being taken up by researchers practically at all.In addition to offering insights into educational technology behaviors and trends, these analyses offer a mirror for the educational technology field itself in a few key areas. First, one of the more subtle findings from the Scopus dataset indicates positivist or quantitative preferences and tendencies in methodological choices, suggesting limited methodological pluralism (Kimmons and Johnstun 2019) . Indeed, this is not a new finding (e.g., Carr-Chellman and Carr-Chellman 2020 and the 2020/5 systems thinking and change special issue of TechTrends), yet, it is one that requires careful consideration and the possible need for adjusting the field's overall philosophical orientation. Our selection and array of methods should mirror the complexity of issues, phenomena, and questions found in our field. As we examine human behaviors related to learning, teaching, and development of thought and language, we need methodologies and research designs that are sensitive to these complex and dynamic realities. In addition, we need a rich array of research methods that would better allow us to see these complicated patterns and make new connections, as well as, confront the demanding issues of causality and generalizability in more sophisticated and nuanced ways. The analysis of public data presented in this article is one example of a technique that can be brought to bear on emergent educational problems, but if the problems we face in educational technology are complex, situated, and diverse, then our research methods should reflect this broadly.Second, the year 2020 brought about many dramatic upheavals for societies and institutions, especially in response to COVID-19, and our results support the notion of responsive shifts and adjustments in educational technology, such as the rapid emphasis on ""remote learning"" in April. However, one of our takeaways from this analysis was that most changes in 2020 seemed to be changes of degree rather than kind and that in many ways the educational technology field was already trending in directions that seemed to be necessary for addressing the pandemic before it started. Some examples of this include the following findings from this study:& social media had been gradually adopted by schools and used as a rapid communication platform with parents and community members leading up to 2020; & much of the research literature prior to 2020 had focused on topics that were necessary for enacting technology-mediated, socially-distant teaching; & and, many schools, teachers, and education leaders were already using existing tools necessary for socially-distant teaching and connectedness prior to 2020 in key ways for improving productivity and sharing valuable practices, resources, and expertise.We do not point this out to minimize the difficulties or immense tolls that the pandemic exacted upon students, parents, educators, and institutions, but it does seem clear that our collective abilities to respond to and cope with the pandemic would likely have been even far more strained if these tools, practices, and research topics had not been so firmly in place, to begin with. That is, though we as scholars and academics generally feel far more comfortable and safe heaping criticisms upon and deconstructing existing systems than we do in praising what has come before, we should acknowledge that educators' and institutions' heroic responses to the pandemic were at least partially made possible or supported by the groundwork that the educational technology community established in prior years. So, for that, we should be grateful and pleased.And third, though the long-term impacts of the pandemic on our students and our institutions are still poorly understood (Kuhfeld et al. 2020) , it at least seems that we have been moving in some good directions and that problems and difficulties in our educational institutions that were laid bare by the pandemic can now be taken up with renewed effort, focus, and hope that we can realistically conquer them. Perhaps the most glaring inadequacies that we must continue to address in educational technology revolve around issues of inequity, practicality, scalability, sustainability, privacy, and dissemination. Notably, many of the benefits provided by the groundwork noted above are dependent upon individual educators' and institutions' existing social capital, networks, and literacies (Veletsianos and Kimmons 2012) . Also, though much research may have already been done on the topics that were needed to address the challenges of the pandemic, whether such studies were sufficiently accessible, practical, or situated in authentic contexts to realistically be of help to struggling schools and educators is another matter (Reeves and Lin 2020) . Indeed, the ability to benefit from existing work and research in our field may largely depend upon local social capital and economic resources and will therefore require close partnerships with educators and youth and their families moving forward (Greenberg et al. 2020) . This is especially true in the cases of marginalized, underserved, and disenfranchised communities. This is especially important to recognize as current trends in the U.S. and elsewhere may be leading to increased segregation and disparities based on race, income, and other factors (Orfield and Frankenberg 2014) , and COVID-19, in particular, seems to be amplifying a variety of inequities related to educational access, economic security, and health care (Fortuna et al. 2020) . In this context, we note that inequity was not a theme strongly represented in our analyses. This may reflect both the focus of the research journals and the nature of the communities included in our analyses. Therefore, as we consider how well-prepared practitioners were for this past year, we must do so with persistent educational inequities in mind and move forward in ways that seek to improve learning for all.In our estimation, some of the ways this analysis might look different if our field was fully committed to addressing both the problems of today and tomorrow would include the following. First, we would see more situated work in practical contexts working with educators to address local problems and to communicate these solutions in ways that are transferable to other contexts. Second, we would see more focus on providing learning and professional development opportunities to all students and teachers via free and open formats, including open educational resources, open textbooks, and open pedagogies (and do research on these activities). Third, we would care less about the newest, expensive gadgets and focus more of our attention on the underlying pedagogical, access, and equity issues governing their use. And fourth, we would further eschew easy, silver-bullet answers to pernicious education problems and embrace the complexity, messiness, and situatedness of the work we do, while simultaneously helping policy-and decision-makers to do the same. Making such adjustments to our field requires concerted effort, but if 2020 has taught us anything about the people working in our field, we should acknowledge that change is constant and that our professionals are resilient and capable, even in the face of heretofore unimaginable crises.",USA,first author,2021-02-24,02
82e2928a10349cb4486ab00fa295164f1b78f6f7,,"prototypic lysosomal disorder Gaucher disease, investigators were initially concerned that with SARS-CoV-2 infection, both the lysosomal involvement and the accompanying cytokine storm or dysregulation of inflammatory cytokines might augment Gaucher disease pathophysiology, resulting in increased mortality in infected patients.During the early phase of the pandemic, a group of Gaucher investigators together identified potential Sars-CoV-2-related management challenges specifically for the Gaucher patient population, providing some suggestions and identifying concerns requiring additional research (Mistry et al., 2020) . These included the need for epidemiological studies, studies regarding the response of patients with Gaucher disease to Sars-CoV-2 and/or its pharmacological interventions and investigations into the impact of Sars-CoV-2 disease on the Gaucher patient community. Moreover, they addressed the challenges to maintaining ongoing requirements for health-sustaining medical treatments for lysosomal diseases, such as regular infusions of costly intravenous enzyme preparations that require access to providers and specialized clinics. There was also at least a theoretical concern that patients with Gaucher disease might be especially at risk if early Sars-CoV-2 treatments like hydroxychloroquine, that could disrupt autophagy needed to maintain homeostasis, were administered. In response to this call to action, both patient groups and physician investigators have attempted to educate and to survey the Gaucher patient population to assess the evolving impact of the Sars-CoV-2 disease and pandemic on their care and health (Elmonem et al., 2020; Fiumara et al., 2020; Riccio, Pieroni, Limoneglli, & Pisani, 2020; Sechi et al., 2020) .Emerging clinical reports like the study by Fierro et al provide some preliminary reassurance for the Gaucher patient population (Fierro et al., 2021) . Focusing on patients exposed to the virus in the early New York City epicenter, the authors conducted a cross-sectional study in a cohort of 181 patients with Gaucher disease that included 150 adults and 31 children. Among this Gaucher cohort, 71% were chronically being treated with either enzyme replacement or substrate inhibitor therapy. Approximately one third of the adults reported being exposed to SARS-CoV-2, although the majority of these respondents did not develop symptoms. Of 94 patients tested by serology, 18 had positive results. Comorbidities, GBA1 genotype and the type of Gaucher disease therapy did not correlate with the probability of being symptomatic or testing positive.Major confounding variables affecting the interpretation of this study are related to the rapid evolution of the pandemic and our understanding of SARS-CoV-2. Much of the data in this Gaucher study were collected early in the pandemic and did not include state-of-the-art quantitative testing or diagnostic confirmation. Instead, out of necessity in light of the period when the data was collected, the authors had to rely on a symptom scoring system based on patient reporting. Only 18 of the 181 patients surveyed reported having experienced three or more related symptoms. Fourteen of the 18 had clinical diagnostic testing, with 10 having SARS-CoV-2 positive results, making it more difficult to ascertain the true incidence of infection in this cohort. The Gaucher patient cohort studied was not particularly diverse, being mostly of were no mortalities. As the SARS-CoV-2 pandemic has evolved, additional reassurance against a high rate of infectivity or incidence of Sars-CoV-2-related complications in Gaucher or lysosomal disease patient cohorts has begun to emerge from reports of Sars-CoV-02 cases in patients with lysosomal storage disorders in Europe, (Andrade-Campos et al., 2020), Israel (Zimran, Szer, & Revel-Vilk, 2020) and Morocco (Naima Fdil, 2020). The series from Spain (Andrade-Campos et al., 2020) did describe one SARS-CoV-2 -related death in a 79-year-old patient with Gaucher disease who had various comorbidities including diabetes. As in the general population, it is logical that older age and other comorbidities are also negative prognostic factors for those with Gaucher disease.It is anticipated that there will be many subsequent reports assessing the impact of the pandemic on specific populations of patients with rare disorders. Now that more quantitative testing and antibody assessment is more accessible, it should be easier to characterize such cohorts with increased precision and by more rigorous standardized clinical research criteria. Such criteria should encompass at least three aspects of disease acquisition and surveillance, including the type and route of clinical diagnostic determination of disease, as well as the presence or absence of Sars-CoV-2 antibodies, the detailed timeline and course of disease, and the impact on the underlying disorder. In order to facilitate comparisons to other cohorts, it is critical that descriptions of the disease course include an accurate timeline of the disease progression, the range of associated symptoms, and disease parameters reflecting the severity of infection.Reports of the impact of Sars-CoV-2 on the patients' underlying disease should include relevant tracked biomarkers and other associated laboratory values, as well as assessments regarding potential exacerbation of underlying conditions or comorbidities. Rigorous longitudinal studies J o u r n a l P r e -p r o o f might also uncover unanticipated long-term disease sequelae. Such data may better guide treating providers in establishing consensus management guidelines for the remainder of this or future pandemics.Another fascinating aspect mandating additional investigation is whether the relatively low incidence and relatively benign course of Sars-CoV-2-related complications in patients with Gaucher disease may be opening a window into an unanticipated phenomenon, protective of Sars-CoV-2 infection and/or its complications. There has been preliminary speculation, based on the low number of cases of Sars-CoV-2 among patients with Gaucher disease in Israel and Australia, that the accumulated glycosphingolipids in patients with Gaucher disease might promote immune tolerance rather than enhancing inflammation as a result of exposure to the virus (Zimran et al., 2020) . Similar to what has been hypothesized in Nieman Pick type C, it is possible that the inherent Gaucher disease and abnormal lysosomal environments in general may be an ""unfavorable"" milieu for SAR-CoV-2 infectivity (Ballout, Sviridov, Bukrinsky, & Remaley, 2020) . Additional carefully collected epidemiological data may help to determine whether the infectivity and disease manifestations in patients with Gaucher disease or other lysosomal storage disorders differs from the general population. If this indeed is true, further study of the factors underlying this observation could lead to novel and improved therapeutic avenues for patients infected with Sars-CoV-2.",USA,first author,2021-02-24,02
b61b02654c5f54fded1d3718713801ad21b59b0c,Ashes2Art: Mitigation Strategies for Short-and Long-term Distress in Emergency Services Personnel During COVID-19,"Our country is in the midst of a public health pandemic while simultaneously experiencing widespread economic, social justice and political crises, all of which are taking a significant biopsychosocial toll on many individuals, families and communities. Indeed, studies show that biological, man-made and natural disasters significantly impact wellbeing, increasing anxiety, depression and other mental health symptomology (Fergusson et al. 2014) . Furthermore, studies show that cumulative exposure to disasters increases risk for both poor mental health (e.g., anxiety, depression, posttraumatic stress disorder) and poor physical health (Lowe et al. 2019 ). Studies show stress in firefighters increase on-duty, as compared to off-duty, and increase over time on shift; while, heterogeneity in off-duty stress may be accounted for by different family-life experiences and available supports (Courtney et al. 2020) . Specifically, firefighters and other first responders experience notable burdens during this pandemic (Miller 2020) . For example, emergency services personnel, including firefighters, have high risk of occupationrelated disease or infection exposure (Baker et al. 2020 ); thus, COVID-19 exposure risk is of natural heightened concern for firefighters and their families.Pre-disaster racial and socio-economic disparities influence post-disaster resiliency outcomes (Mayer 2019) ; and, COVID-19 data show alarming racial and socio-economic disparities (Roland 2020). For example, predominantly African-American counties are three times as likely as predominantly white counties to contract COVID-19 and six times as likely to die from the disease (Yancy 2020) . The country's long-standing structural inequities and adverse social determinants of health, such as housing and food insecurity exposed by this pandemic, and the civil protests against racial injustice and systemic inequities, add layers of uncertainty and emotional intensity to the existing public health crisis for both those who seek help in the pandemic and those working on the pandemic frontlines (Roland 2020).Thus, there is significant concern for emergency services personnel during this pandemic, with increasing role strain and disruptions to their work-family life. Studies show frontline workers have important concerns about their professional role during and after disaster relief efforts. For example, workers during war experience permeable boundaries between their professional work life and family life, exhibiting heightened worry about their families' safety (Segal-Engelchin et al. 2020) . Chronic trauma exposure from man-made or natural disasters, especially experienced early in one's career, can have long-term impact on physical, mental and interpersonal functioning (Bracken-Scully & McGilloway 2016) . Emergency services personnel, during the COVID-19 pandemic, experience similar worry, and are uniquely affected by mandatory quarantine after traumatic exposure. In line with prior research, first responders worry for colleagues and, when isolated from family, worry about their families contracting the virus. As part of their work, they confront acute grief and loss often without timely mechanisms in place to process and appropriately grieve. Concern about family safety as well as one's health, along with the uncertainty, social isolation and exposure to loss and trauma, are all significant enduring challenges confronting frontline workers and first responders during the COVID-19 pandemic. Table 1 illustrates the extreme polarities experienced at the convergence of these crises. Living at the extremes across these domains, while simultaneously needing to isolate from friends and family, poses a serious risk to wellbeing. Extended social isolation, whether through formal workplace quarantine protocols, Governors' stay-at-home orders, or self-imposed isolation due to fear, has created gaps in meaningful human connection. For example, one-fifth of adults in the United States, before the pandemic, experienced loneliness or social isolation, and those who experience loneliness are more likely to have physical and mental health problems (DiJulio et al. 2018) . Heightened anxiety experienced due to social distancing protocols in both work and family domains can create discontinuity in these supportive relationships (Walsh 2020) . For firefighters, this has been particularly challenging. These cumulative stressors about family health and well-being, specific to this pandemic, in addition to the routine cumulative stress exposures inherent in emergency services personnel's daily work, create a condition where the risk to mental and physical health is high for this population, with further research needed to design tailored interventions. For example, Courtney, Lipsey, Braun, Henry, Nelson and Li (2020) state: ""Future research examining how firefighters' lives outside of their jobs relate to stress and tiredness could aid researchers in identifying potential interventions for reducing firefighters' mean stress and stress variability"" (p. 868).Self-care strategies can be effective in mitigating these outcomes. Organizational implementation of self-care strategies can decrease burnout and enhance well-being. For example, a mindfulness-yoga intervention decreased stress and anxiety and increased resilience in healthcare workers (Ofei-Dodoo et al. 2020) ; and, informal debriefings led to increased compassion satisfaction and decreased burnout in fire and rescue personnel (Miller & Unruh 2019) . Although many organizations are increasingly recognizing the importance of self-care for emergency services personnel, the format is typically didactic and information-driven, rather than experiential and oriented around skill development. The self-care needs of emergency services personnel and their families, amplified by the current pandemic, require more than just information distribution, to also include experiential opportunities to learn valuable self-care techniques. Thus, providing a safe space for community connection, selfexpression through artistic skill development, and emotional communication from a strengths-based framework, tenets of social work practice, are implemented in Ashes2Art classes. Ashes2Art is not a structured therapeutic intervention with treatment goals; rather, it offers open, experiential creative arts classes that focus on self-care and promote wellness among emergency services personnel and their families.Mindfulness-based stress reduction is evidence-based with demonstrated effectiveness in improving mental health in healthcare professionals (Shapiro et al. 2005) . For example, in a sample of 121 firefighters, four-weeks of mindfulness, as compared to relaxation training or no training control, increased resiliency (Denkova et al. 2020) . Mindfulness (2019) used a structured intervention that included mandalas for meaning-making around topics of self-care and professional purpose. Social workers routinely use mindfulness training, focused on developing awareness, attention, and cognitive control in response to sensory input, in their health promotion work (Garland et al. 2015) . Social workers skilled in mindfulness techniques could integrate that training with the physical engagement of the creative arts to offer a holistic mind-body self-care experience for clients in crisis. Finding personal sources of meaning during crisis is a significant predictor of successful functioning (Masterson-Duva et al. 2020), and mindfulness-based creative arts that promotes attention to present experiences with active engagement strategies designed to reduce reactivity to those experiences, stands to increase resiliency (Beerse et al. 2020; Ho et al. 2019) . Feeling connected to a community-based arts group can facilitate wellbeing by building trusting relationships with other group members, an experience called ""collective bonding"", and by developing a sense of purpose and competence through learning and enacting new skills (Williams et al. 2019) . Studies show that even a short-term (45 min) unstructured art-making session can decrease cortisol levels and stress and increase joy (Kaimal et al. 2016) , suggesting even making materials available with minimal instruction may allow for meaningful creative engagement in a process that brings about enhanced well-being. A scoping review by the World Health Organization (WHO) summarized the impact of the creative arts on preventing and treating both physical and mental illness and in promoting physical, social and mental well-being (2019). For example, drawing offers opportunities for self-regulation and can facilitate meaningmaking out of challenging experiences:Collages and drawing classes have been found to improve inter-professional working and to help identify team issues for doctors and nurses (462,463), while art appreciation classes have been found to improve tolerance with ambiguity (464). Arts activities can reduce exhaustion and death anxiety and increase emotional awareness in those working in end-of-life care (465). (Fancourt & Finn 2019, p. 28 ).Segal-Engelchin, Achdut, Huss and Sarid (2020) described an arts directive used to help workers cope during war-time crisis. Participants were asked to draw a stressor, draw coping resources, and then to create an integrated drawing that incorporated the stressor and coping resource, which they found facilitated stress reduction, particularly when the size of the stressor was minimized in the new integrated drawing. Prior research has shown that transforming a stressful image can bring healing and growth and decrease stress (Huss & Sarid 2014) , perhaps because art-making experiences allow for safe distancing from raw feelings, while still allowing the artist to remain engaged with the emotional content embodied in the creative work (Mastandreal et al. 2019) . The critical and creative thinking skills gained from direct participation in arts programming and the safe, reflective and open social space it creates may facilitate both intra-and interpersonal growth.Art-making invites exploration of the inherent opposites and extremes that reside within the same contained space, offering the viewer the opportunity to expand ideas and grow in flexibility from initial interpretation through sustained engagement with the piece (Hass-Cohen & Findlay 2015). Art-making allows artists and viewers into a dynamic and interactive relationship with the artwork in a negotiated space where the ambiguity of dualities can be addressed though interaction with the artwork (Barberian et al. 2019) . In this way, art-making can broaden perspective, with the power to reveal new understanding of the current pandemic polarities (see Table 1 ) -art-making has the power to reduce these gaps across polarity extremes in essential ways. For example, themes of exhaustion and energy; fear and reassurance; tension and release; vulnerability and safety can be explored. Art-making encourages expression, control, hands-on support, and making creative connections within a safe and bounded visual space. Active engagement with the art materials, expression through the art process, and processing of the art product, can foster movement on the crisis-to-growth continuum towards energy, release, calm, and connection (Hass-Cohen & Findlay 2015).Ashes2Art, a nonprofit organization working with fire fighters and first responders since 2017, promotes creativity to counter balance the exposure to extreme loss and trauma, and to process post-traumatic stress. Operating under the Northern Virginia Emergency Medical Services Council, Ashes2Art provides art supplies, art classes, and a creative community of support to mitigate the deleterious effects the stress of the job can take on fire fighters and first responders' health and mental health. Ashes2Art does not provide therapy, but offers a creative arts space (arts instruction and art supplies) to teach fine arts techniques and build strong relationships within the emergency services personnel community. Individuals in need of a formal therapist-led psychotherapy group would be encouraged to seek that outside of their participation in Ashes2Art. The art classes are led by a trained artist, who also has a clinical background and degree, who is able to skillfully gauge the cognitive and emotional climate of the classes and redirect the instructional material according to the needs of the group. The focus is on teaching art skills and facilitating open-ended, generative creative solutions.In some classes, responders were asked to use household items found at the stations or at the responder family homes to create their artwork, leveraging their creative resiliency. Giving an initial ""partial directive"" is important because instructions that are too prescriptive can narrow the window for creative engagement, while partial structure is still necessary to allow participants to get started in the artmaking -as the facilitator suggests to participants in the following phrase: ""You get to mess up here!"" -whereas, mistakes in their profession can mean the loss of life. The facilitator must be perceived as authentic and genuine in nature to gain the trust of this responder population -attention to the interpersonal relationship with responders is critical to the successful engagement of class participants. Art classes give participants a safe space to talk, connect and creatively problem-solve, as well as provide an intermediary platform to facilitate bonding that extends beyond the class itself. Many participants continue their art projects with family even after the class is over, which is representative of successful self-care and connection.Firefighters and other emergency services personnel can maintain continuity in social connection through art-making. During the COVID-19 pandemic, Ashes2Art has seen an increased demand for art supplies and the, now online, creative arts classes. Approximately 100 emergency services personnel, including emergency room nurses, dispatchers, Transportation Security Administration (TSA), airport authority, paramedics, firefighters, law enforcement, search and rescue and their families have been served by the program in the greater Washington, DC region since the start of the COVID-19 pandemic. This novel coordinated effort, among typically disparate emergency services branches, aims to continue building an inclusive community of emergency services personnel, where the creative arts can help them connect and network in ways that strengthen support and improve well-being. Peer support is a key resource to Ashes2Art programming. Peer support offers emotional and instrumental support to participants, with credibility and trust coming from their shared professional career experiences. Peer support specialists participate in a training curriculum and are the liaisons to each of the participating fire stations for Ashes2Art initiatives. Fairfax County Fire and Rescue peer support personnel have been pivotal in implementing the Ashes2Art platform.Managing the cumulative exposure to acute stress over a typical 30-year fire fighter career, requires a repertoire of effective coping strategies and adaptive tools. Sensory experience associated with traumatic exposure -the smells, sights, taste, touch and sounds -can reside within a person, embedded in brain and body, for long duration post-exposure (Hass-Cohen & Findlay 2015). Art technique classes can be useful after experiencing difficult responder calls, as art classes require utilization of the whole brain, allowing for the titration of emotions and cognitive control, as opposed to relying on compartmentalization of the experience -""…the use of words relates to cognitive rather than visceral reactions, which allows for emotional distancing and mastery"" (Barberian et al. 2019, p. 355) . Compartmentalization can be a necessary skill to manage in the short-term; however, it can get in the way of being able to integrate new experiences in the longterm (Bracken-Scully & McGilloway 2016). Art classes invite the artist into learning experiences where they can tolerate a range of feelings and come to realize they can still function well afterwards.The mandala can be a vital regulation and wellness tool (Henderson et al. 2007 ). The mandala, a technique where artists create their work inside either a pre-designed controlled space, which sometimes uses the Zentanlge method or a blank circle, has a strong research base as a technique that improves well-being (Campenni & Hartman 2020) . Mandalas have been used to evoke safety as a response to trauma exposure in frontline workers (Grebe 2019) , and randomized controlled trials show mandalas decrease anxiety and negative mood (Babouchkina & Robbins 2015; Carsley & Heath 2019; Lee 2018 ) and enhance state body mindfulness (Campenni & Hartman 2020) . The mandala principles of ""center and periphery"", acknowledge impermanence through awareness of the present and the skill of 'letting go': ""The way to overcome the apparent contradiction between letting go and helping others is to cultivate a view that fuses compassion and wisdom"" (Van Gordon et al. 2017 , p. 1722 . Mandala work enhances observational skills through sustained attention, helping the artist sit well with an image, being present for the moment. Sitting well with an image through sustained observation allows one to release attachment gently and to let go once completed -without judgment. Whitaker (2016) suggests: ""Observation is the crux of discernment. Wanting to skip past observation to judgement is a form of racing to the end instead of staying in the weeds. Art is already intimately linked to observation"" (p. 79).Three Ashes2Art examples, the Mandala Challenge, a Stress Ball Activity, and the Virtual Family Summer Arts Camp, are described, illustrating how active engagement safely emerges during an art-making experience and can, over time, help to facilitate a move from crisis toward growth.A ""Mandala Challenge"" was offered at fire stations throughout Fairfax County. Peer support and Ashes2Art joined together to provide the necessary art supplies and instructional materials, delivering art supplies to all of the stations within their three shifts. A video contained the project instructions and announced there would be an accompanying raffle for the stations, with the winning station receiving a gift certificate and a donation from Ashes2Art to the Firefighters Fund. Once stations started the challenge, others readily joined. Some firefighters brought the supplies home to work on with their families, and workbooks were brought to those in quarantine who were using their own art supplies to complete the projects. Over 70 mandalas were submitted and turned into a final workbook which will be available for download from the website for responders and families. A second multi-state ""Mandala Challenge"" is in the planning stages, starting with Virginia, Maryland and Washington, DC, where first responders will exchange mandalas, designing mandalas for others to create, and alternatively creating mandalas from the others' designs. In the co-design and creation of these mandalas, shared stories will be communicated, and these shared stories as expressed through the co-constructed mandala project will be digitized into an online art gallery.As a platform to relieve stress and enhance support and connection, the stress ball activity includes an integration of a participatory experience and a structured observational analysis. Participants were asked to crumple a piece of white copy paper in a tight ball, and to use art materials (e.g., markers, paints, oil pastels, chalk) to illustrate using color how their tensions and stress might look when most intensely experienced. They were then invited, when ready, to unfold the stress ball and carefully observe the flattened piece of paper. Dialogue focused on comparison between the 3-dimensional experience and the flattened two-dimensional paper, both of which held the same visual content, but yielded divergent perspectives when displayed differently, illustrating that what is observed may be different depending on its presentation even if it holds the same information. The unfolding process, analogous to change, may alter perspective, as participants observe the vast open white space available when that which was tightly held is released. Giving mindful attention to the nuances and details of the wound tension -to the unfolding -and to the new engagement with the opened work, allows new interpretations to emerge, such as deciding what to do now with the newly revealed open space. Participants often recognized that even if the stress ball was entirely covered in color, when they open it up, they see much more open empty space to work with and fill with what they choose. Contextual inquiry questions can focus the dialogue as ""Contextual inquiry is about asking questions up close and in context, relying on observation, listening, and empathy to guide us toward a more intelligent, and therefore more effective, question"" (Berger 2014, p. 97) . Seeking out self-reflective questions of ""what to do now with the new space I'm confronted with?"" offers hope, inspiration, and control over decision-making about how to use time and about what emotions and behaviors should be let into that newly found space. The activity allowed for the power of kinesthetic stress release, where they could 'talk' about stress then engage in a physical experience to feel the difference between processes.Parental exposure to occupational distress can impact family members' sense of well-being. First responders are exposed to stress-inducing work-related incidents/events. Family environment should be examined as a focus of intervention for emotional regulation and relational support to mitigate the potential negative impact of occupational distress on first responder and family member well-being; and, yet there is no known current evidence-based interventions for first responders' children (Kishon et al. 2020) .This past Summer, Ashes2Art offered its inaugural First Responder Family Summer Arts Camp, with 52 participants comprised of a variety of emergency services personnel, including dispatchers, emergency room nurses, municipal and volunteer fire fighters, airport authority (fire fighters), paramedics and their families. The parents were urged to work with their children which cultivated familial connection between family members and within the responder family, such that two aspects of 'family' could be addressed. The camp focused on check-ins to reduce stress and to enhance responder family bonding. Art supply kits were distributed to all families and, after individual instruction, participants were invited to complete the art projects on their own, coming together as a community during four one-hour virtual video sessions over 8 weeks to share their created works. The work focused on ""basic self-regulation skills"" and ""utilizing the resources around you"", with a broad goal to diffuse stress so it does not become cumulative. Participants used tempura paints and made handkerchief batiks, blind contour line drawing self-portraits, outdoor mandalas, and cardboard sculptures out of packages that arrived during the pandemic. Virtual video sessions allowed families to come together to share and learn from each other, oriented around their art-making projects. The most important goal for the camp was to provide a platform for participants to experience (reexperience) the creative process and to freely explore, overcoming the burden of self-criticism or judgement.Next steps include designing a scientific study to empirically examine the emotional and physiological effects of mindfulness-focused arts programming for emergency services personnel and their families, using participants as their own controls over six-months. We hypothesize that direct and indirect regulation of the autonomic nervous system through modulating sensory input via mindfulnessfocused creative arts participation will reduce physiological distress and enhance first responders' confidence, control and coping during and after this COVID-19 pandemic. Enhanced regulation of the autonomic nervous system through sensory input monitoring and modulation may increase control over behavioral decisions. Control over behavioral decisions, behavioral regulation, is strengthened when a person is able to integrate mental, emotional, and physical (affective/bodily sensations) information (Hass-Cohen & Findlay 2015) . Increased Heart Rate Variability (HRV) is related to improved mental health and may be used as a proxy for underlying regulatory brain changes (Mather & Thayer 2018) ; and, we hypothesize increased HRV and decreased daily stress levels will be associated with increased program participation.Stimuli need to have personal connections and relate to the self to produce meaningful learned outcomes (Ann & Hidi 2019) , and this is accomplished in the hands-on artmaking experience. Digitization of participants' mandalas and other artwork can become ""regulation anchors"" that bring the person back to the original art-making experience, helping to ground and regulate when confronted with acute stress exposure, and potentially mitigating longer-term toxic effects of such exposures. An interactive screen interface that would allow the user to change the sensory characteristics of their digitized creative arts imagery-size, shape, color, texture -would enhance prolonged mindful engagement with the image. Over time, a digitized collection of these mindful regulation anchors could offer individuals real-time regulation tools, and repeated activation of the digitized imagery may train the brain and body to respond differently when presented with stressful situations that endanger well-being. In addition, participants would have the option to network into a creative arts community where their artwork resides in a digitized workbook along with those of other participants, creating a national creative community network by and for emergency services personnel. An inclusive community for connection, support, and compassionate dialogue through creative expression may facilitate a larger framework by which emergency services personnel can respond to and process the many challenges that crisis response brings to their work and family lives. Connecting to a larger support network encompassing their creative works and stories may result in shared learning experiences that leads to a sense of collective success.Social workers actively engage in community work that brings wellness, hope and healing at multiple system levels. This work is most timely and needed right now. Helping first responders and their families manage the short-and longterm emotional toll from the work they do in responding to the COVID-19 crisis is paramount to the United States' successful recovery back to a well-functioning post-pandemic society. Enhancing health and mental health through mindfulness-focused creative arts engagement could be included as one part of routine self-care protocols for first responders and their families. We believe such programming allows first responders to be: Creatively Engaged -Socially Connected -Responder-Ready. A physically and mentally healthy first responder workforce is essential now and throughout postcrisis recovery.Art-making offers strategies and tools that help tip towards the healthy and engaged end of the pandemic polarities, towards unity, connection, control and calm. Sensory support system interventions comprised of their own digitized artwork created out of the art-making experience, may preserve that calming effect by activating the regulated neurophysiological state originally experienced when creating art. Mobile technologies that enable individuals to become aware of when their brains and bodies are reacting to stress exposure provide their digitized mandala substitutions at that moment, along with immediate connections to their virtual and/or live peer support network, will help individuals gain awareness and control over their stress response, and offer a real-time mindful regulation strategy that they have created for themselves (Matto 2015; Matto & Seshaiyer 2018; Matto et al. 2019) .It is critical to be able to detect acute stress and intervene early and effectively. First responders need to be ""battleready"" in their jobs, and the creative arts provide a safe platform to explore and manage the cumulative stress experienced, without causing detrimental vulnerability. Although didactic ""wellness materials"" are dispersed to first responders in great quantity, experiential wellness activities are often neglected at significant peril. Art-making offers the experiential and relational components that allow for the physiological release of embodied stress, and helps participants develop the skills and techniques they can draw on for ongoing self-care. In addition, a future opportunity is for Ashes2Art to provide a platform for community Art-making among emergency services personnel across the country through a national virtual space for creating and sharing artwork and self-care stories. Being able to digitally connect to a virtual network of other participants' artwork, regulation anchors and self-care stories, may offer an important community of support that is readily accessible when needed.",United States,abstract,2021-02-25,02
cd3e51ef3064fc790094d99a85fbbec84cef0bef,Four shareworthy SEPR scenario ideas,"Between September 15 and October 15, 2020, the editor in chief of Socio-Ecological Practice Research (SEPR) Wei-Ning Xiang selected five prospectuses out of the twelve submitted for the special theme issue, Our alternative futures in the 2020s and beyond: Scenarios of socio-ecological practice in an uncertain world.The selection is both a recognition and an admiration. It recognizes the painstaking attentiveness the authors gave to the dual ambition outlined in the Call for prospectus for scenario composition (Xiang 2020, p.297): (1) to foresee alternative futures of socio-ecological practice in the 2020s and beyond; and (2) to envision, under each alternative future, the correspondingly coping strategies for socioecological practitioners and scholars. It admires the triple-I qualities the authors creatively built into these scenario ideas: informative, inspirational, and interesting.Considering the amount of time the article development and editorial process will take, the editor in chief publishes four of these ideas in this communication article so that, in a timely fashion, these gemstones of creative, forward thinking can reach out to the journal community of international scholars and practitioners. Publishing these ideas also serves two other purposes: to recognize their scholarly values and to register and thus protect authors' intellectual property rights of their scenario ideas before the full papers are developed.These scenario ideas are presented respectively and independently by their authors in the following four sections (Sects. 2-5). The authors are as such solely and only responsible for the content accuracy in their own sections. All the authors, however, approved the theme and layout of the article and green-light the publication of this communication article. The orders in which sections are arranged and authors listed are determined by the editor in chief, so is designation of the corresponding author of the article.In response to the COVID-19 pandemic, some urban inhabitants in the USA are moving to suburbs to avoid densely settled places, to find lower cost housing now that much work is being done remotely, and to have better access to green space (see, for example, Bortz 2020; Capps et al. 2020; Lerner 2020; Matsuda 2020) . If this wave of migration continues, US cities are unlikely to add more population than suburbs in the decade of the 2020s and perhaps beyond. For planners, developers, elected officials, businesspeople, environmentalists, and concerned citizens, this presents a unique challenge and one-off opportunity to make the suburbs more environmentally, socially, and economically sustainable while accommodating the influx of new settlers. To facilitate their strategic thinking for implementing greater sustainability, I envision two alternative suburban futures.Under a business-as-usual scenario of the typical American suburban settlement pattern, sprawling low-density development and the separation of land uses would continue. With more people moving to suburbs or even exurbs, the USA would see greater reliance on cars, more upward pressure on greenhouse gas emissions, higher infrastructure and health costs, accelerated loss of open space, and general environmental degradation along with more social isolation.Under a sustainable suburb scenario, in sharp contrast to the business-as-usual scenario, American suburbs could become ecologically more resilient, economically more vibrant, and socially more equitable through creative planning, design, and redevelopment while embracing new inhabitants. Such a scenario would feature higher density development, a greater use of public transit, less driving, more walking, and more people living in mixed-use, multifamily developments.Envisioning an alternative future of sustainable suburbs is uplifting. But it also prompts a deep appreciation of the challenges people would face and the opportunities that exist.The obstacles include, but are not limited to, (1) the high cost of new infrastructure, especially transit; (2) the Not-In-My-Backyard (NIMBY) sentiment against development of what could be perceived as LULU (Locally Unwanted Land Uses) 2 ; and (3) densifying existing development. Opportunities reflect taking advantage of trends in more people working remotely, more on-line shopping, a greater desire for green space, and the nation's growing social diversity. I envision and juxtapose these two alternative suburban scenarios with the hope that together they provide a way to engage suburban communities across the USA about their futures and to analyze uncertainties within the planning and design process. In particular, I hope that the sustainable suburb scenario will help planners, developers, elected officials, businesspeople, environmentalists, and concerned citizens to determine whether a proposed development or infrastructure project adds to or detracts from progress toward greater environmental, social, and economic sustainability.with the super wicked COVID problem by Jeffrey Chan 3In the face of the COVID-19 pandemic, large-scale blanket responses have become the status quo. Entire cities (and regions) have been locked down in many places. This has been described as a form of ""overkill"" even by their own proponents (Cadell 2020)-tantamount to detonating ""a social nuclear weapon"" (Christakis 2020, p. 10). Responses of this kind offer a temporary halt to disease transmission but at the expense of incurring a devastating fallout on, inter alia, businesses, jobs, education, and mental health. Indeed, the crisis the COVID-19 pandemic created is a super wicked problem (Xiang 2021 the COVID-19 pandemic drags on, the harder it becomes to address the many undesirable impacts of this problem.In sharp contrast to the prevalent blanket approach, herein I envision an adroit alternative, a counterfactual scenario, 5 of coping with the super wicked COVID problem. Adroitness in this context is the practical artfulness and tactical resourcefulness of achieving goals in the face of a calamityinduced wicked problem. ""Four ounces (are used) to deflect a thousand pounds"" (四 两拨千斤) is a Chinese idiom and an aphorism that underlies the philosophy of Tai-Chi. In a head-to-head fashion, a mass of four ounces would literally be overwhelmed by the force of a thousand pounds. But as the Tai-Chi master Cheng Man-ch'ing [郑曼青 (1902-1975) ] points out sagely, one can offset a buffalo of thousand pounds with a rope of four ounces-when tied to a nose ring, the rope allows one to lead and control the buffalo at will and with ease (Cheng 1985, p.93) . This is possible because, in the words of American environmental scientist Donella Meadows (1941 Meadows ( -2001 Meadows ( ) (2008 , the rope is strategically placed at a leverage point in this disproportionate situation: where a small change in one point can lead to a large shift in the behavior of the entire system.In composing an adroit scenario of coping with the super wicked COVID problem, I am guided by the following four possibility questions:1. Are we able to find the leverage point(s) in the super wicked problem the pandemic triggered? 2. If so, then what is the metaphorical four-ounce rope that can be tied to the nose ring of this thousand-pound beast? 6 In other words, what is the adroitness exemplified? 3. Are we then able to tame-""to better control"" (Chan 2016, p. 123 )-this monster for our well-being by adroitness throughout the 2020s and beyond? 4. What might the world look like had we achieved all the above possibilities?I will conduct a systematic exposition on adroitness and demonstrate its role in our effort to achieve the first three possibilities the alternative Tai-Chi response approach offers.Kankam, Hongmi Koo, Justice Nana Inkoom, and Christine Fürst 7What could the future supplies of cultural ecosystem services (CES) in our region look like in the 2020s and beyond? What would each of the alternative futures mean to us? How could we prepare for them? Asked many concerned farmers, landowners, land-use planners, elected government officials, as well as academics in Southwestern Ghana (Fig. 1) . Their concerns are legitimate. Along with its offshore oil and gas development, the region has been experiencing rapid land-use and land-cover changes and enduring their impacts on CES supplies. In this agricultural and biodiverse region, CES include physical and mental health benefits, aesthetic enjoyment, recreation, and spiritual experiences. These services also evoke a strong sense of attachment among the local people to their land and their rich cultural heritage. As such, sustainable CES supplies are essential to the wellbeing of the people in the region.From 2019 to 2021, we are commissioned by the United States Forest Service (USFS) and Hen Mpoano (a Ghanaian Non-Governmental Organization, www.henmp oano.org) to investigate, inter alia, the above three CES questions as part of a collaborative initiative to conserve the Greater Amanzule Wetlands (GAW) in the region (see Fig. 1 ).To this end, we explored alternative futures of CES supplies under an array of land-use planning scenarios. The scenario themes range from business-as-usual, mangrove afforestation, to market-driven growth, and green network in which an ""eco-corridor"" connects upland and coastal forests through native tree planting. The scenario building process is participatory and collaborative, blending scientific knowledge with local, tacit knowledge (Koo et al. 2018, pp. 5-27) . We worked closely with a diverse group of local people-regional land-use planners, farmers, landowners, professionals of non-governmental organizations, elected government officials, and academics-throughout the entire process. As such, these participants, acting both as scenarists and as scenario users, became the co-owners of the products of this exercise-the scenarios and the impact assessment results (Adams et al. 2016, p. 16 ).The collective learning experience during the scenario building process provides many benefits to all the participants, including ourselves. It enables a productive exploration of the three CES questions the people in the region care about; it offers a unique opportunity to nurture the mind, challenge ideologies, share ideas, inspire creativity, and re-enforce ecological ethics (Xiang and Clarke 2003, pp. 889-890) . All of these, along with the tangible products of the scenario building process, will undoubtedly benefit the socioecological practice in the region and beyond.Conventional ""solutions"" do not solve contemporary problems. To be successful in informing or even influencing socio-ecological practice, future scenarios must be creative, bold, and comprehensible. To write such scenarios, profound changes are needed in the way they are conceived and communicated.A successful scenario must be creative-both informative and visionary. Creative thinking is the key to making novel, insightful knowledge useful-relevant, actionable, and efficacious; and to making it useful systemically-in a way that is integrative as opposed to disciplinary. A successful scenario must be bold. It must break from the status quo and overcome the conventions that have become obstacles to societal progress. Being innovative in this way requires the scenarists to accept certain visibility and exposure to criticism, which also creates opportunities for new collaboration and insight if concepts are evaluated from a broad range of disciplinary perspectives.A successful scenario must also be comprehensible enough (i.e., conveyed in accessible, compelling language) to communicate its message effectively with scenario users and engage their broad support.We herein outline a path-a scenario-to writing successful scenarios that embodies these virtues. Resolution to problems will depend as much on the path chosen to understand and resolve them as on the actions to be taken. Underlying this path is the idea of a co-writing process. The researchers and practitioners form a joint team of scenarists and engage in a collaborative process of formulating creative, bold, and comprehensible scenarios. In such a process, researchers are encouraged to speculate lucidly from their position of expertise, outside the box of academic conventions; they also are compelled to avoid the less accessible language of science in communicating ideas. Practitioners are likewise inspired to free themselves from the conventions of professional expectations and avoid the often bureaucratic language of practice.The path we envision is a shared process of formulating and communicating bold, innovative ideas. More specifically, it first (1) enables the creation of an effective collaboration among participants from a diverse array of disciplinary perspectives; then (2) guides an integrated approach to defining the problem areas and their systemically linked relationships; and finally, (3) facilitates the shared learning required for the development of an increasingly integrated understanding of the interrelated components of the system in which the problem lies and how it might be altered to bring about possible resolution(s).Admittedly, it is neither a trivial nor easy task to change the way researchers and practitioners approach the creation and communication of scenarios. On the path we propose toward virtuous scenarios, there are obstacles to be overcome. For example, creative thinking often runs counter to prevailing social norms in the research and practice communities; it may also pose a perceived threat to established credibility in research and to professional expectations in practice. We hope our proposed path or scenario, along with the actions we suggest, will facilitate the real-world socio-ecological researchers and practitioners to overcome these obstacles and bring about positive, sustainable change in the world.The four scenario ideas showcased above are tersely cogent, crystalizing creative yet substantive thoughts that emerged from their authors' experiences, observations, and reflections. The editor in chief, along with our rapidly growing SEPR community of international scholars and practitioners, looks forward in due course to reading articles in which these ideas are fully developed. Until then, let's celebrate these fresh ideas in the very spirit American author Napoleon Hill cherished in 1937 that every human achievement has its beginning in an idea (Hill 1937, p. xi). 9 Tom Daniels is the Crossways Professor of City and Regional Planning at the University of Pennsylvania, USA, where he directs the concentration in Land Use Planning and Environmental Planning. He is the author of The Environmental Planning Handbook (American Planning Association, 2014) and When City and Country Collide: Managing Growth in the Metropolitan Fringe (Island Press, 1999) .Jeffrey K.H. Chan is an assistant professor at Singapore University of Technology and Design (SUTD), Singapore. His research focuses on design ethics and cities. He is the author of two books, Urban Ethics in the Anthropocene (2019) and Sharing by Design (2020).Stephen Kankam is a PhD candidate at the Institute of Geosciences and Geography, Martin Luther Universität, Germany. He is the Deputy Director of Hen Mpoano (www.henmp oano.org), an NGO in Ghana, where his work involves supporting governments, private sectors, and the civil society in coastal and marine ecosystem governance through capacity building and research.",USA,first author,2021-02-25,02
d2ad1d716bf2996021b994e9522e4f7e468db9a6,Clinical scenario,"The COVID-19 global pandemic has upended health care systems around the globe. As the novel coronavirus spread, many physicians left behind their typical daily routines and transitioned into new roles. Non-emergent orthopaedic surgery was notably impacted, as busy surgical schedules nearly vanished overnight. Many surgeons traded in their scalpels for stethoscopes to assist their internal medicine, pediatric, infectious disease, and emergency room physician colleagues on the pandemic's frontlines. Health care workers of every specialty have been working together to mitigate the immediate issue of the coronavirus pandemic. As we focus on the acute concern, it is important we consider the secondary health repercussions of the global pandemic, especially for our country's children. Specifically, it is crucial to address the growing number of children who are missing routine vaccinations [2] .Since the onset of the COVID-19 global pandemic, the number of visits to ambulatory clinics has declined precipitously -down 60% by early April [2] . Even with a recent increase over the past few months, ambulatory visits still remain below pre-pandemic levels and the cumulative number of lost visits continues to grow [3] . Children are likely to be negatively impacted by the loss of routine care, especially the documented decrease in childhood vaccination administration [4] . Indeed, vaccinations for many infectious diseases have been estimated to have fallen by 26% during the ongoing pandemic [2] . As we continue to fight the waves of the COVID-19 global pandemic, future outbreaks of measles, pertussis, or other preventable diseases will occur if action isn't taken.Therefore, as we continue our transition to a ''new normal"" filled with telemedicine, limited in-person visits, and variable resumption of non-urgent surgery, this paper will consider the ethical principles involved in the role all non-primary care specialists, including orthopaedic surgeons, play in ensuring the health, safety, and well-being of the country's children.The American Medical Association Code of Medical Ethics Opinions related to physicians' responsibilities designate an obligation to respond during disasters and participate in activities to protect and promote the health of the public [5, 6] . One framework requires that physician obligations and involvement in patient care linearly increases as risk to the patient and surrounding community increases [7] . Vaccine rates dipping below community protective levels (''herd immunity"") would be an example where this framework would require greater physician involvement in public health efforts. Therefore, we believe that given the current public health crisis, orthopaedic surgeons have a duty to help ensure the health and well-being not only of patients directly under their care, but also of the general public.While defining oneself as a public health steward may feel novel to some orthopedic surgeons, it is, in fact, a role well-known to our field even if some may not appreciate it as such. Prior orthopaedic surgery public health campaigns include lawnmower safety guidelines in partnership with American Academy of Pediatrics (AAP) [8] , as well as the ''Own the Bone"" initiative aimed to address the increase in osteoporosis-related fragility fractures [9] . At the individual patient level, orthopaedic surgeons routinely promote public health goals-such as addressing the obesity crisis or encouraging smoking cessation-within the context of preoperative optimization. Promoting public health is already an important part of being an orthopaedic surgeon.Vaccinations are outside the usual scope of orthopaedic surgeons. Yet, amidst the COVID-19 crisis, orthopedic surgeons have expanded their work to including assisting intensivists, positioning ventilated patients in the prone position, and covering emergency department shifts [10] . Given the ongoing global pandemic, we believe orthopaedic surgeons with access to pediatric patients have an obligation to promote public health wherever it is feasible to do so; promoting vaccination is one important aspect of health promotion.This obligation lies in the same public health ethic that required the cessation of elective surgery-the preservation of scarce resources to maximize the health of a population. At the present moment, a doctor's visit is, in fact, a precious resource, and it must be treated as such. In these times of scarcity, we have a particular responsibility to maximize the utilization of limited resources [11] . Similarly, those with greater access to patients have greater duties.To that end, we would argue that a large pediatric orthopaedic group has a greater obligation than a solo practice pediatric orthopaedic surgeon to promote vaccinations in order to decrease the burden on society and maximize scarce resources (i.e., doctor's visit).Every touch point provides an opportunity for orthopaedic surgeons to help increase vaccination rates, which, in turn, may help stave off the spread of infectious diseases during and beyond this public health crisis. In fact, there are published vaccination standards for health care professionals from the National Vaccine Advisory Committee (NVAC) and endorsed by the American Academy of Pediatrics (AAP) that ''represent the most desirable immunization practices, which health care professionals should strive to achieve."" [12] Using these standards as guidance, we propose three possible approaches for orthopaedic surgeons to help improve pediatric vaccination rates back to baseline.Medical practice includes routine screening for health maintenance and prevention. For example, pediatricians assess development early and often, internists screen routinely for smoking and alcohol use status, and orthopaedic surgeons monitor for osteoporosis to address fragility fractures. Engaging patients in these preventative health areas is already part of high quality, patientcentered care based on communication, respect, appropriate transfer of knowledge, and concern for the patient's long-term welfare. Therefore, given the ongoing public health crisis, orthopaedic surgeons should-at a minimum-discuss vaccination status during telehealth or in-person clinic visits with pediatric patients and their caretakers. Ideally, specialists could also provide informational pamphlets or handouts. This approach requires minimal additional time and effort on behalf of the physician; it can be easily incorporated into current practice to help increase pediatric vaccination rates.A step beyond the above approach would be for orthopaedic surgeons to place an order for missing vaccinations and/or a referral to a pediatrician or office that provides vaccinations. While this approach moves beyond simply raising the topic of vaccinations, the time commitment remains low, as placing orders and referrals are routine in office visits already. By placing an order, the patient may be more likely to follow through on the treatment. Further, we also believe this approach would benefit from orthopaedic surgeons actively reaching out to their pediatrician colleagues to help establish a more formal, yet simple vaccination referral pattern ahead of time. Ideally, the electronic medical record (EMR) could be leveraged based on a routine vaccination schedule to auto-suggest the appropriate vaccinations and provide referral reminders. The steps recommended in Option 1 would still be followed, with an emphasis on patient education. This approach may be optimal for orthopaedic surgeons, as they would have an opportunity to make a measurable difference -more than we believe is possible in Option 1 -without the need for a great deal more time or resources.The most robust or maximalist approach would be for orthopaedic surgeons to provide routine vaccinations in their offices. At the present time, we would consider this an altruistic option rather than an ethical obligation, though that could change if there were ongoing outbreaks of preventable childhood infections, such as measles. We think that if substantial outbreaks begin to occur, surgeons may be obligated to provide vaccinations. While patients are likely seeking care unrelated to vaccinations when they engage with an orthopaedic surgeon, discussing and offering vaccinations are a patient-centered approach likely to lead to increased vaccination rates. Indeed, prior research demonstrated that offering the influenza vaccine in a pediatric hand clinic significantly increased the rate of vaccination [13] .Orthopedic surgeons would need additional resources and significant effort to successfully deliver vaccinations within their practice, and we do not yet believe the potential benefits of providing vaccines outweighs the costs. Yet, we would argue that this approach would serve dividends when a pediatric COVID-19 vaccine becomes available, and indeed, we may all be recruited to assist in such a vaccination effort.We are in a once in a lifetime public health crisis that requires all non-primary care specialists, including orthopaedic surgeons, to rethink their professional obligations beyond the concerns of the patient in front of them to include the general public. Surgeons are physicians first; we are healers that patients turn to for guidance and insight in their most trying times. At a minimum, orthopaedic surgeons have a moral obligation to raise the topic of vaccinations with every child and parent we encounter in a medical setting. In the case of a global pandemic, we must be champions of public health. This is especially true because the decrease in childhood vaccination administration now may impact herd immunity for previously controlled debilitating diseases for months and years into the future [2] . We must all reconsider our obligations to the public good, and every physician who encounters a pediatric patient must work to increase childhood vaccination rates back to baseline.All authors were involved in the development of this manuscript and gave final approval before submission.None. The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.",USA,first author,2021-02-26,02
5ef4c24799514ad49a3db3abc7e7f651ae0df33a,"1)10 (-35,0)(1,0)30 (0,30)10 (-5,30)(1,0)10 (0,35)(0,-1)30 picturepicture(0,0)(30,0)10 (30,-5)(0,1)10 (35,0)(-1,0)30 (0,30 ture(0,0)(-30,0)10 (-30,-5)(0,1)10 (-35,0)(1,0)30 (0,-30)10 (-5,-30)(1,0)10 (0,-35)(0,1)30 picturepicture(0,0)(30,0)10 (30","The COVID-19 pandemic has increased a scientific interest in coronavirus research. The analysis of the coronavirus dataset starts with obtaining full-length virus genome sequence that can be performed using read alignment (1, 2) or de novo assembly (1, 3) .The assembly pipeline based on read alignment is a tool of choice for the same strains of the close species, e.g. for SARS-CoV-2 SNP profiling of confirmed COVID-19 patients. De novo assembly is better suited for novel species recovery since read alignment for distant species is unreliable. Recently, there were multiple studies that used MEGAHIT (4) assembler to recover full-length sequence of the SARS-CoV-2 genome, also previous studies show that different SPADES (5) modes perform well in virus recovery (6, 7) from complex metagenomes and metaviromes. Nevertheless, none of these assemblers was initially designed for viral assemblies: MEGAHIT and * To whom correspondence should be addressed. Email: a.korobeynikov@spbu.ru METASPADES (8) are metagenomic assemblers, SPADES (9) is designed to assemble single-cell and isolate bacterial datasets, RNASPADES (10) is intended for accurate isoform separation from eukaryotic data. For RNA viral samples (metaviromes and metatranscriptomes) these assemblers can produce fragmented assemblies due to specific sequencing artifacts, coverage variations, host contamination, multiple strains and quasispecies, and splice events (11) . Fast and correct assembly and characterization of viral species is a key step in predicting and preventing the future outbreaks.Many RNA viruses including coronaviruses have a conserved gene structure (12, 13, 14, 15 ) that can help to better assemble full-length genomes. In this study, we present CORONASPADES -a novel assembler designed for RNA viral data. While CORONASPADES was initially developed having coronaviral species in mind, we demonstrate that overall approach is generic and applicable to assembly of other broad viral families.We show that CORONASPADES is able to recover fulllength genomes from publicly available datasets where other popular assemblers produce fragmented assembly.RNA virus assemblers (16, 17, 18) have to face a number of challenges in order to assemble the sequence data into a consensus sequence. These challenges stem from the nature of the sequencing data due to the biases in the reverse transcription and polymerase chain reaction amplification process that current sequencing methods rely on. These biases are further aggravated by enormous viral population diversity causing lots of SNPs as well as structural variations. Such population diversity is explained by high error rates during the replication process of RNA viruses, essentially they occur as quasispecies (i.e, groups of related genotypes) (19) .These properties of the data cause assembly fragmentation or, even worse, make certain regions disappear from c YYYY The Author(s) This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (http://creativecommons.org/licenses/ by-nc/2.0/uk/) which permits unrestricted non-commercial use, distribution, and reproduction in any medium, provided the original work is properly cited. the assembly. Additionally, some RNA viruses (including the species from the order Nidovirales that includes coronaviruses) are known to use discontinuous extension of negative strands to produce multiple mRNAs (20) . Thus, even in case of a single virus species in the sample, assemblers should be able to deal with multiple produced ""isoforms"".Over the years the SPAdes team produced several assembly pipelines aimed for a wide range of sequencing data and tasks. This includes METASPADES (8) for the assembly of consensus bacterial genomes from metagenomes, RNASPADES (10) centering around the reconstruction of multiple isoforms from eukaryotic data as well as more specialized versions such as METAVIRALSPADES (21) .None of these pipelines, however, can handle all the challenges that appear during the assembly of RNA viral data:1. METASPADES cannot cope with the properties and sequencing artifacts typical for RNA-Seq data (outlined below). While it expects multiple species in the input data, overall it assumes relatively uniform coverage across a single bacterial genome. When applied to RNA viral data with uneven overage and extensive variation, the graph simplification procedures of METASPADES (namely, the rare strain disconnector, see (8) for more details) could confuse the main genome with highcovered variation and therefore fragment the assembly. This phenomenon is especially severe for complex metaviromes (see Results section, assembly of Inluenza and HIV data).2. While RNASPADES certainly can cope with the specifics of RNA-Seq data, its aim is quite the opposite as required for RNA viral assembly. For RNA viral assembly the main task is to remove possible variation due to quasispecies, strain variation and sequencing artifacts. For RNA transcriptome assemble the aim is to preserve as much variation due to multiple isoforms as possible. This is why the graph simplification procedure of RNASPADES is quite ""gentle"" (see (10) for more details on the graph simplification procedures) which is further compensated by the isoform restoration procedure. However, the assembly graph of a typical RNA viral dataset (especially a metatranscriptoic / metaviromic one) is much more complex as compared to RNA transcriptome one. As a result, many sequencing artifacts, variation and chimeric connections are still left there which might result in fragmented assemblies, if some part is lost by an accident, or mosaic ones if isoform restoration algorithm would incorrectly resolve variation. Also, we could expect that RNASPADES as other RNA assemblers would certainly inflate the genome duplication ratio as multiple possible arrangements of variation might appear in the output.3. METAVIRALSPADES pipeline is based on METASPADES and uses coverage-based heuristics in order to detect putative DNA virus sequences (cyclic and linear) from assembly graphs, which fails to work on RNA viral data due to uneven coverage. It does not handle RNA-Seq sequencing artifacts as well.The outlined issues required us to develop a new assembly graph simplification pipeline that is specifically aimed to take into account the specifics of RNA viral data.Our new CORONASPADES pipeline consists of two main steps: RNAVIRALSPADES and HMMPathExtension.RNAVIRALSPADES is a standalone assembler on its own that takes takes a transcriptome, meta-transcriptome, virome or meta-virome dataset on input. RNAVIRALSPADES modifies approaches of METASPADES and RNASPADES in order to assemble RNA viruses on species level.Removal of low-complexity (poly-A / poly-T) tips and edges and RNA-seq specific chimeric connections. Analysis in (10) shows that the majority of the chimeric connections in RNA-Seq data are either single-strand chimeric loops or doublestrand hairpins. They are detected by analyzing the graph topology rather than nucleotide sequences or coverage.Another characteristic of RNA-Seq datasets is the large number of low-complexity regions that originate from poly-A tails resulting from polyadenylation at the ends of mRNAs. To avoid chimeric connections and non-informative sequences low-complexity edges are removed from the de Bruijn graph.Transcriptome and metatranscriptome datasets could be quite large and input reads often contain billions of distinct k-mers. Therefore RNAVIRALSPADES implements removal of low-complexity tips and length 1 edges (by default tips shorter than 200 k-mers and having A/T content more than 80% are removed) on both uncondensed and condensed de Bruijn graph. Early removal of large portion of sequencing artifacts before condensing the edges of de Bruijn graph helps to keep the memory consumption low and reduces the running time of further graph cleaning steps as well.Preventing gap closure by low-complexity overlaps. There are several approaches that helps to assemble the regions of low coverage. Using multiple k-mers in iterative manner is one of them. Another one is the gap closure process: paired-end reads are aligned to the tips (and their neighborhoods) of the graph. And if there are enough paired-end reads that span the gap, then the ends of tips are analyzed for a possible overlap that is shorter than k-mer. If there exists an exact overlap that is longer than 10 bp, then the tips are joined into a single edge at this overlap.It turned out that the majority of such overlaps for RNA data are again low-complexity sequences containing long stretches of ""A""s or ""T"" with few mismatches. Almost all these overlaps are spurious and therefore the produced connection would be chimeric. We modified gap closure algorithm was to ignore such overlaps.Collapsing of quasispecies. RNAVIRALSPADES aims for species-level assemblies (as opposed to strain-level assemblies that are certainly infeasible due to high level of variation), therefore the bulge removal procedure was refined to collapse the variation due to quasispecies. Specifically, RNAVIRALSPADES collapses long and similar (with respect to the edit distance) parallel edges in the assembly graph. By default, it does so for edges shorter than 1000 and similar to each other by more than 90% IDY.Low-abundant strains disconnector. Unfortunately, strain differences are not only manifested as single nucleotide variations and small insertions or deletions. Such variations (especially for complex datasets containing many species) are caused by highly diverged genome regions, rearrangements, large deletions, parallel gene transfer, etc. Therefore the topology of the de Bruijn graph in the neighborhood of such variations is more complex than a few dozens of bulges complicating the strain variation masking procedure.METASPADES includes a dedicated edge disconnector algorithm that uses the coverage ratios between adjacent edges in the assembly graph to identify edges with low coverage ratios as those that most likely originate from rare strains. The algorithm then disconnects such edges from highcovered paths. However, there are important exceptions to this approach, for example, cases when low covered edges are connected to repeats with a high copy number. In order to identify such cases, for each edge e a high-covered subgraph connected to e is constructed. In the case of repetitive region, we expect to find a component with a total sum of edge length being small.This repeat-preserving heuristics does not work well for RNA viral datasets due to drastically increased coverage variation compared with metagenomic samples leaving many connections intact. Also, we certainly assume viral genomes to have small genome size and not include high-covered repeats (so all repeats must be intra-species).In RNAVIRALSPADES we use the disconnector algorithm without repeat-preserving heuristics and more conservative thresholds with respect to edge coverage ratio to take into account coverage variation.Generic assembly graph simplification pipeline. Besides the important changes outlined above, RNAVIRALSPADES implements the graph simplification approach similar to consensus assembly graph construction pipeline of METASPADES.As a result, the RNAVIRALSPADES pipeline alone allows for removal of the majority of RNA sequencing artifacts and collapsing the variation. However, still there might be very ambiguous cases when an assembler could not remove the errors neither using the coverage-based heuristics nor the graph topology. The GINGER dataset outlined above is a good example. Certainly, it might be possible to tune various assembler heuristics to deal with that particular case, however, the solution will unlikely work on other datasets as it will be overly-aggressive in error elimination. As a result, some different approach is necessary. RNA transcriptome assemblers solve the problem with isoform reconstruction step, potentially inflating the genome duplication ratio. CORONASPADES instead uses a HMMPathExtension algorithm.The second step of the CORONASPADES pipeline, HMMPathExtension, utilizes the information about viral genome organization to distinguish between putative genomic sequences from uncleaned artifacts.HMMPathExtension is inspired by HMM-based algorithms of BIOSYNTHETICSPADES (22) . It takes a set of HMMs and the assembly graph as input. First, HMMPathExtension aligns HMMs to assembly graph and constructs a domain graph (for details of domain graph construction refer to (22) ). In order to construct domain graph for an arbitrary set of HMMs, we had to add improvements to domain graph construction algorithm. Previous algorithm assumed that profile HMMs are longer than k used during de Bruijn graph construction and can not match to the same interval of the de Bruijn graph. In the current version, if profile HMM is k or shorter, it matches to the single kmer on the de Bruijn graph with prefix that have the best-scored match.BIOSYNTHETICSPADES guarantees that there are no positions on the de Bruijn graph that are matched more than once. This fact arouses from a distinct nature of biosynthetic gene cluster domains. However, the unprecedented diversity of viral data and building blocks of viral genomes, HMM hits can overlap, causing initial domain graph construction algorithm to fail. In order to overcome this problem, we greedily select an arbitrary HMM hit and remove all other hits that overlap with it until there are no overlapping hits. This procedure guarantees that strong and weak edges of the domain graph will be correctly added to the graph.Similar to BIOSYNTHETICSPADES, HMMPathExtension aims to find paths through the domain graph that traverse significant HMM matches in order and translate them to the assembly graph paths. This way the extracted genomic sequence is supported both by the graph topology and the structure of the genome. The only major difference is that BIOSYNTHETICSPADES assumes that different gene clusters do not overlap in the assembly graph, but in case of viruses, multiple virus strains can be easily presented. Unlike BIOSYNTHETICSPADES, HMMPathExtension does not require to thread through all close matches in a connected component of the domain graph. It allows to reconstruct multiple virus sequences of the same family. All paths produced by HMMPathExtension algorithm are maximal by inclusion, it allows to ignore non-viral sequencing artifacts since they should not have any viral matches on them.For coronavirus assemblies CORONASPADES is bundled with the set of HMMs obtained from Pfam SARS-CoV-2 (23) (despite the name, these HMMs are quite general and represent the profiles of various proteins that belong to coronaviruses as well as more conserved ones like RNA dependent RNA polymerase (RdRp) that is conserved across all RNA viruses (24)) and HMMs for coronaviral protein families studied in (25) .We explicitly note that the approach of HMMPathExtension is not limited to coronaviral genomes. The HMMPathExtension step allows for a custom HMM database specification effectively enabling HMM-guided assemblies of other genomes using their internal structure. In the result section, we demonstrate how CORONASPADES can be used to assemble HIV, influenza and CoV genome sequences from diverse datasets. HMM sets used for these assemblies are also available to use.HMMPathExtension takes advantage from hits that uniformly cover the genome of interest, allowing to reconstruct strains mixtures and splice variants. We highlight the features of CORONASPADES using a wide range of publicly available transcriptome and metatranscriptome datasets that include novel and known coronaviral species. We also show how CORONASPADES could be used for not only coronaviral assemblies by reproducing Influenza and HIV assembly benchmark from (16) .FR4NK is a putative novel Alphacoronavirus detected in a metatranscriptome sequencing library from a Peruvian vampire bat (Desmodus rotundus, SRA:ERR2756788). The average coverage is 110x with variation from 2x to 1500x in different regions of the genome. This is a new species of Coronavirus based on RdRP, nucleoprotein, membrane protein and replicase 1a, which all classify this virus an Alphacoronavirus outside of all named sub-genera and most similar to a Pedacovirus.GINGER is a putative novel Alphacoronavirus detected in a transcriptome sequencing library from a Wildcat (Felis silvestris, SRA:SRR72871109). The average coverage is 20x with variation from 230x to 6x in different parts of the genome.PEDV is a known Alphacoronavirus that causes porcine epidemic diarrhea. It was assembled from a transcriptome sequencing library of epithelial cells of pig intestine (Sus scrofa, SRA:SRR10829957). The average coverage is 470x with variation from 30x to 8000x in different parts of the genome.We assemble FR4NK, GINGER and PEDV using several specialized virus assemblers (IVA, PRICE), generic metagenome and transcriptome assemblers (MEGAHIT, METASPADES, RNASPADES, TRINITY (26)) and CORONASPADES. The overview of the results could be found in Table 1 . Conventional RNA assemblers (IVA and PRICE) are using a seed-and-extend approach, therefore a seed sequence was required. This property greatly reduces their applicability for novel species search. In addition, it seems they were unable to deal with the specifics of large transcriptome and metatranscriptome datasets. Other assemblers (MEGAHIT, TRINITY, METASPADES, RNASPADES) overall have shown acceptable results, however their performance was not uniform, as none of them was able to assemble complete virus genomes out of all 3 datasets. CORONASPADES was able to produce whole genomes in all cases.As it was mentioned previously, the HMMPathExtend approach is generic and could be applied to other viral families should the desired set of viral proteins is provided. To showcase this feature the re-create the Shown are: longest viral contig assembled, its completeness as estimated by CheckV (27) and the average amino acid identity to the closest reference in CheckV database. The best results are shown in bold. *Seed was required, 1 kbp of CORONASPADES assembly was used **IVA failed to select seed automatically. 1 kbp of CORONASPADES assembly was provided as a seed *** Two isoforms were reported, one seems too long and likely a misassembly, second one is shorter than expected genome size. Failed to extend the seed Figure 2 shows that CORONASPADES significantly outperforms other tools in terms of assembly contiguity with 30 complete and near-complete assemblies (> 8500 bp). All other assemblers have no more than 14 complete or near-complete assemblies. The number of misassemblies is another important metric, that shows assembly quality. CORONASPADES keeps misassemblies at a relatively low level (see Figure 4) , providing a good contiguity-quality trade-off. Also, these results clearly show that metagenomic assemblers might produce suboptimal results and therefore are not suitable for RNA viral assembly from metaviromes.Influenza assembly is more complicated because influenza type A, B genomes consist of eight segments, that can have highly similar regions at the segment's ends. As a metric for the assembly contiguity, we sum the longest alignment length across all segments. Figure reffig:inf shows that RNASPADES has the best contiguity performance, with CORONASPADES and TRINITY at the second place. However, Figure 4 shows that MEGAHIT, RNASPADES, and TRINITY have the worst misassembly statistics (73.0, 19.82, and 7.162 misassemblies per dataset correspondingly), while CORONASPADES has 2.895 misassemblies per dataset. Therefore CORONASPADES has a reasonable contiguity-correctness trade-off.Raw assembly results are available in Supplementary Tables 1 (for Influenza datasets) and 2 (for HIV datasets).CORONASPADES was used in the Serratus project (29) for a widespread search of novel CoV and CoV-like species from public sequencing libraries. From a screen of 3.8 million libraries comprising 5.6 petabases of sequencing reads, there were reported 11,120 assemblies, including sequences from 13 previously uncharacterized or unavailable CoV or CoVlike operational taxonomic units (OTUs), defined by clustering amino sequences of the RdRp gene at 97% identity. 8 of these OTUs were designated to a putative novel genus of coronaviruses, noting that all were found in samples from nonmammal aquatic vertebrates falling outside deltacoronaviruses genus.GINGER dataset represents the typical case when long sequencing artifacts could influence the assembly results. All metagenome assembles lost some parts of the genome likely being unable to remove the long artifacts having coverage similar to the virus genome (see Figure 1 for assembly graph). RNA assemblers (RNASPADES and TRINITY) solved this problem via isoform restoration steps: different ""isoform"" paths across this subgraph were produced and one of them was a full-length viral genome. The downside of this approach is increased genome duplication ratio as multiple paths through the subgraph are produced and in more complex cases some of them might be mosaic. CORONASPADES traversed all domain matches in order and also produced a full-length viral genome.The influenza A and B virus genomes each comprise eight negative-sense, single-stranded viral RNA segments that code 10-14 proteins, depending on the strain. Each segment possesses noncoding regions, of varying lengths, at both 3'and 5' ends. However, the extreme ends of all segments are highly conserved among all influenza virus segments (30) .As a result, depending on the particular strain, the segments could appear glued in the assembly graph (see Figure 5 ), also the Influenza genomes are highly variable with many rearrangements in at least 2 segments due to the antigenic drift and shift processes (31) . The challenge for an assembler here is to correctly recover the sequences of all eight segments taking into account possible variation.Surprisingly, MEGAHIT for some unknown reason often produced the contigs of 4-8 Kbp that contained parts of multiple segments. This results in a highly elevated rate of misassemblies seen there. The results of other assemblers are overall expected as well: both TRINITY and RNASPADES shown good results in recovery of fulllength segments using the isoform reconstruction procedures. However, some segments were clearly mosaic as could be seen from the Figure 4 . Seed-and-extend approach of IVA resulted in the most accurate in terms of the average number of misassemblies assemblies, albeit at the expense of the recovery of the fuller segments. CORONASPADES was able to recover much more still having an acceptable misassembly rate.HIV genome represents a true nightmare from the assembly standpoint as it employs a very complex system of differential RNA splicing to obtain more than 30 mRNA species from a less than 10 kb genome (32) . This results in a very complex and tangled assembly graph (see Figure 6 ) that an assembler must traverse in order to recover the complete virus genome. Here the HMM-guided approach of CORONASPADES clearly allows to extend the contigs and recover significantly fuller genomes as compared to other tools.Clearly, assembling RNA viral genomes is very challenging (16) . The variety of possible kinds of input data and the overall diversity of the species multiplies these challenges even more. We demonstrated that additional information about the genome structure could significantly improve the viral genome recovery even from very complex datasets and therefore catalyze the new viral discoveries.The datasets supporting the conclusions of this article are available in the NCBI SRA repository, under accessions ERR2756788 (FR4NK), SRR72871109 (GINGER) and SRR10829957 (PEDV). Access instructions for Serratus data can be found at https://github.com/ababaian/serratus/wiki/Access-Data-Release. Influenza and HIV-1 data were taken from IVA paper (16) (lists of accessions are available from Supplementary Tables 1 and 2 ). CORONASPADES version used in this article is a part of SPAdes 3.15 release and is available at http://cab.spbu.ru/software/spades and also deposited on Zenodo under doi:10.5281/zenodo.4438269. HIV and Influenza HMMs were extracted from U-RVDB-prot v20 database and are available from http://cab.spbu.ru/software/coronaspades. by computational resources provided by the Resource Center ""Computer Center of SPbU"". The authors are grateful to Saint Petersburg State University for the overall support of this work. DM is grateful to T32 Weill Cornell Tri-Institutional Training Program in Computational Biology and Medicine. IH is supported by a Maximizing Investigators' Research Award (MIRA) for Early Stage Investigators (R35 GM138152-01).",USA,first author,2021-02-01,02
aff078995cf15dc9f1398b2a819b9210ac5dc6bf,What Are the Clinical Implications of the SARS-CoV-2 Variants 5 Things Every Cardiologist Should Know Rauseo and O'Halloran -2 0 2 1 : --- Clinical Implications of the SARS-CoV-2 Variants,"S ince its emergence in late 2019, severe acute res- (1). Several variants have since been identified, with some designated ""variants of concern"" due to their potential clinical significance ( because it also potentially increases affinity for ACE2, which also means that it is more transmissible (1,2) . infection, or of more concern, they might reflect the variant's ability to evade the previous immune responses, presumably due to E848K mutation. One of the greatest concerns with emerging SARS-CoV-2 variants is the potential to escape natural or vaccineinduced immunity. A number of the S protein mutations have raised concern for escape from neutralizing antibodies produced by convalescent sera or monoclonal antibodies and potential decrease in protection by vaccines. This may also mean that pa- However, the efficacy of this vaccine substantially decreases in the presence of the E484K mutation (5).This effect was also seen in sera from volunteers who ",USA,first author,2021-02-26,02
9ed6353eddcf35780cbce1400a25e38e1c0a973c,Are fast test results preferable to high test sensitivity in contact-tracing strategies?,"To quantify the impact of test-trace-isolate strategies on growing epidemics, we simulate the branching structure of the chains of infections, also referred to as the ""epidemic tree"". 18, 19 Our model lets us keep track of who infected whom, which is essential when simulating contact tracing and quarantining infectious people. In the model ( Figure 1A) , infected individuals give rise to new cases, unless quarantined following testing and tracing efforts.We initiate a simulation with some number of newly infected people, N seed ∈ N. The simulation progresses in discrete timesteps, corresponding to days, and we make the simplifying assumption that every infected person, goes through the same phases before recovering: 3 days of being presymptomatic and noninfectious followed by 8 infectious days. As for COVID-19, 20 some fraction of cases, p asymp , remain asymptomatic for the entire infectious period; all other infected cases experience symptoms starting on day 7 after infection.In the absence of testing, tracing and isolation, an infectious person would give rise to k secondary cases. For each infected, we assume that k is drawn from the probability distribution P (k). When each of these k secondary cases is infected, we determine the time of infection by drawing an integer from the probability distribution P time (t). P time (t) takes positive values on the days where the infected is infectious and, mimicking COVID-19, 1,15 peaks around symptom onset ( Figure 1B ). These infections take place unless the infected is in quarantine at the time the infection would occur.Infectious people quarantine only when waiting for a test to be taken, receiving a test result, or after testing positive. In our model, an infectious person orders a test if either of two things happens: 1) The person is traced; 2) The person develops symptoms. In either case, the person orders a test immediately and then waits δ = δ test +δ result days for the result.The test waiting time is divided into δ test days waiting for the test to be taken followed by δ result days to receive the result. The test correctly identifies the case with probability equal to its sensitivity, 1 − p false , where p false is the false negative rate. If the test comes back positive, each of the person's secondary cases is traced with independent probability p trace .We obtain indistinguishable results when simulating the same δ with varying values of δ test and δ result . Thus, the key parameters of the model are the test waiting time δ, test sensitivity 1 − p false , and tracing efficiency p trace .The output of the simulation is the effective reproduction number of simulated disease: R eff = n children /n parents .We use the model to examine the trade-off between test waiting time and test accuracy depending on the tracing efficiency. In our simulations, we therefore vary the parameters δ, 1 − p false , and p trace and fix all other parameters (for δ ≥ 1, we set δ result = 1). For P (k) we choose a Poisson distribution with mean R 0 = 2 (slightly lower than estimated in early stages of the pandemic 21, 22 ) and for P time (t) we choose the right-skewed distribution depicted in Fig. 1B . Finally, we choose t max = 50.To develop some intuition, let us first introduce the results we obtain when fixing the tracing efficiency, p trace = 0.80. This constraint leaves 2 free parameters: The test sensitivity, 1 − p false , and the test delay, δ. We now compare the effective reproduction number R slow eff obtained by using a slow, but accurate test (parameters: p slow false = 0 and some δ slow ≥ 1 day) to the reproduction number, R rapid eff , obtained with a less accurate, but rapid test (parameters: some p rapid false and δ rapid = 0 days). To evaluate whether speed or accuracy is to be preferred, we compute the difference in obtained effective reproduction numbers of the virus under the different choices of tests,Let us choose some test delay, e.g. δ slow = 2 days (perhaps corresponding to a PCR test with a 1-day waiting time to get tested and a subsequent 1-day waiting time to get the result). In this case, how will ∆R eff depend on the risk of getting a false negative test result? For very high sensitivity (low p false ), this faster test will be almost as accurate as the slower test it is being compared to. For this reason, the fast test will be preferable to the slower one ( Fig. 2A top colorbar) . If we now imagine slowly decreasing the test sensitivity, ∆R eff will gradually increase until it reaches a breaking point where the slow and rapid tests reduce the effective reproduction number equally well: ∆R eff = 0.Decreasing the sensitivity even further makes ∆R eff positive, meaning that for this high probabilities of false negatives, the accurate test is to be preferred.Having established some intuition for the simulations, we proceed to varying the third parameter: the tracing efficiency. By varying the tracing efficiency, for each choice of δ slow we get 2-dimensional heatmaps instead of the one-dimensional colorbars presented in the previous paragraphs (Fig. 2B-D) . In these heatmaps, the breaking points become white curves. Every point to the right of the breaking-point curve is a parameter combination where a faster test is preferable. Every point to the left of the breaking-point curve is a parameter combination that favors an accurate test. Notice how all the breaking-point curves start in the lower-right corner (where tests are completely accurate but no contact tracing is done) and how quickly they move to the left with increasing tracing efficiency. Figure 2E plots the obtained R rapid eff . For each simulated choice of parameters, each computed R eff is averaged over 10 simulations. For clarity, the heatmaps in Fig. 2 have been smoothed with a Gaussian filter.Testing, tracing and isolating positive cases is central in many countries' strategy to fight the current COVID-19 pandemic. [23] [24] [25] We have demonstrated that there is a sizeable trade-off between test sensitivity and test waiting times in such strategies, and that it is often beneficial to prioritize test speed over test sensitivity. Moreover, we find that this benefit of rapid tests increases quickly with increases in test waiting times, and that even modest tracing efficiency unlocks the advantages of rapid tests. This indicates that additional waiting time for test results must be avoided and that it often makes sense to reduce test sensitivity in order to do so. It is to be expected that testing systems will occasionally get under stress during a pandemic, and having a way to avoid build-up of waiting times in this scenario is crucial. Designing such stress-relieve strategies presents an interesting direction for future research.Our choices of the probability distributions P (k) and P time (t) can also be questioned.A better choice for P (k) might be a heavy-tailed distribution that could account for superspreading behavior. 26 Overall, our analysis suggests employing rapid tests to reduce test waiting times as a viable strategy to reduce transmission even at modest waiting times and contact tracing efficiency.In this inset, we assume that 80% of secondary cases are successfully traced following a positive test. The colorbars show results obtained for different choices of δ slow (top colorbar: δ slow = 2 days, middle: δ slow = 3 days, bottom: δ slow = 4 days), and the rapid-test sensitivity (horizontal axis in each colorbar). In each colorbar a breaking point separates sensitivity values favoring the slower, accurate test and values favoring the rapid test. B Comparison of effective reproduction numbers when the result of the slower test arrives after δ slow = 2 days, as a function of the sensitivity and tracing efficiency. C Same as in B but with δ slow = 3 days. D Same as in B, C but with the slower result arriving after δ slow = 4 days. E Heatmap of the effective reproduction number obtained using the rapid, less accurate test, R rapid eff . The breaking-point lines of B, C, D are plotted in black.",USA,first author,2021-02-19,02
315613270fec0b6d1497259d89cc9a7098017764,How reacted USA with the first case of Bubonic Plague on 21 August?,"In August 2020, a news story is published that a resident of California, in the United States, tested positive for black death, being the first human case of the disease in this American state in five years [1] . Along with this, in December 2019, a new coronavirus triggered a group of cases of severe pneumonia in Wuhan, China. Since then, the World Health Organization (WHO) has called the disease ""coronavirus disease 2019"" (COVID-19) and the etiological agent ""severe acute respiratory syndrome-coronavirus-2"" (SARS-CoV-2) [2] .Bubonic plague ranks as the most severe bacterial disease known to man as judged by historical records of mortality and current understanding of the pathological processes that promote the infection [3] .Both diseases are generated by zoonotic agents, so that the population begins to relate both diseases. This case raises a question of how quickly social networks can identify potential outbreaks of zoonotic diseases, especially when comparing with the emergence of COVID-19. The plague identified in USA is a deadly infectious zoonotic disease and is caused by Yersinia pestis, a Gram-negative, immobile cocobacillus, which mainly affects wild rodents, which are its natural reservoirs and can be transmitted to humans and other animals through the bite of fleas from infected rodents. Therefore, it is also known as vector-borne disease [4] .Another important point is to determine the rapid onset of potential risks to public health, such as infections by pathogenic micro-organisms and, because plague in humans is also transmitted by chance contact with infected animal tissue or by the entry of aerosol bacteria by inhalation [5] , it is interesting to see how information is disseminated through social networks and to show that this determination can be a useful tool for the immediate detection of risks to public health.In order to help public health and to make better decisions regarding Public Health and to help with their monitoring, Twitter has demonstrated to be an important information source related to health on the Internet [6] , due to the volume of information shared by citizens and official sources. Twitter provides researchers an information source on public health, in real time and globally. Thus, it could be very important for public health researchIn this new world scenario, as established by Espina [7] , it is necessary to find the determinants of disease outbreaks before they occur, to reduce their impact on populations, and one of the great advantages is to obtain information brought by automated systems.Therefore, concepts, such as generating a relationship between consumer health informatics and public health informatics, must be taken into account. Currently, info-metrics and web analysis tools are being used for this type of purpose, obtaining information in an electronic means, specifically the Internet, with the ultimate goal of having a positive impact on public health and public policies [8] II. DATA AND METHODS The present work performs experiments with source data from Twitter with Natural Language Processing and Data Mining (Text Mining).• Choose terms to search on Twitter • Setup parameters of the query for Twitter and collect data • Pre-processing data to eliminate words with no relevance (stopwords) • VisualizationAfter an exploratory of trends and keywords related to Bubonic Plague, the next terms are chosen:The extraction of tweets is through Twitter API, with the next parameters:• date: 14-08-2020 to 21-08-2020 • terms: the chosen words mentioned in previous subsection • geolocalization, radius: values for each state, see Table. I and Figure 1 for general overview • language: English Due to the spread of the disease in the world, social media platforms and news websites have become places where there is an intense and continuous exchange of information between government agencies, professionals and general public.For the respective analysis, a review of the most relevant news regarding this outbreak of black death was made. Due to the pandemic stage that we live based on COVID-19, it had to be differentiated from tweets on black death, so it had to be filtered by keywords. In figure 2 , we look at the number of tweets per state. While California is where the Black Death case occurred, it is New York where this is most often discussed, followed by Texas and Washington.It is noted that the interest of the population, based on the number of tweets, is in the cities with the highest level of cases of COVID 19. According to Google statistics [9], the cities that present the greatest number of cases are those that talk the most about this issue. This indicates that there is a convergence of interests on the conjuncture, official news and users of social networks. Another important point for users from the cities most affected by COVID 19 to comment more on this news about Black Death, is that, in each of these states, there has been more information about this type of zoonotic diseases outbreak, which can lead to increased anxiety and stress caused by the pandemic, as well as by the efforts to reduce its spread [10] .Twitter is a two-way communication platform with a social network nature that limits its messages to 280 characters and, although it seems very limited. it is widely used for more formal topics than other social networks. In addition, it allows to generate trends based on the use of hashtags (#) which makes visible important issues that involve public health. A word cloud was generated, which is shown in Figure 3 , which gives us a visualization of the 50 most frequently used words in the study time range. We observe that the topic of the origin of the Black Death is the greatest interest of people in all USA.In order to have more detail, the same procedure was performed for all states of the USA, which is shown in figure  4 , where we observe that the word ""Black Death"" is present in most of them. These words related to death are linked to a fear generated at this stage by the COVID-19 pandemic, so it is a wake-up call to examine the psychological consequences of stressors arising from problems related to the emergence of new diseases [11] .Also, in the analysis of words, we can see that users talk about medical treatment, control procedures and political issues related to the health sector.The heat map is a very useful visual form to know the variables and their relationships, so it is used in Fig. 5 as a matrix of the feeling of users through their tweets 24 hours a day. The values are averages and show there are states with greater permanence of the idea of the Black Death as a reality in their country, such as the case of California, Florida, Texas, and New York having the highest 24-hour rate.It is also evident that the hours to create tweets, at the level of all states, is from 16 hours to 03 hours, being the period of greatest activity in this social network.However, because the Internet is an interactive medium, there is also the potential to seamlessly collect even richer data from people, or to direct them to interventions, this represents nothing less than a paradigm shift, as traditional surveillance efforts, which are based, for example, on monitoring emergency room admissions or over-the-counter drug sales, happen without consumers even noticing it or being able to provide input. In contrast, using infoveillance methods, consumers can be directed to provide additional information [12] .The use of Twitter has many potentialities and applications for determining the level of attention to critical situations, such as the presence of a Black Death case. Besides, it can be used as a data source in semi-real time and with a significant sample. This, promoted by the massive use of smart devices, so along with the development of machine learning tools can become a useful tool before, during and after events related to public health.",United States,abstract,2021-02-16,02
561b19a319e3f1dea5487b40428f5d0ceaca64b4,DARPP-32 promotes ERBB3-mediated resistance to molecular targeted therapy in EGFR-mutated lung 1 adenocarcinoma 2 3 4,"Email: hoepp005@umn.edu 27 28 Sk. Kayum Alam, Ph.D. 29 The Hormel Institute, University of Minnesota 30 801 16th Avenue NE 31Austin, MN 55912 32Phone: +1 (507) 355-5223 33Email: skalam@umn.edu 34 35 36 37 38 Introduction gastric cancer. The N-terminally truncated isoform of DARPP-32, termed t-DARPP, was found to utilize a 122 unique alternative first exon located within intron 1 of phosphoprotein phosphatase-1 regulatory subunit 1B 123 (PPP1R1B), the gene that transcribes DARPP-32 and t-DARPP proteins 35 . t-DARPP lacks the first 36 amino 124 acids of DARPP-32, including the T34 phosphorylation residue required for DARPP-32-mediated PP-1 125 inhibition 35 . Elevated expression of t-DARPP isoform in NSCLC is associated with poor overall survival and 126increasing tumor (T) stage 30 . Our findings presented in this report suggest that overexpression of DARPP-32 127 isoforms in EGFR-mutated NSCLC promotes EGFR:ERBB3 ""bypass signaling"" that enables tumor cells to 128 evade EGFR TKI monotherapy-induced apoptosis by potentiating oncogenic AKT and ERK signaling. 129 cycles, and fed a standard diet. Eight-to twelve-week-old male and female mice were anesthetized with 260 pharmaceutical grade ketamine (90-120 mg/kg) and xylazine (5-10 mg/kg) via intraperitoneal injection under a 261 laminar flow hood in an SPF room within the animal facility. Each fully anesthetized mouse was placed in the 262 right lateral decubitus position and the left lateral chest was sterilized. One-million luciferase-labeled human 263 HCC827GR and HCC827P lung cancer cells suspended in 80 μl PBS and high concentration Matrigel 264 (Corning; Cat. no.: 354248) were orthotopically injected in the left thoracic cavity of each mouse. Based on the 265 captured luminescence images of mice using an In-Vivo Xtreme xenogen imaging system (Bruker) as 266 described 28 , mice were randomly divided into two groups with nearly same average luminescence intensity. 267After establishment of the lung tumor, mice were administered either vehicle or gefitinib (25mg/Kg) every other 268 day for 2 weeks. Upon completion of the study, mice were euthanized using asphyxiation by CO2 inhalation to 269 effect with a flow rate displacing less than 30% of the chamber volume per minute in accordance with IACUC Eight-to twelve-week-old male and female mice were subcutaneously injected with 2×10 6 luciferase-labeled 279 human PC9P lung cancer cells suspended in 80 μl PBS and high concentration Matrigel. To determine tumor 280 growth, the tumor volume was measured every week using the formula: (length x width 2 )/2. After establishment 281 of palpable tumor (≥150mm 3 ), mice were randomly divided into two groups and administered either vehicle or 282 gefitinib (25mg/Kg). At the endpoint, mice were euthanized by CO2 asphyxiation. Extirpated tumors were 283 photographed, weighed, and preserved in formalin for immunohistochemistry analysis. This study was 284 performed in accordance with approved University of Minnesota IACUC protocols. 285Patients who met the following criteria were enrolled in this study: (1) pathologically confirmed advanced lung 288 adenocarcinoma; (2) NGS identified EGFR exon 21 L858R mutation; (3) treatment with gefinitib or erlotinib in 289 the first-line setting; and (4) accessed with disease progression and available tumor sample at baseline and 290 progression. Patients were examined every two weeks after EGFR TKI administration and 20% incensement of 291 tumor burden is considered as disease progression according to RECIST To compare differences between two groups, two-way unpaired t-test was performed and values of P ≤0.05 308 were considered significant. One-way analysis of variance (ANOVA) followed by Dunnett's test was used to 309 determine statistically significant differences between multiple groups (greater than two). Data expressed as 310 mean ±SEM are representative of at least three independent experiments. 311The authors declare that the data supporting the findings of this study are available within the article and its 313 supplementary information. 314Given the ability of DARPP-32 to modulate oncogenic signaling 50, 51 , we hypothesized that DARPP-32 318 contributes to acquired EGFR TKI resistance in NSCLC. To test this hypothesis, we utilized two well-319 characterized NSCLC models of EGFR TKI resistance. Gefitinib-resistant HCC827 (EGFR ΔE746-A750 ) human 320 NSCLC cells were previously generated through six months of exposure to increasing concentrations of 321 gefitinib and shown to have acquired gefitinib resistance through a c-MET amplification 43 . Secondly, we relied 322 on gefitinib-sensitive PC9 (EGFR L858R ) human NSCLC cells and their corresponding PC9 gefitinib-resistant 323 (PC9GR2 and PC9GR3) counterparts, which acquired gefitinib resistance through a secondary EGFR T790M 324 mutation following prolonged parental cell exposure to this first-generation EGFR TKI 44 . We observed reduced 325 DARPP-32 protein levels in gefitinib-sensitive, HCC827 parental (HCC827P) and PC9 parental (PC9P) cells 326 upon treatment with EGFR inhibitor, gefitinib ( Fig. 1a-b; Supplementary Fig. 1a-b) . Based on this result, we 327 sought to examine DARPP-32 protein levels in gefitinib-resistant EGFR-mutated NSCLC cells. By 328 immunoblotting, we observed elevated DARPP-32 protein expression in gefitinib-resistant cells relative to 329 parental counterparts (Supplementary Fig. 2a-b) . 330Given that DARPP-32 is upregulated in gefitinib-resistant NSCLC cells, we designed experiments to assess 332 the functional effects of DARPP-32 overexpression in the presence of EGFR TKI. We stably silenced DARPP-333 32 protein expression in HCC827GR cells via lentiviral-mediated transduction of two previously validated 334 Collectively, our findings suggest DARPP-32 reduces gefitinib-induced apoptosis of EGFR-mutated NSCLC 356We next sought to determine the molecular basis of DARPP-32-mediated cell survival in the presence of 359 EGFR inhibition. DARPP-32 has been shown to promote resistance of gastric cancer cells to EGFR inhibitors 360 by promoting an interaction between EGFR and ERBB3, which drives PI3K-AKT signaling 53 to ""bypass"" EGFR 361 TKI resistance. Importantly, we observe concomitant decreases in DARPP-32 protein expression and 362 phosphorylation of EGFR, ERBB2, and ERBB3 over time when gefitinib-sensitive HCC827P and PC9P cells 363were treated with various doses of gefitinib ( Fig. 1a-b; Supplementary Fig. 1a-b) . We next replicated these 364 PC9GR3 all express high levels of DARPP-32, p-EGFR, and p-ERBB3 upon treatment with 100 nM gefitinib 368 ( Fig. 1c-d) . Total ERBB3 protein levels were markedly increased upon EGFR TKI treatment in parental cells 369 and these high ERBB3 levels were maintained in gefitinib-treated HCC827GR, PC9GR2, and PC9GR3 cells ( Fig. 1c-d) . Changes observed in p-ERBB2 and total ERBB2 protein expression were less uniformly consistent 371 across the two resistance models, HCC827 and PC9 (Fig. 1c-d) , and ERBB4 protein was undetectable in 372 these cells (data not shown). Taken together, our observations suggest that upregulation of p-ERBB3, total 373 ERBB3 and total DARPP-32 protein levels positively correlate with an EGFR TKI resistance phenotype in 374 EGFR-mutated NSCLC cells. 375Given that DARPP-32 is overexpressed and ERBB3 is activated during gefitinib treatment in EGFR-mutated 377 NSCLC cells, we propose a mechanism of acquired resistance to EGFR TKIs in NSCLC, in which DARPP-32 378 mediates a switch from EGFR TKI-sensitive EGFR homodimers to TKI-resistant EGFR:ERBB3 heterodimers. 379This hypothesis is supported by findings showing that the physical association of EGFR and ERBB3 promotes 380 resistance to gefitinib in NSCLC 54 . To test this hypothesis, we assessed the phosphorylation status of EGFR 381and ERBB3 by immunofluorescence studies in EGFR TKI-sensitive PC9P human NSCLC cells overexpressing 382 DARPP-32 or t-DARPP upon gefitinib treatment. We observed a substantial reduction of p-EGFR intensity in 383 gefitinib-treated LacZ-overexpressed control PC9P cells, whereas p-EGFR intensity in EGFR-mutated cells 384overexpressing DARPP-32 isoforms remained unchanged upon gefitinib treatment ( Fig. 3a-b) . Overexpression 385 of DARPP-32 and t-DARPP promotes increased p-ERBB3 upon EGFR TKI treatment (Fig. 3a,c) , suggesting 386 DARPP-32 upregulation may be associated with increased activation of ERBB3 in the presence of EGFR TKIs. 387We next asked whether stable shRNA-mediated depletion of DARPP-32 in gefitinib-resistant PC9GR3 cells 388 affects phosphorylation of ERBB3 and EGFR upon gefitinib treatment. We observed a decrease in p-ERBB3 389 expression in gefitinib-treated DARPP-32-ablated PC9GR3 cells, whereas changes of p-ERBB3 levels were 390 not detectable in corresponding LacZ shRNA control PC9GR3 cells upon treatment with gefitinib 391 ( Supplementary Fig. 7a,c) . Others have reported that p-EGFR is not responsive to gefitinib in PC9GR3 cells 44 . 392Correspondingly, knockdown of DARPP-32 in gefitinib-treated PC9GR3 cells did not affect p-EGFR levels 393(Supplementary Fig. 7a-b) . Collectively, our results demonstrating changes in activation of ERBB3 upon 394 DARPP-32 modulation in the presence of EGFR TKI support a model in which DARPP-32 contributes to 395 ERBB3-driven ""bypass signaling"" to promote EGFR-mutated NSCLC cell survival. 396To better understand the mechanism of resistance to gefitinib in EGFR-mutated NSCLC cells, we aimed to 399 determine how DARPP-32 activates ERBB3 signaling to suppress gefitinib-mediated EGFR inhibition. To 400 address our hypothesis that DARPP-32 drives EGFR:ERBB3 heterodimerization to evade EGFR TKI-mediated 401 cell death, we performed immunoprecipitation studies to assess potential EGFR and ERBB3 interactions in 402 DARPP-32-modulated EGFR-mutated NSCLC cells. Immunoprecipitation using anti-ERBB3 antibody 403 demonstrates that EGFR and ERBB3 physically interact and that the EGFR:ERBB3 association increases 404 upon overexpression of DARPP-32 isoforms in HCC827P and PC9P cells ( Fig. 4a- Given that ERBB3 has limited kinase activity and relies on heterodimerization with EGFR for activation 55 , we 417 postulate that DARPP-32 promotes ERBB3 phosphorylation by increasing physical association between p-418 EGFR and p-ERBB3. To address our theory, we performed proximity ligation assay (PLA) using anti-p-EGFR 419 and anti-p-ERBB3 antibodies in PC9GR3 cells. PLA is a powerful tool for identifying protein-protein interaction 420 in situ with high specificity and sensitivity. Our PLA findings suggest that gefitinib treatment induces p-EGFR/p-421 ERBB3 heterodimer complex formation in PC9GR3 cells ( Fig. 5a-b) . However, ablation of DARPP-32 in 422 PC9GR3 cells abolishes gefitinib-induced p-EGFR/p-ERBB3 dimerization, suggesting DARPP-32 plays a 423 significant role in the formation of these active heterodimers ( Fig. 5a-b) . We next sought to determine how DARPP-32 regulates MEK/ERK and PI3K/AKT signaling pathways in the presence of gefitinib. It has been 425 reported that ligand-independent EGFR activation initiates intracellular signaling via Ras/Raf/MEK/ERK and 426 PI3K/AKT signaling pathways 13 . We show by immunoblotting that overexpression of DARPP-32 isoforms 427 increases p-AKT and p-ERK expression in gefitinib-treated sensitive cells (Fig. 6a) . Knockdown of DARPP-32 428 reduces p-AKT and p-ERK expression in gefitinib-treated resistant cells (Fig. 6b) . EGFR-dependent PI3K 429 activation requires dimerization with the ERBB3 receptor because docking sites of PI3K (i.e. p85 subunit) are 430 abundant on ERBB3 and absent within EGFR 13 . To test our hypothesis that DARPP-32 activates the PI3K 431 signaling pathway in EGFR-mutated NSCLC cells, we used a bioinformatics approach to assess DARPP-32 432 transcript expression in specimens derived from 80 EGFR-mutated NSCLC patients cataloged in The Cancer 433Genome Atlas (TCGA). We first subdivided patient-derived specimens into two groups based on high versus 434 low DARPP-32 mRNA expression ( Supplementary Fig. 8a ). Interestingly, we found that expression of 435 RPS6KB2 transcripts, but not RPS6KB1 transcripts, increases in lung tumor specimens with high expression of 436 DARPP-32 ( Supplementary Fig. 8b-c) Based on our findings suggesting that DARPP-32 increases ERBB3 phosphorylation to bypass gefitinib-448induced EGFR inhibition, we next sought to understand whether DARPP-32 drives NSCLC resistance to EGFR 449TKIs in vivo. To this end, we tested whether DARPP-32 ablation increases EGFR TKI sensitivity in a gefitinib-450 resistant orthotopic xenograft mouse model. Briefly, we injected luciferase-labeled human gefitinib-resistant 451 (HCC827GR) NSCLC cells into the left thorax of anesthetized SCID mice, confirmed establishment of lung tumors via luciferase imaging, administered gefitinib over the course of two weeks, and measured tumors 453 through non-invasive luciferase imaging (Fig. 7a ). Mice challenged with HCC827GR cells with DARPP-32 454 stably silenced by shRNA show decreased tumor growth when treated every other day with gefitinib relative to 455 vehicle controls ( Fig. 7b; Supplementary Fig. 9a ). DARPP-32 knockdown sensitizes gefitinib-resistant NSCLC 456 tumors to EGFR inhibition in vivo, whereas no such effect was observed in mice challenged with control LacZ 457 shRNA transduced HCC827GR cells ( Fig. 7b; Supplementary Fig. 9a ). Histological sections from these mice 458were immunostained for Ki-67. We observed decreased tumor cell proliferation in the lungs of gefitinib-treated 459 mice challenged with DARPP-32-silenced HCC287GR cells (Fig. 7c) , confirming that DARPP-32 knockdown 460 enhances EGFR TKI-induced anti-cancer effects in gefitinib-resistant tumors in vivo. 461We next sought to determine whether overexpression of DARPP-32 isoforms promotes resistance to gefitinib 462 in vivo. Gefitinib-sensitive HCC827 parental (HCC827P) tumors overexpressing DARPP-32 or t-DARPP that 463were implanted orthotopically into the lungs of mice exhibit gefitinib resistance relative to controls ( To investigate the clinical relevance of DARPP-32 given its role in promoting resistance to EGFR first-476 generation TKIs in mouse models of human NSCLC, we assessed DARPP-32, p-EGFR, total EGFR, p-477 ERBB3, and total ERBB3 protein expression by immunostaining in paired EGFR TKI-naïve and -resistant 478 specimens from 30 lung adenocarcinoma patients (Supplementary Table 1 ). Briefly, lung tumor specimens were biopsied from lung adenocarcinoma patients before EGFR TKI treatment (i.e. baseline) and following the 480 development of progressive disease after first-line gefitinib or erlotinib therapy. For immunostaining of each 481 protein, three pathologists independently scored the percentage of tumor cells staining positive and 482 corresponding staining intensity (i.e., 0 = none, 1 = weak, 2 = moderate, 3 = strong expression). We calculated 483 an immune reactive (IR) score for each specimen based on the percentage of tumor cells staining positive and 484 the staining intensity in those cells (IR score = percentage of tumor cells x staining intensity). We found that 485 DARPP-32, kinase-activated EGFR, total EGFR, kinase-activated ERBB3, and total ERBB3 proteins are 486 upregulated in 1st generation EGFR TKI-resistant NSCLC patient-derived specimens relative to individual 487 patient-matched (i.e. paired) baseline samples biopsied prior to frontline gefitinib or erlotinib treatment (Fig 9a-488 b). Collectively, our results suggest that DARPP-32 overexpression and increased EGFR and ERBB3 489 activation is associated with EGFR TKI resistance in NSCLC patients. Lung cancer is the deadliest and most frequently diagnosed type of tumor worldwide, with 1.6 million deaths 494 reported annually 57 . The molecular targeting of specific oncogenic drivers has emerged as a major 495 advancement in the treatment of NSCLC. Patients diagnosed with advanced non-squamous cell NSCLC are 496 tested for oncogenic alternations and treated accordingly 20, 58 . Single oncogenic driver mutations in EGFR that 497 confer sensitivity to TKIs are the most common targetable molecular alteration in lung adenocarcinoma. 498Although EGFR mutation positive patients initially respond well to EGFR TKI therapy, most patients inevitably 499 develop resistance and experience rapid advanced disease progression. Developing acquired resistance to 500 lung cancer therapy is a major problem. The development of effective strategies to circumvent the emergence 501 of this resistance is needed to improve survival rates and the quality of life of NSCLC patients. 502The spectrum of identified EGFR resistance mechanisms includes on-target EGFR gatekeeper mutations (i.e. . ERBB3, specifically, has been implicated in the initiation of EGFR TKI resistance. Unlike its fellow family 514 members, ERBB3 was initially believed to be an inactive kinase because its kinase domain lacks certain 515 residues known to be essential for catalytic activity 67 . However, ERBB3 forms heterodimers with other ERBB 516 family members to become transphosphorylated and transactivated to sustain transduction of downstream 517 oncogenic signaling that would otherwise be inhibited by EGFR TKIs acting upon EGFR homodimers [68] [69] [70] . 518Several known mechanisms of ERBB3-induced TKI resistance exist by which ERBB3 compensates for TKI-inhibited EGFR to trigger and sustain PI3K/Akt signal transduction. First, MET amplification has been shown to 520 result in constitutive activation of ERBB3 signaling to promote gefitinib resistance in lung cancer cell lines 43 . 521Second, ERBB3 heterodimerization with ERBB2 has been demonstrated to drive oncogenic signaling in breast 522 cancer 71 as the effects of ERBB2 inhibition could be reversed by increasing ERBB3 phosphorylation and 523 activity to drive a TKI resistance phenotype 70 . Third, ligand-mediated activation of ERBB3 has been shown to 524 result in PI3K/Akt-mediated resistance to TKIs in a variety of cancers, including ERBB2-amplified breast 525 cancer cells stimulated with ERBB3 ligands, NRG1 72 or HRG 73 . We identify a new mechanism of ERBB3-526 mediated TKI resistance in which DARPP-32 physically stimulates this process of EGFR:ERBB3 heterodimer 527 formation to promote PI3K/Akt and MAPK signaling to overcome the inhibitory effects of EGFR TKIs. 528We were the first to report that DARPP-32 overexpression in lung cancer contributes to oncogenic growth 30 . 529While DARPP-32 is virtually undetectable in normal human lung 28 , DARPP-32 is overexpressed in human 530 EGFR-mutated NSCLC. Specifically, we previously demonstrated that DARPP-32 proteins promote NSCLC 531 cell survival through increased Akt and Erk1/2 signaling 30 . Given that these PI3K and MAPK signaling 532 pathways are upregulated during resistance, we hypothesized that overexpression of DARPP-32 proteins in 533 EGFR-mutated NSCLC may promote EGFR:ERBB3 ""bypass signaling"" that enables tumor cells to evade 534 EGFR TKI monotherapy. In this report, we provide the first evidence that DARPP-32 overexpression in EGFR-535 mutated lung adenocarcinoma promotes ERBB3-mediated oncogenic signaling to drive EGFR TKI therapy 536 refractory cancer progression. In vivo studies reveal that ablation of DARPP-32 protein activity sensitizes 537 gefitinib-resistant lung tumor xenografts to EGFR TKI treatment, while DARPP-32 overexpression increases 538 gefitinib-refractory lung cancer progression in gefitinib-sensitive lung tumors orthotopically xenografted into 539 mice. Findings from proximity ligation assays, immunoprecipitation studies, and immunofluorescence 540 experiments presented here support a model in which DARPP-32 mediates a switch from EGFR TKI-sensitive 541 EGFR homodimers to TKI-resistant EGFR:ERBB3 heterodimers to potentiate oncogenic AKT and ERK 542 signaling that drives therapy refractory tumor cell survival. To our knowledge, no proteins have been identified 543 that are capable of mediating such a ""dimerization switch"" in EGFR-mutated NSCLC. Here, we take 544 advantage of a unique cohort of paired tumor specimens derived from 30 lung adenocarcinoma patients before 545 and after the development of EGFR TKI refractory disease progression to reveal that DARPP-32 as well as 546 kinase-activated EGFR and ERBB3 proteins are overexpressed upon acquired EGFR TKI resistance. This 547 observation coincides with our published report that increased t-DARPP immunostaining positively correlates 548 with increasing T stage among unknown EGFR mutation status NSCLC patients 30 . There is no precedent of 549 DARPP-32 isoform immunostaining in molecular targeted therapy naïve vs. resistant patients in other tumor 550Our data comprehensively suggests that DARPP-32 overexpression promotes EGFR TKI resistance by 552 stimulating formation of EGFR:ERBB3 heterodimers, which are less sensitive to EGFR inhibition and drive 553 oncogenic signaling. Therefore, dual inhibition of EGFR and ERBB3 may better prevent treatment-refractory 554 cancer progression as opposed to solely targeting EGFR, especially in tumors overexpressing DARPP-32. A 555 precision oncology approach could be used to identify EGFR-mutated lung adenocarcinomas with high 556 DARPP-32 and phosphorylated ERBB3 expression with the highest likelihood to benefit from dual EGFR and 557 ERBB3 inhibition. For example, duligotuzumab is a human IgG1 monoclonal ""two-in-one"" antibody with high 558 affinity for EGFR (KD ~ 1.9 nM) and ERBB3 (KD ~ 0.4 nM) developed to improve treatment response of solid 559 tumors exhibiting ERBB3-mediated resistance to EGFR-targeted treatment 74 . Partial responses to 560 duligotuzumab were achieved in patients with squamous cell carcinoma of the head and neck that had become 561 resistant to cetuximab, an antibody therapy that inhibits EGFR 75 . Efficacy was also observed in tumors 562 refractory to both radiation and long-term EGFR-targeted treatment 76, 77 . Duligotuzumab monotherapy has 563 been shown to be well-tolerated in patients with locally advanced or metastatic solid tumors of epithelial 564 origin 75 . However, a recent randomized phase II study of duligotuzumab vs. cetuximab in squamous cell 565 carcinoma of the head and neck (i.e. MEHGAN; NCT01577173) found duligotuzumab did not improve disease 566 free survival compared to cetuximab 78 and antibody-reactive protein bands were detected using anti-p-EGFR, EGFR, p-ERBB2, ERBB2, p-ERBB3, 608ERBB3, DARPP-32, and α-tubulin antibodies. Immunoblotting experiments were repeated independently at 609 least three times, and a representative experimental result is shown. 610 , and ERBB3. Immunoprecipitated protein complexes and total cell lysates (input) were immunoblotted using anti-EGFR, ERBB3, FLAG, and α-tubulin antibodies. c-d Human lung adenocarcinoma HCC827P, HCC827GR (c), PC9P, PC9GR2, and PC9GR3 (d) cells were lysed and immunoprecipitated with anti-DARPP-32 (recognizes endogenous DARPP-32 and t-DARPP) and anti-ERBB3 antibodies. Immunoprecipitated lysates along with total cell lysates were separated on SDS-PAGE followed by immunoblot analysis using antibodies against EGFR, ERBB3, DARPP-32, and α-tubulin. Immunoprecipitation experiments were repeated at least three times. : Expression of DARPP-32, p-EGFR, and p-ERBB3 proteins is elevated in EGFR TKI resistant lung adenocarcinoma. a Tumor tissue was biopsied before EGFR TKI treatment (i.e. baseline) and following EGFR TKI resistance (i.e. progressive disease after first-line gefitinib or erlotinib therapy) from lung adenocarcinoma patients with EGFR activating mutations (n=30 patients in each group). Paired baseline (top) and EGFR TKI resistance (bottom) lung tumor specimens were immunostained for DARPP-32, phosphorylated EGFR (p-EGFR), total EGFR, p-ERBB3, and total ERBB3. b IHC score was calculated by multiplying the staining intensity score were immunoblotted with anti-DARPP-32 and -α-tubulin (loading control) antibodies. b HCC827GR cells were transduced with control (LacZ) or DARPP-32 shRNAs and seeded into 96-well cell culture plates. Cells were treated with increasing concentration of gefitinib and colorimeter-based cell survival assay was conducted using MTS1 reagents. c The half maximal inhibitory concentration (IC50) of gefitinib was determined from MTS1 survival assays and plotted. d HCC827P cells were transduced with retrovirus encoding control (LacZ), DARPP-32 or t-DARPP overexpressing clones. Cells were lysed and immunoblotting was performed to detect α-tubulin and DARPP-32 isoforms. e Cell survival assays were performed using HCC827P cells stably overexpressing LacZ, DARPP-32 or t-DARPP proteins exposed to increasing concentrations of gefitinib. f Gefitinib-treated HCC827P cells overexpressing LacZ or DARPP-32 isoforms were subjected to MTS1-based cell survival assays and IC50 of gefitinib was calculated. Each open circle on a graph represents an independent experiment. All bar graphs represent mean ± SEM (n=3). *P<0.05, **P<0.01, and ***P<0.001, one-way ANOVA followed by Dunnett's test for multiple comparison. a DARPP-32-depleted luciferase-labeled human HCC827GR cells were orthotopically injected into the left thoracic cavity of SCID mice. Mice administered either vehicle or gefitinib (25mg/Kg) were imaged for luminescence before and after treatment. b Retrovirus encoding control (LacZ), DARPP-32 or t-DARPP cDNAs were transduced in luciferase-labeled human HCC827P cells. After establishment of the tumor, mice were treated with vehicle or gefitinib (25mg/Kg) three times in a week. Luminescence images of mice were taken pre-and post-treatment. The colored bar represents the numerical value of luminescence.Supplementary Figure 10 : Overexpression of DARPP-32 suppresses gefitinib efficacy in vivo. a-c SCID mice were subcutaneously injected with PC9P cells stably overexpressing control (LacZ) or DARPP-32 cDNAs and treated with vehicle or Gefitinib (25mg/Kg). At endpoint of the experiments, mice were sacrificed and xenografted tumors were extirpated. Photographs of extirpated tumors were taken to visualize gross morphology (a). Tumor volume was calculated from calipers measurement after extirpation (b). Weight of extirpated tumors from sacrificed mice was measured using a digital balance (c). Each open circle on bar graphs represents an individual mouse. Bar diagrams show Mean±SEM. **P<0.01, 2-way unpaired t-test. L858R  60  0  0  0  0  180  80  10  30  0  gefitinib  SD  -10%  25  12 IV  66  2 ADC  L858R  0  210  0  0  0  30  150  20  10  30  gefitinib  PR  -60%  8  13 IV  55  2 ADC  L858R  240  100  0  10  5  240  270  0  60  10  erlotinib  PR  -30%  8  14 IV  66  2 ADC  L858R  90  120  0  0  0  150  270  20  0  0  erlotinib  PR  -80%  11  15 IV  47  2 ADC  L858R  0  0  0  0  0  240  100  20  0  0  gefitinib  SD  -15%  3  16 IV  66  2 ADC  L858R  180  0  0  0  0  150  180  30  15  0  erlotinib  PR  -30%  21  17 IV  63  1 ADC  L858R  120  120  40  0  0  180  180  10  10  0  gefitinib  PR  -35%  9  18 IV  62  1 ADC  L858R  180  30  0  0  0  150  210  10  100  10  erlotinib  PR  -35%  24  19 IV  70  1 ADC  L858R  100  30  20  0  0  90  150  70  50  0  gefitinib  PR  -30%  22  20 IV  62  1 ADC  L858R  210  30  0  0  0  30  30  50  10  0  gefitinib  PR  -30%  4  21 IV  81  1 ADC  L858R  240  80  0  0  0  60  120  10  0  30  erlotinib  PR  -50%  12  22 IV  61  1 ADC  L858R  100  180  0  10  15  60  270  50  10  10  erlotinib  SD  -15%  26  23 IV  54  2 ADC  L858R  240  80  0  0  0  180  100  0  60  0  gefitinib  PR  -50%  15  24 IV  48  2 ADC  L858R  20  160  0  0  0  60  210  60  60  5  erlotinib  SD  -20%  3  25 IV  66  1 ADC  L858R  20  270  30  0  0  90  150  0  30  0  gefitinib  PR  -70%  18  26 IV  55  2 ADC  L858R  240  60  0  5  5  210  210  0  15  25  gefitinib  PR  -35%  13  27 IV  66  1 ADC  L858R  240  50  0  5  5  270  100  10  10  0  erlotinib  PR  -30%  12  28 IV  59  2 ADC  L858R  40  300  0  0  0  45  210  25  40  40  gefitinib  PR  -35%  21  29 IV  62  1 ADC  L858R  40  80  0  10  0  150  120  0  0  20  erlotinib  PR  -42%  7.8  30 IV  70  1 ADC  L858R  60  40  0  0  0  270  160  0  0  0  erlotinib  SD  -20%  19   Supplementary Table 1 ",United States,abstract,2021-02-13,02
f9815e331168a6faa7ca678a0b7d129d3edc71b8,Enzyme kinetics of CRISPR molecular diagnostics,"There have been many interesting advancements in the field of CRISPR diagnostic assays in the last few years. This is particularly true during the current COVID-19 pandemic where CRISPR diagnostics have been frontline contenders for rapid testing solutions [1] [2] [3] [4] . CRISPR diagnostic assays use subtypes of Cas12 or Cas13 enzymes for DNA or RNA detection, respectively [5] [6] [7] [8] . The emerging and strong interest in CRISPR diagnostics research prompts the following question: What exactly are the achievable limits of detection (LODs) and associated assay times enabled by the kinetics of Cas12 and Cas13 enzymes ( Figure 1) ? As expected, the answer to this important question depends strongly on the CRISPR-associated enzyme kinetics as these establish and fundamentally limit the sensitivity of these diagnostics.For ssDNA and dsDNA detection using CRISPR-Cas12, LbCas12a has been the most widely used Cas enzyme. 2, 4, 7, [9] [10] [11] The study of Chen et al. 11 was the first to characterize and report the kinetic rates of LbCas12a. The latter study reported an enzyme turnover rate (kcat) and Michalis-Menten constant (KM) of 250 per second and 4.94 x 10 -7 M, respectively, with a catalytic efficiency (kcat/KM) of 5.1 x 10 8 M -1 s -1 for LbCas12a activated by target ssDNA. For a dsDNA activator, the study reported a kcat and KM of 1250 per second and 7.25 x 10 -7 M, respectively, and a kcat/KM of 1.7 x 10 9 M -1 s -1 . The latter value reportedly approached the limit of diffusion. 11 Cofsky et al. 12 studied the trans-cleavage activity of AsCas12a and reporter a kcat and KM of 0.6 per second and 2.7 x 10 -6 M, respectively. We note the latter value of kcat is a factor 340 times lower than the second-lowest kcat ever reported for any CRIPSR associated enzyme (a study on LbuCas13a; Table 1 ). 13 For ssRNA detection using CRISPR-Cas13, the study of Slaymaker et al. 14 was the first to report enzyme turnover rates among all the subtypes and orthologs of Cas13. They reported a kcat of 987 turnovers per second for PbuCas13b. Subsequently, Shan et al. 15 reported a kcat of 4854 per second and KM of 4.45 x 10 -6 M using a 5 nt (of rU) ssRNA fluorescent reporter in an application of LbuCas13a for MicroRNA (miRNA) detection. Later, Zhou et al. 13 showed for LbuCas13a that a shorter reporter molecule which was composed of 2 nt (of rU) lowered the kcat to 204 per second and KM of 2.62 x 10 -6 M. Most recently, Fozouni et al. 1 presented a study of SARS-CoV-2 viral RNA detection using LbuCas13a and a set of 3 gRNAs, and used a model to fit their experimental data which used parameters of kcat = 600 per second and KM between 1 x 10 -6 M and 3 x 10 -6 M.In this work, we provide back-of-the-envelope analyses and scaling arguments based on Michaelis-Menten-type enzyme kinetics theory applied to CRISPR-diagnostics. We present a set of simple rules based on fundamental principles of species conservation, maximum reaction velocities, and reaction time scales, and these rules can be used as a check on reported parameters of enzyme kinetics. We apply these rules and perform calculations on several published studies. Surprisingly, we find all but one study (the aforementioned lowest ever reported value of kcat) clearly violate at least two of our three rules of consistency. Lastly, we develop and present results from analytical and numerical models for predicting Cas enzyme kinetics and use these to discuss the effect of kinetic parameters on the assay time scales and limits of sensitivity of CRISPRdiagnostic assays.We first present an enzyme kinetics model for the trans-cleavage activity of CRISPRassociated enzymes. The mechanisms of relevant reactions are summarized in Figure 1 . This model invokes Michaelis-Menten enzyme kinetics theory 16 and can be used to develop closedform approximations for product formation versus time. We then present three rules based on kinetics theory and fundamental principles of species conservations. These rules enable simple back-of-the-envelope calculations and can be performed to check the self-consistency and/or accuracy of reported enzyme kinetics data.Upon recognition of the target nucleic acid, the CRISPR-enzymes are activated and exhibit non-specific trans-cleavage of single-stranded nucleic acids (c.f. Fig. 1) . 9, 11, 17 This trans-cleavage activity is a multi-turnover enzymatic reaction catalyzed by the target activated CRISPR enzyme. This reaction is the key process underlying nucleic acid detection assays. Cas12 can be activated by target ssDNA and dsDNA, while Cas13 is activated by ssRNA. Upon activation, Cas12 and Cas13 indiscriminately cleave ssDNA and ssRNA molecules, respectively. CRISPR assays typically use fluorescent nucleic acid molecules (with a quencher) as reporters, which fluoresce only when they are cleaved by the CRISPR enzyme in the presence of target.The trans-cleavage CRISPR enzymatic reaction can be modeled aswhere, ! is target-activated Cas12/13-gRNA complex, # is the uncleaved reporter, ' is the reaction intermediate (enzyme-substrate reporter complex), ) is the cleaved reporter molecules, 0 # and 0 $ are the forward and reverse rate constant for the reaction between ! and #, and 0 %&' is the catalytic turnover rate of the enzyme. The reaction rate laws for the individual species are as follows: where ! ( and # ( are respectively the initial amount of target-activated enzyme and substrate (most typically a synthetic nucleic acid reporter molecule). The ""t"" in parentheses indicate timedependent quantities. We note that ! ( is at most equal to the amount of target nucleic acid present in the sample (usually the Cas-gRNA complex is present in abundance). However, at very low concentrations of target, target recognition and activation of the CRISPR enzyme (cis-cleavage) is limited by the diffusion of the target molecules to the active site of the enzyme. 18 For simplicity, we will here assume that ! ( is given by the concentration of the target nucleic acid. Under these assumptions, the rate of product formation (reporter cleavage) is governed by the Michaelis-Menten equationIn traditional Michaelis-Menten kinetics systems, ! ( ≪ # ( and the kinetics are studied over short time scales (relative to the overall product formation time scale). Hence, in this limit, very little product is formed ) ≪ # ( and [#] ≈ # ( . Thus, the product is formed at a constant rate (e.g., linear fluorescence increase vs time), and the reaction velocity is given by Equation (8) Further, in most practical applications of CRISPR-diagnostics, the concentration of the substrate is much smaller than the Michaelis-Menten constant of the enzyme, [#] ≪ ? ) . Typically, # (~B (100 nM) and ? )~B (1 µM). Thus, we can use this approximation to further derive an expression for the evolution of the product (reporter cleavage) versus time, over much longer time scales. Specifically, we can rewrite Equation (8) asEquation (9) can be rearranged into a linear first-order differential equation 19 asEquation (10) can be solved analytically for the concentration of product formed (reporters cleaves) versus time aswhere J = ? ) /0 %&' ! ( . Here J is a time scale that governs the characteristic time to approximately complete the reaction, and [)](4)/# ( is simply the fraction of cleaved reporters relative to the total initial uncleaved reporters. Physically, we see that the time scale of significant product formation J decreases with: (i) higher turnover rate 0 %&' , (ii) higher target concentration ! ( , (iii) lower ? ) (which represents a higher affinity of the activated enzyme to the substrate). Further, we also see that the ratio of 0 %&' to ? ) is very important for the product formation rate and this ratio arises naturally from the current analysis. The Cas13:gRNA complex is activated by a target ssRNA (cis-cleavage; single turnover), after which the activated enzyme cleaves ssRNA molecules including ssRNA reporters indiscriminately (trans-cleavage; multi turnover). Cas12:gRNA can be activated by both target ssDNA and dsDNA (cis-cleavage; here, shown only for dsDNA). After activation, the Cas12 enzyme cleaves ssDNA molecules including ssDNA reporter molecules indiscriminately (trans-cleavage activity; multi turnover). The trans-cleavage activity for Cas12 and Cas13 each follows Michaelis-Menten kinetics, where the target-activated Cas-gRNA complex is the enzyme (E), the fluorescent reporter molecule is the substrate (S), and the cleaved reporter molecule is the product (P).We here present three simple back-of-the-envelope hand calculations that can be used to verify the accuracy of reported kinetics data from experiments and/or simulations. The first rule derived here originates simply from species conservation: The amount of product formed during the initial linear portion 4 *+, of the kinetics measurements (c.f. Figure 2 ; early time scales where J < 1) cannot exceed the initial amount of substrate (before the start of the reaction). 4 *+, is a quantity that typically is easily apparent from experimental data (e.g. the duration of the initial, nearly linear increase of fluorescence versus time data). We can define the non-dimensional parameter N as the ratio of the total product formed at 4 *+, and the initial substrate concentration # ( . For most CRISPR diagnostics assays, N is the ratio of the amount of cleaved reporters at time 4 *+, to the initial concentration of the uncleaved reporters # ( . Simple conservation of species then limits this value to unity as inHere > is the reported reaction velocity (e.g., in nM/s). The second rule is derived from the theoretical maximum reaction velocity possible as given by Michaelis-Menten kinetics. From Equation (8), the maximum rate of product formation occurs when the substrate concentration is far in excess compared to ? ) , [#] ≫ ? ) , and the theoretical maximum velocity > -&. is equal to 0 %&' ! ( . One can therefore define a non-dimensional quantity, P, as the reported velocity > normalized by > -&. as follows:Third, we observe that the time scale of linear portion of the kinetics data 4 *+, should be at most on the same order as the reaction time scale J. For this, we define a non-dimensional quantity, R, defined as the ratio of 4 *+, and J, and so the third rule is given byLastly, we note that the first rule (condition on N) does not require a priori estimates of the reaction parameters 0 %&' and ? ) . The first rule is therefore a good check on ensuring consistent fluorescence versus concentration calibration for experiments. For example, inconsistencies in calibration or conversion from fluorescence to concentration will result in unphysical values of >, and these artifacts can lead to an apparent violation of the first rule (hence, we here assume the initial substrate concentrations and times are properly reported). The second and third rules rely on empirically determined (e.g. by fitting models to experimental data) reaction parameters 0 %&' and ? ) (e.g., using a curve fit to initial reaction velocity versus substrate concentration kinetics data). The latter two rules (involving P and R) provide useful validations of self-consistency in kinetics data and the reported values of 0 %&' and ? ) . Briefly, all data should obey Rules 1 and 2, and reactions for which [#] ≪ ? ) (this inequality can be interpreted as less than about 5 fold) must obey Rule 3.Presented in Table 1 are the back-of-the-envelope checks for quantities N, P, and R (c.f. Section 2.2) which we performed on published studies that present Michaelis-Menten-type characterization experiments and kinetics data for different Cas12 and Cas13 enzymes. To the best of our knowledge, we have included all published studies to date which present any Michaelis-Menten kinetics data for CRISPR-Cas12/13. We found that all of the studies except one listed in the first column of Table 1 violated at least two of the three checks involving N, P, and R (see fifth, sixth, and seventh columns, respectively). For example, the studies of Chen et al. 11 for LbCas12a and Zhou et al. 13 for LbuCas13a both had values of N and R significantly greater than 1. The study of Shan et al. 15 for LbuCas13a reported values of N, P, and R which were each greater than 1, and so violated all the three rules. Slaymaker et al. 14 studied PbuCas13b, and the study violated at least two (N and P conditions) out of the three checks. The study of Cofsky et al. 12 involving AsCas12a was the only one which passed all three checks. Interestingly, the study of Cofsky et al. 12 is a dramatic outlier in the reported value of kcat (c.f. second column of Table 1 ). The results in Table 1 suggest that the kinetics parameters (second, third, and fourth columns of Table 1 ) published in the aforementioned studies (first column of Table 1 ) with at least one check violated are not reliable and the data may be grossly incorrect. Also listed in Table 1 are other relevant publications 1,10,20-23 (column 10) which cite the aforementioned studies and either directly rely (e.g. in making estimates or modeling experiments) on the published kinetics data or provide new experimental data which reportedly corroborates the older kinetics parameter values that violated our checks.Lastly, we present updated kinetics parameter values (columns 11, 12 and 13 of Table 1 ) which we recently received from the corresponding authors of Refs. 11,14 through personal communication 24, 25 . The current authors learned from the corresponding authors of Ref. 11 (the oldest study in the set) that the error in kinetic rates of LbCas12a in their original publication was due to an incorrect conversion of relative fluorescence units to molar concentration for the initial reaction velocity calculations. Unlike most of originally published data, the updated kinetic rates for Refs. 11,14 are consistent with (i.e. pass) our three back-of-the-envelope checks (see columns 14, 15, and 16 of Table 1 ). That is, for these updated values, the three quantities N, P, and R are each less than unity as expected. If these updated kinetic parameters are correct, a major consequence is that the kinetics of LbCas12a is not catalytically efficient or diffusion-limited (0 %&' /? )~1 0 / to 10 0 M 12 s 12 ), contrary to wide consensus in the CRISPR field (e.g. see Refs. 4, 10, 11, 20, 22 ). Also, turnover rates for LbCas12a and PbuCas13b, respectively, which are 2 to 3 orders of magnitude lower would imply that proportionally longer reaction time scales are required for trans-cleavage activities (Equation (11)). As we discuss in the next section, this would have dramatic effects on the achievable limits of detection using CRISPR diagnostics (e.g. without pre-amplification).We here use the model developed in Section 2.1 to explore the kinetics of Cas enzymes. Figure 2 shows the fraction of reporters cleaved by the target-activated enzyme divided by the initial amount of uncleaved reporters present in the reaction versus time normalized by the reaction time scale J. Results are shown for kcat and KM of 17 s -1 and 1.01 x 10 -6 M, which are based on the updated kinetic parameters for LbCas12a enzyme and a dsDNA activator (Table 1) . Also, we assumed 100 pM (! ( ) of target dsDNA and 200 nM (# ( ) of ssDNA reporters for Figure 2 . Presented in Figure 2 are results from both a numerical model that solves the complete set of coupled differential equations for the enzyme kinetics (Equations (2)-(5)) (solid line) and the analytical solution (shown as symbols in Figure 2 ) given by Equation (11) . First, we see very good agreement between the analytical and numerical solution results. Also, indicated by the green dashed line is a tangent to the numerical solution at early reaction times (4 → 0 s), and the slope of this line is the scaled reaction velocity > * (= >J/# ( ), where > is a quantity typically measured in Michaelis-Menten-type kinetics analysis (Equation (8)). Consistent with our normalization and species conservation (N condition; Section 2.2), note that the cleaved reporter fraction asymptotes to unity for large times. Also, note from Figure 2 that J (= ? ) /0 %&' ! ( ) represents the physically relevant product formation/reaction time scale. Consistent with our formulation (i.e. the R condition; Section 2.2), we see that most of the early-time linear increase in the product amount happens for 4/J < 1. Lastly, we note that, due to our choice of normalization variables, the curve showed in Figure 2 can be fairly generalized to other concentrations of target and reporters (see Equation (11)) as long as ! ( ≪ # ( , and for # ( lower than ? ) by at least a factor of ~5.Next, we study the fraction of cleaved reporters as a function of the target nucleic acid concentration and the concentration of the initial uncleaved reporter (Figure 3) . We assume the same enzyme kinetics parameters as Figure 2 , and study the product formed after 60 min of reaction time (commensurate with typical molecular diagnostic assays). First, note that, for initial reporter concentrations lower than about 1 µM, the fraction of cleaved reporters is nearly invariant with the initial reporter concentration (this limit is provided by the analytical solution in Equation (11) ). Further, the fraction of cleaved reporters after 60 min reaction varies significantly from ~100% at target concentrations greater than ~100 pM to less than 1% for target concentrations lower than ~200 fM. Lastly, we note that the cleaved reporter fraction shown in Figure 3 can be interpreted as an estimate measure of the signal-to-noise ratio of assays that rely on end-point fluorescence readout for target detection (e.g. assuming a sensitive detector with a low noise). The reason for this is that uncleaved reporters very likely represent a substantial degree of background signal (e.g. due to imperfect quenching, probe degradation, and/or unwanted free dye). Figure 2 ). Contour levels of 0 and 1 represents no reporter cleavage and complete reporter cleavage, respectively.Here, we present the variation of reaction time scale J for varying amounts of target nucleic acid based on Michaelis-Menten kinetics analysis (Section 2.1). Figure 4 shows contours of J (in seconds) as a function of the Cas enzyme catalytic efficiency (0 %&' /? ) ) and the target concentration ! ( . Note the inversely proportional relationship for the time scale between catalytic efficiency and target abundance: J = (0 %&' /? ) ) 12 ! ( 12 . High catalytic efficiency and large target concentrations lead to shorter reaction times scales (hence faster reaction completion and fast detection). Notably, if the updated kinetics parameters in Table 1 are true, the time scale for transcleavage reactions involving LbCas12a (for which 0 %&' /? ) ~ 10 6 to 10 7 M -1 s -1 ) can vary from ~5 min for target concentrations greater an 1 nM to ~1 day for target concentrations less than ~1 pM. Note that, by definition, the reaction time scale J denotes the time at which about ~63% of the reporters are cleaved. We presented a model for the trans-cleavage of CRISPR-associated enzyme kinetics based on Michaelis-Menten kinetics theory. The model is used to develop simple, back-of-the-envelope rules to check for consistency in experimentally derived and reported kinetic rate parameters. We applied these rules to data reported in published studies which characterize CRISPR-enzyme transcleavage rates. We found that all except one of the published studies which present Michaelis-Menten kinetics data violated these basic validation criteria. The single study which passed our three validation rules reported a kcat value which is a dramatic outlier relative to all other published values of kcat. We further used our model to develop simple scaling laws relating the kinetic parameters to reaction time scales and the degree of reaction completion. We applied this theory, using updated kinetic rates for LbCas12a, to make predictions of enzyme kinetics across practically relevant ranges of target concentrations for CRISPR-detection. Table 1 . Summary of published enzyme kinetics parameters and our back-of-the-envelope checks for CRISPR-Cas12 and CRISPR-Cas13. Shaded boxes indicate violation of our back-of-the-envelope criteria for consistent kinetics data (Section 2.2). All but one study fail two or more validation rules. ",USA,first author,2021-02-05,02
53af555b4e6eaf49e4482f053eb62a57a7b204bc,Revealing Critical Characteristics of Mobility Patterns in New York City during the Onset of COVID-19 Pandemic,"With more than 90 million confirmed cases and 1.9 million deaths worldwide at the time of this writing, the COVID-19 global pandemic has caused unprecedented social, economic, and environmental impacts Dashboard, 2021; Bashir et al., 2020) . New York City, which became a major hotspot in the United States during the early stages of the pandemic, had more than 500,000 confirmed cases as of January 15, 2021. New York City observed its first peak during the first week of April. Public policy and implementation of control measures are essential to support social distancing, which might help slow the spread of COVID-19 (Lasry et al., 2020; Kraemer et al., 2020) . Huang et al. (2020a) have shown that mobility changes correspond well with the declaration of mitigation measures, implying effectiveness. Additionally, a study done in the U.K. analyzed the impact of government control measures on human mobility reduction and identified a relationship between human mobility trends and COVID-19 cases (Hadjidemetriou et al., 2020) . They found out that reduction in mobility led to lower COVID-19 related casualties.This study assesses the impact of the COVID-19 pandemic and government policies on human mobility for four major boroughs of New York City. The city was an early epicenter of the COVID-19 pandemic in the United States (Thompson et al., 2020) . New York City is also one of the most densely populated cities in the United States, has a well-established intracity public rail, and diversity in transport options. Studies have shown that human mobility correlates directly with the number of positive cases with some time lag (Glaeser et al., 2020; Carteni et al., 2020; Badr et al., 2020; Xiong et al., 2020) and disease reproduction number (Linka et al., 2020) . Iacus et al. (2020) found that mobility alone can explain more than 90% of the initial spread of the COVID-19 virus. Furthermore, Gatto et al. (2020) have found that policies restricting population movement in Italy and resulting lessened mobility reduce virus transmission by 45%. Yabe et al. (2020) found that even non-compulsory measures in Tokyo resulted in a 50% drop in mobility and led to 70% fewer social contacts. Therefore, understanding the effectiveness of government policies on reducing human mobility will help shape these policies and better control any future outbreaks. Almagro et al. (2020) found that crowded spaces play a more critical role than population density in spreading the infection. Gao et al. (2020) used Venables distance as a means to understand the agglomeration of human activities at the county level for 194 US counties. Li et al. (2020) classified points of interest (POIs) as hotspots or non-hotspots and assessed the mobility patterns among them for US cities. They found that while visits to hotspots decreased in some cities, some did not show a considerable drop; however, these studies did not focus on a granular level. Our study was focused on finding these measures at the borough level for New York City to understand whether boroughs show any disparity in movement patterns. We aggregated the POIs at the borough level for New York City to assess the inter-borough and intra-borough hotspot and nonhotspot mobility trends. This knowledge may enable policymakers to better manage the control measures for different boroughs.Researchers have also analyzed the effect of mobility on greenhouse gas emissions by the aviation and transport sectors (Abu-Rayesh and Dincer, 2020). For instance, Jiang et al. (2020) identified the impact of human behavior and mobility on Singapore's environment. They also reported a 30% reduction in mobility leads to about 44% to55% reduction in air emissions related to transportation. Zhou et al. (2020) used mobile phone data to build an exposure model for Shenzhen, China, and found that the reduction in mobility helped flatten the peak number of cases and lead to a delayed peak.Studies have looked at mobility data from different sources for the same dataset but not different types of datasets (Huang et al., 2020b, Iacus et al., Yabe et al.) . To the best of our knowledge, our research is a first of a kind that incorporates various datasets, such as population density, aggregated population mobility, intracity rail use, vehicle use, hotspot and non-hotspot movement patterns, and human activity agglomeration. The novelty of our research lies not only in performing the analysis at a finer scale but also in considering multiple datasets to reduce the uncertainties and gain multi-dimensional insights. The goal is to understand how a pandemic impacts mobility in different sectors, such as transportation-intracity rail and vehicular traffic. Looking across six different datasets, we endeavor to answer the following research questions: 1) How COVID-19 and government policies to counteract the spread of the virus influence human mobility within and across New York City boroughs? 2) How changes in overall mobility are explained by mobility through different means? 3) Does reduced mobility lead to reduced highrisk movements? The first research question gives us insights on how mobility is affected by COVID-19 awareness, state policies, and news ( Figure 1 ) and whether these policies have a significant impact on mobility. Focusing on different datasets gives a holistic perspective on human mobility. The second research question identifies if people switch from high-risk transportation means (New York City subway) to low risk (vehicle) or show similar mobility reduction. The third research question gives insights as to whether reduced mobility causes reduced movements to and from hotspots, as movements linked to hotspots exhibit high risks of spreading the infection. Even a small minority of super-spreader POIs can account for a large number of infections (Chang et al., 2020) . For our study, we obtained mobility data from five sources: Facebook, the Metropolitan Transportation Authority database, New York State open data portal (data.ny.gov), and from studies by Li et al. (2020) and Gao et al. (2020) .From Facebook, we acquired the Facebook Population and Movement datasets for March and April 2020. Facebook anonymizes data by adding a small random noise, implementing spatial smoothing, and dropping small counts. For these datasets, the metrics were aggregated over each tile and linked to the center of a tile or a polygon (or a combination of both). The density dataset consisted of population density, user count (number of users with the location on), among other measures for each data point. The mobility dataset consisted of start and end coordinates and the corresponding movement associated with the start-end coordinate pair. These datasets were available at a frequency of 8 hours but were aggregated over days for the movement dataset and at a weekly resolution for the density dataset. Baseline and crisis values are available for both population and movement datasets. Facebook computed the baseline values in the dataset for each data point using 5 to 13 weeks of pre-crisis data. Baseline values were calculated using data from the previous weeks of the pre-crisis period (Maas et al., 2019) . We used crisis and baseline values of population density for our study. Similarly, we used crisis and baseline values for movement from the movement dataset from the start-end coordinate pairs.We obtained MTA turnstile data from New York State open data portal for January through April 2020. The turnstile dataset consisted of the cumulative entry and exit counts for each turnstile for all subway stations in New York City at an hourly interval. To obtain the hourly entry and exit count, first the difference was computed for entry and exit time series. We then aggregated the entry and exits for these turnstiles at 1-day intervals. Tunnels and bridges toll data from MTA contained the number of transiting vehicles (cars, buses, trucks and motorcycles).Mobility data for 16 US cities (including New York City) across points of interest classified as hotspots and non-hotspots were acquired from the study by Li et al. They used SafeGraph data to map the origin-destination network and identified the hotspots and non-hotspots on the mapped network. Here, hotspots represent high-risk zones, and non-hotspots represent the low-risk zones in terms of infection risk . Hotspot and non-hotspot movement data for New York City were taken from this study and aggregated at the borough level for our analysis.To consider the agglomeration of human activities, we used data Venables distance data for the study by Gao et al. (2020) . They calculated Venables distance for 193 counties in the United States by using digital trace data from Mapbox. Venables distance aggregates the spatial distribution of human activities of different tiles in a county. For more information on the calculation of Venables Distance in this dataset, please refer to Gao et al. (2020) . In our study, we performed the analysis at the borough level for New York City. Table 1 gives an overview of the datasets used in this paper and unique insights offered by each of these datasets. This section describes methods used to analyze datasets for aspects of human mobility and to compute baseline values for Facebook Movement and subway turnstile dataset. Figure 2 illustrates the steps followed for the analysis in this paper with further explanation below. Figure 2 . The process followed for analyzing human mobility using six datasetsDatasets, other than those acquired from Facebook, did not have baseline values from previous data. To assess the change in mobility, for Facebook Movement and Metro Turnstile datasets, the baseline values were computed by taking the average value of the data from months January and February was a combined average for both months. We used a two-month combined average instead of a day-wise average over the weeks for two reasons: 1) We did not have sufficient precrisis data; 2) We adopted a seven-day rolling mean approach to assess mobility for various datasets to remove the variations in mobility on weekdays and weekends, so a precise averaging was not necessary.To assess the pandemic-related variation in population density for March and April, we first extracted the population density data for four main boroughs of New York City: Brooklyn, Manhattan, Queens, and Bronx. Then, we computed weekly averages of baseline and crisis values for population density from March 1through through April 30. After aggregating the data weekly for each grid point, we estimated the percentage change in population density with respect to the baseline values. We then mapped the density change for New York City for different weeks.We analyzed inter-borough and intra-borough population movement using the Facebook Movement dataset, which represents users' general mobility patterns based on the location data of mobile phones. We spatially aggregated the baseline and crisis values from Facebook Movement data at the borough level. Each start or end coordinate was assigned to a borough if it was within that borough boundary. The resampled data, therefore, instead of capturing start-end coordinate movements, captured inter-borough and intra-borough movements. Borough-to-borough movements lacking enough data points to produce statistically significant results were discarded. Then movement change time series (7-day moving average) for inter-borough and intra-borough movement for March and April were plotted.A similar approach was adopted for the turnstile data. Analyzing subway turnstile data gives insights into how mobility in the subway compares to that observed from the Facebook Movement dataset, which corresponds to general mobility trends. MTA does not directly provide turnstile location (coordinates). We first obtained a dataset containing the coordinates of subway stations from MTA. Then we merged these with the primary dataset consisting of turnstile data for each station using station names as the common joining parameter (station names). Since these datasets were not produced in the same year, the station names had minor changes (updated name, shortform, long-form, etc.).We linked these stations manually to a coordinate. After geocoding these stations, the entry and exit data were aggregated over boroughs, applying the same approach as for the Facebook Movement dataset. The exit numbers were slightly less than the entry number for each station because people tend to use emergency exit to exit the station to save time. We therefore considered both entry and exit numbers separately for this analysis.Restrictions on public gatherings may have a different impact on travel via personal vehicles, as they conform to the social-distancing measures and are safer from the standpoint of contact than public transport. To assess road traffic, we considered tunnel and bridge toll data as a proxy to measure the inter-borough road traffic. Since these bridges or tunnels did not connect places within a borough, we could not use this dataset to compute intra-borough vehicle statistics. All of the tunnels and bridges in New York City link different boroughs, so we grouped the toll dataset on the basis of the direction of flow and the linked boroughs. For example, incoming traffic to Brooklyn and outgoing traffic from Brooklyn were grouped separately. This gives an idea about the net inflow or outflow of traffic from a particular borough. The dataset contained the count for vehicles that pay using E-Z pass or cash (includes payment by mail). Because of the pandemic, however, some toll gates did not accept cash, and the exact date of this transition was not available publicly, so this study analyzed only total traffic flow and not the payment methods (contactless or cash). Baseline traffic values were computed for each toll plaza considering total vehicle traffic. The percent change in traffic was calculated using the baseline values for March and April. Time series plots (7-day moving average) for inbound and outbound traffic for four main boroughs were plotted for further analysis.Knowing movements linked to high-risk zones (hotspots) is crucial as they might contribute to the faster spreading of the infection (Almagro et al., 2020) . Li et al. (2020) mapped the Origin-Destination (O.D.) networks from SafeGraph data as directed and weighted bipartite networks. They classified POIs based on a threshold in-flux and out-flux values obtained from the O.D. biadjacency matrix. For our study, these POI (hotspots and non-hotspots) datasets from the study by Li et al. (2020) were reclassified into different boroughs then the movements between POIs were spatially aggregated borough-wise to obtain the inter-and intra-borough movement. For each borough movement case (16 cases,inter-and intra-borough movement), we obtained movement patterns for the hotspot to hotspot (H.H.), hotspot to non-hotspot (H.N.), non-hotspot to hotspot (N.H.), and non-hotspot to non-hotspot (N.N.) movements for March and April. This classification would give additional insights into the composition of overall movement patterns into high-risk and low-risk movements, where high-risk movements correspond to those linked with hotspots and low-risk to non-hotspot.While higher population density and movement activity may correspond to a higher risk of infection, studying the agglomeration of human activities is also important. Higher agglomeration would imply that the average distance between people is less and could lead to a higher risk of disease spread. This measure takes into consideration the areas (ZIP code or census tract) where population density might be lower, yet still show higher agglomeration. Therefore, such areas might have a higher risk of infection spread than would be expected from assessing only population density. We obtained more-granular level data from the study by Gao et al. 2020 for New York City at the borough level to observe the activity density for Manhattan, Queens, Brooklyn, and Bronx.Venables distance is calculated by the following equation:where ak(t) represents the metrics of human activities at tile k at time t, dij represents the center-tocenter distance between tiles i and j. The numerator represents the weighted distance of these activities, and, by dividing by the denominator, the value is normalized, and we obtain the weighted average, or Venables distance (Louail et al., 2014) .We observed the changes in population density for the four boroughs in New York City by analyzing the weekly aggregated density data from Facebook. Figure 3 shows the results for the density change (in percentage) for four boroughs of New York City-Manhattan, Brooklyn, Bronx and Queens-for March and April. We observe that in the first week of March (Figure 3 (a) ) the variations in density changes are within five percent. In the second week of March (Figure 3 (b) ) we begin to see a slight reduction in density in Manhattan. From the 3rd week of March (Figure 3 (c) and (d)), the changes are more apparent, and it is observed that there is a significant decrease in population density in Manhattan and other boroughs show an increase in population density. For some places in Manhattan, the reduction is more than 75%. Since Manhattan is a hub for offices and commercial spaces, results suggest that after a national emergency was declared on March 13 and office strength was reduced by 50% on March 18, people started working from home. The area of Queens showing a decrease in population density can be attributed to the location of John F. Kennedy International Airport. The airport has nearly equal passengers for both domestic and international travel (New York City data portal, 2015 data). Due to travel restrictions put on by many countries after the third week of March, people traveled less globally and also domestically, leading to lower footfall in the airport region.It is observed that in the third week of March, the reduction in population density is the highest in comparison to previous weeks; the reduced population density in the last week of March remains similar for the month of April. The majority of the change happened in the third week of March, which coincides the announcement of a state of emergency and stay-at home orders. Moreover, the changed density state remains the same for the entire month of April (figures are available in the Appendix), which could imply that the populace effectively followed the guidelines throughout, and a steady state was achieved. Figure 3 . Percent population density change (with respect to baseline values) timeline for four boroughs of New York City. (a), (b), (c), and (d) represent the population density for the first, second, third, and fourth week of March, respectively. Red represents higher population density; blue represents lower population density compared to baselineThe above results indicate a reduction in population density for Manhattan, which may reduce the risk for infection spread. For other boroughs, which show an increase in population density, it is not clear whether this increases the risk. We analyzed the mobility patterns and measured the interand intra-borough movement through Facebook Movement and subway turnstile data to address this question. Figure 4 shows the inter-and intra-borough movement patterns for four boroughs for New York City for general mobility using Facebook Movement data. Figure 5 shows subway ridership for each of the boroughs' stations. Figures 4 and 5 show that the reduction in mobility happens in the third and fourth week of March. Figure 4 suggests that for the aggregated movement patterns to and from Manhattan saw a significant drop. Also, movements from Manhattan to other boroughs reduced by 60% to 80%, the largest percentage among the four boroughs. For inter-or intra-borough movements that are not Manhattan linked, the reduction was between 50% to 60%. From Figure 5 , analyzing the percent change in entry counts at stations in each of the boroughs, it is evident that subway ridership dropped by more than 80% for the four boroughs. Similar to observations from Figure 4 , Manhattan showed the highest drop in subway entry count (90% reduction). The use of the subway remains reduced for the month of April. This suggests that people, in general, were following the recommendations of social distancing, working from home, and avoiding the use of public transport. Movements within Bronx, Brooklyn, and Queens were slightly higher than their inter-Percent Change Percent Change borough movements in general, which may indicate commute for purchase of essential goods. In contrast, for Manhattan, the intra-borough movement was the lowest (compared to movement from Manhattan to other boroughs), which could be due to reduction in the population density in Manhattan; therefore, the local commute by people who come from other boroughs is comparatively less, though people working with essential services may commute to Manhattan and back from other boroughs. Figure 4 : Seven-day rolling mean aggregated movement among four boroughs of New York City. Some borough-to-borough movement plots are not shown due to insufficient data. (a), (b), (c) and (d) show the movement from Manhattan, Queens, Brooklyn, and Bronx, respectively, to other boroughs Results from the Facebook Movement data and Metro turnstile data indicate that while subway usage dropped by more than 80% for all the major boroughs, the overall movement within and across different boroughs showed a drop between 50% to 80%. For movements not liked with Manhattan, this reduction was only about 60%. This suggests that other means of travel might results in a lesser reduction in the overall movement than observed from the Facebook Movement data. One aspect that we have not considered yet is people traveling via road. People may resort to traveling by personal vehicles for essential shopping or for jobs exempt from having reduced workforce capacity. Analyzing mobility through roads may give additional insights into the observed difference. The above results give insights into the total movement patterns and mobility through the subway system. But people involved with essential facilities may commute through roads for work, or people may travel to shop for essentials. We analyzed the tunnels and bridge toll data to observe if decreased ridership in the subway leads to an increased flow of vehicles. Figure 6 shows traffic through the tunnels and bridges connecting the boroughs. We used tunnels and bridges toll data as a proxy to study road movement. The results indicate that incoming traffic to Manhattan from the boroughs showed a drop of 70%. Incoming traffic to Queens and Bronx boroughs was reduced by about 60%. Outbound traffic to boroughs other than Manhattan shows a drop of 50% to 70%. These results show that the traffic towards Manhattan shows the highest decrease, and in general, we see about 60% less movement through roads to other boroughs.We observe similar mobility reduction patterns in road movement as observed before for different boroughs, but the magnitude of reduction is not as much as that observed with Metro ridership. This could be because commute by car is a safer means of transportation vis-à-vis possible contagious diseases as compared to public modes of transportation. Moreover, people employed in the operation of critical facilities or emergency response would still need to commute. Additionally, this dataset accounts only for the number of vehicles that pass through a toll plaza, and there is no information about the number of passengers per vehicle. If people shared rides before the pandemic, they may not do so anymore, which could implicate slightly higher than the observed movement of cars per passenger.Change (a) (b) Figure 6 : Seven-day moving average of (a) incoming traffic for Manhattan, Queens, and Bronx; and (b) To further understand the perturbed state where we have reduced mobility, we investigated the Venables distance for these boroughs to get insights into how clustered the activities are with respect to distance. Figure 8 shows the Venables Distance for four boroughs of New York City. The results suggest that the clustering of human activities increased significantly only for Manhattan in the first two weeks of March. Other boroughs showed small increment till the end of March then had a gradual decline. This indicates that Manhattan showed the most clustering of activities in comparison to other boroughs, but it was still a twenty percent increase. Combining insights from hotspot linked movement to Manhattan, results suggest that even though the distance between people is increasing, it may not reduce the risk substantially as hotspot linked movements dominate. Other boroughs like Queens, Bronx, and Brooklyn show only a marginal increase in the Venables distance.These results indicate that the average distance between people did not change significantly for boroughs other than Manhattan. When people started working from home, they did not commute to their offices in Manhattan; hence, the Venables distance increased by roughly twenty percent only for Manhattan. For other boroughs, it is unclear why Venables distance only increases marginally. It may be because of the balancing effect of increased population density and a reduced number of trips within a borough. This study shows how human mobility was affected by the pandemic and how the influence exerted by the first COVID-19 positive case, government policies, and major news had on them. The estimates of aggregate flows of people can help officials understand which policies are most effective (Buckee et al., 2020) . The news of the first case of the COVID-19 in New York City and the declaration of the state of emergency did not have much impact on mobility. We see a steep decrease in mobility only when the curfew is imposed on restaurants and bars by the Governor of New York followed school closures in an attempt to stop the spread of the virus. We see that in March, inter-and intra-borough movement of population declines, and towards the end of March, it reduces to a 60%-90% lower value that continues until the end of April. The highest drop in mobility is observed for Manhattan since it is a business hub and has a smaller number of residential complexes. This trend of decrease in mobility is consistent across different datasets, but we observe slight variations in the magnitude. This variation could be because data from Facebook relies on users who keep their location services enabled. While it may give valuable insights into the movement trends, we can expect some variations as they do not represent all the people. Moreover, the dataset captures general mobility trends and does not specify whether this movement is associated with traveling via road, subway, bicycle, or walking.Subway turnstile data results indicate that the reduction in subway ridership is 10% more for Manhattan and 20% to30% more for other boroughs. Overall, the reduction in subway ridership is more than 80% for all the boroughs, indicating the effectiveness of government control measures. Vehicular mobility shows similar patterns to that of general mobility patterns, but for boroughs other than Manhattan, the reduction is slightly more. Venables distance shows high variation only for Manhattan because it is dominated by office space and has a relatively small percentage of residential population. When the workforce started to work from home, only these areas showed clustered activities. Higher-density areas in Manhattan may be associated with residential areas. Moreover, people did not commute to work to Manhattan, which contributed to an increased average distance among people. Although we see an increase in population density for boroughs Venables Distance like Queens, Brooklyn, and Bronx, the mobility remains between 60% and 90%: low for both interand intra-borough movement. This suggests that people were commuting less frequently and strictly following the stay-at-home orders. This is substantiated by a reduction in subway ridership did not increase vehicle traffic, which showed a similar reduction in movement. But the risk of infection in Manhattan is not reduced significantly, as hotspot-linked movements still dominate even after a significant drop in overall mobility.The authors would like to acknowledge funding supports from the National Science Foundation RAPID project #2026814: ""Urban Resilience to Health Emergencies: Revealing Latent Epidemic Spread Risks from Population Activity Fluctuations and Collective Sense-making. The authors would also like to acknowledge that Safegraph, Mapbox, and Facebook provided datasets under their Data for Good initiatives. Any opinions, findings, and conclusions, or recommendations expressed in this research are those of the authors and do not necessarily reflect the view of the funding agency and the data providers.",USA,first author,2021-02-03,02
d10597162fdeb2142771816617583450c9668b42,Bipartisan politics and poverty as a risk factor for contagion and mortality from SARS-CoV-2 virus in the United States of America,"Moral economics criticizes the contemporary economic model's current position, which establishes the predominance of capital over human well-being and the criteria for classifying ideological institutions considering some inferior human beings due to their race, skin color, or religion (Bolton & Laaser, 2013) .These inequalities reflect vulnerable communities characterized by their housing conditions, transportation, language barriers, population density, health conditions, and medical care access (Smittenaar, 2020) . Unfortunately, this population is more vulnerable to increased exposure to SARS-CoV-2 contagion and specific health considerations such as obesity, diabetes, and hypertension .From the beginning of the first infections until December 31, 2020, 341,199 people died in the United States, with more than 19,663,976 infected; this disease has a tremendous impact on medical care and the economy. The National Institute of Allergies and Infectious Diseases established guidelines that suggested the use of facial protection, social distancing, early diagnosis, and the respective follow-up of those infected as a strategy to contain transmission (Gremmels et al., 2020) .However, with great notoriety in the United States, the execution of public health policies to face the pandemic has been limited to ideological confrontations of the American bipartisanship, with deep inequalities that threaten the sense of justice, equity, and morality (Hadjisolomou & Simone, 2020) .Therefore, based on the problem raised above, we pose the following research question: Is poverty a risk factor attributed to the high infection rates and mortality from the SARS-CoV-2 virus? Next, we will describe the study variables.This study's variables are made up of constructs and indicators, described below according to the order they were considered in the conceptual model. Rolfe et al., 2020; Harrison et al., 2020; Smittenaar, 2020) C19-D COVID-19 Disease SARS-CoV-2 is the severe acute respiratory syndrome caused by the (coronavirus 2) pathogen. (Yao et al., 2020; • • Contagions registered by ) measures the number of infections due to SARS-CoV-2 or severe acute respiratory syndrome.• Death registered by ) measures the number of deaths from SARS-CoV-2 or severe acute respiratory syndrome.Liberal economic theorists have faced the challenges of economic nationalists and trade protectionism that arise from the idea that economic activities should be subordinate to the nation's economic objectives (Helleiner, 2002) . In recent years, with globalization, economic nationalism has changed so as not to disappear in the face of liberalism, reinforcing the motto of classic protectionism and liberal economic nationalism (Clift & Woll, 2012) .With the adoption of free trade, the development of new nationalist economic projects in America and Europe linked to political populism (Scheuerman, 2019) has led nations to move away from liberal economic policies through initiatives that promote different socioeconomic restrictions within the free trade, reinforcing the strategy of national autonomy through economic disintegration and deglobalization (Born et al., 2019) . Poverty is defined as the lack of sufficient income to satisfy basic needs; in the United States, a person is poor when their income falls below a certain threshold of money, which is determined by the Census Bureau of the United States (Census, 2020) .However, there is scientific evidence from studies that support the positive association between low income, low socioeconomic status, and low educational level with health conditions related to tobacco use, obesity, hypertension, cancer, and diabetes (Niessen et al., 2018) .The framework of the ""moral economy"" allows us to reflect on comprehensive organizational management policies and decisions where economic primacy is over human well-being, especially during economic crises such as COVID-19 produced by the severe acute respiratory syndrome or SARS-CoV-2 (Hadjisolomou & Simone, 2020) . Current political agendas have generated insecurity for many marginalized minorities, which are part of a precarious labor system (Standing, 2016) ; the term ""precarious"" is known as a generalized state of insecurity that has tangible effects on the health of the individual (Harrison et al., 2020) .SARS-CoV-2 is a severe acute respiratory syndrome caused by the pathogen (coronavirus 2) (Yao et al., 2020) . This virus has a higher fatality rate among elderly patients and patients with comorbidities . Within the symptoms, infected patients suffer from fever, dyspnoea, dry cough, pneumonia and fatigue accompanied by various non-respiratory clinical characteristics, such as gastrointestinal symptoms and eye inflammation (Hong et al., 2020) .According to studies carried out before the pandemic, socially and economically disadvantaged people are groups of greater vulnerability for developing health conditions (Cookson et al., 2016) . Unfortunately, public policies have shown utter disregard for vulnerable groups, exposing thousands of human beings to mortality for decades (Marmot, 2005) .Unemployment is one of the biggest challenges in the COVID-19 pandemic, as the time of unemployment lengthens certain factors such as declining savings, and the limitations generated by unemployment insurance benefits wreak serious havoc in society (Chodorow-Reich, 2020).Concerning COVID-19, among the risk factors identified in these disadvantaged groups is overcrowding in populated homes, which reduces compliance with social distancing standards, being employed in occupations that do not provide stable income or opportunities to work from home (Stewart, 2020) .Certain factors are critical in identifying the social determinants of health inequity, such as racism (Johnson, 2020) , low-income households (Rolfe et al., 2020) and problems acquiring health plans (Weida et al., 2020) . Therefore, the use of the COVID-19Community Vulnerability Index (CCVI) will evaluate whether a community could respond to the health, economic and social consequences of COVID-19.These socioeconomic indicators measure vulnerabilities related to housing conditions, transportation, language barriers, population density, health conditions, and the population's access to medical care (Stewart, 2020) . The scientific evidence establishes that social disadvantage and vulnerability can influence the incidence of a health emergency similar to that of COVID-19 (Melvin et al., 2020) . Consequently, poverty can not only increase exposure to the virus but also reduce the ability of the immune system to fight it, since people with low income are a negative determinant for access to medical care, this group being the highest risk mortality from COVID-19 . The discussion of the literature presented above allows us to propose the hypothesis of this research:H1: Poverty as a determining social factor drives infection and death from the SARS-CoV-2 virus disease.This research is quantitative -correlational, and it seeks to describe the relationship of the study variables at a given time (Sampieri & Lucio, 2013) using multivariate analysis statistics, clusters, and structural equations with partial least squares (Ajamieh, 2016) through the implementation of a state political control matrix to determine the impact relationships of social determinants in the COVID-19 disease.The methodology was framed in the correlational-causal design because only the level of correlation between the variables was measured to identify possible causalities in the phenomenon that will later be studied (Orengo, 2008) ; The data used consisted of 408 observations structured in panel data obtained in the public repositories of the United States government that described below:• The U.S. Census Bureau• Centers for Disease Control and Prevention, andThe data panel allowed to identify systematic and unobserved differences between the units correlated with factors whose effects should be measured (Wooldridge, 2009) . Also, they allowed the results to be generalized since this study seeks to obtain from this population the data previously organized in tables methodologically designed for such purposes (Census, 2020) .In the United States, there are two political parties, the Democrats and the Republicans (Rodden, 2010) . However, as part of the study model, we identify and classify political parties that control state governments and decide public health (Ahler & Broockman, 2015 In this study, 408 observations were analysed, organized into panel data; the process and tools are detailed below:• The first analysis phase: reflective PLS model (Smart PLS 3.0)• The second analysis phase: clustering and correlation analysis (Orange 3.0 learning machine platform)For this first phase, a non-parametric reflective model of partial least squares PLS andBootstrapping is used since it is reliable and less sensitive to outliers. The model consists of two constructs, and fifty indicators previously explained. Therefore, each construct explains at least 50% of the variance of the indicators.When evaluating the collinearity level, the test (VIF) did not find problems related to collinearity since its values fluctuated at a p-value = 1.00. In the discriminant validity test or the Forner-Larcker Criterion, results in less than 0.7 confirm the existence of validity. The model's predictive quality was performed using the Stone-Geisser redundancy test of cross-validation of the construct or Q2, which assesses the structural and theoretical model; with the results obtained with a value greater than zero 0, the conclusion is drawn existence of predictive validity and relevance of the model (Thaisaiyi, 2020). The analysis of the PLS algorithm's magnitude and significance allows us to measure and test the research model's respective hypothesis relationships. The magnitude is observed in the standardized regression coefficient (β) and its significance ( We will use the K-Means method to meet our grouping criteria (the axiom of nonnegativity, identity, symmetry, and triangular inequality) of the data obtained in the two political groups and the silhouette analysis with the Manhattan metric to define the proximity of the study elements and identify the optimal value of k during the clustering process. The correlational modeling between social determinants and covid-19 disease also generated a new data set using the clustering index as a class attribute, which will allow the identification of patterns and the detection of clusters (Leong & Yue, 2017) .It will also allow us to observe its constancy in time and meaning (Sabogal, 2013) . The data are composed of three groups C1 Republicans, C2 Democrats, C3 California, NewYork, Texas, and Florida. • Low positive correlations found in all Republican States belonging to group C1 between people without health insurance and the number of COVID-19infections registered with (r = .26) and concerning with the number of deaths registered by COVID-19 (r = -.08).• High positive correlations found in all Democratic States belonging to group C2 between the number of people living below the poverty level and the number of registered COVID-19 infections with (r = .88) and concerning with the number of deaths registered by COVID-19 (r = .70).• Moderate positive correlations found in all Democratic States belonging to group C2 between the Covid-19 community vulnerability factor index and the number of COVID-19 infections registered with (r = .59) and concerning with the number of deaths registered by COVID-19 (r = .39).• High positive correlations found in all Democratic States belonging to group C2 between the number of inhabitants and the number of COVID-19 infections registered with (r = .89) and concerning with the number of deaths registered by COVID-19 (r = .74).• Low positive correlations found in all Democratic States belonging to group C2 between people without health insurance and the number of COVID-19infections registered with (r = .21) and concerning with the number of deaths registered by COVID-19 (r = .07). There is emerging evidence that establishes that risk conditions linked to Poverty such as obesity, cardiovascular diseases, diabetes, and hypertension are risk factors for death from COVID-19; consequently, people with low socioeconomic status are more susceptible to mortality from infection . Table 9 . U.S. Party-control regional correlation analysis Community Vulnerability Factors Index (CCIV), which explains the argument that Poverty and lack of economic security puts a public or private health system at risk and calamity (Weida et al., 2020) .In the last two presidential elections, the online strategies carried out by former presidents Obama and Trump became visible in what has been called social media elections (Shmargad & Sanchez, 2020) . However, although both political parties maintained an active presence on social media in the last elections of 2020, a pattern of misinformation based on denial and conspiracy theories unleashed a lack of clear and reliable public health policies.In the first spectrum, state governors who downplayed the Center for Disease Control and Prevention recommendations saw a disproportionate increase in infections and deaths (CDC, 2019). The evidence shows that the risk factor is the population with a lack of sufficient income to satisfy their basic needs. However, although unemployment grew dramatically, the evidence establishes that the unemployed population was not a risk factor. For this reason, it is necessary to deepen with more exploratory studies that identify and evaluate the causes of the high mortality rates that contrast with the poverty and coverage data of the medical plans of states such as NewYork.On a second spectrum, the government's responsibility to address the factors that leave the most economically disadvantaged vulnerable to the virus, expanding the coverage of government health plans and actively contributing to minimizing social inequalities based on ethnic minority groups. The pandemic highlighted social and economic inequalities within American society and is likely to exacerbate them by considering more contagious variants, as there are high levels of transmission.Consequently, the executive and legislative branches' correct political decisionmaking is relevant in the framework of public health, addressing the vulnerabilities of the economically disadvantaged within American society with new, more inclusive health policies to help millions of American citizens living below the poverty line.",United States,abstract,2021-02-04,02
1d4749af4e8fd49e66479be00f6724cd38c5f669,COVID-19 Heterogeneity in Islands Chain Environment,"Significant local variations in the spread of COVID-19 have been established in heterogeneous environments. For example, omas, et al., compares nineteen different cities and counties in the US [20] . ey found that small differences in network models for interdependence and social interaction as well as the effects due to uneven population distributions can lead to substantial differences in infection timing and severity, leading different areas in each city to have vastly different experiences of the pandemic. Similar pa erns associated with heterogeneity have been made for entire nations, such as the work comparing the most affected cities in China [4] . ese works are based on the premise that substantial heterogeneity in social relationships at various scales affect the viral spread. It is unclear, however, whether or not such heterogeneity is a critical factor for an island chain and such study is absent from the literature. is is of utmost importance due to islands' vulnerability to any pandemic, especially for native populations as demonstrated for example with the introduction of measles to the Pacific Islands in the 1800's [28] . Islands are smaller contained populations, and thus epidemiological models may require adjustments to properly apply them to disease containment strategies. Identifying if major local variations can be expected for an island chain in the spread of COVID-19 is crucial since it directly impacts the effectiveness of mitigation measures, vaccine distribution and health care management. We focus here on a specific island chain, the Hawaiian archipelago and take somewhat different approach by comparing the individual island differences and identifying countries exhibiting similar properties. Maui for instance behave much more similarly to Japan over the last three months than her neighbor Islands which was surprising to see. Our goal is to demonstrate that Islands in general, whether they belong to the same archipelago or not, respond differently to the pandemic and cannot be aggregated into one single class. [6] .e Hawaiian Islands are an archipelago of eight major islands, with only seven of them being populated.e State is divided into five counties: Hawai'i , Honolulu, Kalawao, Kaua'i , and Maui. Since Kalawao is the smallest county in all of the 50 states in terms of both population and land area, we focus here on only the four major countiesure 1 shows the main eight islands as well as the various counties. Table 1 shows that Honolulu city and county is the most populated county of the state, with 69% of the state's population. Hawai'i county has the largest land mass of 63% of the entire state, but comes second in resident population. ird by population is Maui county, which spans the islands of Maui, Moloka'i, Lanai, and Kaho'olawe. Kaua'i county, which spans the islands Kaua'i and Ni'ihau, has the smallest population. In determining heterogeneity effects and how the Hawaiian Islands might differ from each other, it is also important to compare the demographics of the four counties we study.Honolulu Table 1 . e state's general statistics by county [11] . While Honolulu city and county has been dominating the COVID-19 daily cases numbers due to its larger population, the other counties are also facing the pandemic. Intuitively we might expect all counties to exhibit homogeneity with respect of impact of the virus, however this is not observed. We describe in detail commonalities and differences between the four counties. Additionally, we compare them to other non-Hawaiian islands to find similarities and differences. Our work highlights the need for localized measures and possibly targeted mitigation measures at the county level and as opposed to the state level for the most effective pandemic control. is has been already initiated to some degree with Kaua'i county implementing their more restricted travel policy on Dec. 2, 2020; on Jan. 19, 2021, Maui implemented the mandatory safe travel app for all travelers, see Fig. 3 for more details. It is critical for decision makers to take into account heterogeneity in their strategies. An important conclusion of this research is the identification of pa erns that change extremely rapidly. is is due primarily to the nonlinear behaviour of the underlying equations that simulate the spread of the pandemic. In other words, it is not sufficient to average the initial conditions of the virus spread and assume that the different islands will exhibit similar behavior in an average sense. On the contrary, nonlinear effects and clusters can take off in one of the contained populations at a different time, thus requiring different pandemic control mandates. We find that it is critical to assure that heterogeneity is included in modeling and thus decision making for adequate and effective pandemic control.ere are useful collections of Hawai'i COVID-19 data in the form of dashboards: the Hawai'i Emergency Management Agency's (HiEMA) dashboard, the State of Hawai'i 's Department of Health's Disease Outbreak Control Division's (DOCD) COVID-19 dashboard, and COVID Pau dashboard (CPD) [9, 10, 12] . Directly utilizing these dashboards alone is challenging. Firstly, the dashboards are not synchronized; they often display different data at various times for the same quantities, such as hospitalization data. Secondly, the availability of the dashboard data is sometimes restricted because of political concerns. Both HiEMA and DOCD provide visual data in plots, but do not allow for downloading of the data. e Hawai'i Data Collaborative dashboard [8] resolves a majority of these issues by providing a Google Spreadsheet of the local Department of Health's DOCD data. e Hawai'i Data Collaborative also works to coalesce data from the other dashboards, and even obtains data directly from the office of Lt. Governor Josh Green. Collected data and their sources are summarized in Table 2 .We also use the distribution of cases per zip code for each county whose tabulation areas are illustrated in S1 Fig. is In this paper, we also compare the Hawaiian counties to other countries, Table 3 Table 3 . e sources of COVID-19 data used in this paper for the comparison countries.ere are two main classes of epidemiological models for this type of disease spread: compartmental models [1] [2] [3] and agent-based models [13, [16] [17] [18] . In this paper, we use a compartmentalized model inspired by [19] , which is based on a standard discrete SEIR model. An extension, key to this paper, that we added to the model is a new group for travelers. Indeed, the tourist population plays a prominent role in Hawai'i and due to our isolated geographic location we are able to to collect precise information about daily arrivals and departure.In our model, a given population is divided into four compartments: Susceptible (not currently infected), Exposed (infected with no symptoms), Infected (infected with symptoms), and Removed (recovered or deceased). Moreover, we subdivide the entire population into three additional groups: the general community (C), healthcare workers (H) and visitors (V). Visitors, who are only considered after October 15, when the safe travels Hawai'i program began, are further broken down into two categories: returning residents and tourists. While the returning residents are absorbed into the community bucket, the tourists are treated as a separate group. ese groups interact with each other, and each of them consists of the aforementioned compartments. In addition, compartments Exposed and Infected (in each population group) are split into multiple stages by day to be er reflect the progression of the disease. ere are two key dynamics of each population group: the dynamics of Susceptible individuals and the dynamics of the rest of the compartments. e time dependent hazard rate, λ(t), governs the susceptible dynamics as it determines the probability, 1 − e −λ(t) , of an individual becoming exposed at time t. e hazard rate is different for different population groups and takes into account interactions between the groups, thus coupling their dynamics.Key to governing the spread of the disease is parameter β, capturing the basal transmission rate due to various interactions among individuals. Our model optimizes β to fit daily cases for a specific geographic location. Specifically, we use several different values of β that capture changes in COVID-19 mitigation policy. Table 4 displays the variables and parameters common to all simulations in this paper (optimized β's are given in the Results section). We introduce parameters p i as probabilities to develop symptoms on day i, and chose them such that if symptoms do develop, it takes between 2 to 14 days, with a mean between 4 and 6 days [26] , while assuming that about 40% of all infections remain asymptomatic. e values of q s,i reflect the sentiment that symptomatic individuals are likely to quarantine, especially after a couple of days of symptoms. In addition, parameter r is the probability of transitioning from one stage of the illness to the next (with the final stage being recovery or death). Based on prior work [5] , we chose r to yield an expected length of illness of 17 days.In addition, we have parameters related to mitigation measures such as mask compliance as well as contact tracing that depend on the geographical location. Table 5 lists the values we use for the State of Hawai'i (those are assumed to be constant over the various counties) as well as the ones for others countries relevant to the discussion section. e parameters have been identified from dashboards/articles as well as for contact tracing. e choice of q a,i reflects the various testing and contact tracing efforts, and provide the probability for an asymptomatic individual to go into isolation as a result of testing and contact tracing.For more information regarding dynamics equations of the model, see S1 Appendix. . . ,13, asymptomatic quarantine after day i 0 before Jun 08, then q 5 = q 6 = q 7 = 0.05 0 before Feb 25, then q 5 = q 6 = q 7 = 0.05 0 before May 05, then q 5 = q 6 = q 7 = 0.05 0 before Apr 01, then q 5 = q 6 = q 7 = 0.05In this section we provide the results of simulations of our model for the four counties of the State of Hawai'i under analysis. In our plots we use the raw daily cases and not the 7 day average because our model fit plots the sum over all groups of the newly isolated and quarantined daily exposed and infected individuals, see S1 Appendix, Model Dynamics.e initial values of most variables are zero. e only non-zero values are the number of susceptible individuals in the general community and the healthcare worker community, the values of which are listed in Table 6 , as well as a single not quarantined symptomatic individual, I c,0 (0) = 1.S c (0) S h (0) Date for I c,0 (0) = 1  Honolulu 937711 15000  Mar 06  Maui  167417 1500  Mar 15  Hawai'i 201513 1500 Mar 16 Table 6 . Susceptible population for each region and first detected symptomatic individual. All other variables have an initial value of 0. Figure 5 displays the model fit for the Honolulu county. e dots represents the daily cases and the curve is the model fit. e vertical lines corresponds to mitigation measures that had an impact on the curve and for which we optimized the β. Table 7 explicit the different β's. e maximal daily case for Honolulu county was 342 and happened on August 12, 2020. We see two major exponential growths, one early in March that was crushed through a stay-at-home order and one in August followed by a second stay-at-home order. However the second lockdown was lifted before daily cases reached single digits in the hope to save the local economy. It can be seen on Table 7 that the first lockdown was more efficient. e largest peak is a ributed to the July 4 festivities, the transmission rate β was however quite smaller than for the first peak, but the State was much slower to call for a second stay-at-home order which resulted in the significantly higher counts. On October 15, 2020 the state of Hawai'i introduced the safe travel program which prompted an influx of tourists and traveling residents, this influx varies with time which explains the waving shape of the fit. For more details on incorporation of travelers in our model see S1 Appendix. Since the Safe travel program the daily cases have been fluctuating quite a lot which makes a fit difficult (some high daily cases came from a correctional facility cluster for instance). e overall trend as of January 15, 2021 is shown to be slightly increasing (the 7-day average can be found in Fig.6 ). Table 7 . Optimized transmission rates to fit Honolulu county data. ey reflect the State and Honolulu non-pharmaceutical mitigation measures. e top of Fig.6 shows the total number of tests, the test positivity rate (i.e. the percent of tests for COVID-19 that came back positive) as well as the daily cases for the Honolulu County. To create this overlayed plot, the shown metrics have been normalized by calculating each data point as a percent of the maximum of the corresponding metric over the whole observation period and using the 7-day rolling average. It can be seen that, as anticipated, test positivity correlates strongly with daily cases. e noticeably large initial values of the test positivity rate (also present for other counties) are likely caused by the a small number of test that have been administered to a very narrow slice of the population with much higher chances of having the virus. When interpreting these plots, it should also be noted that even later in the pandemic the sample of people receiving tests was not unbiased, since the State of Hawai'i has been administering tests to people who satisfy criteria which make them more likely to have the virus. e bo om plot of Fig.6 displays the mobility for Honolulu County, it shows the major dip in mobility triggered by the first stay-at-home order back in March 2020, coming back up in May to peak again in August before the second stay-at-home order. e mobility data clearly suggests why the second lockdown was not as efficient as the first one. In addition to the daily cases, we represents in Fig.7 the cumulative daily counts for Honolulu county distributed per zip code from the onset of daily cases to January 18, 2021. It can be observed that Honolulu downtown as well as the West Coast (Waianae) have been the most affected in terms of daily cases. For the West Coast it is mostly due to its high pacific islanders population and the fact that they have been disproportionately impacted. While they form about 4% of the total Hawai'i population they account for more than 27% of total cases [15] . Daily cases for Hawai'i county were very small until the aftermath of the July 4 celebrations which generated a large spike. e second stay-at-home order on Maui was extremely efficient but immediately followed by an exponential increase in the form of a few clusters. e maximum value is 51 and happened on October 25, 2020 during the third peak with a very close value during the second peak of 39 on August 29, 2020. One can observe a somewhat puzzling decrease in the number of daily cases after the start of the safe travel program. A potential explanation is that the spike in the number of cases that happened at that time was an isolated event unrelated to other activities on the island. Table 9 . Optimized transmission rates to fit Hawai'i county data. ey reflect the State and Hawai'i non-pharmaceutical mitigation measures. e mobility for Hawai'i county did not show a decline as steep as for Honolulu county, and it shows good correlation with the daily cases and testing data. inhabitants  96720  48339  594  12  96740  42069  615  15  96749  17308  122  7  96778  14885  100  7  Table 10 . e four zip codes with the largest cumulative distribution of daily cases. Maui county started the pandemic with a relatively low number of daily cases, but then entered an alarming state of a high number of cases per hundred thousand of population even reaching a a maximum of 56 cases on January 6, 2021. It can be seen clearly the trigger with the introduction of the safe travel program on October 15, 2020. e influx of travelers is not constant through time and because the ratio tourists versus residents is high on Maui we see as a result the wavy increasing curve. In addition to the effect of additional tourists there was a large outbreak in relatively high population density condominium complex. e initial increase after October 15 was solely due to travelers which is why we see a rise in daily cases even though the basal transmission rate β stays small. Table 11 . Optimized transmission rates to fit Maui county data. ey reflect the State and Maui non-pharmaceutical mitigation measures.Tests, positivity and daily cases are represented on Fig.14 and show a strong correlation between the three. e mobility for Maui County seems correlating well until the introduction of the safe travel program. e four zip codes with the largest counts can be found in 12 and their daily behavior is displayed in Fig.16 . ere was a large outbreak in a multistory in early 2021 located in zip code 96732. e residents in this complex used elevators more than residents in other complexes in other areas with fewer stories.ere are relatively larger number of tourists compared to local residents in zip codes 96761 and 96753 as compared to most other zip code areas. is is possible reason these two zip code area had larger increases in December than other areas. Due to the low numbers on Kaua'i a model fit using our compartmental model could not be achieved. It can be observed on Fig.17 that the daily cases started following an exponential growth, it was a ributed to travelers which prompted the mayor of Kaua'i to request authorization to opt-out from the safe travel program. It was followed by a decrease in numbers and stabilization. A new peak can be observed right after the safe travel program was authorized reinstated by Kaua'i for intercounty travelers. e numbers are so small that is it extremely difficult to draw any additional conclusion. We still represent tests, positivity and daily cases on Fig.18 and see as for Maui a strong correlation between the three. e mobility for Kaua'i County is very flat after the initial decrease in March and even went a bit down after the safe travel program started. Fig 18. Top: e number of daily cases and test positivity rate are still well correlated, even though the raw numbers are small. Similar to Hawai'i county, we can see a jump in the daily case numbers that correlates with the increased number of tests rather than the test positivity rate, which is likely due to the biased nature of the population sample on which the tests are performed. Bo om: Overall mobility for Kaua'i County from March 2020 to January 2021 does not correlate well with the daily cases.ere is clearly major differences among the four counties. Fig.19 shows on the same plot normalized model fits for Honolulu, Hawai'i and Maui counties as well as the daily raw numbers for Kaua'i . It can observed that beside Kaua'i for which numbers have been very low to draw comparison, the other three counties correlates well until when the Safe Travel program began on October 15, 2020. Hawai'i county displays an increase in daily numbers right before which were a ributed to a couple of clusters (one in Hilo and one in Ocean View). Maui also had a few clusters, including a major one around October 20 on Lanai and another major one in early January in Kahului. After October 15, 2020 both Honolulu county and Hawai'i county show a slight increase in contrast with Maui county that displays a very sharp increase. Looking at Tables 7, 9 and 11 we observe that the exponential growths and decays for Hawai'i and Maui counties require typically larger value for the basal transmission rate than for Honolulu county. e reason is that changes occurred more rapidly in the outer-islands, for instance the peak for Honolulu county is based on a build-up starting in June while for Hawai'i county the peaks are much more narrower. For Maui county the decay due to the second stay-at-home order was extremely efficient at the beginning and then slowed down which requested an increase in β. Fig 19 . Honolulu, Maui and Kaua'i counties with normalized model fit, Kaua'i with normalized daily cases. It is clearly observed that counties started to differ in respond to the spread of COVID-19 after the safe travel program opened.We analyze similarity by using the L 2 -norm for the difference between two normalized given model fits. One comparison was done over the entire length from March 6, 2020 to January 15, 2021. Results are displayed in Table 13 Table 13 . Normalized L 2 norm between hawaiian counties measuring similarity. Show the impact of the different county's regulations for travel since the dissimilarity between the counties grows when we add the period October 15, 2020 to January 15, 2021. In particular, before travel was instated Honolulu and Maui counties were the most similar, situation that reversed afterwards.In regards to mobility and movement of the counties from the bo om halves of Fig. 6, 10, 14 , and 18, we acknowledge that the counties behavior follow a pa ern that following the onset of the pandemic, movement dramatically slowed down. Afterwards, it began to plateau towards a movement index between the shutdown and normal. Curiously, the correlation between the mobility index and the daily case is far from strong, and in the case of Kaua'i county the picture is more similar to anti-correlation (see Fig.17 ). It suggests that the spread of the virus among households, especially large and multi-generational, could significantly contribute to the overall daily cases. As we can observe from the 3D zip code maps, the cases are very localized. Not surprisingly, they are higher in urban locations and towns where the population density, as well as the probability of indoor gatherings, is higher.We use three other Islands: Japan, Iceland, Puerto-Rico for comparison with our counties. We ran a fit with our compartmental model for the three countries and analyze similarity by looking at the qualitative structure of the results as captured by merge trees (see e.g. [30] ). e la er construct is a topological descriptor of functions, and is constructed by tracking how connected components of the sublevel sets appear and merge as the threshold for the sublevel sets increases. is comparison is favored to a standard L 2 metric due to time shifts in the course of the pandemic for the various countries. An easy way to visualize this process is to move a horizontal line from the bo om to the top of the graph of a function and keep track of the function values at which a new connected component of the graph appears under the line or two existing components get merged. e actual horizontal locations of the branches, which represent the connected components, is not important, just their relative (left-right) positions. e merge trees for our three counties and the aforementioned countries are shown in Fig.20 . ey were computed using the normalized time series for the daily cases numbers starting from June 15. We also slightly simplified the structure (for illustration purposes) by removing very small branches. We can see that the Honolulu county merge tree is most similar to the Iceland merge tree and the Maui county merge tress is most similar to the Japan merge tree. e complexity of the Hawai'i county merge tree makes it more similar to the Puerto Rico merge tree, although these two are not as good of a match as the other pairs.Maui JapanHawai'i Puerto Rico Table 14 provides the initial values for Iceland, Japan and Puerto-Rico used by our model. travel restrictions vary widely between countries, see Table 15 for the estimate made for Iceland, Japan and Puerto-Rico.Iceland, most similar to Honolulu County, detected their first case in February and had a significant first wave, but then controlled the spread beside a super spreader event trigger by two travelers. Traveling has then be very restricted which is why the daily cases are mostly in the single digits at the end of the fit. Hawai'i county is most similar to Puerto-Rico. e accuracy of the data for Puerto-Rico is unclear and it was very difficult to find the travel restrictions. e primary difference is the peak in December that Puerto-Rico suffered. Maui and Japan display a very similar qualitative curve, especially when travelers are ignored for Maui. e reason for Japan explosive growth at the end of the year is a ributed to a few factors, including a controversial encouraging domestic travel policy that is as of January more restrictive and a possible COVID-19 fatigue by the population. Table 14 . Susceptible population for the three countries.In this paper, using the Hawaiian archipelago, we explore the importance of taking into account local variations in island chains. Ratios between residents and tourists as well as age demographic and other specificity call for targeted mitigation measures and Safe Travel program when in a pandemic. (Implementation of the Safe Travel program varies between the different Hawaiian counties.) e State of Hawai'i has launched an aggressive mass vaccination campaign starting in December but the effects of which are only now starting to impact the daily case rate. During the period of our study the very small impact of vaccination was neglected. As of February 2, 2021 we have 202,200 doses administered. e State policy is to keep the vaccination plan as originally planned to 2 doses per individuals even though two cases of the more transmissible B1.1.7 have been detected in Hawai'i . As of February 8, 2021 cases have been decreasing in all four counties.Not studied in this paper is hospital beds capacity, for the State of Hawai'i . e county of Honolulu is home to most of the hospital facilities and healthcare workers. e primary reason we did not discuss this here is the lack of consistent and clear data regarding hospitalisations. Similarly, quantification of COVID-19 related fatalities in the State of Hawai'i is delicate, indeed for instance in January about 60 deaths have been reclassified and added to the cumulative count.It is critical to conduct studies such as those presented here and capture critical data to be used in future pandemics. We are now working with the Hawai'i government on scenarios to understand impact of lifting some of the mitigation measures. rates into quarantine may be different between the three groups.I q,1 (t + 1) = I q,0 (t) + q s,0 I 0 (t)I q,2 (t + 1) = I q,1 (t) + q s,1 I 1 (t)+ + (1 − r)(q s,2 I 2 (t) + I q,2 (t))I q,j (t + 1) = r(q s,j−1 I j−1 (t) + I q,j−1 (t))+ + (1 − r)(q s,j I j (t) + I q,j (t)), j = 3, 4R(t + 1) = R(t) + rI 4 (t) + rI q,4 (t)+Below is a detailed description of the variables, all of which depend on time, t, measured in days.• Variable S(t). e number of susceptible individuals.• Variables E i (t). e number of asymptomatic infected individuals i days after exposure who are not quarantined.• Variables E q,i (t). e number of quarantined asymptomatic infected individuals i days after exposure.• Variables I j (t), i = 0, 1. e number of symptomatic infected individuals i days after the onset of symptoms who are not quarantined.• Variables I j (t), j = 3, 4, 5. e number of symptomatic infected individuals at the nominal stage i of the illness. Note that a person can stay at a given stage for several days.• Variables I q,j (t), j = 0, 1. e number of quarantined symptomatic infected individuals, with j representing either the number of days after the onset of the symptoms (j = 0, 1), or the stage of the illness (j = 2, 3, 4).• Variable R(t). e number of removed (recovered or deceased) individuals. Spli ing exposed individuals into multiple stages, E i , allows us to capture possible differences in the progression of the asymptomatic phase of the disease. Importantly, it allows us to take into account that, according to the Centers for Disease Control and Prevention (CDC) as well as other sources, about 40% of people who contract SARS-CoV-2 remain asymptomatic, and the incubation period for those who do develop symptoms is somewhere between 2 to 14 days after exposure, with the mean incubation period between 4 and 6 days [22, 25, 26] . Individuals who do not develop symptoms after 14 days are assumed recovered. e use of the quarantine sub-compartments, E q,i , allows us to capture the effect of contact tracing and the reduced transmission rate for quarantined individuals. Similarly, having multiple stages for infected individuals be er reflects progression of the symptomatic phase of the disease. e first two stages represent the first two days of symptoms, but the next three should be understood as phases of the immune system fighting the disease. ere is a substantial variability (due to age as well as other factors) in the number of days any given person can spend at each stage. Our model implicitly assumes that the symptomatic phase of the illness lasts at least 5 days (in the unlikely case that each stage lasts just one day).As we mentioned, a crucial part of the dynamics relates to the hazard rate. For the general community, group C, we have λ c (t) = β(1 − p mp (1 − p me )) (I c + εE c ) + γ((1 − ν)I c,q + εE c,q )+ ρ[(I h + εE h ) + γ((1 − ν)I h,q + εE h,q )]+ ρ v [(I v + εE v ) + γ((1 − ν)I v,q + εE v,q )] /(N c + ρ v N v ), (14) and for the tourists we havewhere we suppressed the dependency on t on the right for convenience. We use sub-indices c (community), h (healthcare workers), and v (tourists) to indicate the appropriate group. Subscript q indicates quarantined individuals. Here p me and p mp represent mask efficiency and mask compliance. Mask efficiency is chosen to reflect a reduction in transmission of 75% for all regions. Mask compliance is set at 20% for all regions at the start of the pandemic, but this value is modified on the dates the regions introduce mask regulations.N v denotes the mixing pool for the visitors and N c denotes the mixing pool for the general community, computed aswhere variables E and I here represent the sum over all the stages within these compartments. For the healthcare worker group, we have λ h (t) = ρλ c + βη (I h + εE h ) + κν(I h,q + I c,q + I v,q ) /N h ,where N h (t) = S h + E h + I h + R h . e model fit plot the following value x=c,h,v 3 i=1 q x s,i I(i) + (1 − r)q x s,4 I(4)e safe travel program started on October 15, 2020 which is when travelers are implemented in the model (they were negligible before that). Based on Safe Travels Digital Platform from the State of Hawai'i, we are assuming a pre-travel testing rate of 86%, a false negative rate of 0.5%. We also assume 1% of untested visitors go into exposed quarantine (we had to remove exempt travellers) and a 5% prevalence for the virus.e pre-testing rates for travelers to Maui county is higher, and assumed to be 95%. Traveler average influx is modeled as a piece-wise linear function over two week intervals between the aforementioned time interval. e average influx for the comparing countries is assumed for simplification to be linear over the same time period. See Table 15 .Tourists ",United States,first author,2021-02-12,02
0f8621b8722a718c20432f5f8c4423e142ca1161,Drops in the wind: their dispersion and COVID-19 implications,"So far, COVID pandemic is still growing, as of 18:34pm Central European Time (CET), February 6 2021, there have been 104, 956, 439 corroborated cases of COVID-19, encompassing 2, 290, 488 deaths, reported to the World Health Organization (WHO). It is believed that airborne transmission is one of the main mechanisms for COVID spreading 1,2 and that potential sources of infected droplets are breathing, sneezing, coughing or simply talking. Unfortunately, most of the reported literature neglects the effect of ambient flows on droplets transport. These flows are often present in daily activities such a wind flows, ventilation generated currents in offices, homes, malls, among other public places.Recent studies suggest that talking may be among the most dangerous mechanisms for generating infected droplets 1, [3] [4] [5] . According to Tan 5 and Bourouiba 6 , speech induced plumes can travel 1.3m in 2s or even 8m, which is a distance way longer than the 2m social distancing. Abkarian and Stone 3 using high-speed imaging showed that pronouncing consonants (typical to many languages) such as 'Pa','Ba', and 'Ka' are potent aerolization mechanisms. Abkarian et al 4 using theory, experiments, and simulations documented the flow generated after speaking and breathing, which is in fact the responsible for droplets' transport. Notice that the 2m social distancing, only considered quiescent flows 4, 6, 7 . This situation is not always satisfied in daily conditions, where wind is frequently present either naturally or induced by air condition in buildings or even by simple motion of people 8 . Further evidence of airborne transmission of COVID-19 a) Electronic mail: sem@xanum.uam.mx disease possible enhanced by air currents are: A reported infection of 96 people out of 216 working in a eleventh floor in a call center of South Korea 9 ; a singing rehearsal in Washington, where 53 singers were infected even they were located in a volleyball court but ventilation air currents were present 5 . A study precisely on the effectiveness of air ventilation and COVID implications 8 suggests that only certain type of ventilation called 'displacement ventilation' properly designed to extract contaminated hot air, could be the most effective air condition mechanism to reduce the risk of infection. Related works where droplets produced by breathing, sneezing, coughing, or talking, and immersed in external flows are few. Some examples are Cummins et al 10 who studied micrometric spherical droplets in the presence of a source-sink flow, which simulated a scenario where droplets are produced and subjected to an extraction mechanism (air condition). Incorporating evaporation, humidity, and an uniform external wind, Dbouk and Drikakis 11 presented a conjugated heat and flow transfer problem (occurring in a saliva droplet) and coupled to a CFD analysis. They proposed a transient Nusselt number and varied relative humidity (RH), temperature, and speed of flow. Contrary to past studies, they conclude that evaporation of droplets is enhanced at low RH and high temperatures. As an example, they results indicate that in a cloud of droplets in an environment at RH=50%, temperature T < 30 o C, and under an external flow of 4km/h, there will not be evaporation. Their simulation however, only reached five seconds, hence the full dispersion of droplets could not be reached. B. Blocken et al 12 also performed a CFD analysis for people exhaling while walking or running, and emanating from them possible infected droplets. However, their simulation only considered droplets of radius 20µm and beyond. As it has 1 . Schematic of the problem studied. A person talking either normally (exit speed of droplets around 1m/s) or strongly (exit speed of droplets around 5m/s) 4,10 , and under the presence of an external flow u(r,t).recently been observed, the smallest the size of a droplet, the more dangerous it may be 13 . Feng et al 14 located two virtual humans 3.05m apart and let one human to eject droplets while coughing or sneezing. Using a computational particle fluid dynamics model that considered evaporation, external wind and condensation, and even Brownian motion, they found that at this distance, potentially infected droplets easily reach hair and face of the other human. They also performed a study on the filtration efficiency of several masks. In conclusion, most of the previous works suggest that the safe distancing is not enough under wind conditions.In this work, we consider micrometrical spherical droplets emanating from a person while talking either normally (exit speed of droplets around 1m/s) or strongly (exit speed of droplets around 5m/s) 4,10 , and under the presence of external flow currents, and calculate, following the Maxey-Riley (M-R) equation 15 , their effect on the maximum spreading of droplets of constant radius ranging from 5µm to 100µm. The wind currents profiles are modeled as a shear flow, a Poiseuille flow, and an unsteady shear flow that considers the typical time-dependent situation of wind blowing and ceasing. The present study is organized as follows: Section II describes the model, and the order-of-magnitude of each term in the M-R equation. Section III presents analytical results for the dispersion of micrometric droplets subject to three external flow profiles namely, shear, Poiseuille, and unsteady shear flow. Here, the Boussinesq-Basset memory force is neglected. Section IV is intended to study, by performing numerical simulations, the effect of the Boussinesq-Basset memory force (and the same external flows as in Sec. III) on the dispersion of droplets. Discussions and conclusions are offered in Sec. V.Let us analyze the motion of noninteracting spherical droplets of mass m, radius a, in an environment with air density ρ a and air viscosity µ a , under gravity g, and subject to an external flow of the form u (r, t), with a characteristic speed U max , where r(t) = (x, y, z) is the droplet's position, here t represents time. In this study we will be considering three flows namely shear, Pouiseuille, and unsteady shear flow. Droplets immersed in these profiles will have a characteristic speed v(t) which decreases as the droplets fall due to gravity. With the latter physical quantities a Reynolds number (Re) can be defined as Re = ρ a (U max − v)a/µ a which satisfies Re < 1. Therefore, these droplets individual dynamics described by their translational velocity, v(t) = (v x , v y , v z ), follows the Maxey-Riley equation 15where m a is the mass of air displaced by the sphere, υ a = µ a /ρ a represents the kinematic viscosity, R T = 6πaµ a is the resistance coefficient; while ρ indicates the droplet's density. In addition, the following definitions are included:The forces on the right hand side of Eq. (1) are respectively, the droplet's weight; bouyancy force; forces in the undisturbed flow due to local pressure gradients; the added or virtual mass force; Stokes drag force; and the last two terms represent the Boussinesq-Basset memory force. To find the order-of-magnitude of each term in the Maxey-Riley Eq.(1), one can introduce the followingwhere the characteristic speed is defined as U = mg/R T , which is the terminal velocity of a falling droplet. After applying those dimensionless variables to Eq. (1), one arrives at 5µm < a < 25µm 25µm < a < 50µm 50µm < a < 75µm 75µm < a < 100µmShear Poiseuille where the Reynolds number Re = ρ a U a/µ a has been introduced, as well as the ratio λ = m a /m = ρ a /ρ = 1.225 × 10 −3 . Here g = ga/U 2 .Let us start analyzing the order of magnitude estimate of the terms in Eq. (1) based on typical droplets ejected after talking. According to recent studies 4,10,16 , the radius of those droplets range between 5µm to 100µm, hence Table I shows their respective Reynolds number and the order-of-magnitude involved in Eq. (5) . From this table and for droplets of radius a ∈ [5µm, 20µm], the limit Re → 0 can be applied to the M-R Eq. (5) to finally getwhich implies that the dynamics of droplets of this size isThe latter result belongs to the so-called overdamped approximation, where inertia does not play a role, and particles immediately reach the external flow speed. Alternatively, by keeping inertia and neglecting terms of order √ Re and higher, the Maxey-Riley equation can be rewritten asThis equation allows us to observe the dynamics of droplets at short times.Let us solve Eq. (8) under the presence of shear and Poiseuille flows modeling the effect of wind on the spherical droplets. These profiles are given byNotice that the shear flow profile correspond to the case U 0 = 0. Given Eq. (9), we solve Eq. (8) whose solution including dimensions and subject to r(0) = (0, 0, h) andwhere K = R T /m and β = Ka 2 U 0 /3. Integrating the velocities, we getwhere constants A, B, C, γ y , γ z , s x , s y , s z are defined in Appendix IX.A more realistic situation, is to consider the fact that air flows for a while, and then stops, and then flows again. The simplest model is to assume a time-dependent shear flow scenario. This unsteady vector flow field u(r, t) should satisfy the time-dependent Navier-Stokes equations, which after assuming u(r, t) = (0, u y (z, t) , 0), incompressibility, and a null pressure, reduce toThis parabolic equation must satisfy u y (z, 0) = (U max /h) z, u y (0, t) = 0, and u y (h, t) = U max /2 (1 + cos ωt). Its solution can be veryfied to bewhereOnce Eq. (15) Once Eq. (12), Eq. (13), and Eq. (21) are available, we can now exemplify a typical droplets' dispersion (cloud) after a person talks and generates micrometric droplets (radius between 5 µm to 100 µm 4,10 ), which are subject to either a shear flow (Fig. 3(a) ), a Pouiseuille flow ( Fig. 3(b) ), or an unsteady shear flow (Fig. 3(c) ). We simulate the situation of a normal and a strong talk by imposing an exit speed of droplets (from a cone shape of velocities representing a person's mouth) of v 0 = 1m/s and v 0 = 5m/s, respectively. The cloud is made of 1000 droplets of random size between 5 µm to 100 µm. Additionally, we impose a moderate (U max = 5m/s) and a calm (U max = 1m/s) wind scenario. The cone shape as the initial velocity distribution, and as observed from experiments 10 , is implemented by imposing v(0) = (v 0 cos ϕ 0 sin θ 0 , v 0 sin ϕ 0 sin θ 0 , v 0 cos θ 0 ), whose angular polar and azimuthal initial extremum are set to θ max The simulations for the unsteady flow profile consider ω = 0.5s −1 . Finally, (ϕ, θ) will randomly vary between their extremum. The results can be visualized in Fig. 3 which shows the distribution of droplets at three different times namely, t = 0.08s, t = 0.4s, and t = 1.33s. A color code indicating the droplets' sizes is also introduced. The safe distancing is indicated as a vertical dotted-black line. Clearly, droplets move beyond the safe distancing. As it can be seen, droplets under a moderate wind and after only 1.33s, are already 6m away from the person's mouth. Droplets under a calm wind and less than 50µm in radius will overpass the safe distancing in the next second. These results indicate a potential danger for people in a public space since the safe distancing has been easily surpassed. We finally take Eq. In the literature, the Boussinesq-Basset (B-B) memory force has been less frequently considered, probably because of its order-of-magnitude and because of the required computational effort. However, there exist some theoretical 15,17-21 , numerical [22] [23] [24] [25] and experimental 26, 27 works dealing with this force. In this section we analyze the effect of the memory force term on the dispersion an flying time of spherical droplets.Consider first small droplets ranging between a ∈ [5µm, 20µm]. According to Table I To solve this integro-differential equation, a first order Euler method is chosen. Under this method, a component of the B-B force term can be shown to be:where we have assumed that ∆t = ∆τ and definedAfter certain steps, one can prove that the overdamped M-R Eq. (22) , along the z−direction and in dimensional variables, acquires the following discrete form for k = 3, ...N : where constants c 0 , c 1 , c 2 , c 3 are defined in Appendix X.A similar expression as Eq. (24) is obtained for the other spatial components. In the case of larger droplets and from Table I , one notices that the order-of-magnitude of all terms in Eq. (5) is the same. Therefore, one has to solve for the full M-R Eq. (5). Using the Euler method together with Eq. (23), one can show that the discretized z−component of Eq. (5) in dimensional variables readswhere constants R, b 0 , b 1 , b 2 , b 3 are defined in Appendix X. The discretization of the other components in Eq. (5) is similar to Eq. (25) . After posing Eq. (24) and Eq.(25), we are ready to find the droplets' dynamics under higher order terms. Because of the external flows we have chosen and from the simulations in Sec. III, we observe that the dynamics mostly occurs along the z − y plane, and that initial conditions are not relevant for long times (at least for v T (0) = 0); thus from now on, a 2D problem with initial conditions v z (0) = 0 and v y (0) = U max , will be considered. Equations (5) and (22) are then numerically solved using the discretized scheme in Eq. (24) and Eq. (25) , under the presence of a shear flow (the other flows basically share the same features), and for two typical exit initial speeds while talking 4,10 namely, 1m/s and 5m/s. The time-step used for solving Eq. (5) and Eq. (22) was 4 × 10 −4 s and 5 × 10 −3 s, respectively. The results of the simulations are shown in Figs. 4(a)-(c) . In those figures, ∆y = y M B − y M , where y M B is the maximum travelled distance along the y-direction by droplets of size a ≤ 20µm and obtained from Eq. (22) . For droplets of size a > 20µm, y M B represents the maximum travelled distance along the y-direction obtained after solving the full M-R equation (5); whereas y M represents the solution directly obtained from Eqs. (12) and (13) . One can observe that for a low wind speed, the effect of higher order terms barely enhance the droplets' dispersion. However, for a wind speed of 5m/s and for the smallest considered droplet, higher order terms can increase its dispersion around 2 m. Figures 4(a) -(c) also indicate that as the size of the droplets increases, higher order terms effects become smaller until they finally disappear.The effect of first order terms and the full terms in the M-R equation, on the flying time of spherical droplets as a function of the radius a is also analyzed. Using Eq. (12), the numerical solutions from Eq. (24) and Eq. (25) , and defining ∆t F = t F B − t F ; where for a ≤ 20µm, t F B represents the flying time of a droplet calculated using first order terms (Eq. (22)). For a > 20µm, t F B represents the flying time calculated using the full terms in the M-R equation. On the other hand, t F is the flying time directly obtained from Eqs. (12) . This analysis is shown in Fig. 3(d) . It can be seen that ∆t F increases as the droplets' sizes decrease. In fact, for a = 5µm there is a 0.8s flying time difference between the dynamics of Eq. (5) and Eq. (8) . This extra time also contributes to the observed enhancement of dispersion of small droplets. A numerical analysis on the convergence of ∆y = y M B − y M , as the time-step ∆t in the simulations decreases, is also performed. Fig. 4 (f) shows this convergence for a droplet of radius 30µm after discretizing the full M-R equation (5) . As expected, a linear convergence can be appreciated. The convergence for a droplet of radius 19µm and after using the overdamped M-R equation (22) is shown in Fig. 3(b) . Once again a linear convergence is achieved. Therefore, the latter analysis validates our employed first order numerical algorithm.Finally, the implications of the Boussinesq-Basset memory force term on the sedimentation velocity component v z (t) with v z (0) = 0 is also studied. The numerical results are shown in Fig. 5 , which illustrates the dynamics of v z (t) + U versus time in a log-log plot, and for two different spherical droplets reaching their terminal velocity U . The black-solid lines belong to an exponential decay of v z (t) towards U ; whereas the red-dashed lines indicate a t −1/2 decay. It can be observed that for short times, v z (t) exponentially decays towards U ; however, v z (t) decays according to the scaling t −1/2 for long times. This is a rather surprising result, since the orderof-magnitude of the B-B term is really small. This t −1/2 decay of the sedimenting velocity has been also recently reported 17 . Further consequences of the B-B term on the motion of particles at low Reynolds numbers may be search for in future investigations. 1m/s, 1m/s}) either using single particle dynamics (this work), or using a more elaborated CFD analysis 11 . (c) Droplets' distribution at t = {1s, 2s, 3s, 4s, 5s}, and linear paths followed by some droplets of different sizes under an uniform flow. See Fig. 2 for color code.According to Dbouk and Drikakis 11 and others, evaporation and relative humidity play a role on droplets' dispersion. Those factors may reduce or increase the size of droplets and their cloud shape as it travels. Therefore, our results could be improved to account for a rocket-like dynamics (drops varying mass). Following Dbouk and Drikakis 11 , who considered a conjugated flow-heat-mass transfer problem and CFD dynamics, it can be conclued that evaporation of droplets takes place at high relative humidities, and high temperatures. Thus for the case of countries with an annual average of relative humidity, RH = 50%, a wind speed of 4km/h = 1.1m/s, a temperature less than 30C o , and five seconds later since a cloud of droplets originated, there will be a null evaporation 11 . Other works also supporting a long time survival of infected droplets is Stadnytskyi et al. 28 Based on this information, Fig. 6 (a) shows four droplets' distributions (cloud) five seconds later since the cloud originated under a shear (S) or an unsteady shear (U N S) flow with {U max , v 0 } = {1m/s, 5m/s}. The other numerical parameters employed and the initial velocity distribution of droplets are the same as in Fig.  2 . This figure indicates that droplets with a > 75µm have already reached the floor, and that droplets of size 50µm < a < 75µm are about to reach the floor. How-ever, the smallest droplets under a calm wind (1m/s) for both U N S and S, have surpassed the social distancing (vertical black-dashed lines). The same droplets under a moderate wind (5m/s) for both U N S and S, reached 15m and 25m, respectively. Thus from this figure, one can explicitly visualize a more real scale to which people may be in risk of contagion. Fig. 6 (b) compares the position of droplets' distribution (cloud) under an uniform flow ({h, U max , v 0 } = {h = 1.7m, 1.1m/s, 1m/s}), either using single particle dynamics (this work) or employing a more elaborated CFD analysis 11 . Both methods result in a similar cloud's position. Finally, using the latter parameters, the droplets' distribution at t = {1s, 2s, 3s, 4s, 5s} and some paths followed by droplets of different sizes are shown in Fig.6(c) . These paths have a linear behavior since the cloud dynamics is practically overdamped, implying y(t) ≈ U max t and z(t) ≈ h − U t, thus particles will follow the function z ≈ h−(U/U max )y.In summary, using single particle dynamics, which has the advantage of requiring a minimum computational cost, this paper provided an estimate of the maximum dispersion of micrometric droplets generated after talking. Briefly, under conditions of a null evaporation and only five seconds later since droplets were originated, it was found that an unsteady shear calm wind (1m/s) can disperse droplets beyond the social distancing, and until more than 15m when droplets are subject to a moderate unsteady shear flow (5m/s). As expected, an unsteady shear profile is less efficient to disperse droplets than a constant Poiseuille or shear profile. These constants profiles modeling a calm wind (1m/s) were found to provide a maximum dispersion beyond 250m for the smallest droples (5µm). The effect of the Boussinesq-Basset force term was also analyzed. Although its order-of magnitude is small, it was found to be enough to change the behavior of the sedimentation velocity (from exponentially decaying towards its terminal velocity, to proportionally decaying as t −1/2 ) of a micrometric particle and slightly increase droplets' dispersion and their flying time.Future research would be to consider external flows in the presence of buildings and to find the complex streamlines generated and their effects on droplets' distribution. It may be inferred for example that the presence of a corner on a common street, could generate stagnation points, that may risk areas of infection, since those points could storage for a while infected droplets. Furthermore, walls may induce three-dimensional flows that may drag particles away from the floor, thus increasing its flying time and hence their capability of traveling longer. We hope this study helps people to be more aware about the effect of daily wind currents on the propagation of potentially infected droplets. Based on our findings of droplets easily dispersing beyond the social distancing when subject to wind currents, we recommend the use of masks 8 able to contain the virus, as well as flex seal googles, since droplets dragged by wind may reach eyes. We also recommend to wash all your wearing clothes and shoes, and to shower after being out from home, since infected droplets may be attached to clothes or hair 14 . Direct exposure to wind currents, mainly in crowded cities, should also be avoided.",Mexico,first author,2021-02-16,02
cc1bb75d88018cc33e801287622db99d4e45180c,Application of Yolo on Mask Detection Task,"Under the current COVID-19 background, it is vitally important to control the spread of the disease. Studies have shown that mask-wearing can significantly decrease the risk of COVID-19 transmission. However, it is unreasonable to expect that everyone is able and willing to wear a mask. Many countries and regions have imposed laws to enforce mask wearing in public places. However, these legislations are incredibly difficult to enforce using pure human labor, especially in public places. Automation techniques are necessary to perform detections in real time. There are existing methods that automates mask-detection.The most dominant of these methods employ a deep neural network model called Mask-RCNN to automatically detect people who are wearing and not wearing masks from a video source. The problem with these methods is that Mask-RCNN is computationally heavy. This means that systems that rely on Mask-RCNN requires adequate computing power to run the model in real time. The bar in computing power presents a difficulty to deploy real-time mask detection systems, especially in places where such devices are not affordable. Our project aims to reduce the computation cost of such automated mask detection system by replacing the Mask-RCNN with the YOLO model, which achieves the same level of accuracy and is two-degrees faster. This significant reduction in computation costs allows for less expensive device to be deployed for mask detection. We believe that this would help in enforcing mask wearing policies and consequently reducing the cases of COVID-19 infection.II. RELATED WORKS R-CNN and Mask-R-CNN is a family of convolutional neural networks (CNNs) that perform object detection on images. Proposed in 2014, the original R-CNN is the first to use CNNs to perform object detection. R-CNNs yields significantly better results compared to traditional feature extraction methods such as Scale-invariant feature transform (SIFT), Histogram-of-oriented-gradients (HoG) features and bag-of-features methods [3] . R-CNN detects objects by making around 2000 region proposals from the input image via the Selective Search algorithm, warping the regions in the same way, and passing them through a CNN feature extractor. The output of the CNN is then fed into a simple Support Vector Machine (SVM) classifier for classifying objects in the proposed regions and a regressor for generating the bounding boxes. R-CNN is extremely slow because detecting objects in a single image requires passing all of the region proposals through the CNN. Running time for R-CNN predictions is usually around 1 minute. The R-CNN is very difficult to train because it is RAM heavy and requires training the CNN, the SVM and the regressor. [3] . Improvements to R-CNN was swiftly made with its original author introducing Fast R-CNN in 2015 [2] . Fast R-CNN achieves significantly better running time by eliminating the repeated feed-forward feature extraction of proposed regions. This is done by directly feeding the image through a CNN and use the resulting feature map for region proposals instead via Selected Search. The proposals were then warped into the same shape through a special Region-of-Interest (RoI) layer and then fed into fully connected (FC) layers. The SVM is replaced by a SoftMax layer to perform classification, hence making Fast R-CNN easier to train. Ren et al. further improved on Fast R-CNN by replacing the Selective Search algorithm, which turned out to be the bottle-neck in speed and accuracy of R-CNNs, with a CNN. This CNN, called the Region-proposal Network (RPN) is responsible for proposing regions instead. RPN works in accordance with RoI pooling by sharing the feature maps generated by the feature extractor CNN. Result is a model that can be run in real-time at 5 frames per second on a graphical processing unit (GPU) [9] . Adding arguments on why this is still not okay, we want a faster algorithm: lower computation cost so that we can process more data on cheaper machines/on edge devices to improve coverage of this automated face-mask detection system. YOLO, abbreviation for ""You only look once"", is another type of model that performs object detection on images. Instead of taking the two-stage propose-and-classify approach defined by the family of R-CNN models, YOLO achieves object detection in a single stage by treating the task as a regression problem. This allowed YOLO to achieve a 45 frames-per-second detection speed on a Titan X GPU [7] . Proposed in 2016 by Redmond et al., the original YOLO model divides the input image into a 19×19 grid of cells. Each cell is responsible for predicting 2 bounding boxes by giving a confidence level on if an object exists in each bounding box. The bounding box predictions are non-max suppressed. The final prediction results are those with the highest Intersection over Union (IoU) scores [7] . The original YOLO model had several limitations. 1) Difficulty to detect objects that appear in groups or have unusual aspect ratios or configurations, because each grid cell is responsible for predicting only 2 bounding boxes of fixed aspect ratios; 2) Localization inaccuracies because the loss function treats low and high dimension localization errors equally. Redmon et al. made improvements on the YOLO model in their subsequent research by adding Batch Normalization layers, replacing fully-connected layers with anchor boxes, and using a custom DarkNet-19 convolutional layer to reduce the number of floating-point observations. Redmon et al. made some final consolidations in YOLOv3, the most notable of which is expanding the DarkNet-19 to a larger but more accurate DarkNet-53 CNN that incorporates residual layers while adding minimal computational overhead. The result is a fast, accurate model that can process images at 30 frames-per-second on a Pascal Titan X GPU [8] . Notably, YOLO provides different model architectures that allows for different trade-offs in processing speed and accuracy.Few-Shot Visual Classification. The goal of few-shot learning is to automatically adapt models such that they work well on instances from classes hardly seen at training time. Most of last decade's few-shot learning works can be differentiated along two main axes: 1) how images are transformed into vectorized embeddings, and 2) how"" distances"" are computed between vectors in order to assign labels.Siamese network [5] , an early approach to few-shot learning and classification, used a shared feature extractor to produce embeddings for both the support and query images. Relation networks, and recent GCNN [4] variants, extended this by parameterizing and learning the classification metric using a Multi-Layer Perceptron (MLP). Matching networks [11] learned distinct feature extractors for support and query images which were then used to compute cosine similarities for classification. The feature extractors used in such works are usually obtained by fine-tuned transfer-learned networks.This paper adopts Simple CNAPS to solve problems caused by small and imbalanced dataset. Methods that are most similar to approach are Simple CNAPS [1] , CNAPS [10] (and the related TADAM) and Prototypical networks. It is the state-of-the-art approach for few-shot image classification. In this kind of methods, CNAPS use a pretrained feature extractor augmented with FiLM layers [6] that are adapted for each task using the support images specific to that task. Different from CNAPS, simple CNAPS [1] makes improvements in the following ways. CNAPS has demonstrated the importance of adapting the feature extractor to a specific task. Simple CNAPS demonstrates an improved choice of Bregman divergence and proposes that the use of the Mahalanobis distance is helpful for image classification. In addition, simple CNAPS makes it no extra parameters, which is easier for training and can be used for different classification tasks.Masks play a significant role in protecting the health of individuals against virus spread in air, as is one of the few precautions available for COVID-19 in the absence of immunization. Hence, it is very important for us to detect whether an individual wear a mask and whether they wear correctly as a means of tracing the infection.Currently, data-driven detection and classification models must be fitted with a dataset to function properly. Mask detection and classification dataset in this paper come from one of the latest Face Mask Detection and Kaggle. This dataset contains 853 images belonging to the 3 classes described below, as well as their bounding boxes in PASCAL VOC format:This dataset is well prepared for detection and classification models, that is, in every single image, there might be multiple targets with different classes. This task is what Yolo framework designed for.Additionally, based on this dataset, we also built a simpler dataset consisting of target slices in the original images, in order to train and test Yolo-based classificationonly models. In the training set, there are 3145 images, with 2546 with mask, 508 without mask, and 91 masks worn incorrectly. The above numbers tell us that the dataset is limited in size and is very biased towards the ""Wearing Mask"" class.While most proposed solutions in the Kaggle Face Mask Detection Dataset competition use Faster R-CNN to achieve good detection results, these R-CNN models are still computationally expensive and does not have good framesper-second performance in real time. Our first task is to adjust a well-trained Yolov3 model to this traditional detection & classification task to obtain equal accuracy and faster speed than the proposed solutions.Our work began with the GitHub repository ultralytics/yolov3. The repository is maintained by ultralytics, a U.S.-based particle physics and AI startup with over 6 years of expertise supporting government, academic and business clients.Based on their work and our original dataset, we did the following training and tuning strategies:• Weighted Loss Function: We found that, during training, the model has a tendency to converge better in bounding box and object loss and less well in class loss. To mitigate this problem, we used a weighted loss function that can be expressed as: u th tt th • Data Augmentation: based on the limited size of training data, we adopted a series of data augmentation methods including: -Random Rotation / Translation / Scaling / Flip -Random Hue / Brightness / Inverse / Saturation -Random Gaussian Blur • Undersampling: Given that target Correctly wearing the mask has much more samples than the other two classes, we believe that it is necessary to adopt undersampling technique to make the training data more balanced. • Hyper-parameters tuning: We manually tuned the hyperparameters including batch size, grid size, learning rate schedule.While fitting the traditional detection & classification model, we found that our model had a low classification accuracy. We decided to investigate the cause. After we built the classification-only dataset, we found that the dataset is imbalanced in the distribution of the class samples. Images that belong to Mask worn incorrectly class are very few. For this reason, we adopted the latest Few-Shot classification techniques to perform this classification only task. Goals are:• To get better classification scores than the traditional detection & classification models on the target slices • To compare the performance of feature extraction between two backbones that have relatively equal number of parameters: Mobilenetv3 backbone and YoloNano To achieve goals, we implemented Simple CNAPS. Simple CNAPS [1] is first proposed by Peyman Bateni, et al., based on the previous work about CNAPS, which is one of the state-of-the-art in the Few-Shot classification domain. Compared with the original CNAPS, simple CNAPS makes the few-shot classifier no parameters. Their work is published in CVPR 2020 and showed that simple CNAPS can achieve good performance in few-shot classification task that is even better than the conventional CNAPS. Because there is no source code that has implemented simple CNAPS, we reproduce the model ourselves.One of the great differences between simple CNAPS classifier and traditional FC-layer Classifier used in CNN, is that simple CNAPS adopts the concept of Mahalanobis distance (class-covariance based) instead of Euclidean distance as the metric. An advantage of using a classcovariance based metric during classification is that such metrics take the distribution in feature space into account and give improved decision boundaries for non-linear classifiers. In Mask Detection task, the decision boundary between With mask and Mask worn incorrectly are very close. We identify this as the source of misclassification by our model.Additionally, in the implementation of simple CNAPS, every class is treated equally with its Class Mean and Class Covariance Estimates, which indicates that this classifier will be less influenced by the imbalanced dataset.Furthermore, adopting simple CNAPS decreases the number of FC layers with only a few extra parameters stored. This result is also in line with our initial purpose of the this research: to train a high efficiency detection and classification model for real-time use cases.To implement the simple CNAPS-based classifier, we designed a full 3-stage training-inferring process by using simple CNAPS for classification. This is not mentioned in the original paper. The 3-stage process includes pretraining, finetuning and querying (Figure 2 ).We use OpenCV visualize the prediction results in videos. OpenCV supports reading streams of videos from external devices and files from the local file system. Given a trained model on a mask-detection dataset, we expect the output of the model to contain at least the following fields:  An array of images used in the prediction  An array of predictions generated by the model, of tuples of the following format array of label names The video source is read as an iterable stream of frames of images. Each frame of image is passed into our model at their original height and width (e.g., 1080 pixels wide, 1920 pixels high). Our model generates inference results conforming to the above format. We use the results to draw the bounding boxes, predicting class names and confidence level for each detected object (face, face masks, face masks worn incorrectly) on this frame of image. The drawn frame is then passed into a video encoder to be saved as a frame in the output video. The end result is a new video with the above visualizations with MPEG-4 encoding. The input video is not modified in any way. Processing videos with OpenCV adds overhead to model prediction. The overhead comes from reading frames from the input video, drawing the visualizations and writing the drawn frame to the output video. Model is very performant, achieving a 2 frames-per-second on a modest dual-core Intel Xeon CPU at 1920×1080 resolution.We trained a Faster RCNN, an original Yolov3 and our customized weight loss Yolov3 with fine-tuned hyperparameters, based on original Face Mask detection dataset. The original data set is randomly divided into training set and validation set in a ratio of 4:1. The training process was carried on a server with modest dual-core Intel Xeon CPU and NVidia RTX 2080 Ti video card. Each model is trained in an 8-batch size with 200 epochs. The following table shows their performances on the same validation set. In the weighted loss Yolov3, we set:From the results above, we see clearly that Faster RCNN tends to perform better than Yolov3. We believe that it might because the Faster R-CNN uses a larger feature extractor (ResNet-50). However, with a little loss in the accuracy, Yolov3 has a much better running speed. We can also see that the F1 score is not as good as the precision. This reveals the imbalance of the dataset as we have mentioned before. However, as we applied our customized weighted loss, which added the proportion of L cls , our new model achieves a better F1 score. The experiment results proved our hypothesis.We trained the traditional classification network with FC-layer predictor. We chose a Mobilenetv3 backbone with 2,826,736 trainable variables and a YoloNano backbone with 2,771,991 trainable variables as our candidate feature extractors. Experiment results are listed as follows In order to avoid the influence of imbalanced dataset, we adjust the ratio of each class in the validation set. Our validation set has 183 ""With Mask"" images, 40 ""Mask worn incorrectly"" images, and 129 ""No Mask"" images.From the table above we see the feature extracting ability of YoloNano is not worse than the state of art mobile feature extractor MobileNetv3 (large version). What's more, YoloNano shows a better performance in avoiding overfitting on small datasets. Simple CNAPS-full 0.8693 0.8543 *Here ""Simple CNAPS-50"" means that we set the size of support images of CNAPS as 50, and ""Simple CNAPS-full"" means we set all images in the training set as support images when querying. Besides, we see a remarkable improvement in test accuracy after using simple CNAPS instead of the FC layer predictor. When inspecting the curves, we see that when the support images number increase, the simple CNAPS's performance first improves and then worsens. This matched the results that Peyman et al. mentioned in their paper. Hence, when using simple CNAPS, tuning the number of support images is be very important.When Faster RCNN and Mask RCNN are so popular, why we still consider networks from the Yolo family. With this question, our work showed that the Yolo family networks have great capabilities in feature extraction and object detection that are no worse than the current state-ofthe-art such as faster/mask RCNN and MobileNet. Additionally, Yolo family networks have faster execution times, which is better-suited for practical application in realtime use cases that we proposed: detecting masks in real time.We first designed a full training process for simple CNAPS in a real-life task, and proved that it is helpful in improving the few-shot class classification scores. The next step might be adopting simple CNAPS on the traditional detection & classification frame works.Further improvements can still be made based on our video processing pipeline. These improvements may not be directly related to our model. 1) We do not need to pass every frame to our model. This is based on the assumption that continuous frames in the input video are likely to contain similar content. By strategically skipping frames, we can improve the processing speed of our entire pipeline. 2) We can incorporate instance tracking in our video processing pipeline. Instance tracking compares the pixel content of frames to predict the movement of detected objects. This takes significantly less floating-point operations than passing frames to our model for inferencing and hence will improve our overall processing speed.This project has practical value under the current context of the COVID-19 pandemic. Pipeline is already capable of detecting people with, without and incorrectly wearing masks with reasonable accuracy. With some improvements, we envision that product can be used as a component in a contact tracing system. Product is also relatively computationally efficient. The hardware threshold for deploying our project is low. This means that product is less restricted by budget or the level of economic development at the location of its deployment and hence can reach more places where COVID-19 infections pose more threat to people.Deep learning models have vulnerabilities. While it is possible to conduct adversarial attacks on our model if it is deployed, such attacks are unlikely not cause direct, physical harm to people whose faces are detected. It is worth mentioning that, with minimum improvements, our model is capable of memorizing detected faces (e.g., through a facerecognition deep-learning framework). This is a likely use case if our model is incorporated into a contact-tracking system where facial-recognition and storing faces are required. Facial features are generally considered to have some level of privacy. In such cases, we should implement counter measures such as implementing safe deep learning models, obfuscating stored faces and putting our product behind a safe strong-point to protect the stored human faces.In this paper, we examined the performance of neural networks from the Yolo family in real-time detection tasks. Results showed that this Yolo is capable of achieving stateof-the-art performance in object detection and classification with a much lower inference time. This showed that Yolo is well-suited for detection and classification tasks in real-time settings such as the one we proposed: face-mask detection in real time. Additionally, we implemented the Simple CNAPS model and found that it improves our model performance on the small and biased dataset that is available to us. We have also implemented a sample video processing pipeline to demonstrate our model performance.As detailed in section 3.1, our dataset is acquired from Kaggle. The dataset contains 853 images and one boxing box specification file in PASCAL VOC format for each image. This dataset is used to build simpler dataset containing only the target slices of the original images. This dataset is used to train and test the Yolo-based classificationonly models. There are 3145 images in the training set. 2546 with mask, 508 without mask, 91 masks are worn incorrectly. This dataset is very small and imbalanced.1)Libraries and Frameworks. For the video processing portion of our code, we used PyTorch as our deep learning model framework. We used OpenCV-Python to read and write video streams. For traditional detection and classification task, we trained our models on a container with an Intel Xeon CPU E5-2695v3 with default frequency of 2.30GHz, a GTX 2080 Ti GPU (11GB Memory) and 52.8 GB RAM. The video processing portion of our code is run in a standard Google Colab environment with GPU acceleration.ACKNOWLEDGEMENT Thanks for Olivia Sun for her advice on the content of this paper and her editing work.",United States,first author,2021-02-10,02
a7de7f6dc0e88599f37482f55e26aea5f6e64043,A Bayesian spatio-temporal nowcasting model for public health decision-making and surveillance,"The first cases of SARS-CoV-2 in the United States were reported in early March [1] , though recent phylogenetic evidence suggests the first introductions occurred in January 2020 [2, 3, 4] .As COVID-19 spread throughout the country, states began to set up risk alert systems to support data-driven decision-making, improve government accountability, and communicate health risks to the public [5] . The goal of such systems is to provide clear and consistent messaging around the current state of the COVID-19 pandemic and help people adopt protective behaviors while policymakers implement appropriate structural changes to mitigate spread. Risk or public health alert systems typically develop a series of indicators which use various sources of surveillance data [5] .In some states, these systems were linked to specific policy actions [6] while in others they serve more as a risk communication tool to inform local health departments and the general public [7] .In most systems, several key indicators are tied to the reporting of confirmed COVID-19 cases and their onset date of illness (i.e., the date an individual first began to have symptoms) [8] . However, chronic delays in outbreak investigation and case reporting have led to challenges in estimating case-based indicators and communicating the situation in a location in near real-time.Issues related to reporting lag or reporting delay are not a new challenge in public health surveillance [9, 10, 11] . It is quite common for reporting in infectious disease and vital statistics systems to not occur instantaneously with the onset or occurrence of the event of interest. For infectious diseases, this delay can be due to: 1) a prolonged interval between the time an individual recognizes symptoms and is able to seek care and receive confirmatory testing, 2) administrative backlogs and delays in the acquisition, processing, and ultimate reporting of information, and 3) the length of time necessary to conduct a full case investigation. However, particularly when facing a fast-moving epidemic, important decisions need to be made in real-time despite the fact that the most recent information is likely incomplete. This added uncertainty can reduce the confidence of both policymakers and the public in the public health decision-making process. Methodology is needed to help provide a clearer picture to decision-makers in the face of the uncertainty from delays in reporting.To address this issue and build on the foundational methodology [9, 10, 11] , a relatively recent literature around ""nowcasting"" has emerged for delayed reporting. In contrast to forecasting which focuses on estimating what could happen in the future, nowcasting focuses on estimating what has already happened but has not yet been reported. Nowcasting leverages historical patterns in reporting and trajectories of the disease outcome to estimate current counts given partially reported values. To enhance model flexibility and interpretability, recent work [12, 13, 14] has extended prior work for nowcasting time series [15] and aberration detection [16] within a Bayesian framework. This work has been applied to estimate COVID-19 deaths in regions of the United Kingdom [17] and to incorporate spatial dependence [18, 19] . In addition, simulation modeling approaches have also been used for nowcasting [20, 21, 22] . In contrast to much of the current epidemiological work that relies on the specification of splines to capture trends, Bayesian structural time series can be specified as hierarchical autoregressive processes [23] . Given the link between autoregressive processes and infectious disease dynamics, we propose a spatial extension of the Bayesian structural time series model to nowcast county-level counts of confirmed COVID-19 cases in Ohio while accounting for reporting delay.Despite prior and current literature on methods for accounting for reporting delay, these methods have not been fully embraced in practice. The purpose of this paper is to highlight the critical need to account for reporting lag and other potential daily reporting patterns when assessing whether case rates are increasing. This is important because an increase in case rates is an indicator in many states' alert systems, including the Ohio Public Health Alert System (OPHAS) [7] , and can also serve as an early warning signal of disease spread. We apply our method to OPHAS Indicator 2 which measures ""an increasing trend of at least 5 consecutive days in overall cases by onset date over the last 3 weeks"" [7] . Ohio adopted a 21 day ""look-back"" period in an attempt to manually curtail the effect of reporting delays. We develop an extension of a Bayesian structural time series model that incorporates spatial dependence across counties and flexibly captures temporal dynamics with an autoregressive structure. We use case data from earlier in the pandemic that is now fully reported so the true trends can be determined for each county in Ohio. We then compare indicators based on the method currently used in Ohio, the method suggested by the Centers for Disease Control and Prevention (CDC) [8] , and our Bayesian approach.We used data on confirmed cases of COVID-19 in the state of Ohio which are captured by the Ohio Disease Reporting System and reported publicly [24] . In Ohio, case investigation is done by local, typically county, health departments and entered into the state system. Confirmed cases are defined as individuals who have a positive result on a laboratory molecular amplification test [1] or other approved testing methods. For each individual case, the system records the county of residence and the onset date of illness as determined by case investigators. If onset date is unknown, the system records the earliest date associated with the record. Onset date currently provides the index date for all reporting and analysis at the state-level in Ohio. The reporting date is defined as the first date at which a case appears in the system and is often several days or possibly weeks after the onset date. Thus, when examining case counts by onset date, counts for the most recent days are incomplete because of the delay between onset date and reporting date. The reporting delay can also be impacted by system strains due to case volume and daily variation in reporting that differ by local health department.To explore the impact of reporting patterns on the calculation and subsequent interpretation of public health alert indicators, we retrospectively consider four points in time during the pandemic: June 15, 2020, July 15, 2020, August 15, 2020, and September 15, 2020. At the time of the analysis, at least one full month had passed since September 15, and we assume that case reporting was complete through this date. For each date, we examine cases reported by that date and compute indicators related to the trends in case counts. Since the data are completely reported, we can compare the estimates from the indicators to the true trend observed in the onset cases at that point in time. This will allow us to examine the performance of each proposed approach for determining if a county is experiencing an increasing trend of cases.We refer to the current approach for determining if case rates are increasing used by the Ohio Department of Health as the rolling average approach [7] . This approach computes a 7 day rolling average of case counts, indexed by onset date, for each of the last 21 days. The alert indicator for an increasing trend in cases is flagged if there are 5 consecutive days of increasing averages at any point in the 21 day window. That is, the indicator flags if for 5 consecutive days the average is greater than the average the day before. This approach crudely accounts for daily reporting variation by averaging across 7 days but makes no attempt to account for reporting lag or any other sources of variation.A slightly more sophisticated but still simple approach was recommended by the CDC for detecting rebounds [8] and will be referred to as the spline approach. This approach is similar to the rolling average approach described above but fits a spline to the time series of rolling averages. For consistency, we used 7 day rolling averages over a 21 day period to align with the temporal window of interest for the alert system. We fit a cubic spline [8] to each series with 4 knots. By using a spline, we are able to smooth daily and other systematic variation in reporting patterns. Aligned with the CDC [8] , we determine if there is an increasing trend by looking at the fitted values from the spline and determining if there are any 5 consecutive day periods where the fit for each day is greater than the previous day. Like the rolling average approach, uncertainty is not incorporated into the decision-making process. Splines were estimated using the mgcv package in R [25] .In contrast to the simpler approaches, we explicitly model both the process for new onset cases and the reporting delay process. We extend the general framework outlined by previous work [12, 18] by using an autoregressive spatial Bayesian structural time series, rather than a spline based model.While the spline based model is flexible, it relies on reasonably specifying knots and is not ideal for estimating beyond the range of the observed data. In addition, it can be more challenging to incorporate hierarchical structure when temporal trends may be quite different across locations, which has been the case for COVID-19. Instead, an autoregressive structure retains the ability to flexibly capture spatio-temporal trends while also linking more closely to the dynamics of infectious disease [26] . It also allows for added flexibility in specifying a spatially varying reporting delay process.We follow the general set up outlined in previous work [12, 16] . In Ohio, COVID-19 cases are reported daily so we use a daily time scale. To reduce computation time, we will take a moving window approach [14] that considers the past 90 days (T = 90). From April through September 2020, 94% of cases were reported within 2 weeks of onset and 98% of cases were reported within 30 days. To be conservative, we set a maximum reporting delay time of 30 days following onsetOutcome Model. Let Y it be the count of reported cases in county i = 1, . . . , N with onset date t = 1, . . . , T . Note that Y it is assumed to be the true total count, which is assumed to be partially observed for time t such that t + D > T . We assumewhere O i is an offset of the log population of county i, α it is the latent state of the process, X t is a design vector indicating the day of the week, and η i is the day of the week effect. Note that X t is parameterized using sum to 0 effect coding so α it reflects the average of the process across days of the week. By using this structure for the model, we are able to remove daily reporting variation from the latent state, α it , through X t η i .After removing the daily ""seasonal"" variation, we focus on the model for the latent state or structural part of the model. We use a semi-local linear trend model [27] to allow for some degree of longer term structure while still facilitating a very flexible model. That is for t > 1,α ) and the initial value at t = 1 is α i1 ∼ N (0, 100) . Then for the model for trend, we letwhere δ is a common statewide trend, d i is a county-specific spatial trend, and ρ δ is an autoregres-. A benefit to this parameterization is it allows us to separate changes that are due to white noise ( α it ) from those that are due to more consistent temporal trends (δ it ). By using a stationary model for δ, we are able to provide some structure around a longer term trend while retaining flexibility for local deviations in space and time.To account for spatial correlation, we assume the trends in neighboring counties are correlated and specify an intrinsic conditional autoregressive model. That is,where d −i is the set of counties excluding county i, w ij is an indicator of whether counties i and j are adjacent, w i+ = j =i w ij , and τ 2 d is a variance. To ensure a valid process model, we enforce a sum to 0 constraint on the d i [28] . We chose to incorporate spatial dependence in the trend to reflect a belief that cases in a county are likely to change in a similar fashion as cases in neighboring counties. This choice explicitly aligns with our general surveillance and risk evaluation strategy for counties where we have implicitly considered trends in neighboring counties when making our assessments. Another added benefit is that this helps to stabilize estimates for counties with small populations by borrowing strength from neighboring counties.We also assume county-specific effects of the day of the week. We assume that while variability exists between counties, the daily patterns are similar across the state. We assume the following hierarchical modelwhere η i is a vector of state average day of the week effects, τ 2 η is a variance, and I 6 is a 6 × 6 identity matrix. This allows each county to have its own daily pattern while borrowing strength across all counties in the state as warranted.Reporting Model. Since we know that Y it is observed with reporting lag, we must specify a model for the delay. Let Z itd be the count of cases observed in county i with onset date t that are observed d = 0, . . . , D days after t. Note that Z itd corresponds to when cases are reported d days after onset date t and so is unobserved when t + d > T . We assumewhere Z it = (Z it0 , . . . , Z itD ), p it is the vector of proportions of the total Y it reported on each of the D days, and GD is the generalized Dirichlet distribution. We use a generalized Dirichlet distribution to properly account for potential overdispersion of the p it [12] . This leads to the following conditional distribution:is set of counts reported with a delay that is not d days. To model more intuitive quantities, we reparameterize the distribution [12] in terms of the mean ν itd and dispersion φ d such that α itd = ν itd φ d and β itd = (1 − ν itd )φ d . Then similar to a hazard function, we let logit(ν itd ) = ψ itd and assume the following AR1 modelwhere β d is the average log odds of remaining cases being reported by delay d, V td is a design matrix indicating the day of the week, ξ i is a day of the week effect, ρ ψ is an autoregressive parameter, and ψ itd is an error term. We assume ψ itd iid ∼ N (0, τ 2 ψ ). Note that V td is parameterized using sum to 0 effect coding.The parameterizaton of the delay model allows us to accommodate several important features of COVID-19 reporting and should, in general, be customized to reflect the actual reporting process.First, reporting in Ohio is done by county health departments who may have varying capacity and resources for timely reporting. Thus, the delay model is county-specific. We account for day of the week effects, much like in the model for the case counts, because in many counties, reporting primarily aligns with the work week. We also assume autoregressive temporal dependence to capture the potential for administrative backlogs. For example, if a smaller portion of cases are reported today, we may also expect a smaller proportion the next day because of a backlog. We do not incorporate a term to account for spatial dependence in the delay model as we assume neighboring health departments are independent agencies, and so we would not anticipate spatial structure.As with the outcome model, we allow for county-specifc variability in day of the week reporting effects. We again assume similar patterns across the state and specify the following hierarchical model:where ξ is a vector of state average day of the week effects, τ 2 ξ is a variance, and I 6 is a 6 × 6 identity matrix.Prior Model and Computation. Since we fit our model in the Bayesian paradigm, we must specify prior distributions on all unknown parameters. For each element of η and ξ, we assign independent normal priors with 0 mean and variance 1. We also assign δ a normal prior with 0 mean and variance 1. We use a variance of 1 for these prior distributions as each parameter reflects a relative daily difference on the log scale, and so these priors reflect a reasonable range for those parameters. We assign β d independent normal priors with mean 0 and variance 4, which puts adequate probability on reasonable values on the logit scale. We also assign all variance parameters inverse gamma priors with shape and scale both set to 0.5. All autoregressive parameters are assigned uniform prior distributions over -1 to 1.To compare across approaches, we fit the model for each of the four dates considered. We treat the last day in the series (i.e., the current date) as missing and forecast the expected case count, which reduces model instability due to the rarity of cases reported on the day of onset (d = 0).The model was fit using a Markov chain Monte Carlo algorithm implemented in R using nimble [29] . The algorithm was run for 30,000 iterations with the first 15,000 discarded as burn-in and then thinned by keeping every 10th iteration. Computation time was approximately 20 hours, which would enable a daily update in practice.To determine whether the cases were increasing in the most recent 21 day period, we use the posterior distribution of δ it . Since δ it reflects the trend in county i at time t, there is a net increasing trend over the past 21 days if T t=T −20 δ it > 0. Using the posterior distribution, we can directly compute the posterior probability of an increasing trend for each county.One major advantage of a model-based approach is the flexibility to address more complex questions of interest. However, the goal of this paper is to assess the method used to calculate the OPHAS indicator for when cases are increasing in a county. To most closely align with the question as currently posed by the state of Ohio, we define a true increase in cases as when the number of cases in the most recent 7 day period is greater than the number of cases two weeks prior. While there are other potential ways to define a true increase, this most closely reflects the current definition used by the state of Ohio.The results from applying each of the three methods for calculating increasing case rates are shown in Figure 1 . There are several general observations that can be made across the four time points.The rolling average indicator generally does a poor job at accurately capturing counties where the cases have increased, and in most counties, there were true increases that went undetected. The spline indicator tends to make errors in the other direction by incorrectly flagging counties that did not meet the definition of a true increase. For the model-based approach, we generate a posterior probability of an increasing trend and highlight counties in yellow with a probability greater than 0.7 and in red those with a probability greater than 0.9.In addition to visually examining the results, we calculated sensitivity and specificity for each approach in Table 1 . The rolling average approach currently in use has a very low sensitivity of 0.20 and so is not successfully identifying counties with increasing trends. The spline approach has a much higher sensitivity of 0.87 but at the cost of a specificity of 0.48. Three cut points are shown for the model-based posterior probabilities. As expected, the higher thresholds exhibit excellent specificity but lower sensitivity since it reflects stronger evidence of an increase. Using a cut-point of 0.5, which reflects that the trend is more likely increasing than decreasing, we estimate The model-based approach also provides a rich set of additional results that can provide useful insights. Typically, the main goal of these models is to nowcast case counts. In Figure 2 , we show nowcast estimates with their 90% credible interval in black and the true counts in red for an urban and rural county. Averaging across the 4 time points, the 90% credible interval coverage was 0.96 over the 30 day period with incomplete reporting. The coverage was 0.92 in the most recent 7 days which have the most incomplete reporting. Thus, our model performs as expected for nowcasting cases. In Figure 2 , we also show time series plots of the latent state, which removes the daily seasonality, and the trend. The trend can also be viewed as the derivative of the latent state curve so when it is greater than 0, it indicates increasing case counts.We applied three approaches for assessing increasing trends in cases to completely observed data at four time points during the COVID-19 pandemic. When assessments are linked to onset date, case reporting is subject to reporting lag or delay. We illustrate that the simple approach currently used in OPHAS does not perform well as it fails to account for lag and other variation in reporting.The spline approach outlined by the CDC is more sensitive as it smooths over daily reporting variation but also fails to account for lag. In contrast, the model-based approach accommodates lag, daily variation, and spatio-temporal dependence. The model-based approach can also directly summarize observed evidence of increasing trends and the associated uncertainty through posterior distributions. This results in a better trade-off between sensitivity and specificity and can allow for prioritization of areas where the evidence of an increase is strongest.We note several key advantages to the model-based approach. First, the Bayesian approach allows us to use calculated posterior summaries to directly communicate uncertainty. Public health officials are constantly considering trade offs between different policy options -e.g., stay-at-home Since the posterior probability reflects the probability of an increasing trend given the observed data, this quantity can be used to directly address the policy question of interest and provides an indication of how strong the evidence is in each county. Unlike the spline or 7-day rolling average approaches that return a binary decision, the ability of the model-based approach to convey additional meaning through continuous estimates is a clear advantage that can improve decisionmaking [30, 31] . Second, by accounting for reporting delays and fully exploiting partially reported counts, the Bayesian approach can be more responsive to changing trends and provide earlier warning of changes in trends. Finally, the output from the Bayesian models (shown in Figure   2 ) provide important additional information that can be used by surveillance teams to understand trends over time. These results do require a team of epidemiologists to review the data, but still provide more information than the spline or 7-day moving average methods.When responding to a pandemic, it is important that the public health and policy response is guided by the best available information. Often even the best information can be incomplete and uncertain. However, statistical models have been developed to overcome these issues and aid in characterizing and quantifying uncertainty. These models are not as simple as the approach currently used in Ohio, and this is one limitation of this method. Risk alert systems should be transparent and easy to understand. Complex modeling approaches are difficult to explain to the general public and can lead to mistrust in the data and, by extension, the system as a whole. However, with proper preparation, the model output can be summarized to simply communicate the core messages, while leaving much of the complexity and technical details to the experts implementing the model. Additionally, the Bayesian models provide a wide range of information that can be used internally by epidemiologists and other public health data scientists to directly address important policy questions. Given the clear improvements our Bayesian models offer, it is imperative that we take advantage of these methodological advances to better serve the public and inform the distribution of limited resources.In conclusion, we have illustrated shortcomings in using simple approaches for public health decision-making. We have also illustrated how more sophisticated statistical models can account for the real-world complexities associated with surveillance data. Despite the added complexity, the output from these models can be summarized in a relatively simple and concise form that still appropriately reflects uncertainty. While we cannot eliminate all of the uncertainty in public health surveillance and decision-making, we must use approaches that embrace these challenges and deliver more accurate and honest assessments to policymakers.",United States,abstract,2021-02-08,02
d465b9896268eef7f0c5f39c5e45d395fca372b3,The EpiBench Platform to Propel AI/ML-based Epidemic Forecasting: A Prototype Demonstration Reaching Human Expert-level Performance,"As of writing this paper, a Google Scholar search for ""covid forecasting"" yields 14000 results. AI/ML conferences are seeing an increasing number of papers on epidemic forecasting, all of which lack a well-defined benchmark. While a researcher may compare their approach against a traditional modeling strategy such as SEIR (Hethcote 2000) , our experience suggests that the forecasts are highly sensitive to the implementation which requires deciding data pre-processing Copyright © 2021, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. and learning strategy. Consequently, ""SEIR modeling"" is only a part of the forecasting process, but itself cannot be considered a forecasting method to compare against; it only describes the epidemic process, but does not dictate how to pre-process the data and learn the model parameters, which are critical and non-trivial decisions. This is analogous to how one cannot simply compare against ""deep learning"" and must declare the structure of the network and the learning algorithm. Therefore, in the current state, performing an evaluation and claiming whether an AI/ML new approach is better or when one approach performs better than the other is not possible. There is a need to define the boundary by recognizing the state-of-the-art approaches so that new research can be conducted and verified to push the boundary.The existence of such benchmarks has propelled other fields in AI/ML. For instance, datasets like ImageNet (Deng et al. 2009 ) and CIFAR-100 (Krizhevsky, Hinton et al. 2009 ) along with methods like ResNet (He et al. 2016 ) and VGG-16 (Simonyan and Zisserman 2014) have created a standard against which new approaches need to be compared for Image Classification. Since the release of ImageNet in 2013, the accuracy has been improved from 51% to almost 90% as seen in Figure 1 . The Figure also shows an increasing interest in the task on that dataset over the years as an increasing number of ""other models"". Standard benchmarks have also propelled research in other fields such as Speech (Panayotov et al. 2015) and Graph Neural Networks (Hu et al. 2020) .We propose EpiBench a platform to bring the same benefits to AI/ML applied to epidemic forecasting. We are creating a platform for the community to engage in discussions regarding identification of critical modeling and learning decisions, a community-driven ensemble approach development, and identification of proper evaluation techniques. The platform will be easily extensible by the community in terms of adding new forecasting tasks and datasets. Finally, while EpiBench focuses on retrospective forecasting, i.e., forecasting when ground truth is already available, the approaches identified to be the state-of-the-art will benefit real-time forecasting efforts like Epidemic Prediction Initiative (CDC 2016) by the CDC, and other agencies around the world which drive the Government's response. In this paper, we make the following contributions:• We introduce a prototype of EpiBench which is currently running and accepting submissions for the task of fore- Figure 1 : Increasing interest in image classification over time with best performances over the years on ImageNet (Stojnic and Taylor 2020 We emphasize that this paper is not intended to demonstrate a fully-fledged benchmarking platform, nor to show that a new forecasting method is superior. Instead, the intention is to demonstrate the need for such a platform and results from a prototype as stated above in the contributions, that indicate the potential of the envisioned platform.We first describe some recent platforms that have emerged for submissions and evaluations of COVID-19 forecasts and draw a contrast from our goal.The COVID-19 forecasting hub (Ray et al. 2020 ) keeps a ""live"" record for forecasts of COVID-19 in the US, created by more than 30 leading infectious disease modeling teams from around the globe, including ours, in coordination with CDC. Every week the teams submit their latest forecasts for the number of cumulative and/or incident cases and deaths for US states, counties, and at the national level. The forecasts are reported at a weekly granularity for the upcoming Sundays. This ensures that the periodicity in reporting does not affect the evaluation. Furthermore, daily forecasts are not being used or being communicated (Ray et al. 2020 ). The submitted forecasts may be considered real-time expert forecasts, although, they may not qualify as an AI/ML methodology, although parts of forecast generation may use AI/ML. First, the forecasts represent the submissions by a team and not necessarily by a particular method -the teams are allowed to change their methods. While this platform is useful to provide the best guess of the experts in real-time (as an epidemic is unfolding), due to varying methodologies over different periods of time, it does not provide any insight into which methods work and when. A comparison of a new methodology against the existing submissions will lead to misleading conclusions. For instance, suppose a new methodology computes its errors at different points in time and compares against the errors of a particular team's submission from the forecast hub (see Figure 2 ). From this comparison, one may falsely conclude that the new methodology is better. However, the submitted forecasts may be produced by three different methodologies over time, one of which when used for retrospective forecasts may produce better results. Further, many submissions are tuned by the experts for every submission, through trial-and-error, visual inspection, and may derive knowledge from other sources that can evolve over time. Such methods may not classify as an AI/ML method as they require significant human involvement and will not scale to a large number of time-series. Yet, the submitted forecasts provide a collection of baselines that may be used as performance points representing the realtime expert forecasts, without the claim of one method being better than the other.Epidemic Prediction Initiative While the COVID-19 forecasting hub has received a lot of attention recently, it is a part of the Epidemic Prediction Initiative (EPI) by the CDC (CDC 2016). EPI aims to improve the science and usability of epidemic forecasting by facilitating open forecasting projects and challenges. EPI provides access to some data and defines a metric with which the forecasts are going to be evaluated. EPI has several forecasting challenges including COVID-19, Aedes, West Nile Virus, Dengue, and Influenza. When deciding on the state-of-the-art methodology and comparing a new approach against an existing one, EPI suffers from the same issues as the COVID-19 forecast hub. EpiBench will complement the efforts of EPI and COVID-19 forecast hub-like initiatives by benchmarking methodologies instead of the comparison of teams while utilizing similar data and expertise from the community. The existing initiatives will continue to assist ongoing epidemics through the collective wisdom of the experts, while EpiBench will provide a platform for ""retrospective"" forecasting to compare and learn from and encourage the development of new AI/ML methods.Existing Evaluations for COVID-19 Particularly, for COVID-19, some teams who regularly submit their forecasts to the CDC have been performing periodic evaluations of all the submissions. For example, Youyang Gu evaluates week-ahead predictions for cases and death for county, state, and national level forecasts for the US 1 using mean absolute error (Willmott and Matsuura 2005) . The team Caltech-CS156 2 evaluate daily death forecasts over 7-day period and weekly forecasts. Steve McConnell 3 performs a detailed evaluation of death forecasts of all the submitted models using a number of metrics that address the drawbacks of the traditional evaluation metrics. A forecast hub for Germany and Poland also evaluates submitted forecasts 4 for countrylevel cases and deaths, although they seek submissions of Admin1-level (state) as well. A detailed comparison of publicly available death forecasts for countries around the world is tracked by Covidcompare 5 . Our own evaluations are available on our webpage 6 , where we present mean absolute errors over time for all the methods submitted to the CDC for US state-level case and death forecasts, and for those submitted to Poland+Germany forecast hub for country and admin1-level case and death forecasts.The fundamental difference between these evaluations 1 https://github.com/youyanggu/covid19-forecast-hubevaluation 2 http://cs156.caltech.edu/model/compare.html 3 https://github.com/stevemcconnell/covid19-forecastevaluations 4 https://jobrac.shinyapps.io/app evaluation/ 5 http://covidcompare.io 6 https://scc-usc.github.io/ReCOVER-COVID-19/#/ leaderboard and our goals is that they compare the performance of forecasters rather than AI/ML methods. This is because (i) not all forecasts are generated using AI/ML approaches, (ii) forecasts may be manually tweaked before submission by a human-expert, and (iii) over time forecasters may keep changing their methodology. While such evaluations are crucial for understanding where each team stands every week as the epidemic unfolds, it provides us with no insight on what methods work well and thus does not add to our understanding of how epidemic forecasting can be improved without human intervention.EpiBench aims to enable AI/ML research in epidemic forecasting that currently has a big hurdle of lack of proper benchmarks. It will create a platform for sustained research in improving AI/ML methods as well as our understanding of which technique works when. Before we proceed, we clarify what qualifies as AI/ML in this context.We define an AI/ML approach or methodology as a technique that is a self-contained algorithm/code that does not rely on human intervention for generating different forecasts within the same task and has no foresight, i.e., does not use information/data that was available after the date at which the forecast is being generated. For instance, suppose, the task is to forecast the number of deaths in the US states due to COVID-19 in the next 5 weeks of every Sunday in the period of April to October. Let M be a fixed function determined by the AI/ML methodology. Then for any date t i in the period, with the version of historical data D i as it was seen on t i , the generated forecasts should be M(D i ), without any additional inputs. Any change in the methodology, including simple data pre-processing change, is considered to lead to a different methodology. Further, M should not have any direct dependence on the t i . This excludes explicit programming of using one methodology for an interval and a different one for another. Any approach that does not qualify based on the above but does not use any foresight will be considered human expert forecasts. While the state-of-theart will be defined by AI/ML methods in EpiBench, human expert forecasts will also be included to indicate human expert performance. Submissions in COVID-19 forecast-hub and EPI will be considered under this category.We focus on advancing AI/ML approaches as the immediate target for EpiBench because AI/ML approaches are more scalable. There are more than 3000 counties in the US for which the data is readily available. Google COVID-19 Open Data Initiative 7 provides epidemiological data for around 20,000 locations. Due to the global crisis experienced worldwide during COVID-19, we envision that more data will be available for the future epidemics, resulting in a large number of time-series infeasible to be manually analyzed. Therefore, there is a need for AI/ML-driven fully automated approaches and a platform for proper evaluation and to set up the community for the following innovations, which will be enabled by EpiBench.We have developed an early prototype of EpiBench called COVID-19 forecast-bench (Srivastava and Xu 2020) for the task of COVID-19 case and death predictions in the US states and counties. It keeps a daily record of the versions of case and death time-series as reported by JHU CSSE COVID-19 Data (Dong, Du, and Gardner 2020) . The submitting teams are requested to provide details of their methodologies, particularly regarding data pre-processing, modeling technique, and learning strategy. It is clarified that even changing a simple decision like the smoothing window qualifies as a different methodology. We have already received 3 AI/ML methods excluding several of our own. We have also included more than 30 methodologies (human expert-driven) pulled from the COVID19 forecast-hub (Lab 2020) . Currently, we are providing evaluations for 1-, 2-, 3-, and 4-week ahead forecasts using mean absolute error (Willmott and Matsuura 2005) : For each predictionŷ i corresponding to the ground truth y i , i ∈ {1, . . . , n}, mean absolute error (MAE) is defined as:For the prototype, we define the ground truth as the positive cases and deaths timeseries reported in the latest version of JHU CSSE COVID-19 Data. It is known that this data changes over time, due to back correction (Dong, Du, and Gardner 2020) . Therefore, the latest version of the data is the best known approximation of the true targets (positive cases and dates) for a prior date.One advantage of having retrospective forecasts with various methodologies is to be able to design intelligent ensemble techniques. On the other hand, the ensemble approach of the forecast-hub is limited to taking the average of individual submissions (Ray et al. 2020 ). This is due to the fact that the submissions by individual teams do not stick to the same methodology and involve human decision making. Therefore, learning a model treating the past submissions as predictors is not useful as the nature of the predictors keeps changing. 7 https://github.com/GoogleCloudPlatform/covid-19-open-data Constituent Methodologies as ""Predictors"" To demonstrate the utility of retrospective forecasts in ensemble development, we use variations of our SIkJα approach (Srivastava, Xu, and Prasanna 2020). This approach models the epidemic as a discrete-time process with temporally varying infection and death rates. The model considers many complexities such as unreported cases due to any reason (asymptomatic, mild symptoms, willingness to get tested), immunity (if any) or complete isolation, and reporting delay, and yet, it can be reduced to a system of two linear equations which can be fitted one after the other resulting in fast yet reliable forecasts. The forecasts are performed by smoothing the data, learning the parameters by fitting the reduced model, and then simulating the model into the future using these learned parameters.We use three variations of our SIkJα approach for the task of predicting deaths in the US states over the period of July to October:• SIkJα smooth14 un10 hyper7: This indicates that the input data was set to smooth over 14 days, the underreporting factor was set to 10 (this input has little effect on short-term forecasts (Srivastava, Xu, and Prasanna 2020)), and the hyper-parameters were learned on a heldout validation data of the last 7 days.• SIkJα smooth7 un10 hyper7: This indicates that the input data was set to smooth over 7 days.• SIkJα window noval: This indicates that the input data was set to smooth over 14 days and the hyper-parameters were learned by fitting on a window of the past few days (itself treated as a hyper-parameters) without a separate validation set.Each of the above has advantages and disadvantages. SIkJα smooth14 un10 hyper7 is able to avoid noise by smoothing over a large window, while it may over-smooth a newly emerging pattern which is better detected by SIkJα smooth7 un10 hyper7. Having a small validation set as in these two approaches helps identify hyper-parameters during changing trends. However, this may also overfit, and during stable trends picking the hyper-parameters based on fitting over a large window could be better. Note that our SIkJα is fast (≈ 4s for all US states per run), and so we are able to quickly generate different sensible variations. Next, we will use the results of these methodologies as the constituent predictors in the ensemble.We wish to utilize the individual predictors to improve the forecasts. We generate the forecasts using each of the above on each Sunday using the version of the data that was available on that day, for a period of July-Oct and use them as input predictors in a Random Forest (Meinshausen 2006) . Additionally, it takes the cumulative and incident deaths that week and the incident deaths on the previous week as inputs. The objective is to find a regression model that can consider the outputs of the above three approaches and the recent trend, and ""readjust"" them to reduce error in the future. The Random Forest was implemented using the Matlab TreeBagger function with 100 trees 8 . For each Sunday, the Random Forest was trained using the outcomes in the last two weeks for which ground truth is available. For 4-week ahead forecast, this would mean training on the forecasts generated 4-5 weeks ago by the three approaches listed above. The code to reproduce our results is available in the forecast-bench repository 9 . Figure 3 shows the errors obtained on 4-week ahead predictions as a function of the date of releasing the forecast. The ground truth is the latest version of the death time-series available from JHU CSSE (Dong, Du, and Gardner 2020) . We compared our ensemble approach to the following: • The individual constituent AI/ML approaches:These are shown in dark dashed lines and include SIkJα smooth14 un10 hyper7, SIkJα smooth7 un10 hyper7, and SIkJα window noval. • Top human-expert forecasts submitted to the CDC: These are shown in blurred dashed lines and include submissions from YYG Paramsearch, LNQ ensemble, Oliver Wyman Pandemic Navigator, Steve McConnell CovidComplete, UCLA SuEIR, and our own submission USC SIkJalpha, all of which are available on the forecast-hub. We have also included a version of our model that appears on our Github repository 10 and may differ slightly from our submissions to the forecast-hub. • COVID Hub Ensemble: This is the ensemble (average) of all the submitted forecasts shown in solid dark line. This has been shown to perform better or on par with individual submissions (Ray et al. 2020) . We observe that our ensemble (dark solid purple line) results in a lower error compared to the constituent AI/ML approaches (dark dashed lines). It has a competitive performance with the forecast-hub ensemble and outperforms it consistently over the last few weeks. We emphasize that our ensemble has no human intervention and the whole process from loading the data to producing the forecasts is fully automated. This demonstrates that our ensemble can utilize AI/ML approaches to achieve human-expert level performance. We envision that the ensemble error will further reduce through the inclusion of more AI/ML-driven forecasts.It is to be noted that we do not claim that our ensemble approach is the best AI/ML-based epidemic forecasting approach because such a claim will require more AI/ML methodologies to be included. This is precisely where EpiBench will make an impact by providing a platform for new methodologies to compare against existing ones under a uniform evaluation protocol.Going from data to forecasts requires many decisions that can influence the accuracy. These include, but not limited to, the following: • Data pre-processing: Whether to smooth the data over 7 days or 14 days, picking a rule to declare a point anomalous and a rule to replace anomalous data points. • Choice of modeling: Whether to use an SEIR model, a deep learning model, or an ARIMA model. • Learning strategy: Whether to use Bayesian learning, least square regression, or gradient descent. • Hyper-parameter setting: Specific structure of the neural network, size of the window to consider, or a forgetting factor/weighted least square to only account for the latest trends. Each of the above decisions may lead to different outcomes. Despite the plethora of work in forecasting this year, it is not known which of the above decisions are more critical. As an example, consider the two dark lines (green and purple) in Figure 4 plotted against the blurred lines corresponding to the performance of submissions at the COVID-19 forecast-hub. The two dark lines (green and purple) show a significant difference in their performance, yet the two methodologies are identical with the exception that one of them smooths the data over 14 days and the other over 7 days. Many other approaches perform in the middle of the two while being very different methodology-wise as they use deep learning or Bayesian learning as opposed to our regression approach. This may indicate that for this task, the outcome is more dependent on data pre-processing rather than the choice of the learning strategy. Such an observation can accelerate the computation as regression can be performed much faster than Bayesian learning, and also, it can direct the research in improving data pre-processing and noise filtering which may be more critical for this task and similar tasks of the future. Figure 5 shows the distribution of errors obtained by a method over different days of the week. The plot indicates that there can be a significant difference in performance based on when the forecasts are performed. Again, this suggests that there may be some simple decisions, often overlooked, that affect the outcome. While we have performed these analyses only on variations of our own model SIkJα, it is likely to be the case for other models as well. This is supported by the fact that many of these submitted forecasts claim to use SEIR model 11 , yet they produce drastically different outcomes. This reinforces our claim that decisions beyond the choice of a model are critical in producing accurate forecasts. EpiBench will enable us along with the research community in identifying which decisions are critical by presenting the evaluation of many different methodologies and identifying them based on specific decisions they make to arrive at their forecasts. We wish to leverage EpiBench to start a discussion that will expose the advantages and drawbacks of various metrics and identify a set of metrics for point, interval, and probabilistic forecasts to provide a uniform evaluation protocol. We are planning to initially use the following well-known error metrics, categorized with respect to the type of forecast output.Point forecasts refer to the forecasting of one number for each ground truth of the future, such as predicted number of new cases on a future date and declaring a future date when the peak is expected to happen. For such forecasts we will use mean absolute error (MAE) defined for each prediction y i corresponding to the ground truth y i , i ∈ {1, . . . , n} and a variation of mean percentage absolute error called symmetric MAPE or SMAPE (O'Connor and Lawrence 1998):(2)Variations of both MAE and MAPE are widely used in time-series forecasting (Chatfield 2000) . Particularly, MAE is the evaluation preferred by the CDC for point forecasts (CDC 2016) .Probabilistic forecasts refer to the forecasting of a probability distribution for ground truth of the future, i.e., assigning a probability to each discrete possibility. For such forecasts, we will initially use a log score (Gneiting and Raftery 2007) which is used by the CDC to evaluate real-time submissions of Flu forecasts (CDC 2016).where P (E i ) is the probability assigned to the event E i that is observed in the ground truth. If the assigned probability is so low that ln P (E i ) is less than −10 or undefined, it is replaced by −10. This ensures that one significantly poor score does not affect the average. A higher score is preferred.Interval forecasts refer to the reporting of a range with a confidence interval suggesting the likelihood of the true value falling in the range. One way to evaluate prediction intervals is ""coverage"" (Ray et al. 2020 ) that measures the percentage of time the observed value falls in the provided interval for given confidence (such as 95% confidence interval). Other ways of evaluating interval forecasts and more generally quantile forecasts while penalizing long ranges also exist in the literature (Gneiting and Raftery 2007) .While the above-mentioned metrics have been widely used in epidemic forecasting and time-series forecasting, none of them are unanimously accepted to be the best metric, and each one suffers from drawbacks. For instance, aggregating errors using MAE may lead to assigning a low error to a result that intuitively is worse (see Figure 6 ). We will perform a detailed study of drawbacks of the initial metrics, and engage the community in the design and selection of future evaluation metrics.Expanding from our prototype which is in the form a GitHub repository, We plan to create an infrastructure consisting of a website, a GitHub organization and a Slack workspace. The user will be able to perform the following actions using the EpiBench platform:• View current evaluations for submitted models and a list of state-of-the-art based on various metrics for different epidemic forecasting tasks on the EpiBench website. • Upload a set of forecasts for evaluation through a Git pull request to the appropriate repository in the collection. A link to the proper repository will be available on the EpiBench website. • Download code for evaluation and top among the previously submitted forecasts available on our GitHub. This top subset determines the state-of-the-art based on a selected evaluation metric and helps the download and repository maintenance easier by limiting the size. • Access all the submitted forecasts through a Google Drive link on the website. • Participate in discussions on specific code/repository by opening a ""GitHub Issue"". Also, discussion on evaluation metrics, new forecasting tasks will be facilitated through Slack (sla 2020). • Upload code for execution to reproduce results and to run the code on more datasets.We have demonstrated a prototype of EpiBench, a platform planned to provide a benchmark to compare AI/ML methodologies for epidemic forecasting against each other and against human-expert forecasts. We aim to define the state-of-the-art using EpiBench which will help the AI/ML community to push the boundary. Having various AI/ML methods can also lead to robust and accurate ensemble forecasting. We show that using our own AI/ML approaches (fully automated, no human intervention) in the prototype, we are able to develop an ensemble that matches an ensemble of human expert-level performance on COVID-19 death forecasting in the US states. Moreover, EpiBench can help us identify which decisions (data pre-processing, modeling choice, learning strategy, hyper-parameter tuning, etc.) in the forecasting approach are critical in epidemic forecasting and help direct the research accordingly. In the prototype, we have shown that the forecasts may be highly sensitive to data pre-processing. This relates back to the ensemble development as we were able to utilize the forecasts from different data pre-processing (smoothing) and hyper-parameter tuning methods to obtain significant improvements in the ensemble without altering the choice of modeling or learning strategy.In the future, we wish to expand EpiBench to various epidemic forecasting tasks. The platform will be available to the AI/ML researchers and epidemiologist through (i) the EpiBench website for viewing current evaluations of AI/ML approaches and a list of state-of-the-art based on various metrics for different epidemic forecasting tasks; (ii) a GitHub organization with repositories for uploading forecasts for evaluation and downloading evaluation code and previously submitted forecasts; (iii) a Slack workspace for community discussion on evaluation, new forecasting tasks, and dissemination of updates.",USA,first author,2021-02-04,02
75310c532d1463ebcbc7806278894cba880a7896,A Tale of Three Datasets: Towards Characterizing Mobile Broadband Access in the United States,"Affordable, quality Internet access is critical for full participation in the 21st century economy, education system, and government [24] . Mobile broadband can be achieved through commercial Long-Term Evolution (LTE) cellular networks, which are a proven means of expanding this access [13] , but are often concentrated in urban areas and leave economically marginalized and sparsely populated areas underserved [6] . The U.S. Federal Communications Commission (FCC) incentivizes LTE operators serving rural areas [7, 23] and maintains transparency by releasing maps from each operator showing geographic areas of coverage [9] . Recently third parties have challenged the veracity of these maps, claiming these maps over-represent true coverage, and thus may discourage much-needed investments.Most of these claims, however, are either focused on limited areas where a few dedicated researchers can collect controlled coverage measurements (e.g., through wardriving), or are mainly qualitative in nature [1, 14, 25] . As dependence on mobile broadband connectivity increases, especially in the face of the COVID-19 pandemic, mechanisms that quantitatively validate FCC coverage datasets at scale are becoming acutely necessary to evaluate and direct resources in Internet access deployment efforts [17, 22] . This is an issue of technology and technology policy, with equity and fairness implications for society.An increasingly widespread approach to measure coverage at scale is through crowdsourcing wherein users of the LTE network contribute to coverage measurements. The FCC has recently advocated for the use of crowdsourcing to validate coverage data reported by operators [19] . In this context, we take a data-driven, empirical approach in this work, comparing coverage from a representative crowdsourced dataset with the FCC data. More specifically, our analysis is guided by the following questions: (i) How consistent are existing LTE coverage datasets, ii) where and how do their coverage estimations differ, and what trends are present?We specifically consider a crowdsourced coverage estimate from Skyhook, a commercial location service provider that uses a variety of positioning tools to offer precise geolocation. We select Skyhook because it crowdsources cellular coverage measurements from end-user applications that subscribe to its location services. Such incidental crowdsourcing can potentially provide richer coverage data compared to a voluntary form of crowdsourcing where a user has to explicitly commit to contributing coverage data. We examine this by comparing the Skyhook measurements with those of OpenCellID, an open but voluntary crowdsourced dataset [21] . As will be shown in Section 3.1, we find that the density of the crowdsourced datasets varies significantly by the methodology of data collection, especially in rural areas. In the regions we studied, incidental crowdsourcing (Skyhook) gathered up to 11.1x more cell IDs than voluntary crowdsourcing (OpenCellID).Using Skyhook as an extensive crowdsourced dataset, we quantify how widely and where the crowdsourced coverage data differs from the FCC data. We specifically focus on the state of New Mexico 1 , selected for its mix of demographics, diverse geographic landscape, and our partnership with community stakeholders within the state. We compare coverage at the level of census blocks 2 which are further grouped into urban, rural, and tribal 3 categories. We find that the FCC and Skyhook LTE datasets have a disagreement as great as 15% in rural census blocks with the data from FCC claiming higher coverage than Skyhook. A major concern in interpreting this comparison is accounting for coverage disagreement as a result of lack of data points in the crowdsourced dataset. To confirm the availability of users to provide data points, we check for the presence of alternate cellular technologies (e.g., 2G or 3G) within these census blocks and observe a significant number (up to 9% in tribal rural areas) where such alternates are present, providing evidence that users do visit those blocks but cannot access LTE. These results, similar to a recent study on fixed broadband [18] , suggest a need for incorporating mechanisms to validate the operator-submitted data into the FCC's LTE access measurement methodology, especially in rural and tribal areas.Finally, we compare both FCC and Skyhook coverage maps to our own controlled coverage measurements collected from a northern section of New Mexico. Interestingly, we find that both FCC and Skyhook datasets report higher coverage relative to our controlled measurements with the former showing a higher degree (by up to 26.7%) of over-reporting than the latter. Understanding the causes of these inconsistencies is important for effectively using crowdsourced data to measure LTE coverage, especially as crowdsourcing is increasingly viewed as preferable to provider reports. We 1 Our methodology is not specific to New Mexico and can be easily extended to other regions in the U.S. 2 We use the FCC methodology wherein a census block is considered covered if the centroid is covered [8] 3 Tribal areas have consistently experienced the lowest broadband coverage rates in the United States for the past decade [6] conclude with recommendations for improving LTE coverage measurements, whose importance has only increased in the COVID-19 era of performing work and school from home.In this section, we first provide an overview of the LTE network architecture. This is followed by a description of the LTE coverage datasets compared in our analysis. These datasets are summarized in Table 1 . We also note the limitations associated with each data collection methodology.Internet access in an LTE network is available through base stations (known as eNodeBs) operated by the network provider. User equipment (UE), such as smartphones, tablets, or LTE modems, connects to the eNodeB over the radio link. The eNodeB is connected to a centralized cellular core known as the Evolved Packet Core (EPC). This connection is typically through a wired link forming a middle-mile connection. The EPC consists of several network elements including a Packet Data Network Gateway (PGW), which is the connecting node between an end-user device and the public Internet. Thus, LTE broadband access depends on multiple factors including radio coverage, middle-mile capacity, and interconnection links with other networks (e.g., transit providers, content providers) in the public Internet. However, the focus of this article is on understanding the last-mile LTE connectivity characterized by the radio coverage of the eNodeB.An eNodeB controls a single cell site and consists of several radio transceivers or cells mounted on a raised structure such as a mast or a tower. The radio cells use directional antennas, where each antenna provides coverage in a smaller geographical area using one frequency band. The radio cells can be identified through a globally unique number called cell identifier (or cell ID), which is also visible to an end-user device in range of the cell. The cell ID enables aggregation of connectivity and signal strength information from multiple UEs connected to the same cell, which can then be used to estimate the geolocation of a cell along with its coverage (see Section 2.3).The FCC LTE broadband dataset consists of coverage maps in shapefile format that depict geospatial LTE network deployment for each cellular operators in the U.S. The FCC compiles this dataset semi-annually from operators through Form 477. Every operator that owns cellular network facilities must participate in this data collection. The operators submit shapefiles containing detailed network information in the form of geo-polygons along with the frequency band used in the polygon and the minimum advertised upload and download speeds. The methodology used for obtaining these polygons is proprietary to each operator. Ultimately, the FCC publishes only a coverage map that represents coverage as a binary indicator: in any location, cellular service is either available though an operator, or it is not.We use the binary coverage shapefiles, available on the FCC's website, from June 2019 4 . Figure 1 shows the eight LTE network operators present in the state of New Mexico (NM) and the percentage of total census blocks in NM covered by each operator. Note that we use one of the FCC methodologies to report mobile broadband access, wherein a census block is considered covered if the centroid of the census block is covered [8] . In this paper, we limit our analysis to the top four cellular operators due to their significantly greater prevalence in NM; these operators are also the top four cellular operators in the United States more broadly. Limitations: These coverage maps are generated using predictive models that are proprietary to the operator [12] and not generally reproducible. Furthermore, the publicly available dataset consists of binary coverage and lacks any performance-related data. 5 Skyhook is a location service provider that uses a variety of positioning tools, including a database of cell locations, to offer precise geolocation to subscribed applications [26] . Through apps that subscribe to Skyhook's location services, user devices report back network information, which is gathered into anonymous logs and used to further improve the localization service. Through a data access agreement we are able to view the cell location database consisting of a list of unique cell IDs along with the cell technology (e.g., 3G vs LTE), estimated location, and the estimated coverage. The database was originally constructed through extensive wardriving but is now managed and updated using measurements gathered by devices using the Skyhook API for localization. The device measurements with the same cell ID are combined to estimate the cell location and coverage in the following manner: Cell location estimation: A grid-based methodology similar to that proposed by Nurmi et al. [20] is used to estimate the cell tower location. Specifically, Skyhook divides the geographic area into 7 m squares and groups measurements in the same square to obtain a central measure of the square's signal strength. This is done to reduce the bias due to large numbers of measurements coming from the same area (e.g. a popular gathering place). A weighted average of the signal strength is then used to estimate the cell location. Estimation of cell coverage radius: Skyhook also provides an estimate of the cell's coverage radius using a proprietary method based on the path-loss gradient [27] . The path-loss gradient approximates how the wireless signal attenuates as a function of the distance from the transmitter (radio cell in this case). The value of the path-loss gradient depends on several factors such as environment (foliage, buildings), geographic topography, and cell signal frequency. Skyhook estimates the path-loss gradient using field observations of cell signal strength readings along with their distributed geographic locations. Ideally, the signal attenuation varies based on the direction and the distance from the cell. However, to reduce the complexity of coverage estimation, Skyhook's cell coverage estimation heuristic calculates only one path-loss gradient for a single cell. The path-loss gradient is then used in a set of parameterized equations to estimate the cell coverage radius. The parameters in these equations have been determined with careful research and testing over more than 10 years.The cell location database is updated regularly with recalculation of cell location and cell coverage radius using the new device measurements that have been collected since the last update. For our analysis, we use the cell location database last updated on June 10, 2019.Limitations: Since database entries are crowdsourced when the device passes within range of a cell, this dataset is more comprehensive in population centers and highways where people more often occupy. If there are too few measurements overall, or if measurements are primarily sourced from the same grid section, then the cell location estimate can be inaccurate.To complement these datasets, we performed a targeted measurement campaign collecting coverage information through 120 miles of Rio Arriba county in New Mexico over a period of five days beginning May 28, 2019. Figure 2 shows the locations of ground measurements and the four descriptive area labels we use for this analysis. The North area measurements were taken on highways passing primarily through national forest. The Pueblo area measurements were taken from highways within tribal jurisdiction boundaries. In Santa Clara Pueblo, tribal leadership permitted us to collect additional measurements in residential zones. Finally, the Santa Fe area consists of highway measurements between the pueblos and downtown Santa Fe. While limited in scale, these active measurements provide an important comparison point for coverage and user experience. As described in Section 1, we selected these areas of New Mexico for their mix of tribal and non-tribal demographics; tribal lands tend to have the highest coverage over-statements and the most limited cellular availability within the United States [6] .Our measurements consist of service state and signal strength readings recorded on four Motorola G7 Power (XT1955-5) phones running Android Pie (9.0.0). Service State is a discrete variable indicating whether the phone is connected to a cell. Measurements were collected using the Network Monitor application [16] . An external GlobalSat BU-353-S4 GPS connected to an Ubuntu Lenovo ThinkPad laptop gathered geolocation tags that were matched to network measurements by timestamp. Each phone was outfitted with a SIM card from one of the four top cellular operators in the area: Verizon, T-Mobile, AT&T, and Sprint. The phones recorded service state and signal strength every 10 seconds while we drove at highway speeds (between 40 and 65 miles per hour) in most places and less than 10 miles per hour in residential areas (Santa Clara Pueblo). Limitations: Our wardriving campaign was intensive in terms of human effort, economic cost, and time, making it difficult to scale. The dataset does not capture any temporal variations in coverage as the measurements were collected over a short span of time. It is possible that driving speed or device configuration affects the measurements, e.g., indicating no coverage when a stationary measurement might have detected coverage [10] . We have no evidence that this occurred, but it might warrant some additional investigation.In this section, we first evaluate of Skyhook as a representative crowdsourced dataset by comparing it with a popular voluntary crowdsourced data from OpenCellID [21] . This is followed by comparison of coverage across the FCC, Skyhook, and our wardriving measurement data. Our comparison is guided by the following questions: (i) what is the degree of coverage agreement across the datasets, ii) where and how do their coverage estimations differ?We compare the Skyhook dataset with a publicly available crowdsourced dataset -OpenCellID. Unwired Lab's Open-CellID 6 project provides a publicly available dataset of cell IDs along with their estimated location. The dataset is derived from crowdsourced UE signal strength measurements similar to Skyhook. However, the UE measurements in this case come from users voluntarily installing the OpenCellID application on their smartphone [21] and manually choosing what data to upload. We differentiate this voluntary crowdsourcing method of data collection from Skyhook's incidental crowdsourcing method, where users of the Skyhook API contribute to the data by default. We specifically compare the number of unique LTE cells and the recentness of the measurements in both datasets. We consider each of these factors to contribute to the overall density of the dataset. Methodology: While our coverage comparison will be focused on New Mexico, we analyze our selected crowdsourced data more broadly by considering these datasets within a set of counties of differing population densities across the United States. The counties are selected from three areas of the United States: Western (California), Central (New Mexico and Colorado), and Eastern (Georgia). Within each region, we consider three different kinds of counties as defined by the National Center for Health Statistics' 2013 Urban-Rural Classification Guide [3] . These are: (i) large metropolitan (large), which contain a population of at least one million and a principle city; (ii) small metropolitan (small), which contain a population of less than 250,000; and (iii) micropolitan (micro), which must have at least one urban cluster of at least 10,000, but a total population of less than 50,000. This enables us to study differences based on population density and geographic region for the crowdsourced datasets. We select three counties of each population category, for a total of nine counties, to compare these two datasets. We describe these counties in Table 2 . For each county, we show the 2018 population density estimated from the U.S. Census Bureau's 2010 census records [2] . We first count the number of unique cell IDs that appear in both datasets for each county, as shown in Table 2 . The ""% Overlap"" column in Table 2 shows the percentage of each dataset's cell IDs that also appear in the other dataset, and the ""Common CIDs"" column shows the exact number of common cell IDs. Results: Overall, Skyhook reports a greater number of cells (2.8x -11.1x) for all counties. The difference is particularly pronounced in micro counties. This suggests that relying on volunteers to download an application and offer network measurements may not be the most accurate method for assessing LTE coverage in rural areas. Furthermore, Skyhook includes a majority of the cells that appear in OpenCellID.We next consider how recently each cell ID record was updated with a new measurement. Figure 3 shows the CDF of the latest measurement date for cells in both the datasets, where cells are split into those located in urban and rural census blocks. Almost 60% of the cells in Skyhook were last updated in the month of June 2019, but the most recent update in OpenCellID was in February 2019. Furthermore, cells in rural census blocks were updated less recently than urban census blocks in OpenCellID, while the difference is negligible in the Skyhook dataset. This suggests that the Skyhook dataset is updated more regularly than OpenCellID, thus making it more likely to represent any changes in the network infrastructure.We first compare a coverage shapefile generated from Skyhook cell locations and estimated coverage ranges with the FCC map for each operator. Methodology: We consider coverage at the census block level for this comparison. In addition to reporting coverage shapefiles, the FCC reports coverage at a census block level and considers a census block as covered if the centroid of the census block falls within a covered region [8] . We generate a similar census block level coverage map per-operator using Skyhook's estimated coverage. To do so, we first obtain the coverage shapefile for each operator using a cell's estimated location and coverage radius. Then we use the FCC centroid methodology to generate the Skyhook LTE coverage map at the census block level. We use the Python GeoPandas 0.8.2 library for the associated spatial operations [11] . We group census blocks into four categories: Non-Tribal Urban, Non-Tribal Rural, Tribal Urban, and Tribal Rural. This is done to explore whether the degree of agreement of the two datasets varies across these dimensions. We use the U.S. Census Bureau's classification of urban and rural blocks and its boundary definitions of tribal jurisdiction for this categorization [4] . In this analysis we consider census blocks as tribal if they overlap with any tribal boundaries. We varied the tribal labeling schemes such as classifying a census block tribal if the centroid of the block is within a tribal boundary. However, the results remain qualitatively similar and do not impact the findings presented here. Results: Table 3 relatively higher coverage for both tribal and non-tribal urban census blocks. However, all operators except Verizon offer their lowest coverage in tribal rural areas. For some operators, the differences between non-tribal rural and tribal rural are as great as 23% (based on Skyhook data) and 11% (based on FCC data). The extent of LTE coverage differs between the two datasets. For three out of four providers, Skyhook shows lower coverage than the FCC, particularly in the rural census blocks. For instance, the FCC T-Mobile data shows coverage in 92% of tribal rural blocks, whereas Skyhook shows coverage in only 63% of such blocks. On the other hand, Skyhook shows a higher number of census blocks covered than the FCC for Sprint. The higher coverage in the case of Sprint could have been due to multiple reasons, including: (i) there are differences in the propagation models used by Skyhook and Sprint to estimate coverage with the former's models being more generous than the latter's, and (ii) the Skyhook data is Tribal Urban 0 (0%) 0 (0%) 4 (<1%) 0 (0%) Table 5 : Number of census blocks with LTE coverage according to the FCC, but only 3G coverage according to Skyhook. The numbers in parenthesis report the same data as a percentage of total census blocks of the corresponding type.collected across time and Sprint may have discontinued or temporarily disabled some of the cells, which is challenging to detect from the crowdsourced data. Figure 4 visually compares the LTE coverage maps from the FCC and the Skyhook datasets for Verizon and Sprint. We more deeply examine the discrepancy mapped in yellow in Figure 4a . Table 4 shows the number of census blocks where there is coverage according to the FCC but none according to Skyhook for each operator. Coverage claims in both tribal and non-tribal rural census blocks disagree the most. The number of such blocks are particularly high for Verizon (19, 126 overall) and T-Mobile (18, 189 overall). There are two possible reasons for this disagreement: network operators lack adequate infrastructure in rural areas, but tend to overestimate coverage while reporting it to FCC, or Skyhook is missing data points from rural census blocks where fewer people carry UEs. The latter case will lead to either some LTE cells not being detected or an inaccurate characterization of cell coverage due to fewer measurements.To understand which of these potential reasons for disagreement is more likely, we check whether Skyhook shows 3G coverage for these census blocks (where the FCC reports LTE coverage but Skyhook does not). If Skyhook reports 3G coverage in these blocks, this suggests that users may have contributed to the Skyhook dataset in these census blocks, therefore LTE coverage would have been detected if it existed. Note that a more accurate way would have been to directly consider the location of end-user measurements connected using 3G technology and analyze whether they fall within LTE coverage areas in the FCC data. However, we did not have access to these end-user measurements due to Skyhook's privacy policy. Instead, we consider the 3G coverage maps as a reasonable approximation for our analysis and generate a 3G coverage map at the census block level for these areas in the same manner as described previously for LTE. The number of census blocks that show only 3G coverage according to Skyhook is presented in Table 5 . We observe a significant number of census blocks where Skyhook detects 3G coverage, indicating that the FCC LTE coverage claims may be overstated in these areas. The number of such blocks is greater for tribal rural areas (up to 9%), thus indicating a higher mismatch of the two datasets in tribal rural areas.3.2.2 Active measurements compared to FCC and Skyhook coverage. In this section, we compare our own active measurements with the coverage maps from the FCC and Skyhook described in Section 3.2.1. We focus now on the geographic region around Santa Clara Pueblo, which lies north of Santa Fe (see Figure 2 ), a region with a mix of urban, rural, and tribal population blocks. Methodology: We use the Service State readings collected in our measurements for this analysis (see Section 2.4). We also collected information about the connected cell's technology (e.g. LTE) and the geolocation of the measurements. This information is used to infer whether LTE coverage exists at a location. We consider LTE to be available if the Service State shows IN_SERVICE to indicate an active connection, and if the associated cell is an LTE cell. We term this the active LTE coverage. We then compare the FCC and Skyhook coverage with the active LTE coverage to see whether the datasets agree. Note that we use the coverage shapefiles for both Skyhook and the FCC in this comparison instead of the census block centroid approach in Section 3.2.1. This allows us to compare coverage more precisely for a location, especially if a census block is only partially covered. Results: Table 6 shows the confusion matrices that compare active LTE coverage with reported coverage from the FCC and Skyhook maps. Both maps show coverage at locations where our measurements did not. In the case of Verizon, 81% of the measurements with no coverage are from locations reported as covered by the FCC. This over-reporting is lowest for Sprint and highest for T-Mobile.We also observe significant disagreement (up to 79%) between Skyhook coverage and our measurements. Two possibilities may cause this: i) paucity in Skyhook UE signal strength readings available for cell location and coverage radius estimation, or ii) error in the cell propagation model itself possibly due to variations in the environment conditions such as the terrain. In either case, Skyhook agrees better with our measurements than the FCC in reporting areas with no LTE coverage. E.g., in the case of AT&T, 75% of our measurements with no LTE coverage belong to areas reported as covered by the FCC as compared to 48% by Skyhook. In this section, we discuss some of the implications of our experience collecting and analyzing coverage data, recommendations based on our findings, and directions for future work.Recommendations for the FCC: Our findings make a case for including mechanisms that validate ISP-reported coverage data, especially in rural and tribal regions. Given the scale of cellular networks, crowdsourcing coverage measurements is a viable approach to validate access as opposed to controlled measurements. Within crowdsourcing, we suggest leveraging incidental rather than voluntary approaches, possibly working with third-party services that collect network measurements as part of their service process (as in the case of Skyhook).In addition, crowdsourcing alone may not be sufficient for determining coverage in some cases. Even with the more complete datasets provided through incidental crowdsourcing, rural areas tended to receive significantly fewer measurements per tower. In such cases, mechanisms need to be developed to precisely determine areas of greatest disagreement using sparse crowdsourced datasets. Resources can then be focused to target data collection in these areas instead of a blanket approach measuring coverage everywhere.We find some shortcomings in the existing crowdsourced datasets. First, existing datasets only report areas with positive coverage, i.e., areas where coverage is observed. This makes it difficult to distinguish areas that lack coverage from areas for which no measurements were gathered. Recording areas that lack a usable signal can enable more stronger conclusions from crowdsourced data.Second, we note that even crowdsourced datasets are prone to overestimation of coverage potentially due to errors in cell location and coverage estimation. Research efforts that effectively utilize the knowledge of cellular network design are needed for an accurate characterization of coverage from crowdsourced measurements. For instance, existing cell location estimation techniques localize cells independently (see Section 2.3) and are prone to errors when there are few end-user measurements [15] . Instead, one can utilize the fact that a single physical tower in an LTE network hosts multiple cells. Thus, algorithms that jointly localize cells for whom the end-user measurements are in physical proximity may provide higher accuracy even with fewer enduser measurements. Similarly, alternate data sources can also be considered for localizing cell infrastructure such as using geo-imagery data to identify physical towers or directly obtaining infrastructure data from entities that build and manage physical cell towers (usually different from cellular ISPs).Measuring access beyond binary coverage: While the focus of this work is on understanding coverage, we recognize that a binary notion of coverage alone does not necessarily indicate the existence of usable LTE connectivity. Various other factors can impact end-user experience in a ""covered"" area such as low signal strength or poor middle-mile connectivity. Thus, future coverage measurement efforts need to augment coverage reports with measurements of performance to provide models that are more aligned with user experiences. Measuring such performance metrics poses a greater challenge because end-user experience depends on a myriad of factors beyond just last-mile link quality. We believe that efforts that lead to increased community awareness (e.g., workshops in public libraries, community meetings) on the importance of measuring mobile coverage is the way to tackle this problem.Finally, we also note that access and adoption are different and there are issues beyond access that might also warrant measurement and consideration as accountability measures for operators. Our collection of ground truth data sets involved five days driving through Rio Arriba County in northern New Mexico. In preparation for the trip, we worked to obtain SIM cards that would enable us to access the networks of the four major U.S. LTE operators. This was surprisingly difficult; over the course of a month leading up to the measurement campaign, we spent a collective 24 hours in various operator kiosks and stores in three states in order to obtain four SIM cards (one for each major operator). At one of the stores in Santa Fe, we encountered a woman who had to drive an hour from Las Vegas, NM to address some of the issues she was having with her mobile service operator that were preventing her from using her data plan. While these anecdotal experiences mirror the qualitative claims of coverage overestimation, they do introduce a new set of issues that need to be taken into account to effectively reduce the barriers of Internet access for rural communities.In this paper, we quantitatively examine the LTE coverage disagreement among existing datasets collected using different methodologies. We find that existing datasets display the most divergence when compared with each other in rural and tribal areas. We discuss our findings with respect to their implications for telecommunications policy. We also identify several future research directions for the computing community, including: mechanisms to augment existing datasets to precisely determine areas where more concerted measurement efforts are needed, improved coverage estimation models especially for areas with a lower density of crowdsourced measurements, and accurate and scalable measurement of access beyond a binary notion of coverage.",United States,abstract,2021-02-15,02
ef89be0d51fe3f76a032c4c5edec4f19543aba68,Analysis of the Effectiveness of Face-Coverings on the Death Rate of COVID-19 Using Machine Learning,"Presenting a model that can measure the effectiveness of the mask mandate orders can pave the way for governments to take decisive actions during pandemics. The experimental data in tandem with mathematical modelings can be utilized to study the effects of facial coverings on the spread of viral infections. A plethora of previous publications have tried to address the effectiveness of nonpharmaceutical interventions (NPIs) during pandemics, particularly for the spread of influenza [3, 4] . Deterministic models have been widely used to study the effects of facial masks on the reproduction number R 0 . Indeed, the face mask is taken into account by its role in reducing the transmission per contact [5] . The results of the deterministic model indicated that public use of face masks delays the influenza pandemic.On the other hand, some studies suggest that the use of a face mask does not have a substantial effect on influenza transmission and there is little evidence in favor of the effectiveness of facial masks [6, 7] . As for the COVID-19, the efficacy of the facial mask in impeding the infectivity of the SARS-CoV-2 remains unclear. Having considered the effects of mask in reproduction number R 0 , Li et al. [8] claimed that wearing face masks alongside the social distancing can flatten the epidemic curve. Other studies also pinpointed that public use of a facial mask may contribute to the reduction in spread of COVID-19 [9] . Despite these findings, the efficacy of face masks remains controversial.The cardinal point that has not garnered enough attention is the relationship between the degree of exposure to the virus and its mortality rate. The idea that the severity of the symptoms correlates with the extent of exposure to the COVID-19 was presented by some researchers to justify the high death rate in healthcare workers [10] . Unfortunately, there is not a universal trend that can predict the relationship between the dose of the virus and the severity of the resulting symptoms. A study performed on the relationship between influenza and rhinovirus viral load, and the severity in the upper respiratory tract infections reported a different behavior for those viruses [11] . In fact, the results indicated that for influenza A and the rhinovirus, viral loads were not associated with hospitalization/ICU. On the other hand, for influenza B, viral load was higher in hospitalized/ICU patients. Furthermore, for Respiratory syncytial virus (RSV), viral load seems to correlate with the severity of symptoms as many studies in the literature suggest that a correlation exists [12] [13] [14] . The same controversy holds for the COVID-19. Recently, some studies have tried to investigate the severity of COVID-19 with its load, where they found that the load tightly correlates with the severity [15, 16] . However, another study suggests that no such a correlation exists [17] .To unveil whether COVID-19 viral load is related to disease severity requires an in-depth study, which involves infecting volunteers with controlled doses of virus and monitoring their symptoms. However, experimental challenges in addition to the ethicality of these experiments make this type of studies very challenging at this point [10] . Although studies have not been convergent in whether nose [18] or mouth [19] is the primary site for COVID-19 infection, they underscored the importance of wearing a facial mask as a barrier to the virus spread. Additionally, although the protection level of different types of mask are different, wearing any mask even a cloth mask is better than wearing nothing at all, which can play a role in protection from the exposure to COVID-19 [20, 21] . Given the challenges of the experimental studies on the relationship between the extent of exposure and severity of COVID-19, one way to study whether the extent to which an individual is exposed to the COVID-19 correlates with the severity of the symptoms is to introduce a model that can capture changes in the mortality rate due to the wearing a facial mask. Indeed, if the ratio of the number of death to the number of cases decreases, this can support the hypothesis that there is a correlation between the viral load and the severity of symptoms. Thus, studying the effects of MM order on the mortality rate gains extra importance.An ML analysis can be very useful to shed light on the possible correlation between the public use of mask and changes in the mortality rate. The success of implementing Machine Learning (ML) and Artificial Intelligence (AI) techniques in the previous pandemic has con-vinced researchers to use them as precious tools in fighting against the current outbreak [22] . ML and AI can be used for prediction and forecasting in different regions so that the corresponding health officials can take essential actions in advance [22] . In addition, this technology is capable of enhancing the prediction accuracy for screening both infectious and non-infectious diseases [23] . Six ML methods have been carried out to predict 1, 3, and 6 days ahead the total number of confirmed COVID-19 cases with error ranges of 0.87%-3.51%, 1.02%-5.63%, and 0.95%-6.90%, respectively, in 10 Brazilian states [24] . Moreover, an ML method like XGBoost model was capable of identifying 3 important biomarkers from 485 blood samples in Wuhan, China as the key mortality parameters [25] . ML algorithms also have been used to capture the correlation between the weather data, and COVID-19 mortality and transmission rates [26, 27] . Additionally, ML has been utilized to study the effects of MM order on the number of daily cases, where no significant statistical difference was observed in the number of daily cases in state-wise analysis [28] . These studies confirm the strength of ML as a great tool to investigate the effects of MM order on mortality rates of COVID-19.Another important factor regarding the effectiveness of MM order is society's adherence to the regulations. One study that tried to quantify public compliance with COVID-19 public health recommendations found notable regional differences in intent to follow health guidelines [29] . Some studies noticed a correlation between level of education and intent to voluntarily adhere to social distancing guidelines [29, 30] . However, not only the level of education but also level of income, race and political orientation can play a role in the adherence to the regulations [31] . Based on these findings, it's important to take into account the features that might be correlated with people's compliance with the MM order.Additionally, we will use a data based on the survey provided by New York times available on Github, which quantifies people's adherence to the MM order [32] . As a result, in this study, we will include factors that might play a role in people's adherence to the MM order as our input features.In the proposed work, utilizing different ML classification algorithms, we aim to unveil how the change in the mortality rate correlates with certain features. The features will be chosen in a way that they can reflect abidance by MM order in different counties. We will use the data provided by CDC to find the average monthly number of COVID-19 cases. Additionally, the exact dates of the executive orders signed by the state officials are available for each state. To have appropriate unbiased data, similar to what Maloney et al. [28] has done in his study of the effect of mask mandate, we will be using the data for one month after and before the executive orders for each preventive measure for the three states in US West Coast. Indeed, with this data selection method, we limit the geographical region of the study to ensure that changes in the cases are highly attributed to the public use of masks rather than other factors such as environmental changes.As a verification of the proposed work, the best performing algorithms are further chosen with the calculated hyper-parameters for testing four additional states (Arizona, New Jersey, New York and Texas). The findings demonstrate an acceptable accuracy scores, which justifies the correlation of the chosen features with the effect of COVID-19.The rest of the paper is organized as follows. First, we will represent how our data was collected and arranged. Then we will explicate the ML methods we have used for our prediction. Finally, we will represent and compare the results obtained from different ML methods.In this section, we will explain the collected data and the ML algorithms used for the training and prediction.We defined the parameter of interest as the average ratio of the number of deaths to the total number of cases, referred to as the death ratio, which can be interpreted as a measure of the severity of the disease. The effective date of the executive orders by the governors, requiring mask mandate at all the counties in the three West Coast states of California, Oregon and Washington has been identified, which is publicly available [33] . We used the average death ratio one month before and after the order to study the mortality rate. The rationale behind this selection is to minimize the effects of other factors that might play role in changing the COVID-19 data. The raw dataset for the daily cases and deaths for all the US counties over time is extracted from the USAFACTS website [34] , where county-level data is confirmed by the state and local agencies directly. After obtaining the daily values of death and case numbers for a month before and after the MM order, we divided the monthly average number of deaths by the monthly average number of cases for each county. Then we found the difference between the death ratio for one month before and after the MM order.Finally, we categorized the variation based on its sign to quantify whether the death ratio increases, decreases, or no change occurs. Out of the 130 samples, 47, 30, and 53 of them belong to the ""decrease"", ""increase"", and ""no change"" classes, respectively. We dropped the ""no change"" data as they all correspond to small counties, where there were zero reported COVID-19 cases and deaths, leaving 77 counties in total. Consequently, the two categories of increase (denoted by class 0) and decrease (shown by class 1) are remained for the prediction task. A histogram of the output classes is shown in the Fig. (1) , which expresses that the data is not biased. for these features is all obtained from the US Census website [35] . The US Census measures the median income as the regular income received excluding other payments like tax, etc [36] . The data for the political inclination is constructed based on the 2020 US presidential election results [37] . This feature has been converted to the categorical type in a vectorized manner, i.e. the winner takes the value of 1 in the column, and the opponent takes 0 in their own. Furthermore, we used a survey data, provided by the New York Times, that quantifies the mask usage from 7/2/2020 to 7/14/2020 [32] . Since the survey timeline lies within the month after the MM order for all three studied states, it is valid to use its data for our purpose. Finally, we will try to establish an AI-based relationship between the features and the death ratios of the Pacific Coast states at the county level using 9 different classification algorithms, provided in section 2.2.In this study, we have developed machine learning models to correlate the specified features mentioned in section 2.1 with the aim of shedding light on the relationship between adherence to mask mandate and mortality rate.Classic ML methods of Logistic Regression [38] and Naive Bayes classifier [39] are used. In addition, ensemble learning-based models, Random Forest and Extra Trees, are also analyzed [40] . Moreover, the extreme boosting method, XGBoost is explored [41] . Other methods such as Support Vector Machine, K-Nearest Neighbors [42] , Decision Trees [43] , and Neural Network [44] are additionally used for prediction of effect of Mask Mandate on mortality rate.It should be noted that for carrying out the analysis, the data is split into training and test sets, with a test size of 20%. A k-fold cross validation scheme with 5 folds has been used to evaluate the performance of each method on the validation set and tune its hyper-parameters with the classification accuracy as the metric accordingly. The hyper-parameter tuning is done using either grid search or random search for all the methods. A statistical summary of the final dataset for the purpose of binary classification is outlined in the table 1, which indicates a large difference between the orders of magnitudes of the features. Therefore, min-max and max-abs scaling have been used to transform the input features and output, respectively, before passing the data to the ML algorithms for training. The change in death ratio from one month before to one month after the date of mandating face-covering in the three states is visualized for each county in Fig.(2) . Two clusters of increase in death ratio can be seen, one near northern Washington, and one near central California. Our first intuition was that by increasing population, the chance of viral spread would increase, and therefore we expected to see a positive change in death ratio for more populated counties. However, as it can be seen from the map, there is an inherent randomness which defies our initial intuition about the spread mechanism. Further, it is shown that more counties experienced a decrease in death ratio one month after the usage of face-covering was mandated by each state, as shown in Fig. (1) . Therefore, usage of face-covering is chosen as the main factor affecting the decrease of the change in death ratio. As explained previously, to quantify adherence to the mask mandate, other auxiliary features are chosen, namely, population, median income, and political inclination for each county.As a preliminary analysis, political inclination, based on the result of the 2020 presidential election, is chosen as the focal criterion to categorize the data for changes of death ratio for all three states, as presented in Fig. (3) . Fig. 3(a) shows that in general, communities that voted republican in presidential election of 2020 were affected worse compared to democratic counties. Further, a noticeable correlation is observed between average median income and the change of death ratio, presented in Fig. 3(b) . It is shown that, on average, the communities with less median income experienced a positive change in death ratio, meaning more mortality rate regardless of their political inclination. The strongest correlation however is observed by considering county population, shown in Fig. 3(c) . The counties with fewer residents were affected more adversely by the pandemic compared to high-population counties. The counter intuitive relation between population and change in death ratio further corroborates necessity of inclusion of the two other supplementary features. To have an initial assessment of the variation of percent change in the death ratio, we plotted the percent death ratio as functions of population, median income, and percent of the population that frequently uses mask, which has a relatively high correlation coefficient. would pave the way for capturing the status of change. A summary of the overall death rates in the months before and after the mask mandate order for the 3 states is presented in table 2. It can be observed that change in death ratio significantly decreases in California and Washington, but slightly increases in Oregon. This suggests an intrinsically complex pattern between the death rate as the desired output and the selected inputs. According to a recent study, there is a number of factors attributing to the possibility of a person to follow or not follow the health guidelines set by the state officials [31] . Three features among these parameters plus the mask usage as the fourth feature have been used to conduct the current study.Using the obtained data, the combined effect of features is analyzed on the death ratio. Then All implemented algorithms in this study are capable of providing us with high classification accuracy i.e, to predict whether a county has experienced a decrease in its death ratios or an increase. As provided in Table ( In this body of work, we have analyzed the effect of mask covering on the intensity of spread of the COVID-19 virus by considering the death ratio at the county level to be the primary indicator. To bridge the gap between level of adherence to mask mandate, four main features are used as input data, population, income, political inclination, and the results of the survey on mask usage from New York Times. The change in the death ratio is used as the metric to quantify the effectiveness of face-coverings on the COVID-19 spread. After extracting and refining the data-set from reliable sources, we analyzed the information using 9 different algorithms. Among all the methods used, Random Forest, XGBoost, and NaiveBayes had the best performance with a classification accuracy of 94%. The high performing algorithms, with the computed hyper-parameters, are then used to process four additional states, Arizona, New Jersey, New York, and Texas entirely used as test data set. The acceptable accuracy results for the large test case, further verifies legibility of the chosen features as influential criteria for modeling purposes. The obtained hyper-parameters for these models (except for Naive Bayes) can now be used to predict future conditions of the spread of the virus.It is shown that, in most of the counties, there exist a connection between adherence to the mask mandate and change in death ratio. The findings of this work emphasizes importance of immediate legislative action on well-being of societies. It is hoped that the findings of this work, highlight importance of socioeconomic and political settings on behavior of different communities, which as portrayed could be complex and counter-intuitive. For instance, if the mask mandate had been issued earlier, with better implementation procedures along with effective incentives targetted at specific communities, more people would be encouraged to abide by the issued ordinance, and consequently, fewer individuals and families would have become the victim of the pandemic.",USA,first author,2021-02-08,02
0127eda9fed387e13808370898f29487ba382673,Analyzing Host-Viral Interactome of SARS-CoV-2 for Identifying Vulnerable Host Proteins during COVID-19 Pathogenesis,"The world is experiencing an unprecedented pandemic due to a massive outbreak of Severe Acute Respiratory Syndrome Corona Virus 2 (SARS-CoV-2 ) infected viral disease, COVID-19. SARS-CoV-2 , is a large enveloped coronavirus (family-Coronaviridae, subfamily-Coronavirinae) with non-segmented, single-stranded, and positive-sense RNA genomes [1] , transmits rapidly through human to human contacts. Although SARS-CoV-2 is similar to other known coronaviruses, i.e. SARS-CoV and MERS-CoV [2, 3] , it has demonstrated high rates of infection [4, 5] . Therefore there is the need to understand the disease pathogenesis of SAR-CoV-2 to develop effective therapies and vaccines.The SARS-CoV-2 virus is responsible COVID-19 disease that causes damages in multiple organs as the disease progresses from an asymptomatic phase to a life-threatening disease [6] . Therefore, accurate molecular diagnosis of COVID-19 disease is essential by collecting the proper respiratory tract specimen [7] . In this context, the integrated analysis [8] of various data-sets, including clinical and imaging data, may explain, and hopefully predict, the longitudinal effects of SARS-CoV-2 infection [9, 10]. In particular, many independent projects throughout the world have focused on genomics and proteomics level [10] , and then they integrated these data with clinical ones. These works have produced data about the infection's effect at a molecular scale, evidencing genes and proteins' role, such as the interactions among viral and human proteins. Interactions between a host and its pathogen, are primarily driven by interactions among the host proteins and pathogen proteins; also referred to as host-pathogen protein-protein interaction (PPI) network. The SARS-CoV-2 virus-host interactome have been studied focusing various virulence factors influencing SARS-CoV-2 pathogenesis and interacting mechanism [11, 12, 13, 14, 15, 16] . Further, many recent works also used host-viral protein-protein interaction network as an input to elucidate potential drug targets or repurposed drug molecules [17, 18, 19] . Host-pathogen protein interactions provide important insights into the molecular mechanisms of pathogenecity [20] and for understanding virulence factors influencing SARS-CoV-2 pathogenesis [21, 22] . SARS-CoV-2 is a newly found virus whose interacting human host proteins play a major disease progression role that needs to be investigated.Protein-Protein Interactions (PPI) are usually modelled and analysed with graph theory [23] . In this formalism, the interactions are modelled as a graph whose nodes are proteins (or genes), and the edges are the interaction among them. Several studies have found that specific candidate proteins might play a crucial role [24, 25, 26, 27] . Protein-protein interaction networks are an essential ingredient for any systems-level understanding of cellular processes and modelling, and even drug discovery [28, 29, 30, 31, 32] . The key genes/proteins involved in the different biological pathways can give valuable insight for in-depth characterisation of disease progression [33, 34, 35] . It is well accepted that all the viruses have evolved to target proteins that are central and have strong control over the human interactome [36, 37, 38, 39, 40] . Exploring the predicted interaction networks can suggest new directions for future experimental research and provide cross-species predictions for efficient interaction mapping [41, 34] . The complete workflow of the current study can be seen from Figure 1 . This study aims to identify essential human host proteins based on topology analysis of the protein-protein interaction network of SARS-CoV-2 interacting human host proteins. We performed functional enrichment of the identified proteins to shed out light on cellular, signalling, and disease pathways.We use recently reported host proteins that are physically verified using Affinity purification mass spectrometry for their interactions with SARS-CoV-2 [17, 21, 42] . The used host-viral protein interactions are also available in BioGRID [43] . A total of 2489 host-viral interactions (consisting of 1432 unique host proteins interacting with 37 SARS-CoV-2 viral proteins) are obtained. In Figure 2 , we provided the number of interacting host protein count. It is noted that the majority of the host proteins are targeted to the specific viral protein.Starting with the human proteins that are interacting with the virus, we build a host PPI by querying the Search Tool for the Retrieval of Interacting Genes/Proteins (STRING, Version 10.0; http://string-db.org/) [44] .The topology analysis of the PPI network is performed by using Cytoscape (http://apps.cytoscape.org), a general platform for complex network analysis and visualization [45] .In network analysis, indicators of centrality identify the most critical nodes in the network [46] . The centrality measure uses to characterise each node and edge in the PPI network. The degree measure is the most intuitive for topology analysis of the PPI network. Several other crucial factors that can influence network links are betweenness centrality, closeness centrality, clustering coefficient, topological coefficient, and neighbourhood connectivity. (i) Degree centrality: The degree centrality (simply degree) of a node n in a network is defined as (D n ), which indicates number of directly connected nodes to n. The densely connected nodes in PPI network is considered hub nodes [47] .(ii) Betweenness centrality: Betweenness centrality quantifies the number of times a node acts as a bridge along the shortest path between two other nodes [48] . The betweenness centrality of a node n is represented as:where σ st is the total number of shortest paths from node s to node t and σ st (n) is the number of those paths that pass through n.(iii) Closeness centrality: Closeness centrality is a way of detecting nodes that are able to spread information very efficiently through the network [49] . It can be calculated as :where L(m, n) is the length of shortest path between node n and m, and m denotes any other nodes that are reachable to node n.(iv) Average shortest-path length: Shortest-path length between two nodes (say n and m) in network topology is defined as the number of minimum steps that required to traverse between node n and m! [50] . The average shortest path length (S p ) of node n is the average value of all pair of nodes shortest path from the node n.(v) Clustering coefficient: Clustering coefficient is a measure of the degree to which nodes in a graph tend to cluster together [51] . In undirected networks, the clustering coefficient C n of a node n is defined as:where k n is the number of neighbors of n and e n is the number of connected pairs between all neighbors of n.(vi) Topological coefficient: Topological coefficient is a relative measure for the extent to which a node shares neighbors with other nodes [52] . The topological coefficient T n of a node n with k n neighbors is computed as follows: T n = avg(J(n, m))/k n (4)Where J(n, m) is defined for all nodes m that share at least one neighbour with n, and the value J(n, m) is the number of neighbours shared between the nodes n and m, plus one if there is a direct link between n and m.(vii) Neighborhood connectivity: Neighborhood connectivity (N c ) of a node n is defined as the average connectivity of all neighbors of n [53] . The neighborhood connectivity distribution gives the average of the neighborhood connectivities of all nodes n with k neighbors for k = 0, 1, · · ·.We used NetworkAnalyzer [45] to calculate above centrality score. In NetworkAnalyzer, C c (Closeness centrality) is calculated as the reciprocal of the average shortest path length. So, high C c means highly central, and thus low S p .We performed enrichment analysis to find out set of significantly enriched genes/proteins in different functional and biological pathways. We used KEGG (Kyoto Encyclopedia of Genes and Genomes) [54] for elucidating pathway enrichment of a host protein and Gene Ontology (GO) for the assessment of protein functions [55] . KEGG is a database resource for understanding high-level functions and utilities of the biological system [56] .Complex diseases are caused by a group of genes known as disease genes. More often, a gene can participate in various disease conditions [57, 58] . It helps unravel the disease pathogenesis, which in turn help disease diagnosis, treatment, and disease prevention. We obtained gene-disease association network from DisGeNET (v7.0) database (https://www.disgenet.org/), which contains 1,134,942 gene-disease associations (GDAs), between 21,671 genes and 30,170 disease [59] . From this database, we considered curated gene-disease associations only.Here, we report the outcomes of intermediate steps to reach to our objective of isolating key host proteins followed by their significance analysis.Our candidate host proteins list, collected from the reported host-viral networks (Section 2), consists of total of 1432 distinct proteins that are targeted by SARS-CoV-2 during COVID-19 . We rebuilt the PPI network centered around our candidate proteins using STRING DB. There are 7076 edges in the derived PPI network. We curated derived PPI by keeping only the interactions whose confidence scores are at least 0.7 (high confidence). The derived PPI network is then analysed using Cytoscape. We identified the big connected component (also called gain/main component) of the PPI network. After discarding all disconnected components in the PPI network, we considered gain component of PPI network with 1111 nodes (Approx. 78%) and 7043 edges ( Figure 3 ).We performed topological analysis of the gain component using NetworkAnalyzer [45] . The degree distribution of all the candidate proteins in the gain component showed that the majority of the proteins in the gain component exhibit a higher degree of connectivity (Figure 4 ). Few proteins with degree (shown within parentheses) more than 50 are CDK1(73), PPP2R1A (65) The histogram analysis of all the centrality measures (discussed in section 2.3) showing non-random distribution ( Figure S1 ). We performed correlation (Pearson) analysis among all centrality scores ( Table 1 ). The correlation score between degree centrality (D c ) scores and closeness centrality (C c ) scores observed to be the highest (r = 0.759) in comparison to other measures. Although, we observed correlation between D C and neighbourhood centrality (N c ) is the third-highest (r = 0.557), but N c and B c showed less correlative (r = 0.1101). Overall, we observed correlation score of three centrality measures (D C , B c ,C c ) are quite closer. Therefore, we selected them in subsequent analysis. We identified 373 proteins in these criteria, which are considered highly central proteins (above the median score for all three selected parameters). When we considered all measures, we find only six common proteins (GEMIN4, DDX20, GOLGA3, FKBP15, PMPCA, AK4) above the median score in each category of centrality measurement, and that is the reason why we selected three centrality measures for our downstream analysis. We performed KEGG pathway analysis of selected 373 highly central proteins. We obtained a total of 84 enriched KEGG pathways within the significant level (ad j − p < .05). The enriched pathways were involved in Cellular Processes (9), Environmental Information Processing (9), Genetic Information Processing (13), Human Disease (31), Organismal Systems (15), Metabolism (7). The top seven pathways in each category are shown in Figure 5 .Our current study mainly focused on the proteins that are involved in cellular process, signalling transduction, and human disease (viral and neurodegenerative) pathways, the most affected pathways in the context of COVID-19 disease [60, 61, 62, 63] . There are nine enriched pathways in cellular process (Endocytosis, Phagosome, Adherens junction, Tight junction, Cell cycle, Cellular senescence, Focal adhesion, Regulation of actin cytoskeleton, Lysosome), nine pathways in Environmental Information Processing-signalling transduction (Ras signalling pathway, HIF-1 signalling pathway, Hippo signalling pathway, Apelin signalling pathway, MAPK signalling pathway, TGF-beta signalling pathway, AMPK signalling pathway, NF-kappa B signalling pathway), nine pathways from human disease viral sub-category (Human immunodeficiency virus 1 infection, Human papillomavirus infection, Human cytomegalovirus infection, Hepatitis B, Human T-cell leukaemia virus 1 infection, Influenza A, Hepatitis C, Measles) and four pathways from neurodegenerative disease with sub-category (Huntington disease, Parkinson disease, Alzheimer disease, Prion diseases). A total of 141 distinct proteins (out of 373) were obtained from these pathways, which are then ranked based on presence in selected enriched pathways, and we found that 79 proteins are associated in our candidate pathways. All these proteins were then further studied for We also performed gene set enrichment analysis (Gene ontology). It is observed that out of selected genes mostly involved in Biological process (Supplementary-B) . The top ten terms in each category of gene ontology (BP, MF, CC) are shown in Figure 6 The identified 141 genes involved in four significant pathways (cellular process, signalling transduction, viral and neurodegenerative) are further screened by looking into their association with COVID-19 related disease. We particularly focused on three highly influential diseases during COVID-19 , namely cardiovascular, respiratory tract [64, 65, 66, 67] and immune system disease [68, 69] . To obtain disease-gene association, we used Dis-GeNET database [59] and selected CURET ED source only. We found a total of 64 proteins (out of 141) playing roles in various diseases such as Asthma, Pneumonitis, Pneumonia, Influenza, Lung diseases, Cardiomyopathies, Coronary, Arteriosclerosis, Coronary Artery Disease, Heart failure, HIV Infections etc. (Supplementary-C) . We compared proteins involved in all three disease categories and individual disease in each category (Figure 7) . A total of 119, 37, and 48 unique diseases, and 44, 17, and 24 distinct proteins are associated with the Cardiovascular, Respiratory, and Immune system disease category, respectively. Interestingly, we found a few proteins that are associated with all three disease categories ( AREG, CAV1, IFIH1, PARP1, PLAU, TGFB1, ATM, B2M, DDX58, ENO1, HSPA5, PRKDC, STAT6, TGFBR1, TGFBR2). The top few proteins with ten or more disease associations are PLAU(59), TGFB1(29), CAV1(17), PARP1(17), TGFBR2(13), ATP2A2(11), AREG(10), FASN(10), IFIH1(10), ITGB1(10). The list of all 64 proteins and their associated quantitative parameters (degree, disease count (out of 204), disease type count (out of 3), and pathway count(out of 31) are presented in Table 2 .We then looked into source network ( Figure 2 ) to identify the viral proteins that are targeting our selected 65 disease associated proteins. We found 25 SARS-CoV-2 proteins that are interacting with 65 proteins. Among 25 SARS-CoV-2 viral proteins, eight are accessory proteins (Orf3a, Orf7b, Orf6, Orf7a, Orf7b, Orf8, Orf9b, Orf10), four structural proteins (E,M,N,S) and thirteen non-structural poly-proteins (nsp1, nsp10, nsp12, nsp13, nsp14, nsp2, nsp3, nsp4, nsp5, nsp6, nsp7, nsp8, nsp9). It is observed that several host proteins are interacting with single viral protein. Very few host proteins are interacting with more than one viral proteins. The viral protein Orf7b exhibits the maximum number of target host proteins followed by Orf3a and M protein. Further, five host proteins are found to be common both in Orf3a and Orf7b.We look further for any other viruses that are targeting our 65 host proteins. We mine VirusMINT [70] , a virus-host association database, to find the other related viral diseases. We found that the majority of the highlighted host proteins are also targeted by Table 2 ). These proteins might be highly essential and need to put uttermost importance on developing host-directed antiviral therapies for COVID-19 .In this study, we have analysed human host protein-protein interaction network during the SARS-CoV-2 infection. We identified a set of proteins, including RBX1, HSPA5, ITCH, RAB7A, RAB5A, RAB8A, PSMC5, CAPZB, CANX, IGF2R, HSPA1A, which might influence the whole PPI network. These proteins were enriched for the following processes: cellular process, signalling, and neurodegenerative disease pathways as these pathways are known to be highly infectious for disease pathogenesis during COVID-19 . Finally, we have found 64 potential/key SARS-CoV-2 interacting human host proteins connected with respiratory, cardiovascular, and immune system disease. Many of them are known to target different other viruses and may be highly important for therapeutics treatment of COVID-19 viral disease. We strongly believe that the highlighted key proteins are an extremely promising target, which might play a crucial role during COVID-19 disease progression. [4] Y. Liu, A. A. Gayle, A. Wilder-Smith, J. Rocklöv, The reproductive number of covid-19 is higher compared to sars coronavirus, Journal of travel medicine (2020).[5] V. Surveillances, The epidemiological characteristics of an outbreak of 2019 novel coronavirus diseases (covid-19)-china, 2020, China CDC Weekly 2 (2020) 113-122.[6] K. Servick, For survivors of severe covid-19, beating the virus is just the beginning, Science (2020). ",USA,first author,2021-02-05,02
36074857fa100e21a8f2288297c939faa99a9ca6,D R A F T A Quantitative Evaluation of COVID-19 Epidemiological Models,"Epidemiological models of COVID-19 have proliferated quickly but it is unclear how well they forecast true values of key underlying variables: the number of infected and dead individuals. Establishing the quality of inference and predictive power is essential to make data-driven public health decisions, including those that manage the delicate trade-offs between the economy and public health. Model evaluation is therefore of critical importance (1, 2) . We have created a uniform objective scoring system for COVID-19 models that assess their predictive performance. A scoring system has previously been deployed to assess Flu prediction models in the FLUSIGHT contest two years ago (3, 4) . For COVID-19, investigators have been collating COVID-19 model epidemiological forecasts from multiple research groups in the COVID-19 Forecast Hub (covid19forecasthub.org). These results are concurrently presented on the CDC coronavirus forecasting website. While this effort provides insight into various model forecasts and their various assumptions, it stops short of providing an actual score for cumulative predictive performance. There have been efforts to assess the accuracy of published and unpublished COVID-19 models. Some have focused on evaluating model performance on their weekly cumulative predictions. For instance, two different studies (5, 6) assessed the performance of different models with the median absolute percent error (MAPE) of cumulative deaths. Fried-man et al. (5) , observed that the calculated MAPE increased for longer forecasts, and the best performance model varied by region. Others have focused on evaluating model performance based on weekly incident case forecasts by ranking them according to the mean weekly percentile (7) , while Leaderboard (8) uses the root mean squared error of weekly new deaths and reporting recent and running average performance of eight models. Another group evaluated ensemble models strictly containing probabilistic forecasts by computing a weighted interval score (9) . They found that combining forecasts in various ways consistently leads to improved performance over single model forecasts.Here, we propose to score individual models using a Leave-Forward-Out-Cross-Validation scheme. The score is computed by taking the log of the likelihood of the model forecasts on current data using the model predictions from the past. Each weekly projected quantity is scored separately, making it possible to assess model accuracy by the forecasted time increment. Thus, we have a matrix of scores where each entry is the computed log-likelihood for a model fitted to observed data up to a certain date of a quantity for each week forward from that date. This matrix continually expands in size as new weekly forecasts are made and new forecasting teams join the COVID-19 Forecast Hub collaborative. A global score is computed from the matrix by averaging over the desired elements. Some models may do well for short time predictions but not for longer ones and vice versa. Our score keeps track of how models improve (or degrade) over time and how far into the future they can reliably forecast. Our score dashboard is available at www.covidforeca.st. To calculate scores of epidemiological forecasts on the COVID-19 Forecast Hub, we first converted the reported quantiles into approximate probability density functions (PDFs) and then computed the log-likelihood of the held-out future observation as depicted in Figure 1 .Computation of model likelihood. The model predictions for a model, M d,t , are provided as standard quantiles q of the forecasted cumulative distributions for the case and death counts, v, computed using data up to a forecast date, d, for a prediction at a target end date, t. We convert this to a model likelihood by computing the PDF and evaluating at the corresponding ground truth value, G t . From the quantile data, we upsample v to create a regularized one dimensional grid V such that V = [floor(v min )+0.5 : ceil(v max )-0.5] and thus each grid point is separated by a distance ∆V = 1. This ∆V is held constant across all models. Next, we calculate Q = F (V i ), the cumulative probabilities corresponding to V, based on Piecewise Cubic Hermite Interpolating Polynomial (PCHIP) interpolation of q. Using Python NumPy gradient function we find the derivative of V, F (V ) = f (V ), which is the approximate PDF. Finally, we find the grid point in-in V containing the true value, G t (an integer). If both grid points of the PDF are available, then we define the probability of having G t given the model as. Otherwise, if the actual data falls outside of the forecast prediction interval, we assign p(G t |M d ) = 0 (even though this probability is non-zero for a distribution on semi-infinite support, it is insignificantly small). We validated our algorithm by finding small error between the integrated p(G t |M d ) values and the forecaster provided maximum quantile ranges (Fig. S2 ).Scoring function. We constructed a scoring function that rewarded models for assigning high probabilities to the true values. Thus, models with broad predictive distributions are penalized compared to models with narrower distributions even if the true values are at the mode in both distributions. Conversely, models with narrow distributions are severely pe-nalized if the true value falls outside of their predicted distribution. To this end, we start with the log-likelihood for a model M d,t given the held-out forecast target G t . However, the problem with the log-likelihood alone is that the score will vary depending on the distribution of G t , which can vary over time.To alleviate this problem, we normalize the score by subtracting away an ""optimal log-likelihood"" so thatThis is similar to the negative of the deviance used for generalized linear models. In place of a saturated model prediction, we assume a normal likelihood (for large rates a Poisson distribution is near normal), then we can writewith an expectation ofThe maximum is given by σ 2 = Var(G t ), and setting Var(G t ) = G t , as expected for a Poisson distribution (although the actual data is often overdispersed) we define our score as Overall model performance evaluation. Model scores depend on many intrinsic (e.g. changes to model assumptions) and extrinsic (e.g. epidemiology) factors, and most importantly on time. Thus, an overall model performance evaluation spanning through the entirety of available data of the pandemic can provide insight into all of these components (albeit in aggregate). To make fair comparisons, we analyze groups of models whose forecasts have the same target time horizon (e.g. 1 week ahead or 6 weeks ahead) together and have separate leader boards for each time horizon. We evaluate a model's performance on date t using two metrics: (1) median past score M S and (2) mean past model score performance ranking among other comparable models R t such thatandwhere nW is the n-Week forecast horizon. The leader board considers the time frame starting from July 4, 2020. We do D R A F T not include models with number of forecasts less than 50% of the number of possible weeks in the time frame in the leader boards (Fig. S7 ). Additionally, we used Median Absolute Deviation (MAD) to measure score variability of the models over time. For each forecast type (case or death) and each forecast horizon, we have a set of scores for a model's forecasts from July 4, 2020 onward. We find the median of the set. Then, we find the absolute difference between the elements of the set and the calculated median. This results in a set of absolute deviations. We report the median of that set for each forecast type and each forecast horizon.We generate the ensemble model forecast values v e corresponding to the standard set of quantiles q by using weights informed by past model scores (Fig. S4 ). Assuming there are n models available at a given forecast date d with a particular target end date t, to obtain v e , we weigh the constituent model forecast values v M corresponding to the i th quantile q i (see (11))where w M is the normalized weight of each model. There are many ways of formulating model weights in an ensemble, but we used median of exponentiated past scores of a model up to the date of forecast d as weight such thatWe normalize w M over all available model weights to calculate w M .Hence, an unweighted ensemble has all w M equal to 1/n. Also, we note that when forming time horizon-specific ensembles (e.g. 4-week ahead ensemble), we use scores and averages of that particular time-horizon only and do not involve others (e.g. 1-week ahead or 6-week ahead). We call our score-weighted ensemble model Sweight with the modeler team name FDANIHASU. To assess model performance based on similarity between model types and assumptions, we performed a meta-analysis of the models available on the COVID-19 Forecast Hub. As of January 24, 2021, there were 90 models deployed, and we reviewed 63 of those models which reported whole US population forecasts (weekly cases and cumulative deaths) along with the required pre-designated quantiles to perform scoring. In order to review each model, we first classify them under: deterministic, stochastic or statistical. A model was classified as deterministic if it is built using macro-level compartments representing a group of individuals and the dynamics are defined using average transition rates between compartments. A stochastic model is built at micro-level states occupied by discrete individual persons, randomness is introduced, and the transitions are defined with probabilities. A model was classified as statistical if statistical techniques were applied to analyze a data set and regression-type models were utilized. Deterministic models were categorized further into compartmental and metapopulation. Compartmental models assume a continuous population that is divided into a number of states (e.g. susceptible, infected, and recovered) (12) . Metapopulation models are usually in the form of connected compartment models of subpopulations defined in terms of geographical regions and incorporating random mixing within these subpopulations (12) , therefore adding complexity to compartmental types.Modeling strategies score comparably despite varying assumptions. Based on our literature review of models, about 54% of the models used the well-known epidemiological SIR model and its variations (i.e. SIR, SEIR, etc.) as the main framework in both deterministic and statistical models. About 43% of the models used statistical and probabilistic approaches, and about 3% of the models used other types such as combination of statistical and logistic growth model or by averaging the predictions of several models (Fig. 5A ). Among these classifications, modelers implemented other methods/theories such as spatio-temporal dynamics, seasonality, ground truth reporting periodicities and delays, mobility, and age-structure to increase specificity and complexity. When we analyze the approach the modelers took to drive their main modeling framework, we see that 27% used purely compartmental modeling, 19% used metapopulation approaches to model the spatial/population network interactions, 38% used statistical/stochastic approaches such as deep learning, and about 16% used ensemble forecasting (Fig.  5B) . Although model performances change with time, we have not observed dominance in performance of one modeling category over the others (Fig. 6) . Our detailed method- We developed a scoring framework for the forecasts of COVID-19 epidemiological models using forecast and observed data available at COVID-19 Forecast Hub. Scores can be used to evaluate past performances of all models. Additionally, quantitatively evaluating model forecasts enable score-weighted ensemble model forecasting. We provide a systematic review of available model types which show what type of modeling efforts are more successful in forecasting the COVID-19 epidemiology in the US. Our results suggest that models are unable to capture abrupt changes in COVID-19 epidemiology (e.g. the first two weeks of July and the first two weeks of November in US). Death count forecasts so far have been more accurate than weekly case counts. That could be because incidental case count curves are much higher than death counts and non-monotonic in behavior and may have varying reporting practices across health institutions, counties, and states. We refer the reader to www.covidtracking.com/data for an overview of such variabilities.Our work has some notable limitations. We only consider models on the COVID-19 forecast hub and this may inadvertently lend to selection bias of groups willing to format their model output according to required metrics and upload to the hub. Currently, our scoring framework considers only the US national data and scores on the individual US state model forecasts can be made available. We have also only considered weekly incidental case numbers and number of cumulative deaths, which does not take into account modeling efforts that predict hospital capacity and utilization. Additionally, our ensemble model formation may be optimized. When reporting average forward score for a model, we give equal weights to forecasts made earlier in time to the more recent forecasts. The score-weighted ensemble forecasts might have performed better, if we had focused on the recent forecasts instead of the entire set of longitudinal data pertaining to the pandemic.This work supplements the COVID-19 Forecast Hub effort by taking the modeler provided probability distributions and computing the score for each week the research groups update their forecasts. This can be implemented quickly, but does not standardize how the model uncertainty is computed. This, in particular, can be important if the model is a mechanistic one with multiple parameters. In such a case, the performance of the model should depend on the mechanisms included, the priors on the parameters in the model, and the chosen likelihood function for the noise on the data. Separating these effects might be useful in informing which mechanisms, priors, and noise models are important in obtaining accurate forecasts.A more ambitious scoring framework would be to perform a Bayesian scoring analysis on all models in-house. This would be made easier if model codes were to adhere to a universal standard. The universal standard idea has already been implemented by the FDA for results of clinical trials using Biocompute Objects (13) , which standardize the data processing pipeline. Universal model scoring would be optional but groups would be incentivized to obtain a score in order for their model to be considered as part of an ensemble. The standard could also be made less invasive by using the concept of the Unit test, which is an executable code snippet that verifies the intended behavior of a program. This is widely used in complex software projects. Google alone executes 4.2 million unit tests daily to verify the behavior of its core products. The analogue would be code snippets for D R A F T computing the model score. SciUnit (http://sciunit.io) is a Python package for constructing, executing, and reviewing the outcomes of model validation tests (14) . The core design principle is the programming adage ""separate the implementation from the interface"". Tests are not required to know anything about how a model works; instead, models expose functions that a test calls through an interface called a capability. The implementation of capabilities is left to downstream libraries, where SciUnit underlies libraries for a variety of projects, including The Human Brain Project (1000+ investigators) and OpenWorm (80 investigators across 17 countries). We could integrate public epidemiological models with SciUnit to rapidly, programmatically, and objectively assess the inferential and predictive performance of competing models across a number of relevant public health dimensions.The code for the scoreboard is available at github.com/ONYLAB/Scoreboard.Our scores are updated every Sunday evening and available at www.covidforeca.st. for use under a CC0 license.",USA,first author,2021-02-08,02
55c5f732622df2cc19537062bb00efb71004d705,"Shifting to digital: informing the rapid development, deployment, and future of teaching and learning Introduction The context","during these rapid shifts. The editorial board members not only supported the proposal unanimously, but also offered their time and expertise as guest editors to move this special issue swiftly forward. The core guest editors of the special issue included Drs. Dickson-Deane, Ilgaz, Ioannou, Kimmons, Morel, Natividad, Istenič Starčič, Wijekumar, and Young (in the alphabetical order of guest editors' last names). The guest editors communicated with the potential authors and reviewers, and ensured the quality of the submissions. Dr. Istenič Starčič kindly offered to be the lead guest editor to help streamline the papers for the special issue in the editorial manager system. Drs. Johnson, Spector, and Lin participated in the discussions, and coordinated the editorial process. Therefore, with this special issue-Shifting to Digital, we sought to provide insights into the applications of relevant research informing the rapid development, deployment and future of teaching and learning. We also deliberately sought to include multiple perspectives by seeking authors with varying professional experiences, from diverse nationalities representing a global perspective inclusive of the challenge.Over numerous meetings, the guest editors identified 17 papers published at ETR&D in the past five years, and selected these 17 papers to be responded in this special issue. Criteria for selecting these papers included their relevance to online or digital learning, relevance to rapid deployment, impact factor, scope, and appeal to a wide and diverse population. The goal, however, was not to select a set of best papers by any means, but to use the papers as anchors for creating dialogue and proving useful suggestions for practices towards future research.To accelerate the process and to balance the workload, every guest editor chose one or two of the 17 selected papers and oversaw the review processes of the corresponding essays to these papers. Table 1 below lists the key guest editors (in the alphabetical order Loizzo and Ertmer (2016) of the last names of the guest editors), and the manuscripts they oversaw for selecting corresponding essays in the review process. We created a call for papers for the ""Special Issue -Shifting to Digital"". The special issue called for essay-style response papers (500-1000 words) to the 17 selected publications via AECT newsletter, listserv, websites, and social media. In addition, guest editors reached out to various networks to share the call for papers. The responding essays would address the selected papers by people with varying backgrounds, cultures, expertise, and experiences. The goal was to seek multiple perspectives, which would include, but would not be limited to: theory, research, design, practices, ethics, policy, culture.We established several review criteria for the essay-style responses situating the 17 previously published articles within the current learning needs of the COVID-19 pandemic. We first defined what we meant by ""Shifting to Digital"". We asked that the potential respondent authors provide useful ideas for flexible learning, online learning, learning disruptions, especially where limited resources would be available, or situations where one would have to pivot to different teaching and learning methods within a shortened period of time. We asked that the responding authors focus their commentary pieces on the following aspects:• Impact/Value-What impact or value does the paper have on ""Shift to Digital"" from your specific perspective? What ideas from this paper contribute to its value? • Application-What information from your manuscript can be used to make the ""Shift to Digital""? Given your specific perspective, how do you take ideas presented in the manuscript and use them (i.e., providing specific context and audience)? • Limitations and Constraints-What limitations and constraints do you have about the paper as it relates to your selected perspective? • Future Suggestions-What constructive suggestions do you have for future work, related to your perspective and the ideas presented in the selected manuscript?The potential responding authors were asked to identify 2-3 manuscripts for which they were interested in authoring a response, and to specify the perspective on which they would focus in their response paper. The authors were then invited by the guest editors to write one essay response with the understanding that their submission would go through a double-blind peer-review, and that the invitation to author the response would not guarantee the article's acceptance or publication in ETR&D.Additionally, the guest editors agreed that only one first-authored or single-authored paper from each scholar would be included in this special issue. Again, the goal was to include multiple and diverse voices. All submissions went through a double-blind peer review process, with a range of one to four rounds of revisions.Finally, we accepted approximately 80 response essays for this special issue. These essays each brought unique perspectives to help bridge the research-based and evidencebased publications with a need to better inform the rapid deployment, development, and future of teaching and learning. The guest editors each also provided a summary of the accepted papers responding to the publications they oversaw. Drs. Spector and Harris were invited to write a conclusion piece for this special issue.Given the challenges of Shifting to Digital, we made it a top priority to seek multiple response essays to each of the 17 selected publications, with each essay focusing on a primary perspective. It was important for us to encourage diverse perspectives to provide contextual differences while informing practices. This special issue includes close to a hundred essays in total, with authors from different sectors and included discussions for K12, non-profit, profit, and higher education settings. This special issue was created to inform the processes and challenges of rapid digital development, deployment, and to provide insights into the future of teaching and learning. As editors, we consider it critical, not only to ensure the quality of published scholarship through a double-blind peer-review process, but also to seek ways to connect these works to our readership and to the consumers of knowledge. With the work of all those who contributed to this special issue, we feel that we can start to address the need to share the abundance of evidence-based research and development that have been conducted and published by the interdisciplinary community of scholars in learning technologies, learning sciences, instructional design, and educational technology practices. With this evolving monumental task during the past eight months, the entire special issue team aimed to create dialogues, stimulate reflection, and inform best practices. Now we welcome your comments and feedback for ways to continue this dialogue about the implications of research and knowledge in our world of teaching and learning.",USA,first author,2021-02-02,02
8757df18720aaea8a5df7d19ce7a41d2d1a875ef,Journal Pre-proof Assessing effects of reopening policies on COVID-19 pandemic in Texas with a data- driven transmission model Assessing Effects of Reopening Policies on COVID-19 Pandemic in Texas with a Data-Driven Transmission Model Assessing Effects of Reopening Policies on COVID-19 Pandemic in Texas with a Data-Driven Transmission Model,"In early December 2019, the first Coronavirus Disease 2019 (COVID- 19) case was identified in Wuhan, China, which was caused by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) (Guan et al., 2020) . COVID-19 has rapidly spread to most of the cities in China since then, and eventually caused the pandemic in the world. The outbreak of COVID-19 was declared as a pandemic by the World Health Organization on March 11 th (World Health Organization, 2020). As of May 16, 2020, a total of 4,434,653 confirmed cases and 302,169 deaths had been reported globally (WHO Coronavirus Disease (COVID- 19) Dashboard, 2020). Among all the counties and regions, the United States has been the most worrisome country which has the most confirmed cases and deaths. The number of cases and deaths reached to more than 7 million and 200, 000 respectively in October 2020.Due to the absence of vaccine and treatment, the prevention and control of COVID-19 have mainly relied on behavioral prevention measures, which include keeping social distance, wearing masks, stay-athome order, and closure of nonessential business (Yu et al., 2017) . In the United States, most of the states had declared a state of emergency and issued a stay-at-home order. Although many people have been prevented from infection through social distancing strategies, tens of millions of unemployment claims have been filed during COVID-19 outbreak in the United States (U.S. Bureau of Labor Statistics). As more and more people want to return to work, slowing down the spread of SARS-CoV-2 becomes more challenging.Recently, the stay-at-home order has been lifted across the country and some business restrictions have also been relaxed (CNN, 2020). Since the pandemic has not been completely controlled, the daily new confirmed cases are continually reported, it is urgent to evaluate the effect of the reopening policies on the COVID-19 pandemic to help manage the future medical resources and control measures. It has been observed that the number of daily confirmed cases is approaching another peak after the reopening policies are released in several states, including Texas, Alabama and South Dakota (COVID-19 tracking project (The Atlantic, The Covid Tracking Project, 2020)). For example, between April 10 th and 30 th , 2020, the numbers of daily confirmed cases were never greater than 1,000 in Texas (Texas DSHS, Texas COVID-19 Data, 2020), but the average number of daily confirmed cases between April 30 th and May 16 th , 2020 was 1173, in particular, the number of daily confirmed cases approached 1801 on May 16 th , 2020 after a reopening policy was implemented (Texas DSHS, Texas COVID-19 Data, 2020) . The increase in number of daily confirmed cases after reopening was likely due to the increased contact rate of susceptible people with infected cases. But it is not clear whether there is a second wave of outbreak and what the total number of cases will reach after reopening. It is crucial to understand the effect of reopening policies on the pandemic to prevent more infections. The pandemic situation in different states and counties are different and the local governments make their own decisions on when and how to reopen the business. In this study, we mainly focused on evaluating the reopening policies in Texas, although the methodologies in this paper are applicable to other states or regions in general.As for disease transmission, different mathematical models and statistical methods have been applied to predict the future trend, which include multivariate linear regression (Thomson et al., 2006) , grey forecasting method (Wang, 2018) , time series techniques and neural networks (Liu et al., 2016) and the susceptible/exposed/infective/recovered (SEIR) model (Sanyi et Zhao et al., 2020) . In this study, we proposed a modified SEIR model to study the COVID-19 epidemic in Texas. Using the proposed model, we estimated the COVID-19 epidemic parameters based on the data of reported infected cases and deaths in Texas, and predicted the future epidemics of COVID-19 under different reopening policies. The results of this study can help the local governments make decisions on pandemic control and future reopening policies.We assume that the overall population can be divided into nine compartments: susceptible individuals (M), exposed individuals who are not quarantined (N), exposed and quarantined individuals (N O ), infected individuals with symptoms (P Q ), infected individuals with no symptoms (P R ), confirmed cases who are quarantined at home (S T ), confirmed cases who are hospitalized (S U ), recovered individuals (V), and individuals who died (W). A SEIR model is modified to capture the details of prevention and control measures based on the model in the literature (Sanyi et al., 2020; Xia et al., 2020) . The proposed SEIR model is written as follows:V X = (1 − m U )n R P R + (1 − m r )n T S T + m s n U S U (8)This model assumes that the total number of the population keeps constant, i.e., no migration is considered. The individuals in the infected components, P Q and P R , are the only groups to infect the susceptible people. The transmission dynamic is modelled as follows (see the flowchart in Figure 1 ). Susceptible individuals, M, could become the exposed individuals who were not quarantined, N, after they were exposed to infected individuals P Q and P R , see equation (1) where t T (h) and t U (h) denote the contact rate of infected people with symptoms and without symptoms, respectively. The exposed individuals (N) further could move to the quarantined, infected and susceptible components with different rates, respectively. Specifically, they could move to exposed and quarantined component N O with a quarantine rate q(t), to infected components, P Q and P R , with an infection rate i, and the susceptible component M with a rate \. Individuals in component N O could become infectious with an infection rate q (Mizumoto et al., 2020) . Note that the compartment consisting of exposed individuals (N) is different from the traditional SEIR model (Aron and Schwartz, 1984; Sanyi et al., 2020; , where the exposed individuals are those infected patients but not yet infectious. Here we define the exposed individuals as those who literally contacted with the infected individuals and have not been infected yet. The infected patients with symptoms were detected to become confirmed cases and moved to confirmed and quarantined component S T with a rate o Q (h). The detection rate for infected people with no symptoms is o R (h). Individuals who were infected without symptoms could move to the symptomatic infected component P Q with a rate m U n R or recovered component V with a rate (1 − m U )n R . Individuals who were confirmed cases and quarantined at home could move to hospitalized component S U and recovered component V with a rate n T . Hospitalized patients could move to recovered and death component, V and W, with a rate n U . The recovered cases cannot be infected again. In this model, m T denotes the proportion of confirmed infected people with mild symptoms (no need for hospitalization) ( C. Covid, and R. Team, 2020); m r denotes the probability of confirmed cases quarantined at home becoming to be hospitalized; m s denotes the proportion of hospitalized COVID-19 patients who recovered ( Richardson et al., 2020; Zhou et al., 2020) ; m p is the proportion of the patients who were confirmed with infection and quarantined at home.We assume some parameters to be time varying to reflect the real world change due to policy changes, such as the contact rate, detection rate, quarantine rate and death rate. Specifically, the contact rate of infected people with symptoms t T (h) is modelled as u t T (h) = t Tv , h ≤ x T^; t T (h) = (t Tv − t Ty )z {| _ (`{} _~) + t Ty , h > x T^ (10) where t Tv is the baseline contact rate of the infected people with symptoms, t Ty is the minimum contact rate of infected people with symptoms under control strategies, t Ty < t Tv , and • T denotes how an exponential decrease in the contact rate is achieved. Critical time x T^ denotes the timing of social distancing strategies implemented on March 19th when Texas declared of state disaster and prohibited 10+ person of gathering (Office of Texas Governor, 2020 (11) J o u r n a l P r e -p r o o f where t Uv is the baseline contact rate of infected people without symptoms, t Uy is the minimum contact rate of infected people without symptoms under control strategies, t Uy < t Uv , and • U denotes how an exponential decrease in the contact rate of the infected people without symptoms is achieved. The transition rate of exposed people from non-quarantined state to quarantined, g(h), is (12) where g v denotes the baseline quarantine rate, g ‚ denotes the maximum quarantine rate, g ‚ > g v , • r denotes the parameter of exponential increase in the quarantine rate, and x U^ denotes the critical timing of enhanced quarantine strategies on April 2 nd , 2020 when Texas declared stay-at-home order [21] . The detection rate for infected people with symptoms was modelled as o• Q (h) is the testing rate of infected people with symptoms [14] , (14) where † R (h) is the testing rate of infected people without symptoms, • Rv is baseline of the test rate of infected people without symptoms, † R• is the maximum of the test rate of infected people without symptoms, and ‡ is the sensitivity of the testing kit. Critical time x r^ denotes the timing of enhanced detecting rate for people without symptoms (O.o.T. Governor, 2020) . The proportion of hospitalized COVID-19 patients who recovered [22, 38] , is modelled as m s (h) = (m sv − m sy )z {| '`+ m sv (15) where m sv denotes the baseline recovery proportion, m sy denotes the maximum recovery proportion, m sy > m sv , and • "" denotes the parameter of exponential increase in the recovery proportion.For model fitting and parameter estimation, we used the COVID-19 data collected from the Texas Department of State Health Services (Texas DSHS, 2020; The Atlantic, The Covid Tracking Project, 2020). Particularly, we used the number of cumulative confirmed cases and the number of cumulative deaths from hospitalized COVID-19 patients from March 4 th to April 28 th , 2020, for parameter estimation. The data for the number of hospitalizations and recovered patients were not directly observed, instead they were estimated, which may not be reliable and were not used in our model fitting. We assume the observed data model as,where Yc(t) and Yd(t) denote the reported numbers of cumulative COVID-19 confirmed cases and deaths in Texas, respectively. The measurement errors, -T and -U , are assumed as normal distribution with mean 0 and variance σ 2 . •(h, -) is the predicted number of cumulative confirmed cases by the SEIR model which was estimated by the following differential equation,J o u r n a l P r e -p r o o f W(h, -) is the predicted number of cumulative deaths by the SEIR model, which was calculated through the equation (9) . -denotes the model parameters. The nonlinear least squares (NLS) estimation method can be used to estimate the SEIR model parameters (Cao, et al., 2012) . The NLS objective function for our SEIR model isTo alleviate the model identification problem (Miao et al., 2011) , we fixed some parameters according to literature (see Table 1 ). In addition, all the unknown parameters were constrained with pre-defined lower and upper bounds (see Table 2 ). The interior-point method was used to optimize the loss function (18), and implemented with MATLAB.To evaluate the effect of fixed parameters and initial values on the estimation results, sensitivity analyses were performed. For the fixed parameters m T and s, we selected 6 values around the default value for each parameter in Table 1 . Then, a total of 36 different combinations of the fixed parameters were used to refit the model. For the initial values of parameters, each time we randomly selected one value around the estimated value for each parameter as the new initial value. Then we refitted the model using the generated new initial values. After repeating above steps for 800 times, we obtained the estimation results from the 800 different initial value sets. The distribution of the objective function values can be used to evaluate whether the solution is optimal. The comparison of prediction results under different parameter settings is another way to assess the influence of parameters on modelling results. If the prediction results are close, we can conclude that our model prediction is robust for the variation of parameters.Once the model is established and model parameters are estimated, we simulated the COVID-19 epidemic in Texas under the assumption of different reopening policies. The simulation focused on the effect of different reopening magnitudes on the COVID-19 epidemics in Texas. In the simulations, the timing of actual Texas reopening policies was used. Texas has implemented three phases of reopening which were effective on May 1st, May 18 th and June 3 rd , 2020 respectively (KHOU, 2020). Due to the increase in COVID-19 cases and hospitalizations, Texas governor announced the temporary pause of additional reopening on June 25 th . We quantified the effect of reopening policies by the fold-change of the contact rate, quarantine rate, and detection rate from those on April 30 th , the day before the phase one reopening effective day. The simulation mainly focused on three different levels of risk of reopening which were quantified by the change of the contact rate. Given a certain risk of reopening, we simulated three different magnitudes of control strategies which were quantified by the quarantine and detection rates.According to the Texas Department of State Health Services (DSHS) (Texas DSHS, 2020), the first confirmed COVID-19 case in Texas was documented on March 4 th , 2020. The patient was a man in his 70s who travelled aboard and returned to Texas with symptoms, then was hospitalized immediately after diagnosis. Therefore, we assumed the initial value of the number of hospitalized individuals as 1 on March 4 th , 2020. The initial value of the number of susceptible individuals was assumed as the whole Texas population (N=28,995,881 ). In addition, we fixed some of the model parameters based on literature in order to alleviate the model identifiability problem (see Table 1 ). With the constrained least squares (LS) method, the rest of the unknown parameters in the ODE system were estimated based on reported number of confirmed cases and deaths in Texas which are shown at Table 2 . The proposed model fits the observed COVID-19 data from Match 4 th to April 28 th , 2020 very well (see Figure 2 ). To further valid the model fitting, we performed sensitivity analyses against both fixed parameters and the initial values of parameters (see Figures S3-S10 in the supplemental material). It shows that the model fitting and prediction results are quite robust to the variations of fixed parameters and initial values. We also notice that our final parameter estimates may not be the best solution in terms of the objective function in the sensitivity analyses, but they are very close to the optimal point.We modeled the reopening policy with three levels of risk, i.e., low, medium and high risks that are quantified by the contact rate with infected individuals without symptoms (we assume that the effective contact rate with infected individuals with symptoms could be ignored). The changes of quarantine rate and detection rates were used to quantify the control measures under different reopening J o u r n a l P r e -p r o o f policies. The first phase of reopening in Texas was announced on April 27 th and effective on May 1 st , 2020. Thus, the estimates of the time-varying parameters, the contact rate, quarantine rate and detection rates on April 30 th , 2020 were used as the baseline values for the changes of reopening policies. Based on the proposed SEIR model, the estimated baseline contact rate for patients without symptoms was 4.088; the baseline quarantine rate was 0.104; the baseline detection rate for patients with symptoms was 0.104; and the baseline detection rate for patients without symptoms was 0.061. We quantified the ""low-risk"" reopening policy as the contact rate increased by 2 times on May 1 st , 3 times on May 18 th , 4 times on June 3 rd , then reduced to 3 times on June 25 th , 2020 due to the reopening pause. The medium and high-risk reopening policies were similarly defined but with a larger magnitude of change in the contact rate after reopening. For each level of the reopening risk, we simulated three scenarios of the control measures based on the quarantine rate and detection rates, i.e., 1) no change of control measures; 2) low magnitude of control measures where the quarantine and detection rates increased by 1.5 folds; and 3) high magnitude of control measures where the quarantine and detection rates increased by 2 folds. The detailed simulation design for the Texas reopening policy are summarized in Table 3 . The daily and cumulative numbers of confirmed cases, deaths, infected and hospitalized patients were evaluated under different simulation scenarios between May 1 st and September 30 th , 2020. The reported daily and cumulative confirmed COVID-19 cases and deaths between May 1 st and July 31 st , 2020 were used for comparisons with the simulated results.Under the low-risk reopening policy (i.e., the effective contact rate only increased by 2-4 folds after reopening), if the high magnitude of control measures were implemented (i.e., the detection rates and quarantine rate were enhanced by 2-folds), the pandemic would be well controlled, which was similar to the scenario where no reopening policy was applied, see the epidemic curves of M Tr and M v in Figures 3  and 4 . However, if only a low magnitude of control measures (the detection rates and quarantine rate were enhanced by 1.5-folds), the pandemic would slowly become worse (see the curves of M TU in Figures  3 and 4) . The worst case is that, if no additional control measures were adopted after reopening (no change in the detection rates and quarantine rate), the number of infected cases, hospitalizations and deaths could be rapidly increased with a peak around the late August and early September 2020, see the curves of scenario M TT in Figures 3 and 4 .For the medium risk of reopening case (i.e., the effective contact rate only increased by 3-5 folds after reopening), all the simulation results show that the pandemic would resurge rapidly after reopening. Among the three cases with different magnitudes of control measures, the high magnitude of control measures (the detection rates and quarantine rate were enhanced by 2-folds) could delay the timing of next pandemic wave and reduce the wave magnitude significantly, i.e., the epidemic curve could be flattened (see the curve M Ur in Figures 5 and 6 ). However, if there were no additional control measures adopted after reopening in this case, the number of daily COVID-19 cases, hospitalizations and deaths could dramatically increase to the peak in early July, 2020 (see the curve S21 in Figure 5 ). If the low magnitude of control measures were implemented (the detection rates and quarantine rate were enhanced by 1.5-folds), the pandemic would start to get worse in the middle of June and reach to the peak later in August, 2020, but the peak would be much lower than the case without additional control measures (see the curve S22 in Figures 5 and 6) . Fortunately, the real-world reported confirmed new cases and deaths in Texas (stars in Figures 5 and 6) were between S22 and S23, which might indicate that the medium control measures might have been implemented (i.e., the detection rates and quarantine rate were enhanced between 1.5-folds to 2-folds).On the contrary, for the high-risk reopening policy (i.e., the effective contact rate increased by 4-6 folds after reopening), our simulation results show that the COVID-19 epidemic could not be controlled by even the high magnitude of control measures, and the epidemic could rapidly move to a new wave and different control measures barely had any effect on the timing of next big wave, but only reduced the magnitude of the wave (see Figures S1-S2 in the supplemental material).We also simulated the complete COVID-19 epidemic trajectories until the end of the epidemic in Texas for different scenarios as described above. The final results are summarized in Table 4 . Based on the epidemic trajectory simulations, we observed that, if the stay-at-home order continued instead of reopening after May 2020, the pandemic would be under control (M v ) and end in December 2020, result in a total of 67,196 infections, 1,394 deaths, and 27,582 hospitalizations in Texas. After the reopening policy was implemented, the pandemic could still be under control only if the reopening is a low-risk with a high magnitude of control measures adopted (2-folds increase in the detection rates and quarantine rate), see the curves of M Tr in Figures 3 and 4 . In this case, the pandemic will end in November 2020 and the total number of infected cases, hospitalizations and deaths would be similar to the case without reopening (see Table 4 ). However, if no any control measures were enhanced after reopening, even under the low risk case, the pandemic might last for one more year, probably end in October 2021 with 49,651 in death toll and more than 37% of the Texas population infected. If only a low magnitude of control measures was implemented (1.5-folds increase in the detection rates and quarantine rate), the pandemic might last many years (until spring 2024), but with a smaller death toll, hospitalization and infection counts (see the case S12 in Table 4 ) compared to the case without additional control measures (the case S11 in Table 4 ).If the reopening policy was implemented on May 1 st , 2020 with a medium risk of contact (i.e., the effective contact rate increased by 3-5 folds after reopening) and no additional control measures were implemented after reopening, COVID-19 pandemic might end in April 2021 with a significantly higher total death (101,305) and as many as more than 50% of Texas population could be infected. However, if the additional control measures were implemented (1.5 to 2-folds increase in the detection rates and quarantine rate), COVID-19 pandemic could last longer (end in June 2021 or February 2022), but the total number of deaths, hospitalizations and infected cases could be significantly reduced (see cases S22 and S23 in Table 4 ) compared to the case with no change of controls measures (S21). Particularly, the total deaths could be reduced by more than 40% if the control measures could increase by 1.5-folds and more than 80% if the control measures could increase by 2-folds. If the reopening policy was implemented on May 1 st , 2020 with a high-risk of contact (the effective contact rate increased by 4-6 folds after reopening), COVID-19 pandemic might last for one year (end in spring 2021), but it would result in 10-17 million infections and as high as 142,578 deaths (if no additional control measures were adopted), which is a pandemic disaster.In this study, we developed a comprehensive SEIR model to capture the SARS-CoV-2 transmission based on which we assessed the effect of different reopening policies in Texas, USA. To estimate the model parameters, we used the number of reported confirmed cases and deaths before the reopening policies were implemented, specifically, the data between March 4 th (the first documented COVID-19 case in Texas) and April 28 th , 2020 (the day right after the announcement of Phase 1 reopening policy). Our model fits the reported data very well (Figure 2 ). Based on the estimated model, we simulated the effect of different reopening policies on COVID-19 pandemic in Texas. To our knowledge, this is the first study to investigate the effect of reopening policies in Texas, USA using a data-driven SEIR transmission model.According to the estimated SEIR model, if the ""stay-at-home order"" continued without reopening policy, COVID-19 pandemic could be controlled by the end of 2020 with the lowest number of infected cases, deaths and hospitalizations in Texas. If the reopening policy with strong control and protection measures, i.e., the effective contact rate is low, but the detection rates and quarantine rate were enhanced by 2-folds or higher, the COVID-19 epidemic could be similarly controlled as the case without reopening. However, the data of reported confirmed cases and deaths show that the COVID-19 epidemic in Texas is much worse than these promising cases.If no any additional control and protection measures could be implemented after reopening, the COVID-19 epidemic would result in a rapid pandemic wave with significantly higher numbers of infected cases, hospitalizations and deaths. Additional control and protection measures with different magnitudes could flatten the epidemic curve and reduce the number of infected cases, hospitalizations and deaths, but the low magnitude of control and protection measures could make COVID-19 last longer. For example, the low-risk reopening with a low magnitude of control measures (the case M TU in Table 4 ) could make the pandemic last for four years (up to March 2024). In this case, the COVID-19 epidemic curve could be flattened with a reduced number of infections, but the effect of COVID-19 epidemic on economy would also last longer.Compared the simulation results with the reported COVID-19 epidemic data up to July 2020 in Texas, USA, the real-world epidemic pattern is between the cases of the low and high magnitude of control measures (S22 and S23) with a medium risk of contact rate after reopening (see Figures 5 and 6 ). In this case, the pandemic might last until summer 2021 to February 2022 with a total of 4-10 million infected cases and 20,080-58,604 deaths at the end of epidemic. However, if the COVID-19 epidemic continued in other states of USA and the cross-state transmission could not stopped, this result could be affected and changed. The COVID-19 epidemic trajectories could also be affected by new control policies, vaccines and effective treatments in the future.In this study, the proposed SEIR model shows goodness-of-fit to the reported COVID-19 data before reopening in April 2020, and captured the epidemic trend of COVID-19 after reopening in Texas. We also recognize some limitations of the proposed model and model assumptions. We did not consider the population migration and movement between states in the model. However, since the outbreak of COVID-19, travel restrictions have been implemented and significant cross-state migration and movement could be ignored reasonably. We also assumed that the patients who were confirmed and quarantined at home or hospitalized did not infect others. Due to the data limitation, we also ignored the COVID-19 patients who were dead at home. In the model, we did not consider some big events of gathering, such as annual rodeo and the 'black life matters' parade in big cities, that might have a significant effect on COVID-19 epidemic. Most importantly, the proposed SEIR model suffers the model identifiability problem since the data only for the confirmed infected cases and deaths were available and reliable. The data for the number of hospitalizations and recovered patients were available, but were estimated and not reliable. To alleviate this problem, we fixed some of the model parameters based on the literature and used strong constraints for some of the parameters in the parameter estimation. To valid the simulation results in terms of the choices of the fixed parameters and initial values for model fitting, intensive sensitivity analyses were performed. From Figures S3-S10 in the supplemental material we observed that the prediction results are robust to different choices of the fixed parameters and initial values.This study aims to extend the SEIR model to assess the effect of reopening policies on the COVID-19 epidemic, instead of for accurate predictions of epidemics. The established model can be used to simulate the consequences of different scenarios for different policy changes, which could be used as an evidence-driven guidance for decision-makers to assess the trade-off among different policies. Although our model was developed based on the COVID-19 data of Texas, it could be easily adapted and generalized to other states of USA and other countries. ☒ The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.☐The authors declare the following financial interests/personal relationships which may be considered as potential competing interests:",United States,abstract,2021-02-23,02
6c4d6384d922acc28c647b181e0b4560f0160a06,Title: Overall burden and characteristics of COVID-19 in the United States during 2020,"progression in the future, it is vital that the epidemiological features that have supported these outbreaks be quantified and analyzed in both space and time.Here we use a county-resolved metapopulation model to simulate the transmission of SARS-CoV-2 within and between the 3142 counties of the US. The model depicts both documented and undocumented infections and is coupled with an iterative Bayesian inference algorithm-the ensemble adjustment Kalman filter-which assimilates observations of daily cases in each county and population movement between counties 11, 12 (see Supplementary Information) . The Bayesian inference supports a fitting of the model to case observations and estimation of unobserved state variables (e.g. population susceptibility within a county) and system parameters (e.g. the ascertainment rate in each county). The model fitting captures the 3 waves of the outbreak as manifest at national scales (Fig 1a) , as well as in major metropolitan areas throughout the country (Fig S1) .To further validate the simulations, we compared model estimates of cumulative infections to findings from US Centers for Disease Control and Prevention (CDC) seroprevalence surveys conducted at site and state levels 13 . The seroprevalence data, which provide an out-of-sample corroboration of the model fitting, were adjusted for the waning of antibody levels following adaptive immune response 14, 15 (see Supplementary Information, Figs S2-S3). Model estimates of cumulative infected percentages are well aligned with adjusted seroprevalence estimates from the CDC 10-site survey across sites and through time (Pearson r=0.97, mean absolute error (MAE)=1.34%) (Fig 1b) and are similarly well matched to adjusted estimates at the state level ( Fig S4) .A critical feature of SARS-CoV-2 is its ability to infect and transmit largely from individuals never diagnosed with the virus 5 . The model structure and fitting enable estimation of the ascertainment rate, the percentage of infections confirmed diagnostically, at county scales. The national population-weighted ascertainment rate averaged for all of 2020 was 21.6% (95% credible interval (CI): 18.9 -25.5%). This national ascertainment rate increased from 11.2% (8.3 -15 .7%) during March 2020 to 24.3 % (18.4 -32.1%) during December 2020 (Fig 1c) . The increase through time is a likely by-product of increasing testing capacity, a relaxation of initial restrictions on test usage, and increasing recognition, concern and care-seeking among the public. We additionally focus on 5 metropolitan areas within the US. Small differences in the ascertainment rate manifest across these areas; in particular, ascertainment rates for Phoenix and Miami are higher than the national average for much of the year, whereas New York City, Chicago, and Los Angeles are consistently below the national average.At the national level, three pandemic waves are clearly evident during spring, summer and fall/winter (Fig 1a) ; however, among the 5 focus metropolitan areas the structure differs with New York and Chicago experiencing strong spring and fall/winter waves but little activity during summer, Los Angeles and Phoenix undergoing summer and fall/winter waves, and Miami experiencing all 3 waves (Fig S1) . Los Angeles county, the largest county in the US with a population of more than 10 million people, was particularly hard hit during the fall/winter. The differences in virus activity produced different cumulative infection numbers through time (Fig  2a) . Population susceptibility at the end of the year was 68.8% (63.4 -75.3%) for the US, and among the focal metropolitan areas ranged from 47.9% (39.6 -54.9%) in Los Angeles to 71.4% (65.4 -74.2%) in Phoenix. Though there is variability among counties, a substantial portion of the US population (68.8%) had not been infected by the end of 2020; however, pockets of lower population susceptibility, which are evident in the southwest and southeast on August 1st (Fig.  2b) , expanded considerably by December 1st (Fig 2c) . In particular, areas of the upper Midwest and Mississippi valley, including the Dakotas, Minnesota, Wisconsin and Iowa, are estimated to have population susceptibility below 40% as of December 1, 2020.The structure of the outbreak is evident in both incidence and prevalence estimates (Figs 3, S5, S6). Incidence indicates the daily number of newly infectious individuals-both those who will be confirmed COVID-19 cases and those whose infections will remain undocumented. The majority of infections each month are undocumented (Fig 3a) , as indicated by the low ascertainment rates (Fig 1c) . For all of 2020, an estimated 78.4% of infections in the US were undocumented. Estimates of daily prevalence provide a measure of the community infectious rate, the fraction of the population currently harboring a contagious infection. National SARS-CoV-2 prevalence increased to 0.78% (0.61 -1.00%) by December 31, indicating that roughly 1 in 128 persons was contagious (a similar percentage, 0.84% (0.53 -1.28%), was estimated to be latently infected, i.e. infected but not yet contagious) (Fig 3b) . Among the 5 focal metropolitan areas, prevalence varied considerably: in mid-November, Chicago reached a prevalence of 1.50% (1.28 -1.77%); whereas prevalence in Miami rose to 1.22% (1.00 -1.46%) during July. Los Angeles was even more burdened at the end of 2020 with a prevalence of 2.40% (2.00 -2.89%) as of 31 December (Fig S6) .The model fitting enables estimation of the case fatality rate (CFR) and the infection fatality rate (IFR). Both rates were highest at the national level at the beginning of the spring wave: the CFR was 8.83% (6.75 -11.40%) and the IFR was up to 0.96% (0.62 -1.53%) in March and April (Fig 3c) . Over the course of the year, with earlier diagnosis and treatment, improved patient care, and, in the case of CFR, increased reporting of mild infections, the CFR and IFR dropped to 1.16% (0.95-1.48%) and 0.28% (0.22 -0.35%) by December, respectively. Both rates varied by location and over time; for instance, intermediate drops of CFR and IFR began for Los Angeles, Phoenix and Miami prior to the summer wave in association with a decrease in the average age of documented infection ( Fig S7) . Overall, these findings delineate the mortality risk associated with infection broadly. The national IFR during the latter half of 2020 hovers around 0.30%, well above estimates for both seasonal influenza (<0.02%) 16 and the 2009 influenza pandemic (0.0076%) 17 .Given the high numbers of cases and deaths, and the successive pandemic waves, a central question is whether local populations within the US have responded to the growth of infections in their communities with improved control through non-pharmaceutical interventions (NPIs). Such control, effected through mask usage, social distancing, indoor ventilation, surface cleaning and restrictions on mass gatherings and other indoor activities, is reflected in the modulation of the time-varying reproduction number, Rt. A decrease of Rt over time suggests a community is improving control of the virus by regulation or public adoption of control measures. For each of the three waves during 2020, we identified counties that experienced 2 or more consecutive weeks of increasing (or decreasing) reported cases and also reported 15 daily cases per 100,000 persons at least once during the period. We then examined trends of Rt for each of these 3 periods. During the earliest period in the spring, Rt decreased when counties experienced case growth and case decline; however, the decline in Rt is more precipitous when counties experienced growth (Fig 4a) . During the second, summer period, the decline of Rt in counties with case growth starts at a lower level and is more muted, and counties experiencing declining case numbers instead have an increase of Rt.During the final fall/winter period, the patterns are similar to the summer period with Rt decreasing in counties experiencing case growth but decreasing in counties experiencing case decline. The same trends are present when averaging the counties to regional scales (Fig 4b,c) , as well as when using different case per capita thresholds (Figs. S8-S9). Overall, this analysis suggests a lessening ability or willingness to control SARS-CoV-2 in the US as the year progressed. Part of this year-long trend, particularly during the fall/winter wave, is likely due to seasonal effects that moderate Rt and are beyond direct human control. In particular, evidence suggests that SARS-CoV-2 is more transmissible when humidity levels are low 18 , as is the case during winter in temperate regions, and that people are bound to spend more time indoors during winter when temperatures are low. Both effects likely increased opportunities for transmission during the third wave and for the most part cannot be effectively counteracted. However, policies and behaviors, specifically the use of masks, social distancing, ventilation, restricting mass gatherings and indoor dining, etc., that limit opportunities for virus transmission are subject to regulation and individual choice. Individual control behaviors may have slackened towards the end of the year, and policies allowing indoor dining and other commercial activities were more common late in the year 19 . The relative contributions of seasonal versus behavioral effects on changing Rt trends across successive pandemic waves cannot be disentangled in this analysis.The US experienced the highest numbers of COVID-19 cases and deaths in the world during 2020. Our findings provide quantification of the time-evolving epidemiological characteristics associated with successive pandemic waves in the US, as well as conditions at the end of the year and prospects for 2021. Critically, despite more than 19.6 million reported cases at year's end, more than 68% of the population remained susceptible to viral infection. Several factors will considerably alter population susceptibility in the coming months. Firstly, ongoing transmission will infect naïve hosts and continue to deplete the susceptible pool. Secondly, as more vaccine is distributed and administered, more individuals will be protected against symptomatic infection and the IFR will decrease. Lastly, our model does not represent re-infection, either through waning immunity or immune escape; however, re-infection has been documented 20,21 , evidence of waning antibody levels exists 22, 23 , and new variants of concern have emerged 24,25 and will likely continue to do so. All these processes will affect population susceptibility over time and help determine when society enters a post-pandemic phase, the pattern of endemicity the virus ultimately assumes, and its long-term public health burden 26 .Detection of the virus in the US improved during 2020 with the ascertainment rate rising from less than 11% in March to nearly 25% in December. Still, the majority of infections remain undocumented, consistent with other estimates 27 . While many of these infections likely present with mild or no symptoms, they remain contagious and support undetected transmission of SARS-CoV-2 5 making control of the virus very challenging.Both CFR and IFR declined during 2020. IFR decreased from around 1% in March to about 0.25% in December. Earlier case detection and improved clinical care 28,29 likely contributed to the decline of both the CFR and IFR during 2020; however, both CFR and IFR are also highly age-dependent with older individuals at substantially greater risk of hospitalization and death 27,30 , so changes to the age distribution of infections over time may have also affected these rates.Our findings reveal how conditions associated with transmission, case numbers, susceptibility, mortality and control evolved during 2020. Considerable differences in the progression of the pandemic and its epidemiological features manifest in both space and time. In addition, local control efforts appear to have strengthened or slackened in response to increasing or decreasing cases within a locality. This variable responsiveness underscores the need for continued public health messaging emphasizing the maintenance of NPIs while vaccines are distributed and administered.We use a metapopulation SEIR model to simulate the transmission of COVID-19 in the US at county level. In this model, we explicitly simulate the transmission of documented and undocumented infections, for which separate transmission rates are defined. Further, we assume there is no re-infection of SARS-CoV-2, and that vaccine deployment prior to 31 December 2020 nominally affects population susceptibility.The model incorporates two types of human mobility across 3,142 US counties -regular daily commuting and diffusive random movement. Information on inter-county commuting is available from the US census survey 1 . During the daytime, commuters travel to counties where they work and mix with the population there; after work, they return home and mix with individuals in their home, residential county. Apart from regular commuting, a fraction of the population in each county, assumed to be proportional to the number of inter-county commuters, travels for purposes other than work. As the population present in each county is different during daytime and nighttime, we model the transmission dynamics of COVID-19 separately for these two time periods. Specifically, we formulate the transmission as a discrete Markov process during both day and night times. The transmission dynamics are depicted by the following equations.Daytime transmission:Nighttime transmission:!"" ( + 1) = !"" ( + # ) +!""Daily work commuting: During the daytime, the population in location ,, is the sum of individuals who both live and work in location , documented infected individuals who would otherwise commute to other locations ( ≠ ), and individuals who work in location from other locations ( ≠ ) but are not documented infections. Within the subpopulation !"" , new infections derive from two processes: contact with documented and undocumented infections in location . For each susceptible individual in !"" ( ), the chance of contact with documented infections is ∑ $! % ( )is the total number of documented infections who would commute to all locations but have to stay in location , and the chance of contact with undocumented infections is( ) is the total number of undocumented infections in location . Those contacts lead to new infectionsduring a period of # day. Note this term captures the mixing of populations from different locations due to work commuting, and represents intra-county transmission during the daytime in location .Random movement: Apart from work commuting, during the daytime, # 0 !$ persons, drawn uniformly from the population present in location ( ≠ ) (except for documented infections) move to location and are randomly redistributed into the subpopulation there. Such population exchange exists for all pairs of locations. For example, for the susceptible population, we first compute the number of susceptible individuals entering into subpopulation !"" ( ). In other locations ( ≠ ), the probability a random visitor is susceptible is ∑ $( ( ) is the total mobile population (i.e., total population minus documented infected population) in location . Therefore, the total susceptible population entering location is. Those individuals are redistributed into subpopulations present in location , where the fraction of people in subpopulation !"" is ( !"" − !"" % ( ))/ ! & ( ). Finally, the number of susceptible individualsWe then compute the number of susceptible individuals leaving !"" ( ). The total number of individuals leaving location is; the fraction of susceptible people from !"" isAs a result, the number of susceptible persons leaving !"" ( ) is(6-10) for nighttime transmission similarly.Prior to March 1, 2020, we used the commuting data from the US census survey to prescribe the inter-county movement in the transmission model. After March 1, the census survey data are no longer representative due to changes in mobility behavior following implementation of nonpharmaceutical interventions. We therefore used estimates of the reduction of inter-county visitors to points of interest (POI) (e.g., restaurants, stores, etc.) from SafeGraph 2 to account for the change of inter-county movement on a county-by-county basis. For instance, if the number of inter-county visitors in a county was reduced by 10% on a given day relative to the baseline on March 1, the number of commuters and random visitors to this county would be reduced by 10% accordingly.The transmission model generates daily confirmed cases for each county. To account for reporting delays, we mapped simulated documented infections to confirmed cases using a separate observational delay model. In this delay model, we account for the time interval between a person transitioning from latent to contagious (i.e., → % ) and confirmation of that individual infection. To estimate this delay period, % , we examined a U.S. line list data record consisting of 13.4 million confirmed cases until December 31, 2020 3 . We used a gamma distribution to fit the time-to-event distribution of the interval (in days) from symptom onset to case confirmation for each month in 2020. We modeled % by adding another 2.5 days to the mean periods of the obtained gamma distributions, as symptom onset is estimated to lag the onset of contagiousness 4 . The gamma distributions of % from April to December are provided in Table S1 .We calibrated the transmission model against county-level incidence data reported from 21 February 2020 to 31 December 2020, available at Johns Hopkins University coronavirus resource center 5 . Model parameters were estimated using a sequential data assimilation methodthe ensemble adjustment Kalman filter (EAKF) 6 , which is applicable to high-dimensional metapopulation models and has been successfully used to infer epidemiological parameters for a range of infectious diseases 7-11 . To represent the state-space distribution (including both parameters and variables), the EAKF maintains an ensemble of system state vectors acting as samples from the distribution. In particular, the EAKF assumes a Gaussian distribution of both the prior and likelihood and adjusts the prior distribution to a posterior using Bayes' rule: posterior ∝ prior × likelihood. For the observed variables (i.e., daily incidence), ensemble members are updated deterministically such that the higher moments of the prior distribution are preserved in the posterior. Unobserved variables and parameters are updated based on their covariability with the observed variable, which can be computed directly from the ensemble. Further details on the EAKF scheme can be found in Anderson 6 .To initialize the model-inference system, we seeded exposed individuals ( ) and undocumented infections ( ' ) in counties with at least five confirmed case. Specifically, we randomly drew and ' from uniform distributions [0, 12 ] and [0,10 ] 9 days before the first date with more than five reported cases, , , where is the total number of reported cases between day , and , + 4. This setting provides a broad seeding range for US counties. The prior ascertainment rates were drawn from a distribution with a median value = 0.080 (0.069 -0.093), estimated using case data prior to 13 March 2020. The prior transmission rates were scaled on the basis of the local population density: ! = , × log #, ! /median(log #, ), where ! is the population density in county , median(log #, ) is the median value of log-transformed population density among all counties, and , = 0.95 (0.84 -1.06) is the baseline transmission rate estimated before 13 March 2020. For counties that reported less than 20 cumulative cases as of 15 March 2020, we reduced the prior transmission rate by half to reflect the impact of nonpharmaceutical interventions implemented after the announcement of national emergency. We performed the inference using 100 ensemble members.In this study, we report the transmission dynamics in and around five major US cities: New York, Chicago, Los Angeles, Phoenix, and Miami. Characteristics of SARS-CoV-2 transmission (e.g., ascertainment rate, CFR, and IFR) in these metropolitan areas were aggregated from county-level estimates. Note that in some cases the metropolitan areas as defined here differ from the formal metropolitan statistical areas delineated by the United States Office of Management and Budget. The counties we include in the metropolitan areas for this analysis are:We validated the estimated cumulative infections against the proportion of SARS-CoV-2 seropositive individuals from two large-scale serological surveys in the US: 1) surveys in 10 sites until August 2020 13, 14 , and 2) state-level surveys from August 2020 to November 2020 15, 16 . We primarily focused on the 10-site survey as samples were collected in more consistent and specific locations.The serological surveys give an indication of the proportion of individuals previously infected by SARS-CoV-2 and in principle should be similar to the proportion of cumulative infections estimated by the model. However, the seroprevalence rates likely underestimate the fraction of a population previously infected with SARS-COV-2 due to antibody waning. Specifically, antibody titers in recovered individuals decline over time, and seroreversion in the months following adaptive immune response is common 17 . Note, such decline in antibody titers does not necessarily preclude protection from repeat infections mediated by other components of the adaptive immune response.We adjusted the reported seroprevalence by first correcting for errors in serological testing. The assay used to detect antibodies against SARS-CoV-2 reports 96% (95% CI: 98.3 -99.9%) sensitivity and 99.3% (98.3 -99.9%) specificity 13 . The seroprevalence adjusted for testing sensitivity and specificity is = > %-./%0 + − 1?/( + − 1), where %-./%0 is the reported seroprevalence 18 .We then adapted the method of Buss et al. to quantify antibody waning (seroreversion) and to estimate an adjusted seroprevalence that is inclusive of individuals who have seroreverted 19 . This method has been used to estimate the percentage of the population infected with SARS-CoV-2 in Manaus, Brazil during a largely unmitigated outbreak 19 . In order to estimate the antibody waning rate, we used the seroprevalence data for New York City from the 10-site study. As New York City was the epicenter in the US during the early phase of the COVID-19 pandemic, the effect of seroreversion is expected to be more apparent there than for other locations.To estimate , we first sampled ( ! ) ( = 1, … ,6) from a uniform distribution [ (/7-% ( ! ), '..-% ( ! )], where (/7-% ( ! ) and '..-% ( ! ) are the observed lower and upper bounds of seroprevalence adjusted for testing characteristics. We then searched a range of linearly spaced numbers from 0.001 to 0.999 and computed for each using the sampled seroprevalence data from New York City. As New York City reported few cases in July, we estimated as the value that minimizes the number of new recoveries in the last two sampling periods (i.e., ( 8 ) + ( 9 ), July 7 to 11 and July 27 to 30 July) under the constraint ( ! ) ≥ 0 for all ! . To account for uncertainty in observed seroprevalence, we independently drew 100 samples of , and selected the value that generated the lowest new recoveries in July among all samples. This process was repeated 1,000 times to obtain the distribution of monthly attenuation: = 0.90 (95% CI: 0.86 -0.95). The adjusted seroprevalence in New York City is the cumulative number of recoveries per capita computed using the estimated parameter . For other locations, we used the same parameter to correct the prevalence if it generates nonnegative ( ! ) for all ! . Otherwise, we chose the parameter closest to in New York City that produces non negative ( ! ) 18 . The adjusted and reported seroprevalence for the 10 sites are shown in Fig. S2 . To match the estimated cumulative infection and seroprevalence in one location, we assumed seroconversion takes an average of 10 days (e.g., from infection acquisition to generation of detectable antibody). A 14-day seroconversion period was also tested and results remained similar.We applied the same method to adjust state-level seroprevalence reported from August to November 2020 (Fig. S3) . However, as seroprevalence data were not available prior to August, the adjustment cannot account for seroreversion before August 2020. As a result, the adjusted seroprevalence in August is an underestimate. In addition, because the sample size is small relative to the population of each state and the samples may not be representative of general US population, anomalies may appear in the reported seroprevalence. For instance, the survey in North Dakota estimated 7.3% seroprevalence between 29 July and 12 August; however, it dropped to 0.6% between 12 August and 25 August. To exclude any severely biased seroprevalence data, we assumed the monthly attenuation rate to be no higher than 15%. Observations that indicated faster antibody waning (e.g., North Dakota) were excluded from the analysis. In total, seroprevalence data in 17 states were used (Fig. S3a ). Despite these limitations, our inferred cumulative infected percentages are well matched to adjusted seroprevalence at state level (Fig. S4a , Pearson = 0.76, mean absolute error (MAE) = 3.61%). Note that the adjusted seroprevalence data in August (blue dots) are generally lower than model estimates, as seroreversion prior to August was not considered in the adjustment. For later surveys (yellow nodes), this systematic bias is less severe. We further performed the same analysis using a maximum monthly attenuation rate of 25% ( Fig. S3b and Fig. S4b , Pearson = 0.72, mean absolute error (MAE) = 4.57%).The estimated monthly infections (both documented and undocumented) in the US and five metropolitan areas are reported in Fig. S5 . The prevalence of contagious infections in the community is estimated as the percentage of active infectious cases ( % + ' ) among the general population. We provide the daily confirmed cases and estimated prevalence of contagious infections in the US and five metropolitan areas in Fig. S6 ../>0 ( ) is the posterior confirmed cases on day . Note here we shifted the computation time window forward for % days to account for reporting delays. Based on observations of confirmed COVID-19-related deaths in New York City 20 , the mean time from confirmation to death is & = 9 days. We therefore estimated the number of deaths among patients infected on day as ∑ ℎ( :, and the IFR is computed as = ∑ ℎ( :. As death data for individuals infected in late December were not available when we performed the study, we limited analysis on CFR and IFR until 1 December 2020.As the mortality rate has large variations across different age groups, the overall IFR at a given time depends on the age structure of infections. The fraction of confirmed infections for each age group in HHS region 4 (Alabama, Florida, Georgia, Kentucky, Mississippi, North Carolina, South Carolina, and Tennessee) reported by the CDC 21 is shown in Fig. S7 .",United States,abstract,2021-02-17,02
819fe173a0c2982dc88e6fba85c06cd5160aaba4,Risk factors for increased COVID-19 case-fatality in the United States: A county-level analysis during the first wave,"The Severe Acute Respiratory Syndrome Coronavirus 2 (SARS-CoV-2) originated in Wuhan, China in November 2019 and has since spread to 210 countries worldwide. 1 By June 12th, 2020, SARS-CoV-2 had caused over 2 million Coronavirus Disease 2019 (COVID-19) cases and 114,753 deaths in the United States (US). 2, 3 The distribution of infected cases and fatalities in the US has been heterogeneous across counties, 4 and identification of sub-populations at risk of increased morbidity and mortality remains crucial to effective response efforts by federal, state, and local governments. 5 Counties where governing officials are aware that their populations are at a higher risk of COVID-19 mortality, meaning the population experiences a higher casefatality rate, may opt to tailor state policies or take earlier action to curtail the spread of SARS-CoV-2. Additionally, the federal government may opt to target vaccine resources to counties experiencing higher COVID-19 mortality rates.The case-fatality rate (CFR) is defined as the number of deaths divided by the total number of confirmed cases from a given disease. 6 When a disease is non-endemic, the CFR fluctuates over time. During the beginning of an epidemic, there is often a lag when counting the number of deaths compared to cases and hospitalizations, leading to an underestimation of the CFR.Furthermore, CFR will fluctuate rapidly early in an epidemic when each additional case or death has an excessive impact on calculating CFR. It is important to not only account for the lag between cases and deaths (i.e., lag-adjusted CFR), but also to ensure that the CFR is no longer fluctuating.In this study, we use a lag-adjusted CFR to conduct a county-level mortality risk factor analysis of demographic, socioeconomic, and health-related variables in the US during the first wave of the COVID-19 pandemic (March 28, 2020 to June 12, 2020). We expand upon prior work by considering possible risk factors of an increased CFR from multiple categories (e.g., nonpharmaceutical interventions such as shelter-in-place orders, 7 prevalence of pre-existing conditions such as cardiovascular disease, 8 and socio-economic circumstances such as hospital accessibility 9 ) in a single model.All code for our work can be found on our GitHub repository. 10 We conducted a cross-sectional ecological study to assess risk factors associated with an increased COVID-19 lag-adjusted CFR in US counties. Our study population included 3,004 counties or county-equivalents with Federal Information Processing Standards (FIPS), a unique code for US federal identification. Only publicly available aggregate data were used; therefore, no IRB approval was required.To reduce multicollinearity, we eliminated linear combinations and variables with correlations >0.5 using the R package caret (v6.0.86). Remaining variables were screened for missingness and missing values were imputed using five imputations in the R package mice (v3.8.0). Data were randomly split into training (1,186 counties) and testing sets (593 counties) to assess generalizability (a table of the characteristics can be seen in Appendix A5). A negative binomial Of the 64 variables collected, 22 were retained for analysis after minimizing correlation (Appendix A3-7 14 ). Multiple imputation was used to correct for missingness (less than 2%) in two of the retained variables, neither of which appeared in the final model. 21 Fifteen variables were significant in bivariate models in the first step of purposeful selection, and were included in the initial multivariate model. Eight variables were significant in the initial multivariate model and were retained in the final model. Including variables that were non-significant in the bivariate models with these eight variables did not significantly change the performance of the model, as determined by the Likelihood Ratio Test. No potential confounders were identified among the correlation minimized variables that were previously discarded due to nonsignificance in the models.The final model is shown in Exhibit 1. The negative binomial model appears to be a good fit, capturing the mean-variance relationship observed in the data and displaying expected residuals (Exhibit 2A and 2B). The model was well-calibrated, with the training and testing model having comparable coverage and relative Gini score (Exhibit 2C and 2D; Appendix A7). Since we used a negative binomial model with an offset, the exponentiated coefficients represent the change in laCFR observed for a one-unit increase in each continuous variable, assuming all other variables in the model are held constant (Exhibit 3). Four variables were inversely associated with laCFR: number of hospitals per 10,000 people (-39% laCFR per additional hospital per 10,000), banning religious gatherings during the initial state or county shutdown (-13% laCFR if religious gatherings were banned), percentage of housing units that were mobile homes (-0.79% laCFR per 1% increase in the proportion of mobile homes), and percentage of population without health insurance (-1.5% laCFR per 1% increase in percentage uninsured). Four variables were directly associated with laCFR: percentage over age 65 (+4.4% laCFR per 1% increase in population over age 65), percentage Black or African American (BAA) (+0.97% laCFR per 1% increase in BAA population), percentage with asthma (+9.1% laCFR per 1% increase in asthma prevalence), and number of hospitals (+3.1% laCFR per one additional hospital). Exhibit 4 demonstrates the relationship between each variable and the laCFR over a range of values.In this ecological study of mortality due to SARS-CoV-2 infection during the first wave of COVID-19 in the US, we found that county-level laCFR was significantly associated with eight variables. Four variables -banning religious gathering, proportion of mobile homes, hospitals per 10,000 persons, and proportion of uninsured individuals in a county -were associated with decreased laCFR. Four variables -percentage of population over age 65, total number of hospitals per county, prevalence of asthma, and percentage of population BAA -were associated with increased laCFR. Each variable provided unique insights into factors that may be worth considering for county-level COVID-19 response efforts.The percentage of the population living in mobile homes was also associated with a decrease in laCFR. A 1% increase in mobile home living was associated with a 0.79% decrease in laCFR.While a small difference at first glance, it becomes more meaningful when considering the large variation in mobile home living across counties. Between counties at the 25th percentile of percentage living in mobile homes (4%) and 75th percentile (18%), the difference in the percentage of mobile home living correlated with an 11% decrease in laCFR. This might represent a built-environment effect, given that mobile homes have separate plumbing and ventilation unlike apartments and other multi-family residences. Recent work suggests that fecal aerosol transmission of SARS-CoV2 can occur. 26 Ventilation patterns in apartment complexes represent additional opportunities for transmission. 27 The benefit of separate units such as mobile homes may be especially important to low-income workers who are both more at risk of death from COVID19 due to increased chance of having a co-morbid condition and more likely to live in multi-family housing with maintenance issues. 28 The number of hospitals per 10,000 was also inversely associated with laCFR. We found that for each additional hospital per 10,000 inhabitants, the laCFR decreased by 39%, despite the exclusion of other healthcare-related variables due to non-significance (e.g., ICU bed availability). Prior work demonstrated that the percentage of ICU and non-ICU beds occupied by COVID-19 patients directly correlated with COVID-19 deaths, 29 and a county with more hospitals per 10,000 inhabitants may be able to cope with more COVID-19 cases before reaching the same percentage of hospitals beds occupied as a county with fewer hospitals per 10,000More hospitals per 10,000 persons may also represent increased competition for patients, which is associated with decreased mortality from community-acquired pneumonia. 31 Unexpectedly, the percentage uninsured was inversely associated with laCFR. We found a 1.5% reduction in laCFR for every 1% increase in uninsured inhabitants. Prior studies found longer travel times to COVID-19 testing facilities were directly associated with percentage uninsured. 32, 33 Because uninsured persons may be unable to readily access testing, this finding may relate to incomplete reporting, such that only individuals who survive long enough are tested for COVID-19, leading to a potential undercount of deaths attributable to SARS-CoV-2 infection.This study had several strengths besides the benefits of an ecological design when considering population interventions. First, the data were nationally representative, including over 50% of all US counties. Our model captured the variability in the data and accounted for the observed data distribution. The model also captured almost all outcomes within the prediction interval for both training and testing data sets, with similar accuracy between them, which indicates that our model is generalizable within the US (Appendix A7). Additionally, our model based laCFR calculations on the distribution of times from hospitalization to death from US data, 19 which differed from earlier Chinese data. 37 Using US-based distribution of times likely improved our laCFR estimation for this study. The final model included several variables previously attributed to higher laCFR (such as older age) 34 and included a variable unique to the pandemic shutdown, i.e., banning religious gatherings, giving more nuanced insights into heterogeneous COVID-19 mortality rates across counties.Finally, our study period ended in mid-June. This date was chosen because (1) enough cases had occurred in the US to obtain reliable estimates of laCFR by county and (2) it preceded CDC reopening guidance and a shift in reporting to the HHS Protect system, which is less readily available to the public than the prior CDC reporting system.51 The decision by the government to switch to the HHS Protect system hinders the ability of academic scientists to aid in the response to the on-going pandemic. 51 Making these data more readily available to the public would permit inclusion of additional data for future research.",United States,first author,2021-02-26,02
c73a1706b7aba0828995c610a469f56104a69b1a,"Journal Pre-proof SARS-CoV-2 infects human pluripotent stem cell-derived cardiomyocytes, impairing electrical and mechanical function SARS-CoV-2 infects human pluripotent stem cell-derived cardiomyocytes, impairing electrical and mechanical function","With over 100 million people affected worldwide, the outbreak of Severe Acute Respiratory Syndrome-Coronavirus 2 (SARS-CoV-2) has already left its permanent mark on human history (Hopkins, 2020; Zhu et al., 2020) . SARS-CoV-2 belongs to the family of coronaviridae, a large group of single-stranded enveloped RNA viruses reported for the first time in humans in the 1960s (Andersen et al., 2020; Corman et al., 2018; Cui et al., 2019) . Besides being long recognized as one of the common cold viruses, coronaviruses took center stage in infectious disease medicine following the outbreaks of SARS-CoV in 2003 and of Middle East Respiratory Syndrome-coronavirus (MERS-CoV) a decade later. Coronaviruses became thus recognized as highly pathogenic for humans, with a symptomatology that focuses on the respiratory system while often also involving extra-respiratory organs (Alhogbani, 2016; Nishiga et al., 2020; Oudit et al., 2009; Zhou et al., 2020) . Indeed, even though the lungs represent the main target, cardiovascular complications (including worsening of pre-existing conditions and onset of new disorders), were not only reported for SARS-CoV and MERS-CoV, but are also significantly contributing to the mortality of COVID-19 patients during the ongoing pandemic (Alhogbani, 2016; Oudit et al., 2009; Shi et al., 2020; Zhou et al., 2020) .The most common cardiovascular complications observed after SARS-CoV-2 infection are myocardial injury (including cases with and without classic coronary occlusion), arrhythmias, and heart failure (Baggiano et al., 2020; Nishiga et al., 2020; Ojha et al., 2020; Ruan et al., 2020; Shi et al., 2020; Wang et al., 2020; Xu et al., 2020; Zhou et al., 2020) . In particular, myocardial injury, characterized by elevated serum levels of cardiac troponin I and/or electrocardiogram (ECG) abnormalities, has been independently associated with increased mortality in COVID-19 patients . Moreover, as reported also for SARS-CoV (Madjid et al., 2007) , SARS-CoV-2 can trigger acute coronary syndrome even in the absence of systemic inflammation (Nishiga et al., 2020; Wang et al., 2020) . Retrospective studies show that J o u r n a l P r e -p r o o f hospitalized COVID-19 patients develop cardiac arrhythmias, including ventricular tachycardia and atrial fibrillation (Bhatla et al., 2020; Malaty et al., 2020; Wang et al., 2020; Zylla et al., 2021) . Progressive left ventricular dysfunction and overall symptoms that resemble heart failure have also been observed in a significant number of patients Huang et al., 2020a; Wang et al., 2020; Zhou et al., 2020) . At the beginning of the outbreak this symptomatology was reported mostly in critically ill COVID-19 patients . A sizable number of more recent studies has reported that cardiac symptoms are observed also in mild and even asymptomatic cases of COVID-19 (Arentz et al., 2020; Huang et al., 2020b; Inciardi et al., 2020; Puntmann et al., 2020; Rajpal et al., 2021) .The mechanisms behind cardiac disease reported for COVID-19 are still unclear (Nishiga et al., 2020; Zhou et al., 2020) . Upon lung infection, the uncontrolled release of inflammatory cytokines, termed ""cytokine storm"", could induce multi-organ damage, ultimately leading to organ failure and worsening of pre-existing cardiovascular disorders (Driggin et al., 2020; Inciardi et al., 2020; Tay et al., 2020) . Moreover, COVID-19 is associated with coagulopathies, which also can induce ischemic heart damage (Driggin et al., 2020; Nishiga et al., 2020; Ranucci et al., 2020) . Lastly, SARS-CoV-2 could directly mediate heart injury by entering cardiomyocytes or other cardiac stromal and/or vascular cells via binding of the viral spike glycoprotein to its extracellular receptor, angiotensin I converting enzyme 2 (ACE2) (Baggiano et al., 2020; Hoffmann et al., 2020) . This protein is expressed in different tissues of the human body, including cardiomyocytes and cardiac pericytes, and its primary function is to counterbalance the renin-angiotensin-aldosterone system (Chen et al., 2020a; Hikmet et al., 2020; Li et al., 2020; Verdecchia et al., 2020) .Several studies detected SARS-CoV-2 genome in the heart and/or reported signs of viral myocarditis in COVID-19 infected individuals, including asymptomatic cases (Bradley et al., 2020; Dolhnikoff et al., 2020; Lindner et al., 2020; Rajpal et al., 2021) . Moreover, in vivo and in J o u r n a l P r e -p r o o f vitro studies utilizing both human adult cardiomyocytes and human pluripotent stem cell-derived cardiomyocytes (hPSC-CMs) have shown that SARS-CoV-2 can infect cardiomyocytes, indicating that SARS-CoV-2 could exhibit cardiac tropism (Bojkova et al., 2020; Chen et al., 2020b; Sharma et al., 2020; . However, whether SARS-CoV-2 infection of human cardiomyocytes leads to a direct impairment of cardiac function is still unresolved.Furthermore, whether other cardiac cell types are also susceptible to SARS-CoV-2 remains unclear.In this study we examine the mechanisms behind COVID-19-related cardiac symptoms using hPSC-CMs and hPSC-derived smooth muscle cells (hPSC-SMCs), established models for cardiovascular disease research (Bertero et al., 2019b; Cheung et al., 2012; Serrano et al., 2019; Yang et al., 2018) . SARS-CoV-2 specifically infects and propagates within hPSC-CMs, a process that appears to exquisitely rely on ACE2 and to both involve direct membrane fusion and entry through the endo-lysosomal pathway. Pathways involved in RNA splicing and chromatin accessibility are significantly upregulated after infection, whereas pathways involved in oxidative metabolism and mitochondrial function are downregulated. SARS-CoV-2 infection results in disruption of the contractile cytoskeleton, electrical and mechanical dysfunction, and eventual cell death. These findings provide evidence for a direct viral cytopathic pathway involving cardiac myocytes in the context of COVID-19-related cardiac disease.infection is thought to depend on expression of both the viral receptor ACE2 and various host proteases Millet and Whittaker, 2015; Shang et al., 2020; Zumla et al., 2016) . We found that ACE2 is transcriptionally activated during cardiac differentiation of both RUES2 embryonic stem cell-derived cardiomyocytes (hESC-CMs; Fig. 1A ) and WTC11c induced pluripotent stem cell-derived cardiomyocytes (hiPSC-CMs; Supplementary Fig. 1A ).Single-cell RNA-sequencing analysis detected ACE2 mRNA in ~9% of hESC-CMs, indicating low and/or transitory expression (Fig. 1B) . A larger fraction of cells expressed moderate to high levels of endosomal cysteine proteases CTSB (cathepsin B; ~71.0%) and CTSL (cathepsin L; ~46.0%). Detection of these factors is relevant because they can cleave the spike glycoprotein leading to endomembrane fusion-mediated release of SARS-CoV-2 genome inside the cytoplasm (Kang et al., 2020; Millet and Whittaker, 2015; Ou et al., 2020; Yang and Shen, 2020) . Importantly, these viral processing factors were often co-expressed with ACE2( Supplementary Fig. 1B) . Although viral entry can also be mediated by TMPRSS2 Shulla et al., 2011) , this transmembrane serine protease was not detectable in hESC-CMs ( Supplementary Fig. 1C ), as also reported for the adult human heart (Litvinukova et al., 2020) . Interestingly, the lipid phosphatase, PIKFYVE, another endosomal viral processing factor, and FURIN, a membrane-bound serine protease, were also broadly expressed in hESC-CMs ( Supplementary Fig. 1C ), overall suggesting that the mechanism of SARS-CoV-2 entry in cardiomyocytes might be different from the TMPRSS2-dependent one reported for lung epithelial cells Schneider, 2020; Shang et al., 2020; Xia et al., 2020b) .Despite the relatively low levels of mRNA, ACE2 protein was clearly detectable by western blot in hPSC-CMs derived from multiple lines (RUES2 female hESCs, H7 female hESCs, and WTC11c male hiPSCs), reaching levels comparable to those of VERO cells, a primate kidney epithelial line with established SARS-CoV-2 tropism (Figs. 1C and 1D). Emphasizing the specific tropism of SARS-CoV-2 for hPSC-CMs, ACE2 was expressed at very low levels in hESC-SMCs of varying embryonic origin (lateral mesoderm-or neural crest-derived, all differentiated from H9 female hESCs; Fig. 1C and Supplementary Fig. 1D ). Collectively, hPSC-CMs express proteins that may render them susceptible to SARS-CoV-2 infection (Bojkova et al., 2020; Sharma et al., 2020; . To investigate whether hPSC-CMs are permissive to SARS-CoV-2 replication, we quantified extracellular viral particles and intracellular viral RNA (by plaque assay and RT-qPCR, respectively). The one-step growth curve after 5 MOI infection indicated that viral replication occurred steadily from 24-72 HPI, followed by a precipitous decline as the cells died (Fig. 2C ).The multi-step growth curve (0.1 MOI infection) confirmed that SARS-CoV-2 replicated inside hPSC-CMs (Fig. 2D) , with a marked increase in viral particles and RNA at 48 and 72 HPI (at which point the experiment was stopped). In agreement with morphological observations, H7derived cardiomyocytes were more permissive to SARS-CoV-2 replication than WTC11c- Distinctly from hPSC-CMs, hESC-SMCs exposed to SARS-CoV-2 did not show any cytopathic effects even at the highest MOI at 72 HPI ( Supplementary Fig. 2F ). Accordingly, extracellular viral particles and intracellular viral RNA in hPSC-SMCs were more than two orders of magnitude lower than the ones observed for hPSC-CMs ( Supplementary Fig. 2G ). These findings highlight the specific tropism of SARS-CoV-2 for hPSC-CMs, and exclude that cytopathic effects observed in cardiomyocytes may be attributable to toxic contaminants in the viral preparation.To investigate the role of ACE2 during cardiomyocyte infection by SARS-CoV-2, we generated . We also observed dilated membrane-bound tubular structures, likely representing the endoplasmic reticulum Golgi intermediate compartment (ERGIC), in close proximity to membrane-enclosed viral particles ( Fig. 3D ). In addition, we observed a variety of vesicles containing viruses (Figs. 3D-F). Most notable were large vesicles with electron dense content packed with mature virus particles (Fig.   3E ). In some of these vesicles, we also observed lipid droplets and multilamellar bodies, consistent with lysosomes, whereas others were smooth walled vesicles (Figs. 3E, F) (Ghosh et al., 2020; Snijder et al., 2020) . Finally, exocytosis of virions was readily identifiable on the cell surface (Figs. 3G-I). In summary, these electron microscopic studies demonstrated viral entry via both direct fusion and endocytosis, replication in subcellular membrane structures, and ""hijacking"" of lysosomal vesicles for the bulk release of mature virions by exocytosis. (Banerjee et al., 2020) . In addition, we observed that genes involved in mitochondrial function and energy production were downregulated (Fig. 4F, Supplementary Fig. 4B and Supplementary Tables 2 and 4), indicating that SARS-CoV-2 might promote a shift toward a glycolytic metabolism by suppressing mitochondrial oxidative phosphorylation, which could also favor its replication (Ajaz et al., 2021; Icard et al., 2021) .Upon viral infection, pathogen-associated molecular patterns (PAMPs) initiate the early immune response via host pattern recognition receptors (PRRs). After virus uncoating, RIG-I-like receptors (RLRs) bind to the uncapped and double stranded viral RNA in the cytosol and trigger innate immune activation, leading to the production of type I and type III interferons and the interferon-induced antiviral response (Loo and Gale, 2011) . Upregulated pathways after SARS-CoV-2 infection in hPSC-CMs included those involved in viral defense (Fig. 4E) . To more finely clarify the underlying kinetics, we analyzed the interferon response from 2 to 72 HPI by RT-qPCR. We found that interferon transcripts (INFB1 and IFNL1) were markedly upregulated at 48 and 72 HPI in both cell lines, with a stronger effect in the more sensitive H7 cardiomyocytes ( Fig. 4G and Supplementary Fig. 4C ). The interferon-stimulated genes IFIT1 and IFITM1 were also upregulated at the latest time point. These results indicate that SARS-CoV-2 induces innate immune activation and interferon response in hPSC-CMs, similar to other cell types . Fig. 5A ). This outcome may reflect a decreased efficiency of viral propagation as hPSC-CMs were plated at high density to ensure robust assessment of electrophysiological properties. Nevertheless, viral RNA and viral particles could still be detected at 0.1 MOI, with the highest levels at 5 MOI ( Fig. 5B and Supplementary Fig.5B) , showing that the infection occurred also in these highly dense cultures. Representative propagation maps are shown in Figure 5C and Supplementary Figure 5C , while representative field potential recordings showcasing changes in spike amplitude and frequency are included in Figure 5D and Supplementary Figure   5D . Remarkably, SARS-CoV-2 infection rapidly resulted in reduced beating rate, lower depolarization spike amplitude, and decreased electrical conduction velocity (Figs. 5E and Supplementary Figs. 5E, F) . In H7 hESC-CMs we also observed a time-dependent increase in the field potential duration (FPD) both in spontaneously beating and electrically paced cultures ( Fig. 5F ; similar measurements could not be reliably obtained from WTC11c hiPSC-CMs due to the limited amplitude of the repolarization wave after SARS-CoV-2 infection). Overall, abnormalities in the generation and propagation of electrical signals were significant even in the absence of extensive cell death, suggesting that SARS-CoV-2 infection in cardiomyocytes could directly create a substrate for arrhythmias (Bhatla et al., 2020; Zylla et al., 2021) .We then evaluated the contractile properties of hPSC-CMs using three-dimensional engineered heart tissues (3D-EHTs), following their contractile behavior through magnetic field sensing (Bielawski et al., 2016) (Figs. 6A-B) . For these experiments we focused on WTC11c hiPSCs since 3D-EHTs from H7 hESC-CMs proved to beat spontaneously at too high a frequency (> 2 Hz) to enable accurate measurements of contractile behavior (i.e. the tissue had a tetanic-like contraction with minimal relaxation between beats at this frequency). We infected 3D-EHTs from WTC11c hiPSC-CMs with 10 MOI (to facilitate infection within the non-vascularized, cell-dense J o u r n a l P r e -p r o o f tissue), and analyzed their contraction for a week. This 3D-model experienced viral replication comparable to that of 2D cultures, highlighting once again the cardiac tropism of SARS-CoV-2 ( Fig. 6C) . The maximal twitch force in infected tissues decreased as early as 72 HPI ( Supplementary Fig. 6A) , and the contractions continued to subside to less than 25% of the force measured at the baseline at 144 HPI (Figs. 6D, E and Supplementary Videos 1 and 2) .Cardiomyocyte density progressively decreased while cells also became more rounded (i.e. dedifferentiated) and less aligned with the longitudinal axis of the 3D-EHTs (Fig. 6F and Supplementary Fig. 6B ). This could collectively contribute to the loss of force production.Infected 3D-EHTs also showed decreased expression of the sarcomeric genes MYL2 and MYH6, which may be correlated to the loss of sarcomere organization (Fig. 6G) . Overall, the significant impairment in the contractile properties of 3D-EHTs demonstrates that the mechanical function of cardiomyocytes is impacted by SARS-CoV-2 infection in vitro, and suggest that similar mechanisms could contribute to whole-organ cardiac dysfunction also in patients .A rapidly increasing number of reports acknowledge cardiovascular involvement as a prevalent complication observed in COVID-19 patients, but discriminating between direct versus indirect effects is still an open challenge (Nishiga et al., 2020; Shi et al., 2020; Tay et al., 2020) . In this study, we show that SARS-CoV-2 has the ability to directly infect cardiomyocytes, to impair both their electrophysiological and contractile properties, and to eventually induce cell death.In agreement with earlier reports, we find that cardiomyocytes (but not smooth muscle cells) express ACE2, making them susceptible to SARS-CoV-2 infection. Our experiments in ACE2 knockout hPSC-CMs formally demonstrate the key role of this factor for SARS-CoV-2 entry in this cell type. Interestingly, mRNA levels of ACE2 are heterogeneous within hPSC-CMs from the same culture, and the resulting protein is differentially abundant in hPSC-CMs from different genetic backgrounds. The cytopathic effects of SARS-CoV-2 infection also strongly vary between cardiomyocytes derived from different hPSC lines. ACE2 expression and SARS-CoV-2 susceptibility may be similarly heterogeneous in vivo, both across different regions of the heart and within different subjects (Litvinukova et al., 2020) . This might partially explain the discrepancy between the strong prevalence of heart damage in COVID-19 patients and the limited evidence for viral particles in the heart found by autopsy examinations. We suggest that future analyses should aim to sample various regions of the heart and focus on those patients that had shown the strongest cardiac symptoms.A puzzling observation is that the cytopathic effects of SARS-CoV-2 infection expands to virtually the entire monolayer of hPSC-CMs, even though single cell RNA-seq indicates that many cardiomyocytes do not express detectable levels of ACE2. One possible explanation is that ACE2 transcription is episodic and/or still meaningful low levels that are below the sensitivity of sc-RNA-seq (either way resulting in sufficient protein levels to allow SARS-CoV-2 entry). Alternatively, cytotoxic stimuli triggered by SARS-CoV-2 might spread to the adjacent J o u r n a l P r e -p r o o f cells via gap junctions or through the supernatant as toxic cytokines and/or other danger signals. Finally, the fusogenic properties of the SARS-CoV-2 spike protein may mediate membrane fusion not only between viral and host membranes but also within cardiomyocytes, leading to inter-cellular viral spreading (Schneider, 2020) . Spike protein fusogenicity is secondary to its proteolytic cleavage by host proteases like furin (Millet and Whittaker, 2015) , which is expressed in hPSC-CMs. Noticeably, we observed direct fusion between the virus and hPSC-CMs, a process that may be mediated by proteolytically-primed spike proteins, as in the case of MERS-CoV (Millet and Whittaker, 2014; Xia et al., 2020a; Xia et al., 2020b) . Future studies are needed to clarify whether any of these non-mutually exclusive mechanisms are involved in the strong susceptibility of hPSC-CMs to SARS-CoV-2 infection, and whether similar events are recapitulated in vivo.We found that hPSC-CMs are also extremely permissive to viral replication. Among other types of ultrastructural features, we detected the presence of double-membrane vesicles. These are used by viruses both to concentrate their building materials for efficient replication, and to evade the immune surveillance by ""hiding"" viral factors that can trigger the PAMP pathway (Wolff et al., 2020) . Accordingly, we observed activation of interferon-responsive genes only at late time points of SARS-CoV-2 infection. The interferon response, which is part of the innate immune response activation (Loo and Gale, 2011) , usually occurs within hours from viral infection. The fact that cardiomyocytes infected with SARS-CoV-2 show a delayed response may facilitate viral replication to high levels . Furthermore, RNA-seq showed that SARS-CoV-2 infection affects pathways involved in RNA regulation. SARS-CoV-2 can impair RNA splicing to evade the intracellular innate immune response (Banerjee et al., 2020) , which may be the case also in hPSC-CMs. Moreover, oxidative phosphorylation and mitochondrial function are severely downregulated in the infected cells. SARS-CoV-2 may shift cellular metabolism to J o u r n a l P r e -p r o o f promote glycolytic metabolic activity in support of viral replication (Icard et al., 2021) , providing yet another way to boost its replication also in hPSC-CMs.The presence of highly replicating virus severely affects both the morphology and the function of hPSC-CMs. Infected cardiomyocytes lose cytoskeletal organization, become packed with different types of vesicles, and show broad alterations of gene expression. Using a multielectrode array system, which has been validated to detect potential arrhythmogenic properties of novel drugs (Blinova et al., 2018) , we identified several electrophysiological abnormalities induced by SARS-CoV-2 infection. Prolongation of FPD is particularly noticeable.This measurement reflects the interval between membrane depolarization and repolarization, and as such represents an in vitro surrogate of the QT interval measured by an electrocardiogram. It is well known that prolongation of the QT interval is pro-arrhythmogenic (Chiang and Roden, 2000) . Thus, FPD prolongation in SARS-CoV-2 infected hPSC-CMs may be an in vitro surrogate phenotype mirroring the arrhythmias observed in ~20% of COVID-19 patients (Malaty et al., 2020) . Last but not least, we found marked impairment in both contractile function and histological organization in 3D-EHTs infected with SARS-CoV-2. If similar effects were to occur in the hearts of some COVID-19 patients, this could contribute to cardiac dysfunction. Overall, hPSC-CMs on MEAs and/or organized in 3D-EHTs may represent valuable scalable platforms to identify active compounds that may provide therapeutic value.Collectively, our results support the notion that, independent of inflammation or coagulopathy, SARS-CoV-2 can cause direct functional heart damage by either inducing cell death and/or by impairing electro-mechanical functions. One limitation of this study is our reliance on hPSC-CMs, which are well-known for their functional immaturity (Guo and Pu, 2020; Karbassi et al., 2020; Marchiano et al., 2019) . While the in vitro systems we used have been successfully leveraged to model electrophysiological and contractile alterations due to drugs or inherited mutations (Blinova et al., 2018; Paik et al., 2020) , their application to modeling COVID-19 still J o u r n a l P r e -p r o o f requires further validation. Nevertheless, a recent report by Dolhnikoff et al. identified coronaviral particles in the cytoplasm of cardiomyocytes, endothelial cells, and fibroblasts by electron microscopy in the heart of an 11 year-old child who died from multi-system inflammatory syndrome in children (MIS-C) following COVID-19 infection (Dolhnikoff et al., 2020) . This indicates that in vivo cardiomyocytes with substantially greater maturity than used here are susceptible to SARS-CoV-2 infection. COVID-19 patients are commonly treated with steroids to control systemic inflammation. However, our data suggests that treatments aimed to control the direct damage of SARS-CoV-2, not only by preventing infection but also by preventing viral replication or rescuing cardiac function, should also be taken into consideration to prevent long-term cardiovascular complications.Experimental procedures Cell culture. RUES2 hESCs and WTC11c hiPSCs were maintained and differentiated using small molecules modulators of the WNT pathway (Bertero et al., 2019a) . H7 hESCs were differentiated in suspension culture format by collaborators at the Center for Applied Technology Development at the City of Hope in California. H9 hESCs were maintained and differentiated into LM-SMCs and NC-SMCs as previously described (Bargehr et al., 2016; Serrano et al., 2019) . ACE2 KO clones were generated using CRISPR/Cas9 ribonucleprotein complexes (Synthego).Bulk RNA-seq datasets from RUES2 hESC-CMs had been previously generated and analyzed (Bertero et al., 2019a) . Bulk mRNA-seq data from infected cardiomyocytes were generated by constructing mRNA-seq libraries using the KAPA mRNA HyperPrep Kit (Kapa Biosystems). Libraries were sequenced on an Illumina NovaSeq. For single cell-RNA-seq analysis, a single cell suspension was generated from RUES2 hESC-CMs and single cell RNA-seq was performed using the Chromium NextGEM Single Cell 3' kit (10X Genomics). For quantitative real-time reverse transcription PCR (RT-qPCR), RNA from infected cardiomyocytes was harvested using Trizol reagent. cDNA was obtained with M-MLV reverse transcriptase (Invitrogen), and RT-qPCR was performed with SYBR Select Master Mix (Applied Biosystems). Primers are reported in Supplementary Table 5 .Western blot. hPSC-CMs were lysed using RIPA Buffer. Samples were run on mini-PROTEAN TGX precast gels (Bio-Rad) and then transferred on PVDF membranes. Primary and secondary antibodies (Supplementary Experimental Procedures) were incubated in blocking buffer, and fluorescent signals were acquired using with a GelDoc Imager (Bio-Rad).Level 3 (BSL-3) facility at the University of Washington in compliance with the BSL-3 laboratory J o u r n a l P r e -p r o o f safety protocols (CDC BMBL 5 th ed.) and the recent CDC guidelines for handling SARS-CoV-2.were obtained from BEI Resources (NR-52281) and the University of Texas , respectively, and propagated in VERO cells (USAMRIID). Viral preparations and culture supernatant from SARS-CoV-2-infected cardiomyocytes were titered using a plaque assay. Viral infection. SARS-CoV-2 wild-type or expressing mNeonGreen protein was diluted to the desired MOI in DMEM and incubated on hPSC-CMs or hPSC-SMCs for 1 h at 37 °C (noninfected [mock] controls were incubated with DMEM only). Cells were then washed with DPBS and cultured in the appropriate maintenance media.Immunofluorescence. hPSC-CMs were fixed with 4% paraformaldehyde (PFA) and permeabilized using 0.25% Triton X-100 (Sigma-Aldrich) before staining with primary and secondary antibodies (Supplementary Experimental Procedures).Electron Microscopy. hPSC-CMs were fixed with Karnovsky's fixative. Heavy metal impregnation was performed as detailed elsewhere (Deerinck, 2010) . Thin sections were viewed using a JEOL 1230 transmission electron microscope.Electrophysiological analysis with MEA. CytoView MEA plates (Axion BioSystems) were coated with Matrigel and hPSC-CMs were plated as previously described (Bertero et al., 2019b) . SARS-CoV-2 effects on hPSC-CMs electrophysiology were recorded using Maestro Pro system and analyzed with Cardiac Analysis Software v3.1.8 (all from Axion BioSystems).Post-suspended, fibrin-based 3D-EHTs were generated with hPSC-CMs and HS27a stromal cells (ATCC) at a 1:10 ratio. Twitch force was recorded by tracking the movement of magnets embedded in the flexible posts, as previously described (Bielawski et al., 2016) . For immunostaining, 3D-EHTs were arrested in diastole, fixed in 4% PFA and embedded in TissueTek O.C.T. before sectioning and staining. ",USA,first author,2021-02-13,02
c6c17c4a9d70362aeb398b82cb9629944f047a82,Journal Pre-proof Delivering virtual cancer rehabilitation programming during the first 90 days of the COVID-19 pandemic: A multimethod study Title: Delivering virtual cancer rehabilitation programming during the first 90 days of the COVID-19 pandemic: A multimethod study,"some circumstances, with the ability to: 1) increase access to care; 2) provide a sense of 23 reassurance during a time of isolation; and 3) provide confidence in learning skills to self-24 manage impairments. 25Conclusions: Many appointments can be successfully adapted to virtual formats to deliver 26 cancer rehabilitation programming. Based on our findings, we provide practical 27 recommendations that can be implemented by providers and programs to facilitate the 28 adoption and delivery of virtual care. Cancer rehabilitation is an essential component of survivorship care and has become 60 increasingly relevant with a growing cancer survivor cohort, and high documented rates of 61 impairment and disability. 1,2 The COVID-19 pandemic has required a rapid transition from in-62 person rehabilitation to virtual care through telephone-or video-based visits. 3 However, this 63 shift has largely been made with little evidence on best practices. 64Virtual care may improve access for geographically dispersed patients and reduce 65 physical, financial, and logistical barriers to in-person care. 4 shown promise in addressing physical and psychosocial concerns among cancer survivors. 5,6 67Notwithstanding these potential benefits, regulatory restrictions surrounding reimbursement, 68 licensing, and hospital credentialing, as well as patient and provider attitudes have impeded its 69 broader adoption. 7,8 Additionally, differential access to telecommunication technologies based 70 on social and geographic factors can pose a challenge to its implementation. 8 71As a result of the evolving COVID-19 crisis, the Princess Margaret Cancer Centre 72 proactively suspended all non-essential in-person appointments. Therefore, the Cancer 73Rehabilitation and Survivorship (CRS) Program abruptly shifted services to be delivered virtually 74 as of March 16 th , 2020. Despite recent recommendations for virtual care during the 75 pandemic, 3,9,10 research on virtual cancer rehabilitation is limited. Given the uncertainty for 76 when a return to previous levels of in-person care will occur, the current demand and surge in 77 virtual care use presents a unique opportunity to examine the implementation of virtual cancer 78 rehabilitation and provide strategies on how to adapt in-person care to deliver a sustainable 79 virtual care model. The purpose of this study was: 1) to describe the adaptations made to 80 J o u r n a l P r e -p r o o fWe collected data on process measures including: 1) referrals; 2) completed visits and 128 attendance; 3) method of appointment (i.e., video or phone); 4) weekly appointment 129 capacities; and 5) wait times. These outcomes were compared with the previous 3 months. 130Patients could be placed on a waitlist to be seen by our team in-person once services resumed 131 or brought in if their condition was deemed serious. These appointments included 132 comprehensive assessments, one-on-one appointments, and CaRE initial or follow-up We conducted semi-structured interviews via telephone with CRS HCPs and patients 139 who had received care virtually during the study period. We applied a pragmatic approach to 140 recruitment and aimed to recruit 10 HCPs and 10 patients for interviews due to our narrow 141 research question. 14 However, data was collected until saturation was reached, meaning there 142 were little or no changes to the codes from new interviews. Interviews were completed by two 143 members of our team with experience with qualitative interviewing (C.L., and B.E.). HCP 144 interviews were informed by the FRAME and explored experiences with adapting to virtual care 145 (Supplementary File 1). We purposively sampled patients based on the type of CRS virtual visit 146 they were attending (i.e., comprehensive assessments, follow-up assessments, and CaRE 147 assessments), and interviews explored their perspectives with virtual care (Supplementary File 148 2). Patients were also asked to complete a demographic questionnaire. Context and content modifications were qualitatively synthesized based on the 153 FRAME. 13 Descriptive statistics were used to summarize process outcomes of the CRS program 154 during the 90 days before and after adapting to virtual care. Patient and HCP interviews were 155 analyzed separately, and emerging themes were subsequently aligned to develop a cohesive 156 understanding of experiences with virtual care. We followed a six-step approach for thematic 157 analysis. 15 Interviews were digitally recorded and transcribed verbatim and each transcript 158 underwent a process of open coding by a member of the team (C.L.). The generated themes 159 were reviewed in relation to the coded data and the entire data set and underwent further 160 review by another interviewer (B.E.) to ensure they reflected the interviews conducted. These 161 themes were refined and representative quotes were chosen for each theme. Several strategies 162 were used to ensure trustworthiness including the appropriateness of the interview sample, the 163 relevance of interview questions, and the steps taken to ensure the accuracy of the interview 164 transcripts and generated themes. 16 The weekly capacities of appointments were adjusted to accommodate setting and 211format (e.g., removal of group classes) modifications, as well as removed need for clinic space. 212The maximum number of comprehensive assessments that could be scheduled per week 213 slightly decreased (in-person n=40 vs. virtual n=36). Nevertheless, the capacity for most one-on- Table 3 . Participating patients were referred to the CRS 247 program for multiple and varied reasons including lymphedema (n=6), musculoskeletal (n=5), 248 fatigue (n=5), deconditioning (n=3), neurological (n=2), difficulties with activities of daily living 249 (n=2), and neurocognitive (n=2) issues. The majority of patient participants were on post-250 treatment surveillance (n=9, 75%). The mean duration of the interviews was 27 minutes (range 251 = 15-58 minutes). Three themes emerged from the interviews. Each theme is described below 252 and representative quotes for each theme are provided in Table 4 . being initially aware of the purpose of the visit or the reason for the referral. As a result, HCPs 265 recommended providing pertinent information to patients prior to the appointment (e.g., 266instructions on how to access the virtual platform, and guidelines on ensuring high-quality 267 virtual appointments). 268Patient participants expressed a sense of reassurance and noted that they felt 270 supported during a time of isolation and uncertainty. Several patients emphasized feeling 271 empowered to cope with the worries of the pandemic in addition to their rehabilitation needs. 272Furthermore, patient and HCP participants indicated that they were able to establish rapport, 273particularly during video appointments, as this normalized the virtual care experience. 274However, several HCPs indicated that compared to in-person appointments, communication 275barriers were more pronounced in a virtual environment, which hindered their ability to assess 276 and build rapport with patients utilizing interpretation services. Additionally, a few patient 277 participants described virtual care as an isolating approach to their rehabilitation and expressed 278 a desire for virtual group interactions with other cancer survivors. This was acknowledged by 279 many HCPs, who discussed challenges with abruptly adapting the group classes to a virtual 280 platform. 281HCPs indicated that virtual visits were effective for screening many cancer-related 283 impairments including neurocognitive, psychosocial, fatigue and diet concerns. However, HCPs, 284 specifically PTs, OTs, and physiatrists, experienced more difficulties due to limitations in 285 assessing musculoskeletal and neurological impairments, and lymphedema. Due to a lack of in-286 J o u r n a l P r e -p r o o f Virtual Cancer Rehabilitation During COVID-19 person examination, HCPs often relied on patient self-report and self-assessment. Virtual visits 287 made it difficult to reliably test, palpate and observe patients in order to evaluate their level of 288 impairment and function. This led to a greater level of difficulty narrowing the differential 289 diagnosis, ordering pertinent medical tests, and evaluating their condition at follow-up 290 appointments. HCPs also indicated several challenges teaching loco-regional rehabilitative This study describes the adaptations made to implement virtual cancer rehabilitation 308 programming at the onset of the COVID-19 pandemic. The rapid shift to virtual care presented a 309 challenge and an opportunity to ensure cancer survivors had access to rehabilitation services. 310The CRS program was able to translate the majority of appointments to virtual formats and 311 deliver care at similar or greater volumes compared to in-person care prior to the pandemic. 312Virtual delivery is a priority in cancer rehabilitation due to its ability to mitigate barriers 313 to in-person care. 4,17,18 Our findings demonstrate that virtual care may be feasible, consistent 314 with previous studies, 19-21 with a few important limitations for physical examinations (e.g., 315 musculoskeletal and neurological impairments, and lymphedema). We were able to deliver care 316 at high volumes and attendance rates across a variety of visit types. Our findings suggest that 317 cancer survivors feel they can easily access care and gain confidence in learning skills to self-318 manage their impairments. However, the value of group-based interventions was highlighted in 319 this study, reflecting previous findings on their social benefits. 22 Accordingly, we have begun 320 piloting virtual group education classes. 321The ability of the CRS program to abruptly shift to virtual care was facilitated by 322 regulations surrounding billing for virtual care, as well as organizational capacity and readiness 323 for change. 23 The provincial government approved virtual care to be covered by insurance and 324 introduced temporary billing codes and procedures. Additionally, the Princess Margaret Cancer 325Centre had been delivering virtual appointments on OTN in a limited capacity prior to the 326 pandemic, which facilitated its rapid adoption within the CRS program, and all HCPs were 327 trained on how to navigate OTN prior to delivering care virtually. Finally, previous use of 328 telephone visits (e.g., return to work, social work) and previously developed resources (e.g., e-329 Additionally, although this study described the changes to the CRS process outcomes over time, 366we did not determine whether these changes were significant. Moreover, we did not examine The findings of this study suggest that many appointments can be successfully adapted 379to virtual formats to deliver cancer rehabilitation programming. Virtual delivery can be a 380 feasible and acceptable alternative to in-person care during physical distancing 381 recommendations. While these findings are encouraging and can inform implementation 382 efforts for virtual models, further research is needed to understand its effectiveness. Format: Appointment includes an initial screen with an OT or PT, followed by an assessment with a MD (physiatrist). Setting: Patients are seen in-person. Content: Patients complete electronic questionnaires inperson, and moderate to high distress scores are flagged on a clinician report for the oncology team to assess. Assessments are guided by objective measures including a surveillance physical exam. Appointments include a comprehensive rehabilitation assessment and care plan based on a patient's identified impairment, level of disability, and personal goals. Appointments are booked for a total of 1.5 hours.Format: No change.Setting: Adapted to video or phone. Tailored elements: 1) Questions within standard distress screening questionnaires could be used as probes to guide the assessment, but summary reports were not available as a remote system had not been implemented within the cancer centre; 2) physical tests and assessments were demonstrated and described to allow patients to complete them on their own; and 3) objective measures of function were not completed. Pacing/Timing: No change was made to the scheduled appointment duration.Patients are referred to the CaRE@Home program based on their comprehensive assessment. Format: Initial one-on-one visit with a RKin, and follow-up visits at 8 weeks, and 3 and 6 months. Setting: All assessments are conducted in-person. Weekly counseling is delivered via phone. Content: In-person visits include a fitness assessment (6minute walk test, hand grip dynamometry, body composition, balance) and distress reports via questionnaires completed inperson. Patients are supported with exercise Therabands, emodules for education, a mobile application and wearable technology, and weekly brief telephone counselling. Assessments are booked for 1.5 hours and weekly counseling is scheduled for 20 minutes.No change to the referral process. Format: No change.Setting: All assessments were switched to phone or video. Weekly counseling could now be delivered over video. Removed elements: 1) Fitness assessment (6-minute walk test, hand-drip dynamometry, body composition, 30-second balance); 2) provision of exercise Therabands; and 3) provision of wearable technology. Tailored elements: 1) Exercises were demonstrated and described by the RKin over video, phone, or through online instructional videos; and 2) patient-reported outcomes were completed online at assessment timepoints, but summary reports were not available. Pacing/Timing: No change was made to the scheduled appointment duration.Patients are referred to the CaRE@ELLICSR program based on their comprehensive assessment. Format: Initial one-on-one visit with a RKin, weekly group classes for 8 weeks, and one-on-one follow-up visits with a RKin at 8 weeks, and 3 and 6 months. Setting: All visits and classes are conducted in-person. Content: Patients receive an initial assessment and exercise prescription. Assessments include objective measures and distress reports via questionnaires completed in-person. Group classes consist of supervised exercise and skills management education. Patients are supported with exercise Therabands, a mobile application, and wearable technology to track activity. Assessments are booked for 1.5 hours. Weekly exercise and education classes are 60 minutes each.Patients currently enrolled in the CaRE@ELLICSR program were switched to CaRE@Home. All future groups were suspended. Format: Weekly supervised group exercise classes were modified to individual weekly one-on-one telephone or video calls with a RKin for the remaining weeks of the program. Group skills management education was modified to individual online education. Setting: In-person assessments were adapted to video or phone. Education content was delivered via e-modules. Removed elements: 1) Fitness assessment (6-minute walk test, hand-drip dynamometry, body composition, 30-second balance). Pacing/Timing: No changes were made to the scheduled duration of assessments.Format: A one-on-one visit with an OT or PT. Setting: Primarily in-person; however, OT consults could be delivered via phone. Content: Assessments are guided by distress reports via questionnaires completed in-clinic prior to the appointment and objective measures (e.g., hand grip dynamometry, sit to stand, range of motion). Appointments are booked for 45 minutes.Format: No change. Setting: All appointments were delivered via phone or video. Tailored elements: 1) Questions within standard distress screening questionnaires could be used as probes to guide the assessment, but reports were not available; and 2) physical tests and assessments were demonstrated and described to allow patients to complete them on their own. Removed elements: Objective measures of strength and function. Pacing/Timing: No change was made to the scheduled appointment duration.Format: A one-on-one visit with a PT or RMT. Setting: Patients are seen in-person. Content: Treatments include manual lymphatic massage, compression bandaging, kinesiotaping, and education. Appointments can be booked for 30 or 60 minutes.Setting: Adapted to video or phone. Removed elements: Objective measures of lymphedema. Substituted elements: Manual therapy was postponed, and patients were provided with online resources for manual lymphatic self-massage (videos and pamphlets). Pacing/Timing: No change was made to the scheduled appointment duration.Format: A one-on-one visit with the HCP. Setting: Primarily in-person; however, all visits could be delivered via phone. Content: Assessments are guided by distress reports via questionnaires completed in-clinic prior to the appointment and objective measures. Appointments are booked for 1 hour.Setting: All appointments were delivered via phone or video. Tailored elements: 1) Questions within standard distress screening questionnaires could be used as probes to guide the assessment, but reports were not available.Removed elements: Objective measures of body composition for RD appointments; and 3) neuropsychological testing. Pacing/Timing: No change was made to the scheduled appointment duration.Format: Group-based. Setting: In-person. Content: Monthly 1-hour classes. Topics included return to work, brain fog, lymphedema, and sex and intimacy.Format: Group format was postponed as additional time was required to adapt the content of the classes to a virtual format and ensure privacy concerns were addressed. Patients registered for an upcoming class were contacted by the class lead and offered a one-on-one appointment or other resources. Setting: Adapted to video or phone consults or online resources. Substituted elements: Resources included previously developed e-modules for return to work and brain fog classes, as well as a pamphlet on lymphedema management. Emodules on lymphedema and sex and intimacy were in the process of being developed.Format: Group-based. Setting: In-person; however, cooking classes were streamed live online for patients. Content: Classes included cooking and nutrition demonstrations, mindfulness meditation, and gentle therapeutic exercise.Format: In-person classes were postponed. Setting: Patients were directed to online videos and resources available on the program website and external mediums. Tailored elements: Cooking and nutrition classes were streamed live without an inperson audience. Removed elements: 1) mindfulness meditation; and 2) gentle therapeutic exercise.Abbreviations: MD, medical doctor; OT, occupational therapist; PT, physiotherapist; RMT, registered massage therapist; HCP, health care provider; NC, neurocognitive; SW, social work; RD, registered dietician. J o u r n a l P r e -p r o o f Table 4 . Representative quotes from participant and health care provider interviews Theme Quote Access to Care ""Our clinic usually struggles with issues of having enough rooms, so the option of virtual care gives us some more clinic space in a way. I think it'll solve our issue of clinic space which means we can see more patients or hire more staff and allow our program to grow."" (HCP, Occupation Therapist)""My acceptance to virtual care has allowed me to see people with very strong barriers to rehabilitation such as those with mobility issues or who live far away."" (HCP, Physiatrist)""We have to think about whether we should keep this as an option because maybe I won't have as easy access to downtown hospitals, but I want to maintain my relationship with my doctors and other providers. This would be an amazing source to rely on until together as a team, you decide on when an in-person appointment would be necessary."" (P08)Virtual helped me get the care I needed while managing my kids. The convenience was important. If I had to go downtown, I would have to think of a lot of different things to plan my day with the kids and travel. The convenience of it was very helpful."" (P09)""The benefit is that we can still connect with patients and they seem to really appreciate that we can speak with them. We can still build a therapeutic relationship with patients and still provide some sort of connection and opportunity to check in. So, I think that has been working well. I think we actually have been needed more now as many other points of connection may have stopped."" (HCP, Occupation Therapist)""I think it would be helpful to tell patients what to expect for the virtual visit. So, like a module or link on how to make the most out of the visit. Giving them steps like arriving five minutes before the visit, test the camera and audio, wear clothes for exercise, bring any equipment they have. Also, continuing to communicate the expectations of the visit and that there are going to be limitations for what we can assess virtually."" (HCP, Physiotherapist)""I feel I got really great guidance. I feel continued to be cared for. If I need support or more understanding because something changes, I feel like I could reach out and I can get help. And with the continued uncertainty in the world, it might be necessary to be virtual for the next year. So, it feels really good moving forward."" (P02)""I feel blessed for this opportunity. I was given the confidence to manage my wellness, and needed support during a pandemic. You can feel like you're still working towards something that is going to help you. I think it has made an improvement in my physical and mental life. I had tools that were able to help me handle the cancer and the COVID situation."" (P04)""Assessing range of motion is okay for upper extremities, but sometimes people don't have that mobility with their camera to show their whole body or a good distance from the camera. It's hard to get a good visual of their lymphedema unless the swelling is quite pronounced and visible. Also, often we're doing this over the phone, where I can only go by patient description about their mobility, strength, and lymphedema."" (HCP, Physiotherapist) ""We also have an app we use where patients see the videos and instructions of the exercises, and they can message us on that if they have questions. Through that, we can also share our screen and show them the videos on the app and show the videos and talk it through with them. This makes it easier to teach the exercises and build rapport."" (HCP, Kinesiologist) ""I might have the language to be able to describe what I'm feeling, but the majority might not be able to. So, for someone who doesn't know a lot about the body and can't see or tell if something bad is going on, then you're relying on self-description and they may not describe it well or accurately. Not being able to have a someone go and feel my armpit for example and feel what's swollen, or even look at it well is a problem because you can't visibly see something like that well on a screen.""""The worry about the care not being very personalized was removed right away during the first appointment because I could see [the health care provider], they could see me, and we could communicate with each other. I didn't really know how I was going to be able to say a certain exercise was not okay for me because you can't do an exercise in front of someone virtually. It just doesn't work for me or them actually. So, the video of the exercises were shown to me during the appointment and everything was explained to me so well that it removed all my worries and made it easy."" (P11)Abbreviations: HCP, health care provider; P, participant.J o u r n a l P r e -p r o o f Appointments with multiple health care providers should be organized in a consistent manner to ensure providers are accessing the correct virtual visit. This includes ensuring emails sent to a second provider containing links to access a combined virtual visit contain information such as the time and nature of the visit (e.g., initial, follow-up, referral type).Time allotted for virtual visits may need to be increased in order to accommodate any technological issues, as well as extra time to assess patients' needs given the absence of an in-person physical assessment and provide information to patients electronically after the appointment.Provide patients with detailed instructions on how to access the virtual platform and guidelines for ensuring a high-quality virtual appointment (e.g., testing of audio and video quality). Patients should be reminded about potential wait times as a virtual environment does not provide patients with a sense of the clinic flow.Provide patients with educational material related to the virtual appointment (e.g., lymphedema, exercise, diet) to help patients become familiar with potential topics, test, and self-management skills they may be asked to complete during the appointment, as well as overall expectations of the virtual visit. This includes information from local/regional medical authorities or governing bodies on the limitations of a virtual visit compared to an in-person visit.Health care providers should strongly encourage the use of video assessments for patients referred for musculoskeletal, neurological, and lymphedema concerns, and ensure patients are informed of the potential benefits and reasons for a video appointment compared to an appointment over the phone.Develop and implement an online screening tool that patients can complete prior to the appointment to provide relevant outcomes to health care providers to guide the accuracy and reliability of the assessment and care plan.Health care providers may need to take a more cautious approach to care, including ordering more tests and investigations, requesting a follow-up for re-assessment virtually or at the earliest possible in-person visit, and reduced volume and intensity of prescribed exercise.Incorporate mobile or online applications to deliver interventions and monitor progress and adherence remotely.Take advantage of seeing patients in their home environment by personalizing discussions and recommendations (e.g., supplements or foods available for dietary and nutritional advice, and equipment, household supplies, and furniture for exercise). ",Canada,first author,2021-02-19,02
9cfdd439ce1f324c05c2622a6a406666eb59ffe5,TITLE: A rapid review of equity considerations in large-scale testing campaigns during infectious disease epidemics,"It is essential to understand how COVID-19 testing campaigns are being offered in the current pandemic situation, in order to improve their equitable implementation. Racialized and marginalized communities have been disproportionately affected by COVID-19 (1-3) andimproving equitable access to COVID-19 testing would be a vital step in reducing disease propagation (4) . Large-scale testing is instrumental for surveillance, directly informing measures of prevention, control, and mitigation of infectious diseases (5) (6) (7) (8) . The goal of large-scale testing interventions is to reduce transmission rates through detection, treatment, isolation, and any other relevant control and prevention measures (9) . Testing programs often act as a link to care and support programs, which should be provided equitably, based on risk of infection and disease burden (10) . A proportionate universalism framework-based public health program would imply two components: a universal approach of support and services available to the population as a whole, accompanied by accessible targeted initiatives for those highly vulnerable and for those least likely to benefit from the universal program (11, 12) . When applied to COVID-19 testing initiatives, a proportionate universalism approach could include a universal program for SARS-CoV-2 testing with concerted efforts to reach vulnerable groups less able to access the universal testing programs. Equity is defined by the ""absence of systematic disparities in health or in major social determinants of health between groups with different levels of underlying social advantages/disadvantages'' (13, 14) whereas health inequities refer to ""differences in health status or in the distribution of health resources between different population groups, arising from the social conditions in which people are born, grow, live, work and age. They are unfair, avoidable, and could be reduced by the right mix of government policies."" (15, 16) . This is an important concept for understanding the differences between (in)equity from the more general term (in)equality, two words that are often confused (17,18). Health inequalities refer to the uneven distribution of health or health resources (i.e. clinics, healthcare providers, disease tests, infrastructure, clinical material) in or between populations and it is primarily a descriptive term exempt from moral perspective (17) (18) (19) . Social determinants of health play a key role in both inequality and inequity. Disparities in social determinants are found along social gradients (1) and are often avoidable as they result from deeply rooted social institutions, practices, and injustices (18). Thus, (in)equity is the politicized expression of (in)equality involving a moral commitment to social justice (18). In light of these fundamental differences, equity-sensitive public health interventions require measures of health and social determinants of health specific and sensitive to the health issue at hand (20). In our review we identify if and how equity has been considered in large-scale infectious disease testing initiatives. Identifying examples of (in)equity in these initiatives can help guide the design of largescale testing campaigns for the COVID-19 pandemic.We chose to conduct a rapid review approach as it enabled us to synthesize, with rigor and in a relatively short period of time, the state of knowledge about our research objective (21,22). We have a detailed online protocol published elsewhere (23).The research strategy was developed in consultation with librarians from the French NationalResearch Institute for Sustainable Development (IRD) and the University of Montreal. We began our electronic database query in July 2020 on PubMed and Web of Science, and updated our search in November 2020 to better reflect the rapidly evolving state of COVID-19 literature. The following english and french key words were used to define our queries (Appendix 1) : ""testing"", ""mass testing"", ""dépistage"", ""screening""; ""TB"", ""tuberculosis"", ""tuberculose""; ""HIV"", ""VIH"", ""human immunodeficiency virus""; ""COVID-19"", ""SARS-CoV-2"", ""coronavirus""; ""design"", ""planification"", ""planning""; ""equit*"", ""equal*"", ""inégalités"", ""inégalités sociales en santé"", ""ISS"", ""social inequities in health""; ""pandemi*"", ""epidemic"", ""outbreak"", ""endemic""; ""infectious disease"", ""maladie infectieuse"".We followed the PRISMA extension for scoping reviews (24). We used the Automated Text Classification of Empirical Records (ATCER) (25) tool to classify abstracts with an empirical degree ≥ 80. ATCER is a tool that automatically categorizes publications indexed in bibliographic databases into (a) empirical studies (>50), and (b) non-empirical work (<50) (25). We selected the ATCER threshold of ≥ 80 to reflect articles that were ""highly empirical"", due to our objective of including studies with quantitative data such as program evaluation indicators. The inclusion criteria for articles were: i) a focus on an infectious disease, ii) description of the design portion of a testing or screening program, iii) published in English or in French, iv) had an empirical degree greater than 80 according to the ATCER tool, and v) published after 2010.All identified studies were imported from PubMed and Web of Science into Rayyan QCRI (26), a systematic review software, for screening of the titles, abstracts, and full texts. At least two of three involved reviewers (KO, LD, CD) independently assessed the relevance of titles and abstracts based on the inclusion and exclusion criteria. The second stage of review involved two of three reviewers independently identifying potentially relevant publications based on a full article review.Any discordance in the process was discussed among all reviewers and if no consensus was reached, an additional reviewer (LT) was consulted.After independent full text screening was conducted by at least two reviewers, data from the retained articles were extracted and assessed. Extracted data included the following elements: characteristics (title, authors, year), context (country, disease addressed), and the consideration of health inequities or inequalities in the design of the intervention, the main results, and the discussion of the study. If the study considered health inequities, we extracted further information on which measures of equity were considered and if a specific tool or theoretical framework was used in the program design. Generally, a theoretical framework can be used to inform how a public health program is planned and what strategic and operational components were considered during the process of this planning (27). We considered equity (explicit or implicit) in the i) intervention rationale, ii) design, iii) choice of target population, and iv) final recommendations for future initiatives based on the PROGRESS-plus criteria (28). The PROGRESS Plus framework was developed and endorsed by the Campbell and Cochrane Equity Methods Group, in order to highlight a set of social determinants of health that drive variations in health outcomes and the inequalities among the social determinants of health gradient (28). The categories referred to by the acronym are: place of residence, race or ethnicity, occupation, gender, religion, educational level, socioeconomic status (SES), and social capital. Our goal, through the use of these tools, was to assess the presence or absence of the consideration of health inequities in the implementation or evaluation of testing programs.In addition, we followed the Template for Intervention Description and Replication (TIDieR-PHP) checklist and guide to assess study coherence and program reporting and evaluation completeness (30). The 12-item checklist includes categories: (brief name, why, what (materials), what (procedure), who provided, how, where, when and how much, tailoring, modifications, how well (planned), how well (actual)) and is an extension of the CONSORT checklist.We initially identified 291 references with 41 peer reviewed studies being included in the review ( Figure 1 ). According to MMAT classifications, the studies were a mixture of 2 randomized studies (31,32), 17 non-randomized studies (33-50), 18 descriptive quantitative studies (51-67), and 4 mixed-methods studies (68-71) ( Table 1) . Most of the studies (83%) reported on HIV-related screening programs, while the remaining studies focused on other sexually transmitted infections (n=3) and COVID-19 (n=4). The evaluated studies were implemented in North America (n=27), Europe (n=8), Africa (n=5), and Asia (n=1).Measures of equity/inequity were assessed based on the PROGRESS-Plus framework. None of the 41 included studies evaluated whether the intervention reduced health inequity or inequalities as a study objective, nor did they include a formal definition of equity/inequity (or framework).Elements of health equity were indirectly addressed in 23 studies (Table 2) This rapid review largely featured articles addressing HIV testing programs, and/or testing programs of infectious disease in North America in formal healthcare settings such as clinics or hospitals. None of the 41 studies included in this rapid review examined health equity in their interventions, however, 8 studies did consistently include elements of equity in their testing intervention, without the inclusion of any formal measurement of, or framework specifically implemented in order to address health equity. Specifically, most (n=6) of these 8 articles considered the PROGRESS-plus categories of gender and/or sex.· Use tools such as PROGRESS-Plus framework to ensure explicit inclusion of health equity when in the process of designing, implementing, and/or evaluating interventions.· Promote the use of TIDIER-PHP to systematically review public health programs and promote replicability of existing equitable programs to other settings.Given our objective to include studies with empirical results and also to conduct the review in a timely manner, we chose an ATCER threshold of 80. This may have limited our findings and the generalizability of the results. We recommend that a full scoping review be conducted on this topic to further investigate important trends on the incorporation of health equity into infectious disease testing programs.The results of this rapid review highlight the overall lack of consideration of equity in the design of large-scale testing interventions. This is a particularly concerning issue as social and economic inequities continue to be exacerbated by COVID-19 and there has not been any research to date that discusses how COVID-19 testing programs have been designed with equity in mind (1-3).To achieve equity in testing and to optimize the role of testing in disease prevention and control, strategies should ensure that the probability of being tested is proportionate to the risk of being affected by the disease (85,86). We urge practitioners, decision makers, and researchers to explicitly include equity measures when designing and implementing COVID-19 large-scale testing interventions, which should also be considered in COVID-19 vaccination programs.The authors would like to thank Laurence Goury, librarian at the IRD, and Julie Desnoyers, librarian at the University of Montreal, for their advice regarding the search strategy and the queries on the bibliographic databases.First, opt-out inpatient HIV screening was associated with markedly lower per test positivity rates when compared to targeted testing in the ED, and these newly HIV diagnosed patients were not typically tested through physician-directed testing in the ED. Second, uptake of screening was limited when physicians were responsible for opt-out screening during routine care, with limited time resources seemingly the major barrier. To describe Wisconsin's social networks testing program and outcomes.Although social networks testing did not yield a higher new positivity rate compared to other testing strategies, it proved to be successful at reaching high risk individuals who may not otherwise engage in HIV testing.To examine the results of implementing counselor-based HIV testing and linkage to care components in five urban, NYC pharmacies located in communities highly affected by HIV, in areas with some of the highest rates of poverty in the United States.Participants were satisfied with a counselorbased rapid HIV testing program in community-based pharmacies. Expansion of HIV screening initiatives into community pharmacies is one way to increase access to HIV testing for individuals who might not otherwise interact with the healthcare system Mixed methods Couples HIV testing and counseling implemented in antenatal care settings helps identify more HIV-positive men whose partners were negative than previous practice, with high acceptability among hospital staff. To evaluate a community-based an HIV testing program for its capacity to reach men who have sex with men (MSM) and successfully refer HIVpositive patients to treatment.Easily accessible, community walk-in clinics and targeted testing in high-risk settings are convenient for populations of MSM less likely to seek out the established health care system. Check-point diagnosed 37 new HIV cases, posed no barrier to successful link-age to care, was noninferior in quickly reducing community viral load, was cost-effective, reached younger MSM, and proved an ideal plat-form for trying out new interventions and test forms, which conventional health care providers have not yet embraced. To determine the characteristics of those more likely to undergo frequent (HIV) testing.We found that providers need to strengthen practices to identify persons who have had multiple HIV tests and provide enhanced behavioral interventions for those with persistent risks. This might mean referral to other prevention and support services in order to effect sustainable risk reduction. The results also suggest that some risk behaviors (i.e. injection drug use, MSM and multiple sexual partners) are appropriately recognized as markers for more frequent HIV testing Early implementation of the NACHC model in our setting posed challenges in terms of time involved in initial planning, consistent data collection and reporting, and patient flow. In spite of these challenges, 100 patients were screened for HIV infection who might not have been screened otherwise, and they were given HIV risk reduction handouts after testing, an education intervention that may raise awareness and lead to behavior changes. Younger patients were more likely to undergo testing. The majority of patients who were tested, African American women, represented a high-risk group in North Carolina and the South, and yet African American MSM, those with the highest risk, were underrepresented in our sample. To describe adolescent attitudes and preferences toward rapid HIV testing in a Pediatric Emergency Department.This study offers valuable new insights into adolescent attitudes and preferences for rapid HIV testing in a PED. Adolescents gave high ratings for the location, testing, and counseling process. Our data support the importance of structured counseling, which is contrary to current published perspectives of counseling efficacy. In addition, we found that the PED was a highly preferred location for rapid HIV testing, which supports the need for increased development of prevention and testing programs in this setting. To (i) evaluate a multisite HIV testing program designed to encourage localized HIV testing programs focused on self-identified sexual minority males (especially those of color) aged 13 to 24 years; and (ii) link youths to appropriate prevention services after receipt of their test results.The findings suggest that community-based targeted approaches to HIV testing are more effective than universal screening for reaching young sexual minority males (especially males of color), identifying previously undiagnosed HIV-positive youths, and linking HIVnegative youths to relevant prevention services. Targeted, community-based HIV testing strategies hold promise as a scalable and effective means to identify high-risk youths who are unaware of their HIV status. To evaluate the impact of a focused emergency nurse partnership with a long-standing HIV testing program, by analyzing a successive series of nurse-driven strategies focused on optimizing rates of HIV testing.",Canada,first author,2021-02-23,02
dc8e67fc505341ba28e03d2a33a922d66d046564,UPDATE IN UROLOGY ENDOUROLOGY Editorial Comment: Objective Assessment and Standard Setting for Basic Flexible Ureterorenoscopy Skills Among Urology Trainees Using Simulation-Based Methods,"Flexible ureterorenoscopy (fURS) is a frequent procedure in urology practice (1) . Graduating residents are expected to be competent in the skills necessary to perform fURS.This study aim was to assess the basic fURS skills of graduating residents using a procedure--specific ureteroscopic global rating scale. Forty urology residents in their final year of residency from eleven programs in Canada were evaluated while performing a standardized task using a fURS model. More than 79% of then reported experience in more than 50 fURS. The task was to inspect the entire collecting system and to relocate two lower caliceal stones to an upper calyx using a tipless basket. Expert surgeons and anonymous people from a web platform (crowd-workers) rated the performances. Before the task, all residents felt they would be competent in fURS. However, only 56.9% of the residents were competent enough to perform fURS based on expert ratings and 61.4% based on crowd-workers ratings. Poor outcomes of surgical procedures may be caused by several reasons but surgeon inability must not be one of them (2) .The COVID-19 pandemic caused an abrupt decrease in surgical volume jeopardizing urology training (3, 4) . Simulators and training models already exist to improve proficiency in most common endoscopic procedures and should be more used now (5, 6) . While every effort should be made to ",Canada,abstract,2021-02-03,02
c0e1aa20fc25a878a7017a0431b87f50cc8b3b46,One clot after another in COVID-19 patient: diagnostic utility of handheld echocardiogram,"We present a patient with COVID-19 infection presenting with respiratory failure and shock. Our case report highlights the strengths of focused cardiac ultrasound in differential diagnosis of shock and paradoxical embolism, especially valuable in patients with COVID-19 when access to other imaging modalities can be limited.A 63-year-old woman with the history of hypertension presented to the emergency department during COVID-19 pandemic with significant shortness of breath on minimal exertion and fatigue for 3 weeks. Patient was hypoxic to 74% and tachypneic to 30 breaths/min and required endotracheal intubation. Physical exam was unremarkable. Shortly, thereafter, she became persistently hypotensive requiring vasopressor support. Electrocardiogram revealed sinus rhythm with rate of 70 bpm, tall R wave in V2 and symmetric T wave inversions in precordial leads (Fig. 1) . Chest radiograph post intubation showed bilateral patchy infiltrates. Initial severe acute respiratory syndrome-coronavirus-2 (SARS-CoV-2) PCR test was negative while the second PCR for SARS-CoV-2 done 24 h later returned positive.Initial troponin T was 0.07 ng/ml with maximum at 0.22 ng/ml (reference range < 0.01 ng/ml) and NT-proBNP was 12 945 pg/ml. Elevated white blood cell count (21.1 × 10 3 /μl), creatinine (1.45 mg/dl), C-reactive protein (25.9 mg/dl) and ferritin (546 ng/ml) and D-Dimer 4.34 (ref range ≤ 0.63 mg/l) was noted. Serial ECGs remained stable. Patient remained persistently hypoxic with PaO 2 /FiO2 ratio of 85 which along with CXR findings is suggestive of severe acute respiratory distress syndrome (ARDS). Central venous oxygen saturation of 62% suggested the possibility of mixed shock.Computed tomography angiogram of chest was deferred due to hemodynamic instability and refractory hypoxemia. Systemic anticoagulation with heparin and broad-spectrum antibiotics was initiated. Due to institutional COVID-19 policy for transthoracic echocardiography to minimize personnel exposure, focused cardiac ultrasound (FoCUS) was performed, which revealed mildly increased right ventricular cavity size with flattened septum in systole and diastole along with bowing of interatrial septum toward the left supporting ECG findings of right ventricular strain (Fig. 2 , Supplementary video 1). Due to suspected massive pulmonary embolism (PE) alteplase 50 mg was given intravenously over 120 min. This resulted in significant improvement of hemodynamics, perfusion indices and oxygenation within next 12 h to the extent that hypotension resolved despite being on high PEEP protocol for ARDS. After 24 h, patient was noted to be unresponsive despite being off sedation. Urgent computed tomography (CT) of head revealed multifocal infarcts of both cerebral and cerebellar hemispheres with associated mass effects concerning for acute ischemic infarcts. Follow-up CT in 12 h revealed hemorrhagic transformation and anticoagulation with heparin was held. Due to concern for cardioembolic phenomenon, FoCUS with agitated saline was done that showed early right to left shunt consistent with patent foramen ovale (PFO) (Fig. 3, Supplementary video 2) . Doppler ultrasound of legs did not reveal deep venous thrombosis (DVT). No evidence of atrial fibrillation was noted on prolonged cardiac monitoring. Antiphospholipid antibody syndrome workup was negative.Patient remained intubated for 20 days due to poor mental status but was eventually successfully liberated from mechanical ventilation. She was discharged on apixaban 5 mg BID for PE. After 5 months of continuous physical, neurological and nutritional improvement, TEE was done which confirmed the PFO (Figs. 4 and 5) . She was referred for PFO closure. Shock in COVID-19 patients requires careful assessment. Distributive shock from inflammatory response to SARS-CoV-2 is common, but other types of shock including cardiogenic, obstructive (including tamponade and tension pneumothorax), as well as mixed shock should be considered. Myopericarditis, stress cardiomyopathy, and myocardial infraction (MI) should be in the differential for cardiogenic shock in such patients. A high degree of clinical suspicion is required to diagnose obstructive shock from PE given significant hypoxemia in severe COVID-19 cases due to ARDS [1] . Classic ECG changes of right ventricular strain S1Q3T3 are insensitive. On the other hand, simultaneous T wave inversions in inferior and precordial leads with maximum amplitude of T wave in V1-V2 was previously reported, as sign of PE [2] .Hypercoagulability, both in macro and microvascular circulation, is important contributor to morbidity and mortality in COVID-19 infection, and our understanding of the disease is evolving rapidly. Macro-thrombotic events including acute MI, acute limb ischemia, stoke, DVT, PE as well as pulmonary intravascular coagulopathy with micro-thrombotic complications are described in [3] . Early diagnosis of these grave thrombotic complications in COVID-19 patients may improve outcomes substantially.COVID-19 pandemic created a situation wherein healthcare workers safety and highest care to patients must be in delicate balance. Multiple institutions including American Society of Echocardiography implemented new policies to change use criteria and protocols for different imaging modalities to limit exposure of healthcare workers [4, 5] . FoCUS is valuable bedside tool and able to provide information on left and right ventricular systolic function, valvular abnormalities, pericardial effusion and volume status [6] . There are only limited reports on echocardiography and FoCUS use in COVID-19 patients [7] . Study by European Association of cardiovascular imaging showed 55% of patients with presumed or confirmed COVID-19 had abnormal echocardiography results which changed the management in one-third of the patients [8] . In a smaller study of 91 suspected or known COVID-19 patients, sonographers spent significantly less time using handheld ultrasound but still provided sufficient information for clinical team [9] . The major limitation of FOCUS is the diagnostic accuracy is dependent on the operator's skills.In our case, FoCUS was not only used for diagnosis of massive PE but also to diagnose the large interatrial shunt. Prompt diagnosis of massive PE and appropriate thrombolysis dramatically improved hemodynamics and oxygenation. Although stroke can be explained by prothrombotic state in COVID-19, embolic origin, particularly paradoxical embolism, needs to be ruled out [10] . FoCUS with agitated saline confirmed the diagnosis of interatrial right to left shunting as route for paradoxical embolism.To conclude, FoCUS facilitated diagnosis of massive pulmonary thromboembolism and interatrial shunt that guided clinical management. High clinical suspicion for thrombotic complications in COVID-19 patients is required for prompt diagnosis. FoCUS is a helpful tool readily available at bedside with advantage of limiting exposure of healthcare workers.Supplementary material is available at the Journal of Surgical Case Reports online.",USA,first author,2021-02-15,02
5bde184e73e88573fd0191aef330942136127b16,"Novel Case Report: A Previously Reported, but Pathophysiologically Unexplained, Association Between Collagenous Colitis and Protein-Losing Enteropathy May Be Explained by an Undetected Link with Collagenous Duodenitis","Collagenous colitis (CC) is associated with non-bloody, watery diarrhea, which is pathophysiologically reasonable because normal colonic absorption (or excretion) of water and electrolytes can be blocked by the abnormally thick collagen layer [1] . However, CC has also been associated with six cases of protein-losing enteropathy (PLE) ( [2] [3] [4] [5] [6] [7] ; Table 1 ), with no pathophysiologic explanation. The colon does not normally absorb (or excrete) amino acids/proteins, which is primarily the function of the small bowel [8] .Collagenous duodenitis (CD) 1 (or enteritis) has not been associated with PLE [9] [10] [11] [12] [13] [14] [15] [16] [17] [18] [19] . 2 This work reports a novel case of CD (and CC) associated with PLE; a pathophysiologically reasonable mechanism for CD causing PLE (the thick collagen layer of CD blocks normal intestinal amino acid absorption); and a novel association of PLE with severe COVID-19 infection (attributed to relative immunosuppression from hypoproteinemia, hypoalbuminemia, hypogammaglobulinemia, and malnutrition from PLE) [3, 6] . A potential association of CD with PLE is clinically important; PLE is a life-threatening, but potentially curable, syndrome.A 65-year-old African American woman with a 50-pack-year history of smoking tobacco, no prior renal insufficiency, and no other medical disorders, presented with nausea, vomiting, and generalized abdominal pain for 3 days; five non-bloody, watery stools/day; and 14 kg involuntary weight loss over the prior 3 months. Physical examination on admission revealed a minimally overweight female (BMI = 27.6 kg/m 2 ); normal vital signs; dry mucous membranes, absent axillary sweat, and poor skin turgor; a non-tender, non-distended abdomen without hepatosplenomegaly; and no fecal occult blood. The leukocyte count was 6900/mm 3 (normal: 3500-10,100 leukocytes/mm 3 ), and hemoglobin was 13.9 g/dL (normal: 13.5-17 g/dL). Serum creatinine was 3.61 mg/dL (normal: 0.6-1.3 mg/dL), blood urea nitrogen was 43 mg/dL (normal: 7-25 mg/dL), urine specific gravity was 1.023 (> 1.015 consistent with dehydration), and glomerular filtration rate was 14 mL/min (< 15 mL/min indicates renal failure). Serum potassium was 2.7 mmol/L (normal: 3.5-5 mmol/L). Stool tests for Clostridioides difficile toxins A and B and for ova and parasites were negative. Stool culture for bacterial pathogens was sterile. Stool calprotectin level was 225 mcg/g (normal: 0-50 mcg/g). Abdominopelvic computed tomography (CT) on the initial admission was within normal limits, with no intra-abdominal lymphadenopathy, mural bowel thickening, dilated bowel loops, streaky mesentery, or organomegaly.The patient received lactated Ringer's solution intravenously at 150 mL/h to reverse dehydration and acute renal failure. Tests for celiac disease revealed tissue transglutaminase immunoglobulin (Ig) A of 8.4 units/mL (normal: 0-19.9 units/mL), and total IgA of 247 mg/dL (normal: 70-365 mg/dL). Colonoscopy, performed for chronic diarrhea, revealed an endoscopically normal colon, but histopathology of biopsies taken throughout the colon showed an abnormally thick (> 10 μm) subepithelial collagen layer diagnostic of CC (Fig. 1a, b) . The patient was initially Fig. 1 a High-power photomicrograph of hematoxylin and eosin stained section of a random colonic biopsy from endoscopically normal-appearing colon shows a markedly thickened subepithelial collagen (pink) band measuring approximately 40 μm (diagnostic of collagenous colitis). b High-power photomicrograph of the same colonic biopsy stained with Masson's trichrome, which highlights the collagenous band in blue and confirms the thickened (approximately 40 μm) collagen layer treated with oral budesonide 9 mg/day, with gradually decreasing diarrhea, but mesalamine 800 mg twice daily was added as therapy because of persisting non-bloody diarrhea, with subsequent improvement. The patient was advised to cease smoking, as recommended for patients with collagenous colitis [23] , but refused.She was readmitted 1 month later for refractory nausea and vomiting. Physical exam revealed anasarca, manifested by ascites and 3+ pitting edema of all four extremities. Serum albumin was 1.4 g/dL (normal: 3.5-4.9 g/dL), and prealbumin was 10 mg/dL (normal: 18-44 mg/dL). Hypoalbuminemia was not from liver disease: all liver function tests were within normal limits. Hypoalbuminemia was not from protein-losing nephropathy: urine collection revealed only 276 mg of protein/24 h (nephrotic syndrome: > 3.5 g/24 h). Ascites was not from congestive heart failure: electrocardiogram was within normal limits, and chest X-ray did not reveal cardiomegaly. Stool alpha-1 antitrypsin was 369 mg/ dL (normal: < 54 mg/dL), a finding diagnostic of PLE [24] ; anasarca and hypoalbuminemia were therefore due to PLE. Iron studies were within normal limits. Vitamin B12, folate, and vitamin K were within normal limits, as were cholesterol and triglyceride levels. Vitamin D level was 14 ng/mL (normal 30-100 ng/mL).Esophagogastroduodenoscopy (EGD) revealed minimally nodular mucosa in the first and second portions of the duodenum (Fig. 2a) . Histopathology of duodenal biopsies revealed severe CD [Fig. 2b, c; collagen layer in (c) measuring approximately 332 μm, > 10 μm characteristic of CD)], and of gastric biopsies revealed no Helicobacter pylori. Azathioprine was added to the regimen of mesalamine and budesonide. A dietician recommended a protein-rich diet supplemented with medium-chain triglycerides, but patient refused this diet as unpalatable, and was discharged on total parenteral nutrition (TPN).The patient presented 2 months later with nausea, vomiting, worsening diarrhea, cough, and dyspnea for 7 days. She was taking budesonide, but was noncompliant with azathioprine and mesalamine. Physical examination on admission revealed a mildly thin woman (BMI = 23.47 kg/m 2 ); pulse of 100 beats/min, temperature of 36.6 °C, 18 breaths/ min, and O 2 saturation of 99% on room air; dry mucous membranes; moderate ascites; and soft, non-distended, and non-tender abdomen. Laboratory tests revealed 7900 leukocytes/mm 3 (normal: 3500-10,100 leukocytes/mm 3 ), creatinine of 0.87 mg/dL (normal: 0.6-1.3 mg/dL), potassium of 2.4 mmol/L (normal: 3.5-5 mmol/L), albumin of 2.3 g/ dL (normal: 3.5-4.9 g/dL), prealbumin of 8 mg/dL (normal: 18-44 mg/dL), and serum IgG of 491 mg/dL (normal: 550-1650 mg/dL), findings consistent with malnutrition from PLE. Nasopharyngeal swab was positive for COVID-19 infection by nucleic acid amplification, as confirmed by polymerase chain reaction. C-reactive protein was 48.4 mg/L (normal: 0-7.9 mg/L), attributed to active COVID-19 infection. Stool studies for Clostridioides difficile toxins A and B and for ova and parasites were negative. Stool culture for bacterial pathogens was sterile. Repeat EGD with duodenal Fig. 2 a Esophagogastroduodenoscopy (EGD) revealed endoscopically essentially normal (minimally nodular) mucosa in first and second portions of duodenum, as illustrated for the second portion of the duodenum. b Medium-power photomicrograph of hematoxylin and eosin-stained section of a random biopsy of endoscopically relatively normal-appearing second portion of duodenum shows severe to total blunting of the villi, with no appreciable villous height. The collagen band measures approximately 121 microns (> 10 microns diagnostic of collagenous duodenitis). This collagen band is thicker than that observed in the colon (Fig. 1a) . c Medium-power photomicrograph of the same duodenal biopsy stained with Masson's trichrome, which highlights collagen in blue, shows extensive collagenization of duodenal mucosa, with more discernable collagenization visualized in this stain (measuring approximately 332 μm of entire thickness of the lamina propria) than demonstrated in the hematoxylin and eosin stain biopsies revealed persistent CD. She received intravenous hydration, TPN, hydroxychloroquine for COVID-19 infection, and budesonide for CD. She did well without developing respiratory distress and was discharged 11 days after admission.Etiologies of PLE include erosive GI mucosal diseases such as Crohn's disease or GI malignancies; diseases causing intestinal lymphatic fluid loss from lymphatic obstruction, such as primary intestinal lymphangiectasia, or lymphoma; and diseases increasing intestinal mucosal permeability such as Ménétrier's disease [25, 26] . CC is a reported cause of PLE but lacks a pathophysiologic basis. The current work suggests a novel association of CD (and CC) with PLE. Linkage of CC with CD can explain the pathophysiology of PLE by disruption of normal amino acid absorption by the thick intestinal collagen layer in CD (12× upper limit of normal in the current case). Patients with CC and PLE may be reasonably tested to exclude CD by intestinal biopsies. Diagnosing PLE etiology is important to initiate specific therapy.The current diagnosis of CD was challenging because of negative serology for celiac disease and absence of iron deficiency anemia. CD often occurs with celiac disease [27] , which by itself has a mildly increased subepithelial collagen layer [28] . Initiation of a gluten-free diet causes regression of collagen in celiac disease, but not in CD. Collagenous celiac disease (collagenous sprue) has been rarely reported but has not been associated with PLE, even though it has been associated with hypoalbuminemia [29] . Although this patient had severe to total blunting of the intestinal villi (Fig. 2b) , the patient did not have collagenous sprue, as shown by negative serology for celiac disease.Collagen deposition in CC is believed to be immunemediated; autoimmune diseases, medications, viruses, and bacteria are speculated triggers [19, 28, 30] , including one case of Yersinia enterocolitica [14] . Collagen deposition and inflammation in CC may extend from the colonic to intestinal mucosa and cause CD by dysfunction of subepithelial myofibroblasts [10, 17] . CC is characterized by an abnormally thick (> 10 μm diameter) subepithelial hyalinized collagen band [19, 21, 27, 30] . Although CC is frequently reported, CD is rarely reported [13] . Because of its rarity, CD is not usually suspected in patients with CC.Immunosuppression from human immunodeficiency virus infection, cancer, solid organ transplantation, immunomodulatory therapy for autoimmune diseases, and malnutrition can cause severe COVID-19 outcomes, including prolonged hospitalization, intensive care unit admission, renal failure, intubation, mechanical ventilation, and mortality [31] [32] [33] .This work suggests that PLE may be associated with severe COVID-19 infection, most likely from severe malnutrition, manifested by hypoproteinemia, hypogammaglobulinemia, hypoalbuminemia, and low prealbumin. Immunosuppression from corticosteroid therapy (budesonide in the current case) is a controversial risk factor for severe COVID-19 infection, because corticosteroids may improve the prognosis of COVID-19 infection.COVID-19 can affect the digestive system [34] [35] [36] . The receptor-binding domain of COVID-19 binds strongly to human angiotensin converting enzyme-2 (ACE-2), which is abundantly expressed in the intestines [37] . Studies have identified COVID-19 RNA in stool specimens of infected patients, suggesting the virus may infect the digestive system [34] . It is interesting to speculate whether COVID-19 infection may be more severe in patients with intestinal disease, such as CD.This report is limited by its single-case retrospective nature. However, an association of PLE with CD has a solid pathophysiologic basis because the small intestine is the primary site of amino acid (protein) absorption, which should be severely compromised by a thick intestinal collagen layer. In contrast, the colon does not play a physiologic role in amino acid absorption and CC should not affect amino acid absorption. A minor criticism is that the patient's collagenous colitis was treated about 1 year ago with budesonide and mesalamine. Mesalamine has recently been delisted as recommended therapy for collagenous colitis [38] . Strengths of this work include a strongly positive diagnosis of PLE by alpha-1 antitrypsin levels, a strongly positive pathologic diagnosis of CD, and exclusion of other major causes of hypoalbuminemia and anasarca aside from PLE. This work requires confirmation in a large prospective trial, but such a trial may be problematic because CD is relatively rare.This case demonstrates that presentation of CD (with CC) can result in PLE, attributed to a thick collagen layer preventing absorption of amino acids/proteins in small intestine. Immunosuppression from hypoproteinemia, hypoalbuminemia, hypogammaglobulinemia, and malnutrition from PLE likely constitutes a high risk factor for severe COVID-19 infection.Author's contribution The initial draft of the manuscript was written by Drs. IG, AAS, AIE, KR, and MSC. The manuscript was thoroughly revised, and major additions were made by Dr. MSC, who served as the mentor. Drs. KR and MSC provided clinical gastroenterologic care to the patient. Dr. MA provided the histopathology images and description. Drs. IG and MSC are the primary authors.",USA,first author,2021-02-04,02
c8fc27e4845be0f3c0baa6bdb6fe06f48bc72dfe,Decreased neutralization of SARS-CoV-2 global variants by therapeutic anti-spike protein monoclonal antibodies,"Monoclonal antibody therapies for the treatment of COVID-19 have been found to reduce virus loads and alleviate symptoms when given shortly after diagnosis 1, 2 . The REGN-COV2 therapy developed by Regeneron Pharmaceuticals is a two recombinant monoclonal antibody cocktail consisting of REGN10933 and REGN10987 3, 4 Lilly therapy is based on a single antibody LY-CoV016 5 . The antibodies bind epitopes within the receptor binding domain (RBD) of the Wuhan-Hu-1 spike protein. The rapid evolution of SARS-CoV-2 variants with mutations in the viral S gene that encodes the spike protein raises concerns that monoclonal antibody therapies could lose effectiveness against viruses for which the spike protein has mutations that alter the amino acid sequences of the epitopes bound by the antibodies.Following the isolation of Wuhan-Hu1 SARS-CoV-2 in December 2019, the virus has continued to further evolve as it adapts to the human host. A variant with a D614G mutation 6 the spike protein which was identified in January, 2020 and by May became the predominant strain world-wide with a prevalence of >97%. The amino acid residue, which is located near the S1:S2 processing site, reduces S1 subunit shedding from virions, has increased infectivity and results in higher virus loads 7-9 . Additional variants containing the D614G mutation with increased transmissibility were subsequently identified. The B.1.1.7 lineage (VOC-202012/01) variant identified in patients in the United Kingdom 10-12 encodes a spike protein with 8 mutations in addition to D614G (Δ69-70, Y144Del, N501Y, A570D, P681H, T716I, S982A and D1118H). N501Y is one of six ACE2 contact residues and has been shown to increase affinity for ACE2 13 The increasing prevalence of highly transmissible variants with mutations in the spike protein RBD raises concerns that the therapy could become less effective should any of the mutations lie within the epitopes targeted by the monoclonal antibodies. To address this question, we tested the neutralizing activity of REGN10933 and REGN10987 on Table. 1). The combination of REGN10933 and REGN10987 was highly potent against D614G with an IC50 of 1.69 ng/ml, and appeared to be slightly synergistic as the neutralizing titer was higher than of each antibody alone. Neutralizing titers for the mixture against B.1.351 and mink cluster 5 were reduced 9.14-and 16.2-fold compared to D614G, respectively, a result that reflects the large decrease in neutralizing titer for REGN10933 on both variants combined with a minor decrease in neutralizing titer by REGN10987 on both variants ( Figure. 2 and Table. 1). Analysis of the single point mutations showed that the reduction in neutralizing titer was caused by both E484K and Y453F mutations.We report here that REGN10933, one of the two monoclonal antibodies that constitutes with 10% fetal bovine serum (FBS) and penicillin/streptomycin (P/S) at 37°C in 5% CO2.ACE2.293T cells are clonal cell-line that expresses high levels of human ACE2 and have been previously described 29, 33 .cDNAs encoding REGN10933 and REGN10987 were synthesized using the published sequences of the antibody variable heavy and light chains fused to IgG1 heavy chain and lambda light chain, respectively and cloned into pcDNA3.1 (Invitrogen). The proteins were produced in transfected Freestyle 293 cells and collected from the cell supernatant after four days. The antibodies were purified by on an AKTA prime FPLC with HiTrap Pro A 5cccolumn. The proteins were tested for purity by SDS-PAGE, quantified by BCA assay and tested for spike protein binding by Bio-layer Interferometry on an Octet Detection System.SARS-CoV-2 spike protein pseudotyped lentiviral stocks were produced by cotransfection of 293T cells with pMDL, pLenti.GFP-NLuc, pcCoV2.S-D19 (or variants thereof) and pRSV.Rev as previously described 33 . Virus stocks were normalized for reverse transcriptase activity 34 . Pseudotyped virus infections were done with 1 X 10 4 cells/well in 96 well tissue culture dishes at an MOI=0.2 33 . Luciferase activity was measured after 2 days using Nano-Glo luciferase substrate (Promega) and plates were read in an Envision 2103 microplate luminometer (PerkinElmer). To measure antibody neutralization, antibodies were serially diluted 5-fold and then incubated for 30 minutes at room temperature with pseudotyped virus (corresponding to approximately 2.5 X 10 7 cps luciferase) in a volume of 50 µl. The mixture was added to 1 X 10 4 ACE2.293T cells (corresponding to an MOI of 0.2) in a volume of 50 µl in a 96 well culture dish. After 2 days, the medium was removed and Nano-Glo luciferase substrate (Nanolight) was added to wells. Luminescence was read in an Envision 2103 microplate luminometer (PerkinElmer).All experiments were performed in technical duplicates or triplicates and data were ",USA,first author,2021-02-19,02
7213dac2cc87ccc9afc70b896f1abbdc3657aa2f,Journal Pre-proof Increases in Distress during Stay-At-Home Mandates During the COVID-19 Pandemic: A Longitudinal Study DEPRESSION AND ANXIETY DURING COVID-19 1 Increases in Distress during Stay-At-Home Mandates During the COVID-19 Pandemic: A Longitudinal Study CRediT Author Statement,"The Coronavirus disease 2019 pandemic has thus far contributed to over 500,000 deaths, and hospitalization of thousands of individuals worldwide (Pettersson et al., 2020) . It has also been found to be related to cross-sectional reports of elevated levels of anxiety and distress (Rosen et al., 2020) . Although it is normative to experience elevated anxiety and fear in the face on an on-going health threat such as COVID-19, individuals with certain underlying characteristics experienced greater distress and impairment in the face of other types of crises such as the 9/11 terror attack and Hurricane Katrina. For example, individuals with greater pre-9/11 analogue generalized anxiety disorder (GAD) experienced more post-traumatic stress symptoms following 9/11 (Farach et al., 2008) and greater trait anxiety was related to more post-Katrina post-traumatic stress, generalized anxiety, and depression even after accounting for hurricane-related factors, such as loss of home, death of a loved one, and relocation (Weems et al., 2007) . Thus, it may be that individuals with elevated trait anxiety prior to a global pandemic may experience greater pandemic-related anxiety and/or impairment. However, we are not aware of any published prospective research examining COVID-related psychological functioning as a function of pre-pandemic anxiety or depression.Social anxiety is one phenotypic expression of anxiety that has received little attention in terms of response to disasters such as 9/11 and Hurricane Katrina. Yet, social anxiety is an important individual difference variable to consider for several reasons, including that it is one of the most common anxiety conditions (Kessler et al., 2012) and social anxiety disorder is among the most common psychiatric disorders (Kessler et al., 2005) . Further, given the impacts on social functioning inherent in Stay-At-Home and Shelter-In-Place orders associated with, socially anxious persons may be especially vulnerable to worse COVID-related emotional outcomes.The aims of this study were to further understanding of the emotional impact of the COVID-19 pandemic in several ways: (1) to prospectively test whether anxiety and depression increased from the month before a statewide Stay-At-Home order to during the order; and (2), extend prior work indicating that pre-crisis trait anxiety and GAD symptoms are related to crisisrelated anxiety and depression (Farach et al., 2008; Weems et al., 2007) by testing whether prepandemic social anxiety would be predictive of greater anxiety, depressive, and COVID-related worry and interference during the Stay-At-Home order. We tested these relations in a sample of young adults from a university in Louisiana, a state with some of the worst COVID-related outcomes in the U.S. (von Springer, 2020) and the highest initial growth rate of confirmed cases of coronavirus anywhere in the world (WGNO Web Desk, 2020). Baseline assessment of social anxiety, trait anxiety, and depression occurred in the month leading up to their state's pandemicrelated Stay-At-Home order and follow-up assessment occurred during the Stay-At-Home, one month following its enactment, offering a unique opportunity to prospectively examine the role of social anxiety as a potential risk factor for negative psychological sequelae arising in the context of this global pandemic.Participants were initially recruited through the psychology participant pool from a large state university in Louisiana from February 16, 2020 to March 13, 2020 for a study examining psychosocial functioning in college students. The university's Institutional Review Board approved the original study and participants provided informed consent prior to data collection.On March 13, 2020, the university closed the campus and transitioned to on-line learning in response to the COVID-19 pandemic and the state's governor issued a Stay-At-Home order on March 21, 2020. On 4/13/2020, the Institutional Review Board approved the present follow-up study and data collection occurred until the Phase 1 re-opening of the state on 5/15/2020. One hundred twenty participants completed computerized self-report measures at baseline and follow-up using a secure, on-line data collection website (Qualtrics.com). Participants received referrals to university-affiliated psychological outpatient clinics and the telephone number for the DEPRESSION AND ANXIETY DURING COVID-19 5 local crisis intervention hotline as well as research credit for completion of the surveys.Participants who completed the follow-up survey were also entered into a drawing to win one of four $250 prizes. The sample of 120 had a mean age of 19.8 (SD = 1.6) and racial/ethnic composition was 13.3% non-Hispanic/Latinx African American/Black, 4.2% Asian/Asian American, 76.7% Non-Hispanic/Latinx White, 3.3% Hispanic/Latinx White, and 2.5% Multiracial.Regarding social anxiety, 41.7% scored above the empirically supported clinical cut-score (Heimberg et al., 1992) on the Social Interaction Anxiety Scale (Mattick & Clarke, 1998) , a conservative method to identify SAD among college students (Rodebaugh et al., 2006) .Demographics and COVID-19 Screening. Participants provided information on sex, age, and ethnicity. Participants also responded to 6 items related to COVID-19 diagnosis and exposure as well as recent international travel to areas highly impacted by COVID-19.The Social Interaction Anxiety Scale (Mattick & Clarke, 1998 ) was used to assess social anxiety. The SIAS contains 20 items scored from 0 (not at all characteristic or true of me) to 4 (extremely characteristic or true of me). The SIAS has shown adequate specificity for social anxiety relative to other forms of anxiety (e.g., trait anxiety; Brown et al., 1997) . Internal consistency of the SIAS at baseline was excellent in the current sample (=.94).The Depression Anxiety Stress Scale (DASS-21; Lovibond & Lovibond, 1995) was used to assess depression and trait anxiety. Each subscale contains seven items and has evidenced good internal consistency reliability, convergent and discriminant validity, and criterion-related validity (Antony et al., 1998) . Internal consistency in the present study was good for anxiety (88) and depression (94) COVID-19 Daily Activity Disruptions. Items were developed to assess changes in health behavioral following the COVID-19 pandemic. Items assessed difficulties with daily hygiene, sleeping, social connection, eating, motivation, maintaining a routine, exercising, and fatigue.Participants were asked to consider what is normal/typical for them and rate how true each statement was for them since the COVID-19 pandemic (0 = not all true of me to 3 = very true).These eight items were summed to create a total score (83).COVID-19 Worry Index. Guided by established assessments of worry, (Meyer et al., 1990) , 15 items were developed to assess worry related to COVID-19 from 1 (not at all) to 7 (a great deal). Example items including ""I am worried I will lose friends due to social distancing"" and ""I am worried I will not be able to handle being in quarantine."" Items (15 items) were summed to create a total score (92). At follow-up, no participant had been diagnosed with COVID, although 5.1% thought they may have COVID-19 but had not been tested, 5.9% had been exposed to someone who had a confirmed case of COVID-19, 7.6% had been exposed to someone who had been tested for COVID-19 and was awaiting results, 2.5% had traveled to/from an area with community spread COVID-19 within the past 3 months (e.g., China, Italy), and 49.2% were in New Orleans, for a Mardi Gras parade in 2020, which is noteworthy given that New Orleans is considered an epicenter of the state's pandemic (Edwards, 2020).Means, standard deviations, and correlations among study variables are presented in Next, a series of hierarchical regression analyses were conducted to determine if pre-Stay-At-Home Order social anxiety, trait anxiety, and depression predicted anxiety and depression during the Stay-At-Home Order as well as COVID-related worry and interference (Table 2 ). In all models, pre-Stay-At-Home Order anxiety and depression were entered into Step 1, along with COVID-related variables. Pre-Stay-At-Home Order social anxiety was entered intoStep 2. This approach ensures that effect at Step 2 cannot be attributed to variance shared with variables in Step 1 (Cohen & Cohen, 1983) . In the first model, anxiety during the Stay-At-HomeOrder was entered as the criterion variable. This model was statistically significant, such that the variables in Step 1 accounted for 45.8% of the variance in anxiety during the Stay-At-Home Order, with pre-Stay-At-Home Order social anxiety uniquely accounting for an additional 5.1%.Notably, pre-Stay-At-Home Order depression was no longer statistically significantly related to anxiety during the Stay-At-Home Order when accounting for variance attributable to pre-Stay-At-Home Order anxiety. In the second model, depression during the Stay-At-Home Order was entered as the criterion variable, and this model was also statistically significant, such that the variables in Step 1 accounted for 50.4% of the variance in depression during the Stay-At-Home Order, with social anxiety uniquely accounting for an additional 4.9%. In the third model, COVID-related worry was entered as the criterion variable, and this model was also statistically significant, such that the variables in Step 1 accounted for 9.6% of the variance in COVIDrelated worry, with social anxiety uniquely accounting for an additional 9.1%. Notably, pre-Stay-At-Home Order anxiety and depression were no longer statistically significantly related to COVID-related worry. In the fourth model, COVID-related interference was entered as the criterion variable, and this model was also statistically significant, such that the variables in Step uniquely accounting for an additional 7.5%. Notably, pre-Stay-At-Home Order depression was no longer statistically significantly related to COVID-related interference.To understand the nature of the COVID-related interference related to pre-Stay-At-Home Order affective variables, correlations were examined among pre-Stay-At-Home Order social anxiety, anxiety, depression, and interference scores at the item level (Table 3) . Social anxiety was statistically significantly, positively related to trouble keeping up with daily hygiene, sleeping, keeping in contact with family and friends, feeling motivated, keeping a daily routine, and exercising, as well as eating unhealthier and feeling more fatigued. Pre-Stay-At-HomeOrder anxiety was similarly related to all interference items and depression was statistically significantly related to all items except unhealthy eating.To the best of our knowledge, this is the first known study of prospective predictors of pre-Stay-At-Home Order affective variables in the prediction of anxiety and depression during the COVID-19 pandemic's Stay-At-Home Orders. Results indicated depression, but not trait or social anxiety, increased from the month prior to the state-wide Stay-At-Home order to the month after the order was issued. That depression increased during the first month of the Stay-At-Home order is noteworthy given that prior work found no increase in depression in response to other broad-scale disasters (Weems et al., 2007) , suggesting that either the nature of the COVID-19 pandemic and/or the Stay-At-Home order may uniquely increase depressive symptoms.Interestingly, depression, anxiety, and stress increased among adult communityrecruited participants from the first week of Italy's COVID-19-related Stay-At-Home order to the last week of the order and individuals with pre-existing mental health disorders were especially vulnerable to these increases (Fiorillo et al., 2020) . When considered in light of our findings, these data suggest that among college students, depression was higher during the first month of the COVID-19 pandemic-related Stay-At-Home order and among community adults, depression, anxiety, and stress increased from the first week to the last week of the Stay-At-Home order. Future work is necessary to determine whether anxiety and stress also increased from the first to last weeks of the order among college students to determine whether the increase in anxiety and stress is due to concerns that may be more specific to non-college adults, such as loss of income associated with the Stay-At-Home order.Notably, our study is one of the first known studies to examine the impact of pre-Stay-At-Home affective variables (e.g., social anxiety) and its impact on psychological functioning during Stay-At-Home orders among college students. In line with findings from Hurricane Katrina (Weems et al., 2007) , pre-Stay-At-Home Order trait anxiety predicted anxiety and depression during the Stay-At-Home Order. However, counter to Weems et al. in which pre-Katrina depression was unrelated to follow-up anxiety or depression, pre-Stay-At-Home Order depression predicted depression and anxiety during the Stay-At-Home Order; again, highlighting that the response to the emotional toll of the COVID-19 pandemic may be unique from other crises experienced in this region. Further extending prior work, social anxiety also predicted anxiety and depression during the pandemic. Notably, results also indicated that social anxiety was a robust predictor of both trait anxiety and depression during the Stay-At-Home Order, as well as a unique predictor of COVID-related worry (which was not the case for pre-Stay-At-Home Order depression or anxiety) and a robust predictor COVID-related interference (which was not the case for pre-Stay-At-Home Order ).Results have several important broadscale implications for psychological health and general wellbeing. First, they highlight that depression increased as a result of the COVID-19 pandemic's state-wide Stay-At-Home order. Thus, interventions to teach individuals skills to manage depression could improve functioning during the COVID-19 pandemic or even postpandemic. Second, results indicated that individuals with social anxiety may be especially vulnerable to experiencing anxiety, depression, and COVID-related worry and interference during the COVID-19 pandemic. Thus, these individuals may especially benefit from cognitive behavioral strategies to manage their negative affect, including strategies to manage their behavioral reactions to the pandemic, such as sleep hygiene (National Sleep Foundation, 2020) and exercise. Exercise may be especially useful given data indicating that it can be useful for decreasing anxiety (Stubbs et al., 2017) .Findings must be considered in light of limitations that can inform future work geared toward understanding the affective impact of the COVID-19 pandemic and associated government Stay-At-Home orders. First, the sample consisted largely of White female young adults and it will be important to test whether results generalize to other samples (e.g., noncollege persons, older persons, other racial/ethnic groups). This work is especially important in light of evidence that men and women may experience differential mental health outcomes during the COVID-19 Stay-At-Home orders (Fiorillo et al., 2020; Khubchandani et al., 2020) ; unfortunately, our sample was comprised of too few male participants to test whether sex moderated outcomes. Further work with more diverse samples is also necessary given that the negative health effects of COVID-19 are especially problematic among individuals with preexisting health conditions (e.g., heart disease, immunocompromised, diabetes), older individuals (Centers for Disease Control and Prevention, 2020), and Black and Hispanic/Latinx Americans, most likely due to health disparities and institutional racism rather than individual-level factors (Erdman, 2020); thus, future work is necessary to determine the emotional impact of this pandemic and its associated Stay-At-Home order and other mitigation measures on these highrisk individuals.Second, a non-clinical sample was employed and an important next step will be to test whether results generalize to clinical samples. It may be that clinical samples may be more vulnerable to the adverse mental health effects of COVID-19, as has been found in other disasters (Zvolensky et al., 2015) . In fact, individuals receiving outpatient telehealth services during the Stay-At-Home order and those who were diagnosed with psychiatric disorders endorsed elevated levels of posttraumatic stress during Stay-At-Home orders compared to DEPRESSION AND ANXIETY DURING COVID-19 11 individuals who did not have pre-existing mental health conditions (Carmassi et al., 2020; Hao et al., 2020) , and these symptoms were especially elevated among women with Bipolar disorder (Carmassi et al., 2020) . Third, data were collected via self-reports. Future work could benefit from multi-method (e.g., ecological momentary assessment of momentary predictors of increases in state anxiety, depression, worry, etc.) and multi-informant (e.g., collateral reports of COVID-related impairment) approaches. Fourth, most states no longer have mandated Stay-At-Home orders, although most do encourage social distancing and other mitigation measures.Consequently, an important next step will be to test whether results are unique to staying at home during a pandemic or whether they continue once individuals are permitted more social interaction.The current study provides invaluable information on some of the affective consequences of the COVID-19 pandemic and associated government Stay-At-Home orders.Data indicate that depression, but not anxiety, has increased during the pandemic's Stay-At-Home order and this was especially the case among individuals with elevated pre-Stay-At-Home Order anxiety, social anxiety, and depression. Further, individuals with elevated pre-Stay-At-Home Order social anxiety are suffering from greater levels of COVID-related worry and interference, thus identifying an especially vulnerable group.This research did not receive any specific grant from funding agencies in the public, commercial, or not-for-profit sectors.The authors declare no conflicts of interest with respect to the content of this manuscript.Dr. Buckner receives funding from the U.S. Department of Health & Human Services' Graduate Psychology Education (GPE) Program (Grant D40HP33350) and Our Lady of the Lake Hospital.Dr. Zvolensky receives fees from Elsevier, Guilford Press, and is supported by grants from NIH, American Cancer Society, and Cancer Research Institute of Texas. This content is solely the responsibility of the authors and these funding sources had no role in the design of the study; collection, analysis, and interpretation of data; writing of the manuscript; and decision to submit the manuscript for publication. The other authors report no disclosures. Pre-Pandemic Depression .08 0.66 .510 .00Step 2 .051 10.08 .002Pre-Pandemic Social Anxiety .25 3.18 .002 .05Step 1 .504 14.21 <.001Pre-Pandemic Anxiety .25 2.14 .035 .02Pre-Pandemic Depression .44 3.83 <.001 .07Step 2 .049 10.66 .002Pre-Pandemic Social Anxiety .25 3.27 .002 .05Step Step 2 .091 12.11 .001Pre-Pandemic Social Anxiety .34 3.48 .001 .09Step 1 .220 4.42 <.001Pre-Pandemic Anxiety .37 2.68 .009 .05Pre-Pandemic Depression .05 0.38 .701 .00Step 2 .075 11.64 .001Pre-Pandemic Social Anxiety .31 3.41 .001 .08Note. Social anxiety was assessed with the Social Interaction Anxiety Scale (SIAS; Mattick & Clarke, 1998) , and depression and trait anxiety with the Depression Anxiety Stress Scale (DASS-21; Lovibond & Lovibond, 1995) . standardized beta coefficient ",USA,first author,2021-02-23,02
7434024507a1f167d6a283757a5ef4ec5c257773,"Bayesian Calibration of CO2, Ventilation and COVID-19 Airborne Risk 1 Bayesian Calibration of Using CO2 Sensors to Assess Ventilation Conditions and Associated 1 COVID-19 Airborne Aerosol Transmission Risk in Schools 2","analyzed a one-day measurement of CO2 levels in three schools to estimate the ventilation rate and 1 airborne infection risk. Sensitivity analysis and Bayesian calibration methods were applied to 2 identify uncertainties and calibrate key parameters. The outdoor ventilation rate with a 95% 3 confidence was 1.96 ± 0.31ACH for Room 1 with mechanical ventilation and fully open window, 4 0.40 ± 0.08 ACH for Rooms 2, and 0.79 ± 0.06 ACH for Room 3 with only windows open. A 5 time-averaged CO2 level < 450 ppm is equivalent to a ventilation rate > 10 ACH in all three rooms. 6We also defined the probability of the COVID-19 airborne infection risk associated with 7 ventilation uncertainties. The outdoor ventilation threshold to prevent classroom COVID-19 8 aerosol spreading is between 3 -8 ACH, and the CO2 threshold is around 500 ppm of a school day 9 (< 8 hr) for the three schools. 10The actual outdoor ventilation rate in a room cannot be easily measured, but it can be calculated 12 by measuring the transient indoor CO2 level. Uncertainty in input parameters can result in 13 uncertainty in the calculated ventilation rate. Our three classrooms study shows that the estimated 14 ventilation rate considering various input parameters' uncertainties is between ± 8-20 %. As a result, 15 the uncertainty of the ventilation rate contributes to the estimated COVID-19 airborne aerosol 16 infection risk's uncertainty up to ± 10 %. Other studies can apply the proposed Bayesian and 17 MCMC method to estimating building ventilation rates and airborne aerosol infection risks based 18 on actual measurement data such as CO2 levels with uncertainties and sensitivity of input 19 parameters identified. The outdoor ventilation rate and CO2 threshold values as functions of 20 exposure times could be used as the baseline models to develop correlations to be implemented by 21 cheap/portable sensors to be applied in similar situations to monitor ventilation conditions and 22 airborne risk levels. 23The Harvard-CU Boulder Portable Air Cleaner Calculator 9 suggests a total of five air changes per 1 hour as a good ventilation condition for reducing airborne transmission risk in classrooms. 2While recommendations are mainly based on the ventilation rate, it has been a challenge to 3 quantify the outdoor air ventilation rate in a room. Indoor air CO2 concentration is often considered 4 a surrogate/indicator for the ventilation rate. For example, the Montreal school board (Centre de 5 services scolaire de Montreal) stated in an open letter on December 14, 2020: ""Establishments 6 without a mechanical ventilation system should apply the window opening guidelines to ensure 7 frequent air changes in our premises""; ""Always in order to ensure good indoor air quality, we have 8 also started measuring carbon dioxide (CO2) in our establishments since November. In addition to 9 this initiative, there are the CO2 tests that must be carried out by all school service centers in 10 Quebec before December 16. The level of CO2 is a good indicator of the supply of fresh air in a 11 room. Thus, following these tests, corrective measures will be put forward, if necessary."" 13 . 12 In the literature, several studies used a transient CO2 mass balance method and measured CO2 13 levels to calculate the ventilation rate in different indoor environments such as classrooms and 14 university libraries 10-12 . Batterman (2017) 12 estimated the CO2 generation rate based on the age 15 and assumed activity level for CO2 calculation in mechanically ventilated classrooms, but the real 16 activity type was unknown, so the results were subject to uncertainties. They used the whole day 17 data to estimate ventilation rate, but they did not validate the model by calculating the CO2 at a 18 different time or day. For the estimation of ventilation rate using the transient CO2 sensor data, it 19 is essential to find dominant parameters that affect the final results, calibrate the model by 20 measurement data, quantify and report the ventilation rates and infection risks with uncertainties. 21Therefore, to answer the ""CO2 for Risk Assessment"" question, in this work, we used the calibrated 13 ventilation rate and actual room parameters to calculate the COVID-19 airborne transmission in 14 the three classrooms using the modified Wells-Riley equation. We compared the results with 15 infection risk corresponding to the Reproductive number to be one (R0 = 1), and different 16 ventilation rates, and CO2 threshold levels at various exposure durations. 17where is the room volume ( 3 ); 2 is the indoor air CO2 concentration ( 3 ⁄ ); t is the 6 time duration ( ); is the CO2 generation rate by all occupants ( ⁄ ), which depends on the 7 age and activity level; 1 is the total outdoor air ventilation rate ( 3 ⁄ ); and is the outdoor 8 air CO2 concentration ( 3 ⁄ ). 9The transient mass balance, Eq. 1, is useful for solving arbitrary occupancy patterns and generation 10 rates such as classrooms because students leave the classroom for break and launch. The solution 11of Eq. 1 is: 12The probability of infection (PI) of a susceptible person in the room is calculated using the Wells-2Riley formulation 32 . The method was first used by Jimenez et al. 33 for calculating infection risk 3 in different indoor environments and is recently applied to the City Reduced Probability of 4Infection (CityRPI) model and used for city-scale infection risk analysis 34, 35 . PI is a function of 5 the number of quanta inhaled by the susceptible person (Eq. 3). We assumed that social 6 distancing is maintained between all occupants, and the current study focuses on airborne aerosol 7 transmission only. We used five assumptions for applying this model: i) there is only one infected 8 person in the room who emits SARS-CoV-2 quanta with a constant rate, ii) the initial quanta 9 concentration is zero, iii) the latent period of the disease is longer than the duration students stay 10 in the classroom. Therefore the quanta emission rate remains constant during the day, iv) the indoor 11 environment is well-mixed, and v) the infectious quanta is removed as a first-order process by the 12 ventilation, filtration, deposition on surfaces, and airborne inactivation. The PI in Eq. 1 is based 13 on the attendance of one infected person in the room, so it calculates the probability that COVID-14 19 aerosols are transmitted from the infected person to a susceptible person in the room; therefore, 15 it is a conditional probability of infection (PIcond). 16The number of quanta inhaled by the susceptible person at the exposure time T is calculated by 17 time-averaged quanta concentration. 18is the fraction of people in the room who wears the mask, and is the 2 inhalation mask efficiency. A well-mixed transient mass balance equation similar to Eq. 1 is solved 3 to calculate the room's transient quanta concentration. 4where is the indoor quanta concentration ( 3 ⁄ ); is the net quanta emission rate (ℎ −1 ); and 5 is the first-order loss rate coefficient for quanta (ℎ −1 ) . Assuming that the initial quanta 6 concentration is zero at the beginning of the day, Eq. 5 is solved as follows: 7Because of the change in the occupancy pattern during the day, the time-averaged quanta 8 concentration is calculated using the Trapezoidal integration. is calculated based on the number 9 of infected people in the room , the fraction of people in the room with the mask , exhalation 10 mask efficiency , and quanta emission rate by one infected individual ER . 11The first-order loss rate coefficient reflects several mechanisms: outdoor air ventilation 1 , 12 filtration 2 , deposition on surfaces 3 , and airborne inactivation 4 . 13As already mentioned, the is the conditional probability of infection, assuming that there is 4 one infected person in the room. The prevalence rate of the disease in the city can be used to 5 estimate the number of possible infected individuals in the room. Therefore, the absolute 6 probability of infection is calculated using the , , and number of susceptible 7 people in the room 33 : 8is calculated using the total number of people in the room , number of infected persons, 9 and the fraction of immune people in the community . It can be estimated using the total 10 recovered cases in the study region 36,37 . 11The prevalence rate of the disease is estimated using the daily COVID-19 statistics reported by 12 official sources: 13Both CO2 and infection risk models include uncertain parameters such as ventilation rates and 4 emission rates. Some of the uncertain parameters may impact the result's accuracy and should be 5 calibrated by measurement data. Ideally, with sufficient measurements and computer resources, 6 all the uncertain parameters should be included in the calibration parameters. In reality, limited by 7 data quality/quantity or computer resources, only a few parameters could be included. Many 8 parameters and inputs could also manifest different levels of uncertainties and significances on 9 simulation outputs. So it is impracticable and unnecessary to calibrate all parameters, but for 10 dominant parameters only. Identifying these dominant parameters cannot merely rely on arbitrary 11 parameter selections from modelers' knowledge but should be based on a scientific process, i.e., a 12 sensitivity analysis. 13The importance ranking results may vary with different combinations of sensitivity methods and 1 outputs depending on the variety of fundamental algorithms and conditions of each sensitivity 2 analysis method 41 . To avoid the potential inconsistency, Lim and Zhai proposed a new sensitivity 3 analysis method, sensitivity value index (SVI), to account for the differences in sensitivity analysis 4 methods and target outputs 42 . Eq. 12 shows how SVI is applied to recognizing and comparing the 5 importance rankings from different sensitivity analysis methods through the normalization and 6 aggregation process. 7where , is the value of a sensitivity analysis method, is a parameter, is the total number of 8 the parameters, is a sensitivity method, is the total number of sensitivity methods, is the target 9 output, and is the total number of target outputs. 10As the footstone of all Bayesian statistics, Bayes' theorem was first proposed by Reverend Thomas 12 Bayes in his doctoral dissertation 43 and can be described as: 13The probability of an event is inferred based on the prior knowledge of conditions related to the 14 event. Bayesian inference is one application of Bayes' theorem and can be written as: 15In this study, the Coefficient of Variance of Root Mean Squared Error (CVRMSE) (Eq. 15) and 3Normalized Mean Bais Error (NMBE) were used as indicators to estimate the calibration and 4 validation performance. 5where ̂ is a predicted variable value for period , is an observed value for period , ̅ is the 6 mean of the observed value, and is the sample size. 7In this section, the sensitivity analysis finds the dominant parameters for the calculation of CO2 4 concentrations. Then we use the Bayesian MCMC calibration to estimate the daily average 5 ventilation rate using the CO2 measurement data and occupancy patterns. With the calibrated 6 model, we calculate the CO2 concentrations in the three rooms under different ventilation rates. 7Outdoor/indoor pressure, outdoor/indoor air temperature, occupancy number, room volume, 4 outdoor air ventilation rate, and CO2 exhale rate are input parameters to predict CO2 concentration. 5For the sensitivity analysis, the range of selected model inputs/parameters were defined according 6 to the references, codes, and standards available. Table 2 shows the parameters with their 7 sensitivity importance rankings: a smaller number indicates a more important/sensitive parameter. 8 The calibrated ventilation rates in all three classrooms are all less than 2 ACH. The recommended 3 ventilation rate for a safe indoor environment by Harvard-CU Boulder Portable Air Cleaner 4Calculator for Schools is at least 5 ACH. Therefore, the ventilation rate of all three classrooms 5 seems inadequate. To relate the CO2 levels, e.g., measured from a CO2 sensor, and the ventilation 6 rates, by using the calibrated CO2 model, we calculate the outdoor air ventilation rate in ACH and 7 CFM/person as a function of CO2 levels at different exposure times in Figure 5 . It helps teachers 8 find the room ventilation rate directly based on the CO2 sensors at different school hours. For 9 example, for Room 1, when CO2 > 600 ppm, OA (outdoor air) < 5 ACH (24 CFM/person); CO2 > 10 800 ppm, OA < 2 ACH (9 CFM/person) at any time of the day. A CO2 level less than 480 ppm 11 indicates a ventilation rate greater than 10 ACH (48 CFM/person) at all times. For Room 2, the 12 same CO2 levels correspond to a lower ventilation rate than Room 1. For example, when CO2 > 13 600 ppm, OA < 2 ACH (13 CFM/person); CO2 < 440 ppm indicates that OA > 10 ACH (66 14 CFM/person). This shows that Room 1 shows a higher ventilation rate (ACH) for the same CO2 15 level because of its smaller size. The ventilation rate of Room 3 at a specific CO2 level is higher 16 than Room 2 because of its constant occupancy compared to the variable occupancy of Room 2. It 17 seems lunch breaks indeed lower CO2 levels significantly (thus infectious risk in schools). For 18 Room 3, CO2 > 600 ppm indicates OA < 3 ACH (22 CFM/person). These results show that the 19 indoor CO2 could vary significantly in different classrooms even with the same ventilation rate 20 because of different room sizes, occupants number, and occupancy schedule. All three classrooms 21show that an indoor CO2 lower than 450 ppm indicates a ventilation rate greater than 10 ACH, 22To study CO2 and airborne aerosol infectious risk relation, we first calculate the probability of 3 infection risk with the posterior distribution of the ventilation rate obtained in Section 4.3. Note, 4It also shows that after three hours, PIcond of Room 1 is always smaller than two other rooms due 4 to a higher ventilation rate. More frequent leaves of students (three breaks in a day) also contribute: 5 the quanta level is generally lower than the two other rooms. PIcond of Room 3 continues to rise 6 with the exposure time, unlike other classrooms, again due to the constant occupancy assumed. 7 Therefore, to reduce infection risk, more frequent breaks and leaves could be beneficial when 8increasing the classroom's ventilation rate is relatively harder to achieve. 9The conditional PI is the ratio of the number of infections to susceptibles = ⁄ . The 10 reproductive number (R0), defined by Rudnick and Milton (2003), is the number of secondary 11infections when a single infected person is introduced in the room, and everyone in the room is 12 susceptible. If R0 < 1, then the infectious agent cannot spread in the population. For these three 13 classrooms if is smaller than 5.3%, 5%, and 5.5%, it is expected that the community spread 14 in the classrooms could be stopped. Figure 6 shows that, for Rooms 1, 2, and 3, the conditional PI 15 exceeds the level of R0 = 1 at around two ~ three hours, after which mitigation measures should 16 be taken. 17The ventilation rate threshold to prevent the spread (R0<1) at all exposure times is 8, 3, and 6 ACH 5 for Rooms 1, 2, and 3, respectively. Room 1 requires a higher ventilation rate because of the 6 smaller room size. Room 2 needs a lower ventilation rate than Room 3 because students left the 7 classroom several times. Therefore, the ventilation rate threshold depends on the occupancy 8 schedule and the size of the room. 9Figures 8b and 8c illustrate that the ventilation rate threshold (to prevent the spreading) increases 9 with exposure time and is not a constant number because of the three rooms' different sizes and 10 schedules. 11In summary, the results of all three classrooms show that the ventilation rate threshold to prevent 3 the airborne transmission of COVID-19 depends on several parameters such as room size, student 4 schedules, and exposure time. The indoor CO2 threshold seems to depend on exposure time mostly, 5 and the time-averaged level of 500 ppm seems acceptable for all three classrooms. 6The airborne transmission of COVID-19 is a major infection route in indoor spaces, especially 8 with poor ventilation conditions, large occupancy density, and high exposure time, such as school 9This study also proposed the approach to calculating the probability of the infection risk based on 3 the calibrated ventilation rate, which helps quantify the uncertainty of outdoor ventilation rates. 4Moreover, this study estimated the required ventilation rate threshold and the CO2 threshold values 5 to prevent the airborne aerosol spreading of COVID-19 as a function of exposure time in the 6 classrooms. The ventilation threshold at all hours is 8, 3, and 6 ACH for rooms 1, 2, and 3, 7 respectively, and the CO2 threshold is around 500 ppm at all exposure times (< 8 hr) of a school 8 day for all three classrooms. This threshold is significantly different from the recommended value 9 of 1000 ppm for acceptable indoor air quality conditions. Therefore, it is recommended that the 10 ventilation rate and indoor CO2 concentration thresholds be reconsidered in indoor spaces, 11 especially classrooms, in the current pandemic. ",Canada,first author,2021-02-03,02
3774fa36b60fce1eb55e8942e2f5b4ecca0f5d96,Clini-cal Update in Liver Transplantation,"Liver transplantation (LT) continues to be the mainstay of treatment for end-stage liver disease (ESLD).This review article aims to provide an update from the literature on relevant topics for anesthesiologists caring for LT patients. COVID-19 challenged all healthcare providers this past year and anesthesiologists managing LT patients were no exception. As the role of anesthesiologists expands into perioperative management, management of anticoagulation medications may require intervention. Pain management for LT patients has implications intraoperatively as well as postoperatively. Perioperative glucose management presents a unique challenge in LT patients and appropriate management can have effects following LT as well.Near the end of December 2019, people began to develop clinical characteristics of a viral pneumonia in Wuhan, China, which was quickly determined to be a novel coronavirus. This novel coronavirus would become known as severe acute respiratory syndrome coronavirus (SARS-CoV-2) and the rampant disease it spread to be known as coronavirus disease 2019 (COVID-19). 1 In just over two months from the initial case report, on December 12, 2019, the World Health Organization (WHO) would release a situation report on February 29, 2020, indicating 79,394 confirmed cases of SARS-CoV-2 and 2838 deaths had occurred. 2 Of these cases, 6009 had been confirmed in 53 countries outside of China.Error! Bookmark not defined. It was clear at this time that COVID-19 posed a significant threat to global public health. 3 SARS-CoV-2 is a ß-coronavirus meaning it is a single, positive-stranded RNA virus. 4 On the surface of the virus is an S-glycoprotein which binds to the human cellular receptor angiotensin-converting enzyme 2 (ACE2) and internalizes the virus. 5 ACE2 is most commonly found in the lower respiratory tract and can also be found in biliary and liver epithelial cells making the liver a potential target for infection.Error! Bookmark not defined. ,6 Elevated serum biochemistries, mainly aspartate aminotransferase (AST) and alanine aminotransferase (ALT), can become elevated in severe cases of COVID-19.Error! Bookmark not defined. Due to these findings, patients with nonalcoholic fatty liver disease (NAFLD), cirrhosis, and posttransplant patients were considered to be at an increased risk for severe COVID-19.Error! Bookmark not defined. ,7 In order to avert severe consequences on the transplant community, organizations involved in liver transplantation released recommendations and guidance for liver transplant programs and clinicians moving forward during the COVID-19 pandemic. 8 As early as February 27 th , the Infectious Diseases and Liver Transplantation Special Interest Group (SIG) of the International Liver Transplant Society (ILTS) released a statement saying risk of virus transmission from a donor is low, but present, as SARS-CoV-2 RNA had been identified in the plasma of infected patients. 9 At that time, without rapid testing readily available, it was recommended to avoid deceased and living organs retrieved from a donor in a high prevalence area.Error! Bookmark not defined. As for candidates, it was recommended to avoid transplanting a patient with developing or active respiratory symptoms as well as waiting 14 days if candidate travelled through a high prevalence area.Error! Bookmark not defined. In late March, the American Society of Transplant Surgeons (ASTS) released initial guidance from their COVID-19 Strike Force. At the forefront was inclusion of social distancing, hand sanitization, and respiratory precautions to be incorporated in all transplant protocols. 10 Another drastically important piece of this guidance was each program needed to assess program specific riskbenefit analyses on a case-by-case basis.Error! Bookmark not defined. This was due to the significant variance of infection rates throughout the United States at that time. Recommendations were to continue lifesaving and life altering transplants and for living donations to be placed on hold assuming the recipient could wait.Error! Bookmark not defined. As for deceased donors, testing them for COVID-19 needed to be a high priority and ""prudence suggests that organs from positive donors not be accepted.""Error! Bookmark not defined. Once hospitalized, it was important to prevent person-toperson transmission, in particular in the operating room and intensive care unit (ICU). Anesthesiologists and intensivists are at a very high risk to exposure due to performing aerosol generating proceduresError! Bookmark not defined., therefore they recommended transplant staff need proper training of protective gear including N95 masks.Error! Bookmark not defined.As the pandemic progressed, the American Association for the Study of Liver Disease (AASLD) released their expert panel consensus statement. Of special interest was the section regarding patients with decompensated cirrhosis and patients on the liver transplant waiting list. They encouraged transplant centers to continually analyze the burden of COVID-19 locally and how this would affect patients waiting for a liver transplant.Error! Bookmark not defined. At that time, it was expected to see a reduction in organ recovery based on institutional resource limitation, making risk stratification even more important than normal.Error! Bookmark not defined. Many hospitals were instituting the Center for Medicare and Medicaid Services (CMS) recommendations on limiting nonessential surgeries in order to conserve resources. Transplant surgery was excluded from this and categorized as Tier 3b which means ""do not postpone.""Error! Bookmark not defined. Finally, the experts discussed specifically SARS-CoV-2 in donors and recipients. Stating donors who test positive are medically ineligible for donation and recommend not performing transplants in positive recipients.Error! Bookmark not defined. All of this information was shown in a flow chart for a quick reference guide to decision making which is seen in Figure 1 . The potential decline in transplantation warranted clinicians in the community to consider using organs from COVID-19 positive donors in order to maximize all possible deceased donor organs. 14 The argument being patients with a significantly high MELD score, 40 or more, may have a better clinical outcome if they received an organ from a SARS-CoV-2 positive donor due to a high likelihood of death without transplantation.Error! Bookmark not defined. Utilization of livers from SARS-CoV-2 positive donors was felt to be dangerous by most others due to hepatocellular injury of patients with COVID-19, possible direct viral infection of the liver, and first-pass absorption through the gut. 15 A literature review showed no known SARS-CoV-2 donors were used for liver transplantation in the United States. There have been multiple case reports of SARS-CoV-2 positive recipients receiving liver transplants after resolution of symptoms or negative tests with good outcomes. 16, 17, 18, 19 A more comprehensive analysis was performed later in the pandemic to better understand the impact of COVID-19 on liver transplantation in the United States. 20 This study used the Scientific Registry of Transplant Recipients to compare waitlist registrations, waitlist mortality, and DDLTs from March to August of 2020 on expected values based on trends from January of 2016 to January of 2020. They also investigated local COVID-19 incidence at the state-level and center-level to provide further insight on COVID-19's impact. In states with the highest COVID-19 incidence from March 15 th to April 30 th , there were 33% fewer new listings, 59% more waitlist deaths, and 34% fewer DDLTs than expected. Error! Bookmark not defined. However, states with lowest COVID-19 incidence during this time frame had no change in new listings or DDLTs. Error! Bookmark not defined. Using the guidelines and recommendations by multiple national societies, August waitlist outcomes were occurring at the rates seen in previous years, and DDLTs were actually occurring 13% more frequently across all states. Error! Bookmark not defined. In a matter of months, the transplant community had adjusted focus on the pandemic, institute changes to improve patient care, and nearly normalized liver transplantation practice throughout the US.hospitalization altered the ability to safely care for critical ill COVID-19 patients in addition to post-LT patients. Yet some centers, including our institution, saw an increase in transplants this past year for reasons that are not clear to the authors. Recognition should be given to the various organizations and societies as their recommendations aided in the continuation of transplants during this time and inevitably saved numerous lives via liver transplantation. As the pandemic continues to progress, so does our knowledge of the disease and the best way to handle it. Research related to the full impact of COVID-19 on liver transplantation will be of interest in the years to come.Hemostasis in patients with liver disease is a delicate balance as these patients exhibit both hyper-and hypo-coagulable properties. 21, 22 Previously cirrhotic patients were thought to be 'auto-anticoagulated' due to their decreased production of clotting factors, elevated INR, thrombocytopenia, and platelet dysfunction. 23 Clinically significant bleeding continues to be the prevailing concern though excessive clot formation has also been recognized as an important issue in these patients. 24 Atrial fibrillation (AF) the most common cardiac arrhythmia and increases with age. Additionally, the risk of venous thromboembolism (VTE) and portal vein thrombosis (PVT) contribute to morbidity in older patients. As older patients are listed for LT, these comorbidities are seen more commonly. 25, 26 A meta-analysis by Ambrosino et al suggests that cirrhotic patients demonstrate a 1.7-fold increased risk for VTE and noted a higher prevalence in males. They suggested cirrhosis was an independent risk factor for VTE. 27 Additionally, Lee et al denoted a 1.5-fold increase in AF in the cirrhotic patient population. 28 Currently, there are no specific consensus guidelines for the treatment and prevention of VTE in patients with advanced liver disease. 29 Traditionally, patients with advanced liver disease were treated with vitamin-K antagonists (VKA) or low molecular weight heparin (LMWH) due to low costs, physician experience with these medications and reversibility. 30, 31, 32 Nonetheless, VKAs and LMWH have not become a mainstay of prevention due to altered pharmacokinetics and pharmacodynamics, decreased plasma levels of Proteins C and S further augmenting pharmacologic efficacy, dietary restrictions with warfarin, as well as the implicit difficulty in monitoring VKA effectiveness in patients with an abnormal INR. 33 Direct Oral Anti-Coagulants (DOACs) are recommended over Vitamin K Antagonists (VKAs) when appropriate as the current treatment modality for both VTE and AF in the general population. 34, 35 These medications have not been extensively studied in patients with advanced liver disease, as Child-Turcotte-Pugh C (CTP-C) patients were initially excluded from Phase III trials. Error! Bookmark not defined., 36 Advantages of DOACs include oral administration (as compared to LMWH), similar efficacy, predictable mechanism of action independent of antithrombin levels, standard dosing schedules, and no required monitoring. 37 A meta-analysis of 152,116 patients from phase III RCTs for DOACs demonstrated that DOACs were not associated with increased risk of drug-induced liver injury in the general population. 38 Another study in 2017 assessed over 113,717 patients with nonvalvular AF and found that DOACs were associated with lower rates of hepatic injury hospitalization as compared to VKAs (warfarin). Dabigatran demonstrated the lowest risk for hepatic injury among this population. Error! Bookmark not defined., 39 Neither of these metaanalyses included patients with advanced liver disease, although based upon more recent retrospective findings pharmacologic effects may potentially be extrapolated to the cirrhotic population. A 2013 randomized double-blinded, double-dummy trial comparing the DOAC edoxaban with warfarin in AF patients with the primary efficacy end point of stroke or systemic thrombus and a primary safety endpoint of major bleeding. 40 Within this study, 1083 of 21,105 patients enrolled (5.1%) had a history of mild liver disease. Patients with liver disease had a known increased risk of bleeding however there was no difference in the efficacy or safety of edoxaban when compared to warfarin in patients in this subgroup. Additionally, there were no significant differences in liver related adverse events. 41 Patients with advanced liver disease were primarily excluded from RCTs due to potential risk of bleeding, but emerging retrospective research has demonstrated that DOACs have comparable or lower rates of bleeding in cirrhotic patients when directly compared to standard therapies. Error! Bookmark not defined.A number of systematic reviews and meta-analyses have proposed similar safety and efficacy profiles. A retrospective cohort study demonstrated that DOACs were safer and more effective than warfarin in AF patients with liver disease. 45 DOACs were associated with lower risk of ischemic stroke, intracranial hemorrhage, gastrointestinal bleeding, major bleeding events and all cause deaths. These results were consistent across the sub-group of participants that were noted to have significant active liver disease. Error! Bookmark not defined. Several meta-analyses of retrospective studies have demonstrated comparable safety and efficacy profiles between DOACs and VKAs but there is difficulty applying this data to patients with severe or end-stage liver disease. Error! Bookmark not defined. Though the retrospective data is promising, there remains a lack of prospective studies. 46, 47 PVT is recognized problem for patients awaiting or receiving liver transplantation, occurring in up to 20% of patients with cirrhosis. Error! Bookmark not defined. Both meta-analysis and retrospective studies have demonstrated safety and efficacy of LMWH and VKA treatment for PVT. 48 groups treated with LMWH, VKA or DOACs. Uniquely, this study used meta-regression analysis to assess effect based upon the patient's CTP classification and found the severity of disease did not appear to influence outcomes. 50 The role of DOACs in patients with liver disease has not been discretely defined but recent literature supports their use as an effective and safe treatment in this patient population.Post-liver transplant complications from thromboembolic events can negatively affect patient and organ outcomes. 51 Thrombotic events occur in 2-11% of patients following liver transplantation. 52 A small retrospective study associated DOACs with less bleeding risk when postoperative transplant patients were matched to warfarin treated controls. 53 While anticoagulation selection should continue to depend on specific patient factors including renal function, drug-drug interactions and insurance coverage, DOACs appear to be safe for use in cirrhotic patients before and after transplantation.A national survey of organ transplant programs in 2019 suggests DOACs are being prescribed with the perception that they pose a similar bleeding risk to traditional VTE anticoagulation. Apixiban was the anticoagulation most commonly prescribed for patients on the transplant waitlist. DOAC reversal agent use prior to transplant was noted to be uncommon, primarily occurring before thoracic organ transplant. 54 As illustrated by Vuilleumier, management of DOAC-related bleeding during liver transplant may be burdensome, but reversal agents for DOACs as noted in Table 1 may prove to be truly valuable tools. 55 Guidelines published in the American Journal of Hematology (2019), recommend that Prothrombin Complex Concentrates (PCC) be used for treatment of life-threatening bleeding when reversal agents are unavailable. 56 Pain Management in LT Pain can be a divisive issue in liver transplant patients. One can argue that LT is among the most extensive abdominal operations in terms of duration and stress for the patient with the large abdominal incision and the use of multiple retractors, which contribute to postoperative pain. 57 Despite these factors, postoperative pain following liver transplantation has been shown to be not as severe as compared to open cholecystectomy or hepatic resection. 58, 59 While the administration of opioids intraoperatively and postoperatively has long been considered a viable option, the opioid epidemic has forced clinicians to revisit their approach to perioperative pain management. The new approach to a comprehensive analgesic plan should seek to improve respiratory function, aid in early mobilization and accelerate postoperative recovery with limited opioid consumption.In the context of this epidemic, combined with the prevalence of substance use disorders among liver transplant recipients, more thought should be given to the implementation of multimodal pain management regimens in an effort to reduce perioperative opioid use after liver transplantation. 60 In fact, multimodal analgesic approaches have resulted in reduced opioid utilization in liver transplant recipient populations. Error! Bookmark not defined. What non-opioid agents can a provider use in LT patients can be a challenge. A recent review of multimodal analgesics for LT patients provides an evidence-based approach to pain management. The authors recommendations are listed in Table 2 . While most therapies are familiar to anesthesiologists, the evidence remains limited on their utility in LT patients. 61 Even with limited data, Kutzler et al. sought to investigate the development of a comprehensive multidisciplinary opioid avoidance pathway (OAP) for LT recipients at their institution. 62 The OAP was developed by a multidisciplinary team of health care specialists and offered to all liver transplant recipients regardless of substance use history. Table 3 illustrates the general pathway for patients from pre-transplant to their post-transplant care. Ultimately, they found this pathway reduced morphine milligram equivalents by 92% per post-operative day with no difference in length of stay compared to historical cohorts. Error! Bookmark not defined. This difference was most pronounced in the first five days postoperatively. Of note, two patients in the OAP group use zero opioids during their admission. Their approach was able to provide an analgesic regimen that effectively reduced inpatient and outpatient opioid utilization.Opioid-sparing techniques are used in many surgeries and can play a critical role in pain management for LT patients as opioids may have negative consequences in ELSD due to alterations of liver function and drug pharmacokinetics. The majority of opioid metabolism is liver dependent and the extent of liver disease can have a significant impact on this metabolism. Furthermore, hypoalbuminemia, common in LT patients, causes free drug concentration to increase, resulting in enhanced distribution and higher concentration of drug at the site of action. 63 End-stage liver disease patients may also exhibit an increased density and affinity of central mu-opioid receptors in the brain contributing to the increased sensitivity to opiate agonists in such populations. 64 In addition, opioids may precipitate or aggravate hepatic encephalopathy. Error! Bookmark not defined.Commonly used opioids in LT, fentanyl and sufentanil, are extensively metabolized by the liver. 65 Fentanyl, a synthetic opioid analgesic, has a high hepatic extraction ratio and is highly protein bound; largely to albumin. 66 Clearance of fentanyl is determined by hepatic blood flow and high hepatic extraction of fentanyl and anesthesiologists should be cognizant that an abrupt increase in plasma fentanyl concentration is observed during the anhepatic phase. Furthermore, an opposite abrupt decrease in the plasma fentanyl concentration is observed during the neohepatic phase. Error! Bookmark not defined. Redistribution is largely responsible for the duration of action of fentanyl after single bolus doses while hepatic elimination is more responsible for the duration of action with continuous infusions of fentanyl. Continuous infusions should be used with great caution so as not to result in over sedation or prolonged postoperative mechanical ventilation. Because fentanyl is largely devoid of histaminereleasing properties, it may be preferred in the setting of hemodynamic instability. Error! Bookmark not defined.Sufentanil has high hepatic extraction as well as relevant extrahepatic elimination. 67 A minimal increase in sufentanil drug concentration during the anhepatic phase is suspected. Despite sufentanil relying on partial extrahepatic metabolism, its use in end stage liver disease patients still requires close attention as its analgesic potency is higher than fentanyl with more immediate respiratory depression and bradycardia. It has been reported that sufentanil produces shorter lasting respiratory depression and longer lasting analgesia when compared to fentanyl. 68 Hypotension is a well described effect seen with sufentanil and appears to be dose dependent and impacted by the degree of volume depletion; the latter being a critical consideration in the setting of liver transplantation.In addition to the considerations of acute pain in liver transplant patients, the impact of chronic pain among liver transplant patients is not well studied. Madan, et al. highlighted the common occurrence of chronic pain among liver transplant candidates and its relative undertreatment. 69 Opioid prescribing has increased significantly and excessive opioid prescribing is prevalent, particularly after surgical care. 70 Liver transplant patients represent a population vulnerable to opioid exposure given the prevalence of substance use disorders and the associated risk of opioid misuse. 71 Indeed, a recent review of opioid use while on the transplant waiting list and following transplant revealed concerning trends. Higher opioid use while on the waiting list was associated with higher mortality and graft failure rates than did nonopioid users. 72 Interestingly, the use of opioids had no effect within the first year following LT. Recently the use of opioids while on the waiting list was shown to increase the risk for development of chronic post-surgical pain. 73 In the study of LT patients found 18.9% were on opioids prior to LT and those patients had higher opioid consumption at 24 hours and 7 days. Furthermore, the development of chronic post-surgical pain was more common in the opioid group.Pain management for LT patients requires thoughtful preparation and planning and anesthesiologists are well-suited to help in this process. Early identification of patients on opioids at listing allows for consideration to opioid-weaning prior to transplantation. 74 Use of multi-modal analgesia medications dosed to account for end-organ dysfunction associated with ESLD is essential. Utilization of regional anesthesia should also be considered in LT patients as an opioid-sparing option. Anesthesiologists should continue to lead future research into which therapies are most beneficial for LT patients.Hyperglycemia in the perioperative period commonly occurs as a result of critical illness, surgical stress, and medications administered. There remain deleterious effects of hyperglycemia in surgical patients that include but are not limited to: increased mortality, increased wound infection rates, and risk factors for postoperative pneumonia and acute kidney injury. 75, 76, 77 Management of blood glucose in LT can be challenging given the significant surgical stress and delivery of large doses of steroids. What effects hyperglycemia has on long-term outcomes remains unclear with new evidence published recently.Additionally, the development of diabetes mellitus (DM) following transplant is uncommon and anesthesiologists should be aware of the effect this has on cardiovascular function and overall survival.Early research into glycemic control in LT has been ongoing for years albeit retrospectively. Building on intensive care data on blood glucose (BG) control 78 , Ammori, et al reviewed 184 patients who underwent LT to compare outcomes compared to mean BG levels. 79 They found a lower rate of infections in the first 30 days for the tighter BG group (mean BG < 150 mg/dL) and improved survival at 1year and 2 years. In 2010, Wallia, et al retrospectively reviewed 113 LT and 31 liver-kidney patients to examine the role of BG control on LT outcomes. 80 They found rejection to be more common if patient's mean BG during the hospitalization was > 200 mg/dL than if their mean BG was < 200 mg/dL. Interestingly enough, the incidence of prolonged ventilation was higher in the lower BG arm for reasons that were not clear to the authors.Recently a prospective, randomized control trial examined glucose control for LT patients at a single institution comparing strict BG control versus conventional BG control. 81 Strict BG control was defined as 80-120 mg/dL as opposed to conventional control defined as BG of 180-200 mg/dL. The primary outcomes measured were patient and graft survival at one year. At one-year, overall survival was not statistically different (88% vs. 88%, p = 0.999) and in fact, there was no difference at 3 years (86% vs. 84%, p = 0.999) or 5 years (82% vs. 78%, p = 0.617). Rates of complications (bile leak, bile stricture, CVA, major cardiac event, re-operation, and wound dehiscence) were similar between both groups. Clinically, the strict control group required more insulin (24.4 units on average) compared to the conventical group (10.0 units). Hypoglycemic events (defined as BG < 70 g/dL) were more common in the strict group but not statistically significant.Post-operative acute kidney injury (AKI) is common in LT patients, affecting 17% to 95% of patients. 82 The effect of BG on AKI is not well understood for LT patients though. Yoo et al. utilized time-weighted average glucose levels to evaluate if poor glucose control was associated with AKI. Their retrospective study grouped patients into four categories based on glucose levels as well as different quartiles based on the variability of BG levels through 48 hours. Post-operative AKI occurred in 43.1% of patients overall. Error! Bookmark not defined. Patients in the third and fourth quartiles for BG control were at higher risk for AKI. The authors suggest that glucose variability rather than hyperglycemia alone may be a risk factor for post-operative AKI though further prospective studies may be helpful.Development of post-transplant diabetes mellitus (PTDM) occurs in 12-45% of patients who undergo LT. 83 With an increasing number of patients are receiving LT for non-alcoholic fatty liver disease (NAFLD) the effects of PTDM in patients in these patients are not well understood. A review of 415 patients focused on graft steatosis, rejection, and patient survival as it relates to PTDM. Rates of PTDM were 34.7%, 46.9%, and 56.2% at 1, 3, and 5 years respectively. 84 Notably, half the cases of PTDM developed by 6 months with 75% by 12 months indicating a rapid onset following transplant. Rejection was higher in the PTDM group (31.9%) than in the non-PTDM group (21.8%).Error! Bookmark not defined.Indeed, these findings are consistent with early findings that PTDM following LT showed worse patient and graft survival. 85 In addition to the development of DM following LT, presenting for LT with pre-existing DM carries risk.Long-term follow of LT patients with a median of 14 years found that pre-transplant DM independently predicted atherosclerotic vascular events (AVE). 87 Defining AVE as specific conditions with evidence of atherosclerotic disease were as follows: myocardial infarction, angina, transient ischemic attack, stroke, and intermittent claudication. The authors also noted that pre-transplant DM doubled their risk for AVE.As discussed in this paper, identifying patients with DM may help further risk stratify them before transplantation.Even patients without DM are at risk for hyperglycemia following LT given the surgical stress and administration of medications such as methylprednisolone and calcineurin inhibitors. With the risks of hyperglycemia on outcomes and the risk of development of DM post-transplant, intervention may prevent long-term complications. In this single center trial, patients were assigned to different glucose control regimens (< 140 mg/dL vs. < 180 mg/dL). Post-operative glucose readings were followed and noted when > 200 mg/dL. Based on their findings, four factors were noted that predicted early hyperglycemia following LT. They were shorter length of stay, use of glucose-lowering medications at discharge, donor female gender, and donor white race. 88 While limited by a single center's data, this study may prove useful in identifying patients at risk for post-operative hyperglycemia and DM.Previous retrospective data on peri-operative hyperglycemia indicated risks to patient and graft survival.However, more recent data suggests that tight glucose control may not be as essential as previously thought. That said, we know the development of PTDM and metabolic syndrome following LT is common and may predispose patients to cardiovascular events. 89 With NAFLD continuing to increase as an indication for LT, more may need to be done to identify how best to manage perioperative glucose levels. Further studies are needed to evaluate the effects perioperative glucose management on outcomes and what, if any, interventions can improve both short and long-term outcomes.Liver transplant anesthesiologists manage complex patients before, during, and after a complex procedure. The unique challenges of ESLD patients extend to multiple organ systems and require vigilance to manage. The COVID-19 pandemic presented new challenges to providers this year not only to protect their patients but to protect themselves. While managing limited resources early in the pandemic the concern of limiting life-saving transplants was a real concern. However, useful guidance from national transplant organizations proved invaluable in navigating the new normal of COVID-19.The use of DOAC's may provide patients with a better side effect profile for patients at risk for forming new clots or treating existing colt burden. Understanding how to manage these medications and recognizing the role of reversal agents play as well as the risk of bleeding is critical for transplant anesthesiologists. Opioids have long been the mainstay of pain management for surgery, including LT patients. Their use is not without challenges as long-term use may lead to worse clinical outcomes.Multi-modal analgesia seeks to limit opioid use by employing many non-opioid medications but they may have limitations in ESLD. Finally, the consequences of hyperglycemia during LT may trivial, especially compared to the long-term of effects of diabetes mellitus following transplant.",United States,first author,2021-02-06,02
3ce167306e29b90f6183a8cc2dfa9347377742c1,-NC-ND license Susceptibility-weighted imaging reveals cerebral microvascular injury in severe COVID-19,"Hundreds of thousands of people worldwide have survived severe coronavirus disease 2019 (COVID- 19) since the beginning of the pandemic in December 2019 [1] . For survivors, recovery of brain function may lag behind that of other organs [2, 3] . Hypercoagulability, inflammation, hypoxia, and endothelial cell infection by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) are potential mechanisms contributing to global brain dysfunction [4] . Although brain imaging studies in patients with neurological manifestations of severe COVID-19 are rapidly emerging [5] [6] [7] [8] [9] [10] [11] [12] [13] [14] , performing and interpreting MRI in this critically ill population remains challenging, and fundamental questions about the pathogenesis of brain injury in these patients remain.We investigated the imaging characteristics of COVID-19 brain injury by performing ultrafast high-resolution susceptibility-weighted imaging (SWI) MRI [15] on a clinical MRI scanner located in our Neurosciences Intensive Care Unit (ICU). We focused on SWI because emerging evidence suggests that COVID-19 patients are at risk for microvascular lesions [8] [9] [10] 16] , and the SWI sequence provides optimal sensitivity for detecting microvascular lesions based upon their paramagnetic susceptibility effects in an MRI scanner's magnetic field [15] . In a cohort of 16 consecutively imaged critically ill patients with COVID-19, we tested the hypothesis that COVID-19 is associated with cerebral microvascular injury detectable by SWI. In one patient who underwent autopsy, we performed correlative radiologic-pathologic analyses and cerebrospinal fluid (CSF) SARS-CoV-2 polymerase chain reaction (PCR) to explore the mechanisms of COVID-19 cerebral microvascular injury.Chart review identified all patients at our hospital who met the following inclusion criteria: (1) MRI performed on our Neurosciences ICU scanner between March 12 and May 14, 2020; (2) confirmed COVID-19 diagnosis by reverse transcriptase (RT)-PCR nasopharyngeal swab; and (3) severe COVID-19, as recently defined [17] . Specifically, severe Covid-19 is defined as dyspnea, a respiratory rate of 30 or more breaths per minute, a blood oxygen saturation of 93% or less, a ratio of the partial pressure of arterial oxygen to the fraction of inspired oxygen (PaO2:FiO2) of less than 300 mmHg, or infiltrates in more than 50% of the lung field within 24 to 48 h from the onset of symptoms. There were no exclusion criteria. Clinical characteristics and laboratory data were collected for all patients. This retrospective study was HIPAA compliant and was approved by the institutional review board with a waiver of consent.All patients underwent brain imaging on a 3 Tesla Skyra MRI scanner (Siemens Healthcare) using an ultrafast 3D SWI sequence [15] with the following parameters: TE/TR = 21.5/40 ms, voxel dimensions = 0.9 × 0.9 × 1.8 mm 3 , Wave-CAIPI acceleration R = 6, total scan time 100 s. Conventional T1, T2, fluid-attenuated inversion recovery (FLAIR), and diffusion-weighted images (DWI) were also obtained. Two boardcertified neuroradiologists (J.C., S.Y.H.) independently reviewed the SWI data. Foci of abnormal susceptibility signal were counted using an abbreviated version of the Microbleed Anatomical Rating Scale [18] . The raters counted up to 10 lesions per anatomical location, after which they recorded ""greater than 10"". We resolved discrepancies between the radiologist ratings by consensus.An autopsy was performed for Patient 1, who died on hospital day 16. Routine microscopic analysis of the cerebral and cerebellar gray matter and white matter was performed after approximately two weeks of fixation in buffered formalin and standard paraffin embedding with Luxol and hematoxylin-and-eosin (LH&E) staining. Immunohistochemical staining was performed with a Leica Bond III automated stainer, with mouse monoclonal antibodies directed against neurofilament (Dako M0762, 1:3200), CD3 (Leica PA0553, used as supplied), CD163 (Leica Cat #PA 0090, used as supplied) and CD68 (Biocare Cat # IP-033-AA, also used as supplied).For the Patient 1, extracted RNA was tested for the presence of SARS-CoV-2 using a probe-based quantitative RT-qPCR assay (see Supplementary Material for details). The RNA extraction from CSF was performed under a research protocol with IRB approval and waiver of patient consent. The CSF sample was obtained during a lumber puncture that was performed as part of the patient's clinical care.Clinical and laboratory variables were compared between (1) patients with >10 SWI hypointense lesions, and (2) patients with <10 SWI hypointense lesions, using an unpaired t-test for normally distributed variables and Mann-Whitney U test for variables that were not normally distributed. P-values less than 0.05 were considered significant.A total of 154 patients underwent brain MRI on our Neurosciences ICU scanner during the study period. Twenty-one patients tested positive for COVID-19 prior to the time of brain MRI, and 16 met clinical criteria for severe COVID-19 and were included in the study (Supplementary Table 1 ). All 16 study patients had acute respiratory distress syndrome (ARDS) and were mechanically ventilated at the time of MRI. MRI was performed because of unresponsiveness in 11 cases, and focal neurologic deficits in five cases. Punctate foci of abnormal susceptibility signal were identified in 11/16 cases (69%), and 8/16 (50%) had >10 lesions (Fig. 1, Supplementary Table 2 ).In 4/16 cases (25%), multiple clustered lesions involved the corpus callosum. In the remaining 4/16 cases with >10 lesions, the lesions showed a predilection for subcortical and deep white matter, with variable involvement of the brainstem and cerebellum. Additional MRI findings are summarized in Supplementary Table 3 .Patient 1 was a 57-year-old man with a history of asthma, obesity, and hyperlipidemia who tested positive for SARS CoV-2 by nasopharyngeal RT-PCR swab. His only COVID-19 related symptom on admission was shortness of breath, and he walked into the urgent care clinic. His hospital course was notable for hypoxic respiratory failure requiring mechanical ventilation and pupillary dilatation during weaning of sedation on hospital day 13. Head CT showed diffuse white matter hypoattenuation with preservation of gray-white matter differentiation and no downward herniation. Lumbar puncture was performed on day 14, and CSF analysis showed normal white blood cell count (1 cell/ul) and elevated total protein (181 mg/dL). RT-qPCR for the SARS-CoV-2 nucleocapsid protein targets (N1 and N2) performed on CSF was negative.Brain MRI on day 15 revealed numerous SWI hypointense foci (Fig. 1, left column) , predominantly involving the subcortical and deep white matter, e.g., corpus callosum, internal capsules, and cerebellar white matter, as well as diffuse DWI and T2/FLAIR hyperintensity throughout the white matter. Life-sustaining therapy was withdrawn on hospital day 16, and he died shortly thereafter (see Supplementary Material for clinical details).At autopsy, gross pathology revealed a diffusely edematous brain weighing 1410 g (within normal range), with uncal and tonsillar herniation and diffuse discoloration of the gray-white matter junction. Numerous punctate hemorrhages were observed at the cortical graywhite matter junction and in the deep white matter.Radiologic-pathologic correlations of the microvascular lesions are shown in Fig. 2 . Focused evaluation of the microvascular lesions showed microscopic foci of extravasated red blood cells associated with apparently necrotic blood vessels and foci of ischemic injury. The latter demonstrated significant loss, but not absence, of both axons and myelin, with occasional scattered axonal spheroids within the lesions and an associated macrophage/microglial response without other significant inflammatory cell components (Fig. 3) . Associated with the vessels nearest to the ischemic lesions, there was a moderate accumulation of microglia (CD163) and macrophages (CD68) (Fig. 3) . Detailed pathological findings are reported in the Supplementary Material.In this study of 16 critically ill patients with COVID-19 who underwent brain MRI because of persistent unresponsiveness (n = 11) or focal neurologic deficits (n = 5), we detected diffuse microvascular injury involving the subcortical and deep white matter in 69% of patients. Microvascular lesions manifested as punctate and linear hypointense foci on SWI, with a neuroanatomic predilection for the corpus callosum and the subcortical and deep white matter. There were no significant differences in clinical or laboratory variables between patients with and without SWI lesions. In one patient who died and underwent brain autopsy, the lesions showed mixed pathology: microhemorrhages and microscopic ischemic lesions. While the hemorrhagic lesions could be identified by SWI, no definitive imaging correlate to the microscopic ischemic lesions was observed, likely due to their small size relative to the spatial resolution of clinical DWI. Collectively, these findings suggest that cerebral microvascular lesions are common in severe COVID-19 patients who have neurologic deficits and that the pathogenesis of the microvascular lesions involves both hemorrhagic and ischemic etiologies.These correlative radiologic-pathologic findings add to the growing literature on the neurological effects of COVID-19 and offer insight into the mechanisms of brain injury in severe COVID-19. The neuroanatomic distribution of the microvascular lesions, particularly the callosal and capsular predominance, has been reported as a rare complication of ARDS, high altitude exposure, and extracorporeal membrane oxygenation (ECMO) -all of which are associated with cerebral hypoxia [19, 20] . Endothelial cell infection and endotheliitis have been described in extracerebral organs of patients with COVID-19 [4] , presumably mediated via the ACE2 receptor, which is also found in brain endothelial cells [21] . These findings thus suggest a potential role for hypoxic It is important to acknowledge that the presence of microvascular lesions does not necessarily imply that such lesions are directly caused by COVID-19, or that all lesions reflect an acute etiology of brain injury. A subset of the lesions could be due to pre-existing microvascular lesions for example due to amyloid angiopathy or chronic hypertension, although the observed distribution including prominent callosal involvement would be unusual for these entities. Further, the relationship between microvascular injury and other neuroimaging findings observed in these patients (e.g., large artery infarcts, other types of intracranial hemorrhage, and parenchymal restricted diffusion suggesting hypoxic-ischemic injury) remains uncertain. Future work is needed to elucidate the inter-relationships between these pathophysiologic processes.If replicated, these observations have clinical relevance at the individual patient and population levels. For individuals, detection of diffuse microvascular injury may be clinically actionable. Differentiating microhemorrhage from microthrombosis remains a diagnostic challenge because both appear hypointense on SWI. Nevertheless, identification of SWI lesions could alter the risk-benefit analysis of anticoagulation, a particularly important consideration given the hypercoagulability observed in COVID-19 patients [22] .At the population level, these imaging findings raise fundamental questions about neuroprotective strategies in COVID-19 patients undergoing mechanical ventilation for hypoxic respiratory failure. Could tracking serum-based biomarkers of bleeding, hypercoagulability, and COVID-related hyperinflammatory states or cytokine release syndrome [23] identify patients at risk for cerebral microhemorrhage and ischemia? Could COVID-19-related hypoxia contribute to the pathogenesis of microvascular injury, as suggested by reports of patients with ARDS and ""critical illness-associated cerebral microbleeds""? [19, 20] Finally, does cerebral microvascular injury contribute to the prolonged unresponsiveness being observed in survivors of severe COVID-19? [2, 3, 11] All of these questions warrant urgent, systematic investigation to optimize neurologic outcomes in patients with severe COVID-19.This study was supported by the James S. McDonnell Foundation COVID-19 Recovery of Consciousness Consortium, the NIH National Institute of Neurological Disorders and Stroke (R21NS109627, R21AG067562, RF1NS115268), the NIH Director's Office (DP2HD101400), the NIH National Institute of Mental Health (K23MH115812), the Tiny Blue Dot Foundation, the Harvard University Eleanor and Miles Shore Fellowship Program, and NIH National Institutes of Allergy and Infectious Diseases (2U19AI110818).Dr. Huang has received research support from Siemens Healthineers. Dr. Branda has received research support from Zeus Scientific, bio-Merieux, and Immunetics, and consulting fees from T2 Biosystems, Roche Diagnostics and DiaSorin for work unrelated to this study. Dr. Lev has received research support from GE Healthcare, and consulting fees from GE Healthcare and Takeda Pharmaceutical for work unrelated to this study. All other authors report no relevant disclosures.",United States of America,first author,2021-02-15,02
06ea648b65ed3ec734124a078e83942bfb106031,Bacterial expression and purification of functional recombinant SARS-CoV-2 spike receptor binding domain,"TheCoronavirus disease-2019 (COVID-19) pandemic caused by the Severe Acute Respiratory Syndrome coronavirus 2 (SARS-CoV-2) has, due to its prolific interhuman transmission, become a dire global health concern (1). Since its discovery in Wuhan, China (2) in late 2019, there have been over 100 million cases worldwide, and over 2 million deaths as of January 2021. The novel betacoronavirus, SARS-CoV-2, belongs to the Coronaviridae family and is closely related to SARS-CoV-1 (79% genomic sequence identity) and MERS-CoV (Middle East respiratory syndrome coronavirus; 50% genomic sequence identity), two other pathogens responsible for the SARS epidemic of 2002, and the MERS epidemic in 2012, respectively (3, 4) . SARS-CoV-2 infection elicits a range of clinical presentations, from asymptomatic infection to severe viral pneumonia and death (3, 4) .Like other coronaviruses, SARS-CoV-2 is comprised of four structural proteins: spike (S), envelope (E), membrane (M), and the nucleocapsid (N) (3, 5, 6) . The Sprotein is heavily glycosylated and can be found covering the surface of SARS-CoV-2 (7) ; glycosylation also allows the virus to evade the host immune system and gain entry into host cells via attachment to its receptor, ACE2 (5, 7, 8) . At the amino acid level SARS-CoV-2 shares 90% identity with SARS-CoV-1 (3) . The S protein forms a homotrimeric class I fusion protein with each S monomer containing two subunits, S1 and S2 (4, 5) . When fused to host cell membranes, the S protein undergoes extensive conformational changes that cause dissociation of the S1 subunit from the complex and the formation of a stable post-fusion conformation of the S2 subunit (4, 5) . Much like SARS-CoV-1, receptor binding of the SARS-CoV-2 S protein relies on the receptor binding domain (RBD), which recognizes the aminopeptidase N segment of ACE2 (7) . In addition to ACE2 recognition, the RBD is also responsible for eliciting neutralizing antibodies and has become a highly-investigated target for vaccine and drug development (3, 5, 6) .Spike RBD interaction with host ACE2 is the critical event preceding viral infection. Recent studies have shown that the RBD binds human ACE2 (hACE2) in low nanomolar affinity, further underscoring the importance of RBD in establishing viral attachment (4, 5) . The crystal structure of SARS-Cov-2 RBD has been described by Lan et al. (4) and highlights the key regions of the RBD responsible for ACE2 binding. The RBD consists of extensive β-sheets among which is nestled an extended insertion dubbed the receptor-binding motif (RBM); the RBM contains the residues that make contact with ACE2. The RBD also has ten cysteines ( Fig. 1 ) which stabilize the overall structure through the formation of five disulfide bonds: three within the β-sheet core (C336-C361, C379-C432, and C391-C525), one connecting the distal loops of the RBM (C480-C488), and one that ties the N-and Ctermini together (Cys538-Cys590) (4, 5) . It is important to note that not all of these disulfide bonds are consecutively formed and some require editing by reduction and reoxidation to form the correct bonds, which poses a complicated folding problem in the cytoplasm of bacteria (5) .Although advantageous in terms of ease of protein production, rapid growth, and cost-efficacy, the production of recombinant proteins in E. coli has its challenges (9, 10) . It is vital to maintain the correct disulfide bonds for structural as well as functional stability, which is problematic when expressing proteins of interest in the cytoplasm of wildtype E. coli (11). Disulfide bonds are typically formed in proteins which are secreted, or targeted to the outer membrane. The cellular organelles evolved to carry out this post-translational modification are the mitochondria and endoplasmic reticulum of eukaryotes, and the periplasmic space in prokaryotes (12) . Disulfide bonds formed in the cytoplasm would be quickly reduced by multiple reductases and/or by reductants (such as glutaredoxin and thioredoxin). A possible solution would be to modify the protein construct to allow its secretion into the periplasm, which contains disulfide bondcatalyzing enzymes (9, 11) . However, this route greatly lessens the protein yield due to the limited cellular space occupied by the periplasm (8-16%), and requires modification of the construct to include a signal sequence for periplasmic targeting (9) . Commercially available strains have been engineered to lack thioredoxin reductase and glutathione reductases, and to express disulfide bond isomerases, such as SHuffle (NEB), and Origami (Novagen), though these strains can suffer from low protein solubility and yield due to the lack of de novo or inappropriate disulfide bond formation (11).To circumvent the drawbacks listed above, the Ruddock lab developed the CyDisCo (cytoplasmic disulfide bond formation in E. coli) system and showed that it was possible to produce active disulfidebonded proteins in the cytoplasm of E. coli without deleting reduction systems, simply by expressing the sulfhydryl oxidase Evr1p (12, 13) . Evr1p uses molecular oxygen to form disulfides in a FAD-dependent reaction, allowing the production of disulfide-bonded proteins in the cytoplasm of wild-type E. coli. Another enzyme, protein disulfide isomerase (PDI), is added to edit disulfide bonds during protein folding. PDI can distinguish between properly folded and misfolded proteins, and correct disulfide bonds through cycles of cleavage and formation. In this way, correctly folded proteins with disulfide bonds can be recombinantly produced in the cytoplasm of E. coli.We used the CyDisCo to make recombinant SARS-CoV-2 spike RBD properly folded with correct disulfide bonds. By cotransforming the spike RBD expression plasmid with the CyDisCo system, we were able to successfully produce recombinant spike RBD with the correctly-formed disulfide bonds. Here, we describe a simple cost-effective method of generating antigens using a bacterial expression system. By coexpressing our protein of interest along with the CyDisCo system, we have been able to produce correctly-folded antigen that retains activity and which can be used in diagnostic assays.The genetic sequence of spike RBD was fused to 10X-His-tagged maltosebinding protein (MBP), cloned into pET28a, and ordered from GenScript ( Fig. 2) with codon-optimization for expression in E. coli. To ensure that all five disulfide bonds in the RBD ( Fig. 1 ) (4) remain oxidized when expressed in the highly reducing cytoplasm of E. coli, we co-expressed the RBD-MBP fusion protein with a CyDisCo plasmid (9) . The plasmids were co-expressed in one-shot BL21(DE3) cells (Thermofisher) in Luria-Bertani media (Fisher Bioreagents) under kanamycin (30 µg/ml) and chloramphenicol (34 µg/ml) selection. Cells were grown at 30° C, 275 rpm shaking until an OD600 of 0.3-0.4 was reached, and then induced with a final concentration of 0.5 mM isopropyl β-D-1thiogalactopyranoside (IPTG) (Gold Biotechnology). At this point, the cells were cooled and transferred to 18° C, 150 rpm shaking overnight (approximately 16 hours) (Fig. 3) . Cells were pelleted and stored at -20° C.A cell pellet was thawed and resuspended in a buffer containing 20 mM Tris-HCl pH 7.4, 0.2 M NaCl, and 50 µl of protease inhibitor cocktail (Sigma, Cat.# P8849) per gram of cell pellet. The resuspended pellet was then lysed by three passes through an Emulsiflex C3. The resulting lysate was clarified by centrifugation at 40,000xg for 30 minutes at 4° C. Clarified lysate was then filtered through a 0.45 µm filter (Millipore) before being passed through a 5 ml MBPTrap column (GE) using an AKTA FPLC (Amersham Biosciences). Nonspecifically bound proteins were washed from the column with 10 CV of resuspension buffer, and RBD-MBP was eluted over 10 CV in a gradient method, using a buffer containing 20 mM Tris-HCl pH 7.4, 0.2 M NaCl, and 10 mM maltose. Fractions yielding protein (as observed by A280 peaks on the AKTA FPLC (Amersham Biosciences) chromatogram) were gel-verified using a 10% SDS-PAGE gel (Genscript) that was stained with Coomassie Brilliant Blue G-250 for size (Fig. 4) , then loaded onto a 1 ml NiAff column (GE) with a running buffer containing 2X PBS with 20 mM imidazole, pH 8, and an elution buffer containing 2X PBS with 1 M imidazole, pH 8 over 16 CV. The resulting peaks were again gel-verified (Fig. 4) , and lanes with bands corresponding to 74 kDa (expected size of the RBD-MBP fusion protein) were concentrated and loaded onto a HiLoad 16/60 Superdex75 (GE) sizeexclusion column. Fractions corresponding to the fusion protein (Fig. 4) , were pooled and concentrated (using Amicon regenerated cellulose concentrators (Cat # UFC803096). RBD-MBP identity after each column was confirmed by Peggy Sue (Protein Simple) western analysis using Sino Biological Anti-Coronavirus spike antibody (Cat # 40591-T62). The concentrations were determined using a Fisher NanoDrop1000 using a molecular weight of 74 kDa for the fusion protein, and calculated ɛ280=101.19 M -1 cm -1 . The yield from 2 liters of culture was approximately 0.5 mg purified RBD-MBP. Purified RBD-MBP was stored at -20°C in 2X PBS supplemented with a final concentration of 30% glycerol.The recombinant hACE2-AviTag protein from 293T cells (Acro Biosystems, DE, USA) was captured on a sensor chip in the test flow channels. Samples of 300 μl of freshly prepared serial dilutions of the purified recombinant protein were injected at a flow rate of 50 μl/min (contact duration 180 seconds) for the association. Responses from the protein surface were corrected for the response from a mock surface and for responses from a buffer-only injection. Total hACE2 binding and data analysis were calculated with Bio-Rad ProteOn Manager software (version 3.1).This assay was performed using the purified SARS-CoV-2 RBD-MBP fusion (5 µg per 106 beads) coupled to the surface of group A, region 43, MagPlex® Microspheres (Luminex Corp, IL, USA). Microsphere coupling was performed using the Luminex xMAP Antibody Coupling Kit (Luminex Corp, IL, USA) according to the manufacturer's instructions. The proteincoupled microspheres were re-suspended in PBS-TBN buffer (1X PBS containing 0.1% Tween 20, 0.5% BSA and 0.1% sodium azide) at a final stock concentration of 2x10 6 microspheres per ml, with 2.5x10 3 microspheres used per reaction. Deidentified serum samples were obtained from residual patient sera that tested positive or negative by a clinical SARS-CoV-2 serology assay (Diasorin LIASON SARS-CoV-2 S1/S1 IgG; n=6 per group) at UNMC. Fifty microliters of each serum sample (diluted 1:50 with 1X PBS-TBN buffer) was mixed with 50 µl of the RBD-MBP coupled microspheres in a 96-well plate. The assay plate was incubated for 30 minutes at 37° C with shaking at 700 rpm and then washed 5 times with 1X PBS-TBN buffer. Then, the plate was incubated with biotin-conjugated goat anti-human IgG (Abcam, MA, USA), labeled with streptavidin R-phycoerythrin reporter (Luminex xTAG® SA-PE G75) for 1 hour at 25° C with shaking at 700 rpm. Then, the plate was washed 5 times with 1X PBS-TBN buffer. Finally, the plate was resuspended in 100 ml of 1X PBS-TBN buffer and incubated for 10 minutes at 25°C with shaking at 700 rpm. The microplate was assayed on a Luminex MAGPIXTM System, and results were reported as median fluorescent intensity (MFI).The gene sequence for the Spike RBD-MBP fusion protein was cloned into pET28a and codon-optimized by Genscript. To facilitate cleavage of MBP from RBD, a TEV recognition sequence was included after the MBP protein sequence. RBD-MBP purified readily from BL21(DE3) E. coli pellets. Initial IPTG induction tests showed appreciable accumulation of the fusion protein after 16-18 hours at 18° C (Fig. 4) . Though induction appeared similar to 4 hour induction at 30° C, it was decided that lowertemperature induction for a longer time would encourage thorough editing and formation of disulfide bonds and correct folding of the recombinant protein. The pellets were thawed and lysed, in the presence of protease inhibitor and all steps were performed with the lysate on ice or at 4° C. After the lysate was clarified by centrifugation, it was passed through a MBPTrap column to clear non-specific proteins lacking the MBP tag. Fractions containing RBD-MBP were confirmed through SDS-PAGE (Fig. 4) where RBD-MBP can be observed running at ~74 kDa (indicated by red arrows). Interestingly, we could also see prominent bands at ~42 kDa (indicated by the green arrow), corresponding to the size of MBP, indicating that we also pulled down endogenouslyproduced E. coli MBP. The resulting fractions were pooled before passing through a NiAff column, which bound the 10X His tag on the fusion protein. This additional affinity purification step helped reduce the amount of non-specific proteins that copurified with RBD-MBP, as well as reduce the presence of any cleaved or endogenous MBP from the pool of fusion protein. Finally, RBD-MBP was further purified using a sizeexclusion step over a Superdex75 column. Using the steps outlined above, we were able to obtain approximately 0.5 mg of pure RBD-MBP from 2 liters of culture.To test the activity of purified RBD-MBP, we assessed its binding to hACE2 using SPR against control RBD secreted from human cells (Fig. 5) . We showed that the purified RBD-MBP bound hACE2, indicating correct functional folding of the purified recombinant protein.An immunoassay was performed to confirm that our RBD-MBP was recognized by human SARS-CoV-2-specific antibodies. RBD-MBP-bound microspheres were incubated with sera that had tested positive (n=6) or negative (n=6) in a clinical SARS-CoV-2 serology assay. RBD-specific IgG antibodies were detected in all sera from SARS-CoV-2 antibody-positive patients (Fig. 5 ).In this paper, we have described a rapid method to express and purify functionally active RBD antigen in E. coli. The coexpression of the sulfhydryl oxidase, Evr1p, and the disulfide bond isomerase, PDI in the CyDisCo system along with the plasmid of interest results in a well-folded and functionally active protein in a bacterial system, which is simple, rapid, and less expensive than a eukaryotic or mammalian system. It is noteworthy that the RBD expressed in bacteria here does not have any post-translational modifications. As the structures solved for the RBD had missing gaps in the loops, we fed our sequence into I-Tasser, which generated the complete model (14) (15) (16) . The ribbon was drawn using UCSF Chimera (17) , is colored from blue (N-terminus) to red (C-terminus), and cysteines forming disulfide bonds are labeled.. ",USA,first author,2021-02-03,02
9766028a2d8bf5054337e2f0f0cbe7b67eff4860,Surface-aerosol stability and pathogenicity of diverse MERS-CoV strains from 2012 -2018,"Middle East respiratory syndrome coronavirus (MERS-CoV) was first discovered in 2012 and continues to cause outbreaks in the Middle East as a result of frequent spillover from dromedary camels to humans. MERS-CoV has a mortality rate of ~35% and has spread to 27 countries (1, 2). While dromedary camels have been shown to be the animal reservoir, phylogenetic analysis has shown that humans are a dead-end host (3) . Approximately 41% of MERS-CoV cases in the Kingdom of Saudi Arabia (KSA) are primary, resulting from direct camel-to-human transmission (4) . To date, MERS-CoV has been detected in camels in Burkina Faso, Egypt, Ethiopia, Jordan, Kenya, Morocco, Nigeria, Saudi Arabia, Senegal, Sudan, Tunisia, and Uganda (5) (6) (7) (8) (9) (10) (11) (12) (13) . While MERS-CoV has been isolated from camels in Africa, there are no reports of zoonotic transmission to humans, unlike what has been observed in the Middle East (9) .Human-to-human transmission of MERS-CoV has been reported but is inefficient and primarily occurs in hospital settings and within households (14) . The exact route of transmission between humans is currently still unclear. It is possible that direct contact with infected individuals, as well as fomite and aerosol transmission all collectively contribute to viral transmission. Epidemiological studies have mapped indirect patient contact within hospitals, providing evidence for aerosol and hospital-worker mediated spread (15) (16) (17) (18) . The largest outbreak of MERS-CoV outside of the Middle East occurred in South Korea. A single traveler from the Middle East brought MERS-CoV to South Korea, resulting in 185 subsequent infections (19) .Coronaviruses are the largest non-segmented RNA-based viruses identified, with genome sizes averaging around 30kB. Even though coronavirus polymerase has a proofreading function, coronaviruses within the same species are polymorphic. A recent study found approximately 99% nucleotide similarity as well as small deletions in nonstructural proteins between various isolates collected in the Middle East and North Africa (20) . While this variation may seem minimal, 1% is equivalent to 300 nucleotide changes in the 30kB genome. Indeed, many of these changes are nonsynonymous and are distributed throughout the viral genome.As previously shown, single amino acid changes in the viral genome can result in profoundly varying phenotypes in viral replication (21) . Additionally, one study has aimed to functionally characterize some of these MERS-CoV strain differences, with a particular focus on ORF deletions, and found significant effects in the virus' ability to antagonize host innate immune pathways, translating to viral attenuation in an animal model (20) . Given that MERS-CoV continues to cause outbreaks and evolve, these findings underscore the importance of characterizing how MERS-CoV genetic variation alters viral replication, pathogenicity and stability.Here we expand on previous work from others by testing a broad panel of viral isolates collected from both humans and camels, representing every major geographic region with MERS-CoV outbreaks and spanning from early to contemporary outbreaks. Because MERS-CoV spreads within households and hospitals, we characterized and compared viral phenotypes with immediate implications for public health. We focused on environmental stability both in aerosols as well as surface stability on common materials found in hospitals, replication kinetics in immortalized human cell lines and primary human airway epithelial cultures, as well as pathogenicity in a transgenic mouse model our lab previously developed to test vaccine efficacy (22) . For the environmental stability studies, we included SARS-CoV-2 to allow better comparison of these findings with previously published stability studies (23) .Animal experiment approval was obtained by the Institutional Animal Care and Use Committee (IACUC) at Rocky Mountain Laboratories. All animal experiments were executed in an Association for Assessment and Accreditation of Laboratory Animal Care (AALAC)-approved facility, following the guidelines in NIH Guide for the Care and Four different surfaces were evaluated: polypropylene (ePlastics), AISI 304 alloy stainless steel (Metal Remnants), copper (99.9%) (Metal Remnants) and silver (99.9%) (Sigma-Aldrich). Discs with a radius of 15 mm were cut out, sterilized and placed in 24well plates. Each disc received 50 µl of MERS-CoV at a titer of 10 5 TCID 50 /mL. At appropriate times, 1 mL of DMEM was added to the well, aliquoted and stored at -80°C.All samples were titrated on VeroE6 cells.Virus stability in aerosols was determined as described previously (26) . Briefly, the collison nebulizer used to produce aerosols was loaded with 10 6.5 TCID 50 /ml of MERS-CoV in DMEM containing 2% FBS. Aerosols were maintained in the Goldberg drum and samples were collected at 0-, 30-, 60-, 120-and 180-minutes post aerosolization by passing air at 6L/min for 30 seconds from the drum through a 47mm gelatin filter (Sartorius). Filters were dissolved in 10 mL of DMEM containing 10% FBS and stored at -80°C. All samples were titrated on VeroE6 cells. Transgenic balb/c mice expressing human DPP4 were inoculated intranasally (I.N.) with 10 3 TCID 50 MERS-CoV. Mice were weighed and oropharyngeal swabs were taken daily. At D3, four mice were euthanized, and lung tissue was harvested. The remaining six mice were monitored for survival. Mice were euthanized upon presence of severe disease signs (e.g. hunched posture, lack of movement) or >20% of weight loss.Tissues were homogenized and RNA was extracted using the RNeasy method Necropsies and tissue sampling were performed according to IBC-approved protocols.Lungs were perfused with 10% formalin and processed for histologic review. Harvested tissues were fixed for a minimum of seven days in 10% neutral-buffered formalin and then embedded in paraffin. Tissues were processed using a VIP-6 Tissue Tek, (Sakura All analyses were done using GraphPad Prism version 7.05 for Windows. All strains were compared to EMC/12. Linear regression was determined for the mean value of three runs per virus. Statistical significance was determined using ordinary one-way ANOVA followed by Bonferonni's multiple comparisons test or a two-way unpaired student's t-test.We utilized eight different MERS-CoV strains and one SARS-CoV-2 strain (SARS-CoV-2 strain nCoV-WA1-2020 (MN985325.1)) in the current study. Five MERS-CoV strains were isolated from human cases and three strains were isolated from dromedary camels. Strains were isolated between 2012 and 2018, and originated from the Middle East (5), Africa (2) or South Korea (1) ( Table 1) . All originally obtained viruses were passaged once in VeroE6 cells. Virus stocks were sequenced on the MiSeq. Mutations compared to the published sequence are detailed in Table 1 . Lung pathology was then examined by a board-certified veterinary pathologist blinded to study group allocation. No differences in pathology were observed. Animals rarely showed pulmonary pathology at D3, however animals that had lesions showed only a minimal and random lymphocytic infiltrate. Immunohistochemistry detecting MERS-CoV antigen was expressed rarely or randomly scattered in pulmonary tissue type I and II pneumocytes and not located in areas of inflammation. Morphometric analysis of pulmonary tissue with immunoreactivity revealed no significant difference between groups ( Figure 4G ).The respiratory nature of MERS-CoV, in combination with its high mortality rate and frequent spillover from dromedary camels, position this virus as a potential threat to global health. The ongoing MERS-CoV endemic in the Middle East and subsequent discovery of the virus in camel herds across Africa has resulted in a wealth of publiclyavailable genetic data for various viral strains and isolates. Critically, a small number of studies have shown that genetic variation in MERS-CoV can drastically effect viral phenotypes including replication kinetics and pathogenicity (21, 29, 30) . These findings highlight the need for MERS-CoV surveillance and, importantly, the assessment of new strains as they are isolated for mutations that increase spread, transmission and pathogenicity. In this study, we assessed several viral phenotypes as they relate to public health, in an attempt to better inform public health policy making with regards to MERS-and other respiratory-borne, human CoVs such as SARS-CoV-2. We assembled and tested a panel of diverse MERS-CoV viral isolates. Because MERS-CoV frequently spills over into the human population, we chose to include both humanand camel-derived strains (Table 1, Figure 1 ).Nosocomial spread is at the center of MERS-CoV outbreaks. Therefore, we first assessed the stability of the virus on various surface material types commonly found in hospitals (polypropylene plastic and stainless steel) as well as materials with potential antiviral and known antimicrobial properties (silver and copper) (31, 32) . Regardless of the surface material tested, C/KSA/13 was the least stable over time and fell below detectable levels by 24 hours (Figure 2A) . As shown previously (23) , all virus strains tested had notably reduced stability when left on copper. This finding was repeated on silver surfaces, with the copper surface proving most effective at reducing viral titers ( Figure 2A, right panels) . While copper and silver are generally appreciated for their antibacterial properties, copper has recently been shown to also have antiviral properties against influenza A H1N1 and SARS-CoV-2 (33) (34) (35) . The exact mechanism of copper's antiviral properties is still unclear, but may be related to the formation of hydroxyl radicals by copper ions when in aqueous solution (35) . Silver-based nanoparticles have been shown to be antiviral for human immunodeficiency virus-1 (36), herpes simplex virus 2 (37), hepatitis B virus (38) , respiratory syncytial virus (39) , and monkey pox virus (40) . Regardless of the mechanism, taking advantage of the antiviral properties of copper and silver could be a relatively straightforward method to decrease nosocomial transmission. Indeed, both silver and copper can be used for coating medical tools (41) , and commonly touched items such as bed rails, door handles and intravenous poles (42) . These findings appear to be more broadly applicable for other coronaviruses, as we observed similar results for SARS-CoV-2 (figure 2) (23) . Further research should be invested in determining coronavirus susceptibility to coppermediated inactivation.MERS-CoV infects the lower respiratory tract in humans, and while the exact route of transmission has not been proven in a laboratory setting, it is likely to occur through aerosols and fomites (43) . Studies have suggested that a hospital air-handling system may have contributed to nosocomial spread during the 2015 MERS-CoV outbreak in South Korea (16, 43) and our group has previously shown that the virus can remain viable suspended in air for up to 10 minutes (28) . We tested aerosol stability over time for a diverse set of isolates with a Goldberg drum and observed that all viruses remained viable for a minimum of 180 minutes with approximately a log10 reduction in viral titer observed on average within the collected aerosols ( Figure 2B ).Even though we did not observe major differences in this study, strain stability is an important phenotype to continue monitoring, as mutations in viral capsid proteins have been shown to enhance environmental stability of bacteriophages, Dengue virus, and transmissible gastroenteritis virus (44) (45) (46) . Because MERS-CoV isolates contain polymorphisms throughout the entire viral genome, including the structural proteins that form virions, it is still possible mutations may arise that influence overall virus particle (20) . In primary HAE cultures, all camel-derived viral isolates had reduced replication kinetics compared to EMC/12 ( Figure 3B ). More studies are needed with these camel-derived isolates to determine if their difference in replication kinetics results from a comparison with EMC12, which has well-described tissue culture adaptations, or to see if MERS-CoV may adapt in humans after transmission from camels.Last, we tested our panel of viruses in a transgenic hDPP4 mouse model (22) .We have previously shown that MERS-CoV replicates in type I and II pneumocytes within in the lower respiratory tract of this animal model (22) . While MERS-CoV disease progression does not involve the central nervous system in humans, this small animal model is suitable for vaccine candidate testing, with animal survival or viral-induced death as a binary readout for vaccine efficacy. With the exception of C/BF/15 and SK/15, all strains tested were uniformly lethal in these animals, resulting in similar weight loss profiles and histopathology scores ( Figure 4) . MERS-CoV C/BF/15 contains a deletion in open reading frame 4b (ORF4b), which has been shown in a similar mouse model to result in impaired suppression of the host interferon response and increased type I and type III interferon signaling (20) . Taken together, these results pave the way for testing MERS-CoV vaccine candidates for broadly neutralizing potential in this animal model (22, 47) .Our results with MERS-CoV C/KSA/13 suggest there may be a potential tradeoff between environmental surface stability and replication kinetics. Notably, this was observed for a camel-derived isolate, and we did not observe similar phenotypic relationships for the other strains tested (Figure 2, 3) . Future research efforts with camel-derived viruses and more closely related human-derived viruses could reveal whether adaptations are likely to occur after zoonosis. Our previous viral stability results with SARS-CoV-2 and now these findings with MERS-CoV suggest copper should be incorporated more in hospital settings, particularly in areas of high contact between hospital workers and MERS patients, such as door handles, bed rails, and medical tools (23) . Overall, we observed a range of stability, replication and pathogenesis phenotypes between different MERS-CoV isolates, underscoring the importance of continued surveillance of this virus and other coronaviruses such as SARS-CoV-2.Brief biography on the first authors: A.) 50 µl of MERS-CoV or SARS-CoV-2 was spread on surface, either polypropylene, stainless steel, copper or silver. 1 mL of DMEM was added at T=0, 1, 24, 48 or 72 hours and titrated. B.) MERS-CoV or SARS-CoV-2 containing aerosols were sprayed into the Goldberg drum, and samples were taken at T=0, 30, 60, 120 and 180 minutes and titrated. Linear regression was calculated per virus and displayed in the graph as a line. A-B.) Statistically significant differences between EMC/12 and other strains were calculated using an unpaired Student's two-tailed t-test corrected for multiple comparisons via Bonferroni. Dotted line = limit of detection; p-values = *<0.05; **<0.01, ***<0.001 ",USA,first author,2021-02-12,02
3fedb45a8b6b62730f2b536c0300f067a309342b,Should We Delay the Second COVID-19 Vaccine Dose?,"We derived a simple test formula to check which of the two scenarios is optimal depending on the efficacy of the first and second doses of the vaccine. The formula is given by the following inequality:This shows that, for a given first dose efficacy α 1 that is less than 50%, Scenario 2 is optimal if the value of the second dose efficacy exceeds the threshold α 1 /(1 − α 1 /100), otherwise Scenario 1 is optimal. For instance if we take α 1 = 40% then a second dose efficacy of more than 67% would imply that the best vaccination strategy is to provide the second dose to those who have taken the first dose as quickly as possible (Scenario 2). In Figure  1 we provide a visual picture of the efficacy intervals for the first and second dose where Scenario 1 or Scenario 2 are optimal. In the same figure, we also provide markers for the officially announced vaccine efficacy of Moderna (mRNA-1273 ) [1, 4] , Pfizer-BioNTech [2] , and Oxford-AstraZeneca [8] .We denote by u 1 the number of daily sub-population receiving the first dose and by u 2 the number of daily sub-population receiving the second dose. The objective function to maximize is the total number of daily susceptible sub-population that is effectively vaccinated which is given bywhereᾱ 1 = α 1 /100 andᾱ 2 = α 1 /100 represents the vaccine efficacy of the first and second dose, respectively. The first termᾱ 1 u 1 represents the daily effectively vaccinated subpopulation due to receiving their first COVID-19 vaccine dose, while the second term (1 − α 1 )ᾱ 2 u 2 represents the daily sub-population who have not been effectively vaccinated in the first shot but are now effectively vaccinated owing to the second vaccine shot. If we let u be the (total) daily vaccination rate then we have u 1 + u 2 = u. This allows to rewrite (3) asIt is clear the maximization of the objective function J depends on the sign of the term (ᾱ 1 −ᾱ 2 /(1 +ᾱ 2 )). If this term is positive then the optimal strategy would be to set u 1 = u, u 2 = 0 which corresponds to Scenario 1 of the Results. In the other case, i.e., (ᾱ 1 −ᾱ 2 /(1 +ᾱ 2 )) ≤ 0, the optimal strategy would be to set u 1 = 0, u 2 = u which corresponds to Scenario 2 of the Results.",Canada,first author,2021-02-17,02
465cabd2edf81dc465818a3e8c7ad4c8d32f0723,Vaccine Rollout Strategies: The Case for Vaccinating Essential Workers Early,"1 Introduction exposure in the population, but for equity. 11 , the Pfizer-BioNTech vaccine 43 , and the AstraZeneca 57 vaccine are effective at preventing symptomatic infection and severe illness. There are broadly two ways that a vaccine can attain this kind of result: either by preventing infection from occurring in the first place (""sterilizing immunity"") or allowing infection but preventing disease 17 . In the first case the vaccine necessarily prevents onward transmission, but in the latter case the vaccine may or may not prevent subsequent transmission, depending in part on whether it decreases viral load. The first published reports of Phase 3 trials did not directly address this question, only reporting on the reduction of symptomatic and severe infection. However, knowledge of how effective vaccines are at preventing transmission is crucial for determining optimal vaccination rollout strategies. The emerging data relevant to this issue show both a high rate of sterilizing immunity and a reduction of viral load in the minority of those vaccinated who do become infected. One preliminary set of such data was obtained during Phase 3 trials for the Moderna vaccine: subjects received a PCR test with their second dose, thereby allowing an estimate of the efficacy of the first dose in preventing infection. A 2/3 reduction in infection was observed in asymptomatic infection 42 , which together with the already documented reduction in symptomatic cases 11 gives a high overall reduction in infection. Similar preliminary results are emerging for the Pfizer vaccine 32, 41 and for AstraZeneca vaccine 6 . As well, substantial reduction in viral loads have been found among those who are infected for both the AstraZeneca vaccine 25 and the BioNTech/Pfizer BNT162b2 vaccine 37, 44 , suggesting reduced further transmission even when infection does occur. Given these data, the impact of vaccination on transmission is likely to be strong, and jurisdictions which have planned predominantly oldest-first vaccination rollouts may now wish to use vaccination to reduce transmission more rapidly.Building on the work of Bubar et al 15 , we developed an age-and contact-structured model to explore the impact of vaccination strategies. We incorporate chronic outcomes of COVID-19 infection, along with infections, hospitalizations and deaths. We compare age-based vaccine rollout from oldest to youngest with strategies that prioritize those we call ""essential workers"" -those whose employment requires them to have considerable contact outside the home. Furthermore, we attach health economic outputs by applying a Net Benefit framework to our results, including the expected cost due to hospitalization and chronic conditions resulting from infection, as well as decrements in health utility, which are measured using quality-adjusted life years (QALYs). These estimates are synthesized into Net Monetary Benefit (NMB) by converting QALYs to monetary value, to allow a unified way of evaluating vaccination strategies 54 . and essential worker status, and we explore Long COVID and chronic outcomes. We also have two distinct efficacy modes: preventing infection and therefore transmission, and preventing severe outcomes (symptomatic disease, hospitalization, death and chronic outcomes). We have made the code necessary ot reproduce our results publicly available 1 .In total, we model groups {0 − 9, 10 − 19, 20 − 29, ..., 70 − 79, 80+, 20 − 29 e , 30 − 39 e , ..., 70 − 79 e }, where the e superscript denotes an ""essential worker"" group. We furthermore extend Bubar et al's analysis by implementing and simulating more detailed age-based and essential-workerbased vaccination strategies, and by considering trade-offs between the efficacy of vaccination on preventing infection, and on preventing adverse outcomes.To model contacts among all 15 groups, we first start with the four matrices Λ developed by Prem et al 46 for estimated contact patterns among Canadians at home, work, school, and all other locations. We assume that the average contact rates between each age group and at each location are the same across the population. Each contact matrix Λ provides an estimate of contact patterns over age groups 0-70+ in five-year increments. We first combine each age group into the desired ten-year bins using demographic data from British Columbia (BC), Canada. We then obtained survey data to estimate the distribution of essential workers by age group (the Covid Speak Survey 3 ); these proportions varied from 20% of 30-39 years-olds to approximately 10% of 70-79 years-olds. In total, we estimate that approximately 13% of the population of BC are considered to be ""essential"". We use this data to split the working adult age groups into essential worker and non-essential worker compartments, assuming an even distribution of the number of contacts, following the technique of Buckner et al 16 . We model social distancing in part by eliminating workplace contact between non-essential workers (schools have remained open in BC, and so we do not eliminate school-based contact). In addition, all other contacts are then reduced, reflecting broad distancing measures. By modifying the scaling factor we control the reproductive number, R. In our formulation R reflects the extent and effectiveness of NPI measures (but does not reflect the impact of vaccination). The underlying transmission (parameterized by R) impacts the relative benefits of different vaccination strategies, and we explore this impact.Our simulation approach is motivated by the vaccination programs in British Columbia, across Canada, and in similar jurisdictions. Such jurisdictions have had a relatively small portion of the population naturally infected at the time of writing, and have begun vaccination with the very elderly during a time when social distancing measures have kept the reproduction number low while those over 80 years of age are vaccinated. Accordingly, we hold R at 1.05 from January 1, 2021 for 60 days. We retain the model structure of Bubar et al. 15 which stops and restarts the simulation, moving individuals daily into the appropriate vaccination compartment. After 60 days we raise R, typically to 1.15, 1.3, 1.5 in the main text and with some higher examples in the supplement. This rise in transmission models either relaxation of distancing measures, reduced compliance to widespread distancing measures, or rising frequencies of higher-transmission COVID-19 variants of concern 22 . During the next 210 simulated days we proceed with the specified vaccination scenario. We model age-specific hesitancy, with some portion of each age group declining the vaccine.We consider five vaccination scenarios. In all scenarios the 80+ age group is vaccinated first. In scenario A available vaccines are distributed to age groups in order of decreasing age. In scenario B, after the 80+ group is vaccinated, the vaccine is distributed to everyone else with no preference for age. In scenario C, D, and E, after the 80+ group, essential workers are then vaccinated without regard for age. In scenario C, the rest of the population is vaccinated in decreasing order of age. In scenario D, the rest of the population is vaccinated without regard for age. In scenario E, the 70-79 cohort is vaccinated next and then the rest of the population is vaccinated without regard to age.For each vaccination scenario and choice of parameters, we measured multiple outcomes: number of infections, deaths, hospitalization, and cases of Long COVID. Whether any specific infection became a case of Long COVID was determined by an age-dependent probability which was computed using data from the Covid Symptoms Study App, (CSSA) 55 . The CSSA defines Long COVID as having symptoms longer than 28 days. Hospitalizations and deaths per detected case were estimated from data provided by the Public Health Agency of Canada 30 , Table 13 -26-0003, for infections detected in the period between Sept. 15, 2020 and Jan. 15, 2021. At this time, the ascertainment fraction is believed to have been relatively high 23 . We use an ascertainment fraction of 0.75 to scale the estimated hospitalization and death rates per detected case to infections in the model, and compared the resulting hospitalizations and deaths (along with incidence) to data from British Columbia, Canada in fall 2020 (see Figure S1 ).A disproportionate number of deaths have been among those living in long term care (LTC) settings, accounting for 2/3 of British Columbia's deaths and 80% of Canada's death in the earlier part of the pandemic 40, 59 despite the fact that well under 10% of Canada's seniors aged 65 and over are in long term care 4 . Long term care settings have been prioritized for vaccination and there are already indications of benefits. Accordingly, we reduced the infection fatality rate to reflect the fact that LTC settings are very unlikely to see death rates as high as they experienced in the pandemic to date; we reduced the rate by 1/3, consistent with the above numbers and the PHAC data on cases by age 47 .Finally, we considered some economic measures of the cost of the pandemic from a health system payer perspective: Health utility losses measured in QALYs lost and NMB. Estimating health utility in terms of QALYs allows us to quantify and compare loss of quality and duration of life due to illness, disability, and death 60 . QALYs are estimated such that the maximum value of 1 indicates a year in perfect health, whereas a value of 0 indicates no health (death), and the measure is unbounded such that negative values capture health states worse than death. Utility decrements due to acute COVID infection, hospitalizations, chronic outcomes, and death are estimated as the difference between expected health, and health utility due to COVID. Our calculations built on the work of Briggs et al 12 , with additional material drawn from Kirwin et al 34 .for individuals who died from COVID.For the loss of QALYs due to acute infection we used figures from Kirwin et al 34 . Each infection was given an age-dependent loss of quality adjusted days (Table 1) . Hospitalizations incurred a utility decrement of 0.58, which was adjusted for mean duration of hospital stay by age group, to obtain the quality adjusted days lost for a hospitalization. For those discharged from the hospital, an additional utility decrement of 0.1 QALY was applied for the one-year period following discharge, as individuals do no immediately return to their pre-COVID health state following discharge 34 .We then determined a NMB (loss) for the pandemic, first by converting QALYs lost to a monetary equivalent value by multiplying by $30,000 Canadian dollar 36 and then adding estimates of costs due to hospitalization and chronic outcomes. Using estimates of the direct costs of hospitalisation from Kirwin et al 34 gave $1391.88 per day of hospitalization. The cost of chronic outcomes was again estimated by weighting the cost per year of the list of chronic conditions by their prepandemic prevalence, leading to a value of $10,019.88 per individual per individual annually.Following the data from studies on the Pfizer and Moderna vaccines on the impact of vaccination on infection and on viral load, and data from the clinical trials on the impact on severe disease 11, 32, 41-43 , we assume a 90% effectiveness in preventing illness and death, and then vary the effectiveness in preventing infection from 0.6 to 0.9.Value Source max duration of chronic outcome 25 Table 2 : Model Parameters Figure S1 shows simulated incident cases, hospitalization and deaths compared to data from British Columbia (BC), Canada, during a period of slow but sustained growth at R = 1.2 in fall 2020. This illustrates that the model produces realistic age-structured simulations for BC.Other differences between the age ordering are very small compared to the difference between ""oldest first"" strategies and any alternative that prioritizes essential workers or even all younger adults earlier in the program.We find similar effects when we estimate the incremental costs of the pandemic including both direct costs of hospitalization and chronic outcomes and health utility decrements converted to monetary values (Figure 4 ). Vaccinating essential workers sooner reduces the overall NMB loss due to the pandemic by %50 to %65. This results in a potential savings of (for example) over $M400 (if R = 1.3); see Figure S2 . In all scenarios, NMB lost was largest for the age-based immunization strategy (A). The largest improvement in NMB was achieved with strateges C, D and E, irrespective of vaccine efficacy. Figure 4 highlights the potential for a substantial impact of chronic consequences of infection, both related to health utility losses, and future health system cost.Strategies that vaccinate essential workers early lead to substantial reductions in the number of infections, hospitalizations, deaths, and cases of Long COVID relative to a strategy of oldest first. This finding is robust to details of how the vaccine is rolled out to younger people, the exact fraction of essential workers vaccinated, the effectiveness of the vaccine at preventing transmission, and the underlying transmission (described by R). The reason is that essential workers have many more contacts than older adults and vaccinating them is the most effective way of reducing overall prevalence. For the range of parameters we considered, the benefit of vaccinating essential workers and thereby reducing prevalence by preventing transmission outweighs the benefit of vaccinating older adults first. Reduction in deaths were often modest, but reduction in other measures were substantial, since the total number of infections was reduced. Benefits were similar even if instead of essential workers, young people were vaccinated along with older people irrespective of their work status, since young people tend to have a higher number of contacts on average.There is an important equity consideration, as the COVID-19 pandemic has disproportionately impacted essential workers. Across neighbourhoods in Toronto, for example, per-capita COVID cases and deaths were 2.5 to 3 times higher in neighbourhoods with high (vs low) concentrations of essential workers 48 . Essential workers often have lower incomes, and may be hired as contractors; they may not have paid sick leave, and may have limited ability to negotiate safe working conditions 48 . While many others are able to work safely at home, these individuals cannot. Our findings suggest that prioritizing them for vaccination not only would help to reduce this substantial disparity, it does not even come at a cost of increased adverse outcomes in others; rather, it is better for everyone.We modelled a rise in transmission 60 days into the simulation, in part because of increasing evidence that variants of concern (VOC) are rising in frequency in Canada 14 and elsewhere 58 . A number of distinct VOC have emerged, showing signs of increased transmissibility 7 , and there have already been introductions and community exposures across Canada. As their frequency rises, VOC are likely to drive higher transmission rates, particularly in the current context where many areas are considering relaxing restrictions following declining cases in recent weeks. If VOC transmission is contained, the relaxation of measures itself is likely to result in higher transmission in coming weeks.We explore the portion of the population who are immune at the time that transmission begins to decline and find that the levels of protection at this ""herd immunity"" time are comparable to the theoretical requirement (1 − 1/R) in very simple models, despite the fact that the model has heterogeneous contacts by age and work patterns. This is in contrast to other modelling work which has suggested that heterogeneous contacts mean that far fewer individuals might need to be protected 8, 13 . We note that unlike these studies, our model was compared to age-stratified incidence, hospitalization and death data and matched well. The difference is driven by the fact that our model has less severe contact heterogeneity than these models, and so has sufficient intergroup mixing that relatively high levels of immunity are required for herd protection.Even without considering Long COVID and COVID complications, vaccinating essential workers sooner has strong benefits in terms of reducing infections, hospitalizations, deaths, and in terms of net monetary benefit. However, taking chronic outcomes into account makes the advantages of our proposed vaccination schedules over oldest-first even more stark, showing that they potentially save hundreds of millions dollars of additional NMB. These long-term consequences of COVID infection could impact future health of 0.5% of the population under an oldest-first vaccination strategy, and far fewer (0.25%) if essential workers and/or younger adults are vaccinated earlier.Despite uncertainty in the likelihood and duration of long-term consequences of COVID infection, Long COVID and COVID complications need to be included in considerations of vaccine priority.In Figure S1 , we validate the model contact structure, and the age-based hospitalization and fatality rates against observed cases, hospitalizations, and deaths in British Columbia over a period from October 1 to December 1 2020.In Figure S2 we show the Net Monetary Benefit of each of the alternative vaccination strategies, relative to strategy A (vaccinating from oldest to youngest). The NMB of any of the strategies relative to no vaccinations at all is considerably larger 2 . Figure S3 explores two additional strategies that were not considered in the main text. Both of these additional strategies prioritize essential workers. Strategy F is similar to strategy E, except we consider allocating vaccines to 70-79-year-olds before essential workers (followed by a general rollout). Strategy G is again similar to strategies C and E, where we prioritize essential workers, then target older adults sequentially, followed by all 20-59-year-olds. We see that all of strategies C through G (which prioritize essential workers) out-perform the purely age-based strategies (A and B) in terms of infections, hospitalizations and deaths. However, the strategies which also prioritize adults aged 70-79 (strategies E-G) outperform strategy D (which does not prioritize this age group) in terms of mortality. Across outcomes, we observe that strategies E-G perform very similarly.In our model, individuals with Long COVID do not continue to transmit COVID, and their numbers therefore do not affect the dynamics of the rest of the model. Here we illustrate the impact of assumptions about the vaccine's efficacy against Long COVID.The model in the main text used the same efficacy against Long COVID as for severe outcomes (0.9). Figure S4 illustrates that this efficacy has a minor outcome on the Long COVID prevalence. Although we explore an efficacy of 0.6 compared to the default of 0.9, so a 30% decrease in efficacy this has a minor impact (a less than 30% reduction in Long COVID), because most of the infections in these scenarios occur among those who were not vaccinated. Most of the Long COVID cases also, therefore, occur among the unvaccinated.We explore the sensitivity of our main result-that strategies which prioritize essential workers outperform age-based only strategies-to various model parameters. We show that our conclusion on prioritizing essential workers is robust (except in a small, and perhaps unrealistic parts of the parameter space), but that distinguishing among such strategies is often sensitive to various model 1 .First, we explore transmission rates that so far seem unrealistic for the Canadian setting but have been used in other models 1 . Figure S5 shows trajectories where R is 1.5 or 2, vaccination proceeds at 0.4% per day with an efficacy against transmission of 0.6 and efficacy against disease is at 0.9 as in the main text.Next, we explore the sensitivity of our results to α, the fraction of workplace contact occurring among nonessential workers (taken the be zero in the main text). Figure S6 shows that for values of R between 1.15 and 1.5, our conclusion that prioritizing essential workers outperforms an age-based rollout is robust to changes in α. However, as α increases the net-benefit of targeting essential workers (strategies C-E) over younger adults (strategy B) decreases (note that when α = 1, all working age adults have the same level of contact, regardless of essential worker status). Therefore, the relative performance of strategies which target essential workers (strategies C-E) is sensitive to both R and α, although our conclusion that such strategies outperform general age-based rollouts is robust.We similarly explore the sensitivity of our results to a broader range of v e , the efficacy of vaccination against infection, in Figure S7 . We find that strategies which target younger adults sooner (strategies B and D) perform poorly in terms of deaths when vaccine efficacy is very low (v e < 0.5) across the different R values. Strategies that target essential workers and also older adult age groups (strategies C and E) are robust even for low values of v e .We furthermore explore the sensitivity of our results to changes in the contact matrix structure. First, we consider changing the proportion of essential workers ( Figure S8 ). We find that strategies C and D, which prioritize essential workers and also older adults, are robust to changes in this frequency. However, strategy D (which does not prioritize older adults) is sensitive to changes in this frequency. Next, we find that our results are not qualitatively altered by random perturbations in the contact matrix ( Figure S9 ). However, these results highlight that we may not be able to use this model to determine the small differences among the benefits of strategies C-E (all of which target essential workers, but differ in the details of the rest of the rollout).Finally, in Figures S10 and S11 we test the relative performance of strategy C (which targets essential workers) against the age-based only strategies (A and B) over a wide range of parameters. These figures show the optimal strategy in terms of minimizing mortality for the given set of parameters. We find that strategy A (oldest to youngest) is only optimal in a very small region of the parameter space. Strategy C, which targets essential workers, is optimal almost everywhere. We note that we do not distinguish here across strategies D-G, which also target essential workers. These figures show that our conclusion that age-based only rollouts are non-optimal is robust except in parts of the parameter space which we consider to be unrealistic.",Canada,abstract,2021-02-25,02
3654e0b054de94961872644a5845b6daa81df201,An exploratory study on the correlation of population SARS-CoV-2 cycle threshold values to local disease dynamics,". Preliminary analyses of simulation and surveillance testing data suggest that decreases in the distribution of CT values in a population, as measured by the median CT value, may precede a local outbreak, such that the median CT value may be a useful tool in predicting a surge (23, 24) . The present study describes an exploratory analysis of potential correlations between median CT values and COVID-19 disease dynamics, operationalized as percent positivity, transmission rate and COVID-19 hospitalizations.The samples in this study were collected between September 15th, 2020 and January 11th, 2021 as part of the ongoing diagnostic evaluation services provided by Dascena, Inc to residents in the state of Texas. In the greater El Paso area, a contractor for the El Paso Department of Public Health sends over 90% of collected samples to the Dascena COVID-19 Laboratory in Houston, Texas. The Pearl Independent Institutional Review Board (IRB) approved this study (IRB Protocol 21-DASC-127).This study included nasopharyngeal swabs, salivary samples, an anterior nares swabs sample, and samples for which the type of biological specimen was not specified. The overwhelming majority of samples were nasopharyngeal swabs. All biological samples were sent to the Clinical Laboratory Improvement Amendments (CLIA)-certified Dascena Laboratory. All samples were analyzed with TaqPath COVID-19 Combi Kit (Thermo Fisher Scientific, Waltham, Massachusetts), with extraction performed with a MagMAX RNA Isolation Kit (Thermo Fisher Scientific, Waltham, Massachusetts). Three gene targets are used by these assays, and may be the source of a positive result: the nucleocapsid (N) gene, the spike (S) gene and the open reading frames (ORF1ab) gene (25) . RT-PCR was only run once on any unique sample. For each RT-PCR test, the CT value was recorded. Only samples that produced a valid CT value for a positive COVID-19 test (i.e., at least 2 genes generating a positive signal with a CT value ≤ 37) were used to determine the daily median CT value and in subsequent correlation analyses.The following demographic data were available for testing samples: age, sex, race, ethnicity, and zip code of residence. Testing samples from the greater El Paso area were selected based on the zip codes listed as part of the El Paso metropolitan statistical area (MSA) by the US Department of Labor, Office of Workers Compensation Program (26) . Daily percent positivity rate was calculated among all samples tested by Dascena from the greater El Paso area.In order to contextualize the results, a focused literature search was performed for peerreviewed publications and pre-print manuscripts on the use of CT values measurements across a population as a means of predicting or monitoring COVID-19 outbreaks. Three pre-prints were identified (23, 24, 30) . The datasets from the present study and the pre-prints were then compared in terms of: source population; type of testing; sample size; biological sample types include; duration of study period; gene target(s) of RT-PCR tests; CT-based value(s) measured; metrics used to measure COVID-19 outbreaks; and the outcomes of study.All analyses were conducted in Python (31) using the following packages: pandas, matplotlib, plotly, scipy and statsmodels. The daily median CT value among Dascena test samples, the daily R(t) in the El Paso MSA, and the daily count of hospitalized individuals with COVID-19 in El Paso were plotted over time. Rolling 7-day averages of the daily median CT value (with a minimum 5 days of data present in the window), the daily R(t), the daily number of COVID-19 hospitalizations, and the daily percent positivity among samples from El Paso sent to the Dascena Laboratory were also plotted over time. To better capture the dynamic change in percent positivity among Dascena test samples, the daily change in percent positivity was calculated from the 7-day rolling average for days with more than 200 total tests performed by the Dascena Laboratory. If fewer than 200 tests were performed on a particular day (e.g., due to holiday shut down of collection sites), the percent positivity from the previous day was carried forward. The daily change in percent positivity was then plotted over time.Scatterplots and linear regression were used to evaluate possible associations between the daily median CT value (N gene) and daily R(t), between the daily median CT value (N gene) and the daily count of COVID-19 hospitalizations, and between the daily median CT value (N gene) and the daily change in percent positivity among samples processed by Dascena. Since a significant time delay was observed between changes in the daily median CT value (N gene) and the daily count of COVID-19 hospitalizations, a time lag of 33 days was applied to the hospitalization data prior to creating the scatterplot and conducting linear regression. The median CT value based on the N gene was selected because it has previously been cited in research on population CT values (24, 30) .Pairwise comparisons were performed with Pearson's correlation (significance P < 0.05) to determine if any demographic factors associated with testing samples were significantly associated with R(t), COVID-19 hospitalization count, or percent positivity. The following demographic factors were investigated: daily number of tests; daily median age; daily percent samples from men; daily percent samples from individuals indicating White race; daily percent sample from individuals indicating Hispanic ethnicity.Pairwise comparisons revealed that some demographic factors of testing samples were associated with COVID-19 outbreak measures ( Table 2) . No other factors, including the number of tests performed, median age, or percentage of tests from male, Hispanic or White individuals each day, were significantly correlated with daily R(t), daily difference in positivity rate or daily count of COVID-19 hospitalizations in the El Paso area.At present, surges are largely predicted based on observed local case and mortality rates, which may lag by several weeks behind changes in transmission rates or be obscured by changes in testing capacity (23) . Given the ubiquitous availability of CT data and the pressing nature of the pandemic, interest has risen in exploring the possibility that the population distributions of CT values can be used as indicators for local outbreaks. The current study adds to the growing literature on this topic by providing an analysis of median CT values from samples collected from an entire geographical area, and contextualizing the results with a comparison to other research investigating the application of population CT values.In the greater El Paso area, daily median CT values were found to be negatively correlated with the daily percent positivity among samples, the daily R(t) extracted from community case rates and the daily count of COVID-19 hospitalizations (with a delay). Of note, these associations were not observed in supplementary analyses (Supplementary Table 1 ), were processed. There appeared to be greater day-to-day variability in the median CT values over time rather than consistent trends in the MSAs evaluated in supplementary analyses, potentially reflecting differences in the strength of the signal that could be detected. In addition, substantial differences in the study populations may have contributed to variable significance of the relationship between median CT value and outbreak measures between study sites. This hypothesis is supported by the observation of significant demographic differences between El Paso MSA and the Texas MSAs evaluated in the supplementary analyses (Supplementary Table 2 ). This observation indicates that certain qualities of datasets used to measure population CT values may be important to their utility to approximate local COVID-19 surges.Changes in the population distribution of CT values significantly preceded a rise in COVID-19 hospitalizations in El Paso. However, contrary to the a priori hypothesis that changes in CT values would precede surges, the cross-correlation plots of median CT value, percent positivity and R(t) did not strongly demonstrate such a relationship. It therefore remains unclear from the data whether changes in the population distribution of CT preceded changes in community transmission, or vice versa. Other studies evaluating population CT values in surveillance samples have reported that changes in CT values may precede traditional signs of an outbreak (23, 24) . The inclusion of symptomatically indicated tests in the sample population may have influenced this association, such that a decline in CT values may be more closely linked to current case rates.While the study sample was large, other variables and forms of bias (e.g., sampling bias), may have influenced the results. Indeed, differences in the comprehensiveness of the El Paso dataset versus the supplementary site datasets-or in, other words, the relative proportion of tests conducted by the Dascena laboratory versus other testing providers-may have contributed to skew in the supplementary samples. Future directions for research on population CT values may therefore include analyzing whether significant differences in results can be detected in different sub-samples of tested populations, and evaluating methods to collate CT data across testing providers in a given geographic area.No data on symptomatology was associated with samples at the time of collection, such that these data do not enable a distinction between samples collected as part of clinical evaluation of symptoms consistent with COVID-19, or for other reasons (e.g., clearance for work or travel). Prior research assessing population distribution of CT values in relation to community outbreaks has explicitly used surveillance samples (23, 24) . The variability in the observed correlations between median CT and outbreak measures in El Paso versus other testing locations may reflect, in part, variability in the proportion of symptomatically indicated versus nonsymptomatically indicated tests in a given location. However, other differences between the testing site populations may also have contributed to the observed variability in the relationship between median CT value and outbreak measures, such as differences in the demographics of the tested population. The research question of whether median CT values derived from all testing data, versus only surveillance testing data, may be reliably used to predict disease outbreaks remains unresolved, and can only be addressed using datasets in which symptomatology at the time of testing or reason for testing may be linked to test results.As national, state and local authorities continue to refine public health programs to track and contain the spread of SARS-CoV-2, it is imperative to optimize methods for predicting surges in community transmission. Greater lookahead time would enable local and state officials to enact public health policies to mitigate an anticipated surge, and would provide health systems with the opportunity to initiate changes to their standard operating procedures, including activating reserve clinical personnel, procuring additional resources to the extent possible, and converting facilities to support additional patient flow. The population distribution of CT values, as measured by the median CT value, is a potential indicator for local outbreaks, which merits further investigation.CFT processed the data, adapted the software code and conducted statistical analyses, generated figures, contributed to drafting the manuscript, and participated in critically reviewing and editing the manuscript. AG obtained and organized the data for study, reviewed software and statistical analyses, and contributed to the primary drafting and editing of the manuscript. AGS contributed to critical review of study design and analyses, drafting the manuscript and editing the manuscript. QM and RD formulated the idea for this study, supervised analyses and critically reviewed and edited the manuscript.",United States,first author,2021-02-19,02
586bd6244f0de01891aeb021b5e101745ab05405,Building Cancer Prevention and Control Research Capacity in Rural Appalachian Kentucky Primary Care Clinics During COVID-19: Development and Adaptation of a Multilevel Colorectal Cancer Screening Project,"Like elsewhere in Appalachia, these areas of Kentucky are characterized by high levels of rurality, lower income levels, higher rates of unemployment, lower education levels, and generally poorer health outcomes [3] . In addition to increased CRC mortality, CRC incidence rates are higher throughout Appalachia, particularly in Kentucky where some of the highest incidence and mortality rates in the USA are located [4, 5] . The many socioecological disparities in the region pose unique challenges to researchers seeking to improve CRC outcomes. To maximize effectiveness of interventions, researchers must implement multiple approaches in collaboration with trusted community partners.Previous research has showcased the effectiveness of establishing academic partnerships with primary care clinics and federally qualified health centers (FQHCs) in improving CRC screening outcomes in rural areas [6] [7] [8] . FQHCs serve populations in underserved areas by providing primary care and preventive services to persons across the lifespan, regardless of their ability to pay [9] . These organizations are communitybased, nonprofit, or public and are governed by a board of directors composed of citizens or patients from their service area. Kentucky has nearly 350 clinics [10] designated as FQHCs due to receipt of grant funding from the Health Resources and Services Administration Bureau of Primary Care and specific reimbursement from Medicare and Medicaid [11] . In Appalachian Kentucky, many individuals receive their medical care from these rural primary care clinics and FQHCs [12] . Because of the lower number of physicians practicing in Appalachian Kentucky, clinics also employ physician extenders such as advance practice registered nurses (APRN), physician assistants (PA), and certified medical assistants (CMA) to assist with providing care. These medical staff often live and work within their own communities, creating opportunities to develop trust and rapport with their patients. Combined with their medical training, the aforementioned characteristics make these physician extenders ideal partners to develop and deliver locally tailored health interventions.Researchers at the University of Kentucky (UK) Markey Cancer Center (MCC) have a long and robust history of collaboration with primary healthcare providers and clinics, area health education centers (AHECs), and communities across rural Appalachian Kentucky. Some recent projects include the adaptation of the proactive office encounter model to identify gaps in preventive care in an eight-site FQHC [13] ; a collaboration with 66 rural practices to increase CRC screening [14] ; the development of the Appalachian Community Cancer Network through which a physical activity and screening intervention to reduce regional cancer burden was implemented [15] ; and a 5-year multisite, multilevel intervention in Appalachian Kentucky and Ohio to increase CRC screening and follow-up care, as part of the Accelerating Colorectal Cancer Screening and Follow-up through Implementation Science (ACCSIS) National Cancer Institute-funded Cancer Moonshot SM [16] . Collectively, these and other similar projects have helped establish partnerships with community providers, develop trusting relationships with patients, and ultimately improve health outcomes within Appalachian Kentucky communities.In 2018, the National Cancer Institute called for research initiatives specifically targeting the development of research capacity in clinics that serve underserved rural populations [17] . Researchers at MCC partnered with the Northeast Kentucky AHEC and responded to the initiative proposing to work with four primary care clinics in Appalachian Kentucky. Three objectives were proposed: (1) assessment of clinic capacity for data collection, compilation, and analysis; (2) identification of facilitators and barriers to clinic implementation of evidence-based interventions (EBIs); and (3) pilot testing of individually tailored, multilevel EBIs that address CRC screening and follow-up. Each of these objectives was selected to strengthen clinic capacity to participate in future larger scale multilevel cancer control interventions. However, a set of unexpected barriers arose from the spread of COVID-19, a pandemic that significantly altered the form and function of primary care clinics serving Appalachian Kentucky. This paper describes the formative process of building and maintaining the research capacity of this initiative with providers and staff in the four partner clinics, and the necessary adaptations that were selected collaboratively in response to statewide and clinic-specific COVID-19 restrictions.All proposed project activities were approved by the UK Institutional Review Board and the UK MCC Protocol Review and Monitoring Committee. The project work plan (Table 1 ) includes a series of steps to be carried out over the one-year project duration. Through the partnership with Northeast Kentucky AHEC, primary care clinics were identified and invited to participate in the project. One of AHEC's main responsibilities is facilitating community rotations for medical, nursing, and other allied health students, which requires extensive interactions with primary care clinics throughout its 17-county service area. The selection process included developing a list of potential clinics and reviewing data on clinic catchment areas, patient population, volume, and participation in other research projects. At the time of the selection process, there were several CRC screening projects ongoing in the study area within primary care clinics, so it was necessary to catalog ongoing projects to avoid potentially skewing the results of those other concurrent studies. At the same time primary care clinics were being recruited, a community advisory board (CAB) was developed. The CAB provided community perspectives to help keep the project grounded in terms of local needs, interests, and values. Based on self-selection and having met necessary inclusion criteria, ultimately, four primary care clinics agreed to participate in the project after which formative evaluation activities began. The first formative evaluation step was to conduct key informant interviews and collect data to provide in-depth information about clinic operations in the context of EBIs related to CRC screening, including identifying existing clinic assets and barriers-both actual and perceived-to implementing those EBIs. The small number of physicians in the FQHCs made it critical to include multiple medical professionals (MD, DO, APRN, PA, CMA) in key informant interviews, as each of these individuals takes an active role in promoting CRC screening in their respective clinic patient populations. A total of seven individuals, primarily serving in nursing roles in their respective clinics, agreed to participate. Two members of the research team conducted phone interviews using a researcher-designed, semi-structured interview guide. The guide included questions to explore clinicwide CRC screening practices and probe further to uncover specific patient-, provider-, and clinic-side barriers to CRC screening. Each interview lasted between 30 and 45 min, and responses were recorded, transcribed verbatim, and separately coded by two independent researchers for overarching themes and sub-themes using both deductive and inductive approaches. Few coding discrepancies arose and were subsequently resolved via investigator debriefings.Drawing from previous experience with CRC screening and follow-up in Appalachian Kentucky clinics, clinic champions were identified for each clinic, and a series of meetings was scheduled with clinic champions and managers to introduce evidence-based multilevel intervention strategies selected from the Community Guide [18] , multiple literature reviews, and the research team's previous work, as well as to assist clinic personnel with selecting approaches that could be best tailored to their clinic populations. For example, at the patient level, we presented options such as mailed fecal immunochemical tests (FIT) [19] , improved and expanded patient education materials showcasing different screening options beyond colonoscopy [20] , and patient reminders (such as annual wellness visit birthday card reminders, phone calls, or mailings) [21] . At the provider level, options included provider assessment and feedback [22] , provider education, and provider reminders [21] to encourage patients to undergo screening. Finally, at the clinic level, we introduced strategies such as the adaptation of electronic health record (EHR) systems to better capture screening and follow-up results; clinic-wide promotion of annual wellness visits, during which providers would likely have more time to promote CRC screening [23, 24] ; and implementation of automated EHR alert systems [21] to remind nurses and providers of overdue screenings.Seven key informant interviews were conducted across the four participating primary care clinics. Emergent themes from the analysis of the key informant interviews found barriers at patient, provider, and clinic levels. At the patient level, the most frequently cited barriers included fatalism related to surviving cancer and local residents not wanting to find out if they have cancer. One provider described her patients' concerns in the following manner: ""You don't need to go digging around for things."" Another provider described this mindset as part of the local culture, commenting, ""[They believe] if it ain't broke, don't fix it."" Other identified patient barriers included fear of various negative outcomes, such as bowel perforation, chemotherapy, death, and a perception that the treatment for CRC is worse than the diagnosis. Providers also noted that patients often have competing medical priorities that tend to minimize their concern for CRC screening: ""Sometimes they think, 'Well maybe I should get checked for lung cancer,' but I don't think colon cancer is at their forethought."" Furthermore, it was noted that prevention in general is often not a priority for patients, one provider commenting, ""They just want to talk about what they're here for generally [ … ] I mean, when people come in for a sore throat, they don't want to talk about their bowels."" The other most common patient-side barriers included financial/ insurance concerns, lack of knowledge and education (including illiteracy), and distance-related issues for rural-living patients (including transportation concerns).Numerous other perceived and actual barriers were found at provider and clinic levels. Perhaps the most salient concern was in regard to EHR capacities and limitations related to CRC screening and follow-up tracking. Although providers said their EHR systems were successful at keeping track of unscreened patients, with out-of-system referrals, they encountered difficulty tracking patient follow through with scheduled colonoscopies, thus creating potential gaps in care. Furthermore, providers almost universally identified varying levels of limitations in terms of what can be added to EHR platforms. For example, interviewees noted that it would likely be impossible to keep track of the number of people provided with educational materials using their EHR systems and that they would have those types of implementation outcomes in a separate spreadsheet. Furthermore, while clinic personnel were willing to share de-identified data from their EHRs, in many instances, they lacked the technical assistance and/or infrastructure to provide such data. Other provider barriers included time and workload concerns, concerns about the types or availability of educational materials, and the differing methods of follow-up with patients (i.e., some are contacted via phone whereas others are reached via mail). Lastly, providers identified personal preferences for screening modalities, many preferring colonoscopies to stool-based testing. One individual commented, ""We usually offer the colonoscopy first because it's the best, and then if we [can't] get anywhere with … educating them … we go ahead and offer the Cologuard."" Similarly, when asked about the availability of FIT kits, another provider said, ""We can get that to anyone who's not willing to get a colonoscopy."" In other words, clinics indicated they were offering stool-based test options only to those who first refused colonoscopy.Collectively, the findings from these key informant interviews provided a solid foundation for the remaining activities of the project. However, the increase in risk of COVID-19 infections caused a series of changes in the daily operations of the primary care clinics at the geographic, clinic, provider, and patient levels. Due to state mandate, hospitals across Kentucky paused elective procedures, including colonoscopies, resulting in clinics ceasing referrals. The pause in elective procedures also necessitated that many hospitals in Appalachian Kentucky reduce their staff through furloughs and layoffs. Many clinics changed their hours of operation and transitioned to a hybrid model in which most patients were seen virtually through telehealth, whereas other clinics closed altogether for several weeks. Clinics that remained open did not always continue recommending CRC screening at the same rate as before the pandemic due to time concerns and patients' competing priorities. As a result, the investigators changed their approach to working with the clinics and suggested that additional discussions were needed to explore possible adaptations to strategies previously introduced to clinics.After discussions with clinic managers and staff, a collaborative decision was made to pause the project temporarily as investigators and clinic staff accommodated changing priorities and resource allocation due to the COVID-19 pandemic, during which time clinics reduced their focus on screening and experienced significantly lower patient volumes. When investigators and clinic staff agreed it was appropriate and feasible to re-engage in project activities, new priorities emerged based on residual complications from the pandemic, impacting the priority EBIs for clinics. Due to ongoing backlog for scheduling colonoscopies at local/regional endoscopy centers, clinic champions were more open to increasing mailed, homebased stool-based testing efforts as a screening option. The FIT-DNA test (i.e., Cologuard®) was prioritized over FIT as a stool-based option due to Cologuard® requiring fewer clinic resources than FIT. Clinic champions also prioritized provider education, reminders, and assessment and feedback EBIs, as provider screening orders had been greatly reduced over the preceding months due to COVID-19, and they were looking for innovative methods by which they could increase screening recommendations. Additionally, due to the decrease in in-person patient visits, clinic champions were interested in exploring novel interventions to increase annual wellness visits to assist in recovery of CRC screening rates. On the whole, clinics were eager to consider any EBI that could help elevate screening to pre-pandemic levels. At the same time, EBIs involving patient-or provider-oriented printed materials were deemed less appropriate by clinics, with increased focus on digital materials to reduce the need for personal contact in handling physical materials. Changes in clinic screening priorities are summarized in Table 2 .These shifting priorities led investigators to invest in more discussion with clinics about how to change from a ""colonoscopy first"" model to a shared decision-making model in which patients could choose at-home stool-based options if they were not comfortable with colonoscopy wait times or COVID testing requirements prior to colonoscopy. These discussions were guided by National Colorectal Cancer Roundtable guidelines on reigniting CRC screening during COVID-19 [25] and the need to prioritize colonoscopy scheduling for those with abnormal stool tests or other high-risk patient groups.The COVID-19 pandemic resulted in an immediate impact on primary care practices, particularly in rural areas like Appalachian Kentucky. The resulting changes in daily practice and workflow impacted CRC screening immediately and are expected to negatively influence CRC outcomes for a sustained period of time. Nationwide, from April 2019 to April 2020, the number of colonoscopies and biopsies was reduced by 90%, resulting in 1.7 million missed colonoscopies and nearly 19,000 missed or delayed CRC diagnoses between March and June 2020 [25] [26] [27] . These delays in care-combined with reduced access due to temporary closures of primary care clinics, healthcare practitioner furloughs, and pauses in elective or specialty care-are expected to result in over 4500 excess CRC deaths across the next decade [28] . Given that rural areas of the USA, in general, are disproportionately burdened by higher incidence and mortality rates for many preventable cancers [29] , it is likely that residents of Appalachian Kentucky will bear a substantial proportion of the cancer burden related to COVID-19 and its sequelae.One common method used by rural providers to ensure continuity of care is telehealth, as was the case with the clinics in our study. With in-person visits being 30-50% less frequent than pre-COVID-19, telehealth is an encouraged and recommended method of care for appropriate visit types, such as annual wellness visits during which clinicians might normally provide routine screening recommendations [30] . Factors such as the Centers for Medicare & Medicaid Services expanding Medicare telehealth benefits and the Department of Health and Human Services allowing greater flexibility for physicians to see patients using telehealth methods have further supported its use [31] . Nevertheless, barriers persist for providers who use telehealth, including requirements for providers to be licensed in the same state where the patient is located and concerns related to technology [32] . These issues are particularly salient in rural areas where broadband access might be unreliable or unavailable, physical travel is often problematic, or patients may have to travel across state borders to access healthcare-areas of concern to many residents of Appalachian Kentucky. Furthermore, despite nationwide office visit volume remaining low, telehealth use has also decreased to pre-pandemic levels [33] , leading to probable gaps in patient care that are likely to disproportionately affect rural areas. Clearly, to maintain continuity of care and avoid increased cancer mortality rates-particularly for screenable cancers such as CRC-there is a need for innovative policies and solutions.To reduce the burden of excess CRC mortality in Appalachian Kentucky, there are a variety of options available to clinicians, including the use of at-home stool-based tests like fecal occult blood tests (FOBT), FIT, and FIT-DNA for average-risk patients. The use of stool-based tests as a firstline approach for CRC screening is especially important when elective procedures like colonoscopies are either unavailable or backlogged, as is the case in many rural communities. Due to these backlogs, high-risk patients or those with abnormal FIT/FOBT should be given highest patient priority to receive colonoscopies [34] . For research partners working with clinic partners in Appalachia, it is critical they be particularly understanding of clinic and regional challenges to addressing CRC screening and adjust their approaches accordingly [35] , including providing additional flexibility on timelines and project activities as needed. Given that adaptations are common when integrating EBIs into regular practice [36] , researchers should welcome necessary clinic EBI adaptations and evaluate how selected adaptations affect implementation success and organizational capacity [37] . One method to promote successful implementation during rapidly changing situations is by adopting a participatory implementation science approach to promote constant clinic-researcher engagement and allow clinic partners to take the lead in selecting and adapting EBIs they can confidently implement [38] . Members of the academic research team, then, can provide necessary technical assistance and help with tracking adaptations to reduce clinic burden.In this project, clinic staff expressed specific concern with how to continue CRC screening during COVID-19, and they requested additional training to address this concern. One excellent reference for clinicians is the National Colorectal Cancer Roundtable's playbook for reigniting CRC screening during COVID-19 [25] , a document that, among providing many other suggestions, promotes the prioritization of stoolbased screening for patients at average risk for CRC. In our key informant interviews, clinicians noted a preference for colonoscopy and stated they normally only suggested a stool-based test after patient refusal of colonoscopy. While elective procedures remain backlogged, however, research partners should emphasize the need to prioritize stool-based CRC screening for average-risk populations. One way to do so is to share research on FIT and other stool-based tests with clinic partners. For example, one study discovered that patients were more likely to be screened by FIT (34.2%) than colonoscopy (24.6%), while an another noted that 69% of patients who received a choice of stool-based test or colonoscopy were screened, compared to only 38% who were only offered colonoscopy [20, 39] . Given that studies suggest patient preference for stool-based CRC screening, additional research is needed to fully understand provider-side barriers to recommending these tests.Perhaps the most salient lesson from this formative project is confirmation of the need for both flexibility and adaptability when working with primary care clinics in Appalachian Kentucky. Flexibility is required in adjusting project plans to current events like COVID-19 and in adapting intervention strategies to the ""new normal."" Another lesson from this project relates to EHR concerns, as our rural clinics often lacked the infrastructure to produce important data to track proposed project outcomes, such as follow-up of out-of-system colonoscopies. Many rural clinics do not have in-house information technology support and instead rely on consultants. Such situations mean that requests for data require additional expenditures and take more time than would be required with inhouse IT support. Researchers can reduce this barrier by focusing on measurement tools that can be completed easily and will not be burdensome to clinic staff. Finally, in the context of COVID-19, researchers need to consider that clinics are already overburdened and are likely to be even more burdened due to reduced hours, staff furloughs, and in some cases with temporary closing. Given that the effects of COVID-19 are likely to be felt in Appalachian Kentucky for many years to come, researchers should be encouraged to adopt empathetic, flexible, and clinic-driven approaches in their future partnerships.",USA,first author,2021-02-18,02
860e50a620331d7d6263f003e9c10e92dedbfbe6,Community Health Worker National Workforce Study,"The novel severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) causes coronavirus disease 2019 and has spread rapidly worldwide. In the U.S., the COVID-19 pandemic has resulted in serious societal and economic consequences, especially in communities of color, communities with low incomes, and non-U.S. born communities. Early statistics point to COVID-19 disparities in the US, with higher incidence, rates of hospitalization, and mortality among African Americans, Native Americans, and Latinx populations (Centers for Disease Control and Prevention, 2020; Thakur et al., 2020; Webb Hooper et al., 2020) . Reasons for these disparities are complex, but may be related to discrimination, longstanding societal inequities, higher rates of comorbidities, and difficulties accessing healthcare, obtaining information, and physical distancing (Centers for Disease Control and Prevention, 2020; Thakur et al., 2020; Webb Hooper et al., 2020) .The World Health Organization (WHO) is facilitating a multi-level response to the pandemic. The WHO recommends authorities engage with all affected and at-risk individuals through participatory two-way communication. In the U.S., state, tribal, and local governments have been scaling up a workforce to find and test, isolate, and care for individuals diagnosed with COVID-19, as well as identify, trace, quarantine, and support contacts. Effective contact tracing is urgently needed because many people infected with COVID-19 are asymptomatic or pre-symptomatic and may infect others without realizing it. Furthermore, healthcare systems providing clinical care to those affected by COVID-19 need additional support to manage these patients while also managing patients with other conditions. Community health workers (CHWs) and non-clinical patient navigators (NPNs) are critical to the COVID-19 pandemic response. Implemented in many settings globally (Wells and Gordon, 2020), CHWs are defined as ""frontline public health workers who are trusted members of and/or have an unusually close understanding of the community served."" CHWs ""serve as a liaison/link/intermediary between health/social services and the community to facilitate access to services"" and ""build individual and community capacity by increasing health knowledge and self- Often deployed to reduce health disparities, CHWs/NPNs have a flexible scope of practice that includes providing culturally appropriate health education and information; cultural mediation among individuals, communities, and health and social service systems; care coordination, case management, and systems navigation; providing some direct clinical services (e.g., blood pressure measurements), implementing individual and community assessments; and conducting outreach. CHW interventions are effective in improving receipt of breast, cervical, and colorectal cancer screening (Community Preventive Services Task Force (CPSTF), 2020); retention in HIV care (Mwai et al., 2013) ; receipt of pediatric immunizations (Lewin et al., 2010) ; initiation of breastfeeding (Lewin et al., 2010) ; exclusive breastfeeding (Lewin et al., 2010) ; tuberculosis cure rates (Lewin et al., 2010) ; and control of blood pressure, blood glucose, and cholesterol (Community Preventive Services Task Force (CPSTF), 2020).CHWs/NPNs have flexible and transferable skills critically needed across the COVID-19 disease continuum, from preventing SARS-CoV-2 virus spread to reducing the burden of those diagnosed with COVID-19 and living with its health, social, and economic impacts (Figure 1 ).First, CHWs/NPNs can reach communities most at risk for COVID-19. CHWs/NPNs are well poised to work effectively with diverse communities due to their racial/ethnic and linguistic congruence. CHWs/NPNs understand vulnerable communities, networks within the communities, and local systems. This workforce acts as a cultural liaison between ethnic communities and the larger healthcare and public health systems. Therefore, CHWs/NPNs should be engaged by public health and health system decision makers to determine how to best adapt global recommendations and communications for local contexts.Second, the nation's public health organizations already have experience with employing CHWs/NPNs. This will facilitate the hiring of new CHWs/NPNs or the shifting of COVID-19 tasks to established CHW/NPN employees or volunteers. Using their own COVID-19 data, each community or organization (i.e., towns, tribal communities, health clinics) that employs media, news media, messaging applications, websites, podcasts, the Trump administration,Wikipedia, late night comedy shows, friends, and family (Baum et al., 2020) . Those who receive their news from social media, messaging applications, and Wikipedia are at higher risk of believing misinformation and disinformation statements (Baum et al., 2020; Jamieson and Albarracín, 2020) . CHWs and NPNs have been trained in health communication approaches and are well poised to lead participatory community engagement interventions recommended by the WHO, which aim to provide accurate information on risks of COVID-19 and actions people can take to reduce their risk of it.Fourth, public health officials should work closely with CHW/patient navigator associations to scale up the existing and previously trained patient navigation and CHW workforce to find and test, isolate, and care for individuals diagnosed with COVID-19. Across the country, public health agencies have been working to implement National Association of County and City Health Officials (NACCHO) and WHO recommendations to conduct contact tracing of individuals exposed to the virus. However, contact tracing has been difficult to implement effectively for multiple reasons, including a lack of COVID-19 testing, delays providing COVID-19 testing results, and surges in COVID-19 cases.Another reason that public health agencies may be experiencing difficulties with implementing contact testing is their reliance on personnel who have minimal experience with health care delivery, including volunteers, students, and reassigned government workers (Simmons-Duffin, 2020) . Research indicates CHWs have improved the outcomes of tuberculosis contact tracing (Ospina et al., 2012) . In fact, NACCHO explicitly recommends that CHWs perform contact tracing and has suggested at least $3.7 billion in emergency supplement funding be provided to public health agencies to support a workforce of 100,000 contact tracers (National Association of County & City Health Officials (NACCHO), 2020). As of October 2020, 53,116 COVID-19 contact tracers were working nationwide, with 44 states having inadequate personnel (National Public Radio, 2020). Contact tracing requires building trust with a person who has tested positive for COVID-19 to obtain information on those potentially exposed to SARS-CoV-2 and assisting them in quarantining as required by public health agencies.However, a July 2020 survey found that less than half of U.S. adults surveyed were willing to follow all steps of contact tracing: speaking with public health officials, sharing data regarding where they had been and with whom they had close contact, and quarantining for 14 days (McClain and Rainie, 2020) . For communities that historically experience health, social, and economic disparities, reducing distrust of public systems to improve health of communities is a key CHW/NPN function. CHW/NPNs have culturally competent assessment and intervention J o u r n a l P r e -p r o o f skills, often including motivational enhancement strategies, to assist individuals in accessing services and changing behaviors. Contact tracers should also identify and assist cases and contacts with basic needs, a common job responsibility of CHWs/NPNs. Meeting the basic needs of each affected individual and household is critical to support adherence to quarantine recommendations. To manage the impact of the disease, CHWs/NPNs can also provide needed support to those diagnosed with COVID-19.Finally, a 2011 systematic review indicates that CHW interventions were promising in increasing childhood vaccination (Helzlsouer et al., 2016) . As CHWs and NPNs are trusted community members, they may be instrumental in increasing uptake of the COVID-19 vaccines and addressing COVID-19 vaccination hesitancy.While there are many reasons to increase and redirect the CHW and navigator workforce to meet the nation's needs with regard to the COVID-19 pandemic, there are challenges to doing so. The most critical challenge is the financing of this workforce. CHWs and non-clinical patient navigators are funded in a number of ways, including through healthcare system operational costs; private foundations; federal, state, and local grants; managed care models; and fee-for-service models. Continuing federal support for pandemic response could fund the expansion of CHW/NPN efforts. States can also fund this workforce through Medicaid using a number of different approaches (Albritton, 2016) . For example, the Centers for Medicare and Medicaid Services (CMS) allow non-licensed practitioners, including CHWs, to deliver preventive care. States can also pass legislation and obtain an amendment to their state Medicaid plan. State Medicaid plan amendments enable the state to change their Medicaid policies or operational procedures and could be used for reimbursement of a broader range of services provided by CHWs. States are also allowed to improve their Medicaid program through Section 1115 of the Social Security Act. Thus, states could obtain a ""Section 1115 waiver"" to provide services not typically covered by Medicaid (including CHW services) as part of an experimental, demonstration, or pilot program. Finally, states could revise their contracts with managed care organizations (e.g., for Medicaid) to promote uptake of CHW services (Albritton, ",United States,abstract,2021-02-23,02
2563c93c26464613189c79a77f3b4eee37f36494,Airborne aerosol olfactory deposition contributes to anosmia in COVID-19,"0.5-5μm airborne aerosol deposition, as assessed by fluorescence gray value, was significantly higher in the OE than the RE bilaterally, with minimal to no deposition observed in the RE (maximum fluorescence: OE 19.5(IQR 22.5), RE 1(IQR 3.2), p<0.001; average fluorescence: OE 2.3(IQR 4.5), RE 0.1(IQR 0.2), p<0.01). Conversely, larger 30-100μm aerosolized droplet deposition was significantly greater in the RE than the OE (maximum fluorescence: OE 13(IQR 14.3), RE 38(IQR 45.5), p<0.01; average fluorescence: OE 1.9 (IQR 2.1), RE 5.9(IQR 5.9), p<0.01).Our data experimentally confirm that despite bypassing the majority of the upper airway, small-sized (0.5-5μm) airborne aerosols differentially deposit in significant concentrations within the olfactory epithelium. This provides a compelling aerodynamic mechanism to explain atypical OD in COVID-19. COVID-19 represents an extraordinary global health threat with multi-organ sequelae. Olfactory dysfunction (OD) has emerged in the majority of cases and is predictive of milder disease [1, 2] . However, OD in COVID-19 is unlike typical post-viral smell loss in that it occurs largely in the absence of other upper airway complaints [1, 3] . This symptom pattern is consistent with radiographic findings of severe focal olfactory epithelium (OE) inflammation with otherwise normal nasal respiratory epithelium (RE, Fig 1) [4] . The explanation for this selective olfactory involvement remains mysterious as the OE has the lowest expression of angiotensin converting enzyme 2 (ACE2), the SARS-CoV-2 binding receptor, within the entire nasal cavity [5] . A recent open letter from 239 scientists to international public health organizations called for acknowledgement of airborne spread as a potential transmission mode for SARS-CoV-2 [6] with the subsequent recognition by the World Health Organization in a scientific brief [7] . Given the increased emphasis on airborne transmission, we hypothesized that small concentrations of persistently airborne aerosols (those below 5μm) would be more prone to dispersing within the olfactory epithelium than the lower nasal airway. This selective olfactory dispersion of smaller-sized airborne particulate would therefore provide a novel mechanism linking atypical olfactory dysfunction in COVID-19 with airborne transmission. The purpose of this study was to therefore experimentally characterize whether airborne aerosols are capable of selective OE dispersal within the healthy human nasal cavity.The Mass General Brigham IRB approved the IRB Protocol, 2020P-001246. Written informed consent was obtained from all subjects. Participants were healthy subjects between the ages of 25 and 35 without a history of chronic rhinosinusitis, allergic rhinitis, or other rhinologic disease. At the time of data collection, subjects did not have any symptoms of acute sinusitis, rhinorrhea, or subjective nasal obstruction. A Hudson RCI 1883 nebulizer (Teleflex Medical, Morrisville, NC was used to generate smaller sized particulate in the sub 5μm range, classically characterized as a particle size capable of being persistently airborne for extended periods of time and having protracted settling rates. An optical particle sizer (OPS 3330, TSI Inc, Shoreview, MN) was utilized to measure the size distribution of nebulized airborne particulates to ensure that particles in this range were generated. Alternatively, an atomizer was used to generate larger aerosolized particulate, in the 30-100 μm range (MADomizer, Teleflex, Wayne, (NDC17478-404-01 , Akorn, Inc, Lake Forest, IL, USA) in 5mL saline was utilized in both conditions in the respective source of particle generation (nebulizer vs. atomizer). Immediately following 60 seconds of exposure to nebulization or atomization, subjects then underwent rigid nasal endoscopy equipped with a blue light liter for fluorescein visualization (Karl Storz, Tuttlingen, Germany). Digital images were captured of the OE (olfactory cleft, superior middle turbinate) and RE (nasal floor, inferior turbinate) bilaterally, randomized, and provided to a blinded reviewer for image processing using ImageJ (version 2.0.0-rc-69/1.52p). Images were systematically coloradjusted, thresholded, and transformed to 8-bit grayscale for quantification. Maximum fluorescence intensity, average-intensity of non-zero pixels, and standard error of non-zero pixels were calculated, with subtraction of non-fluorescein stained background values. Nebulizer particulate analysis with an optical particle sizer confirmed reliable sub 5μm airborne aerosol generation with a peak of 2μm. Following fluorescein-labeled airborne aerosol inhalation of nebulized particulate, a significantly higher deposition of aerosols were found in the OE than the RE with minimal to no deposition observed in the RE (maximum fluorescence: OE 19.5(22.5), RE 1(3.2), p<0.001, U = 0, n = 10,6; average fluorescence: OE 2.3(4.5), RE 0.1(0.2) p<0.01, U = 3, n = 10,6, Mann-Whitney U test, n = 3 subjects, Fig 2) . Conversely, following fluorescein labeled aerosolized droplet (30-100 μm) inhalation, significantly greater deposition was observed in the RE as compared with the OE (maximum (2.1), RE 5.9(5.9), p<0.01, U = 1, n = 6,6, Mann-Whitney U test, n = 3 subjects, Fig 2A) .Self-reported OD has been widely described in COVID-19 through a variety of case reports [4] , case series [8] and surveys [9] , with a pooled prevalence of 52.7% [2] . The true rate is likely higher as formal smell testing by Moein et al. [8] revealed OD in 98% of COVID-19 positive patients, only 35% of whom self-reported. Using an olfaction survey, Yan et al. [10] found that loss of smell was in fact more highly correlated with COVID-19 positivity than any other systemic or pulmonary symptom. This correlative finding is echoed in a study utilizing a symptom tracker app in the United Kingdom [9] . Yan et al further demonstrated that self-reported OD was associated with milder disease and most often occurred in the absence of other symptoms, unlike typical post-viral OD. This finding was confirmed by Kaye et al, showing unexpectedly low rates of nasal congestion (25%) and rhinorrhea (18%) in a cohort of COVID-19 positive anosmic patients [3] . These results suggest that SARS-CoV-2 exhibits a unique predilection for impacting the OE to the relative exclusion of the remainder of the nasal airway, a feature corroborated by published reports of nasal CT and MRI scans (Fig 1B) [4] .The simplest mechanism for this distinct and isolated OE inflammation would be evidence of SARS-CoV-2 tropism for either the olfactory neurons or the OE itself. The neurotropic hypothesis appears unlikely as olfactory neurons lack both the ACE2 protein and TMPRSS2 gene required for viral spike protein binding and cellular entry [5] . Furthermore the rapidity of recovery [10] and lack of protective effect among females [8] , otherwise common in neuropathic OD, suggest a non-neural etiology. In contradistinction, OE tropism could be explained by the presence of ACE2 within the sustentacular cells which support the olfactory neurons [5] . However, Brann et al. [5] demonstrated that ACE2 expression was actually higher within the ciliated and secretory cells found throughout the remainder of the RE than in the OE sustentacular cells. Therefore, ACE2 avidity alone cannot explain this phenomenon.In the absence of a biologic explanation for atypical OD, our study explored the feasibility of a mechanism of differential particulate deposition. Small-sized, persistently airborne aerosols (less than 5-10μm) are classically understood to bypass the upper airway in favor of alveolar deposition [11] . While our results confirm this effect within the RE, they also reveal that airborne aerosols in fact deposit in appreciable concentrations within the OE. This effect is unique to smallsized airborne aerosols as we found that larger aerosolized droplets (30-100μm) were more likely to deposit in the RE. Based on these distribution patterns, we therefore surmise that against the background of widely distributed ACE2 throughout both the OE and RE, low concentrations of airborne SARS-Co-V will differentially bind to the OE resulting in localized inflammation.As the potential for airborne transmission of SARS-CoV-2 becomes increasingly accepted by the medical community [6, 7] , clues derived from olfactory physiology, objective smell testing, and imaging studies converge around airborne aerosol exposure as an explanation for the widespread, profound, and relatively isolated OD in COVID-19. Our study is limited by a small number of subjects as well as uniformity of ambient conditions; temperature and humidity changes in alternate conditions could also affect intranasal diffusion, sedimentation, or other variables contributing to deposition of particulate. However, in this small number of subjects our data experimentally shows that despite bypassing the majority of the upper airway, smaller airborne aerosols appear to differentially deposit in significant concentrations within the olfactory epithelium. This provides a compelling aerodynamic mechanism to explain the common and relatively isolated olfactory dysfunction associated with the majority of COVID-19 infections.Supporting information S1 Dataset. Raw data of maximum value, mean gray value of non-zero pixels, and standard error of non-zero pixels for each subject and condition. (XLTX) ",United States of America,first author,2021-02-05,02
6afec9646ae6ee176e08bdd8a894f4566bd21e26,"Journal Pre-proof Thrombo-inflammatory Biomarkers in COVID-19: Systematic Review and Meta- analysis of 17,052 patients Thrombo-inflammatory Biomarkers in COVID-19: Systematic Review and Meta-analysis of 17,052 patients","As coronavirus disease 2019 continues to spread across the world, there is accumulating evidence supporting the relative contribution of specific comorbidities and laboratory patterns among severely affected patients necessitating intensive care admission or resulting in mortality . The US Food and Drug Administration recently approved remdesivir for the treatment of suspected or laboratory-confirmed COVID-19 in hospitalized patients with severe disease [defined as patients with oxygen saturation ≤ 94% on room air or requiring supplemental oxygen or requiring mechanical ventilation or requiring extracorporeal membrane oxygenation (ECMO) 57 ]. A 10-day course has been approved for COVID-19 infected patients who require invasive mechanical ventilation and/or ECMO and a 5-day course for patients not requiring mechanical ventilation and/or ECMO 56 . With the availability of potential treatment, the identification of clinical and laboratory predictors of severe disease is urgently needed to further risk stratify patients and optimize the allocation of medications to improve clinical outcomes. Earlier meta-analyses have evaluated such predictors; however, at the time of their publication, limited data were available, reducing the confidence in their conclusions. Moreover, the data available at the time of prior meta-analyses were exclusively from China, where the COVID-19 infection initially spread. These analyses combined data from multiple studies with overlapping populations and could not account for any racial/ethnic differences in the thromboinflammatory milieu [76] [77] [78] . We hypothesized differences in thrombo-inflammatory milieu according to disease severity and race/ethnicity. The aim of the current systematic review and meta-analysis was to 1) compare the differences in comorbidities and thrombo-inflammatory biomarkers between patients with severe COVID-19 infection/death due to COVID-19 infection and mild COVID-19 infection, and 2) assess the relative contribution of race/ethnicity in the J o u r n a l P r e -p r o o fThis systematic review was performed according to Cochrane Collaboration guidance and the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) statement 79 . The study was exempt from institutional review or ethical board review due to no access to patient-level data.We searched PubMed, The Cochrane Library, EMBASE, EBSCO, Web of Science, and CINAHL databases from January 1, 2020 through July 11, 2020. We included prospective or retrospective studies that compared severe or fatal COVID-19 infection with mild COVID-19 infection or COVID-19 survivors. The search strategy is included in the supplementary appendix 1. All references of the retrieved articles were reviewed for further identification of potentially relevant studies. The identified studies were systematically assessed using the inclusion and exclusion criteria described below.Two reviewers (RC and JG) independently selected the studies and abstracted data on study characteristics, design, reported comorbidities, laboratory parameters, and reported clinical outcomes. Discrepancies between the two reviewers were resolved by discussion and consensus.The final results were reviewed by the senior investigators (WEW and RDM) (Figure 1) . The eligibility criteria were (1) hospitalized patients ≥18 years comparing severe/non-survivor COVID-19 positive patients vs. non-severe/survivor COVID-19 patients; (2) reported biomarkers of inflammation and/or thrombosis. Studies of pregnant women (due to inherent J o u r n a l P r e -p r o o f changes in markers of thrombo-inflammation during pregnancy) and reports with incomplete reporting of biomarkers were excluded. Abstracts, case reports, conference presentations, editorials, reviews, expert opinions, and literature published, not available in English, were excluded.Severe COVID-19 was designated when the patients had one of the following criteria: groups, e.g., critical vs. mild illness, were chosen for analysis. The acute cardiac injury was determined if serum levels of cardiac biomarkers (e.g., troponin I) were above the 99th percentile upper reference limit, or new abnormalities were shown in electrocardiography and/or echocardiography.Assessment of risk of bias for each study was performed using the Newcastle-Ottawa scale for cohort studies 80 . This tool addresses the domains of patient selection, comparability of groups, and outcome assessment.We used the random-effects model to pool results across studies and estimate the weighted mean difference (WMD) and odds ratio (OR). We evaluated heterogeneity of effects using the Higgins I-squared (I 2 ) statistic with heterogeneity defined as I 2 <25% as non-significant heterogeneity, between 25%-50% as mild heterogeneity, between 50%-75% as moderate heterogeneity and >75% as high heterogeneity. We evaluated the assumption of combining data from patients with severe disease with non-survivors and combining non-severe disease data with survivors, by doing each analysis separately. We also compared the results of studies with patients from China vs. other locations. A two-tailed p < 0.05 was considered statistically significant. Meta-analysis was performed using the Comprehensive Meta-Analysis software Table 1 andWe deemed all the studies to be at a high risk of bias due to unadjusted analyses and variability in groups with comorbidities and prognostic factors.Among demographics, patients in the severe/non-survivor group were significantly older compared to non-severe/survivor group (64.4±7.5 years vs. 52.5±9.1 years), a greater proportion were men (64.8% vs. 53.5%), and there was a high prevalence of hypertension (44.7% vs. 22 .6%), diabetes (28.3% vs. 15.9%), cardiac or cerebrovascular disease (23.1% vs. 7.5%), chronic kidney disease (8.5% vs. 3.3%), chronic liver disease (5.1% vs. 3.5%), malignancy (9.9% vs. 6.9%) and, chronic obstructive pulmonary disease (8.5% vs. 3%) compared to nonsevere/survivor group. As expected, the severe/non-survivor group had higher mortality (32.3% vs. Sensitivity analysis was performed by separating disease severity from survivorship.Thus, a separate analysis was done comparing severe vs. non-severe disease, and another analysis compared survivors to non-survivors. In general, both analyses provided similar conclusions (Table 2) . Additionally, the weighted mean differences in thrombo-inflammatory biomarkers were compared between studies conducted in China (n=60) and other countries (n=15) to address the overlap of the study population in the published studies from China ( Table   1 ). The non-Chinese population had a higher comorbidity burden, including hypertension, diabetes, cardiac or cerebrovascular disease, chronic kidney disease, and chronic obstructive pulmonary disease. Otherwise, results were similar in the two populations (supplementary appendix table 5). Also, there were significant differences between the groups in the weighted mean difference for platelet count, fibrinogen level, and hs-Troponin I. The difference in Ddimer levels between the severe/non-survivor and the non-severe/survivor groups was more pronounced in the non-Chinese population. In contrast, the difference between the two groups in Chinese patients) with only 15 studies from other countries. Among the included studies, the non-Chinese study participants had a higher prevalence of comorbidities, including hypertension, diabetes, cardiac or CVD, CKD, chronic liver disease, and COPD. Also, the difference in the Ddimer levels between the severe/non-survivor and the non-severe/survivor groups was more pronounced in the non-Chinese population. In contrast, the difference between CRP levels was more pronounced in the Chinese population (Table 3) . It can be hypothesized that a difference in the comorbidity burden and thrombo-inflammatory milieu between the East Asians, Caucasians, and African Americans could be contributory to the higher case fatality noted in Europe and the United States. However, due to the limited published literature from other countries, our J o u r n a l P r e -p r o o f confidence in these estimates is low. It remains to be determined if racial differences in thrombo-inflammatory milieu affect COVID-19 outcomes.This study has several limitations. In our analysis, we combined the sub-groups of severe COVID-19 with non-survivors which could lead to potential confounders. We addressed the confounders by performing a sub-group analysis comparing severe vs. non-severe COVID-19 and non-survivor vs. survivors and the results were consistent with the main analysis ( Table 2) .Additionally, the included studies had heterogenous populations with differing burden of comorbidities and not all outcomes were available in all included studies. This was reflected in the Higgins I-squared (I 2 ) statistic with 57% reflecting significant heterogeneity and 29% reflecting moderate heterogeneity in the analyzed biomarkers. Another confounder was that majority of the studies were Chinese with potential overlapping populations artificially amplifying the effect of certain comorbidities and biomarkers (multiple studies reported from the same hospital, Table 1 ). To address this limitation, WMDs among thrombo-inflammatory biomarkers were compared according to the country of origin of the study, i.e., Chinese versus non-Chinese (supplementary appendix table 5). However, due to lacking data from non-Chinese countries, definite conclusion could not be drawn about the differential weightage of comorbidities and biomarkers among racial/ethnic groups. As literature continues to increase, it would be imperative to identify the potential role of genetics in the prevalence of poor clinical outcomes among African Americans and Caucasians compared to East Asians. Another caveat in the available data was that the values of D-dimer (concerning units of measurement) were significantly varied in reporting between studies, and several papers misreported the measuring unit making the values 1000 times smaller or higher 105 . While performing the analysis, these values were adjusted to reflect appropriate differences between the two groups. Additionally, J o u r n a l P r e -p r o o f significant heterogeneity between studies coupled with the high risk of bias (due to unadjusted analyses and unbalanced groups) reduces the confidence in the interpretation of the results.Publication bias is also highly likely in a field that primarily consists of small unregistered observational studies.Thrombo-inflammatory biomarkers (D-dimer, Fibrinogen, CRP, hs-CRP, ferritin, and IL-6) and indicators of cardiac damage (hs-Troponin I) on admission were associated with the severity and mortality with COVID-19 infection. Comorbidities conferring higher risk coupled with thrombo-inflammatory biomarkers might assist in the development of risk prediction models for the severity and prognosis of COVID-19. Such models could potentially aid in the selection of population to receive early therapeutic strategies, e.g., remdesivir therapy and improve clinical outcomes. ",USA,first author,2021-02-08,02
5dad110aa86b655c46542ad56c3e04acb0b7c628,The Initial Months of COVID-19: Dog Owners' Veterinary-Related Concerns,"The American Veterinary Medical Association (AVMA) disseminated a survey in April 2020 to US veterinary practice owners to better understand how COVID-19 had affected their practice (1) . The survey included questions about operational changes, client numbers, use of personal protective equipment, and financial impact-and found that all of these areas were significantly impacted by COVID-19. One of the areas most impacted was daily operations. Responding to the need for social distancing, most veterinary hospitals implemented curb side care, with clients waiting in their vehicles while their pet was treated inside. Many hospitals were forced to cancel or limit their appointments and new protocols (and resultant expense) related to the increased need for sanitation and personal protective equipment (PPE) were implemented. The initial financial repercussions were significant, in part due to dramatic decreases in client visits, which resulted in substantial cash shortages. The sudden and serious onset and impact of COVID-19 left pet owners and veterinary professionals alike struggling to find reliable scientific information about the pandemic and its possible impact on humans and animals alike.The rapid new findings related to COVID-19 and the efforts to obtain and report accurate, reliable information is ongoing. The Center for Disease Control and Prevention (CDC) published the Interim Infection Prevention and Control Guidance for Veterinary Clinics Treating Companion Animals (2) in April 2020 and has continued to update it several times. The report is intended to help veterinary clinics ""facilitate preparedness and ensure that practices are in place to help people and animals stay safe and healthy."" The information is focused on how veterinarians can adjust their protocols in regards to optimum human safety. There is no mention of pet owners' concerns.Another recent survey assessed how emergency veterinary hospitals were responding to . Even with the CDC's suggestions regarding procedural strategies (2) , this study found significant variation in how veterinary hospitals interpreted and implemented these suggested policies. Some hospitals continued to provide emergency care, but others that were not able to provide care referred cases back to the owners' primary care veterinarian or provided minimal treatment with additional monitoring by the owner. These hospitals also reported dealing with issues of safety protocols, shortages of staff, and financial impact.Although both of these surveys (1, 3) documented important information that remains critical in adjusting veterinary care to meet client and patient needs during a pandemic, the only item on either of these surveys pertaining to clients' COVID-19 related concerns was about the possible transmission of COVID-19 between humans and animals in the AVMA survey. The impact of the necessary procedural changes on clients (e.g., curb side care, canceling appointments, limiting surgeries) was not addressed. Likewise, questions such as ""What do I do if I have an emergency with my pet? What if I can't find a veterinarian open? What if my pet needs special medication and I cannot access veterinary care?"" were left unanswered.One of the first studies pertaining to veterinary clients' perspective was conducted by Banfield Pet Hospital (4) . In this study, a sample of 1,000 dog and cat owners responded to a range of questions regarding how their personal well-being and concerns about their pets' health has been impacted by COVID-19. Eighty-four percent of respondents reported feeling more attuned to their pet's health, and 37% report paying more attention to their pet's care. Other recent studies have reported similar concerns in the United States as well as Spain and the United Kingdom (5-7).These findings, in addition to the changes within the veterinary field, suggest that COVID-19 has impacted pet owners in many critical areas, yet the subject remains unexplored. Understanding the impact of COVID-19 on pet owners can help veterinary professionals best address their clients' concerns and needs during a pandemic.The purpose of our survey was to better understand dog owners' fears and concerns pertaining to veterinary care and obtainment of pet care products and food during the lock down phase of a pandemic to be better prepared to address these concerns now and in the future. Because dog owners may have unique concerns, in comparison with other companion animals, the decision was made to limit this study to dog owners. A subsequent separate study was initiated for cat owners. To this end, we developed an online, anonymous, cross-sectional survey using Qualtrics (Qualtrics, Inc., Provo, UT, USA). The survey was designed, reviewed, and tested by the co-investigators and their colleagues (veterinary and social science professionals) after seeking input from dog-owning representatives from the community. The survey was pilot tested for ambiguity and/or potentially missing or inappropriate response options, with revisions made based on the results of the pilot testing. The final survey and study design were approved by the Colorado State University Institutional Review Board (IRB # 20-10003H). Survey respondents were recruited through social media outlets and human animal focused organizations (e.g., Facebook dog focused groups, Human Animal Interaction Section of American Psychological Association, etc.) between March 30, 2020 -May 1, 2020.In order to maximize our understanding of the impact of COVID-19, dog owners at least 18 years of age from any country were encouraged to participate with the recognition that countries' veterinary services (within countries as well as between) might be impacted differently. Demographic data were collected (e.g., age group, gender, country of residence, current level of COVID-19 restrictions, number of adults, children and dogs living in the home). Respondents were asked to indicate their social support before COVID-19 and at the time they completed the survey and the psychological impact of having dogs during COVID-19 restrictions (analyses of these items are not included in this paper). Additionally, they were asked about changes in how much time they spent with their dog (in general, actively engaged, and walking). Next, they were asked about their perception of any potential changes in the bond they have with their dog before COVID-19 and currently with two bond rating questions that asked them to rate their bond with their dog on a scale from 1 (not at all bonded) to 10 (extremely bonded). Potential changes in owners' perceptions of dog behaviors were assessed with two questions. The first question asked owners to indicate, 1 month before the COVID-19 outbreak, how frustrated they felt about their dogs' undesirable behaviors on a scale from 1 (minimal/no frustration) to 10 (extremely frustrated). They could also select ""no undesirable behaviors."" This question was followed with a similar question asking owners to rate their current level of frustration.The next section of the survey included questions related to veterinary care and non-veterinary dog related concerns using a 4-point Likert scale (no concern to great concern). Veterinaryrelated questions included level of concern about their ability to afford veterinary care (emergency and non-emergency both now and in the future) and concern about the availability of their veterinarian for emergency and non-emergency issues. The next set of questions pertained to dog supplies (affordability and access), caretaker concerns, and zoonotic risks. These included the ability to afford or acquire dog food/supplies now or in the future, a caretaker for their dog if they themselves became ill or were unable to play/exercise with them, and whether the virus could be passed between dog and owner. They were also asked to indicate their concern about their ability to keep their dog due to COVID-19 changes.Owners were asked if they had designated a caretaker in case they were unable to care for their dog. The next set of questions asked about their veterinary care experiences during COVID-19 restrictions. Lastly, we asked about their past experience and future plans for volunteering for an animal shelter/rescue organization.Data were analyzed using SPSS Version 25 (IBM, Armonk, NY, USA). Descriptive statistics were calculated to characterize current attitudes and patterns in dog care during COVID-19 restriction times. Paired t-tests were used to assess changes in bond score and frustration level with behaviors from 1 month before COVID-19 to ""current"" time. Associations between demographic variables and concern related questions were investigated using Kruskal-Wallis nonparametric analysis of variance. Significance level (α) was set at p = 0.05 and all tests were two-tailed.The total number of responses to the survey was 4,105. At the time of this survey, most participants reported restrictions in their city at the level of ""all non-essential stores/businesses closed and ordered/strongly recommended to stay at home"" (3, 197 , 77.9%) followed by ""all non-essential stores/businesses closed but no order to stay at home"" (724, 17.5%). A small number reported ""some stores/businesses closed"" (151, 3.7%) or ""no restrictions"" (17, 0.4%) or ""other"" (1, 0.4%). Most participants were from the US (3,313, 80.7%); followed by Canada (355, 8.7%), UK (177, 4.3%), and Australia (64, 1.6%); 194 (4.7%) were from other countries including Brazil (29, 0.7%), Germany (12, 0.3%), Ireland (12, 0.3%), Norway (21, 0.5%), South Africa (12, 0.3%) and <10 responses from a wide array of other countries.When queried about number of people and dogs in the home, the most common response for number of adults in the home was two (2,533, 61.7%), followed by one (872, 21.2%). The majority of participants did not have children under the age of 18 living at home (3,305, 80.5%), followed by one child (423, 10.3%). Most participants owned one dog ( The survey questions pertained to both the bonding activities with their dogs, as well as veterinary-related concerns. In this article we are only presenting the veterinary-related concerns; however, it is important to note that 72.1% of respondents indicated they spent more time with their dogs, 64.3% reported increased time spent actively engaged with their dogs, and 55.2% reported that they felt a strengthened bond with their dog.Potential Availability of Emergency and Non-emergency CareParticipants were asked to indicate their level of concern with several veterinary issues (n = 3,996). The issues of most concern were whether their veterinarian would be available if they needed them for emergencies and non-emergencies ( Table 1) . Participants under 30 years of age, compared to older owners, were significantly more concerned about their ability to afford emergency veterinary care in the future and non-emergency veterinary care now. They were also more concerned that their veterinarian will not be available if they needed him/her for both non-emergencies and emergencies. Additionally, the increased amount of concern by owners under 30 years of age regarding their current ability to afford emergency care, when compared to older owners, approached statistical significance (p = 0.059).Participants were also asked to indicate their concern level with several animal, non-veterinary-related issues (n = 3,996). The areas of most concern were the ability to play/exercise their dog or obtain a caretaker for their dog if they contracted COVID-19 ( Table 2) .Participants under 30 years of age, compared to older owners, reported more concern about their ability to afford dog food/supplies now and in the future, and the zoonotic risks of COVID-19 (passed from owner to dog and from dog to owner). Participants 60 years of age and older reported higher concern, compared to younger owners, about acquiring a caretaker for their dog if they contracted COVID-19 and the ability to keep their dog because of COVID-19 related changes. The ability to exercise/play with their dog if they contracted COVID-19 was of high concern for participants 18-29 years old and participants 60 years of age and older when compared to participants between the ages of 30-59.Participants were asked if they had identified someone who could care for their dog if they, as owners, became sick (n = 3,969), to which 2,357 (59.4%) reported yes. Participants 50 years of age and older were more likely to report identifying a caregiver, compared to younger owners [X 2 = 60.69 (4) Some concern No/minimal concern NA/not an issue Great concern Some concern No/minimal concern NA/not an issue were to become ill (n = 3,969), 643 (16.2%) reported ""yes, "" 3,124 (78.7%) reported ""no"" because they had not been asked, and 92 (2.3%) reported ""no, "" they had been asked, but could not commit to this responsibility. Participants 50 years of age and older, when compared to younger owners, were more likely to report agreeing to care for someone else's dog, [X 2 = 33.53 (12), p = 0.001].Participants were asked if their dog had required veterinary care since the COVID-19 outbreak to which 887 (22.3%) reported yes. Of those who said they required veterinary care, the majority reported taking their dog to a veterinarian (709, 79.8%). Those who reported going to the veterinarian were asked to indicate all the reasons for the veterinary visit(s). The most common reasons were vaccinations, monitoring an illness/disease or wellness exam. The numbers for each type of visit are listed in Table 3 .Participants were asked about the procedures in place when they visited their veterinarian (n = 696). The largest percent reported they were met in the parking lot and not allowed inside the hospital (398, 57.2%), followed by allowed in both the reception area and exam room (179, 25.7%) and then allowed in reception area only (51, 7.3%). Most of the ""other"" responses (68, 9.8%) reported that the protocols changed over time and they had experienced more than one protocol.Lastly, participants were asked to describe their most recent veterinary visit experience since the COVID-19 outbreak, during a time where, in most instances, humans were not allowed in the clinics. Several pertinent issues emerged. The most prominent theme reflected participants' concerns regarding their inability to be present with their dog in the veterinary clinic. This was most evident during a euthanasia situation, for example, ""Had to put dog down. Sad that I could not hold her. She died alone."" Dog guardians felt the need to be with their dog to support and take care of them and experienced stress as a result, even with a procedure as benign as a nail trim. One participant noted, ""(Vet) is great because she communicates so well via email and I know that (dog) loves going there. She even texted pictures during this acupuncture appointment."" Other concerns revolved around participants' own worries about their dog's physical and emotional well-being: ""Waited in car while vet took my dog from my car to the clinic. Dog experienced greater anxiety with this protocol."" Importantly, some of the more intense concerns were mitigated by the attention, responsiveness, communication and transparency of the veterinary staff. For instance, ""Put my heart dog to sleep and had a wonderful support by my vets."" Many participants were appreciative of their veterinarian's communication pertaining to COVID-19 transmission risks and the extra safety precautions their hospitals implemented: ""The receptionist invited us into the clinic while reassuring me that everything had just been sterilized. I was This study was conducted during the initial months of the COVID-19 pandemic, when the majority of people were in ""lockdown"" mode, meaning that they were instructed or at least strongly recommended to stay at home and all non-essential stores/businesses closed. This situation was unprecedented, resulting in a great deal of anxiety and uncertainly about the future. This anxiety encompassed all areas of daily living, so it is not surprising that dog owners felt significant concerns related to providing for their dog, nor the fact that these concerns have been expressed by other dog owners in the United States as well as Spain and the United Kingdom (5-7). It is noteworthy that the top concern of dog owners during this time was the availability of their veterinarian for both emergency as well as non-emergency care. This concern was felt most strongly by dog owners 18-29 years of age. Even though veterinary services were classified as essential and therefore permitted to remain operating, it appears this did little to assuage dog owners' fears. These first months were a time in which veterinary hospitals were quickly developing new protocols during a time of limited COVID-19-related information and knowledge. Certainly, these owners' concerns were not unfounded, as veterinary clinics struggled with how to safely offer care. It took hospitals time to develop what is currently being utilized by most veterinary clinics-""curb side"" care-in which clients remain outside in their cars while their pets are treated inside. Although far from ideal, this protocol has allowed veterinary clinics to continue operating with limited human to human contact. Perhaps because younger owners have grown up in a time period when nearly all services and products are consistently and reliably available (and almost instantly), they were more impacted by these initial uncertain times.One lesson that might be gleaned from these initial months and owners' fears is the need for communication. Results from this study further document the invaluable relationship these respondents have with their dog(s) and, hence, how important it is for veterinarians to understand this relationship and the need for owners to be assured they have access to veterinary care during these times, and that their dogs will be well cared for, regardless of COVID-19 restrictions. While hospitals were struggling to implement new protocols, it is unknown how many of them were regularly reaching out to keep their clients informed. Communication of this type does not have to be overly complicated or time consuming but should utilize several communication modes. For example, the use of veterinary clinic mobile apps, text messages and Instagram might be best suited for communicating with younger pet owners, while Facebook and phone messages might work better with older clients. Sending frequent messages, regardless of modality, might help decrease owners' concerns regarding veterinary clinics' availability. As COVID-19 cases continue to rise, or future instances of radical change that necessitate societal restrictions occur, this need to ease owners' concerns will likely only increase.Another major area of concern reported by dog owners during this time was the ability to afford veterinary care and dog supplies. Again, these fears were most pronounced for dog owners younger than 30 years of age, which contradicts research that has suggested that younger pet owners are more willing to pay higher costs for veterinary services when compared to owners 50 and older (9) . It is possible that these results are due to the employment impact of COVID-19 felt by younger Americans.While COVID-19 resulted in large numbers of people losing their jobs, the impact disproportionally affected younger workers, many of whom work in service sector jobs (i.e., retail, food and drinking establishments) (8) . Strategies to help owners afford the care they need for their dogs include the offering of wellness plans, CareCredit, and pet insurance. Owners who are concerned about affording pet supplies could be directed to local pet food banks/pantries. Communicating and publicizing these local services can help clients feel their veterinary hospitals are concerned about all aspects of their pets' well-being.Another aspect of pets' care pertained to plans for one's dog if the owner became ill. Owners expressed considerable concern about how they would be able to play with and exercise their dog if they became ill. This concern was felt most by owners younger than 30 years of age as well as those 60 years and older. A related concern was the ability to obtain a caregiver for their dog if they became ill. This concern was stronger for older owners compared to younger owners. While veterinary clinics cannot directly provide services to meet these needs, acknowledging and validating these fears is important and could be conveyed through blogging about these topics as well providing information about available resources (e.g., dog day care, dog walkers, etc.). Areas of less concern were owners' fears of giving or contracting COVID-19 to/from their dog. This finding is encouraging, suggesting that owners were able to access trustworthy news sources and were able to receive accurate information about these potential risks.It is critical to note that although many owners express concerns related to caring for their dog if they become ill, only 60% had identified a caretaker. Even for owners 60 and older, this percentage (68%) still leaves a considerable number of dogs at potential risk. In addition, the majority (78%) indicated they had not been asked to care for someone else's dog, yet it was higher for participants 50 years of age and older when compared to younger owners. Perhaps this is due to younger owners having children in the home, other responsibilities or being away from home more than older dog owners. The reasons for these age differences warrants further study. Veterinary teams can positively impact both owners and their dogs by proactively asking owners if they have designated a caretaker. This could be as simple as adding a question to the intake/admission form (and explaining the importance of doing so). In this way, it does not have to take any additional appointment time. In terms of veterinary care during the initial months of COVID-19, it is noteworthy that even with all these additional stressors and distractors people experienced during this time, nearly 25% said they needed veterinary care and the majority (80%) of these people reported visiting their veterinarian to get the care they needed. The fact that this percentage varied among countries (e.g., from 24% in the US to 13% in the UK) is worthy of future study.In summary, this study has limitations inherent in online surveys including the potential bias of those who chose to participate. It was only available to dog owners who had access to the internet and the participants were largely female, so care should be taken when generalizing to other populations. This study was also completed during the beginning months of COVID-19, so we do not know how the continued restrictions have impacted peoples' lives and experiences with their dog. Future research could include a longitudinal design to see how people's experiences have evolved over time. We also did not include veterinarians, so a survey, or interviews, that included veterinarians could give insight into some of the challenges they have faced in responding to their clients' needs. A factor that was not considered was income level. Owners with lower incomes have fewer resources and/or options for pet veterinary care and supplies. This is likely exacerbated by the pandemic, only adding more stress for pet owners.For the surveyed population however, the results suggest that these dog owners remained true steadfast ""guardians"" (defined as ""someone who defends and protects"") of their dogs. During the first months of COVID-19, while the world was in turmoil and the future uncertain, the care and well-being of their dogs remained a high priority. As the pandemic unfolds, it is hoped that veterinary hospitals continue to evolve their protocols and communication techniques to best partner with dog owners; thereby serving the needs of these guardians and their companions.Veterinarians, like many other professions, were significantly impacted by the onset of COVID-19 in the spring of 2020. Standard practices such as routine animal checkups and surgeries were disrupted, and veterinary clinics and hospitals had to quickly modify standard protocols to safely serve their clients and patients. The purpose of this article is to present the findings of a survey given to dog owners during the initial lockdown phase of COVID-19 to better understand dog owners' veterinary related concerns during this time. Implications and suggestions for the veterinary field, as well as suggestions for future research, are discussed.The raw data supporting the conclusions of this article will be made available by the authors, without undue reservation.The studies involving human participants were reviewed and approved by Colorado State University Institutional Review Board. Written informed consent for participation was not required for this study in accordance with the national legislation and the institutional requirements.LK and PE conceived the study. LK, PE, JC-M, CB, and WP conducted the research and wrote the manuscript. All authors contributed to the article and approved the submitted version.",United States,abstract,2021-02-02,02
80b09379cb51d44c501c14bfc10fd4077b9c5a85,Intention to receive a COVID-19 vaccine: Results from a population-based survey in 1 Canada 2 3,"33 key populations report a lower intention to vaccinate, there is a need for in-depth education and 58 support for these communities to ensure optimal uptake. 59Keywords 60• COVID-19 61• Vaccine hesitancy 62• Vaccine confidence 63• Vaccine 64• Canada 65The development of safe and effective COVID-19 vaccines is a critical step in ending the 68 pandemic. 1, 2 Vaccine programs have commenced, with multiple phase 3 vaccine trials 69 suggesting very promising efficacy, and recently published data of the Pfizer vaccine showing 70 95% protection against COVID-19. 3, 4 Global health authorities including the World Health 71Organization (WHO) 5 and the American Committee on Immunization Practice 6 have provided 72 guidance for vaccine roll-out globally with the acknowledgment that initial vaccine supply will be 73 limited. In Canada, the National Advisory Committee on Immunization (NACI) has identified 74 priority populations for initial vaccine roll-out, including populations at high risk for severe 75 COVID-19 related illness; those most likely to transmit COVID-19 to those at high risk; those 76 essential to maintaining the COVID-19 response; those who contribute to the maintenance of 77 essential services; and those living or working in conditions that put them at higher risk for 78 infection. 7 Participants could also opt-in to receive an at-home SARS-CoV-2 research antibody test (data 109 collection ongoing and will be reported separately). Ethical approval was received from The 110University of British Columbia Research Ethics Board (H20-01421). 111 112In bivariable analyses, those who were older (>60 years), males, had chronic health conditions, 202were essential health care workers, had more than a high school education, or had two adults in 203 the house were significantly more likely to intend to receive the COVID-19 vaccine (p≤0.05). 204Individuals who were essential non-health care workers, identified as non-white, South Asian or 205 of Indigenous ancestry were significantly less likely to intend to receive vaccination (p≤0.05). 206Given there were only 52 non-binary, GenderQueer, Agender, or Two-spirit respondents, sex, 207 not gender, was used in the model. In multivariable modeling, individuals who were older (>60 208 years) were more likely to intend to receive the COVID-19 vaccine (Table 2) All items in the TPB scale had good to strong agreement (Cronbach's alpha>0.6) and were 218 included in the analysis (Table 3) . A descriptive analysis of male (n = 605) versus female (n = 219 4,178) respondents was completed for the TPB scale and the WHO VHS scale (Table 4 ). In 220 bivariable modeling, all responses in the WHO and TPB scales were significantly different in 221to them would think they should receive the COVID-19 vaccine, and would expect them to 228 receive the vaccine (p < 0.001). Participants intending to be vaccinated were also significantly 229 more likely to report greater influence of indirect social norms, including the opinions of family (p 230 < 0.001), their family physician or primary healthcare provider (p = 0.03), and the Provincial 231To support COVID-19 vaccine implementation, this study investigated intention to receive the 235 COVID-19 vaccine and determine predictors of COVID-19 vaccine uptake of adults living in BC. 236This study included a population of individuals who were recruited from large health research 282 cohorts, and has a higher percentage of respondents who identified as female, white, with more 283 than high school education, and were more likely to live in the southern part of the province 284 compared to the general population of BC. 30 While we had a lower than expected response rate, 285there was no observed differences in age distribution between the responders and non-286 responders. 287288Our study shows that while the majority of respondents intend to receive the COVID-19 vaccine, 290",Canada,abstract,2021-02-05,02
1e750141c45375346cacb618ac444212bf44d748,0123456789) 1 3 Maternal and Child Health Journal,"Previous research on pregnant women has found that natural disasters can have consequential effects on the health of women and their newborns due to increased stress and disruptions in access to social support and care. The COVID-19 pandemic adds a new level of stress to women in the perinatal period as symptoms of anxiety and depression are heightened by social distancing measures and fear of the virus. This commentary focuses primarily on the potential impacts that the COVID-19 pandemic could have on the mental health of pregnant and postpartum women in the United States. It also presents some of the actions that governments and health care systems are taking or could take to expand the ways in which mental health care is delivered, which could spur new ways to provide mental health support to a group that was underserved prior the pandemic.COVID-19 has had a devastating worldwide impact on physical health and on the economy. But we are only beginning to acknowledge the powerful impact of this pandemic on mental health. Symptoms of anxiety and depression are heightened by fear of the virus, social distancing, financial effects and other ramifications of a loss of normality and structure. Many are managing their fear by avoiding risky places, including healthcare facilities. There is one group, however, that cannot practice such avoidance: pregnant women. Labor and delivery is one of the few medical procedures that cannot be postponed. Hospitals have all had to change procedures in response to the pandemic, including limiting or even banning all visitors (including fathers, doulas, and other social supports for laboring women) (Centers for Disease Control and Prevention 2020b; Preston 2020). In India, laboring women even had to visit the police to obtain a 12 h pass before being allowed to approach a hospital (DHNS 2020). The United States Centers for Disease Control and Prevention (CDC) at first recommended temporarily separating infected women from their newborns (Centers for Disease Control and Prevention 2020a; Rodriguez 2020). As evidence emerged, however, including CDC studies showing a low rate of transmission from infected women to newborns and an overall decrease in preterm birth during the pandemic (Berghella et al. 2020; Zambrano et al. 2020) , other bodies, including both the WHO and the American Academy of Pediatrics, have now recommended full rooming-in with hand hygiene and mask wearing (American Academy of Pediatrics 2020; World Health Organization 2020). As these fears receded, however, additional concerns arose, both about increased risk for severe illness in pregnant women with COVID and increased rates of preterm birth in infected women (Centers for Disease Control and Prevention 2020b; Woodworth et al. 2020) .For healthy women, these circumstances can be overwhelming and may lead to new symptoms of anxiety. For the one in five women who suffer from perinatal mood and anxiety disorders (Gavin et al. 2005) , they may be crippling. When the whole country is consumed with thoughts of ventilators, inadequate personal protective equipment, and political wars about masks and vaccines, it's easy to forget that childbirth even outside a pandemic can be dangerous. This is especially true for women of color, with Black women already dying at three times the rate of white women in the U.S. and Black communities and Latinx communities now disproportionately affected by COVID-19 (Evelyn 2020; Martin and Montagne 2017; Vahidy et al. 2020) . Social support is a crucial factor in healthy pregnancy and in the postpartum period, with its lack associated with increased rates of preterm birth and postpartum depressive symptoms (Hetherington et al. 2015; Surkan et al. 2006) . With suicide as a leading cause of death for women in the first year postpartum even at the best of times (Shadigian and Bauer 2005) , what happens when health care systems' attention turns even further away from this vulnerable population?Mental health treatment has changed radically in the last nine months since the beginning of social distancing precautions. At our hospitals, outpatient psychiatry has shifted entirely to telehealth (Johns Hopkins Medicine 2020). Partial hospital programs for more severely ill patients are now virtual, and at UNC the first inpatient psychiatry service dedicated to perinatal women, which one of us directs, closed temporarily in the face of an overwhelming need for hospital beds. As physicians treating pregnant women in this setting, we have heard from many of our patients that they feel isolated at home, without the usual supports of extended family, and our office staff have reported that many women who call for initial appointments have later cancelled or postponed because they fear meeting a new provider over a video connection (or in some cases do not have internet access). This isolation is especially problematic in communities also facing job losses, food insecurity, dense housing and neighborhoods, and increased rates of intimate partner violence (Taub 2020) . The result for women will likely be higher stress and lower rates of treatment -and we know from previous natural disasters that these pregnancies will be at higher risk of preterm birth and these children will be at higher risk of developmental and psychiatric disorders (Franzek et al. 2008; Harville et al. 2010; McLean et al. 2018) . We are already seeing increased rates of almost 40% with clinically relevant symptoms of depression and almost 60% with clinically relevant symptoms of anxiety (Lebel et al. 2020) . This is only the beginning as the social and psychologic effects continue, but also as we better understand the effects of infection with COVID-19 itself and the impacts of Posttraumatic Stress Disorder.What can we do? State medical boards, the Drug Enforcement Administration (DEA), and Medicaid and Medicare have made a good start by loosening regulatory requirements for telehealth provision and reimbursement (U.S. Department of Health and Human Services 2020), but they (and commercial insurers) need to acknowledge the extra time needed and improve reimbursement for remote mental health treatment. Hospitals and health systems need to think creatively about how to enable healthcare teams to support patients that have even higher amounts of stress. Neighborhoods and local institutions should extend and develop support networks to include pregnant women and those suffering from mental illness, not just the elderly. Women and their families can work to maintain existing social support networks, by video or phone or drive-by visits conducted from six feet away. And research is urgently needed to understand the impact that added stress and immune system reactions to the virus will have on this generation of perinatal women and their children.While the challenges are many, there is opportunity as well -to harness the expanded power of internet connectedness to reach this vulnerable group. Convincing depressed postpartum women to show up to the hospital with their newborns has always been a struggle, a struggle that is even greater for low-income women who may lack childcare or access to transportation. With our expanded capacity for video and telephone visits, we may have found a new way for previously reluctant women to access care. Programs such as NC Maternal Mental Health MATTERS represent a growing number of states that have perinatal mental health consultation lines that provide provider-toprovider consultation, telehealth assessments for patients, and resource and referral (Kimmel 2020) . NC MATTERS has seen a dramatic increase in its use during the pandemic. Let's take that as a silver lining and think of other ways to use our altered norms to improve care not only now but for the future of women, their children, and their families.Author Contributions All authors participated substantively to the paper and have approved the final version of the manuscript.Funding Dr. Osborne's work is supported by NIMH K23 MH 110607. Dr. Kimmel's work is supported by NIMH K23 MH110660-01. Dr. Surkan received no financial support for the research, authorship, and/ or publication of this article.Conflict of interest The authors declare no potential conflicts of interest with respect to the research, authorship, or publication of this article.None of the content is included in another manuscript, has been published previously, or is currently under consideration for publication elsewhere.",USA,first author,2021-02-04,02
b2ca881f798185a6f57d3faf76ad43759b05ceed,The differential impact of the COVID-19 epidemic on Medicaid expansion and non-expansion states,"examined the consequences of this nationwide split in Medicaid design on the spread of the COVID-19 epidemic between the expansion and nonexpansion states. Our study shows that, on average, the expansion states had 217.56 fewer confirmed COVID-19 cases per 100,000 residents than the non-expansion states [-210.41 ; 95%CI (-411.131) -(-2.05); P<0.05]. Also, the doubling time of COVID-19 cases in Medicaid expansion states was longer than that of non-expansion states by an average of 1.68 days [1.6826; 95%CI 0.4035-2.9617; P<0.05]. These findings suggest that proactive investment in public health preparedness was an effective protective policy measure in this crisis, unsurpassed by the benefits of COVID-19 emergency plans and funds. The study findings could be relevant to policymakers and healthcare strategists in non-expansion states considering their states' preparations for such public health crises.We added information on the at-risk adults as a share of all adults ages 18 and older. We preferred to use this measure rather than the total population size in light of the literature's current consensus that not all age groups are equally vulnerable to COVID-19 14, 15, 16, 17 .We included the number of community health centers' delivery sites as a proxy of the state's primary care capacity to the underserved populations. 17 We also had information on the length of active stayhome orders as a proxy of the respective state's epidemic containment policies' stringency.Finally, we controlled for the proportion of surveyed population always wearing masks. We obtained this data from the New York Times survey in July 2020. 18, 19 Methods:We applied a multi-step model to investigate the research hypothesis.Descriptive statistics:The public health layout differed in the non-expansion states from that in the expansion states. On average, the non-expansion states had a relatively higher ratio of the hospital and ICU beds to their population than the Medicaid expansion states. Yet, the non-expansion states also had a larger uninsured population and fewer primary care Community Health Centers delivery sites than the expansion states.Compared to the expansion states, the non-expansion states mandated stay-home orders for a shorter average period. Also, non-expansion states' residents' compliance to wearing masks was not as substantial as residents in the expansion states. (Table 2 ) The demographic profile of the two groups of states was comparable but slightly different. In 2019, non-white racial minorities in non-expansion states made 33.6% of the population, compared to 32% in expansion states. The largest minority in non-expansion states was African Americans, 15%, followed by Hispanics, 11%; while the largest minority in expansion states was Hispanics, 12.6%, followed by African Americans, 9.2%.In conclusion, this study confirms that Medicaid expansion states were in a better public health position for crises like the COVID-19 epidemic. While after-the-fact federal assistance could have helped many uninsured, its benefit was not a full replacement to public health preparedness in terms of expanded insurance coverage. Further scientific inquiry will be needed to investigate further the Medicaid expansion elements that most helped the expansion states collectively outperform their non-expansion counterparts.This study has several limitations. First, widespread COVID-19 screening was not evenly available through the study period. It is possible that the case records early in the epidemic are not entirely indicative of COVID-19 spread. Second, we included some, but not all, of the epidemic containment state policies, and we did not add a measure of the stringency of enforcement of these local measures in the respective states. Third, we included one measure of primary care capacity, the number of community health centers' delivery sites.Still, there are other capacity elements like the number of primary care offices and registered general practitioners. Fourth, the analyses did not include the states' financial standings that could play into a state's decision of embracing Medicaid Expansion or not.Finally, the study is descriptive and did not divulge into the causality underlying the findings.",USA,first author,2021-02-25,02
e48c38b0bebe2c4714757fb8bdd83e5ad2fa24ef,Paroxysmal hypothermia and hyperhidrosis with exacerbation after COVID-19 Infection,"Six months later she presented with severe fatigue, cough, muscle ache, joint pain, and fever (39.5 °C). Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) was positive using real-time polymerase chain reaction from a nasopharyngeal swab collection. The patient was diagnosed with mild COVID-19 infection. Outpatient treatment was conservative and symptoms resolved slowly over 3 weeks. During the acute phase of the COVID-19 infection, periods of hypothermia alternated with fever for 4 days. After the recovery phase, however, episodic hyperhidrosis and hypothermia persisted without fever despite the use of clonidine. The patient experienced several episodes of profound hypothermia, all triggered by minimal exertion (e.g., cleaning the house). The dose of clonidine extended-release was increased to 0.1 mg twice daily, which led to complete resolution of the symptoms.Shapiro syndrome is a rare disorder defined clinically by recurrent hyperhidrosis and hypothermia and radiologically by agenesis of the corpus callosum [1] . The variant form refers to the phenotypic Shapiro syndrome without the corpus callosum abnormality [2] . The pathophysiology of Shapiro syndrome remains poorly understood and may be in part related to hypothalamic dysfunction without structural lesion [1] . Pharmacotherapy with different mechanisms of action may provide symptomatic benefit, suggesting involvement of various neurotransmitters [3] .SARS-CoV-2 is a novel coronavirus responsible for COVID-19. Acute infection has been associated with various neurological manifestations possibly related to endothelial inflammation, cytokine storm, immune reaction, or direct invasion of the central nervous system by the virus [4] . Persistence of symptoms after the acute phase of the infection is not rare; many long-haul COVID patients experience orthostatic intolerance, tachycardia, brain fog, persistent fatigue, and subjective change in body temperature [5] .The hypothalamus is part of the central autonomic network and plays a key role in thermoregulation. In Shapiro syndrome, episodic hyperhidrosis is thought to be related to paroxysmal central sympathetic dysregulation, which could explain the benefit of sympatholytic agents such as clonidine [2] . There is evidence that SARS-CoV-2 can lead to hypothalamic dysfunction via direct invasion of the virus and/or reactive inflammation with the olfactory tracts as a port of central nervous system entry [6] . The hypothalamus and associated regions have been shown to express the angiotensin-converting enzyme 2 and transmembrane proteinase, serine 2, which mediate SARS-CoV-2 cellular entry [6] . It can be hypothesized that in the present case, COVID-19 infection, either directly or via cytokine-induced release of prostaglandin E2 from endothelial cells acting via paracrine mechanisms, could have exacerbated dysfunction in the medial preoptic area containing warm-sensitive neurons, triggering excessive sweating and thus hypothermia, exacerbating the preexisting symptoms of variant Shapiro syndrome [7] .Further studies are needed to investigate the possible involvement of the hypothalamus and central autonomic network in COVID-19 infection. ",USA,first author,2021-02-02,02
545e6a9ed0a3ec42b8f27a15099d710800fe0fd8,0123456789) 1 3 World Journal of Pediatrics,"The coronavirus disease 2019 has led to a global pandemic with significant morbidity and mortality [1] . The pediatric population appears to be affected in a much smaller number than adults, with only 1.7% of cases in the United States occurring in children younger than 18. In other European countries, the number of cases in children is less than 2% [2] [3] [4] . Currently, it is unclear whether this is due to lower infection susceptibility in children or if the asymptomatic disease is much more common in those under the age of 18 [5, 6] .Significant numbers of children and teenagers who tested positive for COVID-19 antibodies have developed a severe inflammatory condition with many Kawasaki disease characteristics [7] . As case reports pile up, the world is suddenly paying attention to this pediatric condition that may be related to COVID-19 [8] . This condition is named ""multisystem inflammatory syndrome in pediatrics"" which shares many features with Kawasaki disease and toxic shock syndrome [9, 10] . Kawasaki disease is a rare acute pediatric vasculitis. It usually involves small-to mediumsized arteries in various organs and tissues and can cause coronary artery aneurysms, myocardial infarction, and pericarditis [11] . It is characterized by fever, exanthema, lymphadenopathy, conjunctival injection, and changes to the mucosa and extremities. Kawasaki disease is relatively uncommon, with an incidence rate of 20.8 per 100,000 in the United States, mainly in children aged 5 years or younger [12] . Unexpectedly, published reports of illness like ""multisystem inflammatory syndrome in pediatrics"" occurring in China are lacking, with most reports of hospitalized COVID-19 children in China indicating that their illness is not severe [13, 14] . The etiology of the multisystem inflammatory syndrome remains unknown; however, antigen-driven delayed immune reaction following viral infection in genetically susceptible individuals is the current leading hypothesis [11] . In the last two decades, the coronavirus family has been proposed to be one of the Kawasaki-like syndrome triggers. Human New Haven coronavirus (HCoV-NH) was identified in the respiratory secretions of 72.7% of children with Kawasaki disease [15] , and positive CoV-229E antibodies were detected by immunofluorescence assay in patients with Kawasaki disease [16] , eliciting a putative link with COVID-19 disease. Verdoni et al. described an outbreak of a Kawasakilike disease occurring in Bergamo, Italy, at the peak of the COVID-19 pandemic [17] . As of May 21, other suspected or confirmed children of similar presentations have been reported throughout the United States [18] . This Kawasaki-like disease appears to cause a hyperinflammatory shock state. Hypotension with a requirement for fluid resuscitation seems to be common [19] . Some patients required inotropic support. In addition, patients with this syndrome appear to respond well to intravenous immunoglobulin. However, the disease course seems more severe than the typical Kawasaki disease as adjunct anti-inflammatory treatments were necessary for several patients, with some requiring high-dose corticosteroids. The use of biologics, such as infliximab, has also been described [17, 20] .Despite these findings, much remains unknown about this rare Kawasaki-like disease (i.e., multisystem inflammatory syndrome in pediatrics). Some children have needed intensive care unit (ICU), others recovered quickly. The goal of this meta-analysis was to summarize the clinical and laboratory features of patients with the multisystem inflammatory syndrome in pediatrics diagnosed during the COVID-19 pandemic.This current meta-analysis was carried out according to the Preferred Reporting Items for Systematic reviews and Meta-analysis (PRISMA) statement [21] . Relevant literature was retrieved from Web of Science, PubMed, Scopus, and Science Direct search engines up to June 29, 2020. Our search strategy included the following terms: (""Novel coronavirus 2019"", ""2019 nCoV"", ""COVID-19"", ""Wuhan coronavirus,"" ""Wuhan pneumonia,"" or ""SARS-CoV-2"") and (""Kawasaki-like disease"", ""Kawasaki-like syndrome"", ""multisystem inflammatory syndrome"", ""pediatric inflammatory syndrome"", or ""pediatric inflammatory, multisystem syndrome""). Besides, we manually screened out the relevant potential article in the references selected. The above process was performed independently by three participants.No time or language restriction was applied. Inclusion criteria were as follows: (1) types of studies: retrospective, prospective, observational, descriptive or case-control studies reporting COVID-19 patients with the multisystem inflammatory syndrome; (2) subjects: diagnosed patients with COVID-19; (3) exposure intervention: COVID-19 patients diagnosed with reverse transcription-polymerase chain reaction (RT-PCR)/antibody testing, radiological imaging, or both with the principal criteria of the syndrome (i) patients < 21 years presented with (ii) persistent fever ≥ 38.0 °C for ≥ 24 hours or report of subjective fever lasting ≥ 24 hours, (iii) severe illness leading to hospitalization, (iv) laboratory evidence of inflammation, including, but not limited to, one or more of the followings: an elevated C-reactive protein (CRP), erythrocyte sedimentation rate (ESR), fibrinogen, procalcitonin, D-dimer, ferritin, lactic acid dehydrogenase (LDH), or interleukin-6 (IL-6), elevated neutrophils, reduced lymphocytes and low albumin, (v) multisystem organ involvement (i.e. involving at least two systems), and (vi) laboratory-confirmed SARS-CoV-2 infection (by RT-PCR or antibody test during hospitalization) or an epidemiologic link to a person with Covid-19 [22] . In addition, according to the center for disease control and prevention, any pediatric death with evidence of SARS-CoV-2 infection, and if individuals fulfill full or partial criteria for Kawasaki disease but meet the case definition for multiple inflammatory syndrome, they should be considered as having this syndrome. The Kawasaki disease signs and symptoms that might be associated with the multisystem inflammatory syndrome include bilateral conjunctival injection, oral changes such as cracked and erythematous lips and strawberry tongue, cervical lymphadenopathy, extremity changes such as erythema or palm and sole desquamation, and polymorphous rash [23] . Lastly, (4) outcome indicators: the mean and standard deviation or median and interquartile range for COVID-19-related complications and mortality.The following exclusion criteria were considered: (1) case reports, reviews, editorial materials, conference abstracts, summaries of discussions, (2) insufficient reported data information; or (3) in vitro or in vivo studies.Two investigators (RME and RM) separately conducted literature screening, data extraction, and literature quality evaluation, and any differences were resolved through a third reviewer (MHH). Information was extracted from eligible articles in a predesigned form in excel, including the last name of the first author, date and year of publication, journal name, study design, country of the population, and sample size. Variables were stratified into eight categories: demographic data, Kawasaki-like disease features, other clinical presentations, comorbidities, hospitalization, laboratory measurements, SARS-CoV-2 screening, and medications.All data analyses were performed using OpenMeta[Analyst] [24] and comprehensive meta-analysis software version 3.0 [25] . First, a single-arm meta-analysis for laboratory tests was performed. The mean or untransformed proportion and 95% confidence intervals (CI) were used to estimate pooled results from studies. A continuous random-effects model was applied using the DerSimonian-Laird (inverse variance) method [26, 27] . Heterogeneity was evaluated using Cochran's Q statistic and quantified using I 2 statistics, representing the total variation across studies beyond chance.Articles were considered to have significant heterogeneity between studies when the p value less than 0.1 or I 2 > 50%. Finally, publication bias was assessed using a funnel plot and quantified using Begg's and Mazumdar rank correlation with continuity correction and Egger's linear regression tests. Asymmetry of the collected studies' distribution by visual inspection or P value < 0.1 indicated obvious publication bias [28] .The flow chart summarizing the literature search of this meta-analysis study is illustrated in Fig. 1 . A total of 261 articles were recorded using 5 major online databases (Web of Science, PubMed, Scopus, ScienceDirect, and MedRxiv) till June 29, 2020. After inspection of the retrieved records, 73 articles were removed due to duplication, and 188 records were recognized. Upon screening the title and abstract, our team excluded various articles, including case reports (n = 28), review articles (n = 37), irrelevant reports (n = 42), or editorial items (n = 63). A final of 18 records was appraised for eligibility, with 3 records excluded for no sufficient data. Eventually, a total of 15 eligible reports were identified for the quantitative assessment of this metaanalysis, with 15 records characterized single-arm analysis.The main characteristics of the included records in this metaanalysis are demonstrated in Table 1 [17, 20, [29] [30] [31] [32] [33] [34] [35] [36] [37] [38] [39] [40] . The articles published online from May 6 until June 29, 2020, included five records from France [Paris (5) ], five records from the USA [New York (4), and Pennsylvania (1)], four records from UK [London (2) , and Birmingham (2)], and one record from Italy [Bergamo (1)]. A total of 318 children with a pediatric inflammatory, multisystem syndrome (Kawasaki-like disease) associated with SARS-CoV-2 infection were registered in this meta-analysis. Nine records were retrospective studies, another two were prospective studies, while descriptive case series accounted for four studies.Our meta-analysis included 318 COVID-19 patients presenting with the multisystem inflammatory syndrome. Their mean age was 9.10 years (95% CI 8. 49 Young patients underwent confirmatory tests for COVID-19 disease by either RT-PCR of nasopharyngeal swab (proportion = 46.5%, 95% CI 12.9-80.1%) or anti-SARS-CoV-2 IgG analysis (proportion = 69.6%, 95% CI 48.9-90.2%) ( Table 2 ). For the clinical criteria of the multisystem inflammatory syndrome and Kawasaki-like features, fever (proportion = 82.4%, 95% CI 69.8-95.1%) and polymorphous maculopapular exanthema (proportion = 63.7%, 95% CI 53.8-73.5%) were the most frequent principal features, followed by changes of lips and oral cavity (proportion = 58.1%, 95% CI 38.6-77.6%) and bilateral non-purulent conjunctival congestion (proportion = 56.0%, 95% CI 40.0-71.9%). Changes of peripheral extremities (proportion = 40.7%, 95% CI 12.9-68.5%) and acute nonpurulent cervical lymphadenopathy (proportion = 28.5%, 95% CI 13.9-43.1%) were the least presenting features ( Table 2 ). Children presented more often with gastrointestinal symptoms including abdominal pain, nausea, and diarrhea (proportion = 79.4%, 95% CI 68.1-90.7%) and shock (proportion = 68.1%, 95% CI 51.9-84.3%). Neurocognitive symptoms as headache, irritability, lethargy, or visual change were reported in 31.8% of patients (95% CI 21.9-41.8%), while the prevalence of respiratory symptoms as cough and dyspnea accounted for 29.6% (95% CI 19.6-39.6%) ( Table 2) . Obesity (proportion = 26.0%, 48-233.87 ). There was an increased evidence for coagulopathy represented as a high blood concentration of fibrinogen (mean = 6.24 g/L, 95% CI 4.68-7.80) and D-dimer (mean = 3.79 μg/mL, 95% CI 2.57-5.02) ( Table 2 ).The random-effects model was applied. Association measure: pooled mean (M) was estimated for quantitative variables and untransformed proportions (P) were calculated for categorical events; I 2 : the ratio of true heterogeneity to total observed variation; publication bias: assessed by Egger's test. CI confidence interval; BMI body mass index; Gastrointestinal symptoms included vomiting, diarrhea, and abdominal pain; Neurocognitive symptoms included headache, irritability, lethargy, vision change; Respiratory symptoms included cough and dyspnea; ECG electrocardiogram; PICU pediatric intensive care unit; NT-proBNP N-terminal-prohormone B-type natriuretic peptide; CK creatine kinase; LDH lactate dehydrogenase; ALT alanine aminotransferase; AST aspartate aminotransferase; CRP c-reactive protein; ESR erythrocyte sedimentation rate; WBCs white blood cell counts; RT-PCR reverse transcription-polymerase chain reaction; Ig immunoglobulins; Anti-TNF anti-tumor necrosis Intravenous immunoglobulins and steroids were given in 87.7% (95% CI 80.8-94.7%) and 56.9% (95% CI 33.6-80.2%) of the children. Anticoagulants were utilized in 67.0% (95% CI 47.6-86.3%) of pediatric patients. Anakinra (Anti-IL-1) was prescribed in only 9.4% (95% CI 4.6-14.2%) of cases (Table 2 ).Pediatric patients have largely been overlooked during the COVID-19 pandemic, as the largest cohort of morbidity and mortality has come in elderly adult populations [41] . More recently, the insidious connection between COVID-19 infections and a syndrome similar to Kawasaki disease has been investigated as healthcare professionals noticed outbreaks of the rare constellation of symptoms throughout the United States and the world [39] . The context of these reports is essential as officials weigh the risks of reopening schools with the pandemic ongoing, and physicians are treating pediatric patients with severe inflammatory responses. The association of Kawasaki-like disease to coronaviruses is still a continuous area of research, and the COVID-19 pandemic provides a unique opportunity to investigate the connection of coronavirus infection to a pediatric inflammatory response that mimics Kawasaki disease. The COVID-19-associated multisystem inflammatory syndrome patients tended to be much older than typical Kawasaki disease patients. A large sample of Korean Kawasaki disease patients showed a mean age of just 2.54 years compared with 9.10 in this meta-analysis [42] . This finding is especially important because children with onset of Kawasaki disease aged nine or older are at a significantly higher risk of developing coronary artery aneurysms and left ventricular abnormalities; a feared outcome is up to 25% of untreated children [43] . Older age may be one of many factors in the multiple inflammatory syndrome that contributed to such high proportions of patients experiencing shock and hypotension, along with elevated troponin and BNP levels.Although the cardiac manifestations of Kawasaki disease typically resolve within two years, the long-term effects of an inflammatory response in Kawasaki disease are not fully known, with microvascular changes and intimal thickening proposed as possible sequelae [44] .Patients in this meta-analysis presented with many typical symptoms of Kawasaki disease and several atypical ones. A previous study on Kawasaki disease risk factors for developing coronary artery aneurysms showed that having more of the typical five symptoms is a protective factor. At the same time, atypical presentations are a risk factor [45] . Although the patients in our analysis who developed multisystem inflammatory syndrome in pediatrics met the typical criteria defined by the centers of disease control and prevention [22] , nearly half of them had Kawasaki disease-like clinical features as polymorphous maculopapular exanthema, oral mucosal changes, and/or conjunctival injections, cervical lymphadenopathy, or peripheral edematous changes to extremities. Notably, some of these features are also seen in other severe disorders like toxic shock syndrome, which impact multiple systems and have been associated with other viruses. Unlike Kawasaki disease, cases presented with the specified syndrome were children and adolescents older than 5 years of age and had more frequent cardiovascular involvement [18] .In addition, atypical gastrointestinal and neurocognitive symptoms are frequent and may have contributed to delayed recognition of the children's condition as an inflammatory disease similar to Kawasaki disease, thus delaying intravenous immunoglobulin administration. Abnormal electrocardiograms and chest X-rays are also common findings on admission for the multisystem inflammatory syndrome. The differences between this clinical picture and Kawasaki disease will likely lead to delays in treatment that could be detrimental to patients. It will be necessary for pediatric tertiary care centers to stay apprised of the evolving presentation of this inflammatory illness. A patient's number of symptoms correlated with a lower risk of coronary artery aneurysms. A possible explanation for this is that more Kawasaki like symptoms led to earlier suspicion for inflammatory disease, causing there to be less delay in administering treatments like intravenous immunoglobulin. Another possibility is that dysfunctional immune systems are less likely to produce as many classic disease symptoms [45] .The massive inflammatory response to infection with COVID-19 is a significant point of focus for research, novel therapeutic developments, and vaccine research trials. Pediatric patients in this meta-analysis had markedly elevated inflammatory markers, including C-reactive protein and procalcitonin, previously associated with an increased risk of coronary artery aneurysms in Kawasaki disease [45] . About 69.6% of the patients in this meta-analysis tested positive for SARS-CoV-2 IgG antibodies, a higher number than tested positive for the nasal swab polymerase chain reaction, supporting the etiopathology of this syndrome in that a COVID-19 infection weeks earlier could trigger the syndrome and hemodynamic shock.Many of the laboratory findings in this pediatric population were consistent with findings in adult patients who developed severe respiratory disease from SARS-CoV-2. Elevated lactic acid dehydrogenase, D-dimer levels, procalcitonin levels, troponin I level, and lymphopenia have been demonstrated as markers of worse outcomes in adult COVID-19 patients [46] . IL-6 has been associated with the ""cytokine storm"", or macrophage activation syndrome-like disease thought to be a factor in developing acute respiratory distress syndrome in adult patients [47] . IL-6 also plays a role in the pathogenesis and, more recently, targeted therapy of childhood inflammatory disorders like systemic juvenile idiopathic arthritis [48] . Similarly, children who developed multisystem inflammatory syndrome in this meta-analysis had remarkably high IL-6 levels with a mean of 189.67 pg/ mL, exhibiting the role of systemic inflammation. Further research could evaluate whether immunomodulatory therapies like tocilizumab (considering the potential acceleration of the coronary artery aneurysm formation reported previously) [49] , in addition to intravenous immunoglobulin, could be useful for pediatric patients at risk of developing progressing to multisystem inflammatory syndrome.One of the limitations of this meta-analysis was that the studies were conducted in the United States and Europe. East Asian countries, which historically have higher rates of Kawasaki disease, have pediatric populations that have had longer COVID-19 exposure times, and retrospective studies could be helpful to assess differences in prevalence and outcomes. This region is also known to have different phylogenetic SARS-CoV-2 genomes, which could influence the inflammatory response seen in multisystem inflammatory syndrome patients [50] . In addition, differences in infection rates, host factors, including racial differences, immunomodulators early treatment, or incomplete reporting, should be considered [22] . Second, in the absence of a comparison group and the presence of considerable heterogeneity across studies, caution is warranted in interpreting the current data.The findings presented in the meta-analysis have important implications worldwide, as many countries still struggle with COVID-19, and hotspots put children at risk for infection. More research into the pathophysiology of multisystem inflammatory syndrome is needed to understand how it differs from Kawasaki disease. It could also begin to provide an idea of why some children experience shock and hypotension, while others have less acute complications. In addition, comparing relative rates of coronary artery aneurysms in multisystem inflammatory syndrome versus Kawasaki disease would help medical decision making. In addition, future meta-analyses that consider comparing Kawasaki disease with/without COVID-19 cases would be far more interesting to clarify the clinical differences between these overlapping entities.Although multisystem inflammatory syndrome still appears to be a rare occurrence in COVID-19 positive children, it has become clear that this syndrome requires aggressive medical management with a multidisciplinary team and close, long-term follow-up. Recognizing the atypical presentation of the multisystem inflammatory syndrome, monitoring patients for cardiac and renal decompensation, and early interventions to treat the exaggerated immune response in these patients are critical to prevent further morbidity.Author contributions MHH, RME, EAT, JD, and MSF contributed to study design. MHH, RME, RM, and NS contributed to the systematic search, screening, and data abstraction. MHH, RME, and EAT contributed to statistical analysis. MHH, RME, MSF, and EAT contributed to data interpretation. MHH, RME, AK, ST, MSF, and EAT contributed to writing the first draft. All the authors revised and approved the manuscript.Funding There is no funding source.Ethical approval This article does not contain any studies with human participants or animals performed by any of the authors.",USA,first author,2021-02-20,02
59e7ba81b5f2de893b89f8d4b4893aead608a691,"Characterization of SARS-CoV-2 RNA, Antibodies, and Neutralizing Capacity in Milk Produced by Women with COVID-19 Clinical Science and Epidemiology","T he global spread of severe acute respiratory coronavirus 2 (SARS-CoV-2), the causative agent of coronavirus disease 2019 (COVID- 19) , has led to concerns over mother-tochild transmission, including via breastfeeding. Several studies have reported the presence of SARS-CoV-2 RNA in human milk (1) (2) (3) (4) , whereas others have not (5-9) (see Table S1 in the supplemental material). Most previous studies are limited because they followed only a few participants, were cross-sectional, and/or failed to adequately report how milk was collected and/or analyzed. Thus, some uncertainty remains regarding whether human milk is capable of transmitting SARS-CoV-2 from mother to infant.This paucity of rigorous methodology combined with inconsistency of viral RNA detection across studies has led to conflicting and changing recommendations regarding temporary separation of infants from mothers with COVID-19 and regarding whether infants should nurse directly at the breast or receive expressed milk from a bottle (10) (11) (12) (13) . Alongside the uncertainty about the risks of breastfeeding in the context of maternal COVID-19, it is well established that breastfeeding reduces the risk of a myriad of short-and long-term infectious and noninfectious conditions (14) . Further, even a short delay in initiation of breastfeeding can interfere with the establishment of lactation (15) and increase risks of infant morbidity and mortality (16) (17) (18) .Many of the health-promoting effects of breastfeeding are due to the provision of passive immunity via immunoglobulins and other bioactive factors (e.g., lactoferrin), and previous studies have shown that milk-borne antibodies are produced in response to viral infection (19) (20) (21) (22) . However, few studies have examined the presence of antibodies to SARS-CoV-2 in human milk (23, 24) . In one recent study, milk from 12 of 15 women who either had a laboratory-confirmed SARS-CoV-2 infection or were presumed infected with SARS-CoV-2 contained IgA that was reactive to the receptor binding domain (RBD) of the SARS-CoV-2 spike protein (24) . Milk from all 15 women contained higher levels of IgA that was reactive to the full spike protein than milk collected prior to December 2019 (prepandemic). Serologic reactivity of antibodies in serum samples collected from healthy individuals and those infected with non-SARS common cold coronaviruses (ccCoVs) with SARS-CoV-2 have also been reported (25) . This cross-reactivity is thought to stem from homology of the S2 domain of the spike (S) and nucleocapsid (N) proteins. The extent to which milk-borne antibodies have cross-reactivity to ccCoVs and whether these cross-reactive antibodies neutralize SARS-CoV-2 are currently not known (26) .The primary objective of this study was to determine whether SARS-CoV-2 can be detected in milk produced by, and on the breast skin of, women recently diagnosed with COVID-19 utilizing rigorous collection and analytical techniques. We also quantified anti-SARS-CoV-2 IgA and IgG in milk and the capacity of milk to neutralize SARS-CoV-2. Because subclinical mastitis has been associated with higher viral loads in milk (27) , we also documented sodium-to-potassium ratios (Na/K) in milk, a biomarker of subclinical mastitis.Participants and samples collected. Eighteen women with a recent diagnosis of laboratory-confirmed COVID-19 participated in the study. On average, women were 34.2 6 4.7 years old and 6.8 6 7.8 months postpartum. Additional characteristics of study participants and their infants are presented in Table 1 . Of the 18 participants, all but three had symptoms related to COVID-19, with the most common being loss of smell/taste (11/18) , headache (10/18), and fatigue (7/18) (Fig. 1A) . Two of the three participants who were asymptomatic throughout the course of the study were initially tested for routine surveillance prior to being admitted to the hospital for labor and delivery (participants L and M), while the other (participant N) was tested due to a potential occupational exposure. Within this cohort six infants were tested for COVID-19, two of whom had a positive result (infants of participants F and J). In both these cases, additional household members had confirmed positive COVID-19 tests. Among the four infants with negative COVID-19 tests (infants of participants E, I, L, and P), there were no additional household members with positive COVID-19 tests. Most infants (83%, 15/18) appeared well with no clinical signs of illness. Among the three infants with signs of COVID-19, one (participant A's infant) had a case of diarrhea that resolved the same day; one (participant J's infant and one of the two infants with a positive COVID-19 test) had a fever, cough, nasal congestion, low reactivity/appetite, and rash; and one (participant B's infant) had a fever, cough, and sneezing and was irritable. Interestingly, the other infant with a positive COVID-19 test did not have any signs of illness. By the end of the study period, all infants' signs of illness had subsided.We collected and analyzed 37 milk samples (Fig. 1B) . Repeated samples were collected from 14 participants. Among women with clinical signs and/or symptoms of COVID-19 at enrollment or who developed them during the study, 6 provided samples before onset or within the first week of signs/symptoms, with the earliest sample collected 2 days prior to symptom(s) onset. This participant was initially tested for COVID-19 because of a close family exposure even though she was not currently symptomatic. Across all participants, the first sample was collected on average 12.0 6 8.9 days after onset of signs and/or symptoms. Breast swabs were collected from 15 women, although participant F collected swabs prior to breast cleaning and then after milk collection (rather than before milk collection) (see Table S2 in the supplemental material).SARS-CoV-2 RNA and Na/K in milk. None of the milk contained detectable SARS-CoV-2 RNA. RT-qPCR findings were not modified by the milk fraction tested (i.e., whole milk or supernatant), and results were concordant between laboratories. Milk Na/K ratios ranged from 0.2 to 10.9 (0.5, median) with 12 (36%) samples having an elevated ratio (.0.6), suggesting subclinical mastitis in 9 participants.SARS-CoV-2 RNA on breast swabs. Of the 70 swabs tested, eight had evidence of SARS-CoV-2 RNA (Table S2 ). One swab collected prior to breast washing tested conclusively positive with threshold cycle (C T ) values of ,40 in both duplicates for both the N1 and N2 targets. Two additional swabs collected prior to breast washing had detectable signal in both duplicates for one of the SARS-CoV-2 targets, but only one duplicate for the other target. Five swabs had detectable signal in just one duplicate for one target. Anti-SARS-CoV-2 IgA and IgG in milk. Of the milk samples tested, we found that 76% (26/34) contained SARS-CoV-2-specific IgA and 80% (22/27) contained SARS-CoV-2-specific IgG. Concentrations of anti-SARS-CoV-2 IgA were consistently higher than those of IgG ( Fig. 2A) . Milk produced by women with COVID-19 had higher anti-RBD IgA and IgG concentrations than milk collected from women before the pandemic (P = 0.00013 and P = 0.03, respectively). This pattern was also evident for anti-spike S2 subunit (S2) and antinucleocapsid (N) IgG (P = 0.00093 and P = 0.021, respectively), but not IgA. There were no significant differences in IgA and IgG to the full-length S proteins of ccCoV 229E and IgA to those of OC43 between milk produced by women with COVID-19 and milk produced before the pandemic. Milk produced by infected mothers, however, contained higher levels of IgG to OC43 (P = 0.049) than did prepandemic milk. Concentrations of IgA to SARS-CoV-2 antigens correlated well with ccCoV antigens, suggesting significant cross-reactivity of antibodies to ccCoV spike protein and SARS-CoV-2 S2 fragment (Fig. 2B ). The correlation was particularly high in milk produced by women with COVID-19 and between spike proteins, suggesting that IgA to SARS-CoV-2 S2 was also reactive to ccCoVs' spike proteins and may be a recall response from prior exposure to ccCoVs.Neutralizing capacity of milk. A total of 21 of 34 milk samples (62%) collected from women with COVID-19 were found to neutralize SARS-CoV-2 infectivity in vitro, whereas none of the prepandemic samples were able to do so. Although microneutralization (MN) titers correlated with concentrations of IgA to all SARS-CoV-2 antigens tested ( Fig. 3A and Fig. S1 ), in a multivariable regression model that included all antigen targets as independent variables, only the SARS-CoV-2 RBD had a significant b (P = 0.0125), consistent with neutralization primarily by anti-RBD antibodies. Consequently, an analysis of sequential milk samples collected from study participants identified increases in anti-RBD IgA concentrations in 9 of 15 cases, and 5 of those were associated with elevated microneutralization titers (Fig. 3B ). Anti-RBD IgA was also correlated with anti-RBD IgG, resulting in an apparent correlation of anti-RBD IgG and MN titer (data not shown). However, anti-RBD IgG titers as low as those found here, however, were not neutralizing in our previous study (28) . It is noteworthy that at least one milk sample provided by subjects B and M exhibited neutralizing capacity even though anti-RBD IgA levels were not above those of prepandemic samples. These same samples also did not have detectable anti-RBD IgG. Although human milk is considered the best source of nutrition for most infants, the onset of the global COVID-19 pandemic and our lack of understanding of SARS-CoV-2 transmission have caused confusion around whether infected mothers should FIG 2 Milk antibody concentrations. Panel A shows IgA and IgG to coronavirus antigens in milk produced by COVID-19infected (red) and healthy, prepandemic (blue) women. Antibody concentrations were measured using ELISA specific to the RBD and S2 domains of the spike and nucleocapsid (N) proteins of SARS-CoV-2 and S proteins from human coronaviruses 229E and OC43. The horizontal solid line in the IgA panel denotes the limit of antigen-specific binding that is defined as mean 1 2Â standard deviation of RBD-specific IgA signal in prepandemic controls. The dotted horizontal line denotes the ELISA limit of quantification. P values for the difference between infected and prepandemic controls are from the Wilcoxon signed-rank test. Milk from 44 mothers (34/10, infected/controls) was used for IgA testing, and milk from 37 mothers (27/10, infected/controls) was used for IgG testing. Panel B shows correlations between IgA concentrations to SARS-CoV-2 antigens RBD, S2, and N (x axis) and IgA concentrations to S proteins from 229E and OC43 (y axis) in milk produced by COVID-19-infected (red, n = 34) and healthy, prepandemic (blue, n = 10) women. A linear model was fitted to log-transformed IgA concentrations to give r-squared and P values as indicated. Model prediction (red or blue line as defined above) is shown with the 95% confidence interval (gray shading). be temporarily separated from their infants, as well as whether breastfeeding should be initiated and/or continued during maternal COVID-19 illness. In this prospective study, we collected milk and breast swabs from women with COVID-19 and tested them for the presence of SARS-CoV-2 RNA. We also analyzed the milk for IgA and IgG targeting SARS-CoV-2 and the ability of the samples to neutralize SARS-CoV-2 and thereby reduce infectivity. Milk samples collected prior to the pandemic were analyzed as reference controls.Using methods validated and replicated across two laboratories, and consistent with most previous reports (5-9) (see Table S1 in the supplemental material), we did not detect SARS-CoV-2 RNA in any of the milk samples. Although a single swab collected from the breast before it was cleaned was found conclusively to contain SARS-CoV-2 RNA, a swab collected after the breast was washed did not. Although study participants wore masks and gloves, the presence of SARS-CoV-2 RNA on this breast swab, and the indeterminate detection on 7 other swabs, may help explain the findings of other studies that have reported detecting viral RNA in some milk samples (i.e., contamination of milk via skin and/or respiratory droplets) (4, 29, 30) . It is reassuring that a majority of the infants (83%, 15/18) appeared healthy with no signs of illness, including two whose mothers had detectable viral RNA on their breast skin. Nonetheless, the infants of three participants with viral RNA detected on their breast skin were observed to have at least one symptom associated with COVID-19, although only one of the three infants had a diagnostic test performed (which came back positive). However, it should be noted that in these three cases additional household members were confirmed to have COVID-19, making it difficult to attribute their symptoms or mode of transmission, in the case of the positive infant, to breastfeeding.It is also noteworthy that several of the women in our study had evidence of subclinical mastitis, which has previously been shown to be positively related to viral load in milk produced by HIV-infected women (27) . Nonetheless, we detected no SARS-CoV-2 RNA in the milk produced by any participant in our study. This suggests that there is likely no relationship between subclinical mastitis and the presence of SARS-CoV-2 RNA in a woman's milk. Together, our results suggest that milk does not appear to act as a vehicle for mother-to-child transmission of SARS-CoV-2 in women with mild-tomoderate COVID-19, although viral exposure via breast skin is possible. Our lack of detection of viral RNA on the breast after washing supports existing recommendations for women to take precautions during breastfeeding and/or expression of milk (e.g., practicing respiratory and hand hygiene, cleaning pump parts prior to and after use) to reduce the potential for viral transmission.Importantly, human milk contains a wide variety of immunoglobulins, of which IgA represents the majority (80 to 90%) (31, 32) . In our study, we detected anti-SARS-CoV-2 antibodies in milk, primarily IgA but also IgG, albeit at lower concentrations than those reported for serum of COVID-19 patients during convalescent phase (28) . That same study also noted specific cross-reactivity between the S2 subunits of SARS-CoV-2 and the ccCoV OC43. We also observed that concentrations of anti-SARS-CoV-2 S2 antibodies correlated strongly with those of the other tested ccCoV spike proteins in milk produced by study participants and those produced prior to the pandemic. This pattern of cross-reactivity may reflect structural similarity among the proteins and likely reflects a recall response from prior exposure to ccCoV. However, generation of RBD-reactive antibodies likely requires activation of antigen-specific naive B-cell populations, because the RBD of the SARS-CoV-2 spike protein shares little sequence homology with other ccCoVs.It is noteworthy that while IgA to SARS-CoV-2 S2 subunit and N protein and ccCoVs is present in prepandemic samples, IgG levels to the same antigens except the S protein of 229E are increased in infected mothers. This pattern of increase in milk IgG reactivity is identical to the one we described for serum previously (28) . The difference between IgA and IgG could be due to the shorter lifetime of systemic IgG-secreting B cells versus long-lived submucosal IgA-secreting B cells in the mammary gland following a previous exposure to ccCoVs. This is also consistent with similar apparent difference in specificity of milk IgA versus IgG for influenza virus (33) .Of particular note, we are the first to report that milk produced by women with COVID-19 is able to neutralize SARS-CoV-2 infectivity. While neutralization titer correlated with concentration of RBD-reactive IgA, neutralization was detected in three samples with low RBD-reactive IgA and without detectable RBD-reactive IgG. This may suggest other factors present in milk produced by infected mothers or higher-affinity milk IgA enhancing SARS-CoV-2 neutralization.While the detection of SARS-CoV-2 RNA in milk and/or on the breast is of concern, it does not necessarily indicate the presence of viable or infectious virus. In the only study that has assessed the viability of SARS-CoV-2 in milk, a single milk sample positive for SARS-CoV-2 RNA did not contain replication-competent virus (30) .Unfortunately, in our study we were unable to determine the viability of SARS-CoV-2 in any of the breast swabs positive for SARS-CoV-2 RNA because the entire sample was needed for RNA detection. Future studies should determine the viability of any SARS-CoV-2 found in milk and/or on the breast.Our study has several important strengths, including the use of rigorous collection methods, close temporal proximity of sample collections to COVID-19 diagnosis, validation of analytical methods for human milk, replication of RT-qPCR analyses across laboratories, and analysis of both risks and benefits of milk constituents. We also acknowledge that this study has limitations. For instance, as samples were self-collected and stored in participant freezers, it remains possible, although we believe unlikely, that sample quality and/or contamination may have influenced the results. However, our preliminary testing of various storage and temperature conditions would indicate that the SARS-CoV-2 RNA is robust to similar conditions. Most samples were also collected from women after onset of symptoms, limiting generalizability to presymptomatic women. Differences in symptom onset and time of infection may also be related to the variation in antibody concentrations that we observed. Additionally, no participant was hospitalized due to COVID-19. As disease severity may be related to viral titer (34) , it is possible that milk produced by individuals with more severe COVID-19 could contain SARS-CoV-2. The short duration of the follow-up period also does not allow characterization of the durability of the milk IgA and IgG responses. Initial reports on serum IgG response may suggest a relatively short-lived response (35, 36) , and no data exist on the presence of long-lived memory B cells in the context of SARS-CoV-2. Milk IgA, representing a mucosal response, may have its own pattern of durability.Conclusions. We did not detect SARS-CoV-2 RNA in milk produced by women with mild-to-moderate COVID-19. Moreover, we demonstrated that milk contains anti-SARS-CoV-2 antibodies and that their concentrations are correlated with milk's ability to effectively neutralize SARS-CoV-2 infectivity. We found evidence of SARS-CoV-2 on the areola/nipple region of several women, but it is unclear whether this RNA reflects viable virus. As such, our data do not suggest that infected women should systematically wash their breasts prior to breastfeeding or expressing milk. However, and in support of recommendations put forth by the WHO, if a mother who is confirmed/suspected to have COVID-19 has just coughed over her exposed breast, she should gently wash the breast with soap and warm water before feeding (37) . Taken together with the welldocumented benefits of breastfeeding to maternal and infant health, our data support recommendations to encourage breastfeeding in women with mild-to-moderate COVID-19 illness.Experimental design and clinical data collection. This prospective study was carried out using a repeated-measures, longitudinal design. To be eligible, women needed to be $18 years of age, to be lactating, and to have received a positive test result for COVID-19 in the previous 8 days. Subjects were recruited through social media, word of mouth, and the assistance of national maternal and child health organizations and collaborating hospitals. All participants gave informed consent, and procedures were approved by the Institutional Review Boards at the University of Idaho (20-056, 20-060), the University of Rochester Medical Center (1507), and Brigham and Women's Hospital (2020P000804). Surveys were administered by telephone to ascertain timing of maternal/infant COVID-19 symptoms, reproductive history, breast health, breastfeeding practices, demographics, and anthropometrics.Milk and breast swabs. All collection kits were assembled aseptically by study personnel wearing masks and gloves and were individually packaged to reduce potential contamination. Mothers were instructed in clean techniques to obtain samples, including use of gloves and masks. Milk and swabs of the nipple/areola (""breast swabs"") were self-collected either in participants' homes (with virtual assistance provided by study personnel) or at a hospital (participants Q and R were admitted to the postpartum unit at the time of sample collection). Breast swabs were collected before and after washing the breast with soap and water and prior to milk collection. Women collected up to 30 ml of milk using the provided sterile manual breast pump (Harmony; Medela) and sterile collection containers. Details regarding sample collection are provided in Text S1 in the supplemental material.Following collection, samples were immediately frozen in the subject's freezer until being shipped in a cooler containing frozen cold packs to the University of Idaho (UI) or University of Rochester Medical Center (URMC). Samples collected from subjects Q and R were frozen at 280°C and shipped on dry ice to UI. Once received, samples were processed immediately for RNA extraction and/or stored at 280°C until further analysis. As needed, samples were shipped on dry ice between UI and URMC. Milk samples collected prior to December 2019 from 10 healthy women located in the Rochester, NY, area for general assay development purposes were used as prepandemic control samples.SARS-CoV-2 RNA. Details related to RNA extraction and assay validation are provided in the Text S1. Briefly, RNA was extracted from milk (at both UI and URMC), breast swabs (UI), and extraction controls (at both UI and URMC) using the Quick-DNA/RNA Viral MagBead kit (Zymo Research, Irvine, CA) with addition of the DNase I treatment on extracted nucleic acids following the manufacturer's protocol. Detection of SARS-CoV-2 viral RNA in milk was independently determined in both UI and URMC laboratories using the CDC-designed 2019-nCoV RT-qPCR assay (38) , validated in both laboratories for use with human milk. Per the CDC protocol, samples with C T values of ,40 were considered positive.Antibodies. Concentrations of milk-borne IgA and IgG reactive to the SARS-CoV-2 spike (both S2 subunit and RBD) and nucleocapsid (N) proteins and full-length spike proteins of common cold coronaviruses 229E and OC43 were measured in milk samples by ELISA as previously described (39) . Briefly, Nunc MaxiSorp 96-well plates (Thermo Fisher, Waltham, MA) were coated with optimized concentrations of antigens (1 to 5 mg/ml) overnight at 4°C. Coated plates were blocked for 1 h before the addition of serial 2-fold dilutions of samples. After 2 h of incubation at room temperature, plates were washed and bound IgG and IgA were detected with alkaline phosphatase-conjugated anti-human IgG (clones MT78 and MT57, respectively; Mabtech, Stockholm, Sweden) and anti-human IgA. Bound antigen-specific antibodies were detected by adding p-nitrophenyl phosphate substrate (Thermo Fisher). Absorbance was read at 405 nm after color development. A weight-based concentration method was used to assign antigen-specific antibody titers in test samples (39, 40) .SARS-CoV-2 neutralization. The neutralizing activity of milk against SARS-CoV-2 was measured by microneutralization (MN) assay. Briefly, duplicates of delipidated milk were serially diluted 2-fold in virus diluent and incubated with 100 50% tissue culture infective doses (TCID 50 ) of SARS-CoV-2 virus (Hong Kong/VM20001061/2020 isolate) in 96-well flat-bottomed plates for 1 h at 37°C. After incubation, Vero E6/TMPRSS2 cells (kindly provided by Yoshihiro Kawaoka, National Institute of Infectious Diseases, Japan; 25,000 cells/well) (41) were added to the virus-sample mixtures. Plates were incubated for 48 h at 37°C, when a cytopathic effect was evident in virus-only control wells. Cells were then fixed with 6% paraformaldehyde for 30 min and washed and stained with crystal violet for 1 h. The MN titer was identified as the highest dilution of sample that showed 50% neutralization based on the appearance of the stained cell monolayer compared with the virus control well.Sodium and potassium. For milk samples with sufficient volume (33 of 37), sodium (Na) and potassium (K) concentrations were quantified in 200 ml of milk using LAQUAtwin ion selective meters (Na-11 and K-11, respectively; Horiba Ltd., Kyoto, Japan). Prior to use, each meter was conditioned and calibrated according to vendor specifications. After each measurement, meters were rinsed with Nanopure water, wiped dry, and allowed to reach zero. A Na-to-K ratio (Na/K) of .0.6 was interpreted to indicate subclinical mastitis (42, 43) .Statistical analysis. Except where noted, all statistical analyses were performed using R (version 3.6.1). Statistical testing of antibody concentrations and MN titers was performed using nonparametric tests. Linear regression was performed using either the lm() or rlm() function in R as appropriate. Significance was declared at P , 0.05.Data availability. The data sets generated during and/or analyzed during the current study are available from the corresponding author on reasonable request.Supplemental material is available online only. TEXT S1, DOCX file, 0.04 MB. FIG S1, EPS file, 2.9 MB. ",USA,first author,2021-02-09,02
c5ce6d8caae9c75ca3d20acfe832c2837bbd30d1,The papain-like protease of coronaviruses cleaves ULK1 to disrupt host autophagy,"The recent pandemic of coronavirus disease-2019 (COVID- 19) highlights the health crisis worldwide. Although global efforts to restrict travelling and implement social distancing practices have mitigated the spread of Severe Acute Respiratory Syndrome-Coronavirus-2 (SARS-CoV-2), the etiological agent of COVID-19, the virus remains a significant health threat with >50 million confirmed cases and 1.3 million fatalities.Autophagy-modulating drugs such as chloroquine/hydroxychloroquine have emerged as anti-viral agents against SARS-CoV-2; however, recent placebo-controlled trials showing no clinical benefits and possible safety concerns are spearheading global efforts for better understanding [1] . Autophagy is an evolutionarily conserved process that acts to recycle cellular waste while also responding to invading pathogens. Cellular membranes termed phagophores first enwrap cargo inside double-membraned chambers, so called autophagosomes, after which cargo is degraded upon fusion of autophagosomes with digestive lysosomes. The process is tightly regulated and responsive to various stressors including nutrient, oxidative, and viral stress [2] .The serine/threonine unc-51-like kinase (ULK1) is an upstream regulator of autophagy. The role of ULK1 as nutrient-responsive orchestrator of autophagy has been well characterized [3] . ULK1 is recruited to sites of autophagosome biogenesis where it phosphorylates key autophagy regulatory proteins. Its central role in autophagy has implicated ULK1 in diverse human diseases from cancer and neurodegeneration to inflammatory disorders [4e6] . Structurally, ULK1 possesses an N-terminal kinase domain and a C-terminal early autophagy targeting (EAT) domain. The latter facilitates interaction of ULK1 with its various substrates. Autophagyindependent functions of ULK1 have also emerged including the regulation of ER-Golgi trafficking and innate immune signaling [7e10] . For example, stimulator of interferon genes (STING), an adaptor of the DNA sensor cyclic GMP-AMP synthase (cGAS), was previously identified as a substrate of ULK1 [11] . Furthermore, the innate immune kinase TANK-binding kinase 1 (TBK1) is phosphorylated by ULK1 to participate in metabolic signaling [12] .Many positive-sense RNA viruses, including betacoronaviruses, have evolved strategies to co-opt autophagy by utilizing cellular double membrane vesicles as topological surfaces for viral RNA synthesis [13e16]; however, the precise mechanisms of viral subversion of autophagy components are poorly defined. The current study uncovers the betacoronavirus-encoded papain-like protease (PL pro ) as a pathogenic factor that disrupts autophagy in part by targeting the regulatory kinase ULK1.Murine 17Cl1 fibroblast cells were cultured in DMEM supplemented with 10% FBS and penicillin/streptomycin (100 mg/mL).MHV-A59 and 17Cl1 cells were provided by Dr.Nerea Irigonen (Cambridge).Cells were either sham-infected with DMEM or inoculated with MHV-A59 (MOI ¼ 10). Starvation was performed for 2 h in HBSS medium. V-ATPase inhibitor, bafilomycin-A1 (BAF) and ULK1/2kinase inhibitor, MRT68921-HCl, where used at 125 nM and 5 mM respectively.3ÂFlag-ULK1 was cloned into CMV10 vector at EcorI/BamHI sites. Cleavage-resistant mutants, LGGG-499-QQQG and MRGG-531-MRDD were generated using gBLOCKS DNA synthesis (IDT) and cloned into CMV10 vector at BstEII/FseI and FseI/AflII sites respectively. EGFP-PL pro of SARS-COV-2 was cloned as outlined ( Fig. 2A) pET-41c encoding wild-type or mutant(C145A) SARS-CoV-2 3CL pro were transformed into C41(DE3) E. coli. Starter-culture from a single colony was grown overnight and diluted 100-fold in Terrific-Broth. Expression was induced with 1 mM IPTG after cultures reached an OD600 of 0.6e0.8 and proceeded at 25 C for 5 h. Protein was purified using Ni-NTA according to the manufacturer's instructions.HeLa lysates (20 mg) were incubated with WT or inactive (C145A) SARS-CoV-2 3CL pro (4 mg) in cleavage assay buffer (20 mM HEPES pH 7.4, 150 mM KOAc, 1 mM DTT) for indicated times at 37 C. Reactions were terminated with 6Âsample buffer and subjected to western analysis.Cells were lysed in MOSLB buffer and subjected to western analysis using the following primary antibodies: LC3(NB100-2220), ACTB(A5316), monoclonal-ULK1 (sc-390904), polyclonal-ULK1 (ab167139), NSP9-(SAB3701435), FLAG-(F1804), and GFP-(A-6455).Immunoprecipitation of Flag-ULK1 was performed using ANTI-FLAG®M2 Affinity Gel (F2426) according to manufacturer's instructions.Samples were serially diluted and overlaid on Terasaki plates pre-seeded with 17Cl1 cells. 48 h post-incubation, TCID50 was calculated by the statistical method of Reed/Muench [17] . Titers were expressed as plaque forming unit (PFU)/mL as previously described [18] .Gene expression was quantified as previously described [19] , using primers for Ulk1 (forward:GCAGCAAAGACTCCTGTGACAC; reverse:CCACTACACAGCAGGCTATCAG), and N-gene (forward:CAAAGAAAAGGGCGTAGACAGG; reverse:CGCCATCATCAAG-GATCTGAG) and normalized to Actb.Statistical analysis was performed with unpaired Student's t-test or analysis of variance (ANOVA). P-value <0.05 was considered statistically significant. Results are presented as mean ± SD and representative of 3 independent experiments.Protein expression of ULK1 is decreased while RNA level is upregulated following mouse coronavirus (M-CoV) infection.To understand the molecular underpinnings of betacoronavirus subversion of cellular autophagy, we utilized mouse hepatitis virus-A59 (MHV-A59) as a model and examined its effects on critical components of the canonical autophagy pathway. The serinethreonine kinase ULK1 is an important regulator of cellular autophagy and has recently emerged as an innate immune signaling factor [3,7e9] . The significance of autophagy and innate immune signaling as critical facets of host anti-viral defense, prompted us to investigate the regulation and function of ULK1 during betacoronavirus infection. A time-course infection was conducted with MHV-A59 at a multiplicity of infection (MOI) of 10 in the murine fibroblast cell line 17Cl1. Viral replication was verified by immunoprobing for viral non-structural protein 9 (NSP9) precursor. Coincident with active viral polyprotein processing of NSP9 precursor, we observed a significant loss of ULK1 protein starting at 12 h post-infection with both anti-ULK1 antibodies tested in this study ( Fig. 1A & B) . Interestingly, using the polyclonal anti-ULK1 antibody that recognizes amino acids 351e400, we observed an additional band at~65 kDa (Fig. 1A) . However, this potential cleavage fragment was undetected with monoclonal anti-ULK1 antibody that recognizes amino acids 511e750 (Fig. 1B) , indicating a cleavage may occur within this region. To investigate whether virus-mediated loss of ULK1 is through transcriptional regulation, we performed RT-qPCR. Fig. 1C showed that mRNA levels of Ulk1 were elevated following 12 h and 24 h infection, suggesting that reduced protein expression of ULK1 is not a result of decreased mRNA level. In contrast, elevated gene expression may indicate a compensatory mechanism following reduced protein expression.The discovery of a ULK1 cleavage product in MHV-infected lysates prompted us to investigate whether betacoronaviral proteases are responsible for ULK1 cleavage. Betacoronaviruses encode two proteases, a papain-like cysteine protease (PL pro ) and a 3chymotrypsin-like cysteine protease (3CL pro , also known as Main protease, M pro ) that process viral polyproteins into individual functional proteins [20] . We generated a construct expressing PL pro of SARS-CoV-2, which shares 63% similarity with PL pro domain 2 of MHV-A59. To determine whether PL pro targets ULK1, HEK293T cells were transfected with either a control vector or a plasmid expressing PL pro for 24 h. Expression of PL pro alone was sufficient to recapitulate the reduction in full-length ULK1 observed following MHV-A59 infection using the monoclonal anti-ULK1 antibody (Fig. 2B) . PL pro -mediated cleavage of ULK1 was verified using Nterminal 3ÂFlag-ULK1 construct (Fig. 2C ). HEK293T cells were cotransfected with PL pro together with 3ÂFlag-ULK1. Lysates probed with anti-Flag antibody revealed significant reduction of ULK1 with the concomitant detection of a lower-molecular-weight fragment of~70 kDa. To exclude the involvement of 3CL pro , we performed invitro cleavage assay. Time-course treatment revealed that ULK1 was not targeted by SARS-CoV-2 3CL pro , whereas coxsackievirus 3C pro , the positive control [21] , demonstrated efficient cleavage of ULK1 (Fig. 2D ). Together, our data suggest that PL pro , but not 3CL pro , targets ULK1 for cleavage.To identify the precise location within ULK1 that is targeted by PL pro , we closely investigated the protein sequence of ULK1 and identified two potential cleavage sites in the central region of ULK1 (Fig. 2E ) [22] . Using Flag-tagged ULK1 construct, we mutated the sites and co-transfected wild-type (WT) or mutant ULK1 with either control or PL pro construct into HEK293T cells. Expression of PL pro resulted in the loss of the 3ÂFlag-ULK1 and the appearance of a faster migrating band at~70 kDa in cells expressing WT-ULK1 and G531 mutant ULK1, but not in cells expressing G499 mutant (Fig. 2F) , indicating that PL pro cleaves ULK1 after G499. The observed N-terminal fragment matches the molecular weight of the predicted cleavage fragment. The resulting cleavage of ULK1 by PL pro separates its N-terminal kinase domain from a C-terminal substrate binding domain (Fig. 2G ).To understand the functional consequence of PL pro -mediated cleavage of ULK1, we first examined whether the ability of ULK1 to interact with binding partners is disrupted. ATG13 is a bridging molecule that directly interacts with ULK1 and the scaffold protein FIP200 in the autophagy-initiating ULK1 complex [3] . Expression of PL pro resulted in reduced co-immunoprecipitation of ULK1 with its binding partner ATG13 (Fig. 3A) . Given that ULK1 complex is required for starvation-induced autophagy, we inquired the functional significance of its disruption. The rate of autophagic degradation, designated as 'autophagy-flux', can be measured by comparing levels of LC3-II, a substrate of autophagy, in the presence or absence of lysosomal fusion inhibitors [23] . 17Cl1 cells were sham-or MHV-A59-infected for 6 h, 12 h, and 24 h either in the presence of DMSO or lysosomal fusion inhibitor, bafilomycin-A1 (BAF). Consistent with impaired autophagy, MHV-infected cells had reduced accumulation of LC3-II in the presence of BAF (Fig. 3B) . We next tested whether PL pro expression can recapitulate the impaired autophagy observed following MHV-A59 infection. HEK293T cells were transfected with either a control vector or plasmid expressing PL pro for 24 h and then subjected to starvation in HBSS medium for 2 h in the presence or absence of BAF. Control cells responded efficiently to starvation by increasing autophagyflux; however, cells expressing PL pro did not initiate autophagy (Fig. 3C) , suggesting that PL pro expression disrupts cellular autophagy.The role of ULK1 in betacoronavirus replication is currently unclear. To clarify this, we utilized chemical and genetic approaches to target ULK1 prior to infection with MHV-A59. The chemical inhibitor, MRT68921, potently targets ULK1/2 kinase activity [24] . Functional validation of the inhibitor showed the complete blockage of starvation-induced autophagy (ie. reduced LC3-II accumulation in starvation-induced, BAF-treated cells (Fig. 4A) . To investigate the consequence of ULK1 inhibition, 17Cl1 cells were inoculated with MHV-A59 for 1 h, followed by replenishment with medium containing either DMSO or MRT68921 (5 mM). After 12 or 24 h, the N-gene levels of MHV-A59 were measured by RT-qPCR.Compared to control treatment, MRT68921 significantly attenuated viral RNA replication at 24 h post-infection (Fig. 4B) . Consistent with a pro-viral role for ULK1, RNA levels and viral titers of MHV-A59 were significantly reduced following gene-silencing of Ulk1 (Fig. 4C) . We also assessed the effects of expression of WT-or non-cleavable mutant-ULK1 on viral replication. We showed that cells expressing WT-ULK1 displayed significantly enhanced viral titers (Fig. 4D) , supporting a pro-viral function for ULK1. However, a non-cleavable ULK1 mutant demonstrated diminished viral titers (Fig. 4D) . Collectively, these data support a requirement of ULK1 for replication prior to its cleavage.Diverse viruses have evolved strategies to circumvent the inherently anti-viral defense capacity of autophagy [25] . In particular, RNA viruses that replicate in the cytoplasm can utilize autophagic membranes as topological surfaces for viral replication [15, 26, 27] . However, viruses must evade selective targeting and degradation via autophagy, termed virophagy, a process mediated by autophagy receptors that recognize and sequester viral components inside autophagosomes [28] . The autophagy receptor SQSMT1 was previously shown to mediate virophagy of the positive-strand RNA virus Sindbus [29] . To counteract this, enterovirus such as coxsackievirus B3 and enterovirus-D68 have evolved strategies to subvert the host virophagy efforts by engaging virus-encoded proteases to cleave SQSTM1 [19, 30] . Similarly, enteroviral proteases impede the degradation capacity of autophagy by disrupting autophagosome-lysosome fusion through the selective cleavage of autophagic fusion SNARES [23, 31] . Although recent studies are beginning to unravel the subversion strategies utilized by other RNA viruses, including betacoronaviruses, it remains unclear whether betacoronavirus-encoded proteases target host substrates.The murine betacoronavirus MHV-A59 was reported to induce double membrane vesicles reminiscent of autophagosomes in the absence of intact autophagy [32] , while infection of porcine betacoronavirus, PHEV, demonstrated significant reduction of ULK1 [33] . Findings from the current study suggest that betacoronaviruses may actively target canonical autophagy factors. We provide evidence that SARS-CoV-2-endoced PL pro can cleave ULK1 to disrupt formation of the autophagy-initiating ULK1-complex and functionally impair starvation-induced cellular autophagy/degradative capacity. SARS-CoV-1 PL pro was previously reported to have deubiquitinase activity by recognizing the consensus LXGG motif similar to other host deubiquitinating enzymes [34] . Of note, we identified the SARS-CoV-2 PL pro cleavage site of ULK1 after glycine(G) 499, follows precisely the consensus sequence recognized by the de-ubiquitinase. The interferon regulatory factor 3 (IRF3) was also recently reported as a substrate of PL pro following an LGGG consensus motif similar to ULK1 [20] . The targeting of ULK1 and possibly other host proteins harboring an LXGG motif therefore underscores a novel mechanism through which betacoronaviruses subvert cellular autophagy. In addition to disrupting ULK1mediated autophagy, the deubiquitinase activity of PL pro may HEK293T cells were transfected with either control or PL pro -expressing plasmid for 24 h. Lysates were probed by western blotting for endogenous ULK1 using the monoclonal anti-ULK1 antibody and normalized to ACTB as in Fig. 1A . (C) HEK293T cells were co-transfected with 3ÂFlag-ULK1 and either control vector or PL pro -expressing plasmid for 24 h. Lysates were probed with anti-Flag antibody to detect exogenous ULK1. Arrow denotes cleavage fragment observed at~70 kDa. Densitometry is provided as in Fig. 1A . (D) Purified SARS-CoV-2 3CL wt (4 mg) or catalytically-inactive C145A 3CL mut (4 mg) of SARS-CoV-2 and CVB3 3C wt (0.1 mg) alongside HeLa lysates (30 mg) were used to perform in-vitro cleavage assay.Western blotting was performed to probe for endogenous ULK1 and normalized to ACTB as in Fig. 1A . Arrows denote cleavage fragments. (E) PL pro consensus cleavage motif in ULK1 from H. sapiens, M. musculus, and R. norvegicus is presented. Highlighted gray boxes denote consensus sites. Dashed arrows denote sites of potential cleavages. (F) HEK293T cells were co-transfected with PL pro and either 3ÂFlag-ULK1 WT , 3ÂFlag-ULK1-G499 mut or 3ÂFlag-ULK1-G531 mut . Western blotting was conducted with anti-Flag and anti-GFP antibody for detection of ULK1 and PL pro , respectively. (G) Schematic diagram of ULK1 protein sequence with corresponding functional domains, antibody recognition epitopes and identified PL pro cleavage site. favor viral pathogenesis by disrupting selective autophagy, a process that relies on autophagy receptors recognizing ubiquitinmodified pathogens or cellular cargo [35] .The role of ULK1 in betacoronaviral replication is poorly defined. We found ULK1 protein levels are relatively intact during the initial 6 h of MHV infection. Furthermore, loss-of-function studies prior to infection either through chemical inhibition of ULK1/2 kinase activity or genetic silencing of ULK1 revealed a significant reduction in MHV viral replication. In contrast, ULK1 protein levels are significantly decreased during late infection, coinciding with the Fig. 3 . PL pro -mediated cleavage of ULK1 disrupts autophagy. (A) HEK293T cells were co-transfected with 3ÂFlag-ULK1 together with control vector or PL pro for 24 h. Immunoprecipitation of exogenous 3ÂFlag-ULK1 was performed using anti-Flag M2 agarose beads. IgG light chain and ACTB served as loading controls for immunoprecipitation and inputs, respectively. Schematic depiction of disrupted formation of ULK1-ATG13 complex (right). (B) Disruption of autophagy-flux in MHV-A59-infected cells. Autophagy-flux was assayed in the presence or absence of BAF (125 nM) following sham or viral infection. Cell lysates were analyzed by western blotting for LC3 and normalized to ACTB. NSP9 was used as marker of active viral replication. (C) HEK293T cells expressing either empty vector or PL pro construct were starved for 2 h in the presence or absence of lysosomal inhibitor BAF (125 nM) for 2 h. Lysates were probed for LC3 and normalized to ACTB. Quantification of LC3-II was conducted as in Fig. 1A and presented as (mean ± SD, n ¼ 3) in the right panel. level was determined by RT-qPCR and normalized to Actb (mean ± SD, n ¼ 3).(C) Murine 17Cl1 cells were transfected Cas9 and sg-CON or sg-ULK1 for 48 h. Cells were then infected with MHV-A59 (MOI ¼ 10) for an additional 24 h. ULK1 knockout efficiency (left), viral RNA levels in the cells (middle) and viral titers in the supernatant (right) were measured by western blotting, RT-qPCR, and TCID50 assay, respectively. (D) 17Cl1 cells were transfected with vector, 3Â Flag-ULK1 WT , or 3Â Flag-ULK1 MUT for 24 h. Cells were then infected with MHV-A59 (MOI ¼ 10) for 24 h. Cell lysates were analyzed by western analysis for exogenous ULK1 with anti-Flag antibody. Viral titers in culture medium were determined by TCID50 assay (mean ± SD, n ¼ 3). emergence of lower-molecular-weight cleavage fragment. Additionally, the expression of WT-ULK1 that can undergo proteolytic processing by PL pro enhances viral titers unlike the expression of a non-cleavable ULK1. Collectively, these data suggest that ULK1 may serve a hitherto uncharacterized pro-viral role during early replication. The cleavage of ULK1 during late infection likely suggests that (1) ULK1 function may be dispensable at late stages; (2) ULK1 may serve late-stage anti-viral function that needs to be inactivated; and/or (3) ULK1 cleavage fragments may serve novel proviral function. The attenuation of viral titers in cells expressing non-cleavable ULK1 suggests that persistent ULK1 activity throughout the course of infection may be undesirable for virus. Indeed, ULK1 has previously been reported to regulate anti-viral innate immune signaling [11, 12] .In summary, we uncover a novel function for the PL pro of SARS-CoV-2 in cleaving the autophagy-regulating kinase ULK1 to clarify betacoronaviral pathogenesis and subversion of cellular autophagy.The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.",Canada,first author,2021-02-12,02
ae9380f255867a42d8a67e2bfa077346005c7f05,Journal Pre-proof Fluoxetine as an Anti-Inflammatory Therapy in SARS-CoV-2 Infection Fluoxetine as an Anti-Inflammatory Therapy in SARS-CoV-2 Infection,"disease outcomes [1] . Clinical consequences of COVID-19 infection such as multisystem organ failure, intensive care unit admission, and death result from an exaggerated immune response whereby increased IL6 drives a destructive cytokine storm [2] [3] [4] [5] [6] . This pattern of poor clinical J o u r n a l P r e -p r o o f Page 4 outcomes parallels the Secondary Hemophagocytic Lymphohistiocytosis (SHLH) seen in another coronavirus-induced illness, Severe Acute Respiratory Syndrome (SARS) [7, 8] . Indeed, many infections result in an IL6-mediated cytokine storm that drives negative clinical outcomes. NF-kappaB-mediates increases in the transcriptional expression of the proinflammatory cytokine IL6 [9, 10] . Binding of IL6 to its receptor complex (IL6R) activates the IL6 signal transduction protein (IL6ST or gp130), a subunit of the IL6 receptor complex. IL6ST activation is integral to many intracellular cytokine-mediated inflammatory pathways, including the cytokine storm / cytokine release syndrome in COVID-19 patients [11] . Further, in vitro, in vivo, and clinical data demonstrate that many selective serotonin reuptake inhibitors (SSRIs) decrease IL6 signaling activity and reduce hyperinflammatory states [12] [13] [14] [15] [16] [17] . The SSRI fluoxetine causes pronounced inhibition of NF-kappaB signaling and IL6 expression correlating with decreased illness severity across a variety of animal disease models including cancer, pulmonary inflammation, and sepsis [17] [18] [19] [20] [21] [22] .Fluoxetine's well-established safety profile and its inhibition of IL6 signal transduction suggests that this drug may be advantageous when used early in COVID-19 infection to prevent or reduce the cytokine storm. Evidence supporting this hypothesis can be found across multiple animal models of disease whereby fluoxetine not only reduced IL6 signaling cascades but also prevented end organ damage [16, 18, [23] [24] [25] . In rat models of chronic obstructive pulmonary disease, fluoxetine decreased lung injury by inhibiting the transcription factor NF-kappaB, thus reducing downstream IL6 production [18] . In a lipopolysaccharide (LPS)-induced sepsis model of hyperinflammatory illness, pretreatment with fluoxetine outperformed pretreatment with corticosteroids and resulted in diminished end organ damage that included decreased incidence J o u r n a l P r e -p r o o f Page 5 of pulmonary arterial hypertension, decreased pulmonary arterial muscularization, and decreased extracellular matrix remodeling [23, 24] . Fluoxetine treatment in rats decreased bronchial asthma severity concurrent with reduced levels of inflammatory cytokines, including IL6 [24] .Fluoxetine has also demonstrated inhibition of NF-kappaB with corresponding decreases in inflammatory cytokines like IL6 in models of septic shock and allergic asthma, as well as in patients with depression [16, 25] .Recently, Zhou et al. performed phylogenetic analyses of multiple human coronavirus genomes to identify evolutionarily conserved targets for SARS-CoV-2 therapeutics. Their quantification of interactions between the human coronavirus-host interactome and subsequent gene set enrichment analyses comparing coronavirus-infected host cells and drug-treated human cells identified the SSRI paroxetine as a novel COVID-19 therapeutic candidate [26] . An observational study correlated antidepressant therapy with decreased risk of intubation or death for hospitalized patients with COVID-19 [27] . Preliminary reports also suggest that fluoxetine demonstrates direct inhibition of SARS-CoV-2 viral protein expression [28] , although the present study is focused on fluoxetine's anti-inflammatory activity in human pathophysiology.To investigate the potential clinical utility of using fluoxetine to reduce IL6 mediated inflammation in COVID-19 patients and to elucidate the mechanism by which fluoxetine acts as an anti-inflammatory agent, we used transcriptomic signatures from the Library of Integrated involved in fluoxetine's anti-inflammatory mechanism of action were compared to the transcriptomic changes caused by antidepressant drug therapy. Our resultant data highlights the significance of IL6ST and NF-kappaB in fluoxetine's anti-inflammatory mechanism of action and supports further exploration of fluoxetine as a candidate drug in the treatment of inflammatory pathologies such as those contributing to COVID-19. assay which measures the expression of 978 ""hub"" genes which represent ~82% of the information present in the transcriptome. The iLINCS Portal (www.ilincs.org) provides a convenient gateway to access these signatures. We used the iLINCS application programing interface (API) to download differential gene expression signatures. We acquired all available signatures for fluoxetine (33) , paroxetine (65), bupropion (29) , or dexamethasone (309) treated cell lines. In total, 436 signatures were obtained for all 4 drug treatments, with data generated in 45 different cell lines, at different timepoints (6h -24h) and different doses (0.01uM -80uM) (Table S1 ). To create high-confidence gene signatures, differential gene expression data were filtered such that only those genes with a log-fold change (LFC) ≥ 0.85 or ≤ -0.85 in drug-treated versus corresponding control cell lines were included in downstream gene signature analyses.This LFC threshold was found to effectively reduce excess noise from low-difference genes and Page 7 reduce signatures to their most significant components [29, 30] . The resulting signatures were searched against the iLINCS Consensus Gene Knockdown (CGS) database to generate similarity indices between (a) the drug treatment signatures within a given cell line and (b) individual inflammatory gene knockdown signatures for 27 inflammatory genes with a potential role in fluoxetine's anti-inflammatory mechanism of action (i.e. drug treatment gene signatures were compared to gene knockdown signatures generated only in the same cell line).A concordance score is an adjusted correlation coefficient that can range from -1 to 1.iLINCS only reports a match if the concordance score is ≤ -0.2 or ≥ 0.2. Concordance scores outside of those parameters are considered statistically insignificant. In this way, we identified 779 total signatures (concordance ≤ -0.2 or ≥ 0.2) derived from comparisons of the 168 drug treatment gene signatures to CGS for 27 inflammatory genes in 11 different cell lines (Table S2) .We again filtered our list to include only the highest absolute concordance score (range -0.7166 -0.7982) for each drug treatment, knockdown, and cell line combination. This resulted in 395 concordance scores comparing 27 inflammatory genes and 4 drugs of interest across 11 cell lines (Table S3) . Mean concordance scores are calculated by averaging the concordance scores for a given drug-gene comparison across cell lines. Statistically significant outliers (P < 0.5) within the list of drug-gene concordance scores among cell lines containing calculated concordance scores for less than 3 drugs of interest were identified using the extreme studentized deviate method (Grubbs' test) and subsequently excluded.The entire process was performed using R version 3.6.3. The entire bioinformatic pipeline including raw data, analytical scripts, and results can be reproduced using our publicly available J o u r n a l P r e -p r o o f To assess the potential clinical utility of fluoxetine in the prevention or mitigation of cytokine storm syndromes, and to investigate the mechanism by which fluoxetine realizes its anti-inflammatory effect, we generated differential gene expression signatures produced by fluoxetine, paroxetine, bupropion, or dexamethasone drug treatments. We also generated differential gene expression signatures produced by genetic knockdown of inflammatory genes related to the initiation and maintenance of IL6-mediated cytokine storm. We then compared the drug treatment signatures with the genetic knockdown signatures to generate concordance scores which measure the degree to which a given drug treatment parallels genetic knockdown of a given inflammatory gene. When a drug treatment signature is highly concordant with a genetic knockdown signature, we surmise that this drug and this gene knockdown induce a similar pattern of gene expression changes [31] .We compared gene signatures generated from cell lines that have been treated with fluoxetine, paroxetine, bupropion, and dexamethasone to matched cell lines in which IL6ST was genetically knocked down with siRNA ( Figure 2A ). In this way, the differential gene expression signatures for drug-treated A375 or HEPG2 cell lines were compared to IL6ST knockdown A375 or HEPG2 cell lines, respectively. This allowed us to quantify the degree of similarity between pharmacologically initiated mRNA changes and those resulting from targeted knockdown of a specific gene. In A375 cells, concordance scores quantifying the similarity between drug treated To further develop the relationship between our drugs of interest, IL6ST, and inflammatory pathways, we again analyzed differential gene expression signatures caused by drug treatments in A375 and HEPG2 cell lines. This time however, we compared drug treatment signatures to those produced by NFKB1 knockdown ( Figure 2B ). As before, comparisons of these signatures generated concordance scores quantifying the degree of similarity between a drug treatment and NFKB1 knockdown. In A375 cells, these concordance scores are as follows: These data are particularly interesting in contrast to dexamethasone-induced transcriptional changes. Surprisingly, treatments with fluoxetine approximate inflammatory IL6ST and NFBK1 gene knockdowns more significantly than dexamethasone-a steroid routinely used to treat cytokine induced hyperinflammation. Administration of dexamethasone in porcine respiratory coronavirus-infected pigs downregulated IL6 in the early disease stages suggesting that corticosteroids such as dexamethasone may be beneficial to COVID-19 patients if administered during the early acute phase of infection [34, 35] . A study comparing over 2,000 patients being treated with dexamethasone to over 4,000 control patients receiving usual care showed that hospitalized patients receiving respiratory support such as mechanical ventilation or Page 13 oxygen demonstrate lower 28-day mortality when treated with dexamethasone [36] .Concordance scores generated by comparisons of fluoxetine treatment and IL6ST knockdown or NFKB1 knockdown are also distinctly higher than those comparing bupropion or paroxetine treatment with the same inflammatory gene knockdowns. This is striking given that both bupropion and paroxetine share monoamine neurotransmission profiles with fluoxetine. Previous reports describe the NF-kappaB family of transcription factors as regulating many proinflammatory target genes including IL6ST [9, 10, 37] . Taken together, our data suggest that fluoxetine induces a reduction in IL6ST-mediated signal transduction via NF-kappaB-mediated transcriptional changes. These data also suggest that the anti-inflammatory action of fluoxetine is independent of its action on monoaminergic pathways. Instead, fluoxetine may manifest its antiinflammatory character through a mechanism of action related to the suppression of inflammatory genes such as IL6ST and NFKB1.IL6 signaling is enormously complex and capable of eliciting both pro-and antiinflammatory cellular behaviors [38, 39] . Classical IL6 pathways reliant upon membrane-bound IL6R tend to elicit anti-inflammatory responses. In contrast, trans-signaling-mediated responses are distinctly pro-inflammatory and proceed by way of IL6ST on cells that do not express membrane-bound IL6R [40] . These trans-signaling-mediated responses require soluble IL6R(sIL6R) to interact with IL6 and IL6ST proteins (Figure 3) . A fluoxetine-mediated reduction in IL6ST signal transduction could therefore specifically decrease hyper-inflammatory IL6 pathways while maintaining the classic anti-inflammatory IL6 pathways critical to the reestablishment of homeostasis in hyperinflammatory disorders [41] . Indeed, our analysis shows Page 14 insignificant similarity between fluoxetine treated cells and IL6R knockdown cells (concordance score = 0.2467; supplementary tables 2 and 3).Recent work from our group demonstrates antidepressant-mediated inhibition of IL6 and NF-KappaB signaling pathways limit organ damage, decrease pro-inflammatory cytokine production, decrease intracellular migration of early-stage inflammatory response, and improve animal survival after an overwhelming systemic inflammatory response [42] . The present study further supports the potential of antidepressants like fluoxetine to prevent cytokine storm severity and reduce the risk of severe organ dysfunction and death for COVID-19 patients. Indeed, preliminary reports from a multi-site fluoxetine clinical trial in France [27] , as well as our group's ongoing fluoxetine clinical trial in America (NCT04377308) provide encouraging results suggesting fluoxetine treatment significantly reduces morbidity and mortality in COVID-19patients.Increased IL6 signal transduction causes cytokine storm which is associated with increased morbidity and mortality in COVID-19 patients. SARS-CoV-2 vaccine distribution is underway but immediate life-saving drug treatments are necessary to decrease case-fatality rates.NF-kappaB plays a pivotal role in cytokine storms through transcriptional activation of the proinflammatory cytokines IL6 and IL6ST. This study provides further evidence supporting the use of fluoxetine to decrease NF-kappaB signaling and thereby decrease the IL6ST signal transduction pathway driving cytokine storm in SARS-CoV-2 infection. Using fluoxetine to disrupt this NF-kappaB/IL6ST axis and mitigate the resultant cytokine storm may increase survival and decrease rates of hospitalization in COVID-19 patients.We generated differential gene expression signatures produced by fluoxetine, paroxetine, bupropion, or dexamethasone drug treatments across a variety of concentrations and treatment durations compared to control, untreated, wild-type cells. We also generated differential gene expression signatures produced by genetic knockdown of inflammatory genes related to the initiation and maintenance of IL6-mediated cytokine storm. Again, these signatures are in relation to control, untreated, wild-type cells. We then compared the drug treatment signatures with the genetic knockdown signatures to quantify similarity using concordance scores. When a drug treatment signature is highly concordant with a genetic knockdown signature, it generates a value approaching +1 and allows us to surmise that this drug and this genetic knockdown induce equivalent changes in gene expression. When no significant similarities exist, the concordance score approaches zero. When a drug treatment signature is highly discordant with a genetic Page 16 knockdown signature, it generates a value approaching -1 and allows us to surmise that this drug and this genetic knockdown induce inverted changes in gene expression. The transcription factor NF-kappaB binds the IL6 gene to induce transcriptional expression of the proinflammatory cytokine. Pro-inflammatory trans-signaling-mediated responses involve IL6 proteins binding to soluble IL6 receptors (sIL6R) which activates the IL6 signal transduction protein (IL6ST or gp130). IL6ST activation is integral to many intracellular cytokine-mediated inflammatory pathways including the cytokine storm / cytokine release syndrome driving many of the negative clinic outcomes associated with COVID-19.",USA,first author,2021-02-25,02
bf53a91db9dec0e88e279a4f2f0f0d3bcc120e34,Journal Pre-proof SARS-CoV-2 Antibody Seroprevalence Among Maintenance Dialysis Patients in the United States SARS-CoV-2 Antibody Seroprevalence Among Maintenance Dialysis Patients in the United States,"Coronavirus disease 2019 (COVID-19), caused by novel severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), was declared a global pandemic on 11 March 2020. 1 As of 31 July 2020, there were more than 17 million confirmed cases worldwide, including nearly 5 million in the United States. SARS-CoV-2 infection can result in a spectrum of clinical manifestations ranging from asymptomatic to severe symptomatology, including hypoxia, respiratory failure, and death. 2 Because any infected patient can transmit SARS-CoV-2, 3 it is vital to understand the actual burden of infection above and beyond the reported case rates of symptomatic COVID-19.In the United States, shortages in testing supplies and infrastructural limitations have precluded large-scale surveillance efforts. Fortunately, the seropositivity of anti-SARS-CoV-2 antibodies can be used to illuminate the underlying infection rates post hoc. Not surprisingly, given challenges in testing and surveillance, data from the general population in the United States demonstrate a large number of unreported SARS-CoV-2 infections that exceed the number of reported COVID-19 cases by many fold. [4] [5] [6] End-stage kidney disease patients receiving maintenance dialysis represent a special case, as they are enriched for several characteristics that are putative risk factors for COVID-19, including older age, high proportions of people of color, dense urban geographic footprint, as well as disproportionate rates of heart failure, diabetes, and obesity. 2, 7 Therefore, it may not be surprising that reported case rates are higher in these patients than in the general population. 8 However, the vast majority of maintenance dialysis patients are treated with hemodialysis. Following guidance from the Centers for Disease Control and Prevention, US dialysis organizations have put into place robust J o u r n a l P r e -p r o o f entrance screening procedures, whereby all patients entering a clinic are asked about symptoms, high-risk contacts, or both; patients who screen positive then undergo testing for viral RNA. 9 These procedures, as well as the high rate of interaction with the health care system (~13 clinic visits per month for dialysis treatments), may lead to a narrower gap between viral infections and reported cases among maintenance dialysis patients..Because dialysis patients undergo routine monthly laboratory testing, leftover patient samples provide an opportunity to explore SARS-CoV-2 seropositivity. We performed this national seroprevalence survey among patients receiving dialysis from a single provider organization to understand better: 1) the prevalence of SARS-CoV-2 infection nationally and within individual states; 2) how SARS-CoV-2 seropositivity varies across subgroups of patients; and 3) the magnitude of the gap between SARS-CoV-2 seropositivity and known COVID-19 case rates.The protocol for this study was reviewed by an independent institutional review board (IntegReview IRB) and was determined that under Title 45, part 46, of the US Department of Health and Human Services' Code of Federal Regulations, this study was exempt and that informed consent was not required. This study utilized deidentified remnant serum samples collected for routine laboratory screening from a national sample of maintenance dialysis patients treating with DaVita in the United States. Blood samples were collected prior to dialysis treatment in a 5-mL serum separation tube, clotted for 30 minutes, centrifuged, and refrigerated prior to shipment. All samples were processed at a if the corresponding test reading was > 1 arbitrary unit/mL, and negative otherwise. In addition to IgG concentration, patient sex, age, race, zip code, and collection date were recorded for each sample. Because this was a remnant sample study, no attempts were made to identify patients or to link findings to medical record data.Reported COVID-19 cases and deaths among patients with a COVID-19 diagnosis through 01 July 2020 were ascertained from DaVita electronic medical records overall and by US state. Beginning in March 2020, universal screening was performed upon entrance to DaVita clinics. All DaVita clinics utilize standardized screening tools and all clinic personnel are trained to perform screening in standardized manner. Patients screening positive for COVID-19 symptoms or indicating recent contact with individuals diagnosed with COVID-19 were subsequently tested for viral RNA with a nasal swab and a polymerase chain reaction (PCR) assay. Patients with a positive PCR test were assigned a COVID-19 diagnosis. Additionally, patients reporting receipt of a positive COVID-19 test result from another health care setting, such as a hospital or department of health screening center, were also assigned a COVID-19 diagnosis.Seroprevalence was determined by calculating the proportion of samples considered IgG positive overall and stratified by sample collection date, sex, age, race, and state. Confidence intervals were estimated using an exact binomial distribution.Seroprevalence estimates by patient race were also adjusted for age, population density, median income and geographic COVID-19 prevalence using a generalized linear model. Given the deidentified nature of the sample collection, correspondence between COVID-19 case status and serologic status could not be examined at the level of individual patients. Instead, we considered the ratio of aggregate known case rate to J o u r n a l P r e -p r o o f aggregate seropositivity rate, henceforth termed the infection discovery ratio. The infection discovery ratio was considered at the national level as well as at the level of individual states. Because patients who had died of COVID-19 prior to the sample collection period otherwise counted as cases, but were not sampled for seroprevalence, they were not counted toward the numerator of the infection discovery ratio. The infection discovery ratio was calculated as a cross-section as of 01 July 2020.We tested 12,932 remnant serum samples for IgG antibodies for SARS-CoV-2. Table 1 contains demographic characteristics of the patients from which the samples were obtained. Overall, 747 (5.8%) of the samples were seropositive. There was no longitudinal trend observed in seropositivity ( Figure 1 ). Figure 2 shows the seroprevalence by patient sex, age, and race. There was no difference in seroprevalence among samples from men and women. Seroprevalence was 6.0%-6.5% among samples from patients < 70 years old, 5 Overall, the reported COVID-19 case rate was 3.3% of all patients. The reported COVID-19 case rate ranged from 1.9%-9.4% of patients by state. The highest reported COVID-19 case rates were in New York (9.4%) and lowest in Oregon (1.9%). Overall, the infection discovery ratio was 1.7 but ranged from 0.5-4.5 for individual states.In this study, we found that seroprevalence of antibodies to SARS-COV-2 among maintenance dialysis patients in the United States varied by geography, age, race, and ethnicity. Moreover, our data indicate that there were more infections than known COVID-19 cases among the maintenance dialysis patient population as of 01 July 2020.Globally, there is evidence that reported COVID-19 case rates underestimate the true burden of SARS-CoV-2 infection. Maintenance dialysis patients have many characteristics that put them at high risk for COVID-19, and it has been reported that case rates are higher than in the general population. Here, we measured antibodies to SARS-CoV-2 using remnant serum samples in a large, national sample of US dialysis patients.We sought to understand the prevalence of SARS-CoV-2 infection nationally and within individual states, the variability of seropositivity among patient subgroups, and the magnitude of the gap between SARS-CoV-2 seropositivity and known COVID-19 case rates among maintenance dialysis patients.We estimated the national seroprevalence of SARS-CoV-2 among US maintenance dialysis patients to be 5.8% as of 01 July 2020. Unfortunately, there have been no published national seroprevalence studies among the US general population to J o u r n a l P r e -p r o o f compare to our estimates in dialysis patients. Moreover, there are salient differences between the US general population and the dialysis patient population in terms of characteristics, health status, and the ability to shelter in place; therefore, we did not attempt to standardize our estimates in order to extrapolate seroprevalence to the US general population. At the state level, seropositivity rates in our sample were directionally similar to reported case rates. For example, New York and New Jersey, states with high reported case burdens, had among the highest seropositivity rates in our sample, and Kentucky and Arkansas, states with low reported case burdens, had among the lowest seropositivity rates in our sample. Direct comparison of seropositivity rates in our sample to the general population of states must be interpreted cautiously for 2 important reasons: 1) our seroprevalence data were from a later period in time and are subject to be higher as the epidemic progressed; 2) the high-risk nature of maintenance dialysis patients.However, for states where general population data have been reported, seroprevalence in the dialysis population was approximately 2-3 times that in the general population:Louisiana (16.5% vs 5.8%), Connecticut (15.2% vs 4.9%), Missouri (5.0% vs 2.7%), and New York (23.6% vs 12.5%). 4, 5 Notwithstanding the above limitations (which would tend to bias in a direction that exaggerates risk in the dialysis population), this difference in seroprevalence is substantively lower than the 5-fold difference in reported case rates between maintenance dialysis patients and the general population. 8 Next, we sought to understand how seropositivity differs by patient demographics. Similar to other seroprevalence studies, we did not observe a difference between samples from men and women. 4, 10-12 Samples from patients older than 70 years were less likely to be seropositive. Mortality is higher among older patients diagnosed Finally, we compared seroprevalence estimates to known COVID-19 cases to quantify the gap between recognized and unrecognized infections in the maintenance dialysis patient population. Comparison of the known COVID-19 cases (3.3%) to SARS-CoV-2 seroprevalence (5.8%) indicates that there were actually 1.7 times more infections than known cases as of 01 July 2020. Similar estimates were reported for hemodialysis J o u r n a l P r e -p r o o f patients in China and the United Kingdom. 20, 21 However, our estimate is lower than reported for the general population, which ranged from 6-43 times more than the number of known cases in US states for which data have been reported and 10-16 times in European locales. 4-6, 10, 11, 22 The lower number of unrecognized infections among dialysis patients is likely related to higher testing rates relative to the general population. The majority of DaVita patients visit a clinic 3 times per week for hemodialysis treatments, are screened upon clinic entry, and referred for testing if symptoms are present. Therefore, it is highly probable that infections among dialysis patients are recognized at a greater rate than in the general population.Another recently published study measured seroprevalence of SARS-CoV-2 antibodies in serum samples from 28,503 patients treating at various independent dialysis providers throughout the US. 12 In general, we observed similar patterns of infection among patient types and geographies as they reported. However, their overall seroprevalence estimate was higher than in our study (8.3% vs 5.8%). This difference is most likely due to the fact that their samples were collected in July 2020, when national case rates were quickly rising, whereas the majority of our samples were collected in June, when case rates were relatively steady. Another key difference is that our study was performed among patients dialyzing with a single provider, which treats approximately one-third of all maintenance dialysis patients in the US and therefore, our results may be more representative of the patient population in the US.There are limitations to our study. The sensitivity of the antibody assay is imperfect; therefore, it is likely the seroprevalence and the number of undetected infections estimated here are low. Samples were collected 27 May -01 July 2020, when J o u r n a l P r e -p r o o f the daily new case rate in the United States was at a steady state after the initial peak in April. There was a national resurgence in cases beginning late June, which is not reflected in antibodies measured here, possibly due to insufficient time for seroconversion before study end. Because dialysis patients have impaired antibody responses, it is possible that some infected patients did not develop or lost IgG to SARS-CoV-2 and, therefore, were misclassified as never infected. The remnant samples were deidentified, and we could not match samples to previously known COVID-19 cases; therefore, we could not determine the actual proportion of cases that were truly asymptomatic or the relationship between symptom onset and antibody levels for those who were considered COVID-19 positive. Finally, this study was limited to patients at a single dialysis organization in the United States and may not generalize to maintenance dialysis patients treating with other providers or in other countries.In conclusion, we analyzed antibodies to SARS-CoV-2 in blood samples from more than 12,000 dialysis patients in the United States and observed a seroprevalence of 5.8% as of 01 July 2020. We observed similar patterns of infection among specific demographic groups and US geographies, as reported for the US general population. Our results indicate that there are 1.7 times as many SARS-CoV-2 infections as known COVID-19 cases among dialysis patients. However, due to tight surveillance, the number of unknown infections among dialysis patients appears to be substantially lower than reported among the general population.J o u r n a l P r e -p r o o f Peer Review: Received December 2, 2020. Evaluated by 2 external peer reviewers, with direct editorial input from the Editor-in-Chief. Accepted in revised form January 20, 2021.Center for Medicare and Medicaid Services. Preliminary Medicare COVID-19 Data Snapshot2020.Center for Disease Control. Screening and Triage: Screening Dialysis Patients for ",United States,abstract,2021-02-05,02
8d356bd915599fff7410e4a664901e65b587defc,Journal Pre-proof Assessment of COVID-19 Infection and Mortality Rates Among Nursing Homes with Different Proportions of Black Residents Assessment of COVID-19 Infection and Mortality Rates Among Nursing Homes with Different Proportions of Black Residents Running Title: COVID-19 Infection and Mortality Rates Among Nursing Homes with Different Proportions of Black Residents,"Our primary outcomes were (1) number of confirmed COVID-19 infections and (2) number of 80 confirmed or suspected COVID-19 deaths among nursing home residents. Both outcomes were 81 reported at the nursing home level as proportions of the total number of occupied beds. In these 82 data, confirmed resident infections were defined as positive lab tests for COVID-19, regardless 83 of symptomology. Deaths were defined as persons with suspected or laboratory-positive 84 COVID-19 who died. 85 86 Our primary exposure variable was the proportion of Black residents in nursing homes. 87LTCfocus reports percentage of Black residents from aggregated MDS assessments. Race is 88 selected by the MDS coordinator using information provided by the resident or the family. 17 89 Similar to prior research, we categorized proportions of Black residents in nursing homes as 90 none, <20%, 20-49.9%, ≥50%, or not reported. 3, 18 We combined the 50-79.9% group (n=558), 91 80-94.9% group (n=109), and the 95-100% group (n=14) to provide sufficient power. Not 92 reported denotes nursing homes that had missing data for their percentage of racial/ethnic 93 minorities. Because the most recently available LTCfocus data are from 2017, we examined 94 2011-2017 LTCfocus data to assess the stability of the percentages of Black residents in nursing 95 homes and we found they remained stable during the period. Therefore, we used the 2017 data to 96 characterize the proportion of Black residents in a nursing home. 97 98 Our models included several explanatory variables, choice of which was supported by previous 99 research. 19, 20 First were the facility characteristics. They included bed size (categorized as 0-49, 100 50-149, and 150+ beds), percent of facilities that were part of a chain organization and percent of 101 facilities that were for-profit; percent occupancy; percent Medicaid residents; mean case mix 102 J o u r n a l P r e -p r o o f index; and nurse staffing ratios defined as hours per patient day for registered nurses (RNs), 103 licensed practical nurses (LPNs), and aides, all of which came from the LTCfocus database. We 104 also included percentage of facilities reporting staffing shortages and percentage reporting a lack 105 of personal protection equipment (PPE) supply which originated from the CDC Module. nursing 106 home-level staff shortages included nurse/clinician and aide and lack of a one-week supply of 107 PPE included any of the following: N95 masks, surgical masks, eye protection, gowns, gloves, 108 and hand sanitizer. 20 Supplemental Figure 1 shows the gradient in these changes. 174 175 When stratifying by urbanicity/rurality, we found that COVID-19 infections and deaths increased 176 with increasing proportions of Black residents in both settings (Table 3 ). This association was 177 strongest in nursing homes with ≥50% Black residents in rural settings and these associations 178 were stronger than those observed in the non-stratified models. Changes across models were 179 similar to those reported in the non-stratified models (see Supplemental Figure 2 we found that other unobserved county characteristics, potentially rooted in structural bias, are 213 more important in explaining these disparities. 26 For example, counties with greater proportions 214 of Black citizens may experience scarcity of resources and service availability (e.g., 215transportation, health services), mistrust in the healthcare system among community members, 216 and low socioeconomic indicators (e.g., education, income). 27 Moreover, resources are provided 217 to communities in the context of a history of racial bias in which communities with higher 218proportions of Black members generally receive fewer resources. 28 In terms of analytic limitations, we excluded all nursing homes that did not pass CMS's quality 252 assurance checks, but it is possible that this exclusion may have limited our sample to better 253 performing nursing homes. Additionally, we calculated the proportion of infections and deaths 254 per occupied bed, but occupation rates may have been affected broadly by the pandemic and 255 specifically by infections and deaths in nursing homes. We were also unable to build a Model 4 256 in our stratified analysis. The reason for this is we could not account for county fixed effects in 257 these analyses because of the limited number of nursing homes in a rural county. In regard to our 258 sample, forty percent of the nursing homes were missing information on their proportion of 259Black residents and thereby classified as not reported. A sensitivity analysis that excluded these 260 nursing homes and estimated the models again revealed similar results (data not shown). While 261 we were able to situate the disparities in COVID-19 infections and deaths within potential 262 J o u r n a l P r e -p r o o f structural bias in counties, it is important to note that our access to COVID-19 data were limited 263 to the county level, and county-level analyses lack specificity when drawing conclusions about 264 racial disparities. Future research should consider these issues in more depth when census block 265 data become available. Finally, we examined differences in COVID-19 infections and deaths 266 across nursing homes by proportions of Black residents, but future studies should consider 267 whether these differences exist within nursing homes. 268As disparities in COVID-19 infections and deaths among nursing homes with higher proportions 270 of Black residents are potentially rooted in long-standing issues related to structural bias within 271 counties, it is important that we dismantle the bias and discriminatory structures that continue to 272 fuel these disparities. Some suggestions based on prior research are as follows: Invest in Black 273 communities where these nursing homes are located. Investment is needed in infrastructure, 274 social services, healthcare, education, housing, and neighborhoods. 30 Note: 95% CI reported. All coefficients expressed relative to the reference group, i.e., ""No black residents in a nursing home."" Models 2, 3, and 4 are clustered on county and include: bed size, urbanicity/rurality, region, occupancy rate, percent Medicaid, case mix index, nursing staffing ratios, staff shortages and lack of personal protective equipment (Facility Characteristics). Model 3 includes County COVID-19 burden which = proportion of county infections and deaths; County COVID-19 burden was measured by county-level cumulative COVID-19 infections and deaths. Model 4 includes county fixed effects (FE). ",USA,first author,2021-02-22,02
4f5d375caa914c71fae1dd4e88bc7c8de9536576,Multidisciplinary Recommendations Regarding Post-Vaccine Adenopathy and Radiologic Imaging: Radiology Scientific Expert Panel Manuscript Type: Special Report,"Abstract: Vaccination-associated adenopathy is a frequent imaging finding after administration of COVID-19 vaccines that may lead to a diagnostic conundrum in patients with manifest or suspected cancer, in whom it may be indistinguishable from malignant nodal involvement. To help the medical community address this concern in the absence of studies and evidence-based guidelines, this paper offers recommendations developed by a multidisciplinary panel of experts from three of the leading tertiary care cancer centers in the United States. According to these recommendations, some routine imaging examinations, such as those for screening, should be scheduled before or at least 6 weeks after the final vaccination dose to allow for any reactive adenopathy to resolve. However, there should be no delay of other clinically indicated imaging (e.g., for acute symptoms, short-interval treatment monitoring, urgent treatment planning or complications) due to prior vaccination. The vaccine should be administered on the side contralateral to the primary or suspected cancer, and both doses should be administered in the same arm. Vaccination information (date(s) administered, injection site(s), laterality, and type of vaccine) should be included in every pre-imaging patient questionnaire, and this information should be made readily available to interpreting radiologists. Clear and effective communication between patients, radiologists, referring physician teams and the general public should be considered of the highest priority when managing adenopathy in the setting of COVID-19 vaccination.Summary: COVID-19-vaccination-related adenopathy is a frequent imaging finding that may lead to a diagnostic conundrum in patients with manifest or suspected cancer, in whom it may be indistinguishable from malignant nodal involvement. This special report offers recommendations developed by a multidisciplinary panel of experts from three of the leading tertiary care cancer centers in the United States.The race to develop and execute effective COVID-19 vaccination programs is in full force, as the world grapples with staggering numbers of COVID-19 infections (1). In the U.S., two COVID-19 vaccines (Moderna and Pfizer/BioNTech), both belonging to a novel class of mRNA vaccines which stimulate immune cells to produce antigens, have received emergency use authorization (EUA) from the FDA. The overwhelmingly positive protective effect of vaccines is sometimes accompanied by unintended side effects, most of which are transient and minor. These include regional adenopathy, encountered in up to a third of cases with some conventional vaccines (2) . Lymph node enlargement following vaccination is related to locally activated antigens that accumulate at the injection site and later migrate to the draining nodes (3). As COVID-19 vaccines are administered intramuscularly into the deltoid muscle, vaccination-associated adenopathy typically occurs in the axilla and supraclavicular region (4, 5) .Recognition of this association is crucial in patients with cancer, where it can lead to under-or overdiagnosis and under-or overtreatment as well as heightened anxiety. This is especially relevant for patients with certain cancers such as breast cancer, head and neck cancers, lymphoma, and melanoma of the back and upper extremities, which have a predilection for metastasizing to these lymph node stations. Multiple reports have also found increased nodal and splenic metabolic activity following influenza vaccine on 18 FDG-PET, suggesting imaging findings related to regional and systemic immune response (6, 7) .In the Phase 3 trial leading to Emergency Use Authorization for the Moderna vaccine, adenopathy was reported as an unsolicited event in 1.1% of patients (8) . ""Axillary swelling or tenderness"" was listed separately and occurred in up to 16.0% in patients aged 18-64 years and up to 8.4% of patients over 65 years of age (vs. 4.3% and 2.5% in the corresponding placebo groups, respectively). Notably, in 0.3-0.6% of patients, symptoms were severe enough to require prescription medicine for relief. In the clinical trial leading to Emergency Use Authorization for the Pfizer-BioNTech vaccine, the self-reported rate of adenopathy in patients was 0.3% (9) . Notwithstanding that the reported rate of adenopathy likely underestimates the true number (10) , even at a presumed low relative rate, regional adenopathy will become a frequent incidental imaging finding as large numbers of the population undergo vaccinations I n p r e s s against COVID-19 in the coming months. Clinically, axillary swelling or adenopathy manifested within 2-4 days after either dose and lasted on average 1-2 days (Moderna) and 10 days (Pfizer-BioNTech).First, clear information is not yet available regarding what proportion of patients will experience some form of adenopathy on imaging, whether the rate of adenopathy will vary between different doses and between different vaccines, the size, number, laterality and morphology of affected lymph nodes, or how long nodes will remain detectable as asymmetrically enlarged or otherwise abnormal in appearance on the various imaging modalities. Extrapolating from preliminary cases (such as the one presented in Figure 1 ) and other conditions, the findings may persist for a longer period on imaging, given the higher sensitivity compared to physical exam (10), particularly on 18 FDG-PET, in which inflammatory activity may be detected even in non-enlarged nodes (Figure 2 ) (11) . The weight to be placed on the management and follow-up implications of specific imaging features (e.g. long-/short-axis dimensions, morphology of cortex, preservation of fatty hilum, doppler signal, SUV) remains unknown.As noted in the summary of recommendations provided in the Table, clear and As a general principle, the panel recommends against delaying COVID-19 vaccination due to imaging needs for patients with a history of cancer or for those undergoing screening for cancer. The estimated infection fatality risk of COVID-19 is orders of magnitude higher than the estimated mortality reduction achieved through effective cancer screening programs in the general population (12) . Moreover, mortality from COVID-19 is likely worse in patients with cancer (13).When feasible, the panel recommends performing all cancer-related imaging prior to vaccination. After vaccination, imaging for urgent clinical indications (e.g., acute symptoms, short-interval treatment monitoring, urgent treatment planning or complications) should not be delayed. For all other indications (routine surveillance, screening, staging), postponement of imaging for at least 6 weeks after completion I n p r e s s of recommended vaccinations should be considered. These recommendations are in line with those from the Society of Breast Imaging, which recently recommended that breast imaging may be postponed at least 4-6 weeks following the second dose of a COVID-19 vaccination ""when it does not unduly delay care"" (14) . Due to our preliminary experience of some nodes remaining enlarged after 4 weeks (Figure 1) , a longer interval is desirable, but this needs to be weighed against the patient's risk factors and the overall context. Special consideration should be given to modelling studies suggesting a large proportion of missed cancer diagnoses due to the pandemic (15) , with an expected rise in otherwise avoidable cancer deaths in the coming years (16) .In general, the vaccine should be administered on the side contralateral to the primary cancer site, if applicable, and both vaccine doses should be administered on the same side. CDC guidelines recommend intramuscular injection of Pfizer and Moderna vaccine into the deltoid muscle. Prior studies on other vaccines showed that injection in the thigh or gluteal muscles may adversely affect immunity response. Hence, the panel recommends following CDC guidance and not modifying the injection site based on cancer type or site.Vaccination information (date of each administered dose, injection site including laterality, and type of vaccine) should be included in all pre-imaging questionnaires, unless it is easily and reliably obtainable through another medical record source. This information should be made readily available to radiologists, who should consider it in their interpretation when possible vaccination-related findings are encountered. Depending on the practice setting, it may be desirable to include the full vaccination questionnaire information in all radiology reports containing possible vaccination-related findings. This may be particularly desireable when, for example, the providers involved in the patient's care are not part of integrated medical systems or when referrers may otherwise not have access to vaccination details.It is acknowledged that a single definition for ""adenopathy,"" whether related to cancer or other etiologies (such as vaccination), is not widely agreed upon. In the cancer setting, different criteria have been employed depending on several factors including the primary tumor site. It is beyond the scope of this manuscript to recommend a specific definition, and until more data become available, the committee recommends reporting morphologic (e.g. size, number, shape), functional (e.g. apparent diffusion coefficient value on MRI) and metabolic (e.g. standardized uptake values on PET) features of adenopathy encountered on imaging following vaccination. A standardized macro in the dictation weeks later may be obtained if there is a higher risk of metastatic adenopathy (e.g., breast, head and neck, upper extremity/trunk melanoma or lymphoma). Tissue biopsy should be considered in the setting of high nodal metastatic risk when immediate histopathologic confirmation is necessary for timely patient management. Multi-disciplinary discussion may be helpful in uncertain cases.New unexplained asymmetric ""bumps and lumps"" -incidental, self-detected or revealed during a physical exam -may generate anxiety and may prompt additional imaging and histopathologic assessment due to the possibility of cancerous involvement. It is of paramount importance to educate patients about the expected side-effects of COVID-19 vaccination and their significance. This can be achieved for example with a flyer in the waiting room or accompanying the appointment letter. The information should use lay terms and be understandable on an 8 th grade reading level. In a breast imaging service or practice, an example would be the following text: ""Lymph nodes in the underarms of people who were recently vaccinated for COVID-19 sometimes may become enlarged. This is an expected response as our bodies begin to develop antibodies to the vaccination. As a result, we recommend consulting with your health care provider and scheduling your annual mammogram either before or at least 6 weeks after completion of vaccination to reduce the need for additional testing. This recommendation is for people who do not have any breast symptoms. If you are having any problems with your breasts, you should not delay your visit with us."" Similar communications could be drafted in other clinical scenarios, as appropriate.Weeks before mass vaccinations against COVID-19 commenced, new strains of the virus had been identified (17) . It is only a question of time before new variants escape established vaccine coverage, requiring the development and administration of new vaccines. This cycle may well continue into the near future. Hence, COVID-19-vaccination-related phenomena such as onset, duration and size limits of associated adenopathy deserve further scientific investigation to inform future clinical guidelines. I n p r e s s",United States,abstract,2021-02-24,02
cb6b5e91f360a9eace01674ee8841a3f5f886a03,Black Nurses Collaborative Approach to Addressing COVID-19 in Black Communities,"The National Black Nurses Association (NBNA) was organized in 1971 under the leadership of Dr. Lauranne Sams, former dean and professor of nursing, school of nursing, at Tuskegee University in Tuskegee, Alabama. NBNA, was incorporated in 1972 in the state of Ohio, is the professional voice for African American-registered nurses, licensed vocational/practical nurses, nursing students, and retired nurses [1] . The organization includes 114 chapters in 33 states and the District of Columbia, Washington, DC. NBNA is a non-profit professional organization that promotes community service, health policy and advocacy, workforce expansion, and professional development.For 49 years, NBNA nurses and nursing students have worked to make a difference in the quality of life in our communities by providing culturally competent and congruent health services where Black and Brown people live, work, worship, and play. NBNA uses a community partnership approach to engage the Black population in addressing healthcare needs and outcomes. The organization also collaborates with other like-minded private and public agencies to effect healthcare changes through community service and education. During the novel coronavirus SARS-CoV-2 (COVID-19), Black nurses, while risking their personal safety and the health and well-being of their families, are serving as essential frontline workers and are providing direct care to patients in hospitals, nursing homes, and long-term care facilities, risking their and their families lives. These nurses also served as the most trusted source of information to help the Black community address the many myths and lack of information accuracy about COVID-19. Community-based services and education are the hallmark of NBNA's role in improving access to care and improved health outcomes in the Black population. NBNA members were working in their communities prior to COVID-19 providing preventative health screenings and health education on high blood pressure, blood glucose, cholesterol, HIV, cancer, sickle cell disease, and mental health.In the 1991, NBNA leaders received funding from the US Department of Health and Human Services Division of Nursing to develop a collaborative community health model (CCHM) [2] . The CCHM provides a framework to deliver structured and measurable programs to address health disparities and to improve the health status of the Blacks and other minority populations. Using the blueprint of Healthy People (HP) 2000 and subsequent HP2010, HP2020, and HP2030, the model provides a basis for addressing health protection and promotion, disease prevention, surveillance, education, and data management. In addition, the CCHM has an embedded community-based active engagement approach that support collaborative partnerships with advocacy groups, corporations, health systems, schools, universities, and governmental agencies. This model is also grounded in the concept of community inclusion, social justice, human caring, and healthcare as a fundamental human right.COVID-19 continues to spread in the USA with seven million positive cases on 9/27/2020 and a reported 311,102 cases over a 7-day period. As of the end of September 2020, the total number of deaths associated with COVID-19 in the USA is 204,033 [3] . With the COVID-19 pandemic, a disproportionate number of African American/Blacks (AA) are contracting and dying from the virus. AAs account for about 13.4% of the US population [4] and 18.3% of COVID-19 cases and 20.9% of the deaths [5] . The data seem to support a higher prevalence of COVD-19 in AAs with subsequent poor survival rates. Early during the COVID-19 pandemic, Black and Brown social activists; clinical, translational, and social scientists; politicians; and others began discussing the roles of health disparities and how social determinants of health were impacting outcomes in populations of color. The CDC [6] defines SDOH as societal and environmental conditions where people are born, grow up, live, work, play, worship, age, and transition life. SDOH include such factors as housing, food insecurity, transportation, education, social support, employment, income, social status, and racism and discrimination [4, 6] .During each national disaster such as hurricanes, tornadoes, or dangerous outbreaks of diseases, the USA returns to the same health disparities conversation and debate. Here lies the problem; the country engages in conversation but fails to develop and implement an action plan. After Hurricane Katrina, the health disparity conversation ended almost as fast as the water receded from the Ninth Ward in New Orleans. However, the same SDOH remained post the disaster. Post-COVID-19, the conversations about the living conditions of ""essential employees"" must continue. The USA needs an action plan to improve the lifestyle, environment, education, income, and access to healthcare of every citizen.Activists, politicians, and every day citizens must demand that the US health system moves from an illness and treatment model to a health protection and prevention model. The USA wastes billions of dollars every year. In 2019, researchers estimated that the waste accounts for 30% of total healthcare spending, and the waste is divided into six categories: (1) failure of care delivery, (2) failure of care coordination, (3) overtreatment, (4) pricing failure and low-value care, (5) fraud and abuse, and (6) administrative complexity [7] . When one considers the illness model of care that the US uses (focus on treatment and cures) and the estimated $700 to $900 billion in waste each year, it becomes apparent as to why our responses and ability to aggressively contain COVID-19 are falling short. When it comes to the Black and Brown communities, zip codes matter [4, 5, 8] . COVID-19 is a respiratory illness with an incubation period meaning that a person can be infected with the virus prior to experiencing and exhibiting symptoms [9] . COVID-19 spreads via contact and droplet from coughing. Therefore, one of the recommended treatments is isolation from others. When a person is living in poverty in poor housing and multi-generational families, the preventive measure of isolation is impossible. Black and Brown ""essential workers"" must use mass transportation, and early during this pandemic, they were not provided personal protective equipment which put workers and their families at risk. This pandemic has clearly exposed the fact that race, ethnicity, age, gender, zip code, education, income, and power and politics matter in the US healthcare system. COVID-19 data show that at-risk-population include those with pre-existing conditions, age 65 or older, males, healthcare workers, and other essential workers [9] .Since NBNA has an ongoing presence in the community and a large network of partners, we were one of the first to start informing and educating our communities by working with faith-based organizations, politicians, social service agencies, healthcare systems, public health departments, and many others. NBNA's Collaborative Community Health Model is used as the practice framework by nurses in our 114 chapters to reach out to other national organizations such as the NBNA provides educational webinars, workshops, and conferences. NBNA media footprint has expanded to include op-ed, news releases, and appearances on television and radio. The national office staff and local chapter members are working in advisory roles and on committees with companies that are in the healthcare space such Pfizer, VITAS Healthcare, CVS Health, Prolacta, Novartis, Abbott, Johnson & Johnson, UnitedHealth Group, and Gilead and hospitals such as Children's Mercy Kansas City. Through these networks, NBNA is able to sit at the decision-making table regarding research, clinical trials, and resource distribution.With regard to COVID-19, new partners have joined us in meeting the needs of front-line workers. When NBNA members needed personal protective equipment for our members and resources in our communities, partners such as PUMA, DTLR, Clove, Diddy Love Team, Careismatic Brands, Soul for Soles, Daisy Foundation, and Direct Relief joined NBNA's team. Through the efforts of these companies, NBNA provided face masks, shoes, shoe covers, gloves, gowns, caps, thermometers, and pulse oximeters to frontline workers. COVID-19 care kits were provided to patients and community members. In addition, NBNA members participated in food drives, provided meals for essential works, created safety rounds for checking on home-bound elders, and found time to support the Black Lives Matter movement and to care for protesters. Then, we had partners such as the Black Hollywood Education and Resource Center and other entertainers that provided mental help breaks for NBNA's members to relax, refresh, and provide self-care. NBNA partner with Pfizer and FirstResponderFirst to provide free counseling and mental health services to nurses across the country, including non-NBNA members. The organization through its 114 chapters is planning additional workshops and activities as COVID-19 and the flu season begin creating a twin pandemic.Healthcare in the USA is a big business and one of fastest growing job industries. It is estimated that seven in every10 jobs in the USA are related to healthcare. However, there is an under representation of AA in healthcare professional positions such as medicine, dentistry, nursing, pharmacy, and other health specialties. There are 3.9 million registered nurses (RN) in the USA. AA is only 7.8% of the US RN population [10] . Nursing is a science-based discipline, and potential students need a strong foundation in science, technology, and math. Due to poorly funded education systems in many AA communities, many students are unprepared for the academic rigor of healthcare-related curricula. NBNA is addressing this issue by working with elementary, junior high, high school, and pre-nursing college students. The organization's goal is to increase the number and percentage of AA registered nurses to 11% or higher of the total RN population. Workforce expansion is a key strategic focus of NBNA. NBNA's founding members recognized that in order to make a difference in the quality of life in their communities that black nurses across the nation had to take the lead [1] . Therefore, we are on the frontline fighting structural and institutional racism and injustices.The COVID-19 pandemic has moved the USA closer to the edge of chaos. In the midst of this healthcare crisis, there are societal issues around systemic and institutional racism that expose how law and policy in the USA contribute to the SDOH and poor health outcomes. It is in our hands to seize this moment and become innovators of solutions or remain bystanders of injustice. The USA as a nation cannot continue to quarantine and relegate our conscious with silent voices. The USA should have learned from World Wars I and II, the Vietnam War, Jim Crow laws, the HIV/AIDS epidemic, and other man-made and natural disasters that justice, equity, and human caring matters. The call to action is: What will the US do differently this time? What lessons will the political powers and scientists embrace, and what visible, measurable changes will the people demand? Most importantly is how will business, hospitals, healthcare industry, and educational institutions lead this change. Change must come because COVID-19 has shown us that we are all vulnerable, either directly or indirectly.Code Availability Not applicableConflicts of Interest The author declare that she has no conflict of interest.Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/.",USA,first author,2021-02-12,02
6fab76179a14250afbe0a1fc11d6870f06d6815b,European Journal of Radiology of COVID-19 Patient Prognosis Using Deep Learning-based CT Image Analysis and Electronic Health Records,"Reverse-transcription polymerase chain reaction (RT-PCR) [2,3] assay is currently the mainstay for the diagnosis of COVID-19 pneumonia. While early diagnosis is the key to initiate patient isolation and contact tracing to reduce its spread, assessment and prediction of the severity of COVID-19 pneumonia is important to initiate supportive treatment, project need for hospital admission and anticipate the use of mechanical ventilation (MV) and transition to intensive care unit (ICU). Computed tomography (CT) provides important information in COVID-19 pneumonia, especially for patients with moderate to severe disease as well as those with worsening cardiopulmonary status. CT helps evaluate the infection severity based on presence, extent, and type of pulmonary opacities such as ground-glass opacity (GGO), consolidation, and J o u r n a l P r e -p r o o f crazy-paving patterns [4] [5] [6] . Radiologists can grade the imaging severity of pulmonary opacities using a point-based scoring system [7, 8] . However, such a scoring system is labor-intensive and can be timeconsuming.Recently deep learning has been widely applied to various medical imaging applications. As for COVID- 19 , there are several reports on utilizing deep learning for accurate differentiation of COVID-19 from other lung diseases and segmenting the opacity regions [9] [10] [11] [12] [13] [14] [15] [16] . At the current resource-limited situation, prognosis prediction for COVID-19 is of paramount importance for patient management and decision making, e.g. MV usage and ICU admission. Several studies have explored the role of derived CT biomarkers for prognosis, alone [8, 17] or combined with electronic health records (EHR) [18, 19] , all based on datasets from one institution or country. Considering the differences in medical resources and public health strategies [20, 21] , it is unclear if the risk factors identified would be the same for different regions.In this work, we explored the risk factors for COVID-19 prognosis based on datasets from multiple institutions across the world. We first developed a deep learning-based CT segmentation network using datasets from different countries. CT-based biomarkers, total opacity ratio (TOR), and consolidation ratio (CR) were derived based on the network output. The CT biomarkers were used together with the EHR data for prognosis analysis to identify potential predictors for patient severity outcomes.Contributions of this work include two aspects: (1) deep learning-based CT image segmentation for COVID-19 pneumonia was developed and validated based on datasets from different institutions; (2) COVID-19 patient prognosis analysis was conducted based on datasets from multiple cohorts using both CT-derived biomarkers and EHR data.This study was approved by the respective Institutional Review Boards (IRBs) and informed consent forms were waived due to the retrospective nature of this study. The whole dataset consisted of 369 non-contrast J o u r n a l P r e -p r o o f chest CT examinations of patients with RT-PCR assay positive COVID-19 pneumonia scanned between January 1, 2020 and March 30, 2020, from five hospitals across the world. Of these, manual segmentation of all regions with pulmonary opacities related to COVID- 19 Healthineers, Forchheim, Germany). All chest CT images were resampled to 5mm section thickness and 256 × 256 resolution in the transverse plane. All datasets were initially graded for the type of pulmonary opacities by two fellowship-trained thoracic subspecialty radiologists (XX and XXX with 16 and 13 years of clinical experience in thoracic imaging), who supervised the annotation of each opacity by two postdoctoral research fellows (with 1-2 years of experience in chest CT research). These manually segmented opacity regions were used as ground truth during network training and testing. For the datasets with EHR, detailed summaries are presented in Table 1 . A flowchart of the work is also given in Figure 1 for better understanding of the data organization and processing.The network structure used in this work was based on a dense 3D network structure, which can fully extract features from input images because of better information propagation enabled by dense connections [22] .The Diagram of the network structure is shown in Figure A. 1. It is composed of an encoder path to extract contextual features and a decoder path to recover the image details, which contains the dense blocks as well J o u r n a l P r e -p r o o f as transition-down and transition-up modules. Each convolutional kernel has the size of 3 × 3 × 3.Transition-down module composes by a 1 × 1 × 1 convolution with stride 2 at X, Y axis which results in 1/2 spatial resolution reduction on the length and width of the input feature maps. It contains in-total 9 dense blocks, 4 transition-down and 4 transition-up modules. The last layer is a 1 × 1 × 1 convolution followed by the sigmoid activation function. The total number of trainable parameters for the network is 5.5 million.To let the network focus on regions inside the lung, a lung mask was generated using a pretrained U-Net [23] . The network inputs were 3D CT images inside the lung mask and the outputs were the probability maps of the opacity regions inside the lung. The soft Dice [24] , defined aswas utilized as the objective function, where is the predicted probability map and is the binary ground truth. The soft Dice is an approximation of the Dice coefficient, which can directly use the outputted probability map without pre-defining the threshold. During testing, we used a threshold of 0.5 to generate the binary segmentation mask to calculate the Dice coefficient. The network was implemented based on TensorFlow 1.14 [25] . The Adam optimizer [26] was used during network training to optimize the softdice objective function.During training and testing, we used 3D patches as the network input due to the graphics processing unit The segmentation network output regions of pulmonary opacities (inclusive of all opacities such as ground glass, consolidation, mixed and crazy paving patterns). After obtaining the regions of pulmonary opacities, a threshold of -200 Hounsfield unit (HU) [27] was used to demarcate the consolidation regions inside each pulmonary opacity. Signs of consolidation regions can indicate advanced or more severe disease forms.Both the consolidation regions and the pulmonary-opacity regions are useful for CT biomarker derivations.In our study, two biomarkers were extracted from the CT images based on the network output: TOR, which was defined as the volume of pulmonary-opacity regions divided by the total lung volume; and CR, which was defined as the volume of consolidated regions divided by the total lung volume. For prognosis and survival analysis, both the TOR and CR derived from the CT images were tested as potential predictors.Note that all TOR and CR were calculated based on the network prediction and no TOR and CR were based on manual segmentations.After obtaining TOR and CR, further prognosis analysis was conducted on datasets from three institutions: and CR for all three cohorts (P-value < 0.004), which might justify why CT derived biomarkers (TOR or CR) were predictors in both models #1 and #2.We also studied the risk factors related to patients' survival time based on datasets from INSTITUTE-1where the time points of mortality/discharge were available. There are various studies focusing on opacity-region segmentation from the COVID-19 CT datasets. Huang et al [12] have developed a CT segmentation network in order to perform serial quantitative CT assessment of COVID-19. To make the network training more efficient, Shan et al have devised a human-in-the-loop strategy to reduce the manual labelling efforts [28] . Chaganti et al [27] have designed a deep learning pipeline to perform semantic segmentation and various severity measures together. Fan et al [29] has developed a semi-supervised approach to alleviate the shortage of labelled data. To overcome the pitfalls of noisy labels, Wang et al [30] have developed a noise-robust segmentation network through the usage of a novel Dice loss and an adaptive self-ensembling training framework. Wu et al [31] have developed a weakly supervised network based on hybrid labels to segment both opacity and consolidation regions from COVID-19 CT datasets. Amyar et al [16] used the multi-task loss to improve the segmentation of infection regions in COVID-19 CT images. In this work, we developed a 3D dense network for CT image segmentation based on datasets from five institutes across the world. The dense network structure improved the segmentation performance over traditional UNet by reducing the number of training parameters [32] .Two biomarkers, characterizing the opacities and consolidations, were derived from the network output. In [33, 34] and Sequential Organ Failure Assessment (SOFA) score, known risk factors of COVID-19 mortality [35] . Abnormal WBC count is also observed in other COVID-19 datasets [35, 38] . Previous studies [18, [35] [36] [37] [38] [39] [40] [41] [42] have also reported other laboratory tests as risk factors for adverse outcomes of COVID-19 pneumonia, including lactate dehydrogenase (LDH), lymphocyte count, and high-sensitivity C-reactive protein (hs-CRP). However, these factors were not significant predictors for prognosis based on our datasets. In [43] , CT images and laboratory tests were combined for the prognosis analysis, which used datasets from only one country. It showed that combining CT and lab tests can help improve the prognostic accuracy, indicating Albumin and C-reactive protein as important risk factors. These laboratory tests were not present in our prognosis models J o u r n a l P r e -p r o o f based on our datasets. The difference between our prognosis model and the prior investigations stated above might be due to difference in treatments, sample sizes, measurement time, or population, which deserves further investigations.Our current study has several limitations. Due to the small sample size of the ICU patients in INSTITUTE-2 (10 out of 102), it is difficult to conclude that age and SpO2 were not risk factors for these patients. In addition, the EHR data came from different timepoints: it represented the last measurement before the CT scan in INSTITUTE-3 but on-admission measurement in INSTITUTE-1 and INSTITUTE-2. The hospitalized patients were more likely to be on supplemental oxygen therapy in INSTITUTE-3, which can explain the insignificant difference of SpO2 between the two groups as shown in Figure 6 . We also want to point out that the percentage of CT opacity regions to the whole lung depends on the timepoint when the CT scan was performed. For our prognosis model, the timepoint when the CT scan was performed was not considered in our prognosis model, which is one limitation of our study and other studies which use CT opacity as a biomarker without considering the time course. Currently Chest X-ray is widely used for prescreening and multiple timepoints of CXR are available. As the specificity of CXR is lower than CT regarding COVID-19, performance of biomarkers derived from CXR compared to CT is unknown.Conducting prognosis analysis based on CXR and EHRs is one of our future directions. Finally, in this work the prognosis model was constructed for each institute individually, without building a unified prognosis model for all institutes. Reasons for not building a united model is due to different treatment policies among the institutes and also the differences of measurement time. Pursuing a united prognosis model is one of our future works.In conclusion, based on datasets from multiple institutions across the three continents, we have developed a generalizable deep learning model to segment opacity regions based on CT images from COVID-19patients. Prognosis analysis was conducted using the derived CT biomarkers and EHR data. ResultsInformed consent Informed consent form was waived due to the retrospective nature of this study.Author Quanzheng Li has received research support from Siemens Medical Solutions. Other authors declare that they have no conflict of interest.This work was supported by the National Institutes of Health under grants RF1AG052653. The Wilcoxon signed-rank test was performed between the patient group with non-severe outcome and the patient group with severe outcomes. Correspondingly, *, **, and ns, located at the top of each bar plot, represents p-value<0.05, p-value <0.01, and non-significant, respectively. WBC = white blood cell; SpO2 = peripheral oxygen saturation; TOR = total opacity ratio; CR = consolidation ratio. ",United States,first author,2021-02-05,02
91c923e2f22c034bd128f842b1fbccaec0e0834e,I n p r e s s Lymphadenopathy in COVID-19 Vaccine Recipients: Diagnostic Dilemma in Oncology Patients Manuscript Type: Case Series,"The United States Food and Drug Administration issued emergency use authorization for two vaccines, Pfizer-BioNTech and Moderna COVID-19 vaccines, to help decrease COVID-19 infection and death in December 2020. As of February 6, 2021, about 28.9 million people in the United States had received one or more vaccine doses. (1) (2) (3) . In conjunction with the rapid administration of these vaccines, we have started to observe secondary effects on diagnostic imaging.In clinical studies, axillary lymphadenopathy was reported on the ipsilateral injection side (4, 5) .Ipsilateral axillary swelling/tenderness was the second most frequently reported local reaction to the Moderna COVID-19 vaccine, occurring in 11.6% and 16.0% of recipients following first and second dose respectively. In the Moderna cohort, clinically detected axillary and supraclavicular lymphadenopathy was reported in 1.1% of study participants within 2-4 days after vaccination, as an unsolicited adverse event (4) . In the Pfizer-BioNTech COVID-19 vaccine trial, the rate of ipsilateral axillary and supraclavicular lymphadenopathy was reported to be 0.3% among vaccine recipients versus <0.1% among placebo group (5).In the above vaccine trials, abnormal lymphadenopathy was reported based on physical examination rather than using imaging. In our center, we have observed unilateral axillary lymphadenopathy in five patients using different imaging modalities including PET/CT, MRI and ultrasonography. Initial diagnosis was concerning for metastasis; however, further investigation revealed that these patients had received COVID-19 vaccinations prior to imaging. A description of these patients is below. I n p r e s s Materials and Methods: An institutional review board waiver was obtained for this HIPAA compliant retrospective case series. Cases were identified from our institution from 12.21.2020 to 1.27.2021. In two cases diagnosis was confirmed by histopathology. In three, diagnosis was made based on combination of clinical and radiologic information. For Cases 1-4, the lymphadenopathy was discovered incidentally on radiologic imaging. Case 5 presented for evaluation of left breast and left axillary pain. pseudoprogression secondary to immunotherapy. Given that the biopsy proven index tumor showed complete response to treatment and true progression could not be excluded, a biopsy was recommended. However, further investigation revealed that the patient received the second I n p r e s s dose of Pfizer-BioNTech COVID-19 vaccine six days prior to PET/CT and there was triangular intramuscular FDG uptake in the left arm at the injection site ( Figure 1 ). Based on this information, left axillary lymphadenopathy was attributed to recent vaccination. Findings were discussed with the patient, and the patient opted for observation instead of biopsy. Follow up of the lymphadenopathy will be obtained as part of the patient's three-month follow-up PET/CT for melanoma surveillance. We have highlighted five cases with ipsilateral axillary lymphadenopathy following administration of Pfizer-BioNTech vaccine. Ipsilateral axillary lymphadenopathy following vaccinations has been previously reported with vaccinations other than COVID-19. For example, ipsilateral axillary and supraclavicular lymphadenopathy was clinically reported in a patient following HPV vaccine administration (6) . Radiologically, hypermetabolism in the ipsilateral lymph nodes was reported with 18-FDG PET/CT exams following seasonal H1N1 Influenza-A vaccines (7-9). Shirone et al reported hypermetabolic ipsilateral lymphadenopathy in 4 of 83 patients (4.8%) following seasonal influenza vaccination and all these reported cases were within I n p r e s s seven days following vaccination (9) . On January 22, 2021, the Society of Breast Imaging issued a statement for management recommendations of ipsilateral axillary lymphadenopathy following COVID-19 vaccinations. A recent ultrasonography case series of four patients, demonstrated ipsilateral asymmetrical lymphadenopathy following vaccination with both Pfizer-BioNTech and Moderna vaccines (10, 11) . None of these were confirmed as reactive lymphadenopathy on histopathology; but based on clinical and radiological findings, follow-up was recommended.Although lymphadenopathy related to vaccination has been known in breast cancer imaging, the unprecedented administration of COVID-19 vaccines is affecting almost all modalities of imaging.To our knowledge, a single PET/CT case was published similar to our fourth patient, although this case was without pathologic confirmation (12) .In two cases, we had pathologic confirmation of benign reactive lymphadenopathy secondary to vaccination and to our knowledge, these are the first pathologically proven cases in the literature.Although, the remaining three cases are not confirmed as reactive benign lymph nodes with histopathological evaluation, as we described above, it is more plausible to attribute these findings to recent vaccine administration. At present, no data is available regarding the duration of radiologically evident lymphadenopathy or appropriate follow-up intervals. Until data becomes available, management will be guided by clinical context, particularly in patients with history of cancers with specific propensity towards axillary lymphadenopathy.Due to widescale vaccination of the majority of the U.S. population, axillary lymphadenopathy due to COVID-19 vaccination is likely to be encountered in oncologic patients. In addition, in this limited series, a triangle of intramuscular inflammation was demonstrated at the injection site I n p r e s s on MRI and PET/CT, as also described by Eifer and Eshet (12) , suggesting vaccine-related inflammation.Overall, our findings are important, particularly for cancer patients. Radiologists, oncologists, and internists should be aware of this secondary effect of vaccination to obviate unnecessary changes in management, unnecessary patient emotional stress or biopsy. ",USA,first author,2021-02-24,02
22d3c45d6a0f99f63d6168a67265bd20fa726d83,Journal Pre-proof Learning from the first wave: Lessons about managing patient flow and resource utilization on medical wards at providence health during the COVID-19 pandemic Learning from the First Wave: Lessons about managing patient flow and resource utilization on medical wards at Providence Health during the COVID-19 pandemic,"As of August 13th, 2020, there are just over 21 million officially reported confirmed cases of the novel coronavirus infection causing coronavirus disease 2019 throughout the world. The global pandemic is continuing to rapidly spread throughout the world as shown by a continued high record of 285,486 officially reported confirmed cases per day. In Canada, there have been 121,414 officially confirmed cases with 4,274 cases from British Columbia, of which 552 required hospitalization.In terms of the scale of transmission and exerted impacts within the first wave of this pandemic (January 2020 -June 2020), countries could be classified into three main groups: one first group (e.g. Germany, Italy, Canada, New Zealand) [1] had reached and passed a peak of the pandemic (in terms of daily confirmed cases) and had decreasing transmission rates. The second group (e.g. Brazil, Iran) was in the process of hitting a peak and transmission rates were plateauing. The third was still experiencing a substantial increase in daily confirmed cases and had increasing transmission rates (e.g., India, Columbia) [2] . Many countries in the first category were effective in ""flattening the curve"" of the virus by implementing a wide variety of policy and preventative measures. These measures, designed to slow the spread of the virus, included timebased quarantines, border closures, mandatory lockdowns, travel bans, social distancing and hand washing among others. The economic costs and the scale of social consequences of these measures varied widely and as many countries in the first group relaxed preventative measures and re-opened economies, there was a growing need to specifically target measures with maximum impact and minimal economic cost in preparation of potential subsequent waves [3] .The cycle of community -health care facility -community transmission has been an important source of viral propagation and interventions designed to limit the size and scope of outbreaks at J o u r n a l P r e -p r o o f these facilities are particularly important opportunities to intervene. This focus on communityhealth care facility -community transmission is important not just for the health and wellness of our front-line workers, but also because it represents a major source of potential super-spreading events like we have seen in previous SARS infections [4] .In this paper, we report the experience of adapting the operational and planning systems used on the inpatient medical units at St. Paul's Hospital in Vancouver, BC during the first wave of the pandemic in our Province. Our aim during this first wave was to develop a scalable, flexible system of managing patient flow on our wards that provided the necessary level of biocontainment and safety for both patients and health care workers, thus minimizing the potential for nosocomial transmissions. More, we report on the lessons of our modified Traffic-Control-Bundling protocol for managing diagnostic and operational uncertainty, improving patient flow, and minimizing nosocomial transmission of COVID-19 to health care workers (HCWs).Reporting on these lessons is needed. There has been very little shared information within the international medical community on planning and operational procedures used to mitigate the spread of COVID-19 within hospitals. Given the risk of subsequent waves of infection, this research is useful for healthcare providers working in countries in any stage of their outbreak. Furthermore, as we highlight in section 2.0, while patient flow protocols for COVID-19 learn and build on protocols for other respiratory pathogens such as the flu and SARS, prior research on this has focused on building new facilities to aid containment. With our case, an existing facility was reconfigured to be adjustable to attain disease containment in conjunction with uncertainty about disease transmission and varying patient load on the facility. J o u r n a l P r e -p r o o fIn Canada, by April 28th, an estimated 10 to 20% of all officially reported confirmed cases were frontline healthcare workers. By this date, 428 healthcare workers represented about 21% of the virus cases reported in the province of British Columbia (BC), the jurisdiction of our study [5] . Other nations reported similar healthcare worker exposure rates with up to 10% of reported cases in China [6] and 9% of reported cases in Italy [7] , though the hardest hit regions such as Spain reported rises up to 20%.As shown in Figure 1 It is likely that nosocomial outbreaks (i.e., infections caught in the hospital) play an important role in amplifying local outbreaks [8] , and that the magnitude of this impact increases when health care facilities are forced to operate above capacity due to the massive escalation in load that comes with a health crisis.J o u r n a l P r e -p r o o f Literature on implemented protocols for improving patient flow during pandemic times are scarce. In this section, four protocols will be discussed to contrast the approach taken by St.Paul's Hospital. The common objective of all these protocols is to control patient flow to effectively minimize nosocomial transmission of COVID-19 and hence reserve and maintain the critical medical resources as well as limit the spread of COVID-19's impact. Table 1 compares and contrasts the known pandemic protocols implemented for improving patient flow and mitigating nosocomial transmissions. Table 1 here *** Traffic Control Bundling (TCB) is a patient flow protocol that was first implemented during the 2002 SARS outbreak in Taiwan to effectively reduce infection rates among health care workers (HCWs). Characteristics of TCB include an outdoor triage to separate infected from non-infected patients, the use of isolation wards or hot zones where infected patients are quarantined into individual rooms and the transfer of infected patients using tightly controlled dedicated routings completely separate from clean zones [9] . In addition, TCB advocates the use of transition zones between the clean and hot zones. The transition zones have directional signs, regular training of HCWs on TCB protocols and controlled disinfection in the clean and transition zones with necessary cleaning of fomites for hot zones to further reduce risks of transmission [9] . As it effectively reduced nosocomial transmission for Taiwan during the SARS outbreak, these researchers anticipate that TCB will work effectively against COVID-19 with a marginal enhancement.Enhanced Traffic Control Bundling (eTCB) extends the standard protocols of TCB but also establishes a quarantine ward or intermediate zone in which patients with atypical symptoms J o u r n a l P r e -p r o o f are required to stay for the entire incubation period. This protocol also advocates checkpoints for hand disinfection, requires mandatory face masks for visitors along with enhanced hospital cleaning and disinfection [10] . eTCB is anticipated to break the community-hospital-community transmission cycle as TCB did with SARS.The University Hospital Cologne in Cologne Germany recently implemented the COVID-19 Rapid Response Infrastructure (CRRI) as a protocol for managing patient flow.While the CRRI shares common traits with eTCB, it is unique as it recommissioned an entirely separate building for its purpose and all patients suspected of infection were to approach CRRI directly for initial triaging with nasopharyngeal swab and other preliminary tests [11] . According to authors, the implementation of CRRI effectively reduced the burden of the hospital's ER department while increasing the numbers of tests being conducted [11] .The fourth protocol we discuss was used at the Policlinico Maggiore Hospital in MilanItaly. This region was one of the most impacted areas in Europe. The hospital established an intensive care unit (ICU) section for the COVID-19 positive patients while maintaining normal ICU operation for other patients [12] . The key difference with this protocol was the use of a pretriage assessment, carried out in an ambulance or a shelter unit outside the ER, to identify patients with and without respiratory symptoms [12] . In order to allow time for test results to be confirmed, an isolated staging area was established in the ER department for patients with respiratory symptoms, while patients with the most severe hypoxaemia were assigned to a ""red area"" with mechanical ventilators [12] . This hospital also implemented advanced protocols for managing patient flows including the transfer of confirmed patients via dedicated routes, applying CT scan of the chest during transfers, disinfecting hallways after each transfer and setting up checkpoints with mandatory body temperature checks [12] . This research is especially important to the healthcare literature due to the high volume of incoming patients during COVID-19 pandemic, its geographic and temporal variability, and the high infection rates among HCWs around the world. We describe a system of modified Traffic Control Bundling within the existing hospital infrastructure that is both flexible and scalable making it specifically designed to handle the increased uncertainty that exists during a pandemic.This system more effectively allows hospitals to utilize existing resources, minimizes erroneous resource allocation, and allows more effective matching of their supply and demand.J o u r n a l P r e -p r o o fSt. Paul's Hospital is an inner-city tertiary care center located in downtown Vancouver, BC Canada. It is a referral center for patients located in both BC and the Yukon Territories.There are 5 Internal Medicine run Clinical Teaching Units (CTU) that admit patients to beds located on 4 separate wards (7a through d) with overflow capacity to other off-service wards.Each ward consists of 5 private rooms, 4 semi-private (2 beds per room), and 3 group (4 beds per room) rooms. CTU teams would typically be divided geographically, with one team per ward and one roaming team with patients on all 4 wards, given capacity constraints it is common for these teams to have patients admitted to other off-service wards. The novel nature of COVID-19 means that not only is it new to society, but our understanding of disease diagnosis and how it is transmitted (i.e., is it aerosolized or not, and under what circumstances might it be aerosolized) is limited. This in turn impacts our understanding of how to manage patient flow to prevent nosocomial spread. While a number of cohort studies on patients from China [13] , Italy [14] , and New York [15] Yellow wards are cared for by designated COVID teams to limit potential spread to HCW and J o u r n a l P r e -p r o o f patients in Green zones. A triage process is decided upon by the admitting service to guide patient flow through these wards. The operational goals of the system are to limit the length of stay and number of patients located in yellow zones as these also represent possible opportunities for nosocomial spread. Patients that don't have COVID-19 infection are exposed to a high-risk environment, and patients with COVID-19 have an increased chance of spreading their disease to other patients. Because the pre-test probability of disease for a given admission to hospital changes so rapidly during a pandemic, the admitting team must remain astute to these changes and clearly/reliably update their processes for designating patients to various wards. On admission the epidemiologic risk, history, physician exam, and investigations lead the admitting staff to assign a pre-test probability for COVID-19. Any patient with a positive swab goes to the red wards. Patients with low pre-test probability get admitted to the yellow ward and once their first COVID-19 swab is negative they are moved to a green ward. Patients with moderate pre-test probability require two negative Nasopharyngeal (NP) swabs 24 hours apart and consistent clinical picture to designate them low enough risk to be moved to a green zone.Patients with high pre-test probability often either stay in the Yellow zone until discharged despite negative testing or require multiple diagnostic tests and a compatible clinical diagnosis before moving to a green zone.The St. Paul's Hospital case is also interesting in that it involved temporarily reconfiguring an existing health care facility (i.e. no new extra space was required). Whereas the prior literature cases in Table 1 involved creating completely new facilities or required extensions beyond current facilities for the pandemic. This is important for public health care facilities which tend to be highly constrained for capital for new infrastructure projects [16, 17] .Furthermore, existing facilities need to be able to cope with changing demand for resources from other admitting services, as well as patient loads due to planning decisions for multiple hospitals in the region. In response, St. Paul's Hospital not only reorganized the layout of its facility to have the three zones (Green, Yellow and Red), but also framed the zones using adjustable dividers. This allowed the size and capacity of each zone to be adjusted. Another key layout change involved creating a negative air pressure vacuum in the patient rooms of the Yellow and Red zones through the configuration of vents through windows to allow for greater air transfer outward than inward.J o u r n a l P r e -p r o o fAs COVID-19 infections in health care facilities continue to occur, it has become increasingly clear that community -health care facility -community transmission is important not just for the health and wellness of our front-line workers but for entire communities [18] . The Lessons learned for implementing the modified TCB protocol fall into categories of risk management, capacity management and demand management. One invaluable lesson has been the overall structure of the medicine wards in their ability to refine themselves using a heuristically based system of capacity and demand management. As shown in Figure 3 , implementation of the protocol has provided the ability through which wards can expand and contract to best react to the pandemic demands while maintaining daily hospital procedures. While having similar characteristics of eTCB patients admitted to yellow wards can be effectively moved to green spaces when risk of COVID-19 is felt to be low enough.Use of enhanced universal precautions on green wards (mandatory mask and face shield for all patient interactions, reduced visitation privileges).Flexibility allows yellow and red wards to expand or contract in order to adapt to varying levels of COVID-19 patient admissions.Reduced risk of nosocomial infections on yellow wards for patients and staff.Enables best available evidence and up to date clinical factors to inform patient flow in the hospital by developing probability Potential to experience scale-issues when a large surge of COVID patients occurs that is greater than hospital bed capacity.Costs: 1 extra handover of patients by nursing and physicians. Increased administrative burden to facilitate extra intra-site transfers. Increased administrative burden to adjust ward sizes/risk profiles to up to date clinical evidence.",Canada,first author,2021-02-16,02
a6e44673184653ef64e566e6b05bb02a6d4bba6b,On COVID-19-safety ranking of seats in intercontinental commercial aircrafts: A preliminary multiphysics computational perspective,"In the present-day world, where on one hand public policy makers are grappling to contain the spread of COVID-19 (Anderson et al. 2020 ), on the other hand certain transit systems are facing existential threats (Wilbur et al. 2020) . COVID-19 has crippled public transit systems such as rails, buses, ride-shares, car rentals, and domestic flights. Lowered ridership, increased sanitation requirements in between rides, and the associated expenses can force these systems into liquidation [see this report on Hertz (Ferris 2020) ]. There is a high possibility of a leapfrog towards autonomous cars and personal rapid transit (PRT) systems for intercity, intrastate, and interstate travel. However, air travel would continue to be the dominant mode of intercontinental transportation of humans. The airliners would have to pay special attention towards indoor air quality and thermal comfort.Numerous requirements and standards exist that dictate acceptable indoor air quality. When designing a ventilation system for an airplane fuselage (or cabin) the challenge is to balance these considerations with fuel efficiency since all air entering the cabin is being taken from the compression stage of the engine, reducing thrust (Singh et al. 2002) . The air is first conditioned to the desired temperature and humidity then injected into the cabin through vents on the ceiling at a rate which maximizes efficiency. The air circulates and then exits through an exhaust along the outside of the floor. The air is recirculated and mixed with fresh air before being injected again. Common problems with this system occur when too much recirculated air is introduced back into the cabin with too little fresh air, resulting in headaches and tiredness for passengers (Zhang et al. 2010) . Another concern is the dispersion of contaminants introduced into the cabin through a couch or sneeze. Although a multitude of research has been performed to optimize the ventilation system to most effectively control these factors, implementation of new technology or equipment in the aircraft industry is notoriously slow due to stringent safety guidelines. For this reason, the authors have chosen to examine the existing system used in commercial aircrafts and perform an analysis that will allow a passenger to make an educated decision about which seat will provide the most preferable conditions.As previously mentioned, extensive research has been performed in this area simulating the airflow through an aircraft cabin often with a focus on optimizing the system, or tracking contaminant dispersion. Additionally, large scale experiments have been performed to validate the results obtained through computational fluid dynamics (CFD) simulations. Although these works are not directly pertinent, especially when considering different ventilation simulations, a selection will be briefly discussed because many parameters of the flow and cabin and techniques for numerical modeling guided the work done in this paper. One example, work done by Zhang et al. criticizes current systems for producing a dry environment with excessive air mixing (Zhang et al. 2010) . As a solution they developed an under-aisle distribution system which supplies dry air and humidified air through perforated aisles and increases humidity levels and lowers CO 2 concentrations throughout the cabin. Subsequent work, also by Zhang et al. in 2012, investigates the viability of a personal chair armrest air delivery system that delivers fresh outside air directly to each passenger's breathe zone. The exhausts are moved to be overhead instead of on the floor as is typical. They find that this system results in undesirable vertical temperature gradients, but is able to prevent contaminant release at any level (Zhang et al. 2012) .Numerous studies have also been performed using an unsteady inlet condition. Although we chose a steady inlet condition, which is consistent with most simulations, the results from unsteady flow provide an interesting comparison. Yan et al. (2019) focused on the spreading of disease from a cough or sneeze in an aircraft cabin. Experiments were performed in full scale cabin mockup with an unsteady inlet velocity and tracer gas used to visualize the flow field. Results showed a more complex, but narrower spread than with unsteady flow. Results were compared to CFD results which showed good correlation. Similarly, Wu and Ahmed (2011) performed CFD analysis on a B767 cabin section and showed that an unsteady air supply had more desirable temperature and CO 2 distribution than the equivalent steady flow situation.Experiments performed using full scale models of airplane cabins are especially useful because they provide validation for our results. This work (Liu et al. 2012a ) provides a review of many experimental measurements and numerical simulations done to predict flow in aircraft cabin. Full scale experiments are shown to be the most reliable and accurate; however they are the most expensive and time consuming. They conclude simulations are promising as an alternative (Liu et al. 2012a) . A subsequent study (Liu et al. 2012b ) by the same group used laser tracking and reverse engineering to generate an accurate model of cabin geometry and measurements of boundary conditions (at diffusers) and flow fields. They concluded that flow and boundary conditions in real cabins were complex and velocity and turbulence of inlet flow varied significantly from one opening to the next. Hence, an averaged value of this data serves as a valid approximation for simulations (Liu et al. 2012b) . Wang et al. (2008) acquired experimental data from a full scale mock-up of a Boeing cabin with 35 mannequins including heaters in their body sections. The goal was to evaluate ventilation effectiveness and characterizing air distribution. This study produced results similar to previously published accepted data and proved that modeling passenger heat emittance from just the torso section is a reasonable simplification (Wang et al. 2008) . A research group led by Garner in 2004 performed a study concerned with an injection of particles to the ventilation system mid-flight in relation to a terrorist threat. They measured the velocity field at various points in the actual plane at operating conditions and performed 2D CFD analysis to compare. CFD results matched well with the experimental data suggesting that a 2D computational model is a simplification that does not jeopardize the accuracy of the solution (Garner et al. 2004) . Bosbach et al. (2006) used particle image velocimetry in a full scale mock-up of an aircraft cabin to get velocity field data throughout the domain in order to examine relative effects of forced and natural convection in the temperature distribution in the cabin. This was done in order to validate a CFD analysis showing these effects that was created to minimize computational time. These results gave us confidence that the accuracy of our results would be maintained if natural convection was ignored .Airliners offering intercontinental flights will have to rethink seat placements to ensure safe and uniform environment for each traveler. One option is to permanently remove less suited seats, while the other is to seat passengers only on the better positioned seats. A few recent studies (Adwibowo 2020; Garbey et al. 2020; Perella et al. 2020; Vuorinen 2020; Li et al. 2020) have tried to numerically model the indoor spread of COVID-19 viral particles using CFD. A couple of studies (Li et al. 2016; Bhatia and De Santis 2020) have explicitly studied the transport of pollutants inside aircraft cabins. However, the flow physics of virus laded fluid is not trivial (Mittal et al. 2020 ). Additionally, no study has yet modeled the airflow, transport of nasally and orally released pollutants like CO 2 and coronavirus, and thermal efficiency inside two of the most common longduration intercontinental aircrafts (viz., Airbus A380 and Boeing B747). The authors of the current study present a preliminary multiphysics computational model to do the aforementioned and rank the seats of the first class, business class, and economy class cabins inside A380 and B747. The seat rank is based on a composite metric that makes use of the absolute CO 2 values and relative temperature and velocity values when compared to the ASHRAE-defined ideal temperature and velocity values (ASHRAE 2009). Such a ranking would aid the travelers in deciding which seat to occupy or alternatively can guide the commercial airliners in implementing social distancing on the long-duration flights during the on-going COVID-19 pandemic.Problem physics included solving for the airflow, temperature distribution, and CO 2 transport inside the airplane cabin. CO 2 was chosen as a representative pollutant that is released orally or nasally. As the geometry dimensions were very large and the inlet velocity of air was very low, the flow was expected to be nearly incompressible. Therefore, it was modeled using incompressible Navier-Stokes equations. Continuity equation:Momentum conservation:Temperature distribution was modeled using the energy conservation equation:CO 2 transport was modeled using the mass transport equation:where, V: fluid flow field velocity (m/s); p: fluid flow field pressure (N/m 2 ), : fluid kinematic viscosity (m 2 /s); f: body force acceleration (m/s 2 ); ρ: mass concentration of species k (kg/m 3 ); D: molecular diffusion coefficient; S k : Source term for species k, e.g. due to chemical reactions.The current study has modeled 2D sections for the airplane cabins, so it was important to select the right section to correctly represent the 3D problem. The initial section was across the head and torso of a human, as shown in Figure 1 . But human bodies occupied minimum space of the cabin volume hence it was not the correct representation of the 3D space. Additionally, the human body model interfered with important flow regions, thus stopping the crucial flow patterns from developing. As a result of this, a new section, passing through the laps of human and airplane seat was selected as seen in Figure 2 . Wang et al. (2008) have pointed out that most of the air supplied from one passenger row is circulated and finally exhausted in the same row. Also, Yan et al. (2009) mentioned in their manuscript, that most of the pollutants are transported only within the releasing half and seldom cross the middle line. Therefore, the authors have assumed symmetry in computational domain and have considered only half section of the plane. Boundary conditions for the problem are represented in Figure 3 and Table 1 as shown below.Human body can be modeled either as a constant temperature boundary or a constant heat source. In an earlier iteration of the model, the human body was modeled as a constant temperature boundary when the section across human head and torso was considered. But as a result of the absence of human torso from the new section, it was changed to a constant heat source, in the area corresponding to the human torso. Heat source was provided only for the torso region and not for the legs. Human noses were modeled as CO 2 sources in the problem. Circles of radius 2 cm were created in the cell zone, with their centers lying at the nose locations, and these were treated as noses. Four different grids were created, as shown in Figure 4 . After the grid convergence study, the finest mesh of size 0.0075 m was selected. All the subsequent simulations were carried out using this mesh size.As a result of the absence of any transient elements from the problem, a 2D steady state simulation was performed using ANSYS Fluent (ANSYS 2009). SIMPLE scheme was used for pressure-velocity coupling. SIMPLE is useful for the problem at hand due to the fact that when a steadystate problem is solved iteratively, it is not necessary to fully resolve the linear pressure-velocity coupling, as the changes between consecutive solution are no longer small (ANSYS 2009).For the SIMPLE algorithm, if the momentum equation is solved with a guessed pressure field p * , the resulting face flux f J * computed from the equationsatisfies the continuity equation.The SIMPLE algorithm postulates that f J ¢ can be written aswhere p¢ is the pressure correction. The flux correction equation is then substituted into the discrete continuity equation to obtain the discrete equation for pressure correction: where the source term b is the net flow rate into the cell.facesThe pressure correction is solved using the algebraic multigrid (AMG) method. Once a solution is obtained, the cell pressure and face flux are corrected usingHere α p is the underrelaxation factor for pressure. The corrected flux, J f , satisfies the discrete continuity equation identically during each iteration. RANS standard k-ε model was used for airflow modeling. The standard k-ε model is the most widely used RANS model and was the most preferred model in literature in airplane cabin flow modeling (Günther 2006; Zhai et al. 2007; Zhang et al. 2007; Liu 2014) . Hence, we decided to use this model.Transport equations for the model are as follows:In these equations G k represents the generation of turbulent kinetic energy due to the mean velocity gradients, G b is the generation of turbulent kinetic energy due to buoyancy, Y M represents the contribution of fluctuating dilation in compressible turbulence to overall fluctuation rate, C 1ε , C 2ε , and C 3ε are constants, σ k and σ ε are turbulent Prandtl numbers for k and ε respectively, and S k and S ε are user-define source terms.The turbulent viscosity, μ t , is computed from k and ε, as follows: where C μ is a constant.The model constants C 1ε , C 2ε , C 3ε , σ k and σ ε , have the following default values: C 1ε = 1.44, C 2ε = 1.92, C 3ε = 0.09, σ k = 1.0, σ ε = 1.3Temperature distribution in the cabin was modeled by the default energy equation in ANSYS Fluent. The species transport module was used to model CO 2 transport with CO 2 and air being treated as two different species.Final aim was to rank the seats in Airbus and Boeing sections using the simulation results for velocity, temperature, and CO 2 mass concentration. Following ranking scheme was developed:where, T ideal : ideal temperature = 294 K (ASHRAE 2009); V ideal : ideal velocity = 0.2 m/s (ASHRAE 2009); X ideal : ideal mass concentration of CO 2 = 1.2 × 10 −3 (ASHRAE 2009 ). An absolute value was not used for CO 2 concentration, because lower the value of CO 2 , the better. The ideal temperature and velocity values were obtained from the ASHRAE handbook detailing standards for ambient environmental conditions for the human comfort (ASHRAE 2009).As seen from the ranking scheme, closer the values are to the ideal values, better the seat, and better the rank. Hence, seat with the lowest rank is the best seat.A grid-convergence study was carried out with mesh details as shown in Table 2 . Meshes 1, 2, and 3 are shown in Figures 4(a) to 4(c). Boeing B747 Business Class section was used for this study. This section has two seats and is located on the upper deck of B747 (refer Figure 14(c) ). 2D line plots at the nose-level of passengers for x-velocity, mass fraction of CO 2 , and total temperature are shown in Figures 5 through  7 respectively. The results become invariant as for Mesh 3 and beyond. Mesh 4 is also able to capture the thermal Authors of this paper felt the need to refine the mesh further to a global size of 0.0075 m to account for any changes which the other sections, first and economy, might bring in due to a larger size and/or more passengers. All the remaining results have been obtained using a global element size of 0.0075 m. Simulations were carried out for the following six sections: 1) Airbus A380 First, Business and Economy class (3 sections) 2) Boeing B747 First, Business and Economy class (3 sections)Contour and line plots shown in Figures 8 through 13 are for the first class section of A380 and B747. The Airbus section has two seats and the Boeing one has three seats. Figure 8 shows the steady state contours for the velocity magnitude for the first class section of A380 (Figure 8(a) ) and B747 (Figure 8(b) ). The corresponding line plots for the velocity magnitude at the nose-level are shown in Figure 9 . Two big eddies are seen in A380 while a single large eddy is seen in B747. Velocity magnitude plots at the nose-level for first class sections of A380 and B747 reveal that the velocity magnitude in B747 follows a monotonic trend while moving from the center of the cabin (aisle) to the window. This is due to the presence of a single large eddy seen in B747 as opposed to A380, that has an unpredictable trend in velocity magnitude at the nose-level. Figure 10 shows the steady state contours for the mass concentration of CO 2 for the first class section of A380 (Figure 10(a) ) and B747 (Figure 10(b) ). The corresponding line plots for the mass concentration of CO 2 at the noselevel are shown in Figure 11 . Two big eddies are seen in A380 while a single large eddy is seen in B747. The CO 2 released by the two passengers in A380 seems to circulate around them as opposed to that in B747 where the CO 2 released by three passengers seems to be swept away more efficiently towards the outlet. The resulting higher concentration of CO 2 at the nose-level of passengers in A380 can be seen in Figure 11 (a) while that in B747 is shown in Figure 11 (b). Figure 12 shows the steady state contours for the total temperature for the first class section of A380 (Figure 12(a) ) and B747 (Figure 12(b) ). The corresponding line plots for the total temperature at the nose-level are shown in Figure 13 . A large warmer zone can be seen near the window of A380 while the temperature in B747 seems to be pretty uniform for the major part of the cabin. This can be further illustrated by observing the line plots of Figure 13 .Ranking scheme described in the previous section helps to better combine this data from Figures 8 through 13 for the first class sections of A380 and B747 in the form of a figure of merit like quantity based on the equation describing the seat ranking. Values of CO 2 mass fraction, temperature, and velocity at points corresponding to passenger noses, for different seats of first, business, and economy class sections of Airbus A380 and Boeing B747, are shown in Tables C1-C6 in Appendix C, which is in the Electronic Supplementary Material (ESM) in the online version of this paper. Using these, different seats can be compared according to the values of individual quantities. These values are then substituted in Eq. (16) to compute the cumulative rank for the seats. Lower the value of the ranking quantity, better the seat, and in turn higher the rank. The ranking obtained using this approach is schematically shown in Figure 14 (a) and Figure 14 (b). As can be seen in these two figures, A380's first class seats tie as per the ranking scheme while B747's center seat is the most superior when compared to the window and second to window seats. It should be noted that mirror image of the shown ranking exists on the right half of the cabin sections.Rankings obtained using a similar procedure for the remaining four sections of interest are shown in Figures 14(c) through 14(f). As with the first class sections, even the business and economy sections of A380 and B747 have dissimilar rankings for seats occupying same relative positions. In other words, a window seat in the economy class of A380 would be most preferred but its counterpart, an economy window for B747, would be least preferred. Other results have been presented in the Appendices A and B. Numerical values of CO 2 , V, and T, at points corresponding to passenger noses for all the sections are presented in Appendix C. The Appendices are in the Electronic Supplementary Material (ESM) in the online version of this paperThe study assumes 2D flow pattern for the ease of caluculations. This is backed by previous studies and is generally appropriate for the central portion of the aircraft. However, authors do recognize that there can be 3D motion of air and thereby the pollutants released orally or nasally into the air (viz., CO 2 and viruses such as coronavirus) can travel in the longitudinal directions (i.e., along the length of the aircraft). This is partiularly important to consider at the ends of the aircraft as the fluid flow at the ends will certainly not be 2D. The BCs were based on the data available in the public doamin or by making conservative assumptions. These may not accuratley describe the air duct positions in the studied aircrafts. The inlet air speeds were assumed to be the same for all the studied sections. As a simplifying assumption that also adds to the factor of safety of the model predictions, coronavirus was assumed to be present at places where released CO 2 can be found. The released CO 2 and the associated coronavirus concentration have been modeled as a continnum where as the actual coronavirus particles would be in a discrete phase. Modeling coronavirus as a discrete phase suspended in air will be prohibitively expensive with regards to the computational resources.These rankings are based on the scheme presented by the authors and the section views and BCs as available in the public domain. Many simplifying assumptions are associated with this study and the actual ranking of the seats can be different based on how many of these assumptions fail in real life and personal preference of the traveler.Many factors are considered during the decision making process of purchasing a seat on a plane. Features such as customer service, financial means, and inherent bias often drive the decision making process. However, these factors are not considered in our conclusions about the ideal airplane seat. Furthermore, personal preference plays a significant role when choosing a seat. For example, a particular individual may prefer to sit by the window so he/she can see the view, or sit by the aisle so he/she can stretch his/her legs. Also the ideal enviornmental conditions used in the ranking scheme described previously are an average and not the same for each individual. Some passengers may prefer a hotter ambient temperature and others slightly cooler. For all these reasons we will present our findings in a way that will not make any assumptions about the passenger, but instead provide the reader with all the information necessary to make a more educated purchase with regard to their personal preferences. This information is as shown in Tables 3  through 5 .Each of the abovementioed tables contains data for the three sections of the airplane: first class, business class, and economy class. The section is generally chosen based on the financial means of the traveller so it is unnecessary to compare data between classes. Each row of the table contains data for each of the environmental conditions studied in this report. The mass fraction of CO 2 that can be qualitatively thought of as the mass fraction of orally or nasally released pollutants, is reported as well as the temperature and air velocity at the seat. The data is reported for the best seat in every section for the Boeing cabin and the Airbus cabin. This enables a comparison across classes between the two planes.In Table 3 the data for the first class cabins for Airbus and Boeing are shown. We see that the Airbus seat is warmer than the Boeing seat, but has worse circulation. This decreased circulation is confirmed by the lower air velocity and increased mass fraction of CO 2 . The Airbus seat will be warm, but with the potential to be ""stuffy"". Conversley the Boeing seat, located in the middle on the aisle side, will be cooler and breezy. Table 4 shows the data for the business class sections of both the planes. Here the effects are reversed with respect to the first class cabin. We see that the Airbus seat is colder, but offers better circulation than the Boeing seat. The Airbus seat is located in the side bank of the seats on the aisle side and the Boeing seat, that is warmer compared to the Airbus seat and with worse circulation, is located next to the window.The results for the economy class of both planes are shown in Table 5 . We see that the best seat for the Airbus cabin is located next to the window while the best seat for the Boeing cabin is the middle seat in the side bank of the seats. The Airbus seat has a higher temperature, lower CO 2 concentration, and lower air velocity. Unlike the other sections the trade-off for a warmer seat was worse circulation, we conclude that the Airbus economy best seat is both warm and with good circulation. The Boeing seat performs worse in all these areas.The findings from this preliminary multiphysics computational model may be used by the general public to decide which seat to occupy for their next intercontinental flight. Alternatively, the commercial airliners can use such a model to plan the occupancy of the aircraft on long-duration intercontinental flights (viz., Airbus A380 and Boeing B747).",USA,first author,2021-02-11,02
a1376fee99a4b03ea4667a91d7316afa08a54a8d,Targeting the Coronavirus Nucleocapsid Protein through GSK-3 Inhibition,"COVID-19 is exacting a severe toll on personal and community health, healthcare systems, and the global economy. The response to this crisis will require multiple approaches for detection, prevention, and treatment. With three major b-coronavirus epidemics in less than 20 years, it would also be prudent to anticipate new coronavirus outbreaks in the future. In addition to development of effective vaccines, antiviral strategies that target conserved mechanisms in coronavirus replication and transmission may be needed for COVID-19 and potential future coronavirus outbreaks. Recent high throughput screens have identified bioactive compounds that impair viral replication and infectivity in tissue culture models of infection by the severe acute respiratory syndrome coronvavirus-2 (SARS-CoV-2) [1] [2] [3] [4] [5] . However, their mechanisms of action and their clinical efficacy remain to be fully delineated and additional targets may be needed to combat SARS-CoV-2, new SARS-CoV-2 variants, and potential novel coronavirus outbreaks in the future.Coronaviruses express a nucleocapsid (N) protein that is essential for viral replication, transcription, and assembly [6] [7] [8] [9] [10] . N proteins from the JHM strain of mouse hepatitis virus (JHMV) and from SARS-CoV, which caused the 2002-2004 SARS outbreak, are phosphorylated by glycogen synthase kinase-3 (GSK-3) within an arginine-serine (RS) domain present in N proteins of diverse coronaviruses [7] [8] [9] [11] [12] [13] [14] . Phosphorylation of the JHMV N protein is required for recruitment of the RNA helicase DDX1 and for transcription of long subgenomic RNAs 8 ; inhibition of GSK-3 impairs recruitment of DDX1, binding to viral mRNAs, and viral replication. N These observations suggest that inhibition of GSK-3 could impair coronavirus infections in vivo, including COVID-19 [25] [26] [27] . A recent phosphoproteomic analysis revealed that SARS-CoV-2 N protein is highly phosphorylated within the RS domain 1 , but whether GSK-3 phosphorylates SARS-CoV-2 N protein and whether lithium has any effect against SARS-CoV- 2 have not yet been tested. Here we show that GSK-3 is essential for phosphorylation of the SARS-CoV-2 N protein, that alternative GSK-3 inhibitors impair N phosphorylation and SARS-CoV-2 infection in human lung epithelial cells, and that litihum therapy is associated with significantly reduced risk of COVID-19. Targeting GSK-3 may therefore provide an antiviral therapy for COVID-19 and for coronavirus infections that may arise in the future.The SARS-CoV N protein shares 20-30% sequence identity with the N proteins of other coronaviruses 6 , and despite the limited sequence similarity, they each have an arginine-serine rich (RS) domain that lies between N-terminal and C-terminal conserved domains 6 . The RS domains of N from SARS-CoV and JHMV include repeated motifs (SXXXS) 9 that are frequently associated with GSK-3 phosphorylation, in which the C-terminal serine is phosphorylated by a priming kinase 28 , which then allows GSK-3 to phosphorylate multiple serines or threonines spaced 4 residues apart in the C to N terminal direction (Fig. 1A) . The sequence of the RS domain of SARS-CoV-2 N is 90% similar to N from SARS-CoV, and both proteins contain two sets of three SXXXS motifs each (labeled ""a"" and ""b"" in Fig. 1A and 1B) . While the N protein sequences of other coronaviruses diverge, they retain SXXXS motifs (Fig. 1B) . In addition, the fourth serine (presumed priming site) is always preceded by an arginine in the -3 position 4 (SRXXS). GSK-3-dependent phosphorylation of RS domains has also been reported for multiple splicing factors and other RNA binding proteins 29, 30 .A recent phosphoproteomic analysis showed that the RS domain of the SARS-CoV-2 N protein is highly phosphorylated 1 , but whether GSK-3 phosphorylates N protein from SARS-CoV-2 has not been addressed. We expressed SARS-CoV-2 N in human embryonic kidney 293T cells (Fig.   1C ) or mouse lung epithelial MLE12 cells ( Figure S1A ). N phosphorylation was demonstrated by treating cell lysates with alkaline phosphatase, which increased the electrophoretic mobility of N, as observed previously for SARS-CoV N protein 8, 9 . Lithium chloride (LiCl) inhibited N phosphorylation with IC50 ~10mM in 293T cells (Fig. 1C , S1B). Phosphorylation of the GSK-3substrates Glycogen Synthase (GS; Fig. 1C ) and ß-catenin ( Fig. 2A , lanes 1-3) was also inhibited with an IC50 ~ 10 mM. In contrast, the Ki for LiCl inhibition of GSK-3 in vitro is 1 mM 31, 32 and the effective in vivo concentration for Li + inhibition of GSK-3 in mice and humans is also 1 mM 33,34 . The relatively high Li + concentration needed to inhibit N phosphorylation ex vivo raises the concern that Li + may act through a target other than GSK-3. To examine this possibility rigorously, we tested multiple, selective GSK-3 inhibitors, including bisindolylmaleimide I (BIM-I), CHIR99021, AR-A014418, and Kenpaullone, all of which inhibited N phosphorylation in the low µM range (Fig. 1D , S1C), strongly supporting that GSK-3 is essential for N protein phosphorylation.However, these compounds, which inhibit GSK-3 by competing for ATP binding, may have offtarget effects. As an alternative and more definitive approach, we used siRNAs and CRISPR/Cas9 to knockdown or knockout (KO) both GSK3A and GSK3B, which encode two highly similar GSK-3 isoforms (GSK-3a and GSK-3b, respectively). KO of GSK3A alone had a minimal effect on phosphorylation of N or b-catenin ( Fig. 2A) , consistent with redundant All rights reserved. No reuse allowed without permission.GSK-3 substrates that follow the SXXXS motif require a priming phosphorylation at the Cterminal serine or threonine 36,37 ; mutation of this residue in established GSK-3 substrates including glycogen synthase (GS) and b-catenin prevents phosphorylation of more N-terminal serines and threonines by GSK-3 36,38 . Similarly, mutation of the two putative priming sites in SARS-CoV N blocks phosphorylation by GSK-3 9 . To test whether the SARS-CoV-2 N protein also requires priming site serines, we mutated serine-188 and serine-206 of SARS-CoV-2 N protein to alanines (N S188A,S206A ) and then expressed the single and double mutant N proteins in HEK293T cells. The single mutant form N S188A migrates in the same position as phosphorylated wild-type N protein whereas the N S206A migrates more rapidly, suggesting that it is hypophosphorylated (Fig. 2C ). Mobility of the N S188A,S206A protein is similar to dephosphorylated N protein and is not affected by GSK-3 inhibition LiCl (Fig. 2C ) or treatment with alkaline phosphatase ( Figure S2A ). Additionally, both of the single serine to alanine mutants are more sensitive to LiCl. These data indicate that GSK-3 phosphorylation of SARS-CoV-2 N protein requires the canonical GSK-3 priming site serines.Although our data show that GSK-3 is required for phosphorylation of N protein at a classical GSK-3 consensus site, it remains formally possible that GSK-3 indirectly regulates N protein phosphorylation. Pharmacological inhibition of GSK-3 also activates mTOR and downstream All rights reserved. No reuse allowed without permission.To test whether GSK-3 directly phosphorylates N protein, we performed in vitro kinase assays with recombinant GSK-3b and N protein purified by immunoprecipitation from HEK293T cells.Use of N protein expressed in mammalian cells was important because the priming site will not be phosphorylated in bacterially expressed recombinant protein and, without the priming phosphorylation, the GSK-3 sites may not be phosphorylated. HEK293T cells expressing myctagged N were treated with the GSK-3 inhibitor LiCl and then immunoprecipitated. As shown in Fig. 2D , N protein lacking phosphorlyation at the GSK-3 dependent sites migrates more rapidly than phosphorlyated N (lane 5). Recombinant GSK-3b was then added to the immunoprecipitate and the reaction was incubated for 30 minutes. N protein phosphorylated by GSK-3 migrated with slower mobility (Fig. 2D, lane 6) , similar to N protein from untreated cells.N protein expressed in GSK-3 double knock out (DKO) 293T cells, immunoprecipitated, and added to an in vitro kinase reaction was completely phosphorylated by recombinant GSK-3b (Fig. 2E) . These data demonstrate that GSK-3b directly phosphorylates N protein.All rights reserved. No reuse allowed without permission.The phosphorylation of a motif within an arginine-rich domain, and especially the high conservation of arginine at the -3 position relative to the priming site (Fig. 1B) , suggested that the priming kinase may be an arginine-directed, or ""basophilic"", protein kinase. We began to test candidate kinases using inhibitors of MAP/ERK kinases (MEK1/2), casein kinase II (CKII), calmodulin-dependent protein kinase II, and protein kinase C (PKC). Although most inhibitors we tested had no effect on N phosphorylation (data not shown), including the PKC inhibitor Gö6976 ( Figure S3B ), the structurally related PKC inhibitors Enzastaurin, Sotrastaurin, and Gö6983 did inhibit N phosphorylation ( Fig. 3A and S3C ). Unexpectedly, in addition to potently inhibiting phosphorylation of endogenous PKC substrates induced by the PKC activator PMA ( Figure S3A ), these bisindolylmaleimides also inhibited phosphorylation of the endogenous GSK-3 substrate GS. To distinguish whether the inhibition of N phosphorylation was due to inhibition of GSK-3 or inhibition of a priming phosphorylation by PKC, we knocked down expression of PKC-a, PKC-d, and PKC-e, the major PKC isoforms expressed in HEK293T cells.Single or combined knockdown of PKC had no effect on phosphorylation of N or GS ( Figure   S3D ). To confirm that Enzastaurin and Sotrastaurin directly inhibit GSK-3, we performed in vitro kinase assays. Phosphorylation of the GSK-3 substrate tau and N protein was inhibited by Enzastaurin and Sotrostaurin in vitro (Fig. 3B , 4C, and S3E), confiming that Enzastaurin and Sotrastaurin are direct inhibitors of GSK-3, consistent with a prior report 41 .The GSK-3 inhibitors CHIR99021 and Enzastaurin were tested for antiviral efficacy (detection of double stranded RNA or spike protein) and for their effects on cell viability at two institutions in two lung epithelial cell lines (Calu-3 and A549-Ace2). Calu-3 cells were treated with drugs at varying concentrations for 1 hour, inoculated with SARS-CoV-2, and cell number and the percent of infected cells were quantified at 48 hours post infection (HPI). CHIR99021 inhibited All rights reserved. No reuse allowed without permission.Similarly, previous work has shown that Enzastaurin inhibits SARS-CoV-2-mediated cytopathic effect in Vero E6 cells at 250 nM 4 and reduces infection (based on qRT-PCR and viral titer) in A549-Ace2 cells at 5 µM 1 ; however, we did not observe an effect of Enzastaurin in A549-Ace2 or Calu-3 cells. The reasons for the cell-type variability in these assays is unclear but has been observed by others as well 1 .As lithium is a GSK-3 inhibitor that is widely used to treat bipolar disorder, we asked whether patients on lithium have a reduced risk of COVID-19 infection compared to the general population. We included patient data from three health systems in the United States ( The average age of the patients who received lithium was between 42 -48 years.Given the potential confounding bias for COVID-19 susceptibility with the patient's baseline characteristics, propensity score matching was employed at each site. The matched cohort resulted in 25 patients from UPHS, 50 patients from UIHC, and 10 patients from MSMC who All rights reserved. No reuse allowed without permission.Medications that target common features of the coronavirus family could reduce the severity and transmission of COVID-19 as well as other pathogenic coronaviruses. Our analysis of retrospective EHR data on SARS-CoV-2 PCR testing from three major health systems across the US showed a ~50% reduced risk of COVID-19 in patients taking lithium. We show that the SARS-CoV-2 N protein is phosphorylated by GSK-3 and that lithium and other GSK-3 inhibitors block N phosphorylation, as shown previously for JHMV and SARS-CoV 9 . We also show for the first time that GSK-3 is unequivocally essential for N phosphorylation using GSK3A/B double KO. Diverse GSK-3 inhibitors inhibit N phosphorylation and impair SARS-CoV-2 replication in cell culture models. GSK-3 inhibition may therefore allow safe and effective therapy for COVID-19. As we find GSK-3 consensus sites in the N proteins of diverse coronaviruses, GSK-3 inhibitors may also be effective antiviral therapy in other coronavirus infections, including those that may arise in the future.Lithium has a narrow therapeutic window, however, and the concentration needed to inhibit N phosphorylation and to impair infectivity of SARS-CoV-2 and other coronaviruses in cell All rights reserved. No reuse allowed without permission.While the association of lithium therapy and reduced risk of COVID-19 across three health systems is both signficant and intriguing, observational studies have many limitations. A variety of factors with potential biases cannot be measured even after comparing the cases and controls in a manner that accounts for known confounding factors using a rigorous matching algorithm. For instance, details on medicine usage were derived from records of prescription orders, but information on compliance before SARS-CoV-2 PCR testing is not available. In addition, the collection of a non-random sample population can create a collider bias and lead to distorted associations. For example, the COVID-19 test was restricted particularly in the early pandemic to symptomatic patients so that many asymptomatic patients in the EHR were not tested. These findings should therefore be interpreted carefully and deeper investigation is required in a cohort with a larger sample size.Prior work has shown that lithium and the GSK-3 inhibitor Kenpaullone inhibit N phosphorylation and reduce viral titers in SARS-CoV and JHMV infected Vero6 cells 8, 9 and GSK3 knockdown also impairs replication of IBV in Vero cells 15 . We also show that multiple small molecule GSK-3 inhibitors, including CHIR99021, BIM-I, AR-A014418, Enzastaurin, and Sotrastaurin block SARS-CoV-2 phosphorylation. These pharmacological studies are compelling evidence that GSK-3 is a critical host kinase for N protein, but these drugs may have off-target effects. Thus, All rights reserved. No reuse allowed without permission.The highly selective GSK-3 inhibitor CHIR99021 inhibited SARS-CoV-2 infection in the human lung epithelium-derived cell line Calu-3, an observation that was reproducible in two independent laboratories, and the related compound CHIR98014 was previously reported to inhibit infection in the human lung cancer derived cell line A549-Ace2 1 . Furthermore, the clinically well tolerated drug Enzastaurin was reported to inhibit SARS-CoV-2 infection in A549-Ace2 cells 1 and viral-mediated cytopathic effect in Vero E6 cells 4 . However, the effects of these inhibitors has been variable in different cell lines and in different laboratories. For example, Bouhaddou et al did not observe inhibition with Enzastaurin in Vero6 cells and we did not observe inhibition with Enzastaurin in A549-Ace2 cells or Calu-3 cells. The reasons for this cell type specific effect and variability between laboratories is unclear, but may include differences in the expression and/or activity of targeted signaling pathways in different cell lines that may arise as an adaptation to cell culture conditions and passage number. Nevertheless, it remains clear that GSK-3 is essential for N phosphorylation, as GSK3 knockout abrogates N phosphorylation, and given the essential functions of phosphorylated N in viral transcription, replication, and packaging 8 , developing GSK-3 inhbitors that safely and effectively inhibit N phosphorylation is a promising potential approach to controlling SARS-CoV-2 and other coronavirus infections that may arise in the future.We propose that inhibition of N phosphorylation underlies the antiviral activity of lithium and other GSK-3 inhibitors; however GSK-3 also regulates inflammatory responses 43 , and lithium has been reported to have antiviral activity against other viruses, notably human herpes viruses 25 . Thus modulation of the inflammatory response by litihum may also contribute to the reduced risk of COVID-19 in patients taking lithium. All rights reserved. No reuse allowed without permission.Institutional Review Board (IRB) protocol #844360 and for MSMC under IRB#20-00338.Outcome: The primary outcome of our case-control EHR study was COVID-19 susceptibility where cases are defined by positive test results from RT-PCR of nasal samples and controls All rights reserved. No reuse allowed without permission.Exposure: Lithium use was defined using the prescription orders available within the EHR. The medication name and dose generally differ across health systems and it poses a challenge to develop standard selection criteria. To minimize these differences, we used RxNorm -a resource of standardized nomenclature for drug names from the National Library of Medicine 45 .RxNorm maps branded and generic names, ingredients, drug components, and other drugrelated vocabularies to standard names. The current EHR systems (EPIC) also support RxNorm and there is an existing mapping between drug names and RxNorm concept unique identifiers (RxCUI). We queried RxNorm to extract all the RxCUI linked with lithium carbonate and then extracted prescription orders mapped to RxCUI in the EHR system. The list of RxNorm CUIs can be found in Supplementary Table 2 . A patient was considered on lithium treatment if they had an order placed within 90 days prior to their first positive COVID-19 test (COVID-19 cases) or 90 days before their first negative COVID-19 test (COVID-19 controls). Generally, lithium is prescribed for a longer period of time (> 3 months), so to capture long-term use of lithium we included patients with two or more lithium orders placed within 12 months before their COVID-19 test, using the aforementioned methods for COVID-19 cases and controls.Statistical Analysis: To minimize potential confounding biases among the population tested for COVID-19, we applied a propensity score matching (PSM) method. For each patient on lithium with a record of COVID-19 testing, we first calculated the propensity score using a multivariate logistic regression model adjusting for age, sex, and race. Then, we applied nearest-neighbor matching (MatchIt R) on the propensity scores to select one matched patient for each patient on lithium. We conducted a meta-analysis on the association between lithium use and COVID-19 All rights reserved. No reuse allowed without permission.All rights reserved. No reuse allowed without permission.All rights reserved. No reuse allowed without permission.A B CAll rights reserved. No reuse allowed without permission.All rights reserved. No reuse allowed without permission.Dose-response analysis of Calu-3 cells treated with GSK-3 inhibitors CHIR99021 or Enzastaurin (UPenn). Cells were treated with drug at the indicated concentrations and then inoculated with SARS-CoV-2. Cells were fixed at 48hpi and total cell count (green) and percent viral infection (blue) detected by immunofluorescence for dsRNA were assessed. B. Calu-3 cells were treated with vehicle or the indicated concentrations of CHIR99021, innoculated with SARS-CoV-2, fixed at 48 hpi, and Spike protein was detected by immunofluorescence (UCLA). Enzastaurin had no effect on viral infection in Calu-3 cells.",USA,first author,2021-02-22,02
33c6fdeeb52c6f96d1fee2f154f949235098a19d,Control of COVID-19 transmission on an urban university campus during a second wave of the pandemic,"4 All rights reserved. No reuse allowed without permission.The SARS-CoV-2 global pandemic resulted in nearly 1.8 million deaths worldwide in 2020. 1 After a major surge in cases in spring 2020 in the northeast United States, other parts of the country experienced continued transmission through the summer with a second wave arising in the northeast in fall 2020. 2 This mandated several mitigation actions, including, in spring 2020, the closure of in-person learning at public and private higher education institutions. Faced with potentially dire financial challenges and adverse social impacts associated with continued closure, some universities and colleges developed strategies in spring 2020 to allow campuses to reopen and operate in the fall despite the ongoing threat of COVID-19. 3, 4 Boston University (BU) is a private university with a student/staff/faculty population of around 40,000 individuals. BU is located in the center of a large US city, thus creating a scenario for potential widespread COVID-19 transmission. Despite these challenges, the BU administration pursued an aggressive risk mitigation strategy involving widespread asymptomatic screening for COVID-19, environmental modifications, de-densification strategies, and contact tracing, isolation and quarantine, all with the goal of providing its students the opportunity to return to inperson learning in the fall semester of 2020. Here we describe the BU experience as a case study that we believe offers important lessons that may be broadly applicable to other higher education institutions.Initial planning, starting in March 2020, determined an approach that centered on active surveillance for asymptomatic and symptomatic cases via on-site molecular testing for SARS-CoV-2 (Supplement). This involved setting up de novo systems for high throughput laboratory testing, timely communication of results, rapid contact tracing, isolation of infected individuals, and quarantine of close contacts ( Figure 1 ).Surveillance was complemented by additional control measures, including mask use, enhanced hygiene practices, social distancing recommendations, daily health attestations, de-densification of classrooms and public places, and enhancement of all building air systems. This process was All rights reserved. No reuse allowed without permission.Starting in spring 2020, several different groups were organized to coordinate all aspects of COVID-19 control on campus, including, but not limited to, monitoring incoming data, modifying campus operations, implementing best public health and medical practices, surveillance, and budgeting (Supplement 1.1, Figure S1 ).BU implemented hybrid teaching in which all undergraduate and graduate students could attend classes in-person or remotely. This blended modality allowed classes to accommodate on-line only students using Zoom software and in-person students simultaneously. 5 Accommodations for on-line only teaching were made for educators who were elderly or had medical conditions that increased their COVID-19 risk.All rights reserved. No reuse allowed without permission.SARS-CoV-2 testing categories. Based on guidance from public health authorities, the University developed four SARS-CoV-2 testing categories, related to an individual's risk of becoming infected on campus. These categories determined frequency of testing, ranging from twice weekly for category 1 (e.g., on-campus undergraduates) to no testing for category 4 (e.g., students, faculty, or staff entirely off-campus) (Supplement 1.4).Managing and responding to test results. All individuals with a negative test were automatically notified by email to access their test results through a secure, online portal when their results were available. Anyone with a positive test result was called by a healthcare professional.The contact tracing protocol was based on CDC and Massachusetts Community Tracing Collaborative processes 6,7 , with adaptation from BU academic programs and student input.Contact tracers followed a detailed script to identify all close contacts. A close contact was defined as someone within six feet of an infected person for 15 minutes or more over a 24 hour period (Supplement 1.5).Students who tested positive for SARS-CoV-2 had to isolate for 10 days after symptom onset and resolution of fever for at least 24 hours, and with improvement of other symptoms, or for 10 days from the positive test date if asymptomatic. 8 Students identified as a close contact had to All rights reserved. No reuse allowed without permission.Additional measures including face mask use, enhanced hand hygiene, social distancing recommendations, daily health attestations, de-densification of classrooms and public places, and enhancement of all building air systems including optimization of filtration units were implemented (Supplement 1.9-1.10).We used probabilistic SEIR (susceptible-exposed-infectious-recovered) transmission modeling during summer 2020 to provide insight into the expected relative efficacy of potential interventions for reducing COVID-19 transmission and burden in the BU community with the goal of achieving only linear increases of cases from transmission outside BU (Supplement 1.11). We used a stochastic agent-based model, implemented using the COVID agent-based simulator (covasim) framework. 10BU developed a dedicated COVID-19 external communications platform called Back2BU. 11 The pre-existing ecosystem of data warehousing and analysis systems that traditionally supported the university was augmented to support the data storage, management, and analysis requirements necessary to allow for near-real time surveillance of outcomes associated with BU's COVID-19response. Surveillance efforts focused on monitoring not only standard metrics around incidence, isolation, and quarantine, but also metrics around testing, contact tracing, and compliance with the collection of campus control measures. An external dashboard was created and updated daily to allow the broader BU community and beyond to track now-standard, fundamental metrics (Supplement 1.12-1.15). In addition, an augmented, internal dashboard was created to aid the various groups working with BU leadership to not only monitor but adapt the BU COVID-19 response.All rights reserved. No reuse allowed without permission.A comprehensive phased move-in program was adopted to reduce crowding and lines, giving students the time to test and the university the time to respond to any positive cases on arrival (Supplement 1.18).The plan for this analysis was reviewed by the Boston University CRC Institutional Review Board (IRB) and was classified as non-human subjects research. The BUMC IRB reviewed the safe behavior quality improvement project (Supplement 1.17) and determined it to be exempt.We structure our results to provide information on the: 1) operational aspects of the systems BU put in place to manage the epidemic, and 2) resulting epidemiological features of COVID-19 in BU and the surrounding community. In general, we describe results during the semester: September 3-December 19; however, we include some results from initialization of systems during the summer.Overall, the systems designed in the summer to mitigate the pandemic performed well throughout fall semester, as detailed below.Housing. While 99% (7266) of graduate students lived off-campus, most undergraduates lived in on-campus housing, including a total of 7,131 students as of October 13, 2020, representing 67% of the fall 2020 capacity. Due to de-densification efforts, 3453 (48%) of students lived alone and 3678 (52%) of students lived with one roommate (Supplement 1.5).All rights reserved. No reuse allowed without permission.Testing turnaround times decreased dramatically over the semester, leveling off to around 12-15 hours between sample collection to receipt of results ( Figure 2A) . Ultimately, the BU testing laboratory conducted 467,382 tests for the BU population during the fall semester (517,357including the pre-semester move-in). Figure 2B ). If an individual did not meet criteria to be a close contact, but was part of a social group (e.g., Greek-life membership) or affiliation (e.g., sports team, music group) of recent cases, they were notified of their potential risk of COVID-19 exposure, reminded to follow public health guidelines, and required to increase testing frequency to 3 times per week.Despite having quarantine and isolation capacities of 650 and 342 respectively, occupancy only reached a maximum of 13.7% and 12.9% respectively at any one time ( Figure S3 ).Compliance. On average 12% of on-campus students did not comply with testing or attestation protocols in October and November which was lower than off campus students during the same time (51.5% for off campus students in categories 1, 2 and 3 or 20% if including students in category 4) ( Figure 3A ). Reported violations of other control measures had an initial early semester burst, but gradually reduced throughout the semester ( Figure 3B ). Early semester All rights reserved. No reuse allowed without permission.Changing epidemiology of COVID-19 in Boston. Following the use of statewide control measures in spring 2020, case numbers in Suffolk County (including Boston) remained low throughout the summer, averaging around 0.1 reported case per 1000 population up to mid-October. As the state moved through the reopening phases 12 and the weather became colder (and people spent more time indoors), reported cases began to increase to 0.40/1000 by early November and rose to 0.75/1000 in early December, following Thanksgiving gatherings ( Figure   2C ). These increasing trends were observed statewide and also in collection of SARS-CoV-2 from Boston area wastewater, indicating that they were not just due to increased testing in the Boston area. 13,14During the fall semester, 719 individuals tested positive for COVID-19 in the BU community; including 627 (87.2%) students, 11 (1.5%) faculty, and 212 (25.5%) staff (Table 1) . Cases increased following holidays, particularly Thanksgiving, and that was more pronounced for undergraduate students and non-faculty staff.While the incidence rate among students and staff tracked that of Suffolk County ( Figure 2C ), there were two distinctions. First, BU surveillance testing resulted in detection of many asymptomatic cases (37.7% of total cases) likely more than the passive testing regime in the All rights reserved. No reuse allowed without permission.Sources and locations of transmission. BU contact tracers identified a source of transmission for 51.5% of cases with 55.7% identifying a source outside of BU (Table 1) . Among infected faculty and staff with a known source of infection, the overwhelming majority reported a transmission source outside of BU (100% for faculty and 79.8% for staff). Students identified more BU contacts as sources of infection (39.8% for graduate students and 59.2% undergraduate students, Table 1 ). Notably, BU household contacts were identified as a source of infection less than 1% of the time (Table 1) and anecdotally, there were no sustained transmission events in on-campus housing, indicative of the efficacy of efforts to control spread in campus housing. When asked to identify their close contacts, students rarely identified close contacts in the classroom setting and most close contacts tended to be friends and, after Thanksgiving, family ( Figure 2D ). This indicates that while BU students tended to be more likely to identify another BU affiliate as a source of infection, the contacts leading to infection occurred in places that were not directly targeted by BU interventions.Although many institutions of higher education across the US reopened in fall 2020, some experienced large COVID-19 outbreaks compelling them to revert to on-line only or remote education. [15] [16] [17] The BU experience is important because it has an urban campus situated in a community that experienced high and increasing COVID-19 incidence from August to December 2020 with no option for the university to isolate from the wider community. Despite this challenge, the university benefited from having substantial resources including funding to establish and run a SARS-CoV-2 testing laboratory and sampling centers, a hybrid learning All rights reserved. No reuse allowed without permission.The interventions that were designed over the summer were supported by a strong leadership structure with multiple subcommittees targeting important aspects of the response. There was frequent communication and coordination between these groups to ensure that, if a cluster of cases was emerging, all parties were aware. This meant that testing cadences could be adapted, compliance efforts could be modified, and messaging adapted to blunt any potential risk of an outbreak. This coordinated effort was key to ensuring a high level of compliance and the success of planned interventions.Short turnaround time of results followed by rapid isolation of infected individuals, contact tracing and quarantine of close contacts resulted in limited transmission in the BU community.Faculty and staff were almost always infected outside of the university campus. While the majority of students with a known source of infection reported another BU affiliate as their contact, these infectious events appeared to occur outside of BU housing and instructional settings, where interventions were targeted. When clusters of cases did appear in settings the university could not directly target, e.g., due to social gatherings or other off campus gatherings, these were quickly controlled, due to our vigorous testing regime, rapid contact tracing, and strict enforcement measures, and consequently no major outbreaks were observed. This meant that the resulting numbers of cases throughout the semester were consistent with our goal of maintaining a linear, rather than exponential, increase in cases, which was manageable with our intervention strategies.Surveillance testing allowed us to identify and isolate many close contacts in advance of contact tracing efforts. Importantly, we note that due to the surveillance testing system, BU tended to detect increases in cases in advance of the surrounding community where people were mostly All rights reserved. No reuse allowed without permission.BU's success is consistent with current understanding of best practices for COVID-19 control. In fact, these strategies of aggressive testing, contact tracing, and quarantine and isolation have been successfully implemented in many countries, including Singapore, South Korea, and Taiwan. [21] [22] [23] However, unlike these countries, the BU setting did not allow the restriction of travel between the campus and nearby community, making this a strong demonstration of the utility of these approaches even despite substantial importation of cases from the surrounding community. This can potentially serve as a model for other institutions nested within a broader community.The semester was not without challenges. There were times when the contact tracing team was unable to identify contacts due to some students' reluctance to divulge information regarding where they had been or who they had been with. In these cases, coordination between the dean of students and the contact tracing team was critical in identifying other students who were associated with the infected student(s) through team or club membership so increased frequency of testing (adaptive testing) could be performed.This approach to infection control on a university campus carries a high financial cost 24 ; BU had to implement budget adjustments, including hiring freezes, salary freezes, and several other costcutting measures, to meet the cost of these services and respond to declining revenue because of pandemic-related changes to operations. While we do not attempt a cost effectiveness analysis here, we note that the university was able to meet its financial obligations and avoid large layoffs All rights reserved. No reuse allowed without permission.We recognize that BU benefited from being a large research university with much of the required expertise for our strategy available within the university, saving money and facilitating substantial control over the operations. This is clearly not feasible for all institutions of higher education. This implies that broader efforts in the community, supported by government public health agencies, are required to control spread.",United States,abstract,2021-02-26,02
c98c7acfa1f31debe1ee27d4a1630dbfe6500613,"SARS-CoV-2 Shedding Dynamics Across the Respiratory Tract, Sex, and Disease Severity 1 for Adult and Pediatric COVID-19 2 3","Our systematic review identified studies reporting SARS-CoV-2 quantitation in respiratory 75 specimens taken during the estimated infectious period (-3 to 10 days from symptom onset 76[DFSO]) (15, 18). The systematic review protocol was based on our previous study (19) and was 77 prospectively registered on PROSPERO (registration number, CRD42020204637). The 78 systematic review was conducted according to Cochrane methods guidance (20) . Other than the 79 title of this study, we have followed PRISMA reporting guidelines (21). 80For analyses based on rVL (viral RNA concentration in the respiratory tract) and to account 120 for interstudy variation in the volumes of viral transport media (VTM) used, the rVL for each 121 collected sample was estimated based on the specimen concentration (viral RNA concentration 122 in the specimen) and dilution factor in VTM. Typically, swabbed specimens (NPS and OPS) 123report the viral RNA concentration in VTM. Based on the VTM volume reported in the study 124 along with the expected uptake volume for swabs (0.128 ± 0.031 ml, mean ± SD) (24), we 125 calculated the dilution factor for each respiratory specimen and then estimated the rVL. 126Similarly, liquid specimens (ETA, POS and Spu) are often diluted in VTM, and the rVL was 127 estimated based on the reported collection and VTM volumes. If the diluent volume was not 128 reported, then VTM volumes of 1 ml (NPS and OPS) or 2 ml (POS and ETA) were assumed (23, effect on the intercept (regression t-test for "" ). Shedding dynamics were compared between 165 cohorts by interaction (regression t-test for # ). The statistical significance of viral clearance for 166 each cohort was analyzed using simple linear regression (regression t-test on the slope). 167Regression models were extrapolated (to 0 log10 copies/ml, rather than an assay detection limit) 168to estimate the duration of shedding. 169To assess heterogeneity in shedding, rVL data were fitted to Weibull distributions (19), and 170 the rVL at a case percentile was estimated using the Weibull quantile function. Each cohort in 171 statistical analyses included all rVLs for which the relevant characteristic (LRT or URT, age 172 cohort, sex or disease severity) was ascertained at the individual level. Cohorts with small 173 sample sizes were not compared, as these analyses are more sensitive to potential sampling error. 174Statistical analyses were performed using OriginPro 2019b (OriginLab) and the General Linear 175 Figure) . For pediatric cases, the search found only nonsevere 189 infections and URT specimen measurements. Appendix Table 1 summarizes the characteristics  190 of contributing studies, of which 18 had low risk of bias according to the modified JBI critical 191 appraisal checklist. Studies at high or unclear risk of bias typically included samples that were 192 not representative of the target population; did not report the VTM volume used; had non-193 consecutive inclusion for case series and cohort studies or did not use probability-based sampling 194 for cross-sectional studies; and did not report the response rate (Appendix Table 2 While regression analysis compared mean shedding levels and dynamics, we fitted rVLs to 205After stratifying adults for disease severity, our analyses showed nonsignificant differences 217 in URT shedding based on sex and age. For nonsevere illness, male and female cases had no 218 significant difference in mean rVL at 1 DFSO (P for intercept = 0.085) or rate of viral clearance 219 (P for interaction = 0.644) ( Figure 2C) . Similarly, for severe disease, male and female cases had 220 comparable mean rVLs at 1 DFSO (P for intercept = 0.326) and URT dynamics (P for 221 interaction = 0.280) ( Figure 2D ). For nonsevere illness, younger and older adults had no 222 significant difference in URT shedding levels at 1 DFSO (P for intercept = 0.294) or post-223 symptom-onset dynamics (P for interaction = 0.100) ( Figure 2E ). For severe disease, the adult 224 age cohorts showed similar mean rVLs at 1 DFSO (P for intercept = 0.915) and rates of viral 225 clearance (P for interaction = 0.359) ( Figure 2F) . 226Accordingly, the distributions of severe and nonsevere LRT shedding bifurcated along 240 disease course ( Figure 3B ). At 6 DFSO, the 80 th cp estimate of LRT rVL was 9.40 (95% CI, 241 8.67-10.20) log10 copies/ml for severe COVID-19, while it was 7.66 (95% CI, 6.65-8.83) log10 242 copies/ml for nonsevere illness. At 10 DFSO, the difference between 80 th -cp estimates expanded, 243 as they were 8.63 (95% CI, 8.04-9.26) and 6.01 (95% CI, 4.65-7.78) log10 copies/ml for severe 244 and nonsevere disease, respectively. 245Our data indicated that nonsevere illness yielded greater skewing in LRT shedding than 246 severe disease in the analyzed period ( Figure 3B ). For nonsevere COVID-19, the SD of rVL was 247 1.92, 2.01 and 2.09 log10 copies/ml at 6, 8 and 10 DFSO, respectively. For severe disease, it was 248 lesser 1.25, 1.37 and 1.61 log10 copies/ml at 6, 8 and 10 DFSO, respectively. 249For severe COVID-19, regression analysis showed, in the LRT, comparable mean rVLs at 4 250 DFSO between younger and older adults (P for intercept = 0.745) ( Figure 3C ). Both severe age 251 cohorts also showed persistent LRT shedding in the analyzed period: younger adults (-0.20 [95% 252 CI, -0.32 to 0.042] log10 copies/ml day -1 , P = 0.105) and older adults (-0.13 [95% CI, -0.39 to 253 0.13] log10 copies/ml day -1 , P = 0.316) both had no significant trend in SARS-CoV-2 clearance. 254Likewise, severely affected male cases had no significant trend in LRT shedding (0.001 [95% 255Interestingly, nonsevere cases showed similar SARS-CoV-2 shedding between the URT and 258 LRT, whereas severe cases shed greater and longer in the LRT than the URT (Figure 3, D and 259 E). At 4 DFSO, the URT rVL of nonsevere adults was 6.62 (95% CI, 6.50-6.74) log10 copies/ml, 260 which was not different from the LRT rVL of nonsevere adults (P for intercept = 0.651). In 261 contrast, at 4 DFSO, the URT rVL of severe adults (7.34 [95% CI, 7.01-7.68] log10 copies/ml) 262 was significantly lower than the LRT rVL of severe adults (P for intercept = 0.031). 263 264For the pediatric cohort, regression estimated, in the URT, the mean rVL at 1 DFSO to be 266 7.32 (95% CI, 6.78-7.86) log10 copies/ml and SARS-CoV-2 clearance rate as -0.32 (95% CI, -267 0.42 to -0.22) log10 copies/ml day -1 (Figure 4A ). Both estimates were comparable between the 268 sexes for children ( Figure 4D) . The estimated mean duration of URT shedding (down to 0 log10 269 copies/ml) was 22.6 (95% CI, 17.0-28.1) DFSO for children with COVID-19. 270Between pediatric cases, who had nonsevere illness in our dataset, and adults with nonsevere 271 illness, both URT shedding at 1 DFSO (P for intercept = 0.653) and URT dynamics (P for 272 interaction = 0.400) were similar (Figure 4A) . Distributions of rVL were also comparable 273 between these cohorts ( Figure 4B) . Conversely, URT shedding at 1 DFSO was greater for 274 severely affected adults when compared to nonsevere pediatric cases (P for intercept = 0.017), 275 but URT dynamics remained similar (P for interaction = 0.863) (Figure 4C) . we found that adults with severe COVID-19 showed higher rVLs shortly after symptom onset, 281 but similar SARS-CoV-2 clearance rates, when compared with their nonsevere counterparts. In 282 the LRT, we found that high, persistent shedding was associated with severe COVID-19, but not 283 nonsevere illness, in adults. Interestingly, in the analyzed periods, adults with severe disease 284 tended to have higher rVLs in the LRT than the URT. 285After stratifying for disease severity, we found that sex and age had nonsignificant effects on 286 post-symptom-onset SARS-CoV-2 shedding levels and dynamics for each included analysis 287 (summarized in Table 2 ). Thus, while sex and age influence the tendency to develop severe 288 COVID-19 (2-4), we find no such sex dimorphism or age distinction in URT shedding among 289 cases of similar severity. This includes children, who had nonsevere illness in our study and 290show similar URT shedding post-symptom onset as adults with nonsevere illness. 291While our analyses did not account for virus infectivity, higher SARS-CoV-2 rVL is 311 associated with a higher likelihood of culture positivity, from adults (15, 16) as well as children 312(36), and higher transmission risk (10). Hence, our results suggest that infectiousness increases 313 with COVID-19 severity, concurring with epidemiological analyses (53, 54). They also suggest 314 that adult and pediatric infections of similar severity have comparable infectiousness, reflecting 315 epidemiological findings on age-based infectiousness (54-56). Moreover, since respiratory 316 aerosols are typically produced from the LRT (57), severe SARS-CoV-2 infections may have 317 increased, and extended, risk for aerosol transmission. As severe cases tend to be hospitalized, 318 this provides one possible explanation for the elevated risk of COVID-19 among healthcare 319 workers in inpatient settings (58); airborne precautions, such as the use of N95 or air-purifying 320 respirators, should be implemented around patients with COVID-19. 321Additional studies should permit these remaining comparisons. Second, our analyses did not 326 assess the influence of therapies or additional case characteristics, including comorbidities. 327While the relationships between some comorbidities and SARS-CoV-2 kinetics remain unclear, 328 recent studies indicate many potential therapies (e.g., remdesivir, hydroxychloroquine, lopinavir, 329 ritonavir, low-dose monoclonal antibodies and ivermectin) have no significant anti-SARS-CoV-2 330 effects in patients (59-64). Third, the systematic dataset consisted largely of hospitalized 331 patients, and our results may not generalize to asymptomatic infections. 332",Canada,first author,2021-02-19,02
8361a95e7da6b84875fe53d8b33a5a0c21b37019,Journal Pre-proofs Initial determination of COVID-19 seroprevalence among outpatients and healthcare workers in Minnesota using a novel SARS-CoV-2 total antibody ELISA Full Title: Initial determination of COVID-19 seroprevalence among outpatients and healthcare workers in Minnesota using a novel SARS-CoV-2 total antibody ELISA Running Title: COVID-19 seroprevalence in Minnesota,"SARS-CoV-2 is the viral causative agent of COVID-19, which is currently a global pandemic. 1 COVID-19 serology or antibody tests are a key tool for elucidating an individual's or community's exposure history to SARS-CoV-2, through detection of an immune response from a current or past infection with SARS-CoV-2. Identifying this population is important because SARS-CoV-2 polymerase chain reaction (PCR) tests only detect the presence of viral nucleic acid in individuals with active infections. It is currently estimated that as many as 25% of those who are infected are asymptomatic; therefore antibody testing can provide comprehensive data on true rates of exposure to SARS-CoV-2. 2, 3 Potential uses of serology assays include community screening, contact tracing, epidemiological studies, and screening convalescent plasma collected from individuals who have recovered from COVID- 19. 4 In response to the public health emergency related to COVID-19, the Food and Drug Administration (FDA) invoked the Emergency Use Authorization (EUA) pathway to accelerate the availability of COVID-19 tests. Although FDA EUA is required for clinical applications of SARS-CoV-2 molecular tests, until May 4, 2020, manufacturers of serologic assays were submitting for EUA only on a voluntary basis. 5 As a result, several serology tests were marketed that were not approved under the EUA, did not provide accurate results, had high false positive rates, and were not independently validated. 6 To avoid the significant risks posed by the use of commercially available tests during the early stages of the pandemic -some of which had poor performance characteristics and did not have EUA designation -and potential associated supply chain disruptions, we pursued a multi-departmental effort within the University of Minnesota to develop a SARS-CoV-2 total antibody test using an enzyme-linked immunoassay (ELISA) format. First, we examined what is known about SARS-CoV-2 and other coronaviruses. Coronaviruses share structural similarities and are composed of 16 non-structural and four structural proteins, which are the spike (S), envelope (E), membrane (M), and nucleocapsid (N) proteins. 7 Common to all coronaviruses is a receptor binding domain (RBD) within the spike protein; prior studies have found that the RBD is a common target for neutralizing antibodies with the closely related SARS and MERS viruses. 8 For SARS-CoV-2, the S protein and RBD have unique features relative to other coronaviruses for enhanced cell entry, including an RBD within the S protein that can undergo furin pre-activation for cell entry and the RBD's high angiotensin converting enzyme 2 (ACE2) binding affinity. 9 Given the key role of the RBD in viral pathogenesis and known antigenicity among other closely related coronaviruses, we utilized a recombinant SARS-CoV-2 RBD protein fragment to produce antigen for the development of a manual ELISA within the University of Minnesota's Center for Immunology. 10, 11 The ELISA was then transferred to the University of Minnesota's Advanced Research and Diagnostic Laboratory where clinical validation was performed to enable the assay to be used for patient testing with a current capacity of 2,000 tests per day.As part of the assay validation, we conducted a method comparison study with three commercial SARS-CoV-2 antibody assays that utilize various SARS-CoV-2 antigens (N, S protein), detect different antibody classes (IgG, total antibody), and have different assay formats (ELISA and chemiluminescent microparticle immunoassay).Although these commercial assays have been used in large-scale seroprevalence studies in metropolitan cities worldwide, there is a critical lack of data demonstrating their comparative diagnostic performance. The use of seroprevalence data in guiding public policy decisions underscores the importance of comprehensively delineating the relative clinical sensitivity and specificity of these SARS-CoV-2 serology tests. Our method comparison study was designed to provide this critical data.With our robustly validated laboratory-developed serology test, we set forth to establish an initial determination of COVID-19 seroprevalence among healthcare workers and outpatients in Minnesota. Here, we present the results from the first 38 days that this test was available for the afore-mentioned populations. Genomics Center (UMGC) COVID-19 qRT-qPCR assay). Blood samples from patients meeting these criteria were identified using the laboratory information system (Sunquest, Sunquest Information Systems, Tucson, AZ). Serology testing is prioritized by the M Health Fairview healthcare system to ensure patients are tested in a manner that most significantly impacts the system's ability to understand disease spread and evaluate higher-risk individuals. For our seroprevalence study, we analyzed 3,661 serum samples received during the first 38 days that our assay was available as an orderable clinical test. These samples were obtained from healthcare workers with confirmed and non-confirmed COVID-19 exposures ≥14 days prior, and asymptomatic outpatients with potential COVID-19 exposures or history of prior symptoms consistent with COVID-19 ≥14 days prior.The RBD fragment from the previously published literature 10, 11 was expressed in insect cells. To improve the antigenicity of the RBD fragment, we re-expressed the same RBD fragment in HEK293T cells. To this end, HEK293T cells stably expressing RBD (containing a human Fc tag) were made according to the E and F section of the pLKO.1Protocol from Addgene (http://www.addgene.org/protocols/plko/). The Fc-tagged RBD was then purified as previously described. 10, 11 The SARS-CoV-2 total antibody screening assay employed an indirect enzyme immunoassay technique. Method validation studies included analytical sensitivity, interference, precision around the cutoffs, matrix equivalency, intra-and inter-assay precision, linearity, and stability (Supplemental Methods). The assay was validated for use with serum, lithium heparin plasma, and EDTA plasma (Supplemental Our in-house SARS-CoV-2 total antibody ELISA is a qualitative screen for total antibodies to the spike RBD antigen, with the semi-quantitative measurement of IgG antibodies by endpoint titer (Supplemental Figure 2) . Serum, lithium heparin and EDTA plasma are acceptable specimen types (Supplemental Methods). The limit of quantification (functional sensitivity) is 10 ng/mL. The screening test was designed to recognize IgG, IgM and IgA antibodies as the combined detection of these immunoglobulins has a higher sensitivity than the detection of each antibody alone in the setting of COVID-19. [19] [20] [21] Although it has been shown that heat inactivation of serum interferes with the detection of antibodies to SARS-CoV-2 potentially causing falsenegative results, we did not observe a significant difference in the antibody indices of 10 samples that were analyzed with and without heat inactivation (56°C for 1 hour; p>0.05; t-test). 22 Analytical specificity/cross-reactivity was evaluated by testing 520 blood Haemophilus influenza type B IgG (n=23), Influenza A IgG (n=88), and Influenza B IgG (n=77), and a pre-pandemic cohort used to assess for cross-reactivity to common cold coronavirus antibodies (n=210). Samples were also obtained from 21 patients who tested positive for Hepatitis B virus DNA. Samples with direct evidence of antibodies to the common cold coronaviruses were not available for testing. However, the seroprevalence for the common cold coronaviruses is high (60 -90%); therefore, crossreactivity was indirectly ruled out through testing 210 pre-pandemic samples. 23 The diagnostic performance of the SARS-CoV-2 total antibody ELISA was Table   2 . Among patients with PCR positive NP specimens, stratification by days after symptom onset yields a clinical sensitivity of 71.8% (95% CI: 55.1% -85.0%), 100% clinical specificity (95% CI: 98.5% -100.0%), for patients between 4 -14 days after symptom onset. The assay has the most robust performance characteristics when used with patients >14 days after symptom onset: 100% clinical sensitivity (95% CI: 91.2% -100.0%) and 100% clinical specificity (95% CI: 98.5% -100.0%).The clinical sensitivity of our assay increases with the number of days post-COVID-19 symptom onset (Supplemental Figure 3) . Both patients whose SARS-CoV-2 antibody temporal profiles are depicted in Supplemental Figure 3 had positive diagnostic PCR tests six days after symptom onset. Patient 1 had a 31-day hospital course after ICU admission prior to being discharged, whereas patient 2 had a 16-day hospital course from ICU admission to discharge.Whereas SARS-CoV-2 viral RNA is detectable even prior to symptom onset and reaches its peak at day 5 after symptoms, antibody responses begin near day 7 and most patients exhibit rising IgG and IgM antibody titers 10 days after symptom onset. 20, 26 Because of what is known to-date regarding the viral kinetics and antibody responses in patients with COVID-19, 27 our SARS-CoV-2 total antibody ELISA is not recommended for use in patients within 10 days of symptom onset as they may produce insufficient levels of detectable antibodies.Equivocal results indicate that antibodies were detected at a level close to the threshold of the limit of detection for the assay. Such results could represent an early stage of SARS-CoV-2 infection, detection of decreasing antibody levels, cross-reactivity with viral antibodies not included in the method validation studies, or a weak antibody response among immunosuppressed patients or patients with an underlying immune disorder. Repeat testing of patients with equivocal results with additional blood samples at a later date is recommended if clinically indicated.We compared our laboratory-developed total antibody ELISA to three commercially available serology assays using plasma and serum samples from a total protein IgG assay. For the three discordant results between our laboratory-developed ELISA and the Euroimmun assay, the negative results from our assay are likely correct as these samples were from the pre-pandemic cohort. The one sample with a negative result from our laboratory-developed ELISA that had a positive result when using the Abbott assay was also from the pre-pandemic cohort. The two samples with positive results from our laboratory-developed ELISA that had negative results when using the Abbott assay were obtained from SARS-CoV-2 patients who tested positive by a PCR method using an NP swab. These discordant results could be explained by the difference in the epitopes and isotypes targeted by the different assays (the Abbott assay detects IgG whereas our laboratory-developed ELISA detects IgG, IgM, and IgA) and the sensitivity of the assays when testing patients who are within the early stages of disease progression.The M Health Fairview healthcare system includes 10 hospitals and 60 clinics predominantly located in the Twin Cities, but inclusive of outlying cities throughout the state as well. As an initial step to a statewide COVID-19 testing initiative announced by the Governor of Minnesota to establish an estimate of the percentage of the population that has been exposed to COVID-19, we deployed our SARS-CoV-2 total antibody assay to test 1,282 healthcare workers and 2,379 outpatients within the M Health Fairview system during the first 38 days that our assay was available as an orderable clinical test ( Table 5) . The distribution of IgG titers in the outpatient population was not significantly different from the range of IgG titers among the healthcare workers (p = 0.60, Chisquare test) (Figure 3) . Additionally, there were no significant age-or sex-specific differences in seroprevalence in these two populations.Our study provides the first determination of COVID-19 seroprevalence among healthcare workers and outpatients in Minnesota. Although the 4.46% seroprevalence among this cohort of patients suggests that individuals with mild presentation of COVID-19 develop an antibody response, we do not have data regarding the percentage of these outpatients who required subsequent hospitalization due to COVID-19 related symptoms. As serology tests are deployed on a broader scale, the relationship between asymptomatic or mild forms of disease presentation and the development of an immune response will be more clearly defined.Potential sources of variability among serologic assays include differences in acceptable specimen types (serum, plasma, whole blood), formats (ELISAs, chemiluminescent immunoassay, lateral flow immunoassay), detected antibody classes (IgA, IgM, IgG, total), and SARS-CoV-2 antigen(s) used to design the assay. 28 There is particular debate on whether assays should target the N or S protein -whereas the N protein might be expressed earlier in the viral lytic cycle and may have greater sensitivity earlier in the disease process than the S protein, the S protein could be more immunologically relevant due to its role as a target for neutralizing antibodies and vaccine development. 29 Despite these potential sources of variability, the results from our method comparison study demonstrated excellent concordance between our inhouse method and three commercial antibody methods. Importantly, our data suggest that the target SARS-CoV-2 antigen does not appear to significantly impact the accuracy or concordance of serology test results. This could have important implications for correlating various antibody test methods to protective neutralizing antibodies that primarily target the S protein RBD. In these cases, ELISAs using the SARS-CoV-2 N protein as the antigen could be a reasonable surrogate for measuring protective neutralizing antibodies, although additional confirmatory studies are needed. In a recently published study, antibodies against the N protein showed 100% sensitivity and specificity in patients ≥15 days after symptom onset, whereas antibodies against the S protein were associated with 91% sensitivity and 100% specificity. 29 However, our data demonstrated that our assay, which detects total antibodies to the S protein RBD, exhibited equivalent diagnostic agreement with a commercial assay that detects IgG antibodies against the N protein (Epitope Diagnostics) even when samples were collected <14 days of symptom onset.The population of healthcare workers we tested for our seroprevalence study represents potential workplace COVID-19 exposures. The low seroprevalence (2.96%) in this population suggests that guidelines regarding the use of personal protective equipment (PPE) for these healthcare workers are effective at mitigating the spread of COVID-19. A seroprevalence study in Germany came to the same conclusion regarding the effectiveness of PPE, with a low seroprevalence rate of 1.6% among healthcare workers at a tertiary care hospital. 30 Acknowledging that a sampling of the outpatients within one healthcare system is not a random community sampling, our data suggest that healthcare workers could have a lower overall rate of infection compared to the general population in Minnesota. The results from a study investigating the rate of COVID-19 infection among healthcare workers in downstate New York demonstrated a similar trend. 31 Large-scale geographic COVID-19 seroprevalence surveys have been conducted in major metropolitan cities throughout the U.S. The seroprevalence in Santa Clara County, CA was 2.8% as of April 3-4, 2020. 32 Preliminary data suggest that COVID-19 infections are far more widespread -and the fatality rate much lower -in Los Angeles County than previously thought. The seroprevalence in this region was determined to be 4.1%. 33 Although these studies provide informative benchmarks for local disease prevalence, the commercial serology tests used in these studies have questionable performance characteristics, which impedes the reliability of the pursuant comparative studies. As additional seroprevalence data are obtained to support public health decision-making during the COVID-19 pandemic, it is imperative that these data are acquired using serologic test platforms with reliable performance characteristics.Given the high sensitivity and specificity of our in-house developed test, the predictive value of our test will be robust even among populations with a low prevalence of exposure. Extrapolating the 4.46% seroprevalence in our sample of 2,379 outpatients to the population of Minnesota (5.64 million), 34 251,500 individuals would be expected to have been exposed to COVID-19. However, this number is 10-times greater than the current number of laboratory-confirmed COVID-19 cases in the state as reported by the Minnesota Department of Health, 35 suggesting that COVID-19 is more widespread than reported.Although our study focused on the use of serology tests for seroprevalence determinations, the detection of SARS-CoV-2 antibodies also has an integral role in identifying protective antibodies with neutralization assays. Such assays provide quantitative information on the ability of patient antibodies to confer protective immunity based on the antibody-mediated inhibition of virus growth ex vivo. RBD-specific antibodies have previously been shown to exhibit neutralizing functions against SARS-CoV-2, supporting the likelihood for protective immunity. 36, 37 However, future studies are needed to more rigorously demonstrate correlation between laboratory-developed and commercial antibody test results and neutralizing antibody titers.Our study has limitations that should be considered when interpreting the results.First, remnant blood specimens were utilized for the assay validation studies. The majority of the specimens were analyzed 24-48 hours following their initial collection after which time they were stored at 4°C. However, the data from our stability studies indicate that these storage conditions did not cause significant changes in the levels of SARS-CoV-2 total antibody detected by our ELISA method. Second, the initial date of symptom onset was determined from subjective reports obtained from the patients at their time of hospital admission, as noted in the electronic medical record. However, this is a limitation that is common to several COVID-19 studies. Third, our method validation, which demonstrated 100% sensitivity and specificity after 14 days from symptom onset, was performed primarily with samples from PCR positive COVID-19 patients who required hospitalization. While our data on healthcare workers and outpatients demonstrates the ability of our method to detect antibody responses in milder cases, it is not clear if these sensitivity and specificity metrics apply for nonhospitalized PCR positive COVID-19 patients.Preliminary studies suggest a correlation between serum antibody levels and clinical severity of disease. 38, 39 Therefore, additional studies utilizing quantitative or semi-quantitative antibody methods like ours are needed to definitively establish the relationship between antibody levels and severity. Additional unanswered questions remain including the influence of co-morbidities on patients' COVID-19 immune responses, the impact of immunogenetic determinants on immune response, the time course of antibody production in the context of naturally acquired immunity, the kinetics of a protective antibody response stimulated by a safe and effective vaccine, and the identification and mechanism of action of neutralizing antibodies as prophylactic and therapeutic COVID-19 treatment. Submitted on 05/04/2020 04/26/2020 05/04/2020 Submitted on 03/05/2020 CMIA, chemiluminescent microparticle immunoassay; ELISA, Enzyme-linked immunosorbent assay; PPA, positive predictive agreement, NPA, negative predictive agreement; RBD, receptor binding domain; AI, antibody index; OD, optical density; FDA, Food and Drug Administration; EUA, emergency use authorization * > 14 days, ** ≥ 14 days, ^ ≥ 21 days, ^^ RT-PCR confirmed positive patients. Information was collected from assays' instructions for use Table 4 . Concordance between the laboratory-developed total antibody ELISA and commercially available serology assays ",USA,first author,2021-02-01,02
e8c66629483a7681f3ec5e2d6d21a694ef8787e0,A high-throughput radioactivity-based assay for screening SARS-CoV-2 nsp10-nsp16 complex,"O-methylation of the first nucleotide (N7-meGpppN2′Ome; Cap-1) could stay viable like the host mRNAs 12, 13 . Particularly, CoVs generate mRNAs with a type-1 cap structure to avoid identification and activation of host defence mechanisms [13] [14] [15] [16] . Coronaviral mRNA-capping starts with the removal of 5′-γ-phosphate from nascent viral RNA by nsp13. A Guanosine monophosphate is then attached to the 5′-diphosphate by an RNA-guanylyltransferase to form GpppN-RNA. Subsequently, nsp14 methylates N 7 of guanosine, giving rise to a Cap-0. Ultimately, Cap-0 is transformed into a doubly methylated (Cap-1) structure by nsp16 9, 17 .The importance of conserved nsp16 for function and survival of CoVs has been documented in vivo and in vitro 13, 16, 18, 19 . Nsp16 is a member of the 2′-O methyltransferase (MTase) family, catalyzing the transfer of a methyl group from S-adenosyl methionine (SAM) to RNA substrates 20 . MTases are generally druggable with several highly selective and cell-active inhibitors of human MTases available 21 . The in vitro 2′-O-MTase activity of nsp16 has been reported for Feline-CoV, MERS-CoV, and SARS-CoV [22] [23] [24] [25] . However, nsp16 was significantly active only when in complex with nsp10 23 . Nsp16 alone is unstable, and nsp10-nsp16 complex formation is essential for its binding to SAM and RNA substrate 24 . The crystal structure of nsp16 has only been determined in complex with nsp10 26 . Several structures of nsp10-nsp16 from various CoV species are available as apo, and in complex with RNA substrate, SAM, or SAM analogues, which vastly enables the structure-based hit optimization 24, [26] [27] [28] [29] [30] . Nsp10-nsp16 complex selectively binds and methylates longer CoV mRNAs and synthetic small RNAs with Cap-0 23 . Moreover, SARS-CoV nsp10-nsp16 methylates N7-meGpppA-RNA, but not N7-meGpppG-RNA, which provides some selectivity over the host mRNAs 24 .These studies indicate that the conserved nsp10-nsp16 complex is essential for CoVs ability to mimic the host mRNAs needed for viral replication 12, 13, 23 . Therefore, inhibition of nsp10-nsp16 complex activity could potentially hinder the pathogenesis of CoVs through eliciting a host immune response 13, 15, 16 . However, availability of an optimized assay suitable for high-throughput screening (HTS) is an unmet need. Here, we report development and optimization of a scintillation proximity assay (SPA) for testing RNA MTase activity of nsp10-nsp16 complex, kinetic characterization, and high-throughput screening.Biotinylated RNA substrate (5′ N7-meGpppACCCCC-biotin) was synthesised by bioSYNTHESIS (Levisville, Texas, USA). 384-and 96-well Streptavidin PLUS High-Capacity FlashPlates, 3 H-SAM, and 3 H-biotin were from PerkinElmer (Massachusetts, USA). SAM, sinefungin, and SAH were from Sigma, Missouri, USA. SAM2 ® Biotin-Capture Membrane was obtained from Promega, Wisconsin, USA. All reaction buffers contained 0.4 U/μL RNaseOUT™ ribonuclease inhibitor (Invitrogen, Massachusetts, USA).Expression and purification of SARS-CoV-2 nsp10-nsp16 is recently described. 31 Briefly, nsp16 (S1-N298) and nsp10 (A1-Q139) were separately expressed in Escherichia coli BL21(DE3) RIL and purified to near homogeneity. The nsp10-nsp16 complex was prepared using the purified proteins in an 8 (nsp10) to 1 (nsp16) molar ratio, dialyzed in storage buffer containing 50 mM Tris-HCl (pH 8.0), 200 mM NaCl, 0.5 mM TCEP, and 5% glycerol and flash frozen.The initial MTase reactions were performed in a buffer similar to the reported condition for SARS-CoV nsp10-nsp16 complex 23 with some modifications. Accordingly, 10 μL mixtures containing 50 mM Tris (pH 8.0), 1 mM MgCl2, 5 mM DTT, 2 µM RNA substrate, and 250 nM nsp10-nsp16 complex were prepared. The reactions were started by addition of 4 µM SAM (16% 3 H-SAM).Reactions proceeded for 1 hour, and then quenched by adding 10 μL of 7.5 M Guanidine hydrochloride followed by 60 μL of 20 mM Tris-HCl (pH 8.0). The reaction products were transferred into Streptavidin-coated FlashPlates for scintillation counting using a TopCount instrument (PerkinElmer, Massachusetts, USA). Reaction mixtures were prepared in triplicate. For determining the optimum buffer pH, 50 mM Tris-HCl was used for generating the pH profile ranging from 6.5 to 9.0. The effect of various reagents such as salts, detergents, reducing agents, BSA, EDTA, and DMSO was investigated through titration of each reagent in assay buffer at pH 7.5 and measuring their relative activity compared to the control (i.e., reactions without additive) using the SPA-based assay. The following buffer was chosen as the optimal reaction condition: 50 mM Tris-HCl, 100 mM KCl, 1.5 mM MgCl2, 0.01% Triton-X-100, 0.01% BSA, and 5 mM DTT.All subsequent experiments were performed using this buffer condition. All reactions were performed at room temperature (23 ˚C).For determining the kinetic parameters, reactions were carried out using the optimized buffer condition in triplicate in standard 96-well polypropylene plates. For each experiment, the concentration for one substrate (i.e., SAM or RNA) was varied, while the concentration of the second substrate was kept at near saturation (>3.5x Km). After starting the reaction by adding 3 For clarity, when we report the activity of the protein complex as nmoles/min/mg, the ""mg"" refers to ""mg of nsp16"". Since the complex is 1 (nsp16): 8 (nsp10), the molarity of nsp16 and the nsp10-nsp16 complex are the same.The quality and robustness of the nsp10-nsp16 assay was verified by the standard Z′-factor determination 32 . Optimized reaction mixture containing 125 nM nsp10-nsp16 complex, and 0.8 μM RNA were prepared in the presence or absence of 200 μM sinefungin in 384-well format using an Agilent Bravo automated liquid-handling robot. Final DMSO concentration was 1%. The reactions were started by addition of 1.7 μM SAM (30% 3 H-SAM) and were incubated for 30 minutes at 23 °C. After measuring signal by SPA-based method, the Z′-factor was calculated as previously described 32 .The library of 76 epigenetics chemical probes was from Structural Genomics Consortium (SGC; https://www.thesgc.org/chemical-probes/epigenetics). The compounds were screened at 50 μM with a final DMSO concentration of 1% in 125 nM nsp10-nsp16 complex, 0.8 μM RNA, and 1.7 μM SAM (30% 3 H-SAM). Reactions containing 50 μM SAH and 1% DMSO were used as positive and negative controls, respectively. After 30 min incubation, reactions were quenched, transferred into SPA plates, and the incorporated radioactivity was quantitated as described above.Nsp16 protein sequences were taken from the CoV ORF1ab sequences accessible through UniProt database. These sequences consisted of 229E (P0C6X1), HKU1 (P0C6X3), NL63 (P0C6X5),The nsp16 sequences were aligned using Clustal Omega 33 , and sequence similarities and secondary structure features were rendered by ESPript Version 3.0 34 . The sequence conservation among these sequences was mapped onto the crystal structure of nsp10-nsp16 from SARS-CoV-2 (PDB: 6WKS) using Chimera Version 1.14 35 .In vitro activity of SARS-CoV-2 nsp10-nsp16 complex was tested by monitoring the transfer of 3 H-SAM to the biotinylated N7-meGpppACCCCC RNA substrate. The methylated RNA product was captured using SPA plates followed by recording the changes in CPM. Initial tests at 250 nM of nsp10-nsp16 complex, 2 μM RNA substrate, and 5 μM SAM indicated the protein complex is active with significant signal-to-noise ratio. The assay conditions were further optimized with respect to the pH of the buffer and the presence of several commonly used additives (Fig. 1) . The complex was most active at pH 7.5 (Fig. 1A) . Using this optimal pH, the effects of other buffer components were investigated. Although NaCl over a wide range of concentrations (10-100 mM) reduced the enzyme activity by about 30%, KCl had little effect on nsp10-nsp16 complex activity up to 100 mM, and MgCl2 slightly increased the signal (Figs. 1B-D) . However, presence of Triton X-100 as low as 0.002% increased the signal by more than 20% (Fig. 1E) . Tween-20 had a similar effect (Suppl. Fig. 1A) . The reducing agents, TCEP and DTT, had no significant effect on enzyme activity (Figs. 1G-H) . The presence of BSA at concentrations higher than 0.02% reduced the signal readout (Fig. 1F) . EDTA at concentrations as low as 50 µM considerably reduced the activity (Suppl . Fig. 1B) . Based on these observations, 50 mM Tris-HCl, 100 mM KCl, 1.5 mM MgCl2, 0.01% Triton X-100, 0.01% BSA, and 5 mM DTT was selected as the optimized buffer condition for SARS-CoV-2 nsp10-np16 complex MTase activity assays. Overall, the assay optimization led to 70% increase in assay signal over the starting assay conditions (Suppl. Fig. 1C) . The nsp10-nsp16 complex activity under the optimized conditions was not affected by DMSO up to 5% (Fig.   1I ).The kinetic parameters for nsp10-nsp16 complex were determined using the optimized conditions. Initial assessment of the MTase activity at various concentrations of nsp10-nsp16 complex indicated reaction linearity up to around 250 nM of the protein complex (Supp. Fig. 1D) . At 250 nM of nsp10-nsp16 complex, using the membrane-based approach, apparent Km values of 1.7 ± 0.3 μM and 1.6 ± 0.4 μM were determined for SAM and RNA, respectively, with apparent kcat of 15.9 ± 1.2 h -1 ( Figs. 2A-B) . For determining the Km of SAM, the concentration of RNA was kept at 5.6 μM, whereas when assessing the Km of the RNA substrate, SAM concentration was at 6.0 μM. To investigate if lowering the concentration of nsp10-nsp16 complex is possible without nsp16 inactivation due to complex dissociation, the kinetic parameters for SAM and RNA were also determined at 125 nM of nsp10-nsp16 complex. Using a SPA, the linear initial velocities were used to calculate the kinetic parameters (Suppl. Figs. 2A-B) . The apparent Km of 2.0 ± 0.2 μM and 1.0 ± 0.1 μM for SAM and RNA substrate respectively were determined (Figs. 2C-D) . The apparent kcat value was 26.9 ± 0.3 h -1 . In this round of experiments, the concentration of the second substrates, SAM and RNA, were kept at 8.0 μM and 5.0 μM, respectively. These data indicated that nsp10 and nsp16 stay in complex at lower concentration and the integrity of the complex was not affected by further dilution of the protein complex. Therefore, all further assays were performed at 125 nM of nsp10-nsp16 complex. The N7-unmethylated biotinylated RNA substrate, which was used as a control, showed almost no activity under similar assay conditions (Suppl. To assess the quality of the developed assay for HTS-screening, first the linearity of the reaction over time under the screening conditions was analysed (Suppl. Fig. 2D) . The time-course experiments revealed that the reaction was linear for at least 30 min. Using this assay condition, it was shown that sinefungin inhibited nsp10-nsp16 activity with an IC50 of 3.4 ± 0.4 μM (Hill Slope: -0.9) (Fig. 2E) . Subsequently, the quality and robustness of the developed assay for highthroughput screening was analyzed. For screening in a 384-well format, a Z′-factor of 0.83 was attained (Fig. 2F) . The optimized assay was then employed to screen a panel of 76 epigenetic chemical probes (Suppl. Fig. 3) , which included more than 20 MTase inhibitors (Suppl. Table   1 ). At a final compound concentration of 50 μM, none of these highly selective compounds significantly inhibited (>26%) the activity of nsp10-nsp16 complex, while SAH (IC50 of 5.9 ± 0.6 μM; Suppl. Fig. 1F) , reduced the activity of nsp10-nsp16 by >90% at 50 μM.As the fight against COVID-19 continues, several vaccines against SARS-CoV-2 have been made available to public. However, administering these vaccines requires very specific handling protocols, such as extremely low storage temperature for some, which may not be easily achievable in many countries. Even if all conditions are met, it will take many months to complete the vaccination. In addition, these vaccines may not be effective on fast mutating coronaviruses. This necessitates antiviral development 36 . The 2′-O-MTase nsp16 has been proposed as an appealing target for development of anti-coronaviral therapeutics 8, 11, 28, 37 . Deletion of SARS-CoV nsp16 coding-region resulted in a blockade of viral RNA synthesis 18 , and nsp16 mutants have shown a strong attenuation in infected mice 19 . It has been suggested that nsp10-nsp16 complex, through its mRNA-capping activity, helps the CoVs evade the host immune system 15 , therefore, any interruption in the activity of the nsp10-nsp16 could hinder the pathogenesis of CoVs through eliciting an immune response 13, 15, 16 . Inhibition of nsp10-nsp16 complex MTase activity by SAH (the product of the reaction), sinefungin (a SAM analogue) and aurintricarboxylic acid have been reported 22, 23, 38 . However, potent and cell-permeable nsp10-nsp16 inhibitors are yet to be developed. The availability of activity-based HTS-screening assays would greatly enabe drug discovery. Activity of SARS-CoV nsp10-nsp16 complex has previously been assessed using a filter binding-based assay 22 . Most recently, an HTS RNA-displacement assay has been reported for SARS-CoV-2 nsp10-nsp16 complex that will detect RNA competitive inhibitors. 31 The nsp10-nsp16 complex activity assays reported to-date are low throughput [22] [23] [24] 38 .Here we reported development of a radioactivity-based assay for screening SARS-CoV-2 nsp10-nsp16 complex in a 384-well format. Since around 10-fold molar excess of nsp10 is required for the maximum in vitro MTase activity of nsp16 23 , a 1:8 ratio of nsp16 to nsp10 was chosen to ensure a near maximum activity of the complex. The kinetic parameters of nsp10-nsp16 complex methyltransferase activity are presented for the first time. Thus, the Km of SAM and RNA were determined to be 2.0 ± 0.2 μM and 1.0 ± 0.1 μM, respectively. The ITC Kd values of 5.59 ± 1.15 μM and 1.21 ± 0.41 μM for SAM and RNA, respectively, were previously reported for nsp10-nsp16 complex from SARS-CoV 24 . The IC50 values for SAH and sinefungin determined in this study were consistent with previously reported values for SARS-CoV and MERS-CoV nsp10-nsp16 complex. 22, 23 Testing a subset of potent and selective chemical probes for human methyltransferases did not significantly inhibit the nsp10-nsp16 complex activity, indicating that the assay has a very low rate of false positives and is well suited for HTS. Unlike RNA displacement assays, this methyltransferase activity assay is suitable in detecting both SAM-and RNA competitive inhibitors.The available evidence indicates that many other CoVs currently in various animals are preadapted to likely infect humans in some point of time in the future and cause new pandemics [39] [40] [41] .Considering the natural diversity of CoVs across the globe 1 and the close interactions of humans with wild and domesticated animals, these future pandemics may not be prevented by the current vaccines 36 . This further highlights the importance of developing potent inhibitors against coronaviral proteins that are conserved across this family of viruses toward developing pancoronavirus therapeutics. Nsp16 is highly conserved across the CoV family 12 , and available structures from several coronaviral species also reveal a high degree of structural conservation 24, [26] [27] [28] 30 . For example, SARS-CoV-2 nsp16 shows a minimum sequence identity of 57.05 % with the other pathogenic CoVs (Fig. 3) . Mapping this sequence alignment on the nsp10-nsp16 structure ( Fig. 4) demonstrates the conservation of SAM-and RNA-binding pockets across CoV species.Therefore, inhibitors targeting the active-site of nsp10-nsp16 may be effective against other emerging and re-emerging CoV strains. The radioactivity-based assay reported here will be an enabling tool towards developing such pan inhibitors of nsp10-nsp16 methyltransferase activities and possibly future pan-coronavirus therapeutics.An HTS assay for assessing the activity of SARS-CoV-2 nsp10-nsp16 complex using a SPA-based method was developed. This assay provides a robust and sensitive tool for screening large libraries of compounds and is suitable for identifying inhibitors with different mechanisms of inhibition. It can be employed as an orthogonal method for re-evaluating potential inhibitors identified through other biochemical, biophysical, or cellular screening methods. Considering the critical role of nsp10-nsp16 complex in coronaviral pathogenesis and the highly conserved nature of nsp10-nsp16 complex across CoV species, the identified inhibitors may prove effective against other pathogenic CoVs, preventing future pandemics. . The corresponding percentage activity data for each probe is shown on the graph with a black dot. SAH was used at a similar concentration as a control (blue dot). Please note that the dotted line marks the 50% activity threshold.Supplementary Table 1 . 76 epigenetic compounds were screened against nsp10-nsp16 complex. 76 compounds, including epigenetic probes and their closely related analogues, were screened against SARS-CoV-2 nsp10-nsp16 using the developed HTS assay. The observed percentage of activity of nsp10-nsp16 in the presence of each of these compounds (at 50 µM) is presented. The list of compounds (available at https://www.thesgc.org/chemical-probes), and their specific protein targets is provided. Negative control analogues of the chemical probes are specified with ""Negative Ctrl"" under the ""Specific Targets"" column. ",Canada,first author,2021-02-03,02
02b78d5f1cfefaa9f9148226935b37b5a3f700e0,,"been challenging because of limited testing, variable testing sensitivity, misclassification of COVID-19-associated deaths, lack of completeness of COVID-19 case reports and surveillance forms, and reporting delays to local surveillance systems. 3, 4 Since April 5, 2020, the Council of State and Territorial Epidemiologists (CSTE) has recommended that all COVID-19 deaths be reported to local public health authorities. 5 Based on the CSTE guidelines, a confirmed COVID-19 death case is defined as meeting confirmatory laboratory evidence (positive RT-PCR test result) 5 ; a probable COVID-19 death case is defined as meeting 1 of the following criteria: (1) meets clinical criteria and epidemiological evidence without a positive RT-PCR test result, (2) meets presumptive laboratory evidence (serology test) and either clinical criteria or epidemiological evidence, or (3) meets vital records criteria (""a death certificate that lists COVID-19 disease or SARS-CoV-2 as a cause of death or significant condition contributing to death"") without a positive RT-PCR test result. 5 In Puerto Rico, death from COVID-19 is a reportable event to the PRDoH Mortality Surveillance System (MSS). Accurate classification of COVID-19-associated deaths (confirmed and probable) might vary by reporting source and in some cases requires review by a multidisciplinary team at PRDoH. However, counting only confirmed and probable COVID-19-associated deaths might underestimate the number of deaths attributed to the pandemic. Deaths are not counted by MSS when they are not directly associated with SARS-CoV-2 infections, such as deaths that occur outside a health care setting or deaths that are misclassified by the attending health care provider, which may contribute to an underestimation of deaths associated with COVID-19. Estimating excess deaths can help explain the severity or burden of pandemics and public health emergencies. 6, 7 The objectives of our study were to characterize COVID-19-associated deaths in Puerto Rico during March-July 2020 (using CSTE guidelines) and estimate the range of COVID-19-associated mortality that may have been underestimated.PRDoH MSS is a passive surveillance system that was enhanced for the COVID-19 response by including additional data sources to verify information on deaths attributed to COVID-19. PRDoH MSS includes information on deaths from regional epidemiologists, vital statistics from physicians, and COVID-19 laboratory results (confirmed [RT-PCR molecular test for SARS-CoV-2 RNA] and probable [SARS-CoV-2 serology test]) 8, 9 from Puerto Rico's laboratory reporting system and the National Electronic Disease Surveillance System Base System. 10 The National Electronic Disease Surveillance System Base System is an integrated information system developed by the Centers for Disease Control and Prevention (CDC) to help local, state, and territorial public health departments, such as PRDoH, manage notifiable disease data and send reports to CDC. Puerto Rico's regional epidemiologists receive death information from all hospitals and collect and verify additional COVID-19 death data, including pending laboratory test results, requested by the central PRDoH MSS team. Regardless of where the COVID-19 death occurs (hospital, other health care facility, or home), death certificates are completed by physicians and sent to vital statistics. The PRDoH MSS central team links its data with data on COVID-19 deaths from vital statistics using the International Classification of Diseases, Tenth Revision code U07.1, COVID-19. 11 The PRDoH MSS central team reconciles classification (confirmed or probable) from all reporting sources and reports the daily number of deaths (per date of death) due to COVID-19 into an electronic centralized system at the PRDoH. Deaths that were undefined or under investigation were reviewed by a multidisciplinary team when COVID-19 testing (confirmed and probable) and clinical or pathology information became available. Because public health surveillance data collected by PRDoH and analyzed in this article are not considered research, no institutional review board review was required.Excess mortality is defined as the difference between observed deaths and average expected deaths in the same period as reported by CDC's National Center for Health Statistics (NCHS). 12 We calculated excess mortality using the Farrington surveillance algorithm applied to death data for Puerto Rico from 2013 through the present. 12 Negative values, in which the observed count fell below the NCHS threshold, were set to zero 12 and were not depicted. Details about NCHS methods and excess death data associated with COVID-19 can be found elsewhere. 12 We calculated a range of deaths potentially associated with COVID-19. The lower bound of the range was the sum of confirmed and probable COVID-19 deaths reported by PRDoH during March 17-July 31, 2020 (calendar weeks 12-31). The upper bound of the range of COVID-19-associated deaths was the sum of excess deaths in Puerto Rico reported by NCHS during March 2-August 2, 2020 (calendar weeks 10-31). 2 We calculated 95% CIs for the sum of excess deaths using the standard error of excess deaths for the study period. This range, the difference between the lower bound and the upper bound, represents an estimate of missed deaths that likely were associated with the COVID-19 pandemic. We also depicted the excess estimates for all cases of death excluding COVID-19 deaths to visualize the gap between excess mortality and COVID-19 deaths during the study period. We did not analyze data on underlying medical conditions, symptomology, or course of clinical illness and care received because this information was missing for 171 (76%) cases.As of July 31, 2020, PRDoH had officially reported 225 COVID-19 deaths (119 confirmed cases and 106 probable cases). Of the 225 COVID-19 deaths, 140 (62.2%) decedents were male (Table) During March-July 2020, a total of 863 deaths were reported to NCHS and PRDoH; of these deaths, 638 (95% CI, 625-651) were found to be in excess of the expected baseline. Included in the 638 deaths were the reported 119 confirmed COVID-19 cases and 106 probable COVID-19 cases, leaving as many as 413 possible additional COVID-19-associated deaths that were assigned another cause of death ( Figure) .Since the early stages of the COVID-19 pandemic, monitoring and estimating COVID-19-associated deaths in the United States has been challenging. Public health officials have raised concerns about estimating the ""true"" death toll resulting from COVID-19. 3 Considering excess COVID-19associated mortality might improve our understanding of how many deaths are attributed to the pandemic. Although these methods are being used in the surveillance of COVID-19 mortality, 3,12-14 the results of our analysis suggest that many COVID-19-associated deaths in Puerto Rico during the pandemic were missed-approximately 2 times higher than originally reported-during the study period; as many as 413 COVID-19-associated deaths might have been uncounted. Previous national studies support that deaths from COVID-19 are likely underreported by local surveillance systems. 3, 4, 14 Increased COVID-19 testing and completeness of death reporting under local surveillance could enhance the understanding of the number of deaths caused by this evolving disease and pandemic. We suspect that reported deaths associated with COVID-19 could increase substantially as testing and local surveillance systems improve case ascertainment and classification.Our study results also reaffirm the importance of using CSTE COVID-19 death case definitions in reporting deaths. Of the 225 COVID-19 cases in Puerto Rico, almost half were probable cases. The CSTE case definition was also used in New York City COVID-19 mortality surveillance, with 5048 probable cases added to 13 831 laboratory-confirmed COVID-19 deaths. 13 The inclusion of probable cases is particularly important because, at the time of the study, Puerto Rico had the highest number of probable COVID-19 cases in the country. This new pathogen has placed new and unique demands on local public health surveillance systems and infrastructures everywhere. 15 Therefore, complementing data with NCHS data on excess deaths (measuring all causes of death) is a more sensitive measure than only counting COVID-19 confirmed and probable deaths.Based on our reported data, deaths due to COVID-19 in Puerto Rico are particularly affecting older people and people living in the most populated regions. Data show that most people die in health care settings (hospital or emergency department). Similar to national data, early local pandemic data show that the number of hospital visits was lower than usual, perhaps because of strict public health mitigation measures related to COVID-19. 16, 17 We hypothesized that people in Puerto Rico might have delayed or avoided medical care because of concerns about exposure to COVID-19. Delay or avoidance might have exacerbated uncontrolled chronic conditions or circulating infections, as shown by the conditions that contributed to death indicated on death certificates. Local public health officials should emphasize the importance of attending regular medical appointments to enhance the public's awareness and action on medical care. Public health actions could be strengthened by tailoring public messaging to populations that may require special assistance to attend their medical appointments.This study had several limitations. First, both incomplete and missing data on COVID-19 deaths in the PRDoH MSS database limited our ability to better understand contributing mortality factors or course of illness among the population; national data have had similar limitations (almost 60% of missing mortality data). 4 Second, the fragmented surveillance systems for the COVID-19 response in Puerto Rico likely underestimated COVID-19 death counts. However, the underestimation of deaths could be a common pattern during the current COVID-19 response in many jurisdictions in the United States and elsewhere. 3, [18] [19] [20] Third, excess mortality trend data do not align with the PRDoH epidemiological curve depicted for COVID-19 deaths, as previously reported in COVID-19 analyses. 3, 13, 14 This misalignment may have resulted from the lag between the occurrence of the death and the completion and submission of the death certificate by local public health officials to NCHS. Per NCHS, such data lags can range from 1 to 8 weeks. 11 Therefore, use of local data to depict mortality trends might buffer possible differences in national reporting delays. 21 Fourth, conditions contributing to death based on death certificates might be incomplete or under investigation. Therefore, our results should be interpreted with caution, as Puerto Rico, as with many other US jurisdictions, has been affected by the COVID-19 pandemic. Similar to a previous postdisaster study conducted on the island, 7 all-cause excess mortality proved to be a useful public health tool to monitor the current COVID-19 pandemic. Only counting laboratory-confirmed or probable COVID-19-associated deaths likely underestimates the true number of deaths associated with the pandemic. To better understand underlying medical conditions that contribute to deaths during the pandemic, more complete investigations, including the completion of CDC's standardized case-report form, 22 with medical record abstraction and including additional data sources, could be enhanced. Given the variability of reporting sources and laboratory COVID-19 test results for deaths, PRDoH MSS could consider expanding its passive surveillance efforts to an active or hybrid surveillance to increase death case ascertainment and completeness. Ascertainment of deaths during a pandemic could also take into consideration public health restrictions (eg, lockdown measures, travel restrictions, and total or partial interruption of public transportation) and how they might have affected a person's ability to attend regular medical appointments for chronic or new conditions. Public health officials could consider enhancing the public's awareness of the importance of attending regularly scheduled medical appointments to avoid exacerbation of chronic or acute illness. Enhanced mortality surveillance can provide vital information to help monitor the severity and progression of the COVID-19 pandemic by Figure. Number of laboratory-confirmed (n = 119) and probable (n = 106) COVID-19-associated deaths and total estimated excess deaths, Puerto Rico, March-July 2020. A death case is a person meeting confirmatory laboratory evidence (reverse transcriptasepolymerase chain reaction [RT-PCR] molecular test) during March-July 2020 reported by the Puerto Rico Department of Health. 4 A death case is a person meeting 1 of the following criteria: (1) meets clinical criteria and epidemiological evidence without a positive RT-PCR molecular test result, (2) meets a presumptive laboratory evidence (serology antibody test) and either clinical criteria or epidemiological evidence, or (3) meets vital records criteria (""a death certificate that lists COVID-19 disease or SARS-CoV-2 [severe acute respiratory syndrome coronavirus 2] as a cause of death or significant condition contributing to death"") without a positive RT-PCR molecular test 4 during March 17-July 31, 2020 (calendar weeks 12-31) reported by the Puerto Rico Department of Health. 4 Total excess all-cause deaths reported by the National Center for Health Statistics were estimated using the Farrington surveillance algorithm with the data from 2013 through July 31, 2020, as the difference between observed and expected deaths during March 2-August 2, 2020 (calendar weeks 10-31). Negative excess death estimates were set to zero and are not depicted. 10 Abbreviation: COVID-19, coronavirus disease 2019.estimating deaths directly and indirectly associated with COVID-19. Health department monitoring of all causes of excess death during the COVID-19 pandemic could help guide public health decision making, messaging, and interventions to help prevent additional deaths.",Puerto Rico,abstract,2021-02-17,02
dc386333a59643ef897bc72551b7d950a6124e0a,Disruption of nuclear architecture as a cause of COVID-19 induced anosmia,"Anosmia and hyposmia, complete and partial smell loss, respectively, constitute frequent and defining symptoms of SARS-CoV-2 infections [1] [2] [3] [4] [5] . Although olfactory deficits are common among patients with upper respiratory infections, these symptoms are typically accompanied by rhinorrhea and nasal congestion that result in reduced airflow through the nasal cavity and physical insulation of olfactory sensory neuron (OSN) cilia from volatile chemicals. In contrast, anosmia in COVID-19 appears to be independent from conductive interference, as patients consistently deny associated nasal obstructive symptoms. These observations have prompted the acceptance of anosmia as a key symptom in identifying potential cases of SARS-CoV-2 infection 4 , especially in otherwise asymptomatic patients. Yet, the emerging link between SARS-CoV-2 infection and anosmia raises important mechanistic questions related to the molecular features of olfactory sensory neurons (OSNs). Specifically, OSNs do not express Ace2 and Tmprss2 6-8 , receptors essential for host cell entry by the virus. Thus, the virus may infect OSNs though a different set of extracellular host receptors, or the reported anosmia represents a non-cell autonomous effect 5, 9 . Distinguishing between the two models has immense importance: the former implies that the olfactory epithelium (OE) could constitute a virus gateway to the CNS, through the OSN axons; while the latter could provide insight to the non-cell autonomous consequences of COVID-19 infection, currently considered the cause of severe complications and death.To obtain a molecular understanding of the mechanisms contributing to COVID-19 induced anosmia, we performed RNA-seq analysis on olfactory epithelia obtained from 19 SARS-CoV-2 positive and 3 control subjects at time of death, in order to establish the transcriptional baseline of the human OE. These specimens were obtained from critically ill patients at the onset of the COVID-19 pandemic, prior to the groundswell support for the inclusion of smell and taste loss as essential symptoms. Thus, information on the concomitant presence of anosmia exists only for one patient who self-reported profound smell and taste loss at the onset of symptoms. Based on current projections of the prevalence of smell loss among COVID-19 patients, 40-70% of these subjects may have experienced abrupt olfactory deficits 5, 10 . Without a priori knowledge of olfactory deficits linked to our specimens, we sought to identify the region of nasal mucosa most highly enriched for OSNs, focusing on the olfactory cleft, a region at the roof of the nasal cavity bridging the superior septum and middle turbinate bones (Extended Data Fig.1a) . OE from this region contains high concentration of OSNs as demonstrated by detection of the mature OSN-specific olfactory marker protein (OMP) and the OSN-enriched LDB1 and confirmed by scRNA-seq (Extended Data Fig.1b, c) . Thus, the analysis presented thereafter utilizes microdissections of this particular region of the nasal epithelium. The consistency of this approach in regards of OSN representation is demonstrated by plotting the levels of 30 OSN-specific markers, which were previously identified from mouse scRNA-seq experiments, across the 22 autopsies, revealing comparable representation between samples (Extended Data Fig.  1d ).Upon establishing conditions for extraction of human OE with consistent cellular representation, we asked if the viral RNA genome is detectable in infected samples by RNA-seq. Indeed, we detect the SARS-CoV-2 RNA genome in all the OEs from infected patients, but not in control OEs (Fig.1a) . There is strong variability in the abundance of the viral genome between samples, with autopsies obtained less than 10 days after symptom manifestation demonstrating elevated viral loads at higher frequency (Fig.1b) . To determine the identity of the infected cells, we performed fluorescent in situ RNA hybridization (RNA FISH) by RNA-scope using a probe for the negative strand of the Spike gene, which detects only the replicating virus. Labeling is sparse across the human OE and concentrated predominantly at the lamina propria and to a lesser degree at the most apical layer occupied by sustentacular cells (Fig.1c-e) . Some fluorescent signal is detected at the OSN layer, however, there is no significant difference in the OSN staining patterns between control and SARS-CoV-2 infected OEs (Fig.1c-e) , suggesting non-specific hybridization. Finally, it should be noted that the same RNA FISH probe used in infected lung sections revealed frequent cellular infection in this tissue (Extended Data Fig. 2 ). Thus, our data suggest that the virus predominantly replicates in non-neuronal cells of the nasal epithelium, consistent with the expression patterns of ACE2 and TMPRSS2 [6] [7] [8] [9] .Since COVID-19 does not appear to infect OSNs, at least at a frequency that would account for the prevalence of olfactory deficits, we asked if the virus exerts its effects by influencing expression programs of specific cell types of the OE. Using previously described cell type specific markers (Extended Data Fig. 3a) , we discovered that viral infection alters specifically the expression of mature OSNs (mOSNs) (Fig. 2a) , the cell type responsible for detecting odors and for transmitting this information to the brain. Reduction of mOSN markers, however, does not stem from an increase in apoptotic markers in the infected OEs (Fig.2b) . Moreover, not every mOSN marker is downregulated; genes with crucial role in OR signaling (Adcy3 11 , Cnga2 12 , Gng13 13 ), and trafficking of ORs and Adcy3 (Rtp1 14 , Gfy 15 , respectively), are significantly downregulated in infected OEs (Fig,  2c , Extended Data Fig. 3a) , whereas other mOSN-specific markers are not affected (Extended Data Fig. 3a ). These observations prompted us to also explore the effect of SARS-CoV-2 infection in expression of the actual chemoreceptors per se. Strikingly, cumulative analysis of the total OR mRNA, shows that most infected OEs express significantly less OR mRNA than the three control samples (Fig. 2c, d) . Infected OEs not only express less total OR mRNA, but also have lower complexity in the OR transcriptome, with 116 ORs being undetectable in most SARS-CoV-2 + samples (Fig. 2e) . The age of the human subject does not appear to be a critical determinant of the expression properties of ORs and their signaling components (Extended Data Fig. 3b) , refuting a bias in our analysis due to the increased death rates among older COVID-19 patients. Intriguingly, we do not detect a correlation between the total viral load at the human OE and the transcriptional effects on chemoreceptor pathways (Extended Data Fig. 3c ), which is consistent with a non-cell autonomous process. In this vein, we asked if infected OEs exhibit excessive and prolonged pro-inflammatory responses, which have been reported systemically for patients with severe symptoms and could explain the reported olfactory deficits [16] [17] [18] . Surprisingly, we do not evidence for extreme or maladaptive anti-viral responses originating at the OE (Extended Data Fig. 3d ), however we cannot exclude the systemic contribution of cytokines, or that such responses have been terminated in the OE by the time the patients succumbed. In support of the latter, the few samples collected within two days from the first symptoms tend to have elevated immune responses compared to samples with longer intervals (Extended Data Fig. 3e ).To obtain independent confirmation for the SARS-CoV-2 induced downregulation of ORs and OR signaling molecules, and to explore early stages of infection, we performed experiments in golden hamsters (M. auratus). This rodent species is considered a good animal model for SARS-CoV-2 infection due to high sequence homology between hamster and human ACE2, and similarity in pathogenesis and immunological responses [19] [20] [21] [22] . We performed a time course experiment that allowed us to monitor transcriptional changes in hamster OE, 1, 2, and 4 days after SARS-CoV-2 infection. As expected, we detect significantly higher viral loads in the hamster OEs compared to human epithelial specimens (Fig. 3a) due to the direct viral delivery into the hamster nasal cavities. Despite the high viral load, cellular infection in the hamster OE is infrequent, based on the immunoreactivity of the Nucleocapsid protein (NP) (Fig. 3b) . Moreover, there is low correlation between NP and OMP immunoreactivity (Fig. 3c , Extended Data Figure 4a , b), consistent with our observations in human OE. Importantly, we do not detect NP in OSN axon bundles (Extended Data Fig. 4a , b) refuting the possibility that SARS-CoV-2 invades the CNS through the olfactory system. Consistent with the preferential non-neuronal tropism of SARS-CoV-2, we detect significant downregulation of sustentacular-specific markers from the earliest stages of infection (Fig.3d, Extended Data Fig. 4c ). At later stages we also detect downregulation of markers specific for OSNs and their immediate precursors (Fig.3d, Extended Data Fig. 4c ). Further, as previously reported 23 , we observe areas of restricted tissue damage (data not shown), coinciding with a weak, non-significant increase of apoptotic markers at 4dpi (Extended Data Fig. 4d ). At this timepoint markers of the quiescent stem cells of the OE (Horizontal Basal Cells, HBCs) become upregulated (Extended Data Fig. 4c ), suggesting that local tissue damage induced by high viral titers activates replenishment of Sus and OSN by HBCs. Reflecting the elevated viral titers at this acute infection timepoint, SARS-CoV-2 infection elicits strong inflammatory responses in hamster OE, beginning day 1 post infection (Fig. 3e) . By day 4, there is a trend of dampening response, consistent with trends observed in human OE specimens. Importantly, there is strong and significant transcriptional downregulation of ORs and their signaling components, detected even by day 1 post infection ( Fig.  3f, Extended Data Fig.4c ). The kinetics and magnitude of transcriptional downregulation is not homogeneous across ORs; class I ORs, ~100 OR genes that are differentially regulated from the >1000 class II ORs, demonstrate slower and weaker downregulation than class II ORs (Fig. 3g) . Notably, the same trend is observed in human OEs (Extended Data Fig.4e ), suggesting that conserved differences in the regulation of these two OR subfamilies are responsible for the differential sensitivity to SARS-CoV-2 infection.Because only class II OR gene expression depends on interchromosomal genomic compartments 24-26 , we asked if COVID-19 infection of the OE impacts the OSN nuclear architecture. To answer this, we established a protocol for the isolation of human and hamster OSN nuclei from crosslinked OE specimens by FACS (Extended Data Fig. 5a, b) . In situ HiC on human OSN nuclei from two control and 4 SARS-CoV-2 infected OE samples revealed reduced genomic compartmentalization upon viral infection (Fig. 4a) . Similarly, in hamsters, 3 days post SARS-CoV-2 inoculation (3dpi), there is a strong reduction in the number of predicted genomic compartments in OSN nuclei from infected OE, compared to controls (Fig. 4b) . To increase the genomic resolution of our analysis towards identification of changes on specific compartments, we pooled the 2 control and 2 infected human OE specimens that are most distinct from each other. At a genome wide level, reduced genomic compartmentalization may be explained by an overall decrease on the frequency of specific genomic interactions and an increase of background interactions across all chromosomes, a result that is recapitulated in both humans and hamsters (Extended Data Fig. 5c, d) . Crucially, we observe significant reduction in long-range cis and trans genomic interactions between OR gene clusters in both species upon SARS-CoV-2 infection ( Fig. 4c-f ). Quantification of genomewide trans genomic interactions composing OR-containing compartments, reveals strong and significant reduction in infected OEs from both species (Fig. 4g, h) . Intriguingly, Adcy3, Gng13, and Gfy, together with Omp, Lhx2 and Atf5, which are also downregulated in infected human OEs form a separate interchromosomal compartment that also dissipates upon infection (Extended Data Fig. 6 ). Thus, the dramatic reorganization of nuclear architecture induced by SARS-CoV-2 infection does not only affect directly ORs, but also other genes that are essential for odor detection. Importantly, because we FAC-sorted nuclei with high levels of LHX2 and ATF5 proteins, disruption of genomic compartmentalization is likely the cause and not the consequence of Lhx2 and Atf5 downregulation, transcription factors that are critical for the expression of ORs and of their signaling molecules.Our experiments reveal a molecular explanation for SARS-CoV-2 induced anosmia and uncover a novel mechanism by which this virus can alter the identity and function of host cells that lack entry receptors. Consistent with the previously reported absence of ACE2 and TMPRSS2 from OSNs, our data suggest that OSN infection by SARS-CoV-2 is too infrequent to account for the reported smell loss and the widespread downregulation of ORs and their signaling molecules. Although we cannot exclude the possibility that SARS-CoV-2 infects OSNs via interactions with Neuropilin-1 27 , our data do not support that viral replication in OSNs and transmission via their axons to the olfactory bulb 27,28 , as a cause of anosmia. The simplest explanation for the widespread olfactory deficits is a non-cell autonomous process, which may be mediated by the early onset induction of cytokines by the infected cells 29 . A direct consequence of this process is the dramatic reorganization of OSN nuclear architecture and dissipation of genomic compartments (Fig. 5 ). Nuclear reorganization deprives OSNs from the ability to detect odorants and to transmit this information to the brain, as both ORs and OR signaling molecules depend on these interchromosomal contacts for their expression. Given that most animals use olfaction for social communication, a virus induced loss of smell may limit social interactions of the infected individuals with their conspecifics 30 , limiting transmission within their social group. On the other hand, this process may reflect a viral effort to evade innate immunological responses since mammalian cells deploy interchromosomal contacts to activate antiviral programs 31 . Since adult CNS neurons also assemble long-range cis and trans genomic compartments 32, 33 , this adaptive process may eventually induce long-lasting changes in brain nuclear architecture explaining cognitive and neurological deficiencies linked to SARS-CoV-2 infection 34 . Finally, it is worth noting that the realization that different OR sub-families exhibit differential sensitivity to SARS-CoV-2 infection, could eventually be deployed towards the development of rapid, COVID-19 specific smell-based screening tools.We thank members of the Lomvardas lab for critical comments and suggestions, Konstantin Popadin and Muhammad Saad Shamim for helpful analysis notes, David Weisz for assistance with software and Gary Struhl for the help with imaging, Charles Zuker, Tom Maniatis, Abbas Rizvi, and Max Gottesman for helpful comments and suggestions. The study was approved by the ethics and Institutional Review Board of Columbia University Medical Center (IRB AAAT0689, AAAS7370). LVG Golden Syrian hamsters (Mesocricetus auratus) were treated in compliance with the rules and regulations of IACUC under protocol number PROTO202000113-20-0743. This work was funded by 3R01DC018744-01S1 (NIDCD) (SL, JO) U01DA052783 (NIH Office of the Director, 4D Nucleome Consortium) (SL), HHMI Faculty Scholar Award (SL), and the Zegar Family Foundation (SL), R01AG067025 (P.R), R01AG065582 (P.R). Protocols and Sequencing data have been uploaded to the 4D Nucleome Data Portal (https://data.4dnucleome.org ) and will be available to the public as soon as their curation is completed. , mOSNs (mature OSN) and SUS (sustentacular cells). A paired, two-tailed Wilcoxon rank sum test was used to determine whether the mean expression was different between SARS-CoV-2 + and controls. No significant changes were detected, except for mOSNs. b, Violin plot of apoptotic regulation response across all samples show no changes in distribution. p = 0.6891 was computed using Wilcoxon rank sum. The list of genes used corresponds to the GO category GO:0097194. c, Boxplot representation of the normalized counts (MRN) grouped in SARS-CoV-2 + positive and control samples for Adcy3, Gfy, Gng13, Rtp1, Cnga2, and aggregate OR mRNAs (highlighted in grey); padj values were generated with DESeq2 using the Benjamini-Hochberg method. Aggregate OR expression p value was calculated using two-tailed Wald test. Arrow indicates anosmic sample d, Distribution of aggregate OR mRNA across all human OE samples. The biopsy sample with known anosmia is highlighted with stripes. e, heatmap depicting expression of each OR gene in 3 control and 19 SARS-CoV-2 infected OE specimens. Representative HiC maps of contacts between OR clusters in cis for human (c) and hamster (e) from pooled data. In each case control is the lower triangle below diagonal and SARS-CoV-2 + the upper triangle. Pixel intensity represents normalized number of contacts between pair of loci. Maximum intensity indicated at the top of each scale bar d,f Interchromosomal HiC contacts between OR clusters for human and hamster respectively. Genomic position of OR clusters indicated as green bars; arrows indicate the same OR compartments for both conditions. Pixel intensity represents normalized number of contacts between pair of loci. Maximum intensity indicated at the top of each scale bar. g,h Violin plot depicting the mean number of normalized trans HiC contacts between ORs from chromosome 11 to OR clusters genomewide at 50-kb resolution. Every dot indicates aggregated contacts between ORs on chromosome 11 to ORs from other chromosome, p value was computed using Wilcoxon rank test.A model for the non-cell autonomous induction of anosmia by SARS-CoV2 infection. In control samples (left) silent ORs form a genomic compartment (blue) that promotes assembly of a multi-enhancer hub (red), which activates transcription of a single OR allele. Moreover, a second compartment consisted of numerous genes necessary for transcription, trafficking, and signaling of OR proteins is identified in control OSNs. Upon SARS-CoV2 infection (right), sustentacular cells or cells from the lamina propria elicit signals that induce disruption of genomic compartments and intermingling of genes that are supposed to be spatially segregated. Alternative, this disruption may be induced by elevated systemic cytokines circulating in COVID-19 patients. In either case, disruption of genomic compartmentalization results in downregulation of ORs and of their proteins involved in trafficking and OR signaling, resulting in anosmia. OSNs contain the highest number of significantly downregulated genes, followed by immediate neuronal precursors (INPs). b, Correlation of viral counts to normalized OR aggregate counts (green) and normalized Adcy3 counts (purple). The correlation coefficient and the significance level (p-value) were calculated with Pearson correlation test (p-value = 0.2699) and confirmed with Kendall's rank correlation test (p-value = 0.2631) for Adcy3. Similarly, OR aggregate expression shows no significant correlation (p = 0.5319) which was confirmed with Kendall's rank correlation test (p= 0.265). c, Regression analysis of Adcy3 and OR aggregate expression with age. No significant correlation was found in our cohort of samples which include individuals from 58 to 92 years of age. The statistical test used are the sample as reported in 3b. d, Violin plot of the inflammatory response across all samples show no changes in distribution. P = 0.1468 was computed using Wilcoxon rank sum. The list of genes used corresponds to the GO category GO:0097194. e, log2FC of Ifn-g, TNF-a, Il-2, Il-6 on human OE specimens with different intervals from symptom manifestation to tissue harvesting (from 0 to 48 days). Extended data Figure 5 a, b Representative FACS data for control and SARS-CoV-2+ human and hamster specimens. Fixed DAPI positive, Lhx2/Atf5 double positive for human and Lhx2/OMP double positive for hamster, respectively, nuclei were collected for in situ HiC. c,d HiC map representing whole genome view on chromatin contacts for control (triangle below diagonal) and SARS-CoV-2 infected (triangle above diagonal) human and hamster respectively. e,f Chromatin compartments in human OSNs harboring Adcy3, Gng13 and Gfy in control (left e, top f) and SARS-CoV-2 samples (right e, bottom f). Arrows indicate compartments with genes involved (genomic annotation in green). g, annotated contact domains containing OR clusters (green bars); control domains propagate as blue 'triangles' below diagonal and for SARS-CoV-2 domains are indicated in 'triangle' above diagonal. h, the same for hamster. . Specimens noted to have metastatic cancer and those exceeding a postmortem time of 24 hours were excluded from subsequent analysis. Brain tissue and nasal epithelium, including the olfactory region, were retrieved under a collaborative effort by the Department of Neuropathology and the Department of Otolaryngology. Tissues were obtained and preserved for histological, molecular, and microscopic evaluation using separate surgical instruments to prevent cross-contamination. Control specimens were collected in similar fashion from deceased individuals who had no clinical history of COVID-19 and had negative SARS-CoV-2 PCR at the time of their presentation and again prior to post-mortem dissection. Nasal tissues, including olfactory and respiratory epithelium were harvested from the skull base using an en-bloc resection of the anterior skull base including the cribriform plate. Olfactory epithelium was isolated from the olfactory cleft, spanning turbinate and adjacent septal mucosa prior to being preserved in 1% paraformaldehyde (for HiC), 4% paraformaldehyde (for RNA ISH/IF), or Trizol (for RNA-seq).Hamsters: LVG Golden Syrian hamsters (Mesocricetus auratus) were treated and euthanized in compliance with the rules and regulations of IACUC under protocol number PROTO202000113-20-0743. Only male hamsters were used for experiments. All experiments were performed on dissected olfactory epithelium tissue or on dissociated cells prepared from whole olfactory epithelium tissue. Dissociated cells were prepared using papain (Worthington Biochemical) and FAC-sorted as previously described. All hamster infections were performed in a BSL-3 animal facility at the Center for Comparative Medicine and Surgery at the Icahn School of Medicine at Mount Sinai (New York, NY) using 4-6week-old male golden hamsters purchased from Charles River Laboratories. Hamsters were intraperitonially administered anesthesia of ketamine/xylazine (3:1), [100mg/kg] before inoculation. Inoculations were performed by intranasally administering 100 plaque-forming units (pfu) in a total volume of 100ul per hamster, diluted in PBS. Golden hamsters were provided thermal support after infection until recovery from anesthesia. Before sacrifice, the animals were anesthetized and then perfused with 60mL of PBS through the heart. RNA-seq. RNA was extracted using Direct-zol RNA kits from Zymo Research. 50ng-1ug of total RNA was used to prepare DNA libraries with Truseq RNA Library Prep Kit v2 followed by 75 HO paired-end and multiplexed sequencing. Reads were aligned to human genome (hg38), Mesocricetus auratus (MesAur1.0) and SARS-CoV-2 (wuhCor1) using Subread and the raw read counts were assembled using featureCounts pipeline. Deseq2 was used to detect differences between conditions from the human samples and from the hamster biological replicates. For control samples we performed PCA analysis to remove outliers in an unsupervised fashion; two samples were not clustering with the rest and were removed, however Padj values for differences in OR, Adcy3, Gng13, Gfy and Cnga2 remain significant even if we keep these samples in our analysis (data not shown).Single cell RNA-seq. Cells were dissociated according to the Worthington Papain Dissociation System by incubating fresh olfactory tissue with papain and Calcein VIolet for 40 min at 37 °C. Following dissociation, the live Calcein Violet-positive cells were sorted and assayed for scRNA-seq. Library preparation was performed accordingly to Chromium Single Cell 3ʹ v.3 Protocol and sequenced on NextSeq. Cell Ranger pipelines were used to generate fastq files which subsequently were aligned against hg38. All the cells with less than 1000 genes and less than 2000 UMIs per cell were discarded, resulting in 6828 cells used for analysis. Clustering was performed using Seurat with filtering default of a gene being expressed in at least 3 cells to include in data. To identify each of cell populations, previously annotated in lab olfactory epithelium markers were used to highlight olfactory lineages on tSNE plot.Dissected tissue was fixed in freshly prepared 4% PFA for 24 hrs at 4C and soaked sequentially at 10%, 20% and 30% sucrose 1X PBS for cryopreservation. The tissue was embedded in OCT and 10 um thick sections were mounted on SUPERFROS Plus Gold slides. To detect the S gene transcripts of SarsCov2, RNAscope® Probe -V-nCoV2019-S-sense, cat# 845708, was incubated for 2 hr at 40C, in pre-treated sections as indicated by the RNAscope Multiplex Fluorescenct v2 Assay kit. Zeiss Zen2012 SP1 (v8.1.9.484) was used for capturing confocal images. Autofluorescence of the human OE sections was computationally removed using the ImageJ add-on function described in Baharlou et al 35 .Immunofluorescence. Dissected tissue was fixed in freshly prepared 4% PFA for 24 hrs at 4C. OE was embedded in OCT and coronal cryosections were collected at a thickness of 12 μm. Antigen retrieval was performed with 0.01M citric acid buffer (pH 6.0) for 10 minutes at 99C. Sections were rinsed in PBS and after permeabilization with 1x PBS 0.1% Triton X 100, slides were incubated in blocking solution (4% donkey serum +5% nonfat dry milk + 4% BSA + 0.1% Triton X-100) for 30 minutes at RT. Tissue sections were stained with primary antibodies against OMP 36 (1:100 dilution) and NP (1:200 dilution, MyBiosource Cat. no.# MBS8574840). DNA was labelled with DAPI (2.5 μg/ml, Thermo Fisher Scientific Cat. no.# D3571). Primary antibodies were labelled with the following secondary antibodies: for OMP, anti-chicken IgG conjugated to Alexa-488 (2 μg/ml, Thermo Fisher Scientific Cat. no.# A-11055, RRID:AB_2534102), for NP, anti-rabbit IgG conjugated to Alexa-555 (2 μg/ml, Thermo Fisher Scientific Cat. no.# A-31572, RRID:AB_162543). Confocal images were collected with a Zeiss LSM 700 and image processing was carried out with Fiji (NIH).Fluorescence-activated nuclei sorting: Frozen 1% PFA-fixed tissue was mechanically crushed using Covaris Impactor and then nuclei were extracted with OptiPrep Density Gradient Medium according to the Sigma Millipore protocol. Following extraction and filtering two times through a 35-µm cell strainer, nuclei were stained with Lhx2/Atf5 antibodies for human samples and Lhx2/OMP antibodies for hamster respectively. Next DAPI/Lhx2/Atf5 and DAPI/Lhx2/OMP triple positive nuclei were sorted on a BD Aria II or BD Influx cell sorter for HiC experiments.In situ Hi-C: Depending on the sample, between 30 thousand and 100 thousand nuclei were used for in situ Hi-C. Sorted nuclei were lysed and processed through an in situ Hi-C protocol as previously described with a few modifications. In brief, cells were lysed with 10 mM Tris pH 8 0.2% Igepal, 10 mM NaCl. Pelleted intact nuclei were then resuspended in 0.5% SDS and incubated for 20 min at 62 °C for nuclear permeabilization. After being quenched with 1.1% Triton-X for 10 min at 37 °C, nuclei were digested with 25 U/µl MseI in 1× CutSmart buffer for 1.5 hours at 37 °C. Following digestion, the restriction enzyme was inactivated at 62 °C for 20 min. For the 45-min fill-in at 37 °C, biotinylated dUTP was used instead of dATP to increase ligation efficiency. Ligation was performed at 25 °C for 30 min with rotation after which nuclei were centrifuges. To degrade proteins and revers crosslinks pellets were incubated overnight at 75 °C with proteinase K. Each sample was transferred to Pre-Slit Snap-Cap glass mictoTUBE and sonicated on a Covaris S220 for 90 sec ('Harsh shear' program).Hi-C library preparation and sequencing: Sonicated DNA was purified with 2× Ampure beads following the standard protocol and eluted in 300 µl water. Biotinylated fragments were enriched as previously described using Dynabeads MyOne Strepavidin T1 beads. The biotinylated DNA fragments were prepared for next-generation sequencing directly on the beads by using the Nugen Ovation Ultralow kit protocol as described [Kevin/Adan paper]. DNA was amplified by 7 cycles of PCR. Beads were reclaimed and amplified unbiotinylated DNA fragments were purified with 1× Ampure beads. The quality and concentration of libraries were assessed using Agilent Bioanalyzer and Qubit Quantification Kit. Hi-C libraries were sequenced paired-end on NextSeq 500 (2 × 75 bp), or NovaSeq 6000 (2 × 50 bp).Hi-C data processing and analysis: Raw fastq files were processed using the Juicer single CPU BETA version on AWS. Human data were aligned against hg19 and hamster reads were aligned to MesAur1.0_HiC.fasta.gz using BWA 0.7.17 mem algorithm. Hamster genome assembly was obtained from the DNA Zoo Consortium 37 . After reads are aligned, merged, and sorted, chimaeras are de-duplicated and finally Hi-C contact matrices are generated by binning at various resolutions and matrix balancing. In this paper we present data with stringent cutoff of MAPQ >30. Hi-C matrices used in this paper were matrix-balanced using Juicer's built-in Knight-Ruiz (KR) algorithm. Matrices were visualized using Juicebox 38 . Cumulative interchromosomal contacts at the 50 kb resolution were constructed by calling Juicer Tools dump to extract genome wide normalized data from a .hic file and subsequently analyzed as previously described 24 . A hidden Markov model (HMM) was used to assess the presence of genomic compartments as previously described 24 . Using 2-21 components, HMMs are constructed for odd versus even chromosomes and a score is calculated using hmmlearn's built-in score to ascertain the likelihood of the given number of compartments. The same was done for even versus odd after transposing the matrix. ",USA,first author,2021-02-09,02
b2ddb3a0a3cf3388b97b889fad2470196e805116,Relation of Cardiovascular Risk Factors to Mortality and Cardiovascular Events in Hospitalized Patients with Coronavirus Disease 2019 (From the Yale COVID-19 Cardiovascular Registry),"Coronavirus disease 2019 caused by severe acute respiratory syndrome coronavirus 2 (SARS- constitutes an ongoing global pandemic with considerable public health implications. As of January 7, 2021, >87 million cases had been reported in 191 countries, and 1.9 million deaths had been attributed to this condition (1) .Similar to other common viral illnesses, individuals with established cardiovascular disease or a high burden of cardiovascular risk factors appear to be particularly vulnerable during infection (2) (3) (4) (5) (6) (7) (8) . Concerns have also been raised that use of certain medications that affect the cardiovascular system, notably inhibitors of the renin-angiotensinaldosterone system (RAAS) and non-steroidal anti-inflammatory drugs (NSAIDs), may enhance infectivity and the likelihood of experiencing a severe disease course (9, 10) . Finally, the infection itself may increase the risk of cardiovascular complications, such as arrhythmia, heart failure, thromboembolic events, and myocarditis (11) (12) (13) .Therefore, we designed this study to determine the prevalence of cardiovascular risk factors, established cardiovascular disease, and associated medications, and to identify risk factors for incident cardiovascular events and mortality, among hospitalized patients with COVID-19.The study was conducted at Yale New Haven Hospital (YNHH), a non-profit, 1,541-bed tertiary care medical center operated by the Yale New Haven Health System (YNHHS), and located in New Haven, Connecticut, USA. The Yale COVID-19 Cardiovascular Registry is an ongoing retrospective and prospective registry that is collecting data from all adult patients (age 18 years) admitted or transferred to YNHH with a positive test result for SARS-CoV-2. The diagnosis of SARS-CoV-2 infection was made using a reverse-transcriptase polymerase chain reaction assay or highthroughput sequencing, with nasopharyngeal or oropharyngeal swab specimens obtained at any point before or during hospitalization. However, patients could also be included to the registry if discharged with a diagnosis of COVID-19, using the International Classification of Diseases, Tenth Revision (ICD-10) emergency code, U07.1. For the present analysis, we included all participants admitted between March 1 and May 31, 2020 with a final disposition, i.e., either in-hospital death or survival to hospital discharge.On March 19, the YNHHS COVID-19 Treatment team, led by a multidisciplinary team of physicians, released the first version of its treatment algorithm for patients with non-severe and severe disease (Appendix 1). Per this algorithm, proposed indications for active treatment included 1) respiratory failure with mechanical ventilation or 4 extracorporeal membrane oxygenation, 2) an oxygen saturation 93% on room air or on chronic oxygen supplementation, or 3) fever and/or symptoms of respiratory disease plus abnormal chest imaging plus at least 1 risk factors for adverse outcomes (age >60 years, body mass index 40 kg/m 2 , chronic heart disease, chronic lung disease, or immunosuppressed state). Patients receiving >3 l/min of oxygen supplementation required evaluation by the intensive care unit (ICU). Interruption of ongoing treatment with RAAS-inhibitors or NSAIDs was not advised unless indicated for conventional reasons. Recommended laboratory studies included those related to hematology, inflammation, and circulatory function. The treatment algorithm has been updated numerous times since its release, and the latest version was published on November 25, 2020.Information on hospitalized patients with a positive SARS-CoV-2 test result was acquired through the local Observational Medical Outcomes Partnership repository and the Joint Data Analytics Team at YNHHS, resources that provide customized reporting and data analysis from the electronic health record system, Epic. Study data were subsequently obtained through manual review of each patient's electronic health record by physicians. We collected data related to demographics, including prevalent cardiovascular risk factors, conditions, and medications, presenting symptoms, vital signs, laboratory test results, imaging findings, electrocardiograms, and in-hospital events, including cardiovascular and COVID-19 specific medication use, supportive measures, ICU admission, cardiovascular events, other pertinent clinical events, and mortality. The institutional review board at Yale University approved the study under an expedited review. The design of the registry is illustrated in Figure 1 .Cardiac troponin T was measured using a 4 th generation electrochemiluminescence immunoassay (Elecsys, Roche Diagnostics, Basel, Switzerland). The lower limit of detection (99 th percentile upper reference limit) was 0.010 g/l, and the lowest concentration with a coefficient of variation 10 % was 0. The primary endpoint was in-hospital death from any cause. The secondary endpoint was in-hospital major adverse cardiovascular events (MACE), defined as a composite of type 1 or 2 myocardial infarction, stroke, new acute decompensated heart failure or cardiogenic shock, venous thromboembolism, new-onset ventricular arrhythmia, newonset atrial fibrillation or flutter, pericardial effusion or cardiac tamponade, or aborted cardiac arrest. Myocardial infarction was defined according to the Fourth Universal Definition (14) . Cardiac events were adjudicated by experienced physicians (Appendix 2). Other endpoints that were included for descriptive purposes were ICU admission, mechanical ventilation, and new renal replacement therapy.Continuous variables are presented as medians and interquartile ranges (IQR). Categorical variables are presented as frequencies and corresponding percentages. Unadjusted differences in clinical and laboratory characteristics between survivors and non-survivors were examined using Mann-Whitney U test, Pearson's chi-squared test, or Fisher's exact test, as appropriate. We subsequently performed multivariable binary logistic regression with backward elimination (2sided p-entry on univariable analysis: 0.10; 2-sided p-retention in the multivariable model: 0.10) to identify variables associated with the primary and secondary endpoints, respectively. Age and sex were forced into the regression models where necessary. For each endpoint, 3 subsets of models were rendered, using 1) demographic characteristics alone The study population comprised 586 COVID-19 positive patients who were admitted between March 1 and May 31, 2020 and had completed their hospital course. Median age was 67 (IQR: 55-80) years, 47.4% were female, and 49.0%, 30 .7%, and 16.0% identified as Non-Hispanic White, Non-Hispanic Black, and Hispanic, respectively. A history of cardiovascular disease was reported in 36.7%, the most common of which were coronary artery disease (18.1%), heart failure (17.1%), and atrial arrhythmia (12.2%). In terms of risk factors, 60.2% had hypertension, 39.8% had diabetes mellitus, 38.6% had hyperlipidemia. Angiotensin converting enzyme (ACE) inhibitors or angiotensin II receptor blockers were used by 32.9%, beta blockers by 30.0%, diuretics (including mineralocorticoid receptor antagonists) by 27.5%, aspirin by 29.5%, and NSAIDs by 11.3%. Demographic characteristics, comorbidities, and medications, stratified according to vital status at discharge, are provided in Table 1. 6 Median time from symptom onset to admission was 4 (IQR: 1-7) days, and median length of hospital stay was 13 (IQR: 7-21) days. The most common presenting symptom was cough (59.6%), followed by fever or chills (58.7%), dyspnea (54.5%), and fatigue or malaise (34.1%). Presenting symptoms and vital signs at admission are shown in Table 2 .A total of 82 (14.0%) individuals died in the hospital. Patients who died were more likely to be older (p<0.001), males (p=0.03), and have a history of cardiovascular disease (p<0.001), including all its individual components except venous thromboembolism, and of chronic kidney disease (p<0.001). Furthermore, beta blockers (p=0.002), calcium channel blockers (p=0.008), diuretics (p<0.001), P2Y 12 inhibitors (p=0.002), and statins (p=0.03) were more commonly used by non-survivors than by survivors ( Table 1) .Non-survivors more often presented with altered mental status (p=0.04), hemoptysis (p=0.04), and shortness of breath (p<0.001), and had higher respiratory rates (p=0.001), lower diastolic blood pressures (p=0.04), and more frequently required oxygen therapy (p<0.001) ( Table 2) .White blood cell count (p=0.005), absolute neutrophil count (p<0.001), creatinine (p<0.001), aspartate aminotransferase (p<0.001), total bilirubin (p=0.002), international normalized ratio (INR) (p<0.001), C-reactive protein (p<0.001), procalcitonin (p<0.001), ferritin (p=0.02), D-dimer (p<0.001), troponin T (p<0.001), and NT-proBNP (p<0.001) were generally higher, whereas hemoglobin (p=0.03), absolute lymphocyte count (p<0.001), platelet count (p=0.002), and albumin (p<0.001) were lower, in patients who did not survive to hospital discharge.One-hundred and thirty-five (23.0%) patients experienced a MACE during their course of admission, most commonly new atrial fibrillation or flutter (7.9%), type 2 myocardial infarction (7.5%), venous thromboembolism (5.8%), or new acute decompensated heart failure (5.3%). Only 3 patients experienced a type 1 myocardial infarction, all of which were managed with percutaneous coronary intervention. Most patients with atrial fibrillation were managed with a rate control strategy. The incidence of composite and individual cardiovascular events stratified for survival status is presented in Table 3 .With respect to non-cardiovascular events, 196 (33.5%) were admitted to the ICU, 111 (19.0%) required mechanical ventilation, and 24/557 (4.3%) underwent new renal replacement therapy. Importantly, 31/390 (8.0%) of patients who were not admitted to the ICU died, while 51/196 (26.0%) of patients admitted to the ICU died. and clinical characteristics that were significantly associated with a higher risk of death in at least 1 model included older age, male sex, history of heart failure, history of ventricular arrhythmias, use of P2Y 12 inhibitors, use of oxygen therapy at admission, and higher respiratory rates. Unfavorable laboratory findings included higher C-reactive protein, lower albumin, and higher troponin T.Factors associated with MACE in at least 1 model were older age, male sex, history of coronary artery disease, use of oxygen therapy at admission, higher respiratory rates, altered mental status, lower absolute lymphocyte count, higher total bilirubin, lower albumin, and higher troponin T (Figure 4 ).Our observational study of patients hospitalized with COVID-19 at a tertiary care medical center in the United States showed high prevalences of cardiovascular risk factors and disease. Pre-existing cardiovascular disease, older age, male sex, early need for oxygen supplementation, higher respiratory rates, altered mental status, and laboratory abnormalities, including higher troponin T concentrations were among the characteristics related to poor outcomes.There were no associations of RAAS-inhibitors or NSAIDs with either mortality or cardiovascular events. Our study is particularly notable for its data acquisition through manual chart review and event adjudication by experienced physicians, approaches that provide more reliable information than use of administrative registries alone (15) .Respiratory infections are known to increase the risk of major cardiovascular events and mortality (2, 3, 16) . This is particularly well-established for seasonal influenza where vaccination appears to reduce cardiovascular morbidity and mortality by 15-20% among high-risk individuals (17, 18) . Both age and male sex predict adverse outcomes among patients with influenza, associations that may extend to those with COVID-19 (2, (4) (5) (6) 19, 20) . While the exact mechanism for male predominance in the context of SARS-CoV infections remains obscure, a possible explanation may be offered by sex-related differences in both innate and adaptive immunity related to estrogen receptor signaling (21) . Our findings also support earlier reports that suggested pre-existing cardiovascular disease as an unfavorable prognostic factor (4) (5) (6) (7) (8) 20) . Indeed, the increased physiological demands imposed by severe infection affect persons with cardiovascular disease more seriously than those without (22) . Poor cardiovascular reserve also negatively impacts upon the immune system, potentially leading to infection in itself (23) .Importantly, we found no detrimental effects of RAAS-inhibitors or NSAIDs. Both received considerable attention early during the pandemic because of their potential ability to upregulate expression of ACE-2, 8 the molecule used by SARS-CoV2 for endocytic internalization (9,10). Our results are in agreement with other observational studies of these drug classes (7, 10, 24) and support the position statement of the European Society of Cardiology that treatment with RAAS-inhibitors should not be interrupted in patients with COVID-19 (25) . Considering another widely used medication, aspirin has been proposed to positively affect the disease course through inhibition of viral replication and reduced inflammation (26) . We did not observe prognostic benefits of aspirin, although it may primarily have been used by individuals with established cardiovascular disease. Similarly, the associations between P2Y 12 inhibitors (and calcium channel blockers) and mortality likely represented severity of comorbid cardiovascular conditions rather than independent mechanistic effects.Prior COVID-19 cohorts also reported cough, fever, dyspnea, and fatigue as the most common disease manifestations (4) (5) (6) (7) 19) . Altered mental status, hemoptysis and signs of respiratory failure were more frequent among patients who did not survive. On the other hand, detection of cardiovascular complications in patients with COVID-19 may be particularly challenging, exemplified by the high incidence of non-obstructive coronary disease despite STsegment elevation (27) . In the same way, although troponin elevations are common and have been associated with both mortality and cardiovascular events in this context, interpretation is difficult because they may not be reflective of a primary coronary event (12, 13, (28) (29) (30) . Indeed, while our findings supported prior reports showing that several biomarkers of organ function, inflammation, and circulatory stress were associated with adverse outcomes, none of these are specific for COVID-19 (4, 5, 8, 19, 30) .In addition to our high-quality study data, systematic use of an institutional treatment algorithm also ensured collection of multiple variables, including laboratory tests, allowing for thorough adjustments. A notable limitation included the observational design that prevented us from making finite inferences regarding causality. Indeed, it remains unclear whether the infection is involved in the pathogenesis of, or mainly acts as a trigger for, cardiovascular events in individuals at elevated risk (11) . The limited number of events and associated power for detailed exploration of individual cardiovascular outcomes are additional shortcomings, and the wide MACE-definition may have also made it difficult to infer which endpoints drove the various associations. Given multiplicity, the p-values, particularly those assessing univariable associations, should be interpreted cautiously. Because we only included hospitalized patients, they were older and had a higher comorbidity burden and mortality than unselected patients with COVID-19 (4). In addition, our case mix of patients admitted directly to the hospital or transferred from other institutions makes generalizability uncertain as the latter group would be expected to have a more severe form of the disease. Ongoing randomized studies of RAAS-inhibitors and aspirin are thus eagerly anticipated, as is examination of 9 cardiovascular outcomes after vaccine introduction. In the meantime, vigilance is required regarding optimization of treatment of prevalent cardiovascular risk factors and known conditions, potentially leading to a reduced risk of complications in the setting of COVID-19.In conclusion, consecutive patients hospitalized with COVID-19 had a high prevalence of cardiovascular risk factors and disease. Pre-existing cardiovascular disease, older age, male sex, clinical manifestations of respiratory failure, and laboratory findings indicative of circulatory stress were associated with cardiovascular events and mortality, while use of RAAS-inhibitors and NSAIDs were not.The other authors do not report any relevant disclosures. Abbreviations: ACE = angiotensin converting enzyme; ARB = angiotensin II receptor blocker; HIV = human immunodeficiency virus; NSAID = non-steroidal anti-inflammatory drug Table 2 . Presenting symptoms and vital signs at admission in patients with COVID-19 who survived and did not survive to hospital discharge.Abbreviation: bpm = breaths per minute (respiratory rate) and beats per minute (heart rate) Table 3 . Cardiovascular events in patients with COVID-19 who survived and did not survive to hospital discharge.Abbreviations: MACE = major adverse cardiovascular events Abbreviation: bpm = breaths per minute (respiratory rate) and beats per minute (heart rate) ",USA,first author,2021-02-01,02
5fbb6c3758ef01bc6ed465ccc049c626bd091d7b,COVID-19 restrictions: experiences of immigrant parents in Toronto,"to work from home or the option to travel to work by car or via public transportation at less-crowded times. Racialized immigrants, in particular, are over-represented among the groups of essential workers in jobs that require direct contact with people or involve precarious conditions [7] . These challenges add stress to immigrant parents and their families. Additionally, regulations related to COVID-19 have meant that vital sources of informal and formal support that many immigrant families rely on, such as translation support and services, have been restricted or taken away entirely, thus increasing their risk of stress and burnout [8] .This paper focuses on the COVID-19 related changes and challenges experienced by immigrant parents living in apartment buildings in the Greater Toronto Area of Ontario Canada. It is based on a larger study that aimed to capture, from the points of view of immigrants living in apartment buildings, the physical-distancing challenges they faced and the successful strategies they used to maintain social connectedness during the COVID-19 pandemic.Our study was informed by an ecosystemic framework [9] , which can help clarify how individuals are influenced by micro-(family), meso-(community), and macro-(society) level factors. Understanding the individual experiences and responses of immigrant parents to the pandemic must consider the multilayered systems that create inequity and inequality in basic need areas such as housing, employment, healthcare, and transportation that affect them [10] . For example, during the first six months (summer and fall of 2020) of the COVID-19 pandemic in Canada, meso-and macrolevel factors and policymakers were primarily responsible for shaping decision-making surrounding COVID-19 restrictions such as school and workplace closures, which were then expected to be implemented by individuals and families. The ecosystemic framework helped reveal how some individuals and families have been disproportionately affected [10] by the COVID-19 restrictions related challenges of parenting during the pandemic.This paper is based on a larger study that sought to capture how apartment-dwelling immigrants are affected by the pandemic, and the meso-level factors such as neighbourhood and city contexts and macrolevels factors such as provincial and federal guidelines related to the pandemic. The study used a qualitative interpretive descriptive method [11] , which is widely applied to find practical solutions to real-life problems. This method also allows for flexible inquiry into the experiences of individuals [11] [12] [13] . Consistent with the principles of community-based research, the overall study design, including guidance for culturally, linguistically, and contextually appropriate approaches for pursuing participant recruitment, specification of the interview questions, seeking of informed consent, provision of honoraria, and conduct of interviews, was done in collaboration with our community partners, who have a deep understanding of the interests, concerns, and needs of immigrant communities.After obtaining approval from the Ryerson Research Ethics Board (REB#2020-179), a purposeful sample of immigrants aged 18 years or older and living in apartment buildings in the Greater Toronto Area was recruited via word of mouth, email, social media, and through our connections in the city and with community partners who work with immigrants. Potential participants contacted (or were contacted by) the research assistants (RAs) to learn more about the study. Those interested in participating were provided a copy of the consent form prior to the interview. They were given the option to complete and return it to the RA prior to the interview or provide verbal consent at the time of the interview. Individual interviews were conducted between May and September 2020 on the phone or using a virtual platform (e.g., Zoom, Skype). Participants who did not have access to such technology were excluded.Participants were interviewed using semi-structured interview questions that explored their experiences of the changes and challenges in their life related to the physical distancing measures, how they are coping with these changes and challenges, and the successful strategies used to maintain social connectedness. The interview questions were developed in consultations with our community partners. Interviews lasted about 30-45 minutes, on average. An honorarium ($30) was given to each person in consideration of their time in participating in the study.Interviews were conducted in each participant's language of preference (e.g., Urdu, Spanish, Korean, and Arabic), by bilingual RAs. All interviews were audio-recorded with consent. Interviews conducted in a language other than English were translated into English and transcribed by the RA who conducted the interview. The interviews conducted in English were transcribed by an RA on the research team. Transcripts were read paragraph by paragraph, and coded by three members of the team to establish a coding system. After interviews were fully coded another iteration of analysis ensued with the help of several other team members to compare and contrast codes and to develop similar ideas into subthemes and themes, using thematic analysis [14] .Trustworthiness of the study was ensured through several strategies including interviewer triangulation (interviews were conducted by several interviewers); interviews conducted in different languages (to gain a broader and more comprehensive understanding of the topic by capturing opinions of participants of diverse ethnocultural and linguistic backgrounds); member-checking (with each participant during her/his interview, and with other study participants during subsequent interviews); and seeking community partners' feedback and reactions to the results and the interpretations of the results.In total, 72 immigrants participated in the larger study. Of these 50 participants were parents who are the focus of this paper. Of the 50 immigrant parents, the majority (n = 44; 88%) were mothers. Their ages ranged from 26 to 77 years, and most (n = 36; 78%) had two or more children. They described living in difficult conditions marked by confined and overcrowded apartments in high-rise buildings (n = 45) or subsidized housing (n = 5). About 40% of the participants had been in Canada for less than 10 years. Most reported experiencing financial insecurity due to unemployment-from before COVID-19 or as a result of the pandemic-or having only one partner trying to support the entire family by working in a low-income job. Table 1 provides additional demographic information. Parenting has changed during COVID-19 in terms of parenting roles, responsibilities, and expectations. The following sections explore how immigrant parents experienced changes related to: dealing with changing relationships, coping with added burdens and pressures, living in persistent fear and anxiety, and rethinking lifestyles and habits. Participants reported that COVID-19 regulations of maintaining physical distancing changed family cohesion. Some reported a diminished sense of closeness within the family. For example, a father explained, ""Physical distancing is a good thing to follow but it has separated us from our loved ones"". In contrast, some parents viewed having their children at home all the time as an opportunity to become closer and spend quality time with them: ""I spend time with them, and I relate to their experiences more now."" ""As a single mother, I have always been close to my daughter. During the pandemic, we do more activities like tea parties, so we feel even more connected. Before [the pandemic] it was go, go, go all the time.""Some participants said that their children appreciated the extra time spent with their parents. For some parents, this provided a chance to connect their children to their cultural and linguistic roots:""My children loved having me home all the time, and we watched Korean dramas on Netflix together so that I could teach my children about the Korean history and culture.""Although they were worried about the pandemic, most parents demonstrated resilience and optimism. Some referred to growth in terms of parent-child relationships:""During heated arguments while living and spending so much time together in a confined space, we learned to resolve arguments more diplomatically as we are stuck together instead of walking away or remaining bitter and resentful.""""Being able to stay home with my family and give my child and husband time was a positive experience for me.""However, some explained that spousal relationships, now lacking social and cultural supports combined with the inability to freely go outdoors, were negatively affected. Some participants noted that they had a designated spouse who went to work, and did grocery shopping and other ""outside"" activities such as going to the post office or taking garbage to the bins outside the apartment building, all of which potentially put them in closer proximity to others. Because of safety concerns for the rest of the family, this spouse was relegated to a different room in the apartment for periods as long as 4 to 6 months, a situation that created tensions between spouses, which, in turn, were noted as affecting their parenting styles.The closure of schools and childcare facilities placed sudden and enormous pressure on parents, especially mothers, to be fulltime parents, spouses, caregivers, and in some cases, full or part-time employees. The majority of mothers had no respite from any of these roles, responsibilities, and expectations:""When kids were in school I had time for myself but not anymore and I have to deal with pressure from children all the time."" ""There are many changes in our lifestyle, all my family works from home, so I am busy a lot now, catering to them all the time and no time for myself."" Some participants noted that the burden of being a mother and wife was magnified as they tried to maintain a ""normal"" home environment for children (and others) who are also constrained at home with each other often in small apartments for months. The participants noted that they had to be available to ""entertain"" or spend time with their children most of the time. Some participants remarked that they spent ""every waking moment"" thinking about and planning activities for their children that could take place within their small apartments to keep them busy. Participants who continued to work during the pandemic found this to be an impossible task.A major burden identified by respondents that placed enormous pressure on them was related to the quality of their children's education during the pandemic. Due to physical distancing regulations implemented by the Canadian authorities, schools rapidly shifted to an online virtual format. Living in crowded apartments and sharing one computer was common and problematic for families with multiple school-aged children. In total, 75% of the participants had two or more children; 30% had three or more children. Some families did not have enough bandwidth to have multiple Zoom (Zoom Video Communications, a commonly used internet platform) classes and meetings at the same time. In addition, some parents did not speak English at all or sufficiently well enough to help their children learn. Others lacked computer or academic literacy to assist their children with virtual learning. Overall, most parents expressed difficulties in managing the various virtual learning expectations of the school boards, and the challenges were exacerbated for those with multiple children.The perception that quality of education was compromised contributed to the cumulative stress of parenting. Many felt that online schooling was inadequate and that schools were inadequatelyprepared. As a result, participants felt obligated to fulfill the double burden of serving as a teacher and parent-without appropriate support or preparation. One mother said:""My children's schooling became a priority over everything else. This took up most of my time and energy.""Not only did most participants believe that in-person schooling is more effective for student learning, but managing their children's disappointment of missing being in school and seeing their friends added to the challenging day-to-day tasks of parenting. Additionally, some participants had come to Canada in hopes of providing their children with better education. They saw the move to virtual learning as limiting their children's opportunities, for example, for developing English proficiency and becoming familiar with Canadian customs by interacting with peers. One mother reported that she had relied on a childcare facility to improve her son's English language skills: ""My son does not speak much English. He is two years old, but all daycares are closed."" Overall, our study participants found the changes to their children's education to be extremely stressful and a hindrance to promoting their integration into Canadian mainstream culture.Some participants said that living through the pandemic meant living with persistent fear, especially regarding their children's fate. One mother said, ""I am scared for my children, for my children's future. We don't know what's going to happen. It's draining me mentally."" Overall, parents felt it necessary to continuously remind children about physical distancing, and expressed constant anxiety because their children could not remember or abide by the specific safety expectations and strategies. As one father said ""Taking care of a toddler is more difficult because they do not understand the situation."" Mothers, in particular, felt that they had to be constantly vigilant, which they found mentally and physically exhausting. Some were frustrated that their children did not always adhere to public health measures to protect themselves from COVID-19, but they were also aware of the absurd expectations being placed on young children. Some commented about these ""no-win"" circumstances. For example, one mother told us:""Sometimes I don't even know what to do. I can't scold them or yell at them. Look at the situation. You see so many people getting infected everyday. When you go out, you're scared of getting the germs. When you don't go out, you're scared they're going to go crazy from being trapped or become unhealthy.""Children's health, and particularly their mental health, was a relentless concern for parents who were worried that their children's mental health would ""deteriorate"" and that lockdown could have ""negative impacts in their future."" As one mother told us:""My child can't go outside and often feels depressed staying inside as she loves being around people. I worry that this maybe affecting her developmentally, as my child is very young and this age needs socialization and exploring the outside environment.""While acknowledging the importance of technology in keeping their children occupied, connected, and learning, all participants referred to being ""very worried"" about children's ""constant"" use of technology during the lockdown, and the potential negative consequences that this could have on their physical health as well. Having to use Zoom or Skype or other platforms for virtual schooling added to this worry. The following quote from a mother captured the reality expressed by all parents:""Kids are home and using electronic devices all the time, it's very hard to make them do physical activities and keep them occupied.""Many questioned the impact that 8 to 10 or more hours of long-term exposure to electronic devices on their children's eyesight, hearing, and brain. These fears are heightened for some because of the immigration context of their lives in Canada. One mother explained:""I often feel scared that my child will become sick and if so as a first-generation immigrant to Canada I don't think I have enough support to take care of her.""Overall, parents were anxious and afraid about the uncertainty surrounding the pandemic and related restrictions, and their short-and long-term physical, mental, and emotional health consequences on their children.Parents noted that their lifestyles and daily habits had changed due to the pandemic. Some of these changes are captured in the excerpts below:""Sleeping habits are a big challenge. My daughter used to go to sleep around 7 or 8 pm. And then she wakes up at 6 or 7. But that has changed for her (…) so I sleep at 1 or 2 am. She still wakes up early. So her sleep is affected and my sleep is affected.""A single mother noted that she had to leave her kids at home alone at times because when she did take them with her on errands (e.g., grocery shopping) she received negative ""looks or comments from other people in the store."" Due to COVID-19 restrictions, she could not seek help from her other family members, neighbours, or friends who provided such help prior to the pandemic. Some participants commented on the impact of the COVID-19 restrictions on their daily activities and habits that kept their food and other expenses at a manageable level. As one participant explained:""I cannot shop around for bargains anymore because I don't want to stay in long lineups or take the bus or the subway because I am worried about spending too much time around other people and…and getting the virus. Some people are not wearing masks and don't do social distancing.""These changes have financial consequences on their lives. Other changes to their habits included the extra precautions that they took when interacting with their children:""When my husband goes outside even for a little while and comes home, I make him take a shower before bringing our child near him.""""Although me and my daughter would still eat together, we each use different plates and other tableware.""More drastic changes to their lives included decisions parents made about their own work and education. One participant noted being afraid of going back to work: ""I worry about infecting my daughter if I were to go back to work."" While another noted that her husband had ""dropped out of college to take care of our kids.""Despite the added stressors that many of these changes added, not all changes were perceived negatively. Some parents referred to positive changes such as improved family dynamics:""Our life has changed totally, before the pandemic life was very busy everything seemed [to be] going very fast and there was a lot to do, but now the whole family has to stay home, and things have slowed down considerably."" ""I made healthy meals for my family and home schooled two of my three children. I created a daily routine for them to follow, which included regular walks in the park nearby."" Some of these participants even wondered whether these changes could be maintained if and when life returns to ""normal"".Our findings provide insights into the parenting experiences of immigrants during COVID-19. At the beginning of the pandemic (March 2020), public health guidelines rapidly and frequently changed as new knowledge emerged, leading to changes in federal, provincial, and municipal level health, education, and economic policies that understandably exacerbated public uncertainty and anxiety. Most of these policies ignored the realities of families living in apartment buildings where physical distancing is a challenge. For many Toronto immigrant families living in such spaces, the physical distancing required by policies-and especially separate spaces for children and older persons-was extremely difficult as they tried to navigate crowded apartment buildings, shared elevators, and laundry rooms. Moreover, many take public transport, live in multi-generational and/or multi-family households, and work in essential services.Most participants did not speak English fluently and were not very comfortable with technology and the virtual world beyond basic use. Many were not very familiar with the Canadian education system and feared the disruptions caused by the pandemic would affect their children's education and futures.Many immigrant parents came to Canada to provide their children with a better education, which is often seen as a source of upward mobility. During COVID-19, children have been expected to learn from home in an online format, but the rapid shift to virtual delivery of education in Ontario has been underpinned by normative assumptions of families' social locations and privileges, assuming familial access to technology and internet services. The experiences shared by parents in this study reflect other research findings about the digital divide and equity in access to resources [15] [16] [17] . Our participants noted that the burden to facilitate virtual delivery of education fell primarily on parents, not all of whom have the skills, knowledge, or time to provide this support. They found online learning unsatisfactory: many viewed it as hindering their children's learning and worried that it would affect their socialization, English language acquisition, psycho-social development, and overall acculturation to Canada.Beyond the impact on education, COVID-19 restrictions and government-mandated public health measures such as closure of schools, childcare, and other non-essential services curtailed access to formal and informal support networks. Due to limited English language proficiency and social networking, newcomer immigrant parents already lack social support apart from informal support from their ethno-cultural communities. The loss of informal social connections can amplify factors contributing to parental stress through increased social isolation, inability to access supportive and educational services, and economic difficulties [18] . Given the intimate nature of parent-child relationships, parental experience, particularly parental stress, may influence a child's experiences with the pandemic and overall wellbeing [1] .For mothers who were engaged in paid employment outside the home prior to the pandemic, work provided a sense of freedom and time away from home and family responsibilities. Even those who were not employed in paid work prior to the pandemic noted that having to cater to their children, husbands, and other family members who were always at home meant that they were not able to find any time for themselves. Just over 25% of the study sample did not live with their spouse, and managing these responsibilities were near impossible for them while facing financial constraints and with almost no outside help. The disproportionate impact of the pandemic on families with lower socioeconomic status reflects a lack of understanding about how macro-level factors such as policies play out for immigrants at the meso (community) and micro (family) levels. For example, parents living in small apartments had trouble finding and setting up activities for their children given their confined space; they also struggled with sharing limited technology devices and limited or unreliable internet services, highlighting the need to address digital inequity in supporting students from low socioeconomic backgrounds.Participants were worried about the impact of school closures on their children's health and wellbeing. In addition to the loss of social and emotional space for development and social and cultural integration, they noted that children were less physically active, had longer than usual screen time, and had irregular sleep patterns; some noted that children had less healthy diets, resulting in weight gain and a loss of cardiorespiratory fitness. The psychological impact of stressors such as prolonged duration at home, fears of infection, frustration and boredom, inadequate information, lack of in-person contact with classmates, friends, and teachers, lack of personal space at home, and family and financial loss, all appeared to contribute to tensions in relationships between parents and children.Overall, participants referred to changes in sleeping patterns, anxiety, fear, frustration, and worry. Mental health resources that are sensitive and responsive to the unique needs and contexts of immigrant families are needed. Supportive strategies could include community-oriented approaches, for example, online community group discussions and parenting groups [7] . This kind of strategy should include interpreters and translators, and may require creativity in order to respond to the varying abilities to access the internet, communication devices, and levels of digital literacy. It will be important to build on the resilience of immigrant families and communities to help them adjust and adapt as the pandemic progresses; it may be beneficial to create a safe space outside the family, especially for mothers. For example, community networking is known to facilitate positive parenting and positive outcomes for children [8] . Immigrant parents obtain most support from their ethnic communities, but broadened networks would allow parents from various backgrounds to share their experiences of living through the pandemic. Additionally, provincial, federal, and local governments should provide targeted information in addition to instrumental, financial, and health-related resources and support to immigrant communities.The pandemic and the unintended consequences of macro-and meso-level policies have compounded the already considerable health inequities immigrant families experience due to poor housing, unsafe neighbourhoods, lack of access to services, limited income due to underpaid and precarious work, discrimination, and racism [10, [19] [20] [21] . The lack of availability of resources to support immigrant parents requires immediate attention [1] because it can affect the mental and physical health of parents, parenting, and parent-child relationships.COVID-19 has not only increased pre-existing parental responsibilities but has created many new demands on parents. Contributing to the negative experiences reported by parents in our study is the exacerbation of pre-existing inequalities among immigrants that have been heightened by the pandemic. The situation of many families in this study has become worse due to reduced informal social support, lack of familiarity with the educational system, and lack of ready access to internet, computer, as well as indoor/outdoor space to keep their children socially-connected or occupied while physically distancing. These numerous challenges related to the pandemic have created new stresses, anxieties, fears, and frustrations for them that can affect their own well-being and that of their children. Further, the gendered impact of the pandemic has been enormous on mothers who have been forced to take on most of the family burden related to COVID-19. Yet, they have shown significant resilience in ensuring their children's physical, emotional, and mental health and wellbeing. Building on their resilience, immediate action must be taken to help vulnerable parents, mothers in particular, in order to prevent the long-lasting negative effects on them and their children.The data collection was conducted virtually, which may not have been convenient for all participants. Immigrant parents who did not have ready access to phone, computer, the internet or the time to participate because of the non-stop paid and unpaid work were prevented from participation. Their experiences may considerably differ from what is presented here. The study sample also consists of primarily mothers. A study sample that consists of primarily fathers may yield different results. Our sample was delimited to immigrant parents who live in apartment buildings in the Greater Toronto Area, who have relatively limited access to open and outdoor spaces. Immigrant families living in single-family homes with backyards, have more ready access to nearby outdoor parks, or have more options to reorganize their lives because of their higher socioeconomic status, may have different experiences.",Canada,abstract,2021-02-05,02
0b2c4ce6e114ae1199a604bea2cc05b467fe5392,Clinical Outcomes of Patients Hospitalized with Coronavirus Disease 2019 (COVID-19) in Boston,"The novel coronavirus disease 2019 (COVID-19) pandemic has infected millions of people worldwide, leading to a surge in hospital utilization. [1] [2] [3] Although most patients with COVID-19 have a favorable prognosis, COVID-19 may result in critical illness requiring intensive interventions such as ventilatory support, especially in older patients and those with underlying serious comorbid conditions. 3, 4 To meet these needs, health systems and hospitals have had to rapidly reorganize in-patient services and expand ICU capacity. An accurate representation of clinical outcomes for people hospitalized with COVID-19 can improve planning for health systems, hospitals, clinicians, and patients.Among patients admitted to hospitals, key parameters include the portion that will need ICU level care and ventilatory support, the length of time people would need such services, and the mortality rate. To date, much of the data for such factors has come from health systems in China, Italy, and New York that endured critical shortages of services. [3] [4] [5] [6] [7] Accordingly, in prior reports, it can be hard to differentiate the impact of COVID-19 from the influence of overwhelmed capacity.A clear understanding of outcomes is also extremely important for advance care planning (ACP). ACP is a shared decision-making process in which patients and clinicians weigh the risks and benefits of such interventions in the context of the patient's values and preferences. 8 , 9 The intent o f A C P r e m a i n s u n c h a n g e d d u r i n g t i m e s o f a pandemic-aligning medical care delivery with patient preferences. [8] [9] [10] However, extrapolating data from health systems in crisis, where the demand for care far outpaced the supply, is problematic for clinicians who are working to make individual patient decisions.We sought to report the clinical characteristics and factors associated with ventilatory support, survival, and discharge disposition for all COVID-19 patients admitted to hospitals that are not in crisis, but where COVID-19 disease burden was high and in a surge state, a critically important situation that is unique from prior studies and reports of COVID-19 outcomes. We present a retrospective analysis from a large health care system in the Boston metropolitan region. Although considered an early hotspot for COVID-19, Boston did not surpass capacity or initiate crisis standards.This study was approved by the Partners Institutional Review Board. We conducted a retrospective analysis of all patients hospitalized with confirmed diagnoses of COVID-19 treated at Partners hospitals between January 1, 2020 and April 15, 2020. We used the Partners HealthCare Research Patient Data Registry (RPDR) which stores clinical data for 6.5 million individuals who receive their care from Partners HealthCare providers in Massachusetts. Partners HealthCare provides care in academic, community hospitals, and rehabilitation networks across New England. Partners HealthCare has emergency services integrated across most of its member institutions and includes over 200 ICU beds. We included patients admitted to 5 academic and community hospitals within Partners HealthCare in this study. We used COVID-19 diagnoses codes to identify patients hospitalized with COVID-19, which we confirmed by manual chart review. Partners hospitals did not utilize strict criteria for hospital admission. Instead, the decision regarding the need for hospital admission was left at the discretion of the treating physician. All patients with a positive nasopharyngeal polymerase chain reaction test were included. Clinical outcomes were monitored until May 11, 2020. Patients who were still hospitalized by May 11, 2020, were excluded from analyses. Transfers from one hospital to another were merged and considered a single visit. For patients with a readmission during the study period, data from multiple admissions were merged and considered a single visit.We conducted a comprehensive chart review to obtain information regarding patients' demographics, comorbidities, home medications, and laboratory findings. We collected race and ethnicity using the electronic health record (EHR) prespecified fixed categories. We obtained data on home medications based on the admission medication reconciliation record. We used the Charlson Comorbidity Index (CCI) to examine comorbid conditions as documented in the EHR. 11 We also collected data on the use of certain therapies during hospitalization including corticosteroids, hydroxychloroquine, remdesivir, and tocilizumab.We obtained information regarding hospital length of stay (LOS), ICU admission, and the need for mechanical ventilation, vasopressors, renal replacement therapy, and extracorporeal membrane oxygenation (ECMO) from the electronic medical record. We also collected data on palliative care consultation, code status at the time of admission to the hospital and any changes to code status throughout the hospitalization using EHR order entry. We also collected vital status (discharged alive or dead) as well as discharge disposition. To ensure data fidelity, two coders independently reviewed 10% of all hospitalization outcome data and achieved excellent reliability (97% agreement).We used descriptive statistics including frequencies and percentage for categorical variables and means ± standard deviations (SD) for continuous variables to summarize participant characteristics and clinical outcomes. All reported P values were two-sided, with P<0.05 considered statistically significant.We conducted unadjusted analyses examining the association between demographic and clinical factors of interest with mortality. The following factors were considered in the unadjusted analyses: demographics (age, sex, race (White vs. all other racial categories), and ethnicity), home medications (statins, non-steroidal anti-inflammatory drugs, corticosteroids, angiotensin-converting enzyme inhibitors, or angiotensin II receptor blockers), history of smoking, obesity, comorbidities (CCI), the need for supplemental oxygen on admission, inflammatory markers (lactate dehydrogenase, Creactive protein, ferritin, and D-dimer), and treatments (remdesivir, corticosteroids, or hydroxychloroquine). Factors that were associated with mortality with a P value < 0.10 were then included in the multivariate logistic regression model, as recommended by literature on logistic regression model building. [12] [13] [14] Given collinearity between inflammatory markers, only lactate dehydrogenase was included in the final multivariable logistic regression model. Two hundred eighty-five patients required supplemental oxygen at the time of admission (60.6%) and 197 (41.9%) were febrile on admission. Inflammatory markers at the time of admission are presented in Table 2. Most patients were ""full code"" with no restrictions on life-sustaining treatments at the time of admission (83.6%, 393/470).Overall, 91 patients remained hospitalized by May 11, 2020, and were excluded from the analyses. Among those who remained hospitalized, 50.6% (46/91) were admitted to the ICU, but only 16.5% (15/91) remained in the ICU at the time of last follow-up. Table 3 depicts the clinical measures and outcomes for patients hospitalized with COVID-19 by survival status (alive vs. deceased). Overall, 194 (41.3%) of patients received hydroxychloroquine, 106 (22.6%) received remdesivir, 52 (11.1%) received corticosteroids, and 21 (4.5%) received tocilizumab. Deceased patients had higher inflammatory markers during admission and lower absolute lymphocyte count compared to those discharged alive ( Table 3 ).The median hospital LOS for the entire cohort was 8 days (IQR 1-37). Overall, 178 (37.9%) patients were admitted to the ICU, 158 (33.6%) received mechanical ventilation, 138 (29.4%) received vasopressors, and 118 (25.1%) died during hospitalization. When excluding patients who had documented limitation of life-sustaining therapies on admission, 21.1% (83/393) patients died during hospitalization. The mortality rate was higher for men and for higher age groups, as depicted in Figure 1 . Overall, 22.3% (105/470) had a palliative care consultation. Among those who died during admission (n = 118), 65 (55.1%) received a palliative care consultation with a median time from palliative care consultation to death of 4 days (IQR 1-20). Additionally, 143 (30.4%) patients had orders to limit life-sustaining treatments such as resuscitation In unadjusted analyses, older age, White race, history of statin use, history of angiotensin-converting enzyme inhibitors or angiotensin II receptor blockers use, higher comorbidity score, the use of supplemental oxygen on admission, and higher inflammatory markers on admission were all associated with higher odds of mortality (Table 5 ).In the multivariate logistic regression analyses (n = 420) ( Table 1 ).In this study, we demonstrate that the majority of hospitalized patients with COVID-19 and even the majority of those who received mechanical ventilation survived to hospital discharge. Mortality rates were 25%, markedly lower than those previously reported. Hospital LOS and days on ventilator were approximately 5-6 longer than prior reports. Age, male sex, Charlson Comorbidity Index score, inflammatory markers, and supplemental oxygen use on admission were all associated with mortality. The surge in hospital utilization due to COVID-19 is unprecedented in the modern era. 15 Health systems have had to rapidly re-organize in-patient services and expand ICU capacity. Initial studies from cities overwhelmed by COVID-19 patients described exceptionally high mortality rates. 4, 7 The more favorable outcomes we report likely reflect COVID-19 outcomes in a health system that was not tested to the point of critical resource scarcity.When health systems are not overwhelmed and patients can remain hospitalized or on ventilators for prolonged periods, outcomes are not as poor. It is important to note that a substantial number of patients in prior reports were still hospitalized and this may have inflated mortality rates for patients receiving ICU care. Nonetheless, 25% of the patients hospitalized with COVID-19 and over 40% of those admitted to the ICU died during their hospitalization, underscoring the gravity of this illness. These 16, 17 These mortality rates have significant implications for patient and family decision-making. ACP and decision-making for serious illness more broadly relies on accurate information about the risks and benefits of life-prolonging interventions and the likely disposition. 9, 10, 18 Early reported mortality rates for COVID-19 were quite high, which may have led to ACP discussions and decisions that were not fully informed. The present study serves as a more accurate portrayal of survival with COVID-19 in a busy health system with a surge of patients and hopefully leads to more informed decision-making. It is important to note that most patients in our cohort did not have any limitations on lifesustaining therapies at the time of admission to the hospital, despite their older age and multiple comorbid conditions. Unfortunately, this likely reflects the lack of adequate ACP discussions and automatic ""full code"" status often employed in the USA compared to other countries. 19 Nonetheless, ACP discussions are critical to ensure patients make informed decisions regarding their medical care.There was extensive use of palliative care services in the ICU. Given the critical role palliative care can play in helping patients and families make informed decisions about their care, 8, 20, 21 the existing national shortage of palliative care clinicians is an urgent crisis and rivals other needs such as personal protective equipment and nasal swabs. [22] [23] [24] [25] [26] Exploring goals of care, coordinating and effectuating patient preferences, and controlling pain and suffering are of paramount importance in the face of an uncertain illness such as COVID-19. 27, 28 Significantly expanding the clinician workforce with these skills and rapidly disseminating tools to support ACP is vital. Earlier ACP may also help ease the burden of limited in-patient palliative care resources downstream. [27] [28] [29] This study has several notable limitations and numerous strengths. First, while the study population was diverse with more than half being non-White, the cohort is from a single metropolitan area, thereby limiting the generalizability of our findings. Second, 91 patients remained hospitalized and their outcome data were absent from our analyses. We excluded these patients since Boston hospitals experienced crisis of COVID-19 cases by the end of April and our goal was to report on patient outcomes in hospitals not experiencing crisis. Prior studies in the USA had largely incomplete data sets. Nonetheless, excluding patients who remained hospitalized may result in a selection bias as those who remained hospitalized may have different outcomes compared to the study cohort. Third, knowledge and practices regarding COVID-19 treatment are rapidly changing and this data set reflects the early period of COVID-19 in the USA. It is possible that mortality rates change over time due to identification of effective treatments. Fourth, there was limited follow-up; longer term sequelae remain unclear. Fourth, data regarding race was obtained from the EHR, which includes an ""other"" category that is not fully explained, which limits our ability to interpret data on outcomes of patients based on race. Fifth, while our multivariate logistic regression model adjusted for factors such as comorbidities and severity of illness at presentation, it is possible that there are other unmeasured confounders that may affect the relationship between treatment received and risk of mortality. Additionally, we utilized a P < 0.10 as a cut-off in our multivariable analysis modeling approach, which may have also omitted potential confounders. Finally, this study included only hospitalized patients with confirmed COVID-19. Patients who did not present to the hospital and died at home, or were discharged to hospice from the emergency department are not included. Prior studies also had similar limitations.Managing the COVID-19 global pandemic involves ensuring that health systems are not overwhelmed. This study was conducted in a region of the USA that did not experience crisis standards and exhibited a much lower rate of hospital mortality than in prior papers which reported data from areas enduring critical shortages. Protecting health systems so they will not be over-run and surpass the surge capacity for medical resources such as ICU beds, ventilators, and appropriately trained medical staff have a salutary effect on prognosis and survival.",USA,first author,2021-02-24,02
296994b040db5b5448775317fd4ad038b5060425,Association of mortality and aspirin prescription for COVID-19 patients at the Veterans Health Administration,"Veterans Health Administration (VA) is the largest integrated healthcare system in the United States (U.S.) and enrolled Veterans represent a population at increased risk of poor COVID-19 outcomes due to older age and multiple comorbidities [1] [2] [3] [4] [5] . As part of our continual quality improvement and assessment efforts, we have been developing and validating predictive models to optimize care strategies. Our recent work demonstrated that existing electronic health record (EHR) data can be utilized at VA to assess risk in the form of the Care Assessment Needs (CAN) score for different groups of Veterans including those battling COVID-19 [6, 7] . In the process of optimizing COVID-19 specific predictive models, we identified a strong correlation between preexisting aspirin prescription and decreased all-cause mortality. Given the urgency of this crisis, and the potential for drug repurposing to improve outcomes, this analysis is our in-depth evaluation of the correlation between standard care aspirin prescription and mortality for COVID-19 positive Veterans.Data was obtained from the VA national Corporate Data Warehouse (CDW), a central relational database repository that aggregates EHR records from 1,255 VA health care facilities across the U.S. This database includes enrolled Veterans as well as a very small number of non-Veterans such as qualified spouses. Our work to refine VA risk assessment tools for COVID-19 outcomes started with binary logistic regression modeling of mortality on common variables available in our EHR such as comorbidities and pre-diagnosis medications. A specific medication or medication class was included in the assessment if utilized by more than 10% of the cohort population. This resulted in the inclusion of 17 specific medications and 14 medication classes, which are listed in the S1 Table. There was a strong correlation between pre-diagnosis standard care use of aspirin and decreased all-cause mortality in each of the logistic regression models we evaluated. We utilized log odds of at least -0.05 in mortality as an inclusion criterion for medications in the assessment, and of the 31 medications and medication classes evaluated, pre-diagnosis aspirin prescription was the only one that met this criterion (mortality decreased by 36% with a log odds of -0.45). Retrospective analysis was then performed on both aspirin and non-aspirin groups for 14-day and 30-day mortality assessment. The Care Assessment Needs (CAN) score, the Charlson Comorbidity Index (CCI), specific comorbidities, and demographics were utilized to compare baseline characteristics of the different cohorts.CDW lab tables were queried to identify the first positive COVID-19 polymerase chain reaction (PCR) results for patients. For this evaluation, the time of the first positive COVID-19 test administration was considered the time of diagnosis. Test results performed outside of VA were not included in the evaluation to reduce potential bias due to test variability and incomplete access to care records. Patients without a calculated CAN score within 6 months prior to their first positive COVID-19 lab results were excluded since a patient's CAN score was utilized to inform current health status and patients not actively utilizing VA care will not have a CAN score calculated.The aspirin cohort was defined as those patients who had delivery of an active aspirin prescription by the VA pharmacy at the time of a positive COVID-19 lab test. If a patient had no refills at the time of diagnosis, then the prescription was only considered active if it was filled up to 30 days prior to the positive COVID-19 lab test. Patients who had non-VA aspirin prescriptions documented as an active medication in our EHR, were also considered active, and were included in the treatment group. All other COVID-19 patients, with no documented active Development' (CRADA) agreement. These contracts are typically negotiated in collaboration with VA national Office of General Council (OGC) and attorneys from the collaborating institution. These national sharing policies and standards also apply to deidentified data. In addition, if a contract is in place allowing sharing of deidentified data outside of VA, then VA national policy (VHA Directive 1605.01), states that deidentification certification needs to be met by Expert Determination. The expert determination requires independent assessment from an experienced master or PhD in biostatistics, from a third party not involved in the project, and may require outside funding to support. aspirin prescription, were assigned to the control cohort. This methodology was adopted based on previous work utilizing VA EHR data to assess aspirin use [8] .Patients' health risk was controlled for by using the VA CAN score. The CAN score is a tool that assesses patients' risk of morbidity and mortality using a wide array of data available in the EHR, including socio-demographics, clinical diagnoses, vital signs, medications, lab values, and health care utilization data (S2 Table) . Our previous work has established that the CAN score successfully risk-stratifies COVID-19 patient outcomes with the strongest performance demonstrated in predicting mortality [6, 7] . The CAN score ranges from 0 to 99, with a higher score representing a greater risk patient. We utilized the CAN 1-year mortality model (version 2.5), which is automatically computed weekly based on all living Veterans who actively receive care services from VA.The primary outcomes for this assessment are 14-day and 30-day all-cause mortality within or outside of hospital care. Mortality is identified by date and time of death listed in CDW. The time windows for the evaluation start on the date of the first positive COVID-19 test recorded at VA. The 14-day and 30-day cohort have different end dates to allow for appropriate followup time window to elapse before analysis could be performed for all-cause mortality.For both the 14-day and 30-day mortality outcomes that were evaluated, unadjusted odds ratios using contingency tables were first computed to quantify the difference in mortality between the aspirin treatment and control groups. Given the retrospective observational nature of the data, leading to differences in the treatment and control groups, propensity score matching was applied to reduce confounding effects. To do so, the treatment and control group were matched one-to-one on the unscaled covariates of age, gender, and CAN score (1-year mortality) with the RStudio ""MatchIt"" library (V3.6.2) using the commonly used caliper setting of 0.1. Race (White vs. other) was not included as a covariate in the matching algorithm since our assessment demonstrated that it was not significantly associated with the treatment assignment nor the outcome. New contingency tables and adjusted odds ratios were then computed on the matched cohort for both the all-cause 14-day and 30-day mortality outcomes. Fixing the control cohort as the reference group, odds ratios are reported for the aspirin treatment cohort as point estimates with 95% confidence intervals.This quality improvement and assessment project received a Determination of Non-Research from Stanford IRB (Stanford University, Stanford, CA, USA), as well as by VA determination.The initial cohort of COVID-19 positive Veterans included 35,370 patients identified from March 2, 2020 to September 13, 2020 for the 14-day mortality evaluation, and 32,836 patients identified from March 2, 2020 to August 28, 2020 for the 30-day mortality evaluation. Patients without a CAN score calculated within six months of the first positive COVID-19 PCR result were excluded leaving 28,350 patients in the 14-day mortality cohort, and 26,346 in the 30-day mortality cohort (Fig 1) .In both cohorts, approximately 24% of patients were prescribed aspirin prior to COVID-19 diagnosis. The majority of both the unmatched cohorts are male, which is expected for our VA population. Both cohorts were virtually the same age (58 years each) and in the same health as represented by the CAN score (CAN of 44 each) and Charlson Comorbidity Index (CCI of 2.7 each). The similarity of the 14-day and 30-day cohorts is expected as all subjects in the 30-day group were also part of the 14-day group. More than half of all patients had hypertension, more than 30% had chronic pulmonary disease and diabetes, and 15% had congestive heart failure ( Table 1) . For the treatment and control groups, the differences in age, gender, and CAN score were resolved after applying propensity score matching (Tables 2 and 3 ). The scatter plots of the propensity score as a function of the covariates age, gender, and CAN score demonstrate very closely fitting curves to further confirm this assessment (Fig 2) . (Table 4 ). In the propensity-matched cohort, these adjusted odds ratios represent a drop in 14-day mortality from 6.3% (control group) to 2.5% (treatment group) and a drop in 30-day mortality from 10.5% (control group) to 4.3% (treatment group).As part of our COVID-19 quality improvement and assessment efforts at VA, we have been internally developing and validating COVID-19 prediction models to optimize Veteran care.In the process of assessing logistic regression models, we discovered a strong correlation between preexisting aspirin prescription and decreased mortality in COVID-19 positive Veterans. This observation also confirms a recent study of 400 patients, which found aspirin use to be associated with lower COVID-19 mortality [9] . Our large national study highlights that aspirin is an important target for additional assessment in the treatment of COVID-19. The impact of propensity score matching on the odds ratio points to a strong confounding of aspirin's treatment effect by the covariates age, gender, and CAN score. Accounting for these risk factors that are commonly associated with aspirin prescriptions, findings demonstrated that baseline aspirin prescriptions imparted a strong decrease in mortality, essentially cutting the risk of an adverse outcome by more than half in our population. In addition, these Table 4 . Unadjusted and adjusted odds ratios for the 14-day and 30-day mortality aspirin cohorts (95% confidence interval). All odds ratio p-values are < 0.001. results are statistically and clinically significant for mortality outcomes measured in both the 14-day and 30-day timeframes.The associated benefit of aspirin on Veterans in this disease may be related to several factors. A leading possibility is that aspirin's systemic antithrombotic effects could disrupt the increasingly recognized life-threatening risk of thrombotic events related to COVID-19. As an example, a recent study of autopsy findings in twelve COVID-19 patients found 58% had deep vein thrombosis and 33% had pulmonary embolus as the direct cause of death [10] . There is also an increased rate of acute ischemic strokes in COVID-19 patients, which is felt to be a consequence of the hypercoagulable state associated with the infection [11, 12] . Arterial thrombosis has also been characterized in critically ill COVID-19 patients, resulting in loss of limbs and life [13] . Notably, this evaluation presents positive associations for a population of patients who were on aspirin at the time of diagnosis with COVID-19, and not as a new treatment after becoming acutely ill. This may be a crucial distinction because aspirin inhibits platelets as well as inflammatory cytokines that lead to pathologic platelet aggregation. These effects of aspirin can prevent clot formation but not thrombolysis of an existing clot [14, 15] . Therefore, if COVID-19 hypercoagulability induced thrombotic events, such as myocardial infarction, pulmonary embolism, limb ischemia, and stroke, are an important cause of acute decompensation, the presence of the antiplatelet effects of aspirin before COVID-19 infection could be protective. In addition, since our population may be at higher baseline risk for thrombotic events due to older age and comorbidities, the superimposed impact of a COVID-19 induced prothrombotic state may have disproportionate consequences for our patients that is important to understand as we continually work to rapidly optimize care. Future study will also be needed to assess how aspirin fits into this hypercoagulable state as aspirin has been considered most effective in prevention of arterial thrombotic diseases and less so for venous thrombotic events. Likewise, the anti-inflammatory effect of aspirin may also have an independent or synergistic beneficial effect. There are other potential pathways to consider in which aspirin could positively impact patients with COVID-19 such as inhibiting virus replication [16] .There are cautions to be considered when discussing aspirin use in the setting of COVID-19. Early in this pandemic, there was concern that NSAIDs could be related to adverse cardiovascular and pulmonary outcomes and there was an editorial published that suggested potential harm with NSAID prescription for COVID-19 patients [17] . However, the World Health Organization subsequently published a brief report stating that: "". . .there is no evidence of severe adverse events, acute health care utilization, long-term survival, or quality of life in patients with COVID-19, as a result of the use of NSAID"" [18] . Nevertheless, there are many aspirin contraindications to take into consideration such as in the setting of disseminated intravascular coagulation and other bleeding disorders, which can result in uncontrolled hemorrhage, as well as in children due to the risk of Reye's syndrome.There are critical strengths of this assessment; our data source included a large number of patients, spanning a diverse geographic range, from an integrated longitudinal EHR database. In addition, because VA practices purposeful adverse patient selection, many Veterans rely on VA for over the counter (OTC) medications. Therefore, our database offers a broader scope of care and a more complete record of outpatient aspirin use, which is a crucial variable. However, there are also Veterans with better financial means, who may not rely on VA for OTC medications, and it is possible that some of these patients may not have reported their aspirin use to their clinicians even though medication reconciliation is a national VA system-wide policy for clinical visits and the VA EHR database is designed to include non-VA prescribed OTC medications. Since those with better financial means tend to have better healthcare outcomes, this could result in an underestimation of the beneficial association of aspirin [19, 20] . The relative recent emergence of this pandemic highlights an important limitation of all COVID-19 assessments such as reporting of mortality occurring outside of care facilities, which may be delayed and could also underestimate the impact.There are several areas that deserve additional assessment as more data becomes available. For example, this study did not have information on the dosage of aspirin. Future, sub-cohort analysis of the relative impact of different dosages of aspirin, as well as the effect of less common anticoagulation medications, will become more statistically significant over time as datasets increase in size. Importantly, as a retrospective evaluation, we cannot establish direct cause and effect, only correlation that deserves dedicated controlled trial to assess the potential of aspirin as a drug repurposing option for this population. Finally, when compared to other healthcare systems, the VA population is statistically older with multiple comorbidities, may face unique Veteran related health challenges, and is disproportionally male. As a result, VA specific patient variables, including potential sex differences in biological pathways of clot formation, limit the generalizability of this assessment. However, as more information becomes available, we may be able to gain greater insights about sex related outcome variations in our patients.Aspirin prescription was discovered to be strongly associated with decreased mortality rates for COVID-19 positive patients enrolled at VA. Additional prospective evaluation is required to more completely understand this correlation and the potential implications for improving care.Supporting information S1 Table. The 31 medication variables utilized in the logistic regression analysis. If a unique medication was present in more than 10% of the cohort, it was included as its own variable. All other medications were grouped as ""other"" by drug class. This resulted in the inclusion of 31 variables across 14 separate medication classes. ",United States of America,first author,2021-02-11,02
8fc4b3bfde88cca808b50748b8cfbb8edf1fb0f2,Journal Pre-proof Liver injury in liver transplant patients with COVID-19: a histopathological confirmation Corresponding Author Details,"I welcome the results reported by Kaltschmidt and colleagues. 1 They undoubtedly carry significant implications towards liver transplant (LT) patients infected with COVID-19.The study investigated patterns of liver injury and recovery in 60 patients who died of COVID-19 pneumonia between March and June 2020.13 patients who died of non-COVID-19 fatal pneumonia served as the control. COVID-19 patients more frequently exhibited platelet microaggregates in the microvasculature of the liver (70% vs 30%; p=0.032). This is expected since severe COVID-19 entails a hyperinflammatory, hypercoagulable state with significantly higher rates of thromboembolism. 2 More COVID-19 patients also experienced sinusoidal dilation exceeding 75% (p=0.024). Portal dilation was also more frequently observed (p=0.002). SARS-CoV-2 was detected in 25% of all COVID-19 patient liver samples. Furthermore, more COVID-19 patients had higher-grade hepatic steatosis, with approximately 40% of cases at grade 2/3. The micro-vesicular variant was more preponderant in this cohort. As COVID-19 patients exhibited greater extent of liver damage, there were greater activation of intrahepatic stem cell niche, and more regenerative clusters of hepatocytes in intrahepatic bile ductules. This led to aberrant regeneration efforts.Such results proffer us an alternative view of the long-term consequences of LT patients with COVID-19. These patients were found to experience more severe disease. A US multicentre observational study showed that 72.3% (n=81) patients were hospitalised, and 37.0% (n=30) were admitted to the ICU. 23.2% (n=26) were given mechanical ventilation. 3 Such results corroborated with those from a Spanish nationwide study.86.5% (n=96) were hospitalised, 4 ",United States,abstract,2021-02-10,02
4f64175bce6e486f9111678f33f6a5ba677e89cc,The Use and Misuse of Mathematical Modeling for Infectious Disease Policymaking: Lessons for the COVID-19 Pandemic,"Since the emergence of coronavirus disease 2019 (COVID-19) as a global pandemic, many policymakers have relied on mathematical models to guide highly consequential decisions about mitigation strategy, balancing the goals of protecting health while limiting economic and social disruption. This endeavor can be especially challenging when models disagree. For example, a model from the Institute for Health Metrics and Evaluation (IHME) in April 2020 forecast around 60,000 total deaths from COVID-19 in the United States during the first wave of the pandemic. 1 This figure was passed before the end of April, with more than 125,000 confirmed COVID-19 deaths reported by July 1, at the end of the first wave. 2 The IHME model was reportedly influential in White House deliberations over strategy, 3 even as epidemiologists and modelers criticized its projections as overly optimistic and methodologically flawed. 4-7 IHME has since made several major revisions in response to such criticism, 8 and their recent analyses have projected more than 500,000 deaths by March 2021, similar to other prominent models. The IHME model is hardly the only model to be received with skepticism. [9] [10] [11] Early in the pandemic, several models offered starkly different projections for COVID-19 cases and deaths, 12 and months later, differences between the available models still persist. 13 Although these publicized disagreements may have contributed to public mistrust of mathematical modeling, 7 models remain essential tools for evidence synthesis, planning and forecasting, and decision analysis for infectious disease policymaking. They enable formal and explicit consolidation of scientific evidence on the many factors relevant to a decision, and allow analysts to estimate dynamic outcomes that would be difficult or impossible to measure empirically, including the long-term consequences of policy alternatives. Given the high level of uncertainty around many important parameters (such as the level and duration of immunity to COVID-19, the duration of the latency and incubation periods, and adherence to physical distancing, mask wearing, and other mitigation measures), mathematical models can be used to explore uncertainties around model inputs and assumptions, as well as project plausible ranges for each outcome of interest. These characteristics make models highly valuable planning tools. By identifying the assumptions and uncertainties to which decision making is most sensitive, they can also be used to prioritize research investments, describing the information that is most important to collect to allow better decision making. 14 In the COVID-19 pandemic, prominent modeling applications have been used to chart out possible worstcase scenarios, 15, 16 shape decisions around major policies such as physical distancing 9, 17, 18 and testing, 19, 20 plan for the deployment of public health resources, [21] [22] [23] [24] [25] and infer key epidemiological parameters describing how the epidemic might manifest in different settings. 9,26 These different purposes shape decisions about model complexity and approach, the level of precision required of model results, and the extent to which modeling conclusions will generalize to different situations or questions.In all cases, analysts constructing mathematical disease models make decisions about how to represent partially observed processes-such as disease natural history or how the public will respond to a new disease threat-that generate the consequences and outcomes of interest. Due to imperfect mechanistic information, there can be multiple defensible approaches for constructing and parameterizing models, all consistent with current evidence, but that may nevertheless diverge in their future predictions. Sensitivity of results to these design choices complicates the interpretation of modeling studies. This interpretation has been made more challenging in the current pandemic, with rapid changes in the evidence base and the pressing demand for definitive answers from the public and policymakers. However, concerns over the validity of modeling studies have long existed, and the current debate about severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) modeling mirrors earlier discussions in other disease areas.Most modeling studies report results from a single model, either by using fixed parameter values or by averaging the results of multiple parameter sets. 27 Although estimates of uncertainty are sometimes presented, these are typically used to show the stochastic variation in epidemic trajectories or the range of results produced with alternative parameter values. However, when several models analyze the same question, there can be large differences in reported estimates not attributable to stochastic or parametric uncertainty alone but to the modeling approach adopted, modeling structural decisions, and how empirical evidence is incorporated into the model. For example, to evaluate the effectiveness of mass drug administration for malaria control, Brady et al. 28 compared the expected reductions in malaria prevalence using 4 well-established mechanistic models, all calibrated to the same transmission setting and examining the same 16 intervention scenarios. As shown in Figure  1 , while the models largely agreed on the ordering of interventions, they diverged enormously in terms of the effect size of any particular intervention and of the incremental benefits of one intervention compared to another, differences that would be critical to decision makers from a benefit-harm or cost-effectiveness standpoint.Even if there is agreement at a single point in time, models may diverge in their predictions over other time periods. To illustrate, in an analysis of tuberculosis incidence and mortality over 2000-2025 in South Africa, Houben et al. 29 reported substantial divergence between disease trends produced by 8 independently developed models, as shown in Figure 2 . Even though models had been calibrated to fall within prespecified intervals for 2012, the comparison revealed great variation in modeled disease trends. Models reporting steep increases in incidence provided a different view of the epidemiological 48 30 reported on a comparison between 10 modeled forecasts of human immunodeficiency virus (HIV) prevalence and treatment coverage and the findings of a subsequent national survey that reported the same outcomes. Figure 3 summarizes these contrasts-while for some outcomes, the model estimates were distributed around the survey mean, for others, the estimates were systematically different, with most or all modeled estimates falling to one side of the survey confidence interval. Thus, while aggregating the results of multiple models may reduce the impact of misspecification by any single model, pooled results will still be sensitive to any systematic biases.Such modeling biases are more likely when evaluating policies in novel and rapidly evolving epidemiological circumstances, such as those being considered for COVID-19 control. For established policies and interventions, accumulated evidence will document the realities of routine implementation, whereby policy impact can be less than originally envisaged 31 and can sometimes be harmful. 32 For new policies, these factors that limit effectiveness may not be well described and harmful unintended consequences not yet known. This may not be helped by overreliance on early trials, which are typically conducted in populations where greater impact is expected and where interventions are provided with a level of fidelity impractical in routine health services. 33, 34 Together with publication bias, failure to rigorously monitor and validate interventions, and the conscious or unconscious advocacy of well-meaning researchers, systematic biases in the modeling of novel policies can overestimate the likely impact of these policies and systematically bias policymakers in their favor.As use of mathematical models has become more commonplace, approaches have evolved to guard against modeling biases. First, individual studies may explore how different modeling assumptions affect their projections. 35 Another approach, somewhat akin to systematic reviews, is that of model comparison studies, including some examples mentioned above. In these studies, researchers compare projections from multiple models and examine how any differences are related to modeling assumptions. Recently, Drolet et al. 36 conducted a review of 115 such model comparison studies for vaccinepreventable diseases. They found that, while methodological heterogeneity made it difficult to draw quantitative conclusions, these studies were valuable for identifying tenets of good practice in modeling. Guidelines have been proposed to standardize the process of model comparison, 37 and within some disease areas, consensus guidance has been developed on good modeling practices. 38 A separate line of methodological research has examined the biases associated with parameter inference using mechanistic computer models. This work demonstrates that failures to account for model discrepancy 39, 40 -an imperfect fit between model outcomes and the data used to fit them-may lead to parameter estimates and model predictions that are overly precise and systematically biased. The relevance of model discrepancy for health policy analysis has also been explored. 41 While formal approaches have been developed to account for imperfect fit between model and calibration data, 42,43 these methods have infrequently been used in infectious disease modeling.Many of the considerations discussed above pertain to how a model's outcomes are validated. However, the value of such validation depends critically on the nature of the data available for validation. As shown in Figure  2 , models with different assumptions can produce remarkably similar outcomes at certain points in time while diverging at others. This partial consistencywhich may be used to argue that models agree-is irrelevant if the crucial policy questions relate to the time period where results diverge. Similarly, justifying a model's fitness for purpose by validating it against current policy outcomes is insufficient if divergent results are seen when models are used to forecast the results of a different policy under consideration. This issue-that the model outcomes needed for decision making differ from the outcomes that can be compared to other evidencecomplicates the task of model validation and renders approaches like cross-validation 44 less relevant for policy modeling. As it is generally never possible to validate all outcomes of interest (otherwise, why is a model being used at all?), there will always be some assumptions needed. Blanket claims of the ''validity'' of a model should be viewed with suspicion.Even if the validation of model outcomes is difficult, it is still possible to interrogate model processes. One advantage of mechanistic models (as compared to purely statistical models) is that they attempt to reproduce the underlying processes that generate observed outcomes, such as disease natural history or the processes of providing health care. Because these intermediate calculations are designed to represent real, physical processes, the structures and parameters used to model these mechanisms can be critiqued and compared to external data. For example, in a 2018 systematic review of over 300 tuberculosis transmission models, 45 huge variation in modeled disease risks was attributed to differences in the representation of latent disease, a crucial part of TB natural history. Critically, all of these models could be calibrated to reproduce a particular incidence and mortality profile but would produce very different results if used to compare policy options. By comparing modeled disease risks to empirical data, models that are inconsistent with these data can be identified.Model benchmarking and validation are frequently undertaken by multimodel collaborations. In the United States, the Centers for Disease Control and Prevention (CDC) curates a set of (to date) 37 COVID-19 forecasting models developed by independent research teams. 46 These models have been compared against each other and validated against reported data, as well as used to project future hospitalizations and deaths. An ensemble model has also been developed to combine the participating models. 12 Comparable to a meta-analysis, an ensemble model aims to improve predictive performance by calculating a weighted average of the results of several models, each of which may rely on different assumptions and data. 47, 48 Weights are typically chosen to minimize prediction error of the ensemble, 49 but alternative weighting schemes can prioritize other features if desired. This COVID-19 ensemble provides forecasts for each US state, and most of the component models are mechanistic in nature. It has offered projections since early April, and the true number of deaths for the United States has mostly fallen within the model's 95% credibility interval. Other collaborations and repositories are also being established to document the COVID-19 models that are being developed and will facilitate later comparisons. 50, 51 The rapid accumulation of empirical data will provide greater opportunities for model validation early in the model development process, which may be enhanced by the adoption of data assimilation frameworks. 52, 53 In settings of rapid epidemiological change, validation may only be possible after modeled results are in the public domain. As such, use of models for real-time decision making can be perilous, as with the influence of early IHME forecasts over White House decision makers, despite prominent critiques of the model. [4] [5] [6] [7] 54 Living with Modeling UncertaintyIn the rapidly evolving climate of the COVID-19 pandemic, there are major uncertainties around disease dynamics and policy outcomes, as well as ample opportunity for models to ''get it wrong.'' We should expect that the evidence base and epidemiological context will continue to shift, sometimes making earlier modeled results obsolete. Modeling is likely to remain prominent as new policy questions arise, yet the uncritical acceptance of modeling results will not serve public health or the field of modeling. Careful evaluation and comparison of results-and benchmarking against empirical findings where possible-will be important for revealing assumptions and potential biases, as well as spurring progressive improvement in modeling approaches.",USA,first author,2021-02-03,02
b1abcaa242c83c3939f89f447217d2e0736f9cbc,Estimating the reproductive number R 0 of SARS-CoV-2 in the United States and eight European countries and implications for vaccination,"We collected daily case confirmation and death count data from the John Hopkins CSSE 116 (Center for Systems Science and Engineering) database 117 (https://github.com/CSSEGISandData/COVID-19). The data is accessed and extracted on March 118 31, 2020. The data consists of time series of the cumulative number of case confirmations and 119 deaths by country. Daily incidences were derived from the cumulative counts. We included data 120 from the United States (US) and eight most affected European countries where the total deaths 121 exceed 150 by March 31, 2020. The total deaths threshold is to ensure that the number of deaths 122 is high enough for statistical inference. The eight European countries are France (FR), Italy (IT), 123 Spain (SP), Germany (GR), Belgium (BE), Switzerland (SW), Netherlands (NT), United 124 Kingdom (UK). 125 We included a subset of case and death count data for inference based on the two following 126 criteria. First, to minimize the impact of stochasticity and uncertainty in early data collection, we 127 used case confirmation incidence data starting from the date when the cumulative number of 128 cases was greater than 100, and used daily new death count data starting from the date when the 129 cumulative death count is greater than 20 in each country (see Table S1 and Fig. 1 for the period 130 from which data is included). Second, to estimate the early outbreak growth in each country 131 before control measures were implemented, we included case count data up to the date of 132 lockdown in each country. For death counts, we included a maximum of 15 days of data points 133 starting from the date when the cumulative death count is greater than 20 in each country. We 134 tested the sensitivity of model predictions against variations in the number of data points used for 135 inference. In this analysis, we included the 15, 13 or 10 days of data points prior to the date when 136 lockdown was implemented in each country. Overall, we found that the results are consistent 137 across the different numbers of data points used (Table S1) . 138 139 2.2. Model 140We construct a SEIR type model using ordinary differential equations (ODEs; see 141 Supplementary Text). We consider the exponentially growing phase of the outbreak and thus 142 make the common assumption that the susceptible population is constant over time. Then, the 143 total number of infected individuals can be expressed as:(1) 144 where is the exponential growth rate of the epidemic (the growth rate for short below), and * 0 145 is the number of total infected individuals at time 0, set arbitrarily as January 20, 2020. Note the 146 choice of the date of time 0 does not affect our estimation. 147 We solve the ODE model and derive the following expressions for the key quantities for 148 model inference (see Supplementary Text). The descriptions and values used for the parameters 149 in the ODE model are summarized in Table 1 . 150 The true daily incidence of infected individuals, , can be expressed as:(2) 151 where and 1/ are the transmission parameter of the virus and the latent period of infection, 152 respectively. 153The daily new confirmed case count, , is related to the true daily incidence, as:154 where is the detection probability, i.e. the fraction of newly individuals at time who are ( ) 155 later detected among all infected individuals. We assumed an Erlang distribution for the period 156 between infection and case confirmation , where and are the mean 1/ 157 and the shape parameter for the distribution. 158The daily new death count, , is related to the true daily incidence, as:159 where is the infection fatality ratio. Again, we assumed an Erlang distribution for the period 160 between infection and death , where and are the mean and the shape 1/ 161 parameter for the distribution. 162 We tested three different scenarios for surveillance intensity changes over time, modeled as 163 the detection probability, : 174 We fit the daily case count function and the death count function to incidence data Ψ( ) Φ( ) 175 and daily death data to infer the exponential growth rate of the infection , the initial number ( ) 176 of total infected individuals at time, and the detection probability ( ). Other parameter values 177 are fixed according to previous estimates (see Table 1 ). We assumed that the data were negative 178 binomial distributed conditional on the model and inferred parameters by maximizing the 179 likelihood function using standard methods. 180To compare between models, we calculate the Akaike Information Criterion (AIC) score for 181 each model as (Burnham and Anderson, 2002):= 2 -2 (5) 182 where is the number of fitted parameters and LL is the log likelihood of the model. The model 183 with the lowest AIC score is the best model. A model is significantly worse than the best model 184 if the difference between their AIC scores is greater than 2 (Burnham and Anderson, 2002 197 where and are the mean latent and infectious periods, respectively, and and are the 1/ 1/ 198 shape parameters for the gamma distributions for the latent and the infectious periods, 199 respectively. 200 We set the mean latent period, , to vary between 3 and 4 days. This is based on that the 1/ 201 incubation period is estimated to be between 5-6 days (Backer et al., 2020; Lauer et al., 2020; 202 Sanche et al., 2020) and infected individuals become infectious approximately 2 days before 203 symptom onset . 204 We set the mean infectious period, , to be between 6-8 days to be consistent with the 1/ 205 estimated mean serial interval, i.e. the mean time interval between symptom onsets of an index 206 case and secondary cases in transmission pairs, of 6-8 days (Bi et al., 2020; Lavezzo et al., 2020;  207 Thompson et al., 2020) . See the Discussion section for a discussion of the estimates of the serial 208 interval. We note that this range of infectious period is also consistent with the findings that 209 infectious viruses can be recovered during the first week of symptom onset (and up to 9 days 210 post symptom onset) Wolfel et al., 2020) . 211 To quantify the uncertainty of , we assumed that m=4 and n=3 similar as in our previous 0 212 work . We assume that the exponential growth rate, , varies in the range 213 estimated from the data. The parameters are assumed to be mutually independent and we ( , , ) 214 generate random samples from uniform distributions according to ranges of variations defined 215 above to compute the resulting . We generated parameters, and then computed their 0 10 4 216 respective using Eq. (7). We used the 97.5% and 2.5% percentile of the generated data to 0 217 quantify the 95% confidence interval. 218 219 2.6. Calculation of the level of population immunity after mass vaccination 220We assume a gamma distribution for the duration of protective immunity induced by a 221 hypothetical vaccine to SARS-CoV-2 in a population. Let be the mean duration, and s be the 222 shape parameter of the gamma distribution. For simplicity, we assume that the durations of the 223 immunity induced by natural infection and vaccination are the same. We further assume that the 224 percentage of protected population reaches to 85% after every mass vaccination with the 225 hypothetical vaccine. Note that this is likely to be an optimistic scenario . The 226 fraction of population that are immune to SARS-CoV-2 at time after a mass vaccination can * 227 then be expressed as , where is the cumulative density function of the 85% × (1 -C( * )) C( * ) 228 gamma distribution for the duration of population immunity. Based on this expression, we 229 calculate the time when the population immunity reaches to the herd immunity threshold value 230 by solving for . The solution for is the maximum time 85% × (1 -C( * )) = 1 -1/ 0 * * 231 interval between two vaccinations to maintain herd immunity in a population. 232 233234 3.1. Estimation of the epidemic growth rate and surveillance intensity 235 Using our simplified SEIR-type (susceptible-exposed-infected-recovered) model (see 236 Methods and Supplementary Text for details), we fit both the case incidence data and the daily 237 death count data to estimate the epidemic growth rate and the detection probability, i.e. the 238 probability that an infected person is identified, before interventions were implemented in eight 239 European countries and the US. The exponential growth rates of early outbreaks, r, range 240 between 0.19 and 0.29/day in the nine countries, translating to doubling times between 2.4-3.7 241 days (Fig. 1) . Spain and the US had the highest estimated growth rates, at 0.29/day and 0.28/day, 242 respectively; whereas Switzerland and Netherlands had the lowest estimates at 0.19/day and 243 0.18/day, respectively. Evaluating uncertainties in these estimates (see Methods), we found that 244 the epidemic growth rates are highly constrained by the time series data despite variations in 245 parameter values in the model (Fig. 2A) . 246 We estimated that the detection probability, i.e. the fraction of infected individuals who are 247 detected by surveillance, was likely to be low (<30%) across the countries examined except for 248 Germany. The point estimate of the detection probability in the US is 12%, i.e. approximately 1 249 in 8 infected individuals were detected, similar to a recent estimate using influenza like illness 250 data . This is likely due to the high percentage of infected individuals 251 with no or mild-to-moderate symptoms (Mizumoto et al., 2020; Zou et al., 2020) , which are 252 difficult to detect through passive surveillance systems. The detection probability is higher in 253 Germany (with a point estimate of 58%) than in other countries, providing an explanation of the 254 high number of reported cases compared to the relative low number of deaths in Germany during 255 March 2020. Overall, there exist large uncertainties in our estimation of the detection probability 256 (Fig. S1 ) due to the uncertainties in the fixed parameter values assumed in the model, such as the 257 infection fatality ratio. 258Changes to the detection probability over time, e.g. as a result of changes in testing, could 259 lead to an apparent increase or decrease in case count and biases in inference. We considered two 260 scenarios involving increases in testing over the study period (see Methods for the mathematical 261 formulations), and found no statistical evidence that case counts during the relatively short 262 period for which we perform inference are strongly impacted by changes in surveillance intensity 263 (Table S2 ). While it is highly likely that the probability of a case being detected increased over 264 the period where testing was becoming available, our analysis excluded data from that period. As 265 shown in Fig. 1 , the red, open circles indicate data outside of the study period. Most countries 266 show a pattern of very rapid increase in detected cases in the very early epidemic period that is 267 likely the result of both a growing epidemic and increasing availability and use of testing. 268 269 3.2. Implications of fast epidemic growth for public health intervention strategies 270Using our empirical estimates of the growth rates, we explored the implications for public 271 health efforts to control the COVID-19 outbreak. We considered an outbreak scenario in a large 272 city with a population of 10 million. We first calculated the total fraction of infected individuals 273 after a year, assuming only one infected individual at day 0. If our goal is that the total fraction 274 of infected individuals is less than 10% after a year, the growth rate has to be reduced from 0.2-275 0.3/day to less than 0.03/day (Fig. 2B ). This suggests that moderate social distancing efforts will 276 be insufficient to prevent the virus to infect a large fraction of the populatino. On the other hand, 277 if the targeted growth rate, i.e. 0.03/day, is achieved through very strong public health 278 interventions, then a lower rate may also be attainable. The benefits of a small decrease below 279 the threshold are significant, as the total infected fraction decreases exponentially when r 280 decreases beyond 0.03/day as shown in Fig. 2B . 281To corroborate the results above, we calculated the intervention efforts needed for three 282 hypothetical goals: 1) containment (i.e. the size of epidemic decreases), 2) 1% of the population 283 is infected one year after the intervention, and 3) 10% of the population is infected one year after 284 the intervention. Efforts needed for each goal are similarly high, especially when the population 285 of infected individuals is already more than 1000 (Fig. 2C) . For example, when an outbreak 286 grows at rate 0.29/day (as we estimated for the US), the levels of efforts needed to achieve the 287 three goals are between 80% and 82% reduction in transmission; whereas when the growth rate 288 is 0.19/day, the levels of effort needed are between 70% and 73% reduction. Regardless of the 289 heterogeneity in the growth rates, the force of infection must be significantly reduced, arguing 290 for strong and comprehensive intervention efforts. 291 292 3.3. Estimating the basic reproductive number, R 0 293We computed the basic reproductive number, R 0 , for each country following the approach of 294 Wearing et al. (Wearing et al., 2005) , which uses as input the estimated growth rate, and the 295 durations of the latent and infectious periods. We assumed that the duration of the latent period 296 (i.e. the period between infection and becoming infectious) and the infectious periods to be 3-4 297 days and 6-8 days, respectively (see Methods for justification of these parameter ranges). These 298 choices of parameters are consistent with the estimated mean serial intervals of 6-8 days (Bi et 299 al., 2020; Lavezzo et al., 2020; Thompson et al., 2020) . Note that some estimates of the mean 300 serial intervals are shorter (Du et al., 2020; Ganyani et al., 2020; Nishiura et al., 301 2020) . These shorter serial intervals are a result of intensive intervention efforts to rapidly isolate 302 infected individuals (Ali et al., 2020; Bi et al., 2020) , and can be useful in estimating effective 303 reproductive numbers in places where intensive isolation efforts are implemented. However, for 304 the purpose of estimating the basic reproductive number, R 0 , and the herd immunity threshold (in 305 the next section), the mean serial interval in the absence of isolation effort, i.e. 6-8 days, shall be 306 used. In the Discussion, we present a more complete argument that for the choice of the duration 307 of the mean serial interval. 308Using the estimated ranges of the growth rates for each country, we estimated that the US 309 and Spain had highest median R 0 s at 5.9 (CI: 4.7-7.5) and 6.4 (5.2-8.0), respectively ( Fig. 3 and 310 Table 2 ). For the other countries, we estimated the median R 0 ranges between 3.5 and 4.7 (Fig. 3  311 and Table 2 ). 312 313 3.4. Implications for vaccination strategies 314From the range of median R 0 estimated above, we first calculated the fraction of individuals 315 needed to be immune in a homogenous population such that an outbreak stops growing. This 316 fraction is given by the classical result, 1-1/R 0 . We refer to this term 317 as the 'classical herd immunity threshold', which spanned between 71% and 84% for the 318 countries considered here (Table 2) . We note that recent works show that due to population 319 heterogeneity, the herd immunity threshold induced by disease transmission may be lower than 320 the classical threshold predicted by 1-1/R 0 (Britton et al., 2020; Gomes et al., 2020). However, 321 the herd immunity threshold through random vaccination stays at 1-1/R 0 . 322Multiple lines of evidence suggest that the protective immunity may not be long lived for 323 SARS-CoV-2 (Long et al., 2020; Seow et al., 2020). Thus, we further considered how a vaccine 324 with waning protection could be used to combat COVID-19 given our estimated levels of R 0 (see 325 Method). We assumed that vaccination achieves 85% population immunity in a population. This 326 is an optimistic scenario. For example, with a protective efficacy of 94%, the coverage has to be 327 greater than 90% to achieve 85% population immunity. If this level of immunity is not achieved, 328 for example, due to low vaccination coverage or low protective efficacy, we 329 may not reach herd immunity through vaccination for places where R 0 is estimated to be around 330 6, e.g. the US and Spain. In the model, we assumed a gamma distribution for the duration of 331 protective immunity induced by a hypothetical vaccine in a population, where s is the shape 332 parameter of the gamma distribution (Fig. 4A) . 333 If the duration of protective immunity from the vaccine follows an exponential distribution, 334 (i.e. when ), a sizable fraction of individuals lose immunity rapidly, leading to a loss of = 1 335 herd immunity shortly after the initial vaccination program, especially when R 0 is large and the 336 herd immunity threshold is high (Fig. 4B) . Consequently, the time between vaccinations required 337 to maintain herd immunity is much shorter than the mean duration of protective immunity (Fig.  338 4C) . For example, even if the mean duration of protective immunity is 10 years, vaccination 339 must occur every 2.4 month and 2.4 years to maintain herd immunity when R 0 is 6 and 3, 340 respectively (see the red lines in Fig. 4C ). On the other extreme, when s is very large (Fig. 4A,  341 ), individuals in the population have identical durations of protective immunity. In this = ∞ 342 case, herd immunity persists for a long period of time before the fraction of immune individuals 343 suddenly drops to a very low level (Fig. 4B) . In this case, herd immunity can be kept at a 344 duration similar to the mean duration of protective immunity irrespective of R 0 (see blue lines in 345 Fig. 4C ). 346The reality of an imperfect vaccine is likely to be between these two extremes. When we 347 assume , the distribution becomes more Gaussian-like (Fig. 4A) where some people lose = 10 348 protective immunity faster than others, but that heterogeneity is relatively low. If a mass 349 vaccination achieves 85% immunity in a population and protective immunity lasts on-average 350 around 45 weeks to 1 year (Long et al., 2020) (consistent with the duration of immunity induced 351 by endemic coronaviruses (Callow et al., 1990; Kissler et al., 2020) ), then vaccination will need 352 to occur once a few months (Fig. 4C ). If the mean duration of protective immunity is around 3 353 years as observed for the antibody response to SARS-CoV-1 or MERS-CoV , 354 vaccination once a year or once two years will be sufficient, if R 0 is 6 or 3, respectively (Fig. 4C) . 355 If the mean duration of protective immunity is greater than 10 years (for example, a long T cell 356 immunity to SARS-CoV-1 is observed in individuals recovered from SARS-CoV-1 infection (Le 357 Bert et al., 2020)), the time interval between repeated vaccinations becomes longer than 4 years 358 or 7 years when R 0 is 6 or 3, respectively. 359 360In this work, we report rapid COVID-19 epidemic spread before broad control measures 362 were implemented in the US and in the eight most affected countries in Europe during March, 363 2020. We further estimated that R 0 values range between 3.5 and 6.4 in these countries, which 364 means high herd immunity thresholds between 71% and 84%. Together with our previous 365 estimates for the outbreak in Wuhan , these results are consistent with 366 SARS-CoV-2 being highly transmissible irrespective of heterogeneities in geographic and social 367 settings and emphasize the necessity of strong control measures, such as social distancing. A 368 high level of coverage of effective vaccines are needed to achieve herd immunity. We further 369 show that the heterogeneity of individual-level protection provided by a vaccine is an important 370 factor in determining the frequency of vaccinations. 371Awareness of the extraordinary high rates of COVID-19 spread in the absence of control 372 measures is critically important for epidemic preparedness. The short doubling times of the 373 epidemic means that health care systems can be overwhelmed in a couple of weeks rather than 374 several months in the absence of control . For example, a report shows that the 375 number of COVID-19 patients admitted to intensive care units in Italy during February and early 376 March 2020 grew at a rate of approximately 0.25/day during early epidemic (Grasselli et al., 377 2020) . We estimated that the SARS-CoV-2 outbreaks grew extremely rapidly at rates between 378 0.18 and 0.29/day, in eight European countries and the US. These estimates for European 379 countries are in general consistent with other studies using different approaches and different 380 sources of data (Dehning et al., 2020; Flaxman et al., 2020; Pellis et al., 2020). We further show 381 that because of the high transmissibility of the virus, moderate control efforts will not 382 sufficiently slow the virus spread to achieve measurable public health benefits. This may explain 383 the continuous growth of the outbreak in some countries despite measures, such as work and 384 school closures, were in place. To delay the peak or to reverse the growth of the epidemic with 385 non-pharmaceutical interventions, strong and comprehensive intervention efforts, such as wide-386 spread testing, isolation and quarantine, use of personal protective equipment, and social 387 distancing, may be needed. 388While we found remarkably high rates of epidemic growth in all the examined countries, we 389 caution that our inference is largely driven by data collected from highly populated areas, such as cases and 1286 of their close contacts in Shenzhen, China: a retrospective cohort study. interventions. Science 369, doi:10.1126/science.abb9789. 520 Dorigatti, I., Okell, L., Cori, A., Imai, N., Baguelin, M., Bhatia, S., Boonyasiri, A., Cucunubá, Z., 521Cuomo-Dannenburg, G., FitzJohn, R., al., e., Xi, X., Donnelly, C., Ghani, A., Neil, F., 522 2020. Severity of 2019-novel coronavirus (nCoV). 523(https://www.imperial.ac.uk/media/imperial-college/medicine/sph/ide/gida-524 fellowships/Imperial-College-COVID19-severity-10-02-2020.pdf; accessed Mar 30, 525 2020). ",United States,abstract,2021-02-13,02
5e2b99344feee5f260dec198f6a8b871f78bc4a2,Journal Pre-proof Implications of Inadequate Water and Sanitation Infrastructure for Community Spread of COVID-19 in Remote Alaskan Communities Implications of Inadequate Water and Sanitation Infrastructure for Community Spread of COVID-19 in Remote Alaskan Communities,"Coronavirus disease 2019 is caused by a novel pathogen (SARS-CoV-2) that emerged from a zoonotic reservoir to infect humans in late 2019 in Wuhan, China, spreading across the globe by mid-summer 2020 through efficient human-to-human transmission (Lu et al., 2020; Zhu et al., 2020) . The COVID-19 pandemic has brought renewed attention to the importance of water and sanitation infrastructure to protect human health, and the global inequities that exist in household water security (e.g. Staddon et al., 2020) . Access to piped water and sanitation infrastructure likely reduces the transmission of SARS-CoV-2 by facilitating 2020). While robust immune responses, including antibody and T cell mediated memory responses, are generated even in mild infections, the duration and efficacy of immune responses upon secondary challenge are poorly understood (Altmann and Boyton, 2020) . At present, a number of novel vaccines against SARS-CoV-2 have been granted emergency use authorization after completing clinical trials, and vaccination has begun in the US, Europe, and India (Bhuyan 2021; Karpiński et al., 2021; Mellet and Pepper, 2021; Krammer, 2020) . The effect of vaccination on mitigating community spread of SARS-CoV-2 is anticipated over the next year, however, new more transmissible variants of the virus have arisen that may prolong the pandemic and increase rates of hospitalization (Galloway, 2021) .The transmission of most genotypes of SARS-CoV-2 is characterized by the basic reproduction number (R 0 ) of 1.40-6.49, which is comparatively higher than that of other severe betacoronaviruses (SARS-CoV, MERS-CoV) and influenza viruses (Petersen et al., 2020; Rahman et al., 2020) . While not completely understood, it is thought that the transmission of SARS-CoV-2 occurs through multiple mechanisms including cough/sneeze droplets from an infected person, contact with body parts or clothes of infected persons (Hijnen et al., 2020) , contact with surfaces contaminated with SARS-CoV-2 due to settled droplets (Chia et al., 2020) , and by microaerosols produced from respiratory droplets of infected persons due to sneezing, coughing, In some human cases, SARS-CoV-2 can infect the gastrointestinal (GI) tract (Villapol, 2020; Lei et al., 2021) . The live virus can be excreted into wastewater (raw sewage) (Tran et al., 2020) , and SARS-CoV-2 has been reported in river water (Quito, Ecuador) that received untreated sewage (Guerrero-Latorre et al., 2020) . However, the role of contaminated wastewater in the risk, spread, and persistence of COVID-19 in communities is poorly understood . SARS-CoV-2 has been found to retain a degree of viability in fecal matter, and viral RNA has been routinely detected in wastewater (Arslan et al., 2020; Bivins et al., 2020) . Urban wastewater processing is thought to be generally refractory to survival of live SARS-CoV-2, although non-infectious remnants of viral RNA have been found to persist in wastewater Medema et al., 2020) . In rural Alaska, unprocessed waste disposal methods may increase the duration of live virus persistence and risk of human contact with the virus in wastewater. The approach to understand the spread of a disease in any given community/watershed by testing for its signal in municipal wastewater is known as wastewaterbased epidemiology (WBE). It has previously been employed to investigate the incidence of poliovirus (Lodder et al., 2012) , norovirus (Kazama et al., 2016) and detect other community-or watershed-level activities including use of pharmaceuticals and personal care products, consumption of narcotics, and exposure to pesticides (Choi et al., 2018; Lorenzo and Picó, 2019 ). Thus, raw or even processed wastewater is a potentially important environmental signal for COVID-19 infection in the humans in a community D. Lu et al., 2020; Mao et al., 2020; Murakami et al., 2020) .SARS-CoV-2 can infect the gastrointestinal (GI) tract and cause intense GI and hepatobiliary symptoms (D'Amico et al., 2020) . Although the fecal-oral transmission of SARS-CoV-2 has not J o u r n a l P r e -p r o o f been reported to date, recent studies detected SARS-CoV-2 in the feces of an infected person (Kim et al., 2020; Xiao et al., 2020) . The related SARS-CoV exhibited transmission by a fecaloral route (Esper et al., 2010; Isakbaeva et al., 2004; Jevšnik et al., 2013) . During the SARS outbreak in 2003, aerosolized SARS-CoV particles from floor drains spread into the bathroom of an adjacent apartment building (in multi-unit housing) (McKinney et al., 2006) . Similar transmission of aerosolized SARS-CoV-2 from a bathroom where an infected person took a shower has also been recently reported (Hwang et al., 2021) . In addition, the presence of RNA fragments of SARS-CoV-2 in feces, anal swabs, and urine from infected persons has been reported widely (Chen et al., 2020; Kipkorir et al., 2020; Peng et al., 2020) . While these studies indicate a serious concern about the capability of SARS-like coronaviruses to spread via wastewater and suggest the possibility of a fecal-oral route of transmission for SARS-CoV-2, as of the time of this writing, this mode of transmission has not been implicated in the spread of COVID-19 outside of hospital settings (D'Amico et al., 2020).The state of Alaska has reported more than 52,000 laboratory-confirmed cases of COVID-19 (7% incidence in the population), and suffered 277 deaths, as of 2 nd February, 2021, with spread of the virus to every urban and most rural regions of the state (DHSS, 2021) . In response to the pandemic, capacity for wastewater sampling, laboratory processing, and validation of a COVID-19 PCR detection assay was developed at the University of Alaska. SARS-CoV-2 RNA was detected in a major community in interior Alaska in July 2020, corresponding to an increase in the epidemic curve in human COVID-19 cases. SARS-CoV-2 RNA has also been detected in several smaller, isolated communities in Alaska, in a trend that mirrors the number of human cases (B. Briggs, E. Bortz, pers. comm.; data not shown). These preliminary studies suggest the J o u r n a l P r e -p r o o f utility of this method as an environmental signal for SARS-CoV-2 prevalence to detect unrecognized COVID-19 cases in the community. Genomic tracking of SARS-CoV-2 in wastewater is also possible with application of advanced next-generation sequencing (short read NGS) technology, and has been found to mirror the human diversity of genome variants in the community (Crits-Christoph et al., 2020) . New diagnostic assays for targeted genome sequencing of SARS-CoV-2 using short-read or nanopore NGS technology are also being developed (E.Bortz, pers. comm.; data not shown), to broaden community wastewater surveillance, and generate an early signal of the incidence of new variants of SARS-CoV-2 such as the more transmissible B.1.1.7 lineage (Galloway, 2021) .Alaska is characterized by a widely dispersed population with more than 60,000 people living in remote communities of fewer than 1,000 residents that are located off the road system and are only accessible by plane or boat. Many of these communities are predominately Alaska Native.From 2006 to 2010, the poverty rate among AI/AN communities in tribal areas was 1.8 times the United States average (32% vs 18%) (Pindus et al., 2017) ., and the rates of unemployment were also significantly higher. Such socio-economic factors impact the risk of transmission of SARS-CoV-2 as well as disease implications after transmission has occurred in rural Alaska (Table 1) .It is sometimes said that there is little homelessness in remote Alaska because families move in together, creating multi-generational, multi-family households. In remote Alaska, 25-40% of households are overcrowded, compared to the national average of less than 5% (Wiltse and Madden, 2018) . According to the United States Department of Housing and Urban J o u r n a l P r e -p r o o f Development's (HUD), an ""overcrowded"" home is defined as having more than one person per room (Blake et al., 2007) . Home overcrowding in rural Alaska presents challenges to limiting the spread of the virus once a family member becomes ill with COVID-19. The lack of space restricts the isolation of these family members exposing additional family members to the virus (Table 1) .Remoteness leads to both isolation from services and the necessity for intrastate travel for those services and economic and subsistence activities. For example, hunting, fishing, and gathering food and water, activities that depend on collective labor and inter-village travel, are essential for household food security, social connection, and cultural wellbeing. Residents also make regular trips to larger communities to purchase food, fuel, and other household needs at lower prices.Additionally, many residents in the rural communities are employed in seasonal or shift work that requires intrastate travel from their homes to fisheries, mines, oil fields, and other distant/remote workplaces. For example, more than 70% of workers in the North Slope Borough (NSB) come from another borough or census area within Alaska (Krieger, 2019) because the well-paid jobs in the oil and gas industry in NSB attract Alaskans from all over the state. Many of these workplaces also employ labor from outside Alaska (about 20% of all workers in Alaska are nonresident; Krieger (2019)) presenting an additional exposure and transmission risk to rural Alaskans as village residents travel between work and home.Furthermore, the hub-and-spoke tribal healthcare system requires patients to travel regionally for medical care that is unavailable at local clinics. Regional ""hub"" communities have larger populations (several thousand) compared to smaller surrounding villages and serve as the centers for primary health care and transportation services in their respective regions. Patients requiring J o u r n a l P r e -p r o o f more specialized medical care or hospitalization usually must travel on commercial airplanes to nearby cities (e.g., Anchorage, Fairbanks). COVID-19 outbreaks in remote Alaskan communities with inadequate medical facilities places a heavy burden on local commercial air carriers that may only land at some communities a few times per week. As an extreme example, transportation to and from the community of Little Diomede, Alaska is limited to a few months in the summer by small boats when the Bering Strait is free of sea ice, in the winter when planes can land on the sea ice, and the rest of the year by helicopter. Moreover, several air carriers that serve remote Alaska have taken a heavy financial blow due to COVID-19-related travel restrictions, further limiting transportation options to larger medical facilities.Like many communities across the Arctic, the remoteness of Alaskan communities provided some protection from transmission during the early stages of the pandemic, as city and tribal governments were able to limit travel in and out of their communities (Bennett, 2020) . As the pandemic progressed, and travel restrictions were eased (Kitchenman, 2020) , cases of COVID-19 began to rise in Alaska's remote regions (Hollander et al., 2020) . Although regional and community-led efforts to limit non-essential travel into and between remote villages have been in place, limitations in testing capabilities as well as legal limits on enforcement have impeded the ability of communities to avoid the introduction of SARS-CoV-2 into communities. For example, in late October 2020, the western Alaska village of Chevak (pop. ~1,000 residents) reported a sudden surge in cases with nearly 20% of population infected with SARS-CoV-2 virus (Kim, 2020) . By late November 2020, all rural regions in Alaska were reporting ""high"" (>10 cases/100,000) 14-day averaged daily case rates, with Yukon Kuskokwim-Delta region reporting a case rate around 150 per 100,000 (DHSS, 2020b).Over 3300 homes in more than 30 of the 190 remote Alaskan communities lack in-home piped water and sewer services, and another 16 are considered ""underserved"" with 20-50% of homes lacking connection to piped services (ADEC, 2013; DHSS, 2020a) . Additionally, a report by Pettit (2014) points out that 18% of AI/AN households in selected AI/AN counties in Alaska had incomplete plumbing and 15% lacked complete kitchen facilities. Residents of unplumbed homes either receive treated water through a closed truck haul service, or they self-haul water in limited amounts from a local watering point or washeteria (usually 5-30 gallons at a time) on foot using a wheelbarrow or sled or by snow machine or four-wheeler (Fig. 1A) . In self-haul households, household water quantity used is typically less than 5 gallons per person per day (gpcd) (Eichelberger, 2018; Mattos et al., 2020; Thomas et al., 2016) , far less than the WHO recommendation of 13.2 gpcd for intermediate water access (Howard and Bartram, 2003) . A recent study found that 80% of participating households (out of 43 homes in two remote, rural, unpiped communities in Alaska) reported reusing washbasin water an average of 3 times before changing the water (Mattos et al., 2020) , which may increase pathogen exposure (CDC, 2020).Limited access to water in remote Alaskan communities contributes to a significantly higher risk of respiratory infections (Hennessy et al., 2008; Mosites et al., 2020) . For example, compared to regions with greater coverage of in-home plumbing, hospitalization rates of children living in unplumbed communities is 3.4 times greater for respiratory syncytial virus (under the age of 5 years) and 30% higher for pneumonia among infants (Hennessy et al., 2008) .Reliable access to clean water and sanitation services in both piped and unpiped communities is challenged by environmental factors, including extreme cold, permafrost, andincreasinglyclimate change (Brubaker et al., 2011; Eichelberger, 2019; Sohns et al., 2020) . For example, utility systems in remote cold region communities face additional challenges because of J o u r n a l P r e -p r o o f continuous and discontinuous permafrost, warming winter conditions that lead to ground instability on the surface and subsurface, warming-induced degradation of permafrost that leads to operation and maintenance issues, high costs of maintenance, and risks for waterborne diseases due to potential breach of water mains (Smith, 1996) . In addition to the damage to piped water and sewer infrastructure, climate change is also contributing to problems such as poor water quality, high turbidity, and loss of raw water sources (Cozzetto et al., 2014; Melvin et al., 2017) .For many in unplumbed homes, central community facilities, or ""washeterias"" (Fig. 1E ) provide a critical access point for access to treated water, showers, and laundry (often for a fee). These buildings are usually attached to or housed within the water treatment plant. Several washeterias in rural Alaska have outstanding repair needs but the state and federal support to address such needs has been shrinking over the years (e.g., ADEC, 2013) . Many operate at a deficit because of operational costs involved. Others, such as the facility in Newtok, Alaska, are unable to provide service due to inadequate community energy infrastructure (Eichelberger, 2019) . Since the start of the COVID-19 pandemic, those who manage washeterias have had to limit access to maintain social distancing. Under conditions of limited access for laundry, households share household washers and dryers thereby increasing their social contacts (Eichelberger, 2019 (Eichelberger, , 2011 (Eichelberger, , 2010 Jepson et al., 2017 ) -a practice that may increase the potential for exposure to SARS-CoV-2.In unpiped communities where pit latrines (""outhouses"") are not feasible (due to environmental factors such as high groundwater tables and permafrost), residents use 5-gallon bucket latrines (known as ""honey buckets"") ( Fig. 1B) and manually dispose of the collected human waste in J o u r n a l P r e -p r o o f centralized collection containers known as hoppers (Fig 1C) or directly in minimally controlled dumps or sewage lagoons (Fig. 1D ). Many homes lack delineated bathrooms to defecate or practice personal hygiene privately. Honey buckets may sit in the entryway separated by a door to the outside and interior, or in the corner of a room separated by a sheet or curtain from the rest of the room. Particularly in communities without collection services, bags of human waste often accumulate outside of homes for days or weeks while they await transport to the dump or honey bucket lagoon. Mattos et al. (2020) , in their study of two unplumbed remote Alaskan communities, found that bags of sewage sit outside of homes an average of 4-13 days, depending upon the season. It is common for bags to break or get ripped open by animals, spilling their contents near homes.Collected waste can also be spilled during transport to hoppers or dumps, exposing the population to raw sewage from across the community (Chambers, 2008; Chambers et al, 2009 ).These hoppers also leak as they are often conveyed to the dump off the main pathways like board walks to avoid spilling to trafficked areas but resulting in spills adjunct to these areas. The lack of proper sanitation facilities and manual transport of human waste in rural Alaska could thus pose a potential infection risk via water or aerosol pathway (Bogler et al., 2020) , though there is no evidence yet for fecal-oral transmission of SARS-CoV-2 (D' Amico et al., 2020) .Similarly, households that haul their water must also manually dispose of their greywater.Residents typically collect greywater in a basin or slop bucket (Fig. 1F) and dump it in a convenient place outside of the home, often on the ground not far from foot and vehicle pathways. Some households connect a floor pipe to their sinks and dispose of the water on the ground underneath their raised foundation. It is possible that pathogens in greywater can then be picked up by individuals who come into direct contact with the disposal areas (Chambers et al., J o u r n a l P r e -p r o o f Journal Pre-proof Fig 2. Additionally, the sanitation practices associated with sewage collection and disposal discussed here can lead to comorbidities or pre-existing conditions that can impact the severity of COVID-19.The COVID-19 pandemic has highlighted the long-standing inequities in Indigenous communities throughout the United States (Hathaway, 2020; Kakol et al., 2020; van Dorn et al., 2020; Wilder, 2020) , including in water and sanitation infrastructure. By July 2020, tribal communities in the contiguous United States had over four times the incidence of COVID-19 cases compared to the rest of the United States with much of this discrepancy likely due to lack of indoor plumbing (Rodriguez-Lonebear et al., 2020) . The Navajo Nation experienced a high death rate per capita early in the pandemic, exacerbated by the lack of safe water sources on the reservation (Abou-Sabe et al., 2020) . Temporary hand washing stations, strict stay-at-home curfews, widespread mask usage, and substantial testing efforts have helped limit continued spread of the virus, but long lines at water filling stations and water rationing limit people's ability to take basic precautions against transmission of SARS-CoV-2 and other pathogens (Abou-Sabe et al., 2020; James, 2020) .In Alaska, community leaders recognized early the need to mitigate water insecurity to prevent the spread of SARS-CoV-2 in their communities. Regional entities and tribal health organizations worked together to bulk order and distribute hand sanitizer, bleach, and other sanitary supplies to remote communities. In the Northwest Arctic Borough, special efforts were made to prioritize the distribution of hand sanitizer to homes without indoor plumbing. Tribal health organizations circulated instructions (e.g., YKHC, 2020) to water plant operators for how to make household bleach, which was distributed free of charge to community members. The J o u r n a l P r e -p r o o f state of Alaska also distributed high numbers of personal protective equipment (PPE) kits, gloves, and surgical and respiratory masks (Krakow, 2020) .Furthermore, the COVID-19 pandemic has brought attention to the human right to water and sanitation. Water and sewer utilities in Western Alaska have waived fees to encourage residents to use more water for hygiene and to facilitate sanitary disposal of waste (KYUK, 2020) . In March 2020, the Alaska Rural Utility Collaborative began reconnecting homes that had been disconnected from running water services due to nonpayment. Others have used CARES Act funding to subsidize water and sewer bills, to provide short-term and intermediate handwashing stations and dry toilets to unpiped households, and to build new homes that include in-home water and sanitation systems (Eurich 2020; D. Beveridge, ANTHC, pers. comm.) . Some communities had to endure long wait times to get allocations of CARES Act funding that was primarily being planned to be spent toward improved water and sanitation infrastructure (Kirk 2020 ).Considering the unique challenges faced by rural Alaska during the COVID-19 pandemic, efforts to enhance water, sanitation and hygiene access in remote communities need to be renewed and increased at the local, regional, state, and federal levels. Stakeholders across remote Alaska have made diligent efforts to reduce disease transmission, increase sanitization efforts, and reduce risk, but the threat of COVID-19 outbreak in remote communities is still very high and the consequences will have significant and far-reaching impacts on the people living there. The provision of in-home plumbing infrastructure, suitable community facilities, adequate healthcare, and appropriate financial support would help protect isolated communities get through the current pandemic and provide vital infrastructure necessary for community health under normal conditions. As we continue to navigate in unknown waters and shift to rebuilding, we hope that Zhu, N., Zhang, D., Wang, W., Li, X., Yang, B., Song, J., Zhao, X., Huang, B., Shi, W., Lu, R., others, 2020. A novel coronavirus from patients with pneumonia in China, 2019. N. Engl. J. Med. 382, 727-733. Table 1 . Socio-economic, geographic, and environmental factors that may influence the transmission and spread of SARS-CoV-2 in rural Alaska. Factors Effect Socio-economic  Overcrowded homes make social distancing more challenging, lead to larger and more susceptible social bubblescontributing to easier viral transmission and spread.  Overcrowding also restricts the isolation or quarantine of exposed and infected individuals.  Mining and oil industries attract individuals from within and outside Alaska, which increases overall travel, and thus the risk of SARS-CoV-2 transmission.  Unemployment, poor economic conditions, and reduced state/federal support restrict access to medical facilities and water and sanitation services. Geographic  Necessity of travel for some health services at regional medical facilities increases the risk of SARS-CoV-2 transmission/spread.  COVID-19 testing and vaccine distribution is more challenging in communities that are geographically isolated.  Development of piped water and sanitation systems are challenged by small, isolated communities and large distances between houses. Environmental  Extreme cold and presence of permafrost restricts the development of adequate water and sewer infrastructure.  Degradation of permafrost due to climatic changes impacts water quality, water sources, and existing piped water and sewer infrastructure. ",United States,first author,2021-02-14,02
cd7c3a028a55259787e14ecd8c9db4b4cf2c44b2,Journal Pre-proof Age-dependent effects of the recombinant spike protein/SARS-CoV-2 on the M-CSF- and IL-34-differentiated macrophages in vitro Age- dependent effects of the recombinant spike protein/SARS-CoV-2 on the M-CSF-and IL-34- differentiated macrophages in vitro Age-dependent effects of the recombinant Spike protein/SARS-CoV-2 on the M-CSF-and IL-34-differentiated macrophages in vitro,"The current COVID-19 pandemic, caused by the novel severe acute respiratory syndrome coronavirus-2 (SARS-CoV-2), is characterized by an overwhelming macrophage (Mφ)-induced cytokine storm, which leads to the mild-to-severe respiratory disease and death caused by pneumonia [1] . Severe symptomatology is more prevalent in males than in females, and both morbidity and mortality are aggravated by age [1] . These differences have been adjudicated to age-and gender-dependent expression of receptors that facilitate the entry of SARS-CoV-2 virus to the cell, along with the age-related co-morbidities [2] .As a characteristic structural component of the virion membrane of SARS and MERS coronaviruses, the Spike protein (S-protein) is responsible for the viral entry into Mφ, by activation of cysteine protease cathepsins [3] . The activated Mφ produces a distinct panel of pro-inflammatory cytokines, including tumor necrosis factor alpha (TNF-α), interleukin-1β (IL-1β) and IL-6, which are collectively termed senescence-associated secretory phenotype (SASP).This Mφ polarization and activation is triggered by the ligation of Macrophage colony stimulating factor (M-CSF) and IL-34, with the CSF-1 receptor [4] . The M-SCF-induced Mφ are highly immunostimulatory, whereas the IL-34 activated Mφ possess immunosuppressive characteristics [5] . Furthermore, M-CSF differentiated Mφ are more susceptible to viral infection and correlate with higher mortality due to viral disease, whereas Il-34 differentiated Mφ is shown to possess elevated resistance to viral infection [6] . Incidentally, the SARS-CoV-2 S-protein binds to the surface proteins on peripheral blood mononuclear cells and induces the production of M-CSF, which then mediates the pro-inflammatory SASP cytokine storm that characterizes severe COVID-19 symptomatology [7] .Although the production of SASPs, which includes pro-inflammatory cytokines and chemokines, senescence-regulatory proteins and lysosomal cathepsins (Cat), by Mφ is well established in various infectious and sterile experimental models of age-related inflammation [8] , the differential effect of the SARS-CoV-2 S-protein on M-CSF-and IL-34Mφ remains elusive in the context of age and gender. Thus, this study aimed to evaluate the age-and sex-dependent effects of the SARS-CoV-2 recombinant S-protein on the expression of pro-inflammatory cytokines (TNF-α, IL-1β, IL-6, macrophage migration inhibitory factor (MIF)), nuclear senescence-regulatory proteins (Hmgb1, p53, p21), and cathepsins (CatB, CatL and CatK) using M-CSF and IL-34 primed bone marrow derived macrophages, as a potential in vitro experimental model of COVID-19/SARS-CoV-2.Bone marrow derived macrophages (BMDMs) were isolated from the femurs and tibias of young The intracellular activities of cathepsin B, L and K were evaluated using the Magic Red™ Cathepsin (Immunochemistry Technologies, Bio-Rad) kits, following the manufacturer's recommended protocol. Images were acquired with a Zeiss LSM780 confocal microscope.The collected data were analyzed using the Student's t-test for the comparison between two groups, or a one-way ANOVA with post hoc Tukey's test for the comparisons among different groups. A p < 0.05 was considered statistically significant. Data were analyzed using Sigma Plot v.14 software.To the best of our knowledge, the S-protein significantly elevated expression of Tnf-α, Il-1β, Il-6and Mif RNAs in aged male M-CSF-Mφ (Fig 1A-C, Suppl. Fig. 1 ), whereas only Tnf-α, Il-1β and Il-6 were overexpressed in young male Mφ (Fig 1A-C) . In contrast, IL34-Mφ from old male mice showed an anti-inflammatory effect, with inhibition of Tnf-α and Il-6 ( Fig 1G, I) , while inhibition of Il-1β and Il-6 were observed in IL-34-Mφ from young male mice (Fig 1H-I) . These data indicate that the S-protein increased the expression of SASP cytokines in M-CSF-Mφ while decreasing it J o u r n a l P r e -p r o o f in IL-34-Mφ, from male mice. For young and aged female MCSF-Mφ exposed to the S-Protein, no significant fluctuations in the expression of the Tnf-α, Il-1β, Il-6 and Mif genes were observed (Fig 2; Suppl. Fig. 1) . Furthermore, only a significant increase in the expression of Il-1β (Fig 2I) was detected in young female IL-34 Mφ, whereas no changes were observed in any of the reported cytokines in aged female IL34-Mφ. These data corresponded to a recently published observation showing that high serum levels of TNF-α and IL-6 have been identified in the COVID-19 patients, with IL-6 being significantly higher in critically ill patients [9] ; however, the gender or age distribution of these data have not been reported. Additionally, in COVID-19 patients, M-CSF, but not IL-34 expression, has been assessed, and found to be elevated [10] .Although, M-CSF and IL-34 have been identified in chronic inflammation, their specific contribution to the inflammatory process has not yet been detailed [11] . Our sex and age specific observations in mouse Mφ correlated with statistical findings of high prevalence and severity of COVID-19 symptoms in senior male patients [2, 12] . Additionally, our data clearly demonstrated the expected inflammatory phenotype induced by the SARS-CoV-2 in M-CSF, but not in IL-34, differentiated Mφ.Since the S-protein induced production of pro-inflammatory SASP cytokines from Mφ (Fig 1 and   2 ) and the increased susceptibility of senescent cells to viral infection [13] , we next evaluated the effect of the S-protein on the expression of key nuclear senescence-regulatory proteins, including Hmgb1, p53 and p21, in MCSF-and IL34-Mφ. Exposure to the S-protein induced the overexpression of Hmgb1, p53 and p21, by MCSF-Mφ (Fig 1D-F) , but not in IL34-Mφ, isolated from old and young male mice (Fig 1J-L) . In contrast, Hmgb1 and p21 were significantly overexpressed in young female IL34-Mφ (Fig 2D,F) , but not in MCSF-Mφ. Interestingly, no changes were observed in M-CSF-and IL-34-Mφ from old female mice, which may potentially be affected by the SARS-CoV-2 through different signaling pathways. HMGB1 is a damage associated molecular pattern (DAMP) alarmin, which amplifies senescence-associated J o u r n a l P r e -p r o o f inflammation [14] . Furthermore, HMGB1 is a mediator of the inflammatory cell infiltration to the lungs and contributes to the reprograming of Mφ towards a pro-inflammatory phenotype, which is upregulated in the aging lungs and kidneys [15] . Similarly, p53 and its downstream gene p21 are upregulated in fibrotic lung disease and are known to be activated in response to DNA damage [16, 17] . Furthermore, p53 intervenes in viral activation and has been identified in the bronchial lavage fluid of COVID-19 patients [18, 19] .Numerous studies show cathepsins may facilitate the cellular senescence and aging-associated diseases, including osteoporosis and Alzheimer's disease [20] . Furthermore, CatB and L are activated by the S-proteins from the SARS and MERS coronaviruses to mediate membrane fusion and subsequent release of viral RNA into the host cell [3] . Importantly, CatK is not known to be directly associated with viral infection or replication; however, it does induce production of SASPs, including pro-inflammatory TNF-α, IL-6 and IL-1β cytokines, from Mφ and Mφ-like osteoclast precursors [21] [22] [23] [24] . Thus, we finally assessed the age-and sex-dependent mRNA expression of CatB, L and K, along with their intracellular activity in M-CSF-and IL-34-Mφ exposed to the S-protein using real time PCR and confocal microscopy assays, respectively.In young males, S-protein was found to significantly elevate CatB and CatK genes expression and intracellular activities in M-CSF-Mφ (Fig 1 M, O) , whereas CatL and CatK expressions and activities were increased in IL-34-Mφ (Fig 1Q-R) . Conversely, the expression and activity of (Fig 2P,R) ; however, the expression and intracellular activities of CatB, CatL and CatK in response to S-protein were neither affected in young and old female M-CSF-Mφ nor in old female IL-34-Mφ (Fig. 2) . While the importance of CatB and CatL in the SARS coronavirus-induced inflammation has been reported in previous studies [25] , J o u r n a l P r e -p r o o f this study detected, for the first time, the increased expression and intracellular activity of CatK in M-CSF-Mφ and IL-34-Mφ exposed to the S-protein of SARS-CoV-2. Therefore, further investigations are warranted to elucidate the role of CatK in the age and sex associated severity of COVID-19 symptoms.The mechanisms by which Spike-protein/SARS-CoV-2 induces the expression of inflammatory SASP cytokines, which characterize the severe COVID-19 clinical profile, are still to be determined. These inflammatory cytokines are largely produced by cells of the innate immune response, including Mφ. Hereby, we demonstrate the manner in which the specific age-and sex-dependent proliferation of Mφ induced by M-CSF or IL-34 leads to the distinct gene expression of various SASP markers in response to stimulus by the S-protein of SARS-CoV-2.Significantly higher inflammatory and senescent phenotypes were observed in male M-CSF-Mφ, but not female MCSF-Mφ, which correlate with clinical data suggesting the male prevalence of COVID-19 [12] . Conversely, an anti-inflammatory effect was observed in IL-34 proliferated male but not female Mφ in vitro. IL-34 has been identified as a target of pro-inflammatory microRNA, miR-31-3p, which mediates inflammation in human lung fibroblasts, by inhibiting IL-34, which, in turn, causes flaring of IL-6 and IL-8 production [26] . Interestingly, a mild inflammatory effect and distinct gene expression phenotype was observed in the S-protein stimulated young female IL34-Mφ, which was not the case with old female Mφ. The expression of IL-34 in mild and severe COVID-19 cases should be assessed, with sex and age distinctions, to determine whether IL-34 correlates with SARS-CoV-2 susceptibility. Moreover, IL-34 may be considered a potential therapeutic target for COVID-19 in the male population. Sex and gender related variations in the immune response have been previously reported in SARS-CoV-2 positive J o u r n a l P r e -p r o o f patients [27] . In this context, the current study demonstrates that sex-and age-related variations to stimulus by the SARS-CoV-2 S-protein can also be obtained in mouse models of the disease. ",United States of America,first author,2021-02-03,02
d1a0ca0f89823ae8b3018f3af162ffa2b7df8755,Prior COVID-19 Infection and Antibody Response to Single Versus Double Dose mRNA SARS-CoV-2 Vaccination,"baseline prior to vaccine, after vaccine dose 1, and after vaccine dose 2. We observed that the anti-S IgG antibody response following a single vaccine dose in persons who had recovered from confirmed prior COVID-19 infection was similar to the antibody response following two doses of vaccine in persons without prior infection (P≥0.58). Patterns were similar for the postvaccine symptoms experienced by infection recovered persons following their first dose compared to the symptoms experienced by infection naïve persons following their second dose (P=0.66). These results support the premise that a single dose of mRNA vaccine could provoke in COVID-19 recovered individuals a level of immunity that is comparable to that seen in infection naïve persons following a double dose regimen. Additional studies are needed to validate our findings, which could allow for public health programs to expand the reach of population wide vaccination efforts.Disease 2019 (COVID-19), offers great promise for curbing spread of infection and accelerating the timeline towards a potential level of herd immunity. [1] [2] [3] Amidst ongoing efforts to rapidly deploy vaccinations, challenges to the supply chain have prompted queries around whether single rather than double dose administration may suffice for certain individuals -including those recovered from prior COVID-19 infection. 4 Emerging data from small studies suggest that individuals who have recovered from either a recent or remote COVID-19 infection may have a sustained immunity that could be assessed via measurable antibody response to a single vaccine dose administration. 5, 6 To this end, we evaluated the SARS-CoV-2 antibody response following first and second doses of mRNA vaccination administered in a large and diverse cohort of healthcare workers while specifically focusing on the response in persons with confirmed prior COVID-19 compared to those without prior infection.In a cohort of healthcare workers who received Pfizer-BioNTech vaccination at our medical center in Southern California, 7 we used the Abbott Architect immunoassays (Abbott Park, IL) to quantify circulating levels of SARS-CoV-2 anti-nucleocapsid (N) protein IgG and anti-spike (S) protein IgG at 3 time points: before or up to 3 days after dose 1, within 7 to 21 days after dose 1, and within 7 to 21 days after dose 2. The Abbott anti-S IgG assay is CE marked with anticipated near-future emergency use authorization. Given that a conservative high titer plaque reduction neutralization (PRNT) assay of 1:250 has been correlated to the anti-S IgG cutoff of 4160 AU/mL, we additionally examined the proportion of vaccine recipients who achieved this threshold following administration of one dose or two.All participants provided survey data on medical history, including prior COVID-19 exposures and infection, in addition to data on symptoms experienced after each dose of vaccine. We determined prior COVID-19 infection status and timing in relation to date of the first vaccine dose received, based on concordance of data on COVID-19 diagnosis documented in the electronic health record, presence of anti-N IgG antibodies at baseline pre-vaccination testing, and the self-reported survey information collected. All cases of data discrepancy regarding prior COVID-19 infection status underwent manual physician adjudication.A total of N=1089 vaccine recipients provided at least one blood sample for antibody testing, with an average age of 41.8±12.1 years, 60.8% female and 53.4% non-white ( Table 1) In the total sample, proportions of anti-S IgG levels at or above the 4160 AU/mL threshold were similar in COVID-19 recovered persons at baseline compared to infection naïve persons after a single dose (P=0.94). Notably, these proportions were lower in COVID recovered after a single dose compared to infection naïve persons after 2 doses (P<0.001), and then no different when both groups were compared after 2 doses (Table S5 and Figure S4 ).We found that COVID-19 recovered individuals develop a level of provoked antibody response, following a single dose of mRNA vaccine, that is comparable to the provoked antibody response seen after a two-dose vaccination course administered to infection naïve persons. Extending from similar results seen in smaller studies, 5,6 our findings in a large and diverse cohort of healthcare workers highlight the potential of a strategy for maximizing vaccine supply that warrants further investigation.Recent work has demonstrated that COVID-19 specific antibodies are efficiently generated and detectable in the circulation following a single dose of vaccines that were originally intended for complete administration to include an additional booster dose. 5 These findings have prompted some organizations to favor prioritizing at least a first vaccine dose to majority segments of the population while considering variable timing for the second dose. In the absence of clinical outcomes data to support any variations from pre-specified vaccination protocols, [8] [9] [10] there are immuno-biological data suggesting possible alternate strategies for COVID-19 recovered individuals. In fact, detectable presence of naturally acquired anti-SARS-CoV-2 antibodies and measures of discernible T-cell mediated immunity, especially in persons who have successfully recovered from recent versus remote infection, have prompted some experts to suggest delaying any vaccination for these individuals. 11-13 However, acknowledging the unclear duration of naturally acquired immunity and the unknown extent to which immunity to one strain of SARS-CoV-2 confers protection from variants, there is general agreement that vaccination strategies for COVID-19 recovered persons warrants careful consideration.",USA,first author,2021-02-24,02
b08ba7cd358c8fea6db45aff9a0533148ebf6a63,Benchmark Development of multiplexed reverse-transcription loop-mediated isothermal amplification for detection of SARS-CoV-2 and influenza viral RNA,"have been applied to the detection of SARS-CoV-2 [23, 25] enabling the detection of more than one target in the same reaction but as yet requiring additional probe design and without the inclusion of internal control assays.As the COVID-19 pandemic continues into flu season, the ability to distinguish which causative agent is responsible for what can manifest as very similar symptoms will be of great importance for diagnostics and disease surveillance. A patient presenting with respiratory symptoms may have one of a number of viral infections (e.g., SARS-CoV-2, influenza A or B, respiratory syncytial virus, a rhinovirus), so using one test to identify multiple infectious agents in the same procedure will save time and cost. Most importantly, it gives a more definitive diagnostic identification. Syndromic panel tests (e.g., Genmark, Biofire) are the ultimate example of this principle, providing a simultaneous test for dozens of respiratory pathogens, but these tests are expensive and not suited to the need for expanded use of molecular testing that has arisen during COVID-19. Here we demonstrate a simple LAMP assay for detection of four targets (SARS-CoV-2, influenza A, influenza B and an internal control) that provides high sensitivity in a single reaction, expanding the utility of the widely used LAMP chemistry to a multiplex diagnostic setting.DARQ LAMP primer sets include all conventional LAMP primers (outer primers F3 and B3, inner primers FIP and BIP, and Loop primers LF and LB) and a duplex oligonucleotide consisting of the FIP modified at its 5 end with a dark quencher (Q-FIP) annealed to a complementary F1c oligonucleotide with 3 fluorophore (Fd) ( Table 1 ) [21] . E1 and N2 LAMP primers targeting SARS-CoV-2 sequence (Gen-Bank accession number MN908947) were from our previous screening [11] . Primer sets for targeting multiple influenza A and B strains (IAV and IBV primer sets) were designed and validated previously [26] . Oligonucleotides were synthesized at Integrated DNA Technologies (IA, USA) with standard desalting for conventional LAMP primers and HPLC purification for Q-FIP and Fd oligonucleotides. Synthetic SARS-CoV-2 RNA containing an equal ratio of the viral genome regions was purchased from Twist Bioscience (Twist Synthetic SARS-CoV-2 RNA Control 2 #102024, MN908947.3; Twist Bioscience, CA, USA). RNAs for influenza A and B were purchased from ATCC (VA, USA): H1N1/2009pdm (VR-1737D), H1N1 A/PR/8/34 (VR-1469DQ), H3N2 A/Virginia/ATCC6/2012 (VR-1811D), H3N2 A/Aichi/2/68 (VR-1680D), B/Wisconsin/1/2010 BX-41A (VR-1885DQ) and B/Lee/40 (VR-1535D). Viral RNA was diluted to lower concentrations in 10 ng/μl Jurkat total RNA (Biochain, CA, USA) based on quantification provided by the manufacturers. For the 24 repeat reactions, the amount of RNA used was 50 copies of SARS-CoV-2 RNA, 1 μl of 1:10000 diluted influenza A RNA (VR-1737D) and approximately 21 copies of influenza B RNA (VR-1885DQ). This amount of viral RNA was sufficient for more than half of, but not all, the 24 reactions to show positive amplification, thus allowing detection of sensitivity change under different conditions. All influenza primers were initially screened for performance using WarmStart R Colorimetric LAMP 2X Master Mix (DNA and RNA; New England Biolabs, M1800) and with WarmStart LAMP Kit (DNA and RNA) (E1700) supplemented with 1μM SYTO R -9 double-stranded DNA binding dye (Thermo Fisher S34854, MA, USA). DARQ LAMP reactions contained 1 × E1700, with an additional 0.32 U/μl Bst 2. We had previously established sensitive LAMP primer sets for SARS-CoV-2 detection [11] and synthesized DARQ-compatible labeled FIP and Fd oligonucleotides with different detection fluorophores for Gene E (E1, JOE) and Gene N (N2, FAM), as well as our internal control primer set (ACTB, ROX) ( Table 1 ). Both E1 and N2 primer sets were tested and found to be suitable for DARQ LAMP in multiplexing with other primers, but only data for E1 are shown here. For influenza detection we designed a variety of LAMP primer sets and pulled existing primers from literature reports [26] [27] [28] [29] [30] and evaluated them for speed, sensitivity and compatibility with our SARS-CoV-2 and control primers. From this comparison we selected the IAV [26, 27] and IBV [26] primer sets (Table 1 ) as they were among the most sensitive primer sets in our screening and were designed for suitability with various strains. The IAV set targets the RNA sequence for the matrix (M) protein and has been validated to detect many avian and human influenza A strains from H1N1 to H15N8, including multiple H1N1/2009pdm and H7N9 strains [26, 27] . In our testing, we found it amplified well with RNAs from the 2009 H1N1 (H1N1/2009pdm) and 1934 H1N1 (A/PR/8/34) strains, as well as 2012 H3N2 (A/Virginia/ATCC6/2012) and 1968 H3N2 (A/Aichi/2/68). The IBV set detects the RNA for the NS protein and has been tested with RNA from an influenza B virus isolated in 2012 [26] ; we found it amplified well with RNA from strain B/Wisconsin/1/2010 BX-41A, but not with RNA from the B/Lee/40 strain isolated 80 years ago. We also performed sequence alignments of IAV and IBV target regions; these primer sets are expected to detect strains isolated in recent years. With this information, IAV and IBV primer sets were chosen for multiplexing with our SARS-CoV-2 primer set using Cy5 and FAM fluorophores, respectively.First we compared DARQ LAMP with conventional intercalating dye detection of tenfold dilutions of viral RNAs for each primer set. The results for SARS-CoV-2 RNA using the E1 primer set, either with or without the ACTB control primer set, are shown in Figure 1 E1 [11] E1-F3 TGAGTACGAACTTATGTACTCATN2-F3 ACCAGGAACTAATCAGACAAG speed by DARQ LAMP showed a target dosage response, just as in the conventional LAMP monitored by SYTO-9 dsDNA-binding dye ( Figure 1A & B) . Reaction speed decreased in the presence of the DARQ duplex and slowed slightly more with the addition of a second primer set (ACTB; Figure 1C & E). Similarly, in the duplex LAMP reactions, ACTB amplified slightly more slowly than in reactions containing only ACTB and Jurkat RNA ( Figure 1D) , but the signal level was sufficient for ACTB to serve as an internal positive and loading control. Using 0.25 × primer concentration for the ACTB internal control allowed for even amplification in single versus duplex reactions while still providing sufficient fluorescent signal for detection. Similar results were observed with IAV and IBV primer sets, indicating that these primer sets work well in DARQ LAMP and are compatible with ACTB primers. Next we sought to evaluate whether DARQ LAMP has a detection sensitivity similar to that of standard LAMP. Figure 2 shows the results of 24 LAMP reactions, each with 50 copies of SARS-CoV-2 RNA, and 8 NTCs. In all configurations (standard intercalating LAMP, Figure 2A ; single-plex DARQ LAMP, Figure 2B ; duplex E1+ACTB DARQ LAMP, Figure 2C ) we measured a similar number of positive LAMP reactions and negative NTCs. This indicates that DARQ LAMP has similar detection sensitivity to conventional LAMP reactions, and that the addition of a second primer set does not increase the rate of nontemplate amplification with our reaction conditions. Although real-time monitoring of LAMP provides some level of quantitative information, heating to 60 • C with multiplex fluorescence requires a qPCR instrument or similar, and reactions must be incubated on the detection instrument for the entire reaction time. An alternative approach compatible with more instruments is to use end point fluorescence detection. We investigated the possibility of using end point fluorescence scanning to detect signal in DARQ LAMP reactions. After incubating at 60 • C, the same plate used for realtime monitoring was scanned for fluorescence levels in a BioTek Synergy Neo2 plate reader and the raw fluorescence unit values were plotted (Figure 2A-C, lower panel) . The difference in signal levels between positive and negative LAMP or NTC reactions was easily distinguished using a threshold value set based on negative (background value), and calling positives accordingly matched the results 100% with those obtained by real-time monitoring ( Figure 2E) . Similarly, the ACTB signal in duplex LAMP reactions was determined by scanning and matched the real-time results ( Figure 2D ). This result demonstrates the compatibility of end point plate reader measurements with multiplex DARQ LAMP, enabling its use on a wider range of instrument types and increasing the potential test throughput.Next we extended the number and range of targets for DARQ LAMP for the detection of a single target and an internal control in the presence of up to four sets of LAMP primers. Figure 3 shows the results of 24 replicate LAMP reactions, each with 50 copies of SARS-CoV-2 RNA, and 8 NTCs using: E1 and ACTB primers (duplex; Figure 3A) ; E1, ACTB and IAV (three-plex, Figure 3B ); or E1, ACTB, IAV and IBV (four-plex, Figure 3C ). In all three cases, the SARS-CoV-2 RNA was successfully detected with equivalent sensitivity. We did observe a slowing of amplification with increasing primer amounts, but sensitivity was not significantly affected. Again, the real-time results matched exactly with the end point measurements on a plate reader ( Figure 3A-C, lower half panel) ACTB signal also appeared as expected and could be easily called as positive by the real-time data or end point fluorescence scanning in all reaction configurations ( Figure 3D & E) . A similar evaluation was performed with the IAV/influenza A RNA and IBV/influenza B RNA; equivalent performance was observed with these targets and combinations of primers and templates ( Supplementary Figures 1  & 2) . While not measuring a strict limit of detection, we used low-copy inputs (SARS-CoV-2 ∼50 copies; influenza A 1:10,000 dilution; influenza B ∼21 copies) for which <100% of reactions would indicate positive, in order to maximize our sensitivity to altered reaction performance. The results demonstrate that DARQ LAMP detection sensitivity is not significantly affected with up to four primer sets present in the reaction, though in testing 24 replicates at very low copy inputs we saw approximately 1 fewer positive result in reactions containing all four primer sets. Importantly, the rate of nontemplate amplification, which would present a false positive result, did not increase when adding multiple primer sets in the reaction. With testing in real-world settings, the vast majority of samples will contain zero or one of the viral targets detectable in the multiplex assay. However, coinfections are possible and the assay must maintain performance in the presence of multiple target sequences. To study this scenario, we examined amplification of two DARQ LAMP targets and an internal control in the same reaction. We added two viral RNA targets to 24 DARQ LAMP reactions that all contained E1, IAV, IBV and ACTB primers (and Jurkat RNA for internal control) and monitored amplification by real-time and end point fluorescence scanning. In all three triplex combinations (SARS-CoV-2 + influenza A + ACTB; SARS-CoV-2 + influenza B + ACTB; influenza A + influenza B + ACTB), the positive rate of each target was equivalent to that of the single-plex or duplex reactions described above, indicating that sensitivity was unaffected (Figure 4 ). The majority of reactions showed detection of both viral targets, with a minority detecting only one of the targets (Figure 4) . The shape of the real-time curves in these triplex LAMP reactions (two targets + ACTB) appeared slightly flatter and slower, but distinction above background was easily seen; by combining the real-time data with the end point fluorescence level (data not shown), positives could be differentiated from negatives in the same manner as described above.Detection of multiple viral targets in a molecular diagnostic reaction is hardly our original idea and is already widely used worldwide for multiplex PCR tests and syndromic panels. But as the COVID-19 pandemic continues into late 2020 and beyond, the need for more and varied testing remains an urgent priority worldwide. LAMP has found a use as a COVID testing modality due to its flexibility and simplicity, but as cold and flu season arrives, more functionality will be needed in LAMP tests to keep pace with diagnostic testing requirements. While fieldable colorimetric LAMP is extremely useful for screening and surveillance, the ability to multiplex influenza and potentially other targets will supplement the supply-constrained RT-qPCR workflows. Here we demonstrate multiplex fluorescent DARQ LAMP with detection of three primary respiratory viral RNA targets and an internal control in a single reaction. While not as simple as visual colorimetric LAMP, the DARQ approach is rapid (<40 min) and is compatible with standard qPCR instruments. We also showed that positive signals can be reliably detected by end point scanning of DARQ fluorescence levels in a plate reader, and thus the reactions could be performed on heat blocks, regular PCR cyclers or even simple incubators followed by quick scanning. The work presented here utilized only extracted and synthetic control RNA materials rather than real clinical samples, which would of course be needed for a real diagnostic test, but we hope that by demonstrating this multiplex approach we can help enable broader usage of LAMP testing and further support the continuing need for diagnostics to combat COVID-19. Ideally, as powerful molecular testing gains wider adoption, we will continue to utilize these approaches, with LAMP and other diagnostic methods tracking and fighting the further threats to public health that will inevitably arise in the future.To view the supplementary data that accompany this paper please visit the journal website at: www.futurescience.com/doi/suppl/10.2144/btn-2020-0157Author contributions Y Zhang conducted experiments, collected and analyzed data. Y Zhang and N Tanner conceived the study and wrote the manuscript. ",USA,first author,2021-02-04,02
429332211d52949cccdc5f54cc4249890d2d0fa6,Delivery of recombinant SARS-CoV-2 envelope protein into human cells,"The severe acute respiratory syndrome 2 virus (SARS-CoV-2) became a focal point of science and society in 2020. It is to be hoped that the ongoing vaccine development and delivery program will soon allow the world to return to an approximation of normalcy (1, 2) . However, previous coronavirus (CoV) epidemics, including Middle East respiratory syndrome (MERS) (3) and SARS (4) from 2002-2003 foretell that future CoV zoonotic events (5) are likely to afflict humankind. Fundamental studies of the molecular underpinnings of CoVs may help to mitigate the current and future pandemics.Within CoVs, there are four critically conserved structural proteins (6, 7) , each of which is of possible therapeutic importance due to their essential functions (8) , Among these is the SARS-CoV-2 envelope (E) protein. The E protein is a single-pass transmembrane protein whose roles in pathogenesis are incompletely understood (9) . However, its importance is highlighted by cellular studies showing that the CoV E and M proteins alone are sufficient to produce a budding virus-like particle (VLP) (10) (11) (12) . Moreover, deletion of E drastically lowers viral fitness (13) (14) (15) and growing evidence suggests that E is directly responsible for acute respiratory distress syndrome (ARDS) occurring in conjunction with CoV infections (16) . E is highly expressed in infected cells, but only a small fraction is incorporated into mature viral particles, implying functions beyond its role as a mature capsid structural protein (17) . Supporting this idea, the E protein is known to populate both monomer and oligomer forms in vivo (18) . Most biophysical measurements have focused on the homopentamer form that functions as a cation-selective ion channel (19) (20) (21) (22) , which is analogous to a well-studied and validated drug target, the influenza M2 protein (23, 24) .A distinct feature of coronavirus assembly is that their nascent particles bud into the lumen of the endoplasmic reticulumto-Golgi intermediate compartments (ERGIC) in cells (25) . The E protein is critical to viral maturation (10, 17, 26) . Localization of SARS E to these membranes is remarkably stringent, likely a consequence of Golgitargeting motifs present in the E protein (26) . Since E functions in multiple roles that are critical to viral fitness (27) (28) (29) , it is desirable to develop methods to further characterize key pathogenic mechanisms. Current methods to study the E protein in mammalian cells are reliant on transfection of genetic material encoding the protein into cells and its subsequent transcription and/or translation. Here, we sought to develop a robust method for exogenous delivery of purified SARS-CoV-2 envelope protein (S2-E) into cells to enable chemical biological methods for studies of S2-E function and to facilitate novel COVID therapies.We developed a straightforward bacterial expression and purification protocol that yields ~100 µg/L of 90-95% pure fulllength S2-E under conditions in which it is bereft of detergent and lipid, with its aqueous solubility being maintained by complexation with the zwitterionic amphipol PMAL-C8 (30,31) ( Fig. S1 and Supporting Material and Methods). This purification protocol has been streamlined to a single gravity column and does not require a FPLC or ultracentrifuge. Once purified into lipid/detergent-free amphipol solution, the S2-E/amphipol complexes remain stable and soluble in aqueous solution even following removal of excess uncomplexed amphipols. Amphipols are a class of amphipathic polymers that exhibit weak detergent properties, in that they can solubilize and stabilize the native membrane protein folds, but cannot solubilize or even permeabilize membranes (32, 33) . Additionally, some amphipols are well tolerated by animals (34) and have been used in Chlamydia vaccine development (35, 36) because they do not elicit the production of anti-amphipol antibodies (37) .Planar lipid bilayer electrophysiology was used to test if amphipols could deliver the S2-E protein to a membrane environment to form ion channels without otherwise disrupting the lipid bilayer (Fig. 1A) . As expected, amphipol-based S2-E delivery resulted in ion channel activity that is consistent with previous SARS-CoV-1 E (38) and preliminary S2-E (39) channel measurements in terms of current amplitudes, sodium cation selectivity, and open probabilities. (Figs. 1B,C, and S2, and Supporting Materials and Methods). The S2-E-dependent currents and similarity to other planar bilayer measurements support that the idea that S2-E is released spontaneously from the amphipol into membranes. The bilayer integrity during amphipol delivery and exposure was monitored through membrane capacitance measurements. The bilayers remained stable throughout the recordings with an average value of 58 ± 3 pF. These results demonstrate that recombinant S2-E can be delivered into pre-formed lipid bilayers using amphipols, where the protein not only inserts into the bilayers, but also retains ion channel function, without significantly compromising the bilayer integrity.We next tested whether S2-E can be delivered from amphipol complexes to the membranes of human cells. To this end, S2-E was irreversibly tagged with the fluorophore nitrobenzoxadiazole (NBD) to form S2-E-NBD. This allowed us to track the time course of delivery of S2-E into HeLa cells using confocal microscopy. As shown in Figs. 2 and S5, the S2-E-NBD protein was delivered from amphipol complexes to HeLa cell membranes, with all cells exhibiting NBD signal within 30 min (Fig. 2B). Fig. 2C -F shows the 8 hour progression of the S2-E-NBD protein from the plasma membranes to a predominately perinuclear intracellular location. After 16-18 h nearly all the S2-E was observed in the vicinity of the nucleus, with a clear focal area on one side of the nuclear compartment rather than being evenly distributed, ring-like, around the entire nucleus (Fig. 2G,H) . Delivered S2-E was typically more diffuse at early time points but becomes punctate as it traffics to the perinuclear space.The amount of S2-E signal in cells was dependent on the applied amphipol/S2-E ""dose"" and no obvious cell toxicity was observed until a concentration of 10 µM S2-E in the culture was reached (Figs. S3 and  S4 ). To ensure that we were microscopically tracking intact S2-E instead of dye freed from full length S2-E by degradation, we confirmed the S2-E localization following cell fixation and permeabilization with a polyclonal anti-S2-E antibody (Fig. S3) . The same Fig. S3 Western blot data also rules out the possibility that the tracked NBD fluorescence could arise from a minor impurity in our S2-E-NBD samples. While amphipols have previously been reported to deliver select membrane proteins to artificial lipid bilayers (30, 40) , this study represents the first use of amphipols to deliver a protein to live mammalian cells. Elucidation of the pathway(s) taken by the S2-E protein to dissociate from its soluble amphipol complex to then insert into the membrane to adopt a transbilayer configuration will require further study.We also examined possible delivery of S2-E from amphipol solutions into SW1573 human alveolar cells, a COVID-19relevant cell line (41) . We observed (Fig. S4 ) that S2-E is indeed taken up by these cells and subject to the same cell surface-toperinuclear ""retrograde"" trafficking as seen in HeLa cells.During viral replication, most E protein is retained at the Golgi/ERGIC regions. S2-E retention is important to virion assembly because CoVs assemble and bud from the Golgi/ERGIC space before being secreted. The fact that S2-E retrograde traffics proximal to one side the nucleus (Fig.  2G,H) is consistent with its localization at or near the Golgi/ERGIC compartments. To gain further insight into the final cellular location of S2-E we used organelle-specific monoclonal antibodies to pinpoint the locations of the Golgi and ERGIC relative to delivered S2-E. At later timepoints after initial delivery, S2-E was typically seen to concentrate in the area surrounding the Golgi, but not within the Golgi, (Figs. 3A-C and S6). In like manner, S2-E was seen to locate proximal to the cytosol-facing side of the ERGIC (see Fig. 3D-F) .It is likely that the Golgi-localization motifs (26) in S2-E drive its retrograde trafficking in a way closely related to the mechanism that facilitates E protein Golgi/ERGIC retention during viral infection. However, we cannot rule out the possibility that the retrograde trafficking documented in Fig. 3 reflects the outcome of a cellular stress response to amphipol-delivered S2-E. Isolated coronavirus E overexpression in transiently transfected model mammalian cell lines is known to induce apoptosis (42, 43) . However, comparative studies of cell infection with SARS versus SARS lacking the E gene have shown that lower levels of E protein can modulate the unfolded protein response (UPR) and thereby mitigate apoptosis (44) . It is plausible that the amphipol-mediated extracellular delivery of S2-E triggers cell stress and UPR-related retrograde trafficking, leading to deposition of S2-E in perinuclear aggresomes. Aggresomes are ordered protein aggregates that form following transport of certain proteins along microtubes by dynein to perinuclear microtubule-organizing centers (45) . Interestingly, previous reports have linked aggresome formation and their subsequent clearance via autophagy to coronavirus replication (46) (47) (48) . Further study is clearly required. For now, we can confidently state that delivered S2-E ultimately traffics back to a perinuclear area that is immediate to the Golgi and ERGIC compartments which mirrors the localization of SARS-CoV-2 infected cells.We have shown that the S2-E protein can be stripped of lipid and detergent and purified into aqueous solutions in which its solubility is maintained solely by complexation with amphipols. The protein can then be delivered to lipid bilayers, in which the protein spontaneously inserts into the membrane to form ion channels. Likewise, addition of the S2-E protein to living human cells results in plasma membrane integration and subsequent retrograde trafficking deep within the cell to a location immediately adjacent to both Golgi and ERGIC compartments, which are believed to be the key locales of coronavirus replication and assembly. The S2-E proteinto-cells approach established by this work should be exploitable as a route to delivering chemically modified full length S2-E to cells in culture or possibly even to cells under physiological conditions. This capability enables a wide range of chemical biological tools to explore the biological function of this protein or to test whether chemical warhead-armed S2-E can play the role of a Trojan horse to interfere with SARS-CoV-2 replication, potentially as an anti-COVID therapeutic or prophylactic. The results of this work also establish a general paradigm for using amphipols to deliver membrane proteins to living cells, although whether numerous other membrane proteins can be successfully delivered using this approach remains to be explored.All data needed to evaluate the conclusions in the paper and supporting information are presented in the manuscript or in the supporting information. Correspondence and requests for materials should be addressed to WDVH (wade.van.horn@vanderbilt.edu) or CRS (chuck.sanders@vanderbilt.edu).Special thanks to Abigail C. Neininger for help with fluorescence microscopy.JMH, RC, DDL, and AH conducted all experiments for this work. All authors participated in data analysis and wrote the paper. WDVH and CRS conceived of the work and directed the approaches used.This work was supported by NIH grants RF1 AG056147 (CRS) and R01 GM112077 (WVH). JMH was supported by NIH T32 CA00958229 and by F31 AG061984. Special thanks to Abigail C. Neininger for help with fluorescent microscopy. The Vanderbilt Cell Imaging Shared Resource is supported by NIH grants CA68485, DK20593, DK58404, DK59637, and EY08126.The authors declare no competing financial interest.Severe Color markers are: green, S2-E labeled with NBD; red-in panels A-C-is from an antibody to Golgin-97, a Golgi marker; in panels D-F, red is from an antibody to ERGIC-53, a defining marker for the ERGIC region; blue is the fluorescent dye DRAQ5, marking the cell nucleus. Panels (A) and (D) are the control samples where cells were not treated with S2-E-NBD. Other panels are labeled with time following S2-E-NBD addition to the cell culture. Experiments were repeated 3 times using 3 different S2-E-NBD preparations. All scale bars are 25 µm. Further details in materials and methods and Supporting Information Fig. S6 ",USA,first author,2021-02-19,02
fb00399b83d1b000cd1290ea66639d04c5739d79,0123456789) 1 3 Community Mental Health Journal,"In the United States, between March 10, 2020, and March 27, 2020, all states implemented some form of social distancing and/or shelter in place policy in response to the COVID-19 pandemic (Siedner et al. 2020) . Mental health care outpatient clinics and services rapidly moved towards using tele-mental health to comply with social distancing policies and to protect their clients and staff from COVID-19 (Wright and Caudill 2020) . This fast move was supported by the fact that mental health care via tele-mental health (also referred to as telepsychiatry) has been proven to be effective (Shore 2013; Chakrabarti 2015; Torous et al. 2020) . To facilitate this move, emergency waivers suspending the requirement to comply with the Health Insurance Portability and Accountability Act of 1996 (HIPAA-the health information privacy law in the US) for tele-mental health were issued by governmental agencies (Wright and Caudill 2020) . In this process, the fidelity that helped establish the effectiveness of telehealth/telemedicine might have been lost. For instance, the guide for tele-mental health developed by the American Psychiatric Association together with the American Telemedicine Association states that ""all modes of communication of personal health history shall be HIPAA compliant"", as well as the need to ensure privacy (Shore et al. 2018) . With the emergency HIPPA waivers, these recommendations could, potentially, not be followed with the same rigor, leading to decrease in quality of service. Even before the current COVID-19 pandemic, several challenges and concerns have been raised regarding tele-mental health as a substitute to in-person appointments, (e.g. anxiety and technophobia) (Langarizadeh et al. 2017 ). This strategy, at most, should be considered an excellent adjunct to traditional service delivery, complementing and supplementing in-person care (Chakrabarti 2015; Mehrotra et al. 2017; Greenhalgh et al. 2018) . After two months of social distancing policies where telehealth/telemedicine became the new norm for outpatient mental health service delivery, For-LikeMinds, conducted an on-line survey with its community about tele-mental health. ForLikeMinds is an online peer support community dedicated to the recovery and wellness of people living with or supporting someone with mental illness, substance use, or stressful life events (Ponte 2020) .The utilization of telecommunication platforms, such as videoconferencing, to deliver mental health services remotely defines tele-mental health (Mahmoud et al. 2020) . It was not a surprise, then, that mental health services via tele-mental health became a routine component during the COVID19 pandemic. Tele-mental health is a consensus choice when it comes to providing a safe and convenient access to routine mental healthcare, avoiding exposure to COVID-19, especially for those at higher risk of being affected (Smith et al. 2020) . In recent years, there has been a significant expansion of tele-mental health services. For instance, in the US in 2017 almost 30% of mental health facilities offered tele-mental health services (Mahmoud et al. 2020) .Tele-mental health is a well-known practice and has been around for more than half a century (Mahmoud et al. 2020; Hilty et al. 2013) . In 2009, the American Telemedicine Association established guidelines for tele-mental health. In their guidelines, standard provisions include the availability of appropriate staff before, during, and after tele-mental health encounters to meet patient and provider needs and enhanced requirements for privacy and confidentiality (Yellowlees et al. 2010) . In their review of the literature about the effectiveness of tele-mental health, Hilty et al. (2013) concluded that tele-mental health services were mostly effective if a plan of assessment and care for patients was in place.Other key administrative issues for successful tele-mental health program implementation would be licensure requirements, malpractice insurance, insurance coverage, adherence to HIPPA regulations, and establishment of protocols (Write and Caudill 2020). On the other hand, several limitations to tele-mental health have been identified such as lower quality of patient-physician relationship, fragmentation of care, and challenges in accessing telecommunication technology (Dorsey and Topol 2016; Greenhalgh et al. 2020) .A review of the literature before the COVID-19 pandemic demonstrated that, regarding psychotherapeutic interventions and therapeutic alliance in treatment, it seems that patient satisfaction with tele-mental health was comparable to in-person delivery, when well implemented and technology support was available (Jenkins-Guarnieri et al. 2015) .In their first on-line survey about the COVID-19 pandemic and the concerns of people with mental illness, ForLike-Minds captured significant concerns about how the pandemic was affecting respondents' mental health. Participants in the first survey were specifically concerned with disruption in treatment, access to medication, and the likelihood of their condition getting worse and/or developing a new mental illness (Costa et al. 2020) . Leadership at ForLikeMinds decided to conduct a second on-line survey to address resilience and mental health care during the COVID-19 pandemic. After almost two months since the beginning of social isolation measures, how were people with mental illness doing? Was tele-mental health working for people with mental illness? Did they have any suggestions that could improve tele-mental health?A survey about resilience and tele-mental health-the Coronavirus Mental Health Resilience Survey-was developed by ForLikeMinds' leadership based on their own research and perception of how their network was coping with the pandemic. It was then sent out to their members and followers. The Coronavirus Mental Health Resilience Survey is composed of 11 multiple-choice questions with the option of comments and one open question. The multiple-choice questions addressed the following issues: did participants self-identify as living with a mental illness, which mental illness they identified with, where they were in their recovery journey, what was the impact of the pandemic on their mental health, if they had developed a new mental illness, how had the mental health support they received changed during the pandemic, how had their mental health care changed as a consequence of the pandemic, if they were receiving tele-mental health support, how they were coping with the pandemic, how isolated they felt, and how had their level of social connectedness changed during the pandemic. The open-ended question asked participants about their thoughts on what would be most helpful for their communities during this difficult time.The survey was distributed to members of ForLikeMinds and to their Facebook community using Survey Monkey. The dataset extracted from Survey Monkey was de-identified before it was sent to the Yale Program for Recovery and Community Health for analysis (i.e., secondary data analysis). SPSS was used for the statistical analysis. Analyses were run after cases were selected. Case selection was based on having checked the statement ""I am completing this survey primarily as someone living with mental illness"". Frequencies were determined for each multiple-choice question. Bivariate Correlations utilizing Spearman rank order correlation was established to determine the correlations between the variable ""how do you feel you are coping with the pandemic"" (ordinal variable) and all other nominal and ordinal variables. Significance (2-tailed) was established at a level of p < 0.05. Effect sizes of the relationship between variables were established and an effect size of approximately 0.1 was considered a small effect size, and effect size of approximately 0.3 was considered a medium effect size and effect size of approximately 0.5 was considered a large effect size Swank and Mullen (2017) .Comments to the question ""have you seen your mental healthcare provider by video session"" were analyzed together with the responses to the open-ended question ""what would help our community most during this crisis?"". A phenomenological approach was used to analyze each individual statement and to define a main theme for each statement (Davidson 2003; Davidson et al. 2008; Van Manen 2016) . Statements were also classified as positive, neutral, or negative. Two members of the research group analyzed and defined themes for each statement independently. Themes generated from statements were then grouped based on how participants felt they were coping with the pandemic. Classification of positive, neutral, and negative, was based on the interpretation of the researchers who analyzed the statements. Both researchers agreed in how each statement were classified. Results from the independent analysis were compared and a final set of themes were established.Institutional Review Board (IRB) was not pursued because there was no identifiable private health information in the data set that researchers used for the analysis.ForLikeMinds is an online support community dedicated to the recovery and wellness of people living with or supporting someone with mental illness, substance use, or stressful life events. It has over 15,000 members plus a Facebook community of nearly 23,000 followers. Four hundred and thirty-five unique individuals responded to the survey. Of these, 381 individuals (88%) self-identified as living with a mental illness. As mentioned in the methodology, all data analysis reported here refers to participants living with a mental illness. Of those living with a mental illness, 74% reported having an anxiety disorder, 60% having a major depressive disorder, 36% having post-traumatic stress disorder, 30% having bipolar disorder, 13% having borderline disorder, 11% having obsessive compulsive disorder, and 5% having schizophrenia (respondents could report multiple conditions). Seventy one percent (71%) of participants said they had at least two mental illnesses and 59% said they had at least three mental illnesses. The most likely conditions to occur together were anxiety and major depressive disorder (49% of participants had both conditions), anxiety and post-traumatic stress disorder (31%), and major depressive disorder and post-traumatic depressive disorder (26%). When asked about where they were in their recovery, 17% responded that they were living a full and meaningful life, 36% said that they had symptoms but were able to manage them, and 47% said that they were struggling to get or stay well.The Coronavirus Mental Health Resilience Survey didn't ask specific sociodemographic questions. Based on other surveys conducted at ForLikeMinds which collected sociodemographic data, we expect respondents to be mostly females (85%), white (84%) and 55 years old and older (57%).Participants were asked about how much the COVID-19 pandemic had impacted their mental health. For 21%, their mental health was much worse, 51% said their mental health was worse, 22% said that the pandemic had no real impact on their mental health, 5% said that they were doing better, and 1% said that their mental health had been much better since the pandemic. When asked if they had developed a ""new"" mental illness during the COVID-19 pandemic, 21% responded affirmatively. Regarding the mental health supports they received, 12% said that their mental health support stopped after the pandemic started, 30% said that it had decreased, 42% said their mental health support had remained unchanged and for 16% their mental health support had actually increased. Changes in mental health care was addressed in the survey. For 7%, their mental health care improved during the pandemic, 55% said that their care remained unchanged, while 28% said that their care deteriorated once the pandemic had started. Additionally, 7% said that it had become more difficult for them to get their medication.For the question about seeing their mental health care provider through video conferencing following the stay at home recommendations, participants were given the option of checking more than one response. With this, 8% said that they started seeing a new mental health care provider by video sessions, 33% said that they had switched from inperson sessions to video sessions with the same provider, 33% said that they preferred in-person sessions to video sessions, 3% said that they preferred video sessions to in-person sessions, about 8% said that they would like to continue seeing their mental health care provider by video sessions after the stay at home recommendations are lifted, about 10% of participants reported that they were meeting with their providers over the phone and 11% said that they had stopped seeing their mental health care provider because tele-mental health was not offered to them.Participants were asked about how they were coping with the pandemic. For 16%, they were coping well; 50% said that they were coping okay; and 34% said that they were coping poorly. When asked about how isolated they felt compared to before the pandemic, 69% said that they were feeling more isolated, 26% felt the same, and 4% said that they felt less isolated. In response to the question about how the level of social connectedness had changed for them during the pandemic, 64% said that they felt less connected socially, 25% felt the same, and 11% felt that their level of social connectedness had increased.Several variables presented a significant correlation with how people felt they were coping with the pandemic. Of notice, the variables that captured mental health treatment and how people felt about their mental health treatment during the pandemic presented a moderate to strong correlation with how people felt they were coping with the pandemic. For instance, those who saw the same provider through video sessions were coping better with the pandemic, while those who felt that their mental health treatment had deteriorated or who had more difficulty in getting their medication or who felt that their mental health support had stopped were coping worse. Also of notice, those who said that they had anxiety disorder or major depressive disorder or PTSD were coping worse while those who said that they had bipolar disorder were coping better (Table 1) .One hundred and seventy-five participants (46%) of those living with a mental illness provided a written response to the two analyzed open questions. Altogether, 205 written statements were analyzed. Eighty-nine participants (23%) provided additional comments for the question ""have you seen your mental health care provider by videos session during the lockdown"" (question 1) and 116 participants (30%) answered the question ""what would help our community most during this crisis?"" (question 2).Regarding the classification of each statement, 52 statements (30%) were classified as negative (e.g. ""I am not sleeping well. I am often sad. I find it difficult to get things done.""), 69 (39%) were classified as neutral (e.g. ""Depends on the day""), and 84 (48%) were classified as positive (e.g. ""I have never felt more rested and in control than I do right now""). Convergence was observed between multiple choice and open-ended questions and qualitative analysis was conducted taking convergence into consideration.Three main themes emerged from the analysis: (1) accessibility to care; (2) self-care strategies; and (3) community support and relationship.Related to accessibility to care, those who said that they were coping poorly with the pandemic presented several barriers and challenges such as not feeling comfortable using tele-mental health, not having been able to connect to their provider, feeling that there was a decrease in number of sessions, challenges in using technology, and that the phone was less effective:""I can't do video sessions. I don't have internet, and data doesn't work. This is hard [because] as a kid I was sexually abused (…) and I just can't do that. Every time I think about it I want to puke and it's led to flashbacks about the videos and abuse, and I just can't do it..."" ""I am hearing impaired. Video Conferencing is difficult."" ""Instead of 50 minutes of therapy it's 30-minute phone sessions, no video.""They also presented suggestions such as group therapy via video and more options for online counseling: ""More options for online counseling. Most counselors are not familiar with or comfortable using technology such as FaceTime or Zoom. Also, insurance should cover these sessions just as it does in-person sessions."" For those coping satisfactorily with the pandemic, accessibility to care fell into two subcategories: some respondents were meeting with their providers over the phone instead of on video sessions, but that did not pose much of a problem; others were still waiting for their first tele-mental health session:""Don't have access to video sessions. We have phone sessions and would like the option to choose whether we'd like phone sessions or in person sessions after the restrictions are lifted."" ""Telephone appointments are the norm in our area."" ""Waiting for the sessions with new mental health care provider.""For those who were coping well with the pandemic many felt very supported by their providers, but they also pointed out limits of tele-mental health:""I have had phone consults. My doctor calls me anytime I leave a message. Before and during this pandemic."" ""Some conditions are less likely to deal with screen time and can actually go downhill as a result: concussions or with dementia can get more confused. The technology has not gotten easier, and with older folks particularly affected the tech has not helped.""For the two other main themes, self-care strategies and community support and relationships, comments and suggestions were similar regardless of how participants said they were coping with the pandemic. Participants suggested self-care strategies that included having hope, faith, mindfulness, and education for better self-care: ""More freedom and personal accountability ... reminders it is each individual's responsibility to stay clean and healthy.""-participant who was coping poorly ""I believe to try to make videos easy to understand of mindfulness or other skills to try calm ourselves down and also try to connect and reach out to each person by their culture and/or lifestyle so each person can try to be informed about mental illness/health and so they can better reach to use mental health services."" -participant who was coping okay ""Education on resources for people experiencing more anxiety or other mental health issues."" -participant who was coping well Regarding community support and relationships, concerns with loneliness and lack of support was pervasive throughout all three groups:""Recognition that isolation disproportionately affects some people, including those who were already struggling with loneliness; it is distinct from the stress that everyone is facing and has tangible effects."" (coping poorly participant) ""We need to connect physically with real people. Online is not a substitute. Superficial conversations at a distance is not a substitute."" (coping okay) ""Seeing people, touching people through hugs. I never get hugs. Ever. More realistically, if someone could just stop by without coming in, just to say hi."" (coping well)They also suggested different community support strategies directed towards increase in relationships and connection to others such as doing Zoom activities together, a place to connect with others, and webinars about how to reach out and have social contact via internet.Results from the quantitative and qualitative responses seems to agree or converge.The severity and unprecedented nature of the COVID-19 pandemic imposed the need for bold and creative solutions to address the disruption of access to mental health care, principally after social distancing and stay at home policies were abruptly implemented. Tele-mental health became a very important form of delivering mental health care in this new scenario. On the one hand, this survey shows that the tele-mental health received by participants, in many cases, had not adhered to the fidelity criteria of the evidence-based model for tele-mental health. This seems to be especially true regarding recommendations related to availability of staff before, during, and after the tele-mental health appointment (Yellowlees et al. 2010) . People who do not have access to technology, who do not have the knowledge, who are afraid for different reasons of using tele-mental health, or who do not have enough privacy in their homes were left with few options (Sevelius et al. 2020) . A significant group of participants are talking to their providers only over the phone (at least 10%) and at least 11% said that they had stopped seeing their mental health care provider. When responding to preferences, 33% said that they preferred in-person sessions to video sessions, while only 3% said that they preferred video sessions. On the other hand, for many participants, the COVID-19 pandemic seems to have aggravated their lives. Almost 75% said they had anxiety, 72% said that their mental health was worse or much worse since the pandemic, and 21% said that they had developed a new mental illness during the pandemic. The response from participants about how they were coping with the pandemic seems to reflect the combination of these two main factors-the challenges they were facing in accessing care through tele-mental health plus the mental health consequences from COVID-19. Not surprising, the effect size of the correlation between how participants were coping with the pandemic and feeling more isolated was medium to large and the effect size between coping and where they were in their recovery journey was large Swank and Mullen (2017) . For participants, the tele-mental health they received could be improved by offering more options of care and by increasing the quality of care provided. Making it easier to connect to providers, whether by offering technical assistance or by decreasing the waiting time for an appointment was also key. Finally, participants suggested that tele-mental health could be a very useful way to help people learn self-care strategies (e.g. mindfulness) and to connect with other people to help build relationships and to address loneliness.People described feeling disconnected from others, including both family and friends and mental health professionals, and may have felt abandoned by the mental health system and government. People described less personal contact with others. Those interacting with friends, family, and mental health professionals via phone or video said these connections were not as good, or were not of the same quality, as in-person interactions. Respondents also described not feeling cared for by the mental health system. For instance, tele-mental health could be more utilized for self-care strategies and to help build community supports and relationships. These could be fruitful ways of further developing and refining individual preferences in utilizing tele-mental health (Horowitz et al. 2006 ).Respondents to the survey represent only a small percentage of ForLikeMinds community. It was not possible to determine if this sample is an unbiased representation of the whole ForLikeMinds community. There might be a selection bias in the sampling methodology. As we used social media to recruit and for people to respond to the survey, we could have a biased population towards people more comfortable in utilizing technology to communicate. Those who completed the survey may also not be representative of all people with a mental illness living in the US. There may be differences between those who decided to participate in the survey and those who chose not to. We need also to consider that as with any self-reported survey, there may be differences between how people answer the survey and how they feel. Finally, as the survey was conducted on-line with member and followers of ForLike-Minds, the survey most likely didn't capture the opinion of people without access to the internet or with little interest and/or knowledge of internet navigation.The disruption caused by the COVID19 pandemic in mental health care may have not been completely solved by simply substituting tele-mental health care for in-person care. This survey offers an opportunity to reflect about the importance of building innovative strategies to create a working alliance with people who need care through tele-mental health. It is not mostly about the quantity of time providers spend with their clients on the phone or through video connections. It is about empowering and providing people the means to utilize technology as a tool ultimately to support them in their own recovery, including a focus on self-care and fostering social support. It is about the possibility of redefining ways in which tele-mental health is offered equitably and truly made accessible to everyone who needs it.",United States,abstract,2021-02-10,02
701cfddaa2c665e2a09b14f14139f6bb3f454a8d,"HYDROXYCHLOROQUINE FOR THE TREATMENT OF SEVERE RESPIRATORY INFECTION BY COVID-19: A RANDOMIZED CONTROLLED TRIAL , from the Instituto Nacional de Enfermedades Respiratorias Mexico City, and Drs","For the primary outcome, a result for each group and the estimated effect size and its precision Results, Table 2 Harms Important adverse events or side effects Results, Table  Conclusions General interpretation of the results Yes Trial registration Registration number and name of trial register YesSource of funding Acknowledgments *This item is specific to conference abstractsThe outbreak of respiratory infection by the novel coronavirus 2019 (SARS-CoV-2) started in December 2019, in Wuhan (Hubei Province), China [1] [2] [3] [4] [5] . From this city, the outbreak has been spreading to the majority of countries worldwide in a severe pandemic 6 . As of July 17, 2020, more than 13 million infections and half a million deaths have been reported 6 .Several drugs have been prescribed for patients with COVID-19, based on their known immunomodulatory or anti-inflammatory effects, or on their in-vitro antiviral effects 7 . Chloroquine and HydroxyChloroQuine (HCQ) have been in regular use for decades to treat malaria and, more recently, for the treatment of some rheumatic diseases, with a well-documented benefit/risk profile at a very low cost. The majority of published studies on HCQ or chloroquine have been observational, or relatively small controlled trials. The antiviral Remdesivir shortened time to recovery in hospitalized adults with COVID-19 compared with placebo but did not demonstrate improvement in survival 8 . In contrast, Dexamethasone at a moderate dose had an important reduction in mortality in patients with severe COVID-19 9 . Several large trials on HCQ have been recently suspended, such as the RECOVERY trial 10 , the World Health Organization SOLIDARITY trial 11 , and an NIH-funded trial involving HCQ 12 , but the full details of the results are unknown, as there are to our knowledge, no peer-reviewed formal publications to date.Our aim was to estimate whether 10-day treatment with a relatively low dose of HCQ (200 mg twice daily), reduces 30-day mortality in hospitalized patients with severe COVID-19 disease, a low-cost treatment unlikely to result in important adverse effects.We excluded patients with known previous COVID-19 infection, those previously treated with HCQ or chloroquine during the last month, pregnant woman, those with a planned transfer to another hospital unit, or those participating in another COVID-19 trial. We also excluded patients based on a contraindication to start or continue HCQ including known hypersensitivity to HCQ or chloroquine, a corrected QT interval (QTc) >0.50 s, severe liver or kidney disease, a history of pre-existing maculopathy, and to avoid to the extent possible a dangerous prolongation of the QTc and derived complications 14 , those with >11 score points (of a maximum of 21 score points) on a scale assessing the risk of QTc prolongation in hospitalized patients, including age, gender, myocardial infarction or heart failure, sepsis, the use of drugs known to prolong the QTc or diuretics, and hypokalemia 15 . Attending physicians were free to exclude a patient from the protocol at any time.Eligible patients were randomized centrally, and separately for each participating hospital, utilizing an online-dedicated software (http://www.randomization.com), and results were employed to label flasks containing 20 tablets of the experimental drug and the identically appearing and packed sucrose placebo. Randomization considered two separate groups: (a) patients in critical condition specifically under invasive mechanical ventilation and with a disease severity grade 7-9 according to the World Health Organization (WHO) classification 16 with or without renal dialysis or the use of vasoactive drugs, and (b) those without invasive mechanical ventilation, with WHO classification disease severity classification of 4-6, all receiving supplementary oxygen therapy.Other categories of disease severity in the WHO classification, defined by non-invasive ventilation and the use of Extra-Corporeal Membrane Oxygenation (ECMO), were not utilized in the participating hospitals, and high-flow oxygen devices were prescribed only in 10 patients.Subjects entering the experimental group received HCQ orally or by nasogastric tube, 200 mg every 12 h, for 10 days. Subjects in the placebo group received an identical sucrose-placebo for 10 days.Blinding: Recruiters, patients, treating physicians, nursing staff, and the rest of the treating team, along with the follow-up evaluation monitors and the data-entry personnel, were blinded to group assignment.The main outcome was the 30-day mortality rate after randomization. Secondary outcomes included the proportion of patients requiring invasive ventilatory support after admission, duration in days of invasive mechanical ventilation for patients requiring such a procedure, duration of hospitalization in survivors, and incidence of severe adverse events leading to treatment discontinuation, intervention, or death.Patients were treated according to the protocols of the participating institution under the responsibility of the attending physician, who could prescribe other drugs intended as a specific treatment for COVID-19, but not as part of another drug trial. Physicians-in-charge could also avoid participation in the trial if they considered the patient´s participation to be risky or inadequate or could cancel participation later in the follow-up. Monitors registered all interventions, medications for all purposes, or non-drug interventions.Adverse events were reported regularly to the Institutional Ethics Committees and to the manufacturer of the drug and placebo (Sanofi-Aventis de México, S.A. de C.V.)Each participant had a single capture form filled, with daily updates across the duration of treatment (10 days), hospital discharge, or death. If the patient was at home by day 30, the status was evaluated by a telephone call. Treatment adherence was assessed each day by counting the remaining assigned pills in the flask. In Oaxaca, a daily dose (two pills), were given daily to the nurse. All medications administered, the results of bacterial cultures, the use of supplementary oxygen or mechanical ventilation, additional support such as dialysis, vasoactive drugs, antibiotics, vital status, adverse events, the presence of a prolonged QTc (>0.5 s) from an ECG, and laboratory results were recorded each day during treatment. RT-PCR in pharyngeal or nasopharyngeal aspirate, or in tracheal aspirate/bronchial lavage if intubated, was ordered every 7 days from randomization.The original design considered, under uncertainty of a pandemic in its initial phases, a total randomized population of 600 patients (300 per group), based on an estimation of a 50% reduction in mortality from 15% in the placebo group, with a study power of 80% and a two-tailed significance alpha of 0.05. An interim analysis was planned, upon completion of one half of the sample. In mid-July, 2020, the rhythm of recruitment was reduced drastically, due to several reasons including patient refusal, that of their relatives, or that of their treating physicians, coinciding with the worldwide suspension of several large trials testing HCQ in which no benefits of the drug were found 10-12 . Thus, it became unfeasible to complete the proposed sample size.As described in Table 1 , the mean age of the studied individuals was 49.6 ± 12 years, and the majority were males (75%). Comorbidities were present in 66%, obesity in 47%, diabetes in 16%, high blood pressure in 17%, current tobacco smoking in 11%, and cardiovascular disease in one.Median duration of symptoms before reaching the hospital was 7 days, and median days from admission to randomization were 3 days.All patients, from their first encounter in the ER, were in respiratory failure, with severe hypoxemia (mean SpO2 by pulse oximeter 65 ± 20%), tachycardia (pulse rate 108 ± 17 beats min -1 ), and tachypnea (breathing frequency [BF] 32 ±10 breaths min -1 ) (See Table 2 ). At randomization, 162 required invasive mechanical ventilation, 10 were treated with high flow oxygen, and the remaining patients received supplementary oxygen by nasal prongs (Table 2 ) with a mean PaO2/FIO2 of 145 ± 67 in the whole group, 130 ± 54 in those with mechanical ventilation, and 194 ± 80 in those with supplementary oxygen, but already with a slower BF (24 ± 5.9 breaths min -1 ) and heart rate (85 ± 18 beats min -1 ) compared with their arrival at the ER. Median SOFA score was 6 points in those under ventilation and 3 points in non-ventilated patients. (Table 2 ) Patients from INER more often required mechanical ventilation at randomization (86%) compared with the remaining two other participating hospitals (66% in Oaxaca, and none in Ixtapaluca, respectively).Use of other medications during the 10-day treatment of HCQ or placebo, was very common:Clarithromycin was prescribed to 146 (68%) patients, and Azithromycin to 50 (23%) of patients, prescribed usually as part of the antibiotic coverage of suspected bacterial pneumonia. A cephalosporin was prescribed to 182 (85%), a carbapenem to 182 (85%), Oseltamivir to 39 (18%), Lopinavir/Ritonavir to 62 (29%), and anticoagulants to 120 (56%). Tocilizumab was not available at the hospitals and was prescribed only in five cases.Systemic corticosteroids were prescribed to 114 subjects, more than 50% of the study population; the most frequent systemic corticosteroid was Methylprednisolone followed by Dexamethasone without a difference among the treatment groups. Patients who required mechanical ventilation were more frequently prescribed a systemic corticosteroid. (Table 3 .) Methylprednisolone doses varied, but on average were 100 ± 72 mg per day; Dexamethasone doses were 5 ± 2 mg per day.Among all participating individuals, 39% died: 47% of those requiring mechanical ventilation, and 13% of the remaining participants. No significant difference in the main outcome, 30-day mortality, could be identified in treatment groups (38% in HCQ, 41% in placebo, HR 0.89, and 95%CI 0.58-1.38), either in all participants, (Figure 1 and 2) or on separating those with mechanical ventilation and non-ventilated patients with supplementary oxygen. No significant difference in severe adverse events, including deaths was observed in the treatment groups (52% in HCQ, vs. 54% in placebo, HR 0.95, 95% CI 0.65-1.40) ( Table 3) . Eight patients had treatment discontinued due to an adverse event (four in each group), and in 20, the attending physician discontinued treatment (eight in the HCQ group and 12 in the placebo group).Increase in serum creatinine levels was one of the most frequently reported adverse events, without difference between treatment groups: 144 subjects had an increase in serum creatinine of >1.3 times the upper limit of normal of the clinical laboratory, and in 40 subjects it was reported as a severe adverse event, with 14 of these patients treated with hemodialysis. In a randomized trial compared with placebo, HCQ did not significantly reduce the 30-day mortality of an especially severe and hypoxemic group of patients with COVID-19. Secondary outcomes also failed to be improved by HCQ, but importantly severe toxicity was not observed to a greater degree in treated patients, despite the concomitant use of other drugs, including Azithromycin. Azithromycin was commonly prescribed as part of an empiric antibiotic for pneumonia, but also, especially at the beginning of the pandemic in Mexico, as an attempt to modify the natural course of the COVID-19.All three hospitals participating in the trial possessed important surge-capacity preparations for COVID-19. Since the epidemic developed in China, all three hospitals aimed at preparing a larger number of beds with access to mechanical ventilation, finally reaching around three times the original number of beds available. The National Institute of Respiratory Diseases has a total of 178 beds in seven wards devoted to respiratory diseases, and 30 beds with a ventilator in the Intensive Care Unit, and in the ER. The Institute was transformed into a hospital with >100 beds with access to mechanical ventilation distributed in all wards. However, trained personnel for that number of intensive care beds was scarce, and scarcity increased because of COVID-19 infections among the personnel, and especially after a presidential decree that sent home all workers more than 65 years of age or with comorbidities.Even though new personnel was hired, the majority were recently graduated physicians, nurses, and allied health personnel with little experience with critical patients. With the preparation of the hospital, the capacity of the mechanical ventilation services was not overwhelmed as occurred in other countries before. Instead, limitations derived from insufficient personnel with proper training in intensive care, and the occasional scarcity of medicines, and Personal Protection Equipment.Although this was a trial with proper randomization and blinding, demonstrated by the comparison of baseline characteristics of the treatment arms, reducing the possibility of biases due to known or unknown variables, the trial ended short of the planned sample size. Increasing the number of recruited patients proved very difficult with a growing number of refusals by patients, relatives, and treating physicians once the large trials, including RECOVERY, SOLIDARITY, and that supported by NIH, suspended their treatment arms with HCQ due to a lack of beneficial effect, although no harm from HCQ was reported. Information of these suspended trials traveled by newspapers and media 17 , and reached the widespread population with a great impact, even before a proper peer-reviewed publication was available and analyzed, because of the considerable prestige and importance of the institutions responsible for the trials. It is understandable that in the middle of a pandemic, a rapid presentation of results of large, proper clinical trials may help to select the best treatments to improve patients or avoid drugs lacking benefit or generating harm but, on the other hand, it lead to the premature termination of several trials.We and others could demonstrate that HCQ side effects can be minimized with proper follow-up keeping track of the QTc segment and utilizing instruments such as the multivariable Tisdale´s scale score 15 to predict individuals at higher risk of QTc prolongation and its complications, combined with a relatively low dose of HCQ, safe even for prolonged periods for the majority of patients, and lacking a loading dose. Our population was using different types of medications including Azithromycin, several antibiotics, systemic corticosteroids, and Lopinavir/Ritonavir, in an attempt to improve survival, the majority of the time before any drug demonstrated improvement of patients with COVID-19.In summary, no beneficial effect or significant harm could be demonstrated in our randomized controlled trial including 214 patients, using relatively low doses of HCQ compared with placebo in hospitalized patients with severe COVID-19. However, the study was stopped early and likely was underpowered for finding a statistically and clinically important difference in the primary outcome.¨ Received allocated intervention (n=102) ¨ Did not receive allocated intervention (n=4) n=1, randomized after acceptance, but the two firsts RT-PCR were negative and did not receive treatment. n=3, randomized but the drug was lost in the ward and did not receive treatment.None lost to follow up. Treating physician discontinued intervention (n= 12) Discontinued intervention because of adverse reactions (n= 4)Allocated to placebo (n=108) ¨ Received allocated intervention (n=105) Did not receive allocated intervention (n=3) n=1, randomized after acceptance but the two firsts RT-PCR were negative and did not receive treatment. n=1, randomized but the drug was lost and did not receive treatment. n=1, randomized but participated in another clinical trial Analysed (n=108). None excluded.Randomized (n= 214)",Mexico,first author,2021-02-05,02
508cca6b70d46db44169f66b9d237ee0dd12c9f3,Galectin-3 as a potential prognostic biomarker of severe COVID-19 in SARS-CoV-2 infected patients,"Coronavirus disease 2019 caused by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) infection has afflicted tens of millions of people in a worldwide pandemic, straining health care systems across the world (1, 2) . Prognostic biomarkers that can identify high-risk patients are needed to improve clinical management and allow appropriate allocation of healthcare resources. Moreover, the lack of current curative therapies emphasizes the need to get a better understanding of the pathophysiological process behind SARS-CoV-2 infection and its long-term consequences for the development of targeted therapeutic strategies.Severe COVID-19 is associated with a systemic hyperinflammatory response characterized by high levels of circulating cytokines and chemokines (3) and substantial lung infiltration of innate immune cells (4) that can lead to acute respiratory distress syndrome (ARDS), multi-organ failure and death (5, 6) . Among the inflammatory cytokines are those associated with the activation of monocyte/macrophages such as Interleukin 6 (IL-6), Tumor necrosis factor (TNF), and the CC-chemokine ligand 2 (CCL2) (3, 6, 7) .Studies have shown that those inflammatory cytokines contribute to the recruitment of additional inflammatory cells that not only aggravate the lung damage, but also lead to pulmonary fibrosis (8, 9) . Subsets of M2 macrophages expressing profibrogenic genes have been found in the bronchoalveolar lavage of COVID-19 patients (4) , reflecting that the pathological process of SARS-CoV-2 infection not only involves an acute inflammatory response in the lungs, but is also associated with fibrotic complications (10) .Galectin-3 is a 29-35 kDa ß-galactoside binding lectin first identified in macrophages (11) . It plays an important role as a driver and amplifier of the pro-inflammatory response by promoting the release of several cytokines including IL-6 and TNF-α (12) , which are some of the major cytokines present in severe COVID-19 patients (3) . High levels of galectin-3 are known to drive neutrophil infiltration and the release of pro-inflammatory cytokines, contributing to acute airway inflammation (13) (14) (15) . In addition, studies have shown that endogenous galectin-3 can enhance the effects of viral infection by promoting host inflammatory responses (16, 17) .Galectin-3 is increasingly recognized as a potentially important diagnostic or prognostic biomarker for a variety of inflammatory and fibrotic diseases (18, 19) , (20) . Galectin-3 has been implicated in the development of organ fibrosis and is found to be highly upregulated in the injured lung, particularly in patients with idiopathic pulmonary fibrosis (21, 22) . Elevated circulating galectin-3 levels were previously reported to be associated with disease severity and mortality in ARDS patients (23) .Inflammation and fibrosis are key contributing mechanisms to the progression of severe COVID-19 and the development of its long-term consequences (3), (10, 24) . Given the known proinflammatory and profibrotic roles of galectin-3, we measured circulating galectin-3 levels in COVID-19 patients to assess its prognostic value.In this prospective study we followed 156 patients with confirmed COVID-19 from admission to discharge or death. We hypothesized that levels of serum galectin-3 upon hospital admission could identify patients at high-risk of progressing to a severe COVID-19 outcome resulting in invasive mechanical ventilation (IMV) and/or death. Additionally, galectin-3 levels were correlated with clinical and inflammatory laboratory markers. COVID-19 patients were diagnosed as either critical (>50% lung damage) or moderate (<50% of lung damage) based on computerized tomography (CT). We found that elevated serum galectin-3 was significantly higher in critical patients compared to moderate ones and was found to be an independent predictor of severe outcome regardless of the percentage of lung involvement. Results from this study indicate that galectin-3 may be a useful prognostic biomarker in COVID-19 patients to provide early identification of patients at high risk of severe illness and to provide guidance on resource allocation. Further studies are warranted to understand the potential pathophysiological role of galectin-3 in COVID-19 disease progression and the development of targeted therapies. presumably reflecting a greater inflammatory state due to more severe lung damage. The total All rights reserved. No reuse allowed without permission.To explore the possible role of galectin-3 as a biomarker of severity, circulating levels were measured in sera from COVID-19 patients using a commercial enzyme-linked immunosorbent assay (ELISA). We found that COVID-19 patients upon hospital admission had significantly elevated circulating levels of galectin-3 when compared to age-matched pre-pandemic healthy subjects ( Figure 1a) . Critical patients had significantly higher levels of galectin-predicting severe outcomes in the moderate group compared to CRP (AUC=0.95, p<0.0001, and AUC=0.87, p<0.01, respectively) (Figure 2f ).Given that elevated galectin-3 levels were found in patients who progressed to a severe outcome, and considering its participation in the inflammatory response, correlations with inflammatory parameters previously studied in COVID-19 using the spearman correlation coefficient, in accordance with the non-normal distribution of the data were carried out. We To assess the discriminative power of galectin-3 as a predictor of severe outcome, ROC curves were plotted. Galectin-3 discriminates well between critical and moderate patients with an AUC We performed a forward-stepwise logistic regression analysis to identify independent demographic and laboratory parameters that strongly correlated with a severe outcome, and thus with disease progression (i.e., IMV and/or death). A smoothing spline of galectin-3 showed a non-linear relationship with severe outcome; therefore, we used the Youden's J statistic to determine the ideal binary cut-point of galectin-3 for classifying severe outcomes Table 2 ). Of note, All rights reserved. No reuse allowed without permission.In this prospective cohort of COVID-19 patients, we assessed the classification performance of circulating galectin-3 levels obtained upon hospitalization on the development of a severe outcome, defined as requirement of IMV and/or death. We hypothesized that this molecule could be associated with symptom severity due to its known involvement in the exacerbated inflammatory response, a feature that has been exhibited in COVID-19 patients (3).The hyperinflammatory state in COVID-19 patients and its relationship with galectin-3 was observed in this study, as higher levels of this lectin upon admission were found in critical patients with lung affection greater than 50%. Our results indicate that galectin-3 levels above 30 .59 ng/mL discriminate between patients with critical or moderate disease with a high specificity. ARDS is characterized by a diffuse alveolar damage in the lung, caused by the severe inflammatory process (25) . The high levels of galectin-3 found in these patients might be All rights reserved. No reuse allowed without permission.Evidence in the literature has implicated the cytokine release syndrome as the main factor responsible for the high mortality observed in COVID-19 patients (26) . Specifically, IL-6 and TNF-α have been found to be independent predictors of severity and poor outcome (3).Galectin-3 is a leading orchestrator of the inflammatory response syndrome by activating and triggering the release of inflammatory cytokines. Our observations indicate that higher galectin-3 levels are found in those patients with a severe outcome. Furthermore, we found that galectin-3 possesses power as an independent predictor of severe outcome when adjusting for age, gender, comorbidities and other inflammatory parameters. ARDS in COVID-19 leads to more severe outcomes than ARDS due to other causes (27) . With a general mortality of 26%-61.5%in those admitted to the intensive care unit, and significantly higher in those requiring IMV (65.7% to 94%) (27) . Our results indicate that values greater than 30.99 ng/mL have a high sensitivity and specificity to predict an adverse clinical course with the possibility of requiring IMV and/or death. Galectin-3 was not only able to classify a severe outcome in critical patients, but, more importantly, was able to identify severe outcomes in moderate patients (AUC= 0.95).While IMV is intended to minimize the progression of lung injury (28) , it has been also demonstrated to induce or aggravate lung damage and in the long-run may contribute to lung fibrosis (4, 29) . Chronic pulmonary fibrosis has been observed in recovered COVID-19 patients (10, 24) . Galectin-3 is known to play a role in the pathogenesis of pulmonary fibrosis, and clinical trials testing galectin-3 inhibitors are currently underway for the treatment of idiopathic pulmonary fibrosis (30) . Galectin-3 could provide an important biomarker for severe COVID-19with potential for involvement in the direct pathophysiological process of the underlying disease.To better understand the relationship between galectin-3 and the inflammatory response after SARS-CoV-2 infection, we explored its association with CRP. CRP, an acute inflammatory biomarker with ability to predict mortality in COVID-19 (31, 32) , was identified as an independent predictor of severe outcome in our cohort and had a positive correlation with galectin-3. This novel association between galectin-3 and CRP has not been reported in viral infection, much less in COVID-19 but it suggests the utility of this molecule in detecting the inflammatory state of patients upon hospital arrival. As both CRP and galectin-3 were identified as independent predictors, we sought to identify which one would perform better according to its All rights reserved. No reuse allowed without permission.Part of the relevance of this molecule in COVID-19 may be also explained given its interaction with neutrophils, a crucial immune cell whose recruitment is essential in the innate immune response against invading pathogens (e.g., SARS-CoV-2). Neutrophilia is also believed to be a key aspect in the cytokine release that has been studied in severe patients (33) which in this cohort was positively correlated with galectin-3, consequently supporting its role in the acute pro-inflammatory response. Moreover, a previous report has shown that galectin-3 is an adhesion molecule that mediates neutrophil adhesion to endothelial cells during Streptococcus pneumoniae infection, confirming its association with lung inflammation as it is actively released after infection (34) .In accordance with earlier studies (35) , we also identified hypoalbuminemia as a common characteristic among critically ill patients and support the correlation between albumin and the systemic inflammation in COVID-19 patients, as a negative correlation was found with galectin-3, which is a known contributor to the release of pro-inflammatory cytokines (12) . Albumin is an important biomarker that reflects the inflammatory state, as its production is decreased due to higher levels of IL-6 (36). Observations carried out by Huang et al. in a large cohort of COVID-19 patients identified the decrease in albumin levels as a significant indicator of progression to a critical stage and death. They associated this pathologic finding with a reduced capacity of synthesis by hepatocytes as mild hepatic injury was evident (37) . Another aspect relevant to consider is that capillary leakage into the interstitial space increases in severe illness such as sepsis, leading to the sequestration of albumin (38) . All rights reserved. No reuse allowed without permission.can provide a useful biomarker to evaluate therapeutic interventions.In this study, we have offered evidence on the prognostic use of galectin-3 in SARS-CoV-2 infected patients which may extend to other critical diseases and propose its combined use with other inflammatory markers to guide the clinical rationale when assessing a hospitalized patient's risk. Inhibitors of galectin-3 have been shown to reduce the levels of both IL-6 and TNF-α in vitro and have shown anti-inflammatory effects in vivo (39) . Based on the data presented here, we also propose galectin-3 as a feasible pharmacological target to minimize the hyperinflammatory phase and the subsequent lung fibrosis in COVID-19 patients.There are some limitations to our study. First, since this is a single-center experience, data from different populations and a multicenter analysis will be needed for validation. Second, due to the small sample size, further clinical studies with larger sample sizes are required to confirm these findings before galectin-3 can definitively be recommended as a standard biomarker in the hospital setting. Despite these limitations, this study demonstrates in a prospective cohort of COVID-19 patients at one of the largest health institutes in Mexico that measurement of galectin-3 levels upon hospital admission could be helpful in predicting disease severity. Finally, the combined use of galectin-3, CRP and albumin showed strong predictive ability, and thus could aid to efficiently allocate medical resources before patients develop an adverse outcome.All rights reserved. No reuse allowed without permission.Patients who required IMV and/or died during hospitalization were categorized as having a severe outcome. Patients who recovered and were discharged without requiring IMV were categorized as having a non-severe outcome.Clinical and laboratory data were extracted from the electronic medical records including:Demographics (age, gender, comorbidities), clinical (days of hospital stay), radiological (chest CT findings), laboratory and patient outcome data (need for IMV and/or death). Laboratory data included arterial blood gas, complete blood count, triglycerides, albumin, lactate dehydrogenase, liver enzymes, coagulation tests (D-dimer, INR) and inflammation-related parameters (CRP and ferritin).Blood samples were collected upon hospital admission from all 156 patients. Samples were centrifuged at 3,000 rpm for 10 min, and serum was aliquoted and stored at -70°C until further analysis. Galectin-3 was measured in the serum samples using a commercial ELISA Kit (Invitrogen, #BMS 279-4, Carlsbad, CA, USA), according to the manufacturing instructions. All All rights reserved. No reuse allowed without permission.Data are expressed as frequencies for categorical variables and as mean with standard deviation (SD) or median with interquartile range (IQR) for continuous variables according to The authors declare no conflicts of interest that pertain to this workAll rights reserved. No reuse allowed without permission.All rights reserved. No reuse allowed without permission.",Mexico,first author,2021-02-09,02
7b258681dabf4457f5defca7298b28e1798a43bf,Long-term air pollution and other risk factors associated with COVID-19 at the census-tract-level in Colorado,"We obtained census tract-level counts of COVID-19 cases, hospitalizations, and deaths from the Colorado Electronic Disease Reporting System (CEDRS) as well as tract-level counts of unique individuals tested for COVID-19 from Colorado's electronic lab reporting (ELR) system. All counts were stratified by age group and gender, and prior to aggregation to census tract, individual records were geocoded using the address information provided within the CEDRS and ELR databases. While CDPHE ascertains patient address information for COVID-19 cases within the CEDRS database, missing address information for individuals receiving a COVID-19 test within the ELR database can be filled in either by matching to other surveillance data sources or substituted by the address of the health care provider.In all, approximately 88% of cases and 93% individuals with a COVID-19 test were geocoded to a census tract. For our main analysis, we computed the total number of all COVID-19 infections, hospitalizations, and deaths by census tract between March 1, 2020 and August 31, 2020. The COVID-19 data were pulled from the CEDRS and ELR databases on October 22, 2020. Figure We identified a total of 42 additional census tract-level factors based on those included as confounders in two previous U.S. county-level analyses of the association between PM2.5 exposure and COVID-19 mortality Knittel & Ozaltun, 2020) . However, we detected significant problems with multicollinearity among several of these proposed covariates when we translated them to the censustract level in Colorado. Therefore, we selected a reduced set of 20 covariates through stepwise regression and manual examination of the variance inflation factors (VIFs). Descriptions of all 42 potential confounding variables and details of the variable selection procedure are presented in the supplemental information.The selected set of covariates includes six measures from the U.S. Census American Community Survey (ACS) 2014-2018 five-year estimates describing the age, race/ethnicity, and income distribution of each census tract. The race/ethnicity of each census tract was characterized by the proportion of the population that is non-Hispanic African American and the proportion that is non-African American people of color. The latter demographic group is composed mainly of Colorado's Hispanic/Latino community, but also includes the proportion that is American Indian and Alaska Native, Asian, NativeHawaiian and other Pacific islander, and two or more races. We included three measures describing the age distribution in each census tract: the proportion of the population between 18 and 44 years old, the proportion between 45 and 64 years old, and the proportion over 64 years old. We also included All rights reserved. No reuse allowed without permission.Because COVID-19 transmission is thought to be affected by meteorology (Merow and Urban, 2020; Poirier et al., 2020) , we included the 30-year average summer temperature and summer relative humidity at the census-tract level as covariates.We include five measures from the ACS related to social distancing: population density, the proportion of the population living in overcrowded housing, the proportion employed in an essential industry, and the proportion living in correctional facilities, nursing homes, or mental hospitals. We also considered two measures of social distancing derived from mobile phone data provided by the SafeGraph COVID-19Data Consortium and compiled for the Colorado Department of Public Health and Environment (CDPHE) by Citizen Software Engineers. The first is a derived measure of virus exposure combining average daily travel to a census tract with the infection rate of the corresponding county of origin. Higher measures correspond to greater volumes of travel to a census tract originating in counties with higher COVID-19 infection rates. The second is an index of the average daily amount of time spent at home per census tract derived from mobile phone location data. For the main analysis, we averaged these variables over the time period spanning March 1, 2020 to the end of the City and County of Denver's stay-at-home order on May 8, 2020.We also included two measures accounting for underlying health factors in each census tract. These measures were based on estimates of census tract level adult prevalence of diabetes, heart disease, obesity and smoking and the age-adjusted rates of hospitalization for asthma, diabetes, heart disease, and influenza. The prevalence estimates were derived from multiple years of Colorado Behavioral Risk Factor Surveillance System data (2014) (2015) (2016) (2017) , and the hospitalization data was computed from 5 years (2014) (2015) (2016) (2017) (2018) of discharge data from the Colorado Hospital Association. We used principal component analysis to reduce the comorbidity measures to a pair of uncorrelated principal components. The first comorbidity component was strongly correlated with higher prevalence rates while the second comorbidity component was strongly correlated with higher age-adjusted hospitalization rates.Next, to control for differential testing patterns, we considered the crude testing rate per census tract population from the 2014-2018 ACS estimates. We also considered the time elapsed in days since the first case was reported for each census tract, as well as the number of certified hospital beds per unit population to control for differences due to timing of initial outbreak and overall health care access.concentrations and counts of COVID-19 outcomes at the census-tract level. The BYM model includes both an intrinsic conditional auto-regressive (ICAR) component to account for spatial autocorrelation between census tracts and an exchangeable random-effect component to account for uncorrelated variation across all census tracts. The prior distributions controlling for the variance of the ICAR and exchangeable components were selected to give approximately equal emphasis to the two components (Bernardinelli et al., 1995; Morris et al., 2019) . Our model also includes a county-level exchangeable random-effect component to account for uncorrelated variation due to unmeasured county-level factors. Our primary analyses included 12 separate models, one for each combination of three COVID-19 outcomes and four PM2.5 exposure surfaces. In each model, the census tract-level count of each COVID-19 outcome was assumed to follow a Poisson distribution using the indirectly age-sex standardized expected count as an offset term.We adjusted each of our 12 models by the same set of 20 census tract-level covariates described in the previous section. PM2.5 measurements in this analysis represent long-term annual average census-tract concentrations reported in units of µg/m 3 . Hence, our reported regression coefficients for the PM2.5 variables represent the effect of a 1 µg/m 3 increase in long-term annual average PM2.5 concentration at the census-tract level. Further, we scaled the two race/ethnicity variables by their respective interquartile ranges (IQR), and thus reported regression coefficients compare a census-tract in the 75th-percentile of a given race/ethnicity variable to a census-tract in the 25th-percentile. In other words, it compares a census-tract with a typical high proportion of either non-Hispanic African Americans or non-African American people of color to a census-tract with a typical low proportion. All other variables were converted to z-scores and their coefficients represent the effect of a onestandard-deviation increase above their respective means.For each of our 12 models, we conducted four main sensitivity analyses. First, to assess the impact of our choice of offset term, we explored an alternative offset term that used the census-tract population per 100,000 from the American Community Survey 2014-2018 5-year estimates. Second, while including spatially correlated random effects often leads to more accurate estimates of fixed effects (Beale et al., 2010) , it has also been suggested that their inclusion may introduce bias in the estimates of the fixed effects (Hodges & Reich, 2010) . To account for the latter possibility, we created a separate set of models by replacing the BYM component with a census tract-level random intercept term. Third, to assess robustness of the results to study area selection, we stratified census tracts into two groups, the first including only census tracts that fall within the 5 most populous counties in the Denver metro area (Adams, Arapahoe, Denver, Douglas, and Jefferson Counties), and the second including all tracts outside of these counties. The purpose was to rule out the possibility that any All rights reserved. No reuse allowed without permission.Considering our main analysis together with our sensitivity analyses of the choice of offset term and method of addressing spatial autocorrelation, our next task was to select the best-fitting model among four candidate study designs. For convenience, we refer to the competing study designs as relative risk -BYM, relative risk -i.i.d., relative rate -BYM, and relative rate -i.i.d. Here, relative risk describes the use of the expected count as the offset term in the regression model whereas relative rate refers to the use of census-tract population per 100,000 in the offset term. The naming convention reflects the interpretation of the exponentiated regression coefficients, which in the former case can be interpreted as the multiplicative effect on the census-tract relative risk, while in the latter case would be interpreted as the multiplicative effect on the relative rate per 100,000 population. The i.i.d. model uses a tract-level random intercept term to account for uncorrelated variation across all census tracts, while the BYM models include both a random intercept and an ICAR component at the censustract level. For each study design, we built a series of nested models, starting with a null model that included only the respective offset term and random effects as regressors. We then estimated separate unadjusted risk/rate ratios for the effect of our four different measures of long-term PM2.5 exposure on each COVID-19 outcome. We then estimated fully adjusted models including all other census-tract level characteristics to control for potential confounding of the PM2.5 effect.We considered two primary factors to select an optimal model: the deviance information criterion (DIC) and the Moran's I statistic of the model residuals. Briefly, the DIC is a measure of model fit that accounts for both goodness of fit and the effective number of parameters. Lower DIC values indicate better model fit, and differences in DIC greater than 10 are generally considered meaningful (Spiegelhalter et al. 2002) . Moran's I is a correlation coefficient that measures the overall spatial autocorrelation of the model residuals. The null hypothesis of the Moran's I test states that the residuals are not spatially correlated, and thus a small p-value yields evidence that significant residual spatial correlation is present.All rights reserved. No reuse allowed without permission.All rights reserved. No reuse allowed without permission.All rights reserved. No reuse allowed without permission.Our results clearly suggest the choice of exposure surface has a large impact on the direction and significance of the adjusted association between long-term PM2.5 exposure and COVID-19 outcomes.The EPA exposure surface displayed the most consistent positive adjusted associations with COVID-19 outcomes. After controlling for all other census-tract level factors, long-term PM2.5 exposure measured by the EPA surface was statistically associated with an increase in COVID-19 infections in two out of four study designs, and with increases in hospitalizations and mortality across all four study designs. According to our best-fitting model, a 1 µg/m 3 increase in long-term PM2.5 exposure measured by the EPA surface was associated with a positive, but insignificant increase in the relative risk of COVID-19 infections (RR: 1.10, 95% CI: 0.99 -1.21). The same increase in long-term PM2.5 exposure was associated with a 25% increase in the relative risk of hospitalizations (RR: 1.25, 95% CI: 1.06 -1.46) and a 35% increase in the relative risk of mortality (RR: 1.35, 95% CI: 1.05 -1.74). Results for the Pierce and Schwartz surfaces were generally consistent with those of the EPA surface; however, none of the associations for these two surfaces were statistically significant in the relative risk-BYM model. A 1 µg/m 3 increase in long-term PM2.5 exposure measured by the Pierce surface was associated with positive, but insignificant increases in the relative risk of COVID-19 infections (RR: 1.02, 95% CI: 0.89 -All rights reserved. No reuse allowed without permission.1.01, 95% CI: 0.96 -1.06), hospitalizations (RR: 1.07, 95% CI: 0.99 -1.15), and mortality (RR: 1.06, 95% CI: 0.91 -1.24).At the same time, the results from the ACAG surface point in the opposite direction from the three other exposure surfaces. In our best-fitting model, a 1 µg/m 3 increase in long-term PM2.5 measured by the ACAG surface was associated with a statistically insignificant decrease in the relative risk of COVID- While not the primary goal of our analysis, we identified significant associations between several other factors and COVID-19 infections, hospitalizations, and mortality at the census-tract level in Colorado.Adjusting for all other census-tract-level factors, we found statistically significant evidence that census-tracts with a larger proportion of non-Hispanic African American population are associated with increased risk of COVID-19 infections (RR: 1.04, 95% CI: 1.02 -1.06) and hospitalizations (RR: 1.07, 95% CI: 1.04 -1.11). In addition, census-tracts with larger proportions of non-African American people of color were statistically significantly and positively associated with the risk of infections (RR: 1.31, 95% CI: 1.25 -1.39), hospitalizations (RR: 1.44, 95% CI: 1.32 -1.58), and mortality (RR: 1.59, 95% CI: 1.32 -1.91). With respect to social distancing-related factors, we found a one-standard deviation increase in our mobility risk index was statistically associated with increases in the risk of infections (RR: 1.18, 95% CI: 1.09 -1.28) and hospitalizations (RR: 1.15, 95% CI: 1.04 -1.27).In addition, we found evidence that communities with a larger proportion of essential workers were subject to increased risk of COVID-19 infections (RR: 1.05, 95% CI: 1.01 -1.09) and hospitalizations (RR:1.06, 95% CI: 1.00 -1.13), whereas those with greater percentages of populations confined to correctional facilities, nursing homes, or mental hospitals had lower risk of hospitalizations (RR: 0.92, 95% CI: 0.87 -0.97), but potentially higher risk of mortality (RR: 1.11, 95% CI:1.00 -1.22). Despite indirect age adjustment of our estimates via an expected count in our offset term, we found statistically significant evidence that mortality risk is higher in both census tracts with greater population percentages of adults age 65 years and older (RR: 1.30, 95% CI: 1.14 -1.49) and tracts with greater population percentages of adults age 18 to 44 years (RR: 1.37, 95% CI: 1.12 -1.68). Lastly, the number of days since the first case in a census tract was diagnosed was positively associated with higher risk of infections (RR: 1.08, 95% CI: 1.04 -1.11), hospitalizations (RR: 1.27 , 95% CI: 1.16 -1.40), All rights reserved. No reuse allowed without permission.Previous studies looking at COVID-19 infections have reported even greater variability in the estimated PM2.5 effects. At the county level in the United States, Millet et al., 2020 and Rodriguez-Diaz et al., 2020 both report that a 1 µg/m 3 increase in PM2.5 is associated with a non-significant 1% increase in COVID-19 infections. In the United Kingdom, Travaglio et al., 2021 find that estimated effect can range from a 10% decrease to a 12% increase, depending on how the data are aggregated; in the Netherlands, Andrée, 2020 found that PM2.5 from 8 µg/m 3 to 10 µg/m 3 is associated with a decrease in COVID-19infections, while a further increase from 10 to 12 µg/m 3 is associated with nearly a 100% increase in COVID-19 infections; In China, Zheng et al., 2020 report that a 1 µg/m 3 increase in PM2.5 is associated with a statistically significant 1% increase in COVID-19 infections.These studies used different model designs, covered different time periods, and adjusted for different covariates. It is therefore unsurprising that these studies found different estimates of the effect on PM2.5 on COVID-19 outcomes. Our analysis adds another potential source of uncertainty, that differences in how PM2.5 is estimated over small spatial regions can cause noticeable changes in the results. Among the 12 surface-outcome combinations studied here, results from our best-fitting model suggested 2 associations are positive and statistically significant, 7 are positive but not statistically significant, and 3 are negative but not statistically significant. None of our results from our best-fitting model in the statewide analysis or in the time-period or study area sensitivity studies show a statistically significant decrease in COVID-19 outcomes with increases in long-term PM2.5 concentrations.All rights reserved. No reuse allowed without permission.Looking forward, better estimates of the health effects of environmental exposures will require resolving the disagreements among the four PM2.5 estimation surfaces. Figure 7 shows where the surfaces currently agree or disagree, based on the standard deviation of the four surfaces in each census tract. The greatest areas of disagreement are typically found in the area around the Denver metro area, potentially suggesting that the disagreement is caused not by differences in PM2.5 emissions (which are likely to be concentrated in the metro core), but are caused by differences in the modeled chemical formation and transport of PM2.5. Figure 7 : Standard deviation of the four PM2.5 estimates in each census tract Simply examining where the PM2.5 surfaces agree or disagree does not tell us which of the census tracts have the greatest impact on our model results. We therefore examined how our regression results changed if we changed the PM2.5 estimate in a single census tract. Figure 8 shows the change in our PM2.5 effect estimate on hospitalizations when the PM2.5 estimate for a single census tract is changed from the EPA surface to the ACAG surface. The EPA and ACAG surfaces we used in this sensitivity analysis as these surfaces showed the highest and lowest PM2.5 effects (Fig. 4) .All rights reserved. No reuse allowed without permission.Early descriptions of outcomes among patients with COVID-19 in the United States indicated disease severity is highest among adults age 65 years and older, people with underlying health conditions, and is strongly linked to race/ethnicity and other socioeconomic factors (CDC COVID-19 Response Team, 2020a , 2020b Hsu et al. 2020) . Health inequities of the COVID-19 pandemic are thought to be at least partially explained by well-documented racial and ethnic disparities in the prevalence of chronic health conditions (Alcendor, 2020) ; however, several recent studies have suggested disparities among Black and Hispanic/Latino communities may be better explained by overrepresentation among the essential workforce (Oppel et al. 2020; Rogers et. al. 2020) . While our ecological study designs means we cannot make inferences about individuals, our results offer a proxy for understanding how these patterns increase vulnerability disproportionately for certain populations in Colorado.Our findings suggest communities of color in Colorado are subject to higher risk of infection as well as of more severe complications of COVID-19. Using the fully adjusted relative risk-BYM model we found All rights reserved. No reuse allowed without permission.We also found that larger proportions of non-African American people of color, a group largely composed of Colorado's Hispanic/Latino community, were statistically associated with increased risk of all three COVID-19 outcomes. Further, we found a separate statistically significant association between the percentage of census-tract population employed in an essential industry and the risk of infection, which appears to be further supported by our finding that communities with more individuals in prime working age (18-44 years) are subject to greater risk of mortality.Our findings are consistent with Millet et al., 2020 who in a similar ecological study of U.S. counties found that higher proportions of non-Hispanic African American residents were associated with increased rates of infection and mortality. With respect to non-Hispanic African Americans, the similarity of our findings to those of a nationwide study are particularly noteworthy given Colorado's smaller overall population of non-Hispanic African Americans compared to other regions of the United States. A per-IQR increase in the proportion of non-Hispanic African Americans among Colorado censustracts represents an increase of only 3.3% (0.3%, 3.6%), while an identical increase among all U.S. counties represents a 9.6% increase (0.7%, 10.3%). By contrast, a similar ecological study of U.S. counties by Rodriguez-Diaz et al., 2020 did not find statistically significant associations between predominantly Hispanic/Latino counties and COVID-19 rates in the Western U.S. Our findings suggest sub-county variation in the population of people of color may be crucial to understanding health disparities of the COVID-19 pandemic in Colorado. Together, the results of our study contribute additional support for the need to address the disproportionate impact of COVID-19 on higher-risk populations as the pandemic response and recovery efforts continue in Colorado.This study quantifies the environmental, demographic, and socioeconomic associations and disparities for three COVID-19 outcomes in Colorado. We show the uncertainty in census-tract PM2.5 concentrations is a key factor limiting our ability to link environmental exposures and health outcomes, and highlight specific regions in Colorado where the uncertainty in PM2.5 concentrations is most impactful.In the majority of our analyses, we find that a small increase in long-term exposure to fine particle pollution is associated with a positive but non-statistically significant increase in infections, hospitalizations, and deaths due to COVID-19. It is notable that we see these results even at relatively All rights reserved. No reuse allowed without permission.In the long-term, improved understanding of the links between air pollution and human health at the neighborhood scale will require the development of improved PM2.5 surfaces that can more accurately capture variations in PM2.5 concentrations on the scale of kilometers. Increased monitoring, either from regulatory or low-cost sensors, higher resolution computer models, and remote sensing products from new satellites could all play a role in improving the accuracy and precision of PM2.5 surfaces at the neighborhood scale. In addition, there is a clear need for a method to independently validate these PM2.5 surfaces after they are generated.While the uncertainty in PM2.5 concentrations makes it difficult to establish definitive conclusions, this study provides evidence that local rates of COVID-19 infections, hospitalizations, and mortality are influenced by patterns of exposure to air pollution, racial and ethnic composition, local travel patterns, and risk factors such as aging population structure and underlying comorbidities. As such, this study could help provide a scientific basis for precisely targeting COVID-19 response efforts in Colorado based upon community-specific risk factors. For example, additional public health interventions, such as recommending ways to decrease personal exposure to fine particle pollution and considering ways to effect more social distancing, could be implemented in specific neighborhoods to better protect those most at risk.Finally, the results of this analysis indicate the need for expanded investigations regarding the link between air pollution exposure and COVID-19 outcomes. In particular, further analysis of the link between short-term air pollution exposure and COVID-19 is urgently needed to establish whether these more modifiable exposures play a role in infection and disease severity. The impact of long-term PM2.5 exposure on COVID-19 outcomes at relatively low levels of PM2.5 pollution is another area that would be helped by further research.All rights reserved. No reuse allowed without permission.The Colorado Department of Public Health and Environment acknowledges that long-standing systemic racism, including economic and environmental injustice, has created conditions that negatively affect marginalized communities, particularly people of color. These conditions, which limit opportunities for optimal health and influence individual behaviors, are critical predictors of health outcomes. To realize a future where all Coloradans can thrive, we must be leaders in undoing policies and practices that have contributed to these inequities. All rights reserved. No reuse allowed without permission.",United States,abstract,2021-02-23,02
b4af5157ec0b604cddcfb71856ee505ecf49b4dc,Human mobility and COVID-19 transmission: a systematic review and future directions,"Human mobility plays an important role in the transmission of infectious diseases. With the increase of human mobility caused by the development of transportation networks and globalization, the spread of infectious diseases can be unprecedentedly rapid and difficult to prevent and control, resulting in pandemics. Such pandemics have been witnessed in history, for example, the 1918 novel influenza A (H1N1) pandemic, the 2009 H1N1 pandemic, and the current coronavirus disease 2019 . Without a widely distributed vaccine, controlling human mobility has been identified and promoted as the primary strategy to mitigate the transmission of COVID-19 (Gatto, Bertuzzo et al. 2020 , Yabe, Tsubouchi et al. 2020 . During this pandemic, various policies have been implemented worldwide to restrict human mobility across and within countries including international travel bans and national border closures, restrictions between states and cities, stayat-home orders, limited private and public gatherings, in addition to closing schools, universities, workplaces, and public transportation (Hale and Webster 2020) .Since the outbreak, academic researchers have put substantial efforts into studying the relationship between human mobility and COVID-19 transmission (hereinafter referred to as ""mobility-transmission relationship""). Many studies have reported the efficacy of mobility restrictions on controlling the spread of the virus , Yabe, Tsubouchi et al. 2020 . However, the timeline and stringency of social restriction policies and lockdown orders have been vociferously challenged due to significant social and economic costs (Bonaccorsi, Pierri et al. 2020 , Lecocq, Hicks et al. 2020 ). In addition, the scientific comparison of data and methodologies used to examine the mobility-transmission relationship has been under-explored.To fulfill the aforementioned knowledge gaps, we conducted a systematic review of articles that measure the mobility-transmission relationship in terms of their study purposes, data usage, statistical models, and key findings. Based on our review, we offered future research directions in the spatial and temporal dimensions to researchers with similar interests in this topic. Through collective efforts from multiple disciplines, we hope to mitigate the spread of infectious diseases with evidence-based solutions and to be better prepared for the potential outbreak of future infectious diseases given the increased globalization, urbanization, and interruption of human beings to eco-systems.We followed the guidelines of the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) statement to select articles and to report the findings. PRISMA statement is a guideline developed to support researchers to conduct systematic reviews (Moher, Liberati et al. 2009 ). We applied the checklist of PRISMA with the items to report in a systematic review and a flow diagram indicating the workflow of selecting articles in a systemic review (Moher, Liberati et al. 2009 ). We commenced with searching through the Web of Science (WoS) Core Collection of all the published articles between January 2020 to September 2020 to cover the most recent publications with the topic of human mobility and COVID-19. WoS is the most widely used and authoritative database of research publications and citations. WoS Core Collection Coverage includes more than 20,900 journals plus books and conference proceedings from various disciplines (Birkle, Pendlebury et al. 2020) . The searching terms we used are ""((COVID-19 OR ""novel coronaviruses"" OR 2019-nCov OR SARS CoV-2) AND (""human mobility"" OR ""human movement"" OR ""population flow"" OR ""social distanc*"" OR ""physical distanc*"" OR ""travel restriction"" OR ""movement control"" OR stay-at-home OR lockdown OR shelter-in-place))"".The flow diagram of the article selection through different phases of the review was presented in Figure 1 . We limited our search to published and early access articles, resulting in a total number of 1,649 articles. We then excluded the articles in irrelevant areas (e.g., psychology, neuroscience, neurology, and surgery), narrowing down 868 articles. We further excluded 755 articles that do not meet our inclusion criteria (Table 1 ) by screening their titles and abstracts.Through reading and assessing full texts, 47 articles highly relevant to our review's interest were finally selected. We summarized and analyzed the information of the study countries/regions, study purposes, data resources, statistical models, and key findings. This information was summarized in Supplementary Table 1 . Based on what we found, we proposed future research directions of mobility-transmission studies.The selected papers mainly rely on two types of data: COVID-19 data at different scales and human mobility data. COVID-19 data in terms of the number of confirmed and susceptible cases, deaths, and recovered cases are usually easy to retrieve from research institutes, public health authorities, or government reports, while human mobility data are multi-sourced with specific applications. This review mainly focuses on human mobility data in terms of its sources, public accessibility, spatial coverage, time coverage, update frequency, advantages, and disadvantages ( Table 2 ).The first type of mobility data is big data gathered by technology companies, including Baidu, SafeGraph, Google, and Tencent. For example, Google mobility data is created by aggregated and anonymized data sets from users who have turned on the Location History setting in the products such as Google Maps (Aktay, Bavadekar et al. 2020) . It is encoded as a percentage change in the mobility metric compared to the baseline of human mobility from January 3 to February 6, 2020 (Aktay, Bavadekar et al. 2020) . Unlike Google mobility data, SafeGraph mobility data adds unique and valuable insights into the mobility change by estimating the aggregated and anonymized summary of foot traffic to 6 million points-of-interest in North America (Safegraph 2021) . Safegraph aggregates the data by category (e.g., Airports or Supermarkets) or brands (e.g., Costco or McDonald's) (Safegraph 2021 ). In addition, Baidu, a Chinese leading information technology (IT) company, offers location-based services to mobile devices for online searching and mapping based on the Global Positioning System, Internet Protocol addresses, locations of signaling towers, and wireless networks. Baidu Mobility Index contains daily inbound (i.e., percentage of people traveling to the city from all the cities in China) and outbound (i.e., percentage of people traveling from the city to all the cities in China) mobility data for all cities in China (except for Hong Kong, Macau and Taiwan) on each day from January 1, 2020, to May 7, 2020 (Liu, Clemente et al. 2020) . Baidu mobility data has been widely used to study how the population migration at the early stage of the COVID-19 outbreak in China. Similarly, Tencent is another Chinese leading IT company providing inter-city human mobility information by integrating air flight, train, and vehicle data. However, Tencent only released the inflow and outflow data from10 Chinese cities with the highest mobility index.The second type of mobility data is the public transit data, collected through air flights. For example, the Bureau of Transportation Statistics in the U.S. published passenger numbers of flights at the state and national level (United States Department of Transportation), which was used by Peirlinck et al. to model the spreading of COVID-19 across the U.S. . Public transit data has the advantage of compensating for the international or interregional mobility estimates, which cannot be revealed by Google mobility data. However, its key disadvantage is the roughness and availability at a relatively coarse scale, which cannot accurately simulate the spreading of COVID-19 at a fine scale.The third category is census data, which records the number of people moving between or within administrative regions. For example, the United States Census Bureau publishes yearly geographic mobility dataset by region and category including race, sex, age, relationship to householder, educational attainment, marital status, nativity, tenure, and poverty status at the national, inter-state, intra-state, inter-county, and intra-county level (United States Census Bureau). When building epidemic models to estimate the effect of human mobility on COVID-19 transmission, Gatto et al. identified mobility fluxes at the municipal and provincial levels based on the 2011 commuting data from the Italian Census Bureau (Gatto, Bertuzzo et al. 2020) .Census data is representative, easy to access, and usually available at various spatial scales (e.g., county, states, and nationwide). However, census data is usually updated infrequently, its data could be too out-of-date and unable to reflect changes in human mobility with the rapid response to the implementation of social restriction and lockdown policies during the pandemic.The selected articles rely on mathematical modeling for analysis, simulation, and prediction of the association between human mobility and COVID-19. According to Siettos et al.'s categories of mathematic modeling of infectious disease dynamics, we categorized the mathematical models used in the selected articles into three categories: statistical method, mathematical/mechanistic state-space model, and simplified arithmetic model (Siettos and Russo 2013) . The category of these analytical models was presented in Figure 2 .A total of 26 selected articles apply statistical methods, including correlation and exploratory analyses, as well as simple linear and advanced regression models. These models are mainly used in evaluating the effectiveness of social restriction policies and modeling the relationship between human mobility and COVID-transmission. The correlation and exploratory analyses conducted in these articles consist of Pearson correlation analysis , rank-sum test (two groups) (McGrail, Dai et al. 2020) , and Kruskal-Wallis test with Dunn's post hoc analysis (McGrail, Dai et al. 2020) . Other studies employ simple linear regressions models, including feasible generalized least squares fixed effect model (Yang, Chen et al. 2020 , Zhang, Litvinova et al. 2020 , generalized linear estimating model ), hierarchical linear model (Alfano and Ercolano 2020), multivariate regression model (Sirkeci and Yüceşahin 2020) , quasi-Poisson regression model (Tobías 2020) , and binary regression model (Yuan, Xiao et al. 2020) . However, such methods have limitations;Among the selected articles, one study uses a simplified arithmetic model (Killeen and Kiware 2020) with simple calculations (e.g., addition, subtraction, multiplication, division, rounding off, a few conditional statements, and two unavoidable power terms) to ease the interpretability of the model. This model enables non-specialist readers to understand the process of modeling and in-depth inspect numerical predictions.The selected articles aim to 1) examine the effectiveness of policy-induced mobility control on COVID-19 (hereinafter referred to ""policy implementation and evaluation""); 2) predict the COVID-19 dynamic through modeling or simulating human mobility or its related measures (hereinafter referred to ""simulation and prediction""); 3) compare studies presenting the association between human mobility and COVID-19 across countries or regions (hereinafter referred to as ""cross-country/region comparison""). The key findings of each purpose were presented below. Some articles may fall into more than one category if they contribute to each category equivalently.The relationship between human mobility and the virus spread is temporal and spatial heterogeneity, along with observing a time-lag effect of mobility on the virus spread. Policy interventions, despite being globally effective in reducing both the spread of infection and its self-sustaining dynamics, have had heterogeneous impacts locally (Dickson, Espa et al. 2020 , O'Sullivan, Gahegan et al. 2020 . For example, large metropolitan areas encounter more disruptions and larger challenges to control infection because they cannot easily be broken down into separately managed regions (O'Sullivan, Gahegan et al. 2020). Laborintensive cities in China need to take stronger measures to prevent a potential rebound in COVID-19 cases after releasing the restriction policies . Lockdown on public transport (e.g., auto, railway, coach, and flight) in China has the most prominent impact on virus control compared to lockdown on other public spaces (Zheng 2020) . Researchers found in India that a prudent post-lockdown strategy might focus on easing physical distancing restrictions within high-risk places while maintaining restrictions between high-risk places (DeFries, Agarwala et al. 2020) Moreover, policy measures need to be adjusted across the different phases of the pandemic. In the initial stage of the outbreak, human mobility from Wuhan to other places in China was highly relevant to the growth rate of the COVID-19 cases in other cities and provinces. Still, this association became negative after the implantation of Wuhan lockdown and other travel restrictions nationally . Additionally, the reduction of infection caused by mobility control is observed to be relatively weaker in places where the outbreak occurred later .Furthermore, mobility control is observed to have a time-lag effect on the virus transmission and such effect varies across the geographic contexts and the timeline of the pandemic. In this U.S., researchers found that social distancing reduced the daily growth rate of confirmed COVID-19 cases by 5.4 percentage after one to five days but 9.1 percentage points after sixteen to twenty days (Courtemanche, Garuccio et al. 2020) . Studies across various countries reported that the efficacy of lockdown continues to hold over two weeks or even up to 20 days after a lockdown was implemented Ercolano 2020, McGrail, Dai et al. 2020) .Scholars find that the timing, effectiveness, and stringency of policy implementation are crucial for the success of COVID-19 control efforts in different countries (Gupta, Jain et al. 2020 , Ngonghala, Iboi et al. 2020 )(). The early implementation of social and mobility restrictions is especially effective in lowering the peak value of new infections and reducing the infection scale (Bherwani, Anjum et al. 2020 , Kaur, Bherwani et al. 2020 , Yuan, Xiao et al. 2020 . Ngonghala et al. asserted that ensuring the high adherence/coverage of policy intervention and enhancing the effectiveness of such intervention is particularly important in control infection in the local community (Ngonghala, Iboi et al. 2020) . However, policymakers are more concerned about the public pressure towards lockdown mitigation as well as the downside of restrictive lockdown, for example, the tradeoff of social and economic upheaval (Westerhoff and Kolodkin 2020) . For example, Tsay et al. support the ""on-off"" policies alternating between strict social restriction and relaxing such restrictions can be effective at flattening the infection curve while likely minimizing social and economic cost, especially for the places where persistent small outbreaks oscillate between high-risk regions for many months ).Another stream of the selected articles focuses on proposing and developing mathematical models to simulate and predict dynamics of COVID-19 with various assumed plans or policies in limiting human mobility or altering time variances of certain plan and policies to predict disease changes (e.g., (Gupta, Jain et al. 2020 , Jia, Lu et al. 2020 ).The modeling work conducted in our selected papers provides similar findings regarding policy implementation and mobility control as described above. Also, these modeling work bring in technical benefits as follows to help estimate outbreak dynamics and provide decision guidelines for successful outbreak control . First, policy interventions parameterized in the modeling process are adjustable, allowing the evaluation of local policy scenarios and relaxing political measures (Rainisch, Undurraga et al. 2020) . For example, Gatto et al. measured averted hospitalizations by running scenarios obtained by selectively relaxing the imposed restrictions to support the planning of emergency measures (Gatto, Bertuzzo et al. 2020 ). Second, developing multi-disciplinary models are able to explore temporal changes in spreading patterns and outbreak dynamics ) and estimate the potentials of vaccination ). As Salje et al. asserted, population immunity appears insufficient to avoid a second wave if all social restrictions are released at the end of the lockdown (Salje, Tran Kiem et al. 2020) . Third, some models can predict the outbreak spreading and the pandemic cessation dates (Aviv-Sharon and Aharoni 2020, Jia, Lu et al. 2020 ).The comparison of modeling results across different locales and various scenarios serves as a direct tool to detect community transmission burden (Jia, Lu et al. 2020 ).Several comparison studies reveal findings specific to different geographic contexts that have not been covered in the previous summary. In general, policy interventions may well explain the majority of cross-country variation in virus control in the initial stage of the pandemic (Balmford, Annan et al. 2020) . However, these are less definitive conclusions if extended to a full spectrum of the pandemic. Mobility restriction policies implemented during the pandemic differ widely around the world. Policies that work well in one country may not be effective in other places. For instance, Kaur et al. indicated that countries that acted late in bringing in the policy intervention suffered from a higher infection rate than countries that reacted faster (Kaur, Bherwani et al. 2020) . It is partially in line with the findings from a 10-country comparison that countries that have not imposed lockdown or have imposed lockdown either late or without stringency have performed poorly in infection control, except for Korea (Moosa 2020) . The outbreak in Korea has been controlled rather well without a full lockdown, as Korea conducted a combination of interventions including border control, testing, tracing, the quality of the healthcare system, preparedness for epidemics and pandemics, and population density (Moosa 2020 ). Thus, when it comes to implementing different policy approaches to the pandemic, careful consideration of cross-country differences is required in terms of countries' nature as well as their demographic and socioeconomic variations. Yang et al. observed that China has efficient government initiatives and effective collaborative governance for mobilizing corporate resources to provide essential goods; however, this mode may be not suitable to the UK where it is more possible to take a hybrid intervention of suppression and mitigation to balance the total infections and economic loss (Yang, Qi et al. 2020 ).Future studies should involve the expertise of researchers and professionals across disciplines.First, since covert transmission may be the main mode of spread and subject to the risk of a second epidemic peak, and its role is severely underestimated (Ding and Gao 2020), epidemiologists and other health professionals can contribute to the measurement of covert cases, which can be used in future modeling. Second, policy interventions that are widely discussed to control mobility are lockdown, social distancing, and travel restrictions. However, these strategies can be extended to border controls at a regional or national level as well as testing and contact tracing policies at an individual level (Moosa 2020). Herein, policymakers and stakeholders should be involved to optimize the quantification of policies. Third, the effect of seasonality on the transmission dynamics of COVID-19 is underestimated in current scholarship Ercolano 2020, Gupta, Jain et al. 2020) , although some scholars assume that the decrease of COVID-19 infection may be suspiciously attributable to unknown seasonal factors, for example, temperature and absolute humidity (Lai, Ruktanonchai et al. 2020 , Rainisch, Undurraga et al. 2020 . Referring to the fact that the transmission of similar respiratory illnesses (e.g., influenza, syncytial virus) peaks in winter (Lipsitch and Viboud 2009, Shaman and Kohn 2009) , the evaluation of the seasonality effect is needed.The resurge of infection has also been observed to be associated with the release of national border controls (Moosa 2020); therefore, widespread decisive national action and international co-operation are required to conditionally reopen trade and travel between countries. Great caution is needed as gradual, exploratory steps toward reopening (Courtemanche, Garuccio et al. 2020 ) as even a slight relaxation of lockdown or importation controls may cause containment failure (Killeen and Kiware 2020) . A combination of multiple interventions may achieve the strongest and most rapid effect on containing the spread of the virus (Lai, Ruktanonchai et al. 2020 ). In addition, health education about the risk and severity of COVID-19 infection is needed to increase public awareness (Ding and Gao 2020).Migration data used in current publications largely came from public sources, including data released by large companies (e.g., migration data from Baidu, Google, Apple, Facebook, and Twitter), global mobility network, and mobile phone companies (Zhang, Dong et al. 2020 ).There are limitations of these data sources. Some data are country-specific; for example, the Baidu migration data is only available in China (Yuan, Xiao et al. 2020) . Second, mobility data retrieved from mobile phones or mobile app users designed by large companies encounter data biases in population coverage, which may exclude some specific subgroups particularly children and aged populations who may not use mobile phones (Banerjee and Nayak 2020, Lai, Ruktanonchai et al. 2020 ). The index-based mobility data (e.g., provided by Google, Baidu, and Apple) does not include population inflow to and/or outflow from a given place. Alternatively, user-based social media big data (e.g., geotagged Twitter data) is able to indicate the interregional movement to improve the accuracy of models (Gupta, Jain et al. 2020 , O'Sullivan, Gahegan et al. 2020 ), although such big data is less used in current studies. With the technological advancements and the emergence of further refined data, it will be interesting in future studies to involve additional data, to use a combination of multi-sourced data, and to compare the reliability and quality of data (Banerjee and Nayak 2020, McGrail, Dai et al. 2020) . Moreover, data sharing and information disclosure are encouraged for future studies.The study has limitations that should be noted. First, we did not include non-peer-reviewed articles (e.g., working papers and preprints) in this review. Traditional peer review usually takes months from submission to publication, while timely reporting of research findings is a priority during the pandemic, which dramatically increased the use of preprint service (Jung, Sun et al. 2020 ). Though preprints provide direct and rapid access to information, criteria used to justify preprints are not available. Thus, we only searched for published and early access articles, which inevitably exclude the findings from some popular non-peer-reviewed articles. Second, this review includes a small number of eligible articles focusing on Africa and South America which could be due to the late appearance of the first case in some regions as well as the limited funding and resource to conduct COVID-19 related research. Third, our search obtained limited articles covering the second and third waves of the COVID-19 pandemic, which has been observed in several countries after lifting mobility restriction policies. The findings summarized in this review may not well explain the resurged cases or the cases via converted transmission over a long time. Thus, we encourage future researchers to extend our systematic review to cover a longer period and to include the most updated results from both published and preprint articles from various regions.Inclusion 1) measure the association between human mobility and COVID-19 transmission, 2) measure the association between human mobility-related policies and COVID-19 transmission, and 3) apply quantitative methods.Exclusion 1) measure the association between human mobility and other COVID-19 pandemic related issues, e.g., economic development, mental health, family relationship, 2) apply qualitative methods.Population movement makes a substantial contribution to the disease spread in the early stage of the outbreak, Travel bans were effective but would have been more helpful if implemented earlier.Cities that are labor-intensive need to take more strong measures.Correlation model Baidu migration 3To track and analyze the development of the COVID-19 outbreak in the top 100 cities that were destinations for people who left Wuhan before the city entered lockdown.Higher intensities of population movement were associated with a higher incidence of COVID-19 during the pandemic.Baidu maps smart eye database 4To explore the correlation between migration scale index and the number of confirmed COVID-19 cases. To depict the effect of 'Wuhan lockdown' and Hubei province launching the first-level response to major public health emergencies on the control of the COVID-19 epidemic.The measures in Wuhan and Hebei Province may have had a good effect on controlling the COVID-19 epidemic.Baidu migration 5 Zou et al.To summarize the outbreak dynamics using three parameters that characterize the epidemic's timing, rate, and peak. To analyze the trends of incident cases, deaths, and intensive care unit admissions (ICU) in Spain Lockdown in Italy and Spain reduced the diagnosed cases and ICU admissions, especially in Spain.and Italy before and after their respective national lockdowns.To estimate the impact of the lockdown and current population immunity on SARS-CoV-2 transmission.The lockdown initiated on 17 March 2020 reduced the reproductive number. Population immunity appears to be insufficient to avoid a second wave if all control measures are released at the end of the lockdown. To compare cross-country COVID-19 statistics by considering differences in reporting and variation in underlying socioeconomic conditions across countries.Cross 8 countries a further week-long delay in imposing lockdown would likely have cost more than half a million lives. Those countries which acted more promptly saved substantially more lives than those that delayed. While the economic burden of lockdown is large, prompt lockdown could save lives and generate net benefits for society. To assess the efficacy of social distancing on the spread of COVID19 in the U.S. and worldwide.In the U.S., the implementation of social distancing policies corresponded with a reduction in COVID19 spread rates, and that the reduction in spread rate is proportional to the average change in mobility. Globally, social distancing policies significantly reduced the COVID19 spread rate, resulting in an estimated 65% reduction in new COVID19 cases over a two-week time period. To explore the effects of lockdown and medical resources on the COVID-19 transmission in Wuhan.The later Wuhan takes the lockdown measures, the lower the peak value of new infections and the smaller the final scale. Susceptible-exposedinfected-quarantinedrecovered (SEIQR) model 21 Zheng et al. China To predict the role of lockdown on different transport (auto, high-speed railway, common railway, coach, and flight) means and analyze its impact on the disease transmission.The spread of the crisis is not purely dependent on the transportation situation, but also affected on the control methods conducted by the public power and on the other hand by the frequency of local economic activities as well as the occurrence number of crowd-collected activities. To develop a mathematical model, the SEIAR-SD model, of the COVID-19 pandemic for predicting the COVID-19 number of cases, progression of the pandemic, and its duration.In the absence of an effective treatment or a vaccine against COVID-19, social distancing (lockdown) and public health interventions including case detection with testing and isolation, contact tracing and quarantining, will be crucial for the prevention of the spread of the pandemic,The susceptibleexposedinfectious/asymptom atic-recovered social distancing (SEIAR-SD) model To measure the geographical spread of COVID-19 and the growth pattern based on the population outflow from Wuhan.To document the efficacy of quarantine in ceasing movement.We modeled the epidemic curves of COVID-19 across different locales using population flows and showed that deviations from model predictions served as tools to detect the burden of community transmission. This approach can be used by policy-makers in any nation with available data to make rapid and accurate risk assessments and to plan the allocation of limited resources ahead of ongoing outbreaks. To introduce a novel optimization-base decision-making framework for managing the COVID-19 outbreak in the US, including the dynamics of affected populations, estimating the model parameters and hidden states from data, and an optimal control strategy for sequencing social distancing and testing events such that the number of infections is minimized.Social distancing and quarantining are most effective when implemented early, with quarantining of confirmed infected subjects having a much higher impact. ""on-off"" policies alternating between strict social distancing and relaxing such restrictions can be effective at ""flattening"" the curve while likely minimizing social and economic cost. To compare the progress of the pandemic in Italy, Germany, and Turkey based on transmission simulations in an attempt to examine 1) the reasons of differences in active cases and fatality rates 2) the number of tests and possible quarantine schemes to control the spread of the pandemic.The estimates of the number of initial cases in Italy compared to Turkey and Germany are higher.Turkey will probably experience about 30% less number of fatalities than Germany due its smaller elderly population. If social distancing and work contacts are limited to 25% of daily routines, Germany and Turkey may limit the number of fatalities to a few thousand as the reproduction number decreases to about 1.3 from 2.8. Random testing may reduce the number of fatalities by 10% upon testing least 5/1000 of the population. Quarantining of family and workmates of positively tested individuals may reduce the total number of fatalities by about 50%. To measure the response of the Serbian government and health authorities to the SARS-CoV-2 pandemic in the early stage of the local outbreak between Mar.Initial exponential growth slows down within the presumed incubation period of 2 weeks after adopting lockdown and other nonpharmaceutical epidemiological measures.Exponential growth 15th and Apr. 15th, 2020 by predictive numerical models.Quarantine and other social distancing measures should be adopted as soon as possible in a case of any similar outbreak since alternatives mean prolonged epidemical situation and growing costs in human life, pressure on the health system, and economy. Africa To describe two spatially explicit models created for simulating and addressing the evolution of the COVID-19 pandemic on a regional basis.The application of a regionally varying series of lockdown policies is likely to be just as effective at minimizing contagion, while offering advantages of less restrictive rules for part of the population. ",USA,first author,2021-02-05,02
6158a5db11ff260fd42d08ad229eb054b02b47af,,"After the first detected COVID-19 case in New York City (NYC) on March 1, 2020, the city rapidly became the first epicenter of disease in the United States. As of April 2020, at its peak the NYC Department of Health and Mental Hygiene (NYCDOHMH) reported 15 days in that period with over 6000 new confirmed cases of COVID-19 and over 500 deaths (New York City Department of Health and Mental Hygiene, 2020a) . There is emerging evidence that marginalized (i.e. low-income) and vulnerable (i.e. racial and ethnic minority) populations are disproportionately affected by COVID-19 (Webb Hooper et al., 2020; Alsan et al., 2020) . Black and Hispanic/Latinx people in the U.S. experienced higher case rates and death rates compared to Whites, and there was a clear socio-demographic gradient in COVID-19 infection by income and poverty (New York University Furman Center, 2020; Price-Haywood et al., 2020; Raifman and Raifman, 2020) . Occupational characteristics were associated with risk for the disease as well as secondary transmissions; e.g., workers in the healthcare sector and other essential service occupations were at higher risk for infection, due to frequent interactions with possibly infected individuals, and being in close quarters for extended periods of time with other workers (Baker et al., 2020) . In addition to the individual-level characteristics, environmental factors in urban contexts such as urban design, housing density, and transportation systems can impact the transmission of infectious diseases (Harlem, 2020) . Highly populated neighborhoods and multi-family housing structures tend to increase person-to-person contacts, which in turn can exacerbate community transmission (Rocklov and Sjodin, 2020; Ghinai et al., 2020) . The frequent use of public transportation systems has also been noted as a potential risk factor of COVID-19 in urban areas (Zheng et al., 2020) .Recent analytic studies looking at associations between neighborhood characteristics and the geographic distribution of COVID-19 have focused on socio-demographic factors, but have not explored the contribution of environmental factors. In addition, as SARS-CoV-2 testing and COVID-19 case/death rates show geographical clustering with high spatial autocorrelation (Kang et al., 2020) , it is critical to properly adjust for such spatial similarity in the modeling stage. Lastly, with the advent of COVID-19, the socio-demographic landscapes in NYC changed due to residents moving out of NYC in response to the pandemic. On average, 5% of NYC residents left the city between March 1 and May 1, but the proportion of residents who left the city was socially patterned and varied substantially across neighborhoods (Quealy, 2020) . The COVID-19 rates provided by NYCDOHMH are based on estimated populations from census data before the pandemic; thus, the SARS-CoV-2 testing and COVID-19 case/death rates are likely to be biased estimates. To the best of our knowledge, none of the recent studies on socio-demographic predictors of COVID-19 cases, testing, or hospitalizations have incorporated data on NYC's population changes across neighborhoods, and few have accounted for spatial dependencies that could bias estimates. In this study, we examine the geographic variation in socio-demographic characteristics, migration patterns, mobility, and built environmental factors in NYC in relation to COVID-19 rates, using spatial analytic methods to address potential issues of spatial autocorrelation.COVID-19 statistics for testing, positive cases, and death counts of New York City residents by residential ZCTA (ZIP Code Tabulation Area) were obtained from the New York City Department of Health and Mental Hygiene on June 10, 2020 (New York City Department of Health and Mental Hygiene, 2020c). The NYCDOHMH reports data using modified ZCTAs, with certain boundaries modified to combine areas with small or no populations to allow for stable estimates of COVID-19 rates. After combining 34 such ZCTAs, there were a total of 177 modified ZCTAs (referred to simply as ZCTAs from now on) with valid COVID-19 data included in this analysis. The three outcomesnumber of SARS-CoV-2 tests, COVID-19 cases, and deathswere normalized by the population of their ZCTAs and used as outcomes. The total population by ZCTA was obtained from the 2018 American Community Survey 5-year estimates. As our method for spatial regression analysis can only account for areas with physically-touching neighbors, one ZCTA with no neighboring areas (10044: Roosevelt Island) was excluded from the analysis. Another island in NYC, Rikers Island, is included in the analysis as it is incorporated into ZCTA 11370, which contains land in Queens (Astoria Heights) that shares boundaries with neighboring ZCTAs.Pre-pandemic socio-demographic characteristics were calculated by ZCTA from the 2018 American Community Survey 5-year estimates, including age, sex, race/ethnicity, median income, household size, occupation, and commuting characteristics (U.S. Census Bureau, 2020). Specifically, variables included in the present analysis as predictors of COVID-19 outcomes were: male-to-female ratio (number of male/number of female); percentages of the population under 18 (used as reference), 18-44, 45-64, 65-74, and over 75 years; percentages of non-Hispanic White (used as reference), Black, Asian, others, and Hispanic populations; median household income; average household size; percentages involved in essential service occupations (firefighting, law enforcement, building and ground cleaning and maintenances, food preparation and serving related, and personal care) and health-related occupations (healthcare practitioners and technical occupations, healthcare support services); and percentage commuting via public transit. The socio-demographic variables were estimates from 2014 to 2018 surveys, and therefore the data may not fully reflect characteristics during the pandemic. Socio-demographic variables expressed as proportions were re-scaled such that a 1-unit change reflected the inter-quartile range (IQR), that is, the difference between the 75th and 25th percentile ZCTA.A zoning map for NYC was obtained from the NYC Department of City Planning (New York City Department of City Planning, 2020), and each ZCTA's percentages of land assigned to low and high-density residential zonings were calculated using Quantum GIS v3.10. (QGIS Development Team, Open Source Geospatial Foundation Project). Residential zones R1-R5 are classified as low-density zones, predominantly consisting of detached or semi-detached single-and two-family housing. Zones R6-R10 are classified as higher-density residential zones, and allow for high-rise multifamily housing (New York City Department of City Planning, 2018).Lastly, in order to account for residents moving out of the city during the COVID-19 pandemic, a dataset from cellular phone usage was utilized as a proxy measure of population changes. The data from cellular phone towers captures the mobility and migration patterns of a wide range of residents, as the towers interact with all types of cellular devices even when those devices are in stand-by and calls are not in progress. More than 1 million cellular devices that interacted with cellular towers in NYC were analyzed, and the percentage change in registered cellular phone signals between March 1, 2020 and May 1, 2020 were aggregated into census tracts by Teralytics Inc. (New York, NY). These data were provided to our research team by The New York Times (Quealy, 2020) . The census-tract-level data were converted to ZCTAs with the help of Crosswalk Files provided by the U.S. Department of Housing and Urban Development. For ZCTAs containing area from multiple census tracts, we calculated a weighted average of the component census tracts' population change rates. Weights were determined by calculating the proportion of residential addresses in a ZCTA contained within each given census tract (U.S. Department of Housing and Urban Development). The resulting ZCTA-level percent decreases in residential population was conceptualized as an ""out-migration"" index, and this metric was included in our analyses as a covariate.Spatial autocorrelation indicates geographical interdependencies among observations in data. When spatial autocorrelation is detected, the major assumptions of uncorrelated error terms and independence of observations are violated. This can lead to biased parameter estimates, necessitating adjustment for spatial clustering (LeSage and Pace, 2009; Ward and Gleditsch, 2019) . Therefore, we first tested for spatial autocorrelations of all variables using the Global Moran's I. In this study, a row-standardized binary contiguity spatial weight matrix with first-order queen's criteria was employed, which is a conventional spatial matrix for areal data (Haining, 1991) . A pseudo p-value of the Global Moran's I for each variable was estimated from a Monte Carlo simulation of 999 random iterations. Second, spatially adjusted Spearman correlations were tested to evaluate bivariate correlations between study variables and COVID-19 rates based on a spatial adjustment method proposed by Clifford and Richardson (Clifford and Richardson, 1985; Duncan et al., 2011) .After evaluating spatial autocorrelation for each variable of interest, we tested regression models for each exposure variable after adjusting for both the spatial autocorrelation and the out-migration index. This set of regression models provides unbiased crude associations between neighborhood-level factors and COVID-19 rates, adjusting for the potential confounding due to out-migration. Lastly, a set of spatially adjusted multivariable models with all neighborhood characteristic variables were specified. Because the neighborhood-level socio-demographic and built-environmental factors are interconnected (Leal et al., 2012) , we tested variance inflation factors (VIF) for each variable to check the degree of multicollinearity (Song et al., 2017) . We employed a cut-off point of 10, considering the sample size of the analysis and underlying correlations between socio-demographic characteristics (Craney and Surles, 2002) .In the model with COVID-19 case rate as the outcome, we included testing rate as a covariate because the case rate is associated with the number of tests conducted in a ZCTA. Likewise, the case rate was included as a covariate in the model with COVID-19 death rate as the outcome. The multivariable models were adjusted for spatial autocor-relation contingent on Lagrange Multiplier (LM) test results. The LM tests evaluated spatial error and lag dependences from non-spatial ordinary least squares (OLS) models (LeSage and Pace, 2009). Based on the test results, spatial error models or spatial lag models were developed to account for spatial autocorrelation (LeSage and Pace, 2009; Ward and Gleditsch, 2019) . The spatial error model equation can be represented as follows:Where y is the dependent variable; β is the vector of the regression parameter associated with the matrix of observations on the covariates X; λ is the spatial autoregressive coefficient that indicates the extent to which the spatial component of the errors is correlated with each other; W is the given spatial weight matrix; and μ is an independent error term. The spatial lag model considered is given by:where y is the dependent variable; ρ is the spatial autoregressive coefficient for the lagged dependent variable matrix Wy (W is the given spatial weight matrix); β is the vector of coefficients of regression parameters associated with the independent variable matrix X; and ε is an error term that is assumed to be independent and identically distributed.In the spatial lag model, therefore, spatial autocorrelation is introduced in the form of the spatially dependent variable, as the outcomes in one place predict an increased likelihood of similar outcomes in neighboring places.The Akaike Information Criterion was examined for goodness-of-fit (Bozdogan, 1987) . All statistical analyses were conducted in R statistical software version.Maps showing COVID-19 testing, case and death rates and selected Fig. 1. COVID-19 testing, case, death rates (/100,000) and socio-demographics in New York city by ZCTA socio-demographic characteristics by ZCTA are provided in Fig. 1 . Table 1 provides descriptive statistics and the spatial autocorrelation statistic (Moran's I) for each study variable. The city-wide SARS-CoV-2 testing rate was 9569.9 per 100,000 population (standard deviation across ZCTAs (SD): 2641.5), and the COVID-19 case and death rates were 2286.8 (SD: 878.0) and 188.7 (SD: 102.0) per 100,000 respectively. The Moran's I statistics show strong spatial autocorrelation of all variables of interest, indicating the violation of independence of observations. For example, the COVID-19 case rate has high spatial homogeneity (Moran's I = 0.75, p-value<0.01).The spatially adjusted Spearman test illustrates the rank-order correlations between COVID-19 rates and variables of interest (Table 2) . For example, a high percentage of the population in health-related occupations is highly correlated with SARS-CoV-2 testing (rho = 0.41), case rate (rho = 0.62), and death rate (rho = 0.50). The out-migration index was associated with lower testing (rho = − 0.29), case (rho = − 0.57) and death (rho = − 0.40) rates, meaning that ZCTAs that lost more of their population during the pandemic had lower rates for all three outcomes assessed. Bivariate and multivariable model estimates for each outcome are provided in Table 3 . The bivariate analyses indicated predictors of each COVID-19 rate after adjusting for spatial autocorrelation and outmigration. The Moran's I values for the non-spatial multivariable OLS regression residuals showed evidence of spatial autocorrelation in each model, confirming the need for a spatial error model or a spatial lag model. The LM tests of OLS models indicate that spatial lag models would be better-fitting models for SARS-CoV-2 testing and case rates, whereas a spatial error model could be applied for COVID-19 death rate (Florax et al., 2003) . Lastly, the VIF tests for each multivariable OLS model detected high multicollinearity of one independent variable: the percentage of people in the ZCTA working service jobs (VIF > 10). We therefore fitted spatial lag and error models without that variable, and the results remained stable in terms of the size and confidence interval of each coefficient (data not shown).From the multivariable spatial lag model (Table 3) (the interquartile range) shows a +2238 per 100,000-person difference in the testing rate, after adjusting for covariates. (Table 3 ). The out-migration index score was positively associated with ZCTA-level case rates (β = 11.5, CI: [0.2, 22.8]). (β = 48.3, CI: [20.9, 75 .7]) were positive predictors of COVID-19 death rate. The out-migration index score was not associated with ZCTA-level COVID-19 death rates.The aim of this study was to examine social and environmental determinants of COVID-19 in NYC. To the best of our knowledge, this is the first study to address the potential bias due to residents moving out of the city at differential rates across neighborhoods. News-media reported that out-migration varied strongly by neighborhood socio-demographic characteristics, and our analysis found that neighborhood level outmigration, as measured by cell phone derived data, was also associated with COVID-19 case rates. As reported in the Supplemental table (Table S1) , there appeared to be modest confounding by out-migration; the sizes of coefficients for parameter estimates differed between models that did and did not adjust for the out-migration. After adjustment for out-migration, we identified potential drivers of SARS-CoV-2 test, case, and death rates, including a ZCTA's composition by sex, age, race/ ethnicity, income, and occupational risks. Specifically, our results showed that higher percentages of residents who were Black and Hispanic were positively associated with COVID-19 case rates. We also confirmed that neighborhoods with higher percentages of essential Boldface indicates statistical significance.service and healthcare-related workers had increased SARS-CoV-2 testing and death rates. These findings are consistent with recent studies on the social determinants of COVID-19 (New York City Department of Health and Mental Hygiene, 2020a; Webb Hooper et al., 2020; New York University Furman Center, 2020; Baker et al., 2020) . Contrary to the existing findings (Harris, 2020) , higher pre-pandemic transit ridership in a neighborhood was not associated with higher COVID-19 case or death rates. Subway use has decreased dramatically after the declaration of a local state of emergency (Sy et al., 2020) , and this null association may reflect the reduced overall ridership during the pandemic. Another possible explanation could be increased vigilance in transit ridersand subsequent higher levels of health-promoting behaviors such as physical distancing and mask-wearingdue to public awareness of the risk for infection in enclosed spaces. Additionally, the NYC Metropolitan Transportation Authority (MTA) worked to mitigate COVID-19 transmission risk by regularly disinfecting all subways and buses, installing hand sanitizers in all stations, and marking six feet of distance on subway platforms (Goldbaum 2020) (New York City Office of the Mayor, 2020).Our results indicated that neighborhoods zoned for predominantly low-density housing had higher COVID-19 case rates than those zoned for predominantly high-density housing. While this is not consistent with the conventional hypothesis (Rocklov and Sjodin, 2020) , there are inconsistent findings regarding the association between population density and COVID-19 rates. Recent studies on neighborhood-level factors in Chinese and European cities reported that population density was negatively or not associated with COVID-19 (Liu, 2020; Gerli et al., 2020) . One explanation could be the differential application of mitigation strategies. Early in the pandemic the Center for Disease Control and Prevention and the NYCDOHMH announced guidelines for maintaining safe operations of multifamily housing, including closing public areas in the building, disinfecting common areas, providing hand sanitizer in common areas, and mandatory mask-wearing (Centers for Disease Control and Prevention, 2020; New York City Department of Health and Mental Hygiene, 2020b) . A myriad of high-rise residential buildings in NYC voluntarily implemented such recommendations (Amy Plitt, 2020), and such vigilance may be associated with the relatively low COVID-19 case rates in neighborhoods zoned for high-density residential buildings. Visual inspection of the map (Fig. 1) shows that areas with the highest percentage of low-density housing are located on the periphery of the city. It is possible that such a geographic location could lead to lower access to healthcare and social support, and subsequent higher COVID-19 risk despite any protections conferred by living in low-density housing (Ji et al., 2020) .There are limitations in this analysis. First, the city's COVID-19 testing and case data are not necessarily representative of the underlying populations at risk or experiencing COVID-19 infection in their ZCTA. Of note, until early May the NYC DOHMH discouraged people with mild and moderate symptoms from being tested due to limited testing resources. Therefore, these reported rates are subject to potential selection/sampling bias as well as misclassification. To illustrate, NYC overall is 52% female and 48% male (U.S. Census Bureau, 2020), but the testing breakdown by sex was 56% female and 44% male. Because COVID-19 testing and case data did not come from a randomly sampled or representative population, our analyses may be confounded by the skewedness of the underlying data. However, the COVID-19 testing, case, and death rates from the DOHMH were the best and only available data to estimate population-level COVID-19 in NYC. Second, this analysis is susceptible to many common problems in neighborhood-level analyses. It is susceptible to the ecological fallacy: that the associations found in aggregated data may not translate to corresponding associations at the individual level. Additionally, in ecological studies measurement errors in the predictor variables can bias results away from the null (Brenner et al., 1992) . Our unit of analysis, ZCTA, and similar geographic boundaries can be subject to the modifiable area unit problem (MAUP) -potential bias due to the artificial aggregation of point-based data (Wong, 2009) . Third, there is a temporal mismatch between the COVID-19 statistics and the socio-demographic data used in this analysis. COVID-19 data were retrieved on June 10, 2020, whereas the American Community Survey data are estimates from a 5-year survey conducted between 2014 and 2018. Fourth, the analysis is also susceptible to potential residual confounding, such as by the uneven distribution of underlying health conditions by neighborhood. For example, chronic respiratory and cardiovascular diseases can increase the risk for COVID-19 death (Jordan et al., 2020) , and may also be associated with neighborhood conditions, but such measures were not Boldface indicates statistical significance.incorporated in this analysis due to lack of available data. Lastly, the cellular phone data-based estimates of out-migration provided by The New York Times may not fully capture people's movement in and out of the city, since phone usage may systematically differ from actual mobility of the residents in corresponding ZCTA.This study provides important information on neighborhood-level factors and their association with COVID-19, in the context of a large metropolitan city with a high burden of COVID-19 in the United States. In addition to socio-demographic characteristics like neighborhoodlevel distributions of sex, age, and race/ethnicity, we must also focus on the impacts of the built environment on COVID-19 transmission and mortality. Future research should emphasize interactions between health behaviors (i.e. social distancing and commuting behaviors) and built environments in order to shed light on the environmental determinants of COVID-19.This research did not receive any specific grant or funding from agencies in the public, commercial, or not-for-profit sectors.",United States,first author,2021-02-19,02
b03002113d950a29b23fe7e7d74af875986f6e84,Assessing mandatory stay-at-home and business closure effects on the spread of COVID-19,"The spread of COVID-19 has led to multiple policy responses that aim to reduce the transmission of the SARS-CoV-2. The principal goal of these so-called nonpharmaceutical interventions (NPI) is to reduce transmission in the absence of pharmaceutical options in order to reduce resultant death, disease and health system overload. Some of the most restrictive NPI policies include mandatory stay-at-home and business closure orders ('lockdowns'). The early adoption of these more restrictive nonpharmaceutical interventions (mrNPIs) in early 2020 was justified because of the rapid spread of the disease, overwhelmed health systems in some hard-hit places and substantial uncertainty about the virus' morbidity and mortality. 1 Because of the potential harmful health effects of mrNPI-including hunger, 2 opioid-related overdoses, 3 missed vaccinations, 4, 5 increase in non-COVID diseases from missed health services, [6] [7] [8] [9] domestic abuse, 10 mental health and suicidality, 11, 12 and a host of economic consequences with health implications 13,14 -it is increasingly recognized that their postulated benefits deserve careful study. One approach to evaluating NPI benefits uses disease modelling approaches. One prominent modelling analysis estimated that, across Europe, mrNPIs accounted for 81% of the reduction in the effective reproduction number (R t ), a measure of disease transmission. 15 However, in the absence of empirical assessment of the policies, their effects on reduced transmission are assumed rather than assessed. 16, 17 That analysis attributes nearly all the reduction in transmission to the last intervention, whichever intervention happened to be last, complete lockdowns in France or banning of public events in Sweden. 16 Another, more empirically grounded approach to assessing NPI effects uses statistical regression models and exploits variation in the location and timing of NPI implementations to identify changes in epidemic spread following various policies. 18 These empirical studies find large reductions in the growth rate of new cases that are attributable to NPIs. An important challenge with these analyses is that they use pre-policy growth rates to determine the 'counterfactual' trajectory of new cases-the expected case growth rate in the absence of NPIs. This is problematic because it is widely recognized that epidemic dynamics are time-varying, and brakes on disease transmission occur without any interventions (through resolution of infections), as well as from behaviour changes unrelated to the NPIs. 19, 20 These epidemic dynamics are demonstrated by an analysis showing that slowing of COVID-19 epidemic growth was similar in many contexts, in a way that is more consistent with natural dynamics than policy prescriptions. 21 These challenges suggest that assessing the impact of mrNPIs is important, yet difficult. We propose an approach that balances the strengths of empirical analyses while taking into consideration underlying epidemic dynamics. We compare epidemic spread in places that implemented mrNPIs to counterfactuals that implemented only less-restrictive NPIs (lrNPIs). In this way, it may be possible to isolate the role of mrNPIs, net of lrNPIs and epidemic dynamics.Here, we use Sweden and South Korea as the counterfactuals to isolate the effects of mrNPIs in countries that implemented mrNPIs and lrNPIs. Unlike most of its neighbours that implemented mandatory stay-at-home and business closures, Sweden's approach in the early stages of the pandemic relied entirely on lrNPIs, including social distancing guidelines, discouraging of international and domestic travel, and a ban on large gatherings. 22, 23 South Korea also did not implement mrNPIs. Its strategy relied on intensive investments in testing, contact tracing and isolation of infected cases and close contacts. 24, 25 We isolate the effect of more restrictive NPIs (mrNPIs) by comparing the combined effect size of all NPIs in 8 countries that implemented more restrictive policies (England, France, Germany, Iran, Italy, the Netherlands, Spain and the United States) with the effect size of all NPIs in the 2 countries that only implemented less-restrictive NPIs (lrNPIs). In effect, we follow the general scheme:We analyse only these countries because the analysis depends on subnational data, which were only available for those countries, as explained further below.The conceptual model underlying this approach is that, prior to meaningful population immunity, individual behaviour is the primary driver of reductions in transmission rate, and that any NPI may provide a nudge towards individual behaviour change, with response rates that vary between individuals and over time. lrNPIs could have large anti-contagion effects if individual behavioural response is large, in which case additional, more restrictive NPIs may not provide much additional benefit. On the other hand, if lrNPIs provide relatively small nudges to individual behaviour, then mrNPIs may result in large behavioural effects at the margin, and large reductions in the growth of new cases. However, because underlying epidemic dynamics are imprecisely characterized and are important for estimating the policy effects, our models test the extent to which mrNPIs had additional effect on reducing transmission by differencing the sum of NPI effects and epidemic dynamics in countries that did not enact mrNPIs from the sum of NPI effects and epidemic dynamics in countries that did.Effects of mrNPI = Effects of (mrNPI + lrNPI + epidemic dynamics) −Effects of (lrNPI + epidemic dynamics) | 3 of 9 BENDAVID Et Al.We estimate the unique effects of mrNPIs on case growth rate during the Northern Hemisphere spring of 2020 in England, France, Germany, Iran, Italy, the Netherlands, Spain and the United States by comparing the effect of NPIs in these countries to those in Sweden and South Korea (separately). The data we use build on an analysis of NPI effects and consist of daily case numbers in subnational administrative regions of each country (eg regions in France, provinces in Iran, states in the United States and counties in Sweden), merged with the type and timing of policies in each administrative region. 18, 26 We use data from a COVID-19 policy databank and previous analyses of policy impacts to determine the timing and location of each NPI. 18, 27 Each observation in the data, then, is identified by the subnational administrative region and the date, with data on the number of cases on that date and indicators characterizing the presence of each policy. We include indicators for changes in case definitions or testing technologies to capture abrupt changes in case counts that are not the result of the underlying epidemic (these are mostly single-day indicators), as suggested in a previous analysis. 18 We define the dependent variable as the daily difference in the natural log of the number of confirmed cases, which approximates the daily growth rate of infections (g). We then estimate the following linear models:The model terms are indexed by country (c), subnational unit (i), day (t) and NPI indicator (p). 0,ci is a series of fixed effects for the subnational unit, and ct is country-specific day-of-week fixed effects. The parameters of interest are pc , which identify the effect of each policy on the growth rate in cases. The parameter cit is a single-day indicator that models changes in case definitions that result in short discontinuities in case counts that are not due to underlying epidemic changes.We estimate these models separately for each pair of countries (one with mrNPIs, one without), for a total of 16 models. We then add the coefficients of all the policies for the country with mrNPIs (yielding the combined effects of all NPIs in the mrNPI country) and subtract the combined effects of all NPIs in the comparator country without mrNPI. As noted above, the difference isolates the effect of mrNPIs on case growth rates. We estimate robust standard errors throughout, with clustering at the day-of-week level to account for serial correlation.It is important to note that because the true number of infections is not visible in any country, it is impossible to assess the impact of national policies on transmission or new infections. 28 Instead, we follow other studies evaluating the effects of NPIs that use case numbers, implicitly assuming that their observed dynamics may represent a consistent shadow of the underlying infection dynamics. 18 The code for the data preparation, analysis and visualization is provided along with the article (Supplementary Material).The growth rate in new cases prior to implementation of any NPIs was positive in all study countries ( Figure 1) . The figure shows that, across all subnational units in all ten countries, the average growth rate prior to NPIs ranged from 0.23 in Spain (23% daily growth; 95% CI: 0.13 to 0.34) to 0.47 (95% CI: 0.39 to 0.55) in the Netherlands. The average across all 10 countries was 0.32, and in South Korea and Sweden, the 2 countries without mrNPIs, the pre-NPI growth rates were 0.25 and 0.33, respectively. The variation of pre-policy growth rates in cases may reflect epidemic intensity, testing coverage (higher growth may be a reflection of expanding testing capacity and of more people wishing to be tested) and pre-policy behaviour changes that led to increased or decreased transmission. In the framework of this analysis, there is no evidence that more restrictive nonpharmaceutical interventions ('lockdowns') contributed substantially to bending the curve of new cases in England, France, Germany, Iran, Italy, the Netherlands, Spain or the United States in early 2020. By comparing the effectiveness of NPIs on case growth rates in countries that implemented more restrictive measures with those that implemented less-restrictive measures, the evidence points away from indicating that mrNPIs provided additional meaningful benefit above and beyond lrNPIs. While modest decreases in daily growth (under 30%) cannot be excluded in a few countries, the possibility of large decreases in daily growth due to mrNPIs is incompatible with the accumulated data.The direction of the effect size in most scenarios points towards an increase in the case growth rate, though these estimates are only distinguishable from zero in Spain (consistent with nonbeneficial effect of lockdowns). Only in Iran do the estimates consistently point in the direction of additional reduction in the growth rate, yet those effects are statistically indistinguishable from zero. While it is hard to draw firm conclusions from these estimates, they are consistent with a recent analysis that identified increased population-level transmission and cases in Hunan, China, during the period of stay-at-home orders, attributed to increased intra-household density and transmission. 29 In other words, it is possible that stay-at-home orders may facilitate transmission if they increase person-to-person contact where transmission is efficient such as closed spaces.Our study builds on the findings of overall effectiveness of NPIs in reducing case growth rate. This has a plausible underlying behavioural mechanism: NPIs are motivated by the notion that they lead to anti-contagion behaviour changes, either directly through personal compliance with the interventions, or by providing a signal about disease risk, as communicated by policymakers, which is used in deciding on individual behaviours. The degree to which risk communications motivate personal behaviours has been used to explain South Korea's response to NPIs, where large personal behaviour changes were observed following less-restrictive NPIs. 30 This analysis ties together observations about the possible effectiveness of NPIs with COVID-19 epidemic case growth changes that appear surprisingly similar despite wide variation in national policies. [31] [32] [33] Our behavioural model of NPIsthat their effectiveness depends on individual behaviour for which policies provide a noisy nudge-helps explain why the degree of NPI restrictiveness does not seem to explain the decline in case growth rate. Data on individual behaviours such F I G U R E 1 Growth rate in cases for study countries. The black bars demonstrate the average growth rate in cases in each subnational unit (95% CI) prior to any policies implemented. The figures to the right show the daily growth rate in cases for each of the countries and demonstrate the shared decline in case growth across all countries, including the countries that did not implement mrNPIs (South Korea and Sweden) as visits to businesses, walking or driving show dramatic declines days to weeks prior to the implementation of business closures and mandatory stay-at-home orders in our study countries, consistent with the behavioural mechanisms noted above. [34] [35] [36] These observations are consistent with a model where the severity of the risk perceived by individuals was a stronger driver of anti-contagion behaviours than the specific nature of the NPIs. In other words, reductions in social activities that led to reduction in case growth were happening prior to implementation of mrNPIs because populations in affected countries were internalizing the impact of the pandemic in China, Italy and New York, and noting a growing set of recommendations to reduce social contacts, all of which happened before mrNPIs. This may also explain the highly variable effect sizes of the same NPI in different countries. For example, the effects of international travel bans were positive (unhelpful) in Germany and negative (beneficial) in the Netherlands (Figure 2 ). While this study casts doubt on any firm conclusions about the effectiveness of restrictive NPIs, it also underscores the importance of more definitive evaluations of NPI effects. NPIs can also have harms, besides any questionable benefits, and the harms may be more prominent for some NPIs than for others. For example, school closures may have very serious harms, estimated at an equivalent of 5.5 million life years for children in the United States during the spring school closures alone. 37 Considerations of harms should play a prominent role in policy decisions, especially if an NPI is ineffective at reducing the spread of infections. Of note, Sweden did not close primary schools throughout 2020 as of this writing.While we find no evidence of large anti-contagion effects from mandatory stay-at-home and business closure policies, we should acknowledge that the underlying data and methods have important limitations. First, cross-country comparisons are difficult: countries may have different rules, cultures and relationships between the government and citizenry. For that reason, we collected information on all countries for which subnational data on case growth were obtainable. Of course, these differences may also exist across subnational units, as demonstrated in the case of different states in the United States. Additional countries could provide more evidence, especially countries that had meaningful epidemic penetration and did not use mrNPIs for epidemic control. Second, confirmed case counts are a F I G U R E 2 Effects of individual NPIs in all study countries. The variation in the timing and location of NPI implementation allows us to identify the effects of individual NPIs on the daily growth rate of cases. Where multiple NPIs were implemented simultaneously (in the same day) across all subnational units (eg school closure, work from home and no private gatherings in Spain), their overall effect cannot be identified individually and is shown combined noisy measure of disease transmission. Testing availability, personal demand for or fear of getting tested, testing guidelines, changing test characteristics and viral evolution all interfere in the relationship between the underlying infections and case counts. Because the location and timing of policies are endogenous to perceived epidemic stage, the noise in case counts is associated with the policies, making bias possible and very difficult to eradicate. The fixedeffects approach provides unbiased estimates so long as the location or timing of policies is quasi-arbitrary with respect to the outcome. This may fail to hold in this assessment of NPI effects because the underlying epidemic dynamics are nonlinear, and the policies respond to-and modify-the epidemic stage. This limitation also holds for all other empirical assessments of NPI effects. 18 Third, our findings rest on a conceptualization, common in the literature, of NPIs as 'reduced-form' interventions: an upstream policy has expected downstream effects on transmission. This allows us to use Sweden and South Korea as comparators, since they had applied less-restrictive interventions, which then enable netting out the combined effect of lrNPIs and the underlying epidemic dynamics. While contextual factors that mediate the effects of NPIs are important-countries implemented different variants of the same NPI, and the population responded differentlymany analyses examining the effects of NPIs have a similar 'reduced-form' structure. 18, 31, 38 In that sense, our comparison is positioned squarely within the literature on the effects of NPIs.During the Northern Hemisphere fall and winter of 2020, many countries, especially in Europe and the United States, experienced a large wave of COVID-19 morbidity and mortality. Those waves were met with new (or renewed) NPIs, including mrNPIs in some countries (eg England) and lrNPIs in others (eg Portugal) that had used mrNPIs in the first wave. The spread of infections in countries that were largely spared in the spring (eg Austria and Greece) further highlights the challenges and limited ability of NPIs to control the spread of this highly transmissible respiratory virus. Empirical data for the characteristics F I G U R E 3 Combined effects of all NPIs in study countries. The point estimate and 95% CI of the combined effect of NPIs on growth rate in cases, estimated from a combination of individual NPIs. The estimates show significant effects in all countries except Spain and range from a 33% (9%-57%) decline in South Korea to 10% (6%-13%) in England. The point estimate of the effect in Spain is also negative but small (2%) and not significant of fatalities in the later wave before mrNPIs were adopted as compared with the first wave (when mrNPIs had been used) show that the proportion of COVID-19 deaths that occurred in nursing homes was often higher under mrNPIs rather than under less-restrictive measures. 39 This further suggests that restrictive measures do not clearly achieve protection of vulnerable populations. Some evidence also suggests 40 that sometimes under more restrictive measures, infections may be more frequent in settings where vulnerable populations reside relative to the general population. 40 In summary, we fail to find strong evidence supporting a role for more restrictive NPIs in the control of COVID in early 2020. We do not question the role of all public health interventions, or of coordinated communications about the epidemic, but we fail to find an additional benefit of stayat-home orders and business closures. The data cannot fully exclude the possibility of some benefits. However, even if they exist, these benefits may not match the numerous harms of these aggressive measures. More targeted public health interventions that more effectively reduce transmissions may be important for future epidemic control without the harms of highly restrictive measures.The funding organizations had no role in the design or execution of this analysis.EB conceived the project; EB and CO designed the analyses, prepared the data and executed the analyses; JB and JPAI were involved in discussing and interpreting the results, and drafting, revising and improving the manuscript. All authors have approved the final manuscript. ",United States,abstract,2021-02-01,02
57782b91e2a8a0da0388aecbe20844da3f856ea7,Communicating Effectively via Tele-oncology (Comskil TeleOnc) : a Guide for Best Practices for Communication Skills in Virtual Cancer Care,"The emergence of a novel coronavirus (SARS-CoV-2, causing coronavirus disease 2019 or COVID-19) has disrupted the US medical care system [1] . Although the use of telemedicine had preceded the COVID-19 pandemic, it has rapidly emerged as an essential technological tool in the current era. Telemedicine enables health care visits to continue effectively while supporting social distancing to reduce the risk of COVID-19 transmission among patients, families, and clinicians [2] [3] [4] . Telemedicine (or telehealth) is defined by the Health Resources and Services Administration (HRSA) of the US Department of Health and Human Services as ""the use of electronic information and telecommunications technologies to support and promote long-distance clinical health care, patient and professional health-related education, and public health and health administration"" [5] . Telemedicine technologies include telephone, videoconferencing, internet, store-and-forward imaging, streaming media, and terrestrial and wireless communications [5] with videoconferencing being the most frequently used telemedicine technology [4] [5] [6] .As the nations around the world, and in particular the USA, deal with managing patients with COVID-19 and decreasing the spread of infection, telemedicine has become the modality of choice to assist patients with various medical needs, including cancer care. In the last decade, for example, tele-oncology (telemedicine in oncology) has gained traction and found a prominent role in medical, surgical, and radiation oncology, as well as in bone marrow transplant and palliative care services [6, 7] . Sabesan [4] describes medical oncology models for tele-oncology services that include face-to-face initial appointments followed by video visits for consultation and supervision of administration of chemotherapeutic agents and oral medication. Additionally, tele-oncology services can benefit clinicians and patients in rural practices, enabling them to have greater access to a cancer center's multidisciplinary team through methods such as virtual tumor group meetings with patient case presentations and discussions [4] . Similarly, teleoncology has found applicability in patient support services such as psychiatry and nutrition counseling [7] . Recently, Memorial Sloan Kettering Cancer Center's Tobacco Treatment Program rapidly scaled up individual and group telehealth treatment visits, showing a higher level of initial patient engagement with telehealth tobacco treatment visits, compared to in-person visits for cancer patients [8] . Until the COVID-19 outbreak, the use of tele-oncology was limited primarily to patients in rural and underserved areas and its use for mainstream oncology care was minimal [6] . Systematic reviews [9, 10] assessing effectiveness of tele-oncology have concluded that tele-oncology via videoconferencing is effective for use in the clinical care of oncology patients due to factors such as convenience, reduced travel time and costs, reduced appointment wait times, enhanced access to care, and overall ease of use. However, reports on other patient-reported outcomes have been mixed or non-existent [9, [11] [12] [13] . For instance, patient barriers to engaging in tele-oncology via videoconferencing include difficulty (or reluctance) to communicate with providers using digital platforms such as webcams and videos [13] , and the experience of emotional distance between patients and clinicians [12] . Thus, a focus on improving communication, especially when dealing with cancer diagnoses and treatments between clinicians and patients when using tele-oncology, is warranted.Given the current circumstances, many clinicians have suddenly been faced with tele-oncology care provision without adequate training. Because few practicing oncology clinicians have previously utilized telemedicine technology, training is essential for familiarization with technical components of telemedicine as well as for adjustment to a virtual method of communicating sensitive medical information [6] . A teleconsultation is far more than a simple FaceTime® or Doximity call with a patient, and thus requires some level of training. Providing clinicians with key communication skills specifically for telemedicine is essential to establishing rapport, maximizing engagement, and conducting a comprehensive patient history and virtual exam [14] . This paper addresses this timely and critical need to enhance clinician readiness to provide high-quality care to patients with cancer by presenting a brief tele-oncology communication (Comskil TeleOnc) guide that utilizes the best practices of an adapted communication skills training [15] .Based on Memorial Sloan Kettering's Comskil Conceptual Model, the Comskil TeleOnc Guide was developed to assist clinicians with limited training in tele-oncology [15] . This conceptual model describes four overarching components that drive the communication interaction between the clinician and patient/families: (i) the communication goal, (ii) communication strategies, (iii) communication skills, and (iv) process tasks. The first component is the communication goal (i.e., the intended outcome of a medical consultation/interaction). The goal is achieved using communication strategies (a priori/ sequential plans that direct communication behavior towards realization of the goal). Strategies, in turn, are achieved with communication goals (discrete verbal utterances) and process tasks (verbal and non-verbal behaviors that create an appropriate environment for effective communication).While the majority of communication goals, strategies, skills, and process tasks described in this manuscript do not significantly differ from face-to-face clinician-patient consultations, there are some skills/process tasks that are unique to tele-visits (e.g., ensuring privacy, technology check, and make technology back-up plan), whereas others are the same as in face-to-face interactions (e.g., declare agenda, invite agenda, and acknowledge). The sequence of skills recommended and the way in which skill use is exemplified in this manuscript provides a resource for clinicians on effective communication via tele-oncology.The goal of the Comskil TeleOnc Guide is to recognize, elicit, and effectively respond to patients' medical needs and concerns while utilizing empathic responses to communicate understanding, alleviate distress, and provide support via videoconferencing. Five strategies are recommended for achieving the communication goal and described next (see Table 1 for the Comskil TeleOnc Guide). These strategies include skills and process tasks that should be used throughout the conversation. Examples of each are provided for clarity.In strategy 1, the clinician establishes the clinician-patient relationship and creates rapport with the patient. The teleoncology visit should begin with a technology check so that the clinician can ensure that the patient can hear and see the clinician well (and vice versa) and enables the patient to appropriately engage in the consultation. This is followed by introductions (if this is the first visit) or greetings (if the visit is a follow-up visit), as needed. It is also important for the clinician to assess patient privacy by confirming that the patient is in a setting where they feel comfortable discussing their private health information. Given the reliance on technology, it is recommended that the clinician has a technology back-up plan (e.g., telephone number, alternate platform) in mind that ensures a process for dealing with technology issues before they arise. Next, it is helpful to check a patient's preference for people they would like to include in the discussion, including those whom they live with as well as those outside of their home with whom they would like to conference in. Within rapport formation, it is also important for the clinician to endorse question asking during the visit and encourage the patient to pause the conversation if they have questions. Clinicians should also continue to encourage patients to take notes or write down questions that come up during the conversation. Finally, partnership statements (e.g., ""we will get through this together"" and ""we will work together to make this meeting helpful"") allow for alliance formation between the clinician and the patient and can provide support.Strategy 2 involves setting an agenda for the tele-oncology visit. In order to accomplish agenda setting, it is helpful for the clinician to declare their agenda and discuss items to be reviewed during the visit. It is also recommended to invite the patient's agenda and ask if there are any specific items the patient would like to discuss. Additionally, the clinician Assess patient privacy comfortable discussing their private health information.""Before we get started, I'd like to make sure that you're in a space where you feel comfortable talking about your health information.""Establish a plan for dealing with technology issues before they arise.stops working, I'll call you on that number.""Ask if there is someone else they would like to include in the discussion, including those they live with. If so, invite them to bring them in so they can be present. If the patient is using a device other than their phone to engage in the televisit, you can ask them to call the person and put them on speaker so they can participate. If others are added to the visit, make sure to note this in your documentation of the visit.If the patient needs or requests an interpreter, the coordinator can add them in before the televisit begins, or you can conference them in.""Would you like to invite anyone else to our televisit today?""Encourage the patient to stop you if they have questions and to write down any notes or questions that come up while you talk.""If you'd like to take notes, please do so. Also, feel free to stop me with any questions you have.""Partner with the patient and address that though this may not be the ideal form of communication, you will work through it together to ensure their questions and concerns are responded to. and I'm glad we're able to meet this way. I want to work together with you as we work through this visit. I'll give you as much information as you'd like, and feel free to bring up any questions or concerns you have.""Step 2: Set the AgendaDiscuss what you would like to go over during the visit. ""I'd like to talk about your recent scans today."" Invite agenda go over. ""Is there anything else that you'd like to discuss today?""For example, you may want to go over how much time is allotted for the visit, or what can and cannot be covered during a televisit.""So, we have about half an hour together today, and I want to make sure we're able to cover everything you'd like to talk about. ""Step If you notice that the patient has a blurry picture and/or audio problems, you may need to prompt them to hold their device still, prop it up against a book, or in some cases, switch rooms to be closer to their WIFI router/server. ""Can you see and hear me okay?"" ""Please prop up your smart phone up against a book, so the picture doesn't move in and out.""In situations where the visual/audio still isn't working: ""Please move your phone/computer and go to the place in your home where your Wi-Fi router is for the best service.""their name and birth date.""Hi! I'm Dr. Smith, and I'm a medical oncologist. Please be called.""should set expectations and review how much time is allotted for their visit. If the clinician is not able to address all of their and their patient's agenda items, it is recommended that they negotiate and prioritize items to ensure the patient receives the most important information they need from the day's visit. Finally, checking a patient's current understanding of the reason for the visit can help the clinician structure the conversation and fill in knowledge gaps when appropriate. Strategy 3 involves empathically responding to the patient's emotion or experience and introduces core skills that should be interspersed throughout the interaction. This strategy includes skills such as acknowledge, validate, normalize, and encourage expression of feelings. These verbal acknowledgments of support Check the patient's understanding of information discussed so far.""I know I've given you a lot of information. Can you tell me, in your own words, what you heard so I can make sure everything came across clearly?""Step 5: End the televisitProvide a time-check 5-10 minutes before the end of your visit to set expectations for wrapping up the visit. This will help you and the patient organize your thoughts, so the conversation doesn't end too abruptly.""So, it looks like we have 10 more minutes before we need to stop. Let's make sure we go over self-care at home and when you should call the hospital. How does that sound?""Go over the main points of your discussion.""So, just to review: we discussed what to do if your fever gets higher, if you feel like you're going to throw up, andInvite the patient to ask you any questions. ""What questions do you have?""Encourage the patient to contact you outside of the visit time if they have any lingering questions.""Please call my direct number if you think of any questions after our visit ends."" Provide referrals, when appropriateDepending on the patient's needs, provide referrals when appropriate to specialties such as psychiatry, social work, integrative medicine, palliative care, etc.""We have many different resources that can address your personal needs, and we are always open to you.""Review what will happen following the televisit and close the consultation.""Before we end, I just want to make sure we discuss the next steps. My coordinator will call you to schedule a visit in 2 weeks. We will meet virtually, like today. And, if you start to feel sick, take your temperature and call myHelp the patient prioritize the most important information they would like to get out of the day's visit.Check the patient's understanding regarding the reasons for the visit.""So, what's the reason for our visit today?""Step 3: Respond Empathically to Emotions Acknowledge Pay attention to emotional cues from the patient during very worried. Verbally acknowledge these cues during the visit.""You seem to be very anxious today.""Establish that even though you're not meeting in-person, this is still a safe space where the patient can express their emotions and concerns.hope you feel comfortable sharing anything. How are you feeling?""Make a statement expressing that the patient's emotional response to an event or an experience is appropriate and reasonable.""I can imagine how hard this must be for you.""Make a comparative statement which expresses that a particular emotional response is not out of the ordinary.""It's not unusual to feel so sad at a time like this. Many of my patients have shared similar feelings.""Though silence may feel awkward in a televisit, it is still an important tool to allow patients to process information effectively and gather their thoughts.Be mindful that there may be a lag/delay in the conversation due to tech issues, so it's important to pause and allow the patient ample time to respond and speak after delivering information or asking a question.Pause after speaking and wait a few seconds before responding to a patient to reduce interruptions. Use visual cues, such as nodding, to show that you are listening.Step 4: Deliver the Information Preview Orient your patient to information that you are about to provide.""Now, I'll go over some side effects that you may start experiencing by next week.""Give information using the KISS (keep it short and simple) strategy and break up the information into manageable chunks.""You may have a mild fever, not more than 101 degrees.and care during this difficult time are even more relevant in a post-pandemic world, especially given that in-person interactions are limited and some patients may be forced into more isolated settings with less social support. Though it can be difficult to assess a patient's emotional state via a virtual platform, encouraging patients to verbally express their concerns and feelings is crucial to establishing rapport and trust in the patient-clinician relationship. Appropriate use of silence is also encouraged during a tele-oncology visit. Though silence may feel awkward at times, it is still an important tool to allow patients to process information effectively and gather their thoughts. Clinicians should also be mindful that there may be a lag or delay in the conversation due to technical issues, so it is important to pause and allow patients ample time to respond and speak after delivering information or asking a question. Strategy 4 includes delivery of the key medical information. This can be accomplished by previewing the information before going into details to help orient the patient and assist in information organization. While the clinician provides information, we recommend using the KISS (keep it short and simple) strategy in addition to breaking up the information into manageable chunks. After provision of information, it is important to, again, check the patient's understanding to ensure there are no misconceptions, misinformation, or misperception about the information discussed in the tele-oncology visit.Lastly, strategy 5 involves ending the tele-oncology visit. It is recommended that clinicians provide a time-check roughly a few minutes before the end of the visit to set expectations for wrapping up. This will help the clinician and the patient organize their respective thoughts and will prevent an abrupt end to the conversation. After the time-check, it is helpful for the clinician to summarize the main points of the discussion and to invite questions from the patient. Clinicians should also endorse question asking, encouraging patients to contact them outside of the visit and provide contact information, especially if there are any lingering questions. Providing referrals to specialties such as psychiatry, social work, integrative medicine, and palliative care may be helpful for some patients, and the clinician must evaluate that on a case-by-case basis. The visit should end with a clear review of next steps, including what will happen following the tele-visit.This paper describes a newly developed Comskil TeleOnc Guide, curated by our team of communication experts and practicing oncology clinicians, and refined in partnership with colleagues from Telemedicine, Patient Experience, and other faculty members with substantial experience in providing teleoncology care. Focusing on the utilization of communication skills, adapted from our educational programming based on our Comskil conceptual model, this guide maximizes care provision for patients via videoconferencing. As cancer care centers around the nation advance into an increasingly digital era, it is paramount that clinicians be prepared for conducting effective consultations via videoconferencing. The guide presented here is not all-encompassing or prescriptive, but rather keeps communication best practices in mind to provide a patient-centered framework for conducting a tele-oncology visit. Our aim in developing this communication guide is to provide direction to clinicians on how to more effectively communicate with their patients in a post-pandemic health care system. The long-term objective of the research team is to develop a virtual Comskil TeleOnc Coaching Intervention to improve quality of care related to clinician-patient communication and patient satisfaction in oncology care delivered via tele-oncology.",USA,first author,2021-02-05,02
19a33319d979ef7a4f3815288f20af62822aaeb9,,"Canada and countries around the globe have recognized interprofessional primary care (IPC) teams as a crucial approach to support the increasingly complex health care needs of populations [1] [2] [3] [4] . IPC teams are defined as two or more health professionals working collaboratively to provide comprehensive, patient-centred care [4] . Team based primary care offers increased access to a range of IPC providers beyond physician only primary care, including social workers, pharmacists, dietitians, occupational therapists and physical therapists and others [1] [2] [3] [4] . Given this breadth of perspectives, primary care teams are well placed to address the profound clinical, behavioral, and mental health care demands that are emerging and will continue to emerge throughout the pandemic [5] .The early COVID-19 research has focused on the acute care management and experiences almost exclusively from the perspective of physicians [5, 6] . Less emphasis has been placed on understanding the impact of the pandemic on non-physician IPC providers [7] , despite the increasing recognition of the value of teams to manage the complexities of COVID-19 [5] . There is currently no research to provide guidance to IPC providers and teams operating during COVID-19 [7] , compounding already high levels of stress experienced by healthcare providers in this context. Examining the practices and experiences of IPC providers during the early phases of the COVID-19 pandemic will inform how teams address the rapidly evolving needs of patients and communities and provide a benchmark in which to examine this evolution. The objective of this study was to describe the state of IPC provider practice within primary care teams during the COVID-19 pandemic.An observational cross-sectional study design was used. A web-based survey was distributed to non-physician IPC providers working in team-based primary care clinics in the province of Ontario, Canada to answer the following questions: How are IPC providers currently providing services during the COVID-19 pandemic? How has the method of service delivery changed since the implementation of COVID-19 physical distancing requirements? How confident are IPC providers with alternate methods of service delivery being implemented during the COVID-19 pandemic? What types of patientcare issues are being seen during COVID-19 and how are these different than prior to COVID-19? What is the personal and professional impact of COVID-19 on IPC providers?The web-based survey was developed for the study using Qualtrics (Qualtrics. Provo, UT, USA. 2013) and was informed by previous surveys of occupational therapy [8] and social work [9] practices in IPC teams in the province of Ontario, Canada. The survey was developed in collaboration with our partner organization, The Association of Family Health Teams of Ontario. All members of the research team reviewed and revised survey questions to ensure clarity. The final web-based survey included 26 close-ended and six open-ended questions that aligned with study objectives. The final survey was pilot tested with the clinical research team members, representing multiple health professions who were not involved in the initial creation of the surveys. See supplemental file 1 for a copy of the survey.Ethics approval and consent was obtained from the Queen's University Health Sciences and Affiliated Teaching Hospitals Research Ethics Board in Kingston, Canada (Approval # 6026691 -REH-750-19).We used a convenience sampling technique. The study population included non-physician IPC providers who were able to complete a web-based survey in English, and self-reported as being currently employed within a Family Health Team in the province of Ontario, Canada. Ontario Family Health Teams provide services to approximately 25% of the population in Ontario [10] . While the exact composition and number of providers varies between Family Health Teams, each team provides comprehensive care and a broad range of physical, behavioral, and mental health services [11] [12] [13] [14] . Family Health Teams are aligned with the broader framework of the Patient's Medical Home [4, 13] .IPC providers were invited to participate in the webbased survey through recruitment emails and posts on social media (Facebook, Twitter, LinkedIn). Emails were distributed by a number of provincial professional associations. Recruitment emails and social media provided a brief description of the research project and a link to the survey. The survey link took interested participants to the first page of the survey, which contained a more detailed description of the study and a statement asking participants for consent to participate. The web-based survey was open for 15 days from April 22, 2020 until May 8, 2020. During this timeframe a state of emergency was declared in the province of Ontario, lasting from March 17th until May 19th and only essential businesses remained open and hospitals were closed to everything but urgent and emergency care.Survey data were exported from Qualtrics to Microsoft Excel. Close-ended survey questions were imported from Excel to SPSS. Data were cleaned and analyzed by five authors (NB, JM, CM, AM, TT) using descriptive statistics. Data from open-ended questions (""What is your experience during COVID-19""; ""Prior to COVID-19, what were the three most common health conditions you were seeing?""; ""Since COVID-19, what are the three most common health conditions you are seeing?"") were exported to Microsoft Excel and multiple authors completed an inductive content analysis for each open ended question. Authors met and compared responses until consensus was reached [16] . For the content analysis of the experience question each of six authors (RA, NB, CD, CM, KV, AW) completed a preliminary read of the first 100 responses and developed an initial coding structure that included 12 broad codes. Each author was assigned a section of the data and applied the coding structure to the responses. More than one code could be applied to a response if there were multiple statements or elements in a response. Responses were further identified as being positive, negative or neutral. Once the initial coding process was completed the six authors met to review the coding structure and ten coded responses were randomly selected and reviewed by the team to ensure the accuracy of the applied codes. Further discussion resulted in the unanimous agreement of the removal of three codes (time use, patient experience and intersection of family and work) and integrated into five themes. Authors reviewed and recoded their assigned responses in accordance with the final coding structure. For the content analysis of the conditions seen, two authors (TT, JM) independently coded each response based on health condition listed and met to compare and reach consensus on the coding of each condition listed.A total of 473 IPC providers consented to participate in this survey, of the total 2423.48 full time equivalent IPC providers, for a response rate of 20%. Of those that consented, 445 IPC providers completed at least one survey question and were retained for full analysis of the data provided. Respondents were from twelve professional disciplines, with social workers (25%) being the largest proportion followed by dietitians (22%) and nurses (12%). Table 1 provides an outline of the demographics of the participants.Since COVID-19, the majority of providers did not report a change in their work hours (81.5%); however, 20.5% of IPC providers were redeployed to an alternate organization or job. Table 2 provides details related to workload, referrals patterns and wait lists. Almost half (48.3%) of respondents reported experiencing greater team collaboration since COVID-19, with collaboration most frequently supported by email and phone. Table 3 outlines the nature and extent of team collaboration.Prior to COVID-19, IPC providers reported an average of nearly 70% of their time was spent delivering direct in-person care. On average, the majority of the care provided to patients prior to COVID-19 occurred in-person at the clinic (77.0%) and in-person at their patients' home (21.4%). Since COVID-19 IPC providers reported that an average of 61% of their time was spent delivering one-on-one care, with the majority of care having shifted to telephone-based encounters (76.5%), followed by some in-person care in the clinic (27.3%). Table 4 provides details on the delivery of IPC services.The most common conditions identified when participants were asked to list the three most common health conditions they were seeing prior to COVID-19 were mental health or addictions concerns (25.5% of all conditions listed within the top three most frequency seen conditions were mental health or addictions), diabetes (14.8%), cardiovascular conditions (12.5%), and pain or musculoskeletal conditions (8.0%). See Table 5 and Fig. 1 for the full results. During the COVID-19 pandemic, shifting roles, working in teams, personal impact and inadequate guidance. Each theme contained both positive and negative statements which was thought to reflect the wide variation in provider experiences during the first weeks of the pandemic as IPC practice shifted, almost overnight, to providing virtual care. Virtual care includes synchronous and asynchronous forms of communication such as the use of video platforms, telephone, instant messaging as well as others. The theme of 'Access' reflected both the increased access to services that were now available to patients by phone or video, but also a concern over barriers to access due to difficulty using technology, accessing technology or a general preference by patients to receive face-to-face care.The theme of 'Shifting Roles' highlighted the changing roles that participants across each of the professions experienced in part due to the rapid shift to virtual care. Some participants indicated that they were able to maintain their roles through virtual care delivery, whereas others were unable to contribute to patient-care because their role was incompatible or difficult to implement through virtual means (e.g. home safety assessments, or specific procedures). Many of the participants attributed shifting roles to the referral process used to link patients with IPC providers. Although some participants grappled with increased work, many others described having a reduction in role that was a result of reduced physician-initiated referrals. Others took on completely new roles to support the management of COVID-19 in assessment centres or their own clinics.'Working in Teams' emphasized the unique experience participants reported of working in an IPC team during the early phase of the COVID-19 pandemic. Many participants highlighted the support the team provided during the transition to virtual care, and emphasized the ability of the team to come together to solve the challenge of safely delivering care presented by COVID-19. However, many participants overwhelmingly expressed feelings of isolation because of the lack of contact with their teams and the lack of daily hallway conversations. 'Personal Impact' was the fourth theme and it highlighted the significant personal impact on participants working during the early phase of the COVID-19 pandemic. Participants described feelings of isolation, worry, and exhaustion. Some participants expressed that they felt a sense of greater purpose and meaning because they were able to help their colleagues and patients during the immediate COVID-19 pandemic crisis.'Inadequate Guidance' was an overarching theme that highlighted a general sense that primary care had not been a focus of COVID-19 planning. IPC providers identified the initial wave of COVID-19 had focused on the medical rather than the social and emotional aspects of health and as primary care shifted to focus on emergency or urgent care IPC providers received little guidance as to where their services fit. Lack of guidance made it difficult to prioritize patient issues and more broadly to determine the role of the IPC team. Sample quotes can be found in Table 6 .The rapidly emerging pandemic literature has focused on acute and institutional medical care [5, 7, 17] . We are not aware of any other papers that have examined IPC teams during the COVID-19 pandemic. Results of our study demonstrate the rapidly shifting roles of IPC providers and the need for immediate guidance so that primary care teams can be better prepared to care for the clinical, behavioral, and mental health needs anticipated in future COVID-19 waves.This study was conducted in the province of Ontario, Canada, the countries most populated province [10] . This context offers an important opportunity to examine team-based care during COVID-19, with IPC teams having been in place and operating across the province for well over a decade [11] . Many countries across the globe have recognized the importance of team-based primary care [1] [2] [3] [4] and the Family Health Teams in Ontario represents a well-established model of team based primary care [4] .Our results show the overwhelming focus on supporting mental health both before and since COVID-19. In part, this is because mental health is a prevalent issue in primary care [14] and also because interprofessional teams were conceived to support physicians in managing increasingly complex populations, specifically with regards to increasing chronic mental and physical health conditions [4, 15] . Even in the early weeks of the COVID-19 response there was an increased focus on mental health, specifically anxiety, and this was also being reported in the literature [5, 18] . There is evidence that the COVID-19 pandemic will heighten the need for acute and long-term mental health care supports for individuals and populations [5, 19] . It is being recognized by health officials internationally, nationally and provincially that the mental health impact could be as significant as the COVID-19 virus itself [5, [17] [18] [19] . The data also highlights an increase in appointments to support Table 5 Most common conditions seen prior to COVID-19 and during the COVID-19 pandemic patients experiencing social isolation and health system navigation, which is suggestive of this growing indirect effect of COVID-19, which is expected to continue [17] . Although IPC team members are trained and experienced in providing mental health care, a significant challenge arising from the COVID-19 pandemic is to ensure these services remain accessible to patients as service delivery has rapidly shifted to virtual care [20] . While there was an increased focus on mental health, there was a shift away from supporting chronic physical health conditions. The study has highlighted that access to in-person primary care was largely halted during the early phase of the pandemic, however, there continued to be full access to virtual services from IPC providers. Our results suggest that the shift away from providing care to individuals with chronic conditions could reflect either a preference for individuals with chronic conditions to delay their appointments or targeted appointments to older adults and those known to be socially isolated or at risk of loneliness. It has been noted in the emerging COVID-19 literature that there is an expected wave of secondary health issues related to the postponement of non-urgent appointment and services [21] . Teams should consider how they can reach out to patients with chronic conditions to offer virtual supports or connect to community supports.Primary care is unique compared to acute care settings in that their care delivery has shifted almost entirely to virtual care [20] . Prior to COVID-19 virtual care had limited uptake in primary care [20] . It is clear from the results of this survey that providers are seeing benefits to patients, families and themselves and research will need to shift to examine who most benefits from this mode of delivery and what approaches are most effective [22] . Our study was conducted in the early weeks of the COVID-19 response and emphasizes the need to integrate ongoing comprehensive planning and supports for virtual care. It will be important to conduct follow-up with these same providers at regular intervals to continue to understand the experiences and use of virtual care over time and with experience [22] .One of the challenges highlighted in the study is that the existing referral process used to engage IPC Role Halted ""There is little I can do for most of my clients via telephone other than check-in and ensure they have everything they need at home."" ""Many are cancelling services for nutrition counselling."" ""Leadership team has instructed to cut back on all non-essential occupational therapy services.""No role change, modality change ""The biggest change has been working from home and not seeing patients in person. Other than that a lot of the workload is the same.""Changing capacity ""With fewer non-clinical interruptions throughout the day, I've been able to increase my capacity for clinical care."" ""I hope that moving forward we can continue to implement providing MORE care over the phone or via [videoconferencing] . I can see MORE patients during the day due to COVID with these changes of most care being provided over the phone."" ""I find that I'm able to reach more pts. in a day than previously, when in person visits were scheduled. This may be d/t the fact that most pts. and caregivers are also home during the day and able to participate in call.""Improved availability ""It has reaffirmed the importance/necessity of in-person visits for many patients. It has also opened up the door to other possibilities as phone/virtual visits are possible and potentially even easier/more accessible for some patients."" ""Patients loving the phone access."" ""Several patient populations such as busy moms or seniors prefer phone follow-up as saves time or does not involve driving to appts.""Seeking health care ""I realize people are living with their ailments rather than seeking medical care immediately.""Technology barriers ""Difficult with those who are hearing impaired like many seniors."" ""Difficult to assess non-verbal when performing geriatric assessments. Difficult to assess cognition."" ""Depending on age demographics of patients and their comfort with technology, I am sometimes limited in what I can accomplish over the phone.""Supporting each other ""Supporting and understanding."" ""Great team support."" ""Our entire team work and support each other daily.""Working together to create solutions ""The team has rallied and come together and is functioning well to ensure patients are given high quality care despite challenges."" ""Overall I'd have to say it's been a learning experience in collaboration. I find our FHT has really pulled together and offered to help each other with programs/initiatives.""Missing team connection ""I have certainly missed the camaraderie of working as a co-located team, and I am getting fewer ""quick questions"" from my colleagues. ""Organizational leadership ""When collaboration amongst all providers of care from clerical to physicians and IHPs can be done the improvement seen in morale and patient care is significant. When Admin appears out of touch and not engaged with the team the negative impact is more emphasized as it is already a period of uncertainty and fear for many team members."" ""I have felt incredibly supported by our management with recognition that this is different and hard and employees are managing various roles at home (not only remote working)."" ""It has been very challenging, lacking a lot of guidance and consistent direction from physicians/management in our office.""Isolating ""Working from home has been unusual and isolating as I am accustomed to working with patients and colleagues in person.""Uncertainty and stress ""Nothing is the same and it changes day to day."" providers may not be effective at ensuring patients have full and direct access to these providers. Referrals to IPC team members are primarily through physicians, and the COVID-19 response has highlighted the need for reconsideration of this traditional referral model to improve access to the range of services embedded within interprofessional models of primary care. The literature has identified referral processes as a critical component of supporting access to and fostering integrated primary care [23, 24] . Moving forward teams need to consider how patients can have direct access to team members to best support patients managing the direct and indirect consequences of COVID-19. Collaboration and communication within teams has been shown to be critical in supporting integrated and coordinated care [22, 23, 25] . Almost half of the teams reported increased teamwork since COVID-19 and suggest teams are building on strong processes and using their collective expertise to build solutions to support access. Strong collaborative teams have been shown to lead to positive health outcomes [26, 27] and COVID-19 has highlighted specifically the value of teams in mobilizing their resources to support their patients.It must be acknowledged that Family Health Teams represent one model of primary care and generalization to all primary care models should occur with caution. Providers were asked to identify the most common conditions seen and this is not the same as conducting a chart audit of practice, which would provide a direct measure of practice patterns. We also recognize that the conditions seen and changes in the conditions were what were reported by participants and are not the actual prevalence of these conditions. The survey represents the state of IPC during the early phase of the COVID-19 restrictions and it is anticipated that the experience in primary care will continue to evolve. Ongoing research is needed throughout the phases of the pandemic to examine the long term and emerging impact on teambased primary care.The study provides an important picture of IPC and highlights the role that each sector of the health care system has in managing the far-reaching impacts of COVID-19. Supporting access to and awareness of IPC providers' services will be crucial in ensuring patients receive supports they need, including direct referral pathways, and mitigating barriers to receiving virtual care. ",Canada,abstract,2021-02-03,02
ab2f37562964732ea31c11cda0170f441af48b8c,Financial Implications of COVID-19 on a Tertiary Academic Vascular Surgery Practice,"hospital and professional side that, without significant productivity increases, will not be 1 recoupable. determined that patient informed consent was not required. The IRB waiver was maintained 9throughout the duration of this study. Our division consisted of 8 active vascular surgeons during 10 both the pre-pandemic and pandemic study periods. A rotating call schedule was continued from 11 the pre-pandemic to pandemic study period. Fortunately, no faculty members required quarantine 12 due to COVID exposure. All vascular surgery inpatients were included in the inpatient claims as defined by the vascular 2 surgery service line. The CMS Prospective Payment Service (PPS) was utilized to obtain the 3 national reimbursement rate for inpatient hospitalizations as assigned to each DRG. 3 Geographic 4 payment adjustments for capital and labor rates were utilized for our region, however, to make 5 this methodology more widely applicable we removed adjustments such as direct and indirect 6 medical education (DME and IME), disproportionate share hospital (DSH), and other CMS 7 programs such as Value Based Purchasing (VBP), and outlier payments which may not be 8 universally applicable to other medical institutions. This allowed us to generate values that are 9replicable at any institution using CMS values and hospital volume. The DRG relative weight for 10 each admission was multiplied by the CMS reimbursement rate as published in their annual 11 report and this resulted in an estimated reimbursement for the service. The inpatient 12 reimbursement was based on completed and submitted claims. Physician Fee Schedule (MPFS) was used to calculate the reimbursement as well as the work 1 relative value units (wRVU) generated by each claim. 5 Reimbursements and productivity (wRVU) were compared between the pre-pandemic (March 5 and April 2019) and pandemic (March and April 2020) time periods. Medicare reimbursement 6 rates were used for the Medical Center and professional billing, and it was assumed that all 7 claims were reimbursed in order to standardize comparisons between the study time periods. 8Modeling sensitivity analyses were used to determine the increase in future productivity over 9 baseline required to mitigate losses incurred during the pandemic. Reimbursement levels for 10 each revenue stream in 2019 were used to define baseline productivity. The time needed to 11 ""make up"" the difference between pandemic and baseline reimbursement levels was then 12 calculated for various increased levels in productivity. Professional productivity (as measured by wRVUs) sustained a similar decline from 10478 16 wRVU to 5386 wRVU (-51%) (Figures 3 and 4) . Modeling sensitivity analyses demonstrated that if a vascular division were able to 19increase Medical Center Inpatient and Outpatient revenue to above pre-pandemic levels by 10%, 20 5%, or 3%, it would take 9 months, 19 months, or 31 months, respectively, for the hospital to 21 recover pandemic-associated losses (Table 1) . Similarly, professional reimbursement recovery 22 would require 11 months, 20 months, or 36 months with a 10%, 5%, or 3% increase in 23 productivity ( Table 2 ). The top five most common inpatient procedures (as sorted by DRG) were 1 compared between the pre-pandemic and pandemic study periods (Table 3) . Similarly, the top 2 five most common outpatient claims (as sorted by APC and ICD-10) were also compared 3 between the pre-pandemic and pandemic study periods (Tables 4 and 5) . In this study we demonstrate that the coronavirus pandemic has resulted in significant 2 reduction in both the medical center and professional reimbursement for a vascular surgery 3 division. The net impact of reallocation of resources, reduction in operative volume and clinic 4 visits, and attempts to safeguard patients from further exposure resulted in a more than 50% 5 reduction in reimbursement across all avenues of vascular surgery services. At our institution, 6COVID admissions peaked at 28% of inpatients and 125% of our ICU capacity. Further, our 7 study provides compelling evidence that the financial impact of COVID-19 will be difficult to 8While it is impossible to completely determine the clinical, social, and psychological 11 consequences of the COVID-19 pandemic, there have been numerous attempts to understand the 12 financial impact. The reason to do so is two-fold: (1) the magnitude of the loss is important for 13 developing budgets going forward and (2) the types of losses may suggest areas of opportunity 14 for recovery. Financial market analysis has estimated that the impact on US hospitals was over 15 $200 billion as of June 2020, but this report lacked a granular assessment of the impact on an 16 individual service line. 6 It is likely that different specialties suffered different magnitudes and 17 types of losses, such that a one-size-fits-all budgeting and recovery strategy may not be optimal. 18To our knowledge, this study is the first to both quantify the financial impact of the COVID-19 19 pandemic on an academic vascular surgery division and to project the length of time and 20 increased productivity needed to recoup those losses. The COVID-19 pandemic required re-allocation of resources and personnel as well as 1 cancellation of elective procedures and visits. This was clearly seen in the reduction of outpatient 2 services, which saw a 68% reduction in volume and 65% reduction in reimbursement. Inpatient 3 services, however, were not as heavily impacted: vascular surgery inpatient services saw a 43% 4 reduction in volume and a 39% reduction in reimbursement. This is consistent with previous data 5showing that greater than 50% of inpatient vascular care is emergent. 7 Furthermore, it is likely 6 that these inpatients, although fewer, were sicker and required more care as evidenced by the 7 reimbursement decreasing 10% less than the volume (volume decreased by 43% while 8 reimbursement only decreased by 39%). In other words, patients may have only presented if 9absolutely necessary due to fear of contracting coronavirus in the hospital setting, which is 10 consistent with studies showing that up to 60% of patients felt uncomfortable seeking care in 11 hospitals. 8 Although there were fewer patients, they had more advanced disease (including non-12 vascular comorbidities) and thus required more services, which in turn, generated more healthcare. It is therefore critically important that hospital systems understand the losses, and can 21 estimate how long it could take for hospital and professional revenues to ""bounce back."" 22Analysis by the American Hospital Association (AHA) shows losses will continue to mount at a 23 rate of more than $20 billion per month until the end of 2020 largely due to decreased patient 1 volume and cancellation of elective procedures. 1 This would bring total losses for the US health 2 system at over 320 billion dollars: a staggering amount not including the additional costs for 3 needed items such as PPE. While the CARES Act was meant to help blunt these financial 4 constraints it falls far short of covering these losses. Our institution did receive funds from the 5 CARES act but the exact amount has not been divulged. While there is some fund exchange 6 between the Medical Center and our medical group, we are not privy to the specific details and 7 have no control over distribution. This highlights the financial obstacles in recouping the losses: 8we most likely will not be able to increase our volume above pre-pandemic levels, assuming 9 medical institutions could facilitate such increases, and safeguards such as government aid fall 10 far short of creating a stopgap for the sustained losses. 11There are many potential obstacles to making up these losses. First, increasing hospital 13 operative volume to above pre-pandemic levels will be very challenging for both clinicians and 14 medical centers. Opening additional operating rooms for longer times during the evening or 15 weekends incurs additional personnel-related costs such as hiring additional staff and paying a 16 higher rate for overtime. At the time of writing, an additional obstacle is reduced OR availability 17 due to mandated restrictions aimed at reducing overall hospital census. There is also the risk of 18 less tangible effects such as surgeon and staff burnout. Vascular Surgery has been reported to 19have the longest hours of any specialty in the medical profession. 9 Therefore, a 10% increase in 20 productivity over a 9 to 11-month period (the time required to recoup losses according to our 21 models) would not be sustainable or safe, especially given the recent findings of the SVS 22Wellness Task Force showing that 30% of vascular surgeons met criteria for burnout prior to the 23 pandemic. 10 We believe that such an attempt to recoup lost revenue would certainly exacerbate 1 this finding and be detrimental to any vascular surgeon. Second, patients who have missed or had 2 their appointments rescheduled due to the pandemic may no longer be candidates for their 3 originally intended surgical procedures. An example of this would be a patient who would have 4 originally been seen with dry gangrene but presents with wet gangrene, necessitating an 5 amputation rather than a bypass. Another possibility is that patients with claudication may decide 6 to more aggressively pursue an exercise regimen than they otherwise would have, resulting in an 7 improvement in symptoms rather than deterioration. Finally, as previously stated, patients remain 8 reluctant to visit a medical center or physician's office due to ongoing concerns for contracting 9 COVID-19. 10 11 There will almost certainly be a persistent level of COVID-19 related costs as hospital 12systems return to what has been colloquially referred to as the ""new normal."" This involves 13 increased costs for personal protective equipment, testing, and procedural changes until a vaccine 14 is widely available. The long-term financial impact of these changes is yet to be seen. Taking 15 these changes and the associated costs into account, it seems likely that the modeling sensitivity 16 analyses presented here are not conservative enough. To that end, we believe that the complete 17 mitigation of losses is not feasible in the short-term. Alternative, novel strategies are needed to 18 financially sustain the vascular division and hospital, during a prolonged recovery period. One 19 strategy that our institution adopted and implemented is telehealth or telemedicine. Audio and 20 visual clinical services were rapidly expanded through government regulations both at the federal 21 and state level. 11, 12 This allowed greater than 200 clinical services to be performed remotely, 22 thereby reducing physical contact and promoting social distancing. 13 This was a logical step 23 when viewed through the lens of infection control, and insurers signaled their approval by 1 reimbursing telemedicine visits akin to in-person clinic appointments. 14 Further, most insurance 2 carriers reduced or removed copayments and deductibles for telehealth visits in order to promote 3 improved access to remote care. 15 During the study period there was redeployment of team 4 members and administrative support staff to different areas of the hospital, but there were no 5 instances of furlough or termination within our institution. One of the ways in which our division 6 activities changed was the creation of a Surgical Workforce Access Team (SWAT) which 7 provided line-placement services (arterial/dialysis/central venous access) to Covid-19 ICU. 16 8Other novel concepts that were originally utilized for COVID but may assist with increasing 9 volume could be Hospitals without Walls or temporary expansion sites. While their overall cost 10 structures and reimbursement models remain uncertain, they may serve as an adjunct resource to 11 increase volume or divert care to a lower cost venue. 17 To further reduce cost of care and 12 increase capacity, medical centers and physician groups may try to utilize lower cost sites of 13 service such as office-based labs and ambulatory surgical centers as opposed to medical centers 14 but these ventures require considerable time and resources to launch. This strategy is thus 15 unlikely to relieve short-term financial needs. Inevitably, significant government support may be 16 required either through increased reimbursements for medical services or in the forms of low 17 interest/forgivable loans or grants to help the healthcare system recoup losses. Unfortunately, the 18 current political climate does not seem to be conducive to meaningful and coordinated support 19 from the federal government. 18 There are several limitations to our study. Our data collection period was limited to without a clear timeline for return to normalcy. This likely has the effect of decreasing the 1 magnitude of the financial loss, as decreased clinical volumes persisted into the early summer of 2 2020. The calculated values for ""reimbursement per DRG"" are also slightly lower than the true 3 values -this is because several adjustments, such as those for Direct and Indirect Medical 4Education, were removed to make the calculations generalizable to non-academic medical 5 centers. Another limitation is that our reimbursement values are based on Medicare 6 reimbursement levels and do not take into account other payers. This could lead to 7 underestimation of reimbursements, though this would be somewhat offset by claims that were 8 not successfully reimbursed. We also did not incorporate the impact on office-based practices 9(private physician offices and OBLs) or ambulatory surgical centers (ASC) as this makes up a 10 minority of the vascular surgery volume at our academic medical center. However, other reports 11 have demonstrated that more than 97% of these practices were negatively impacted with some 12 being unable to reopen. 19 While this study examined a large number of claims, due to the de-13 identified nature of the data we are not able to determine how many of the claims are unique 14 patients versus readmissions. Lastly, our division was able to adopt and implement telehealth 15 visits very early in the pandemic period, which initially constituted approximately 4% of the 16 clinical volume for the division during the study period but has markedly increased over the 1 The COVID-19 pandemic has had a devastating, profound, and lasting impact on the 2 world in terms of lives lost and financial hardships. This study details the financial impact on a 3 vascular surgery division that has resulted in losses ranging from 39% to 65% when compared to 4 the same period during the previous year. Given that the pandemic is still ongoing and that our 5 models indicate that complete mitigation of losses is not feasible in the short-term, alternative, 6 novel strategies are needed to financially sustain the vascular division and hospital, during a 7 prolonged recovery period. 254 10 269 6 *DRG codes: 38: extracranial procedures with complication or comorbidity, 39: extracranial procedures without complication or comorbidity/major complication or comorbidity, 240: amputation for circulatory system disorders except upper limb and toe with complication or comorbidity, 252: other vascular procedures with major complication or comorbidity, 253: other vascular procedures with complication or comorbidity, 254: other vascular procedures without complication or comorbidity/major complication or comorbidity, 269: aortic and heart assist procedures except pulsation balloon without complication or comorbidity/major complication or comorbidity Table 3 . Top 5 most common DRG codes during each study period *DRG codes: 38: extracranial procedures with complication or comorbidity, 39: extracranial procedures without complication or comorbidity/major complication or comorbidity, 240: amputation for circulatory system disorders except upper limb and toe with complication or comorbidity, 252: other vascular procedures with major complication or comorbidity, 253: other vascular procedures with complication or comorbidity, 254: other vascular procedures without complication or comorbidity/major complication or comorbidity, 269: aortic and heart assist procedures except pulsation balloon without complication or comorbidity/major complication or comorbidity ",United States,abstract,2021-02-03,02
66dd0812774b4d18ae39ccde3887652a48367713,Persistent COVID-19 symptoms minimally impact the development of SARS-CoV-2 specific 1 cellular immunity 2 3 4 5 HengSheng Fang,"INTRODUCTION 72 SARS-CoV-2 is a recently emerged novel single-stranded RNA virus that was initially identified as the 73 causative agent of a pneumonia outbreak in Wuhan, China in early December, 2019 [1] [2] [3] . This initial 74 outbreak has since developed into an unprecedented world-wide pandemic, resulting in an estimated 96 75 million infections and 2 million deaths as of January 2021 . The multi-faceted illness associated with 76 SARS-CoV-2 infection -COVID-19 -is characterized by inflammation of the respiratory tract, fever, 77 musculoskeletal pain, and cough [4] [5] [6] . While SARS-CoV-2-specific humoral and cellular immunity is 78 evident in the majority of patients following the resolution of acute infection and appears to persist for at 79 least 6-8 months [7, 8] , the role of this adaptive immune response in regulating viral replication and 80 disease pathogenesis remains unclear. Furthermore, little is known about how variations in the complex 81 clinical manifestations of COVID-19 impact the development of SARS-CoV-2 specific immunologic 82 memory. 83 84 A notable feature of SARS-CoV-2 infection is that COVID-19 symptoms can persist for weeks or 85 months after initial manifestation even in patients not requiring hospitalization or other medical 86 interventions [9, 10] . This is especially evident in older adults with underlying chronic medical 87 conditions but has been extensively documented in patients across a wide age range [10] . Even in young 88 adults, nearly 20% of patients with confirmed SARS-CoV-2 infection fail to return to full normal daily 89 activities 14-21 days after the onset of COVID-19 symptoms and/or a positive SARS-CoV-2 test in an 90 outpatient setting [11] . Although replication-competent SARS-CoV-2 has been difficult to detect in 91 individuals with protracted COVID-19 symptoms, recovered patients continue to shed detectable SARS-92CoV-2 RNA in their upper respiratory tract and in their stool for weeks after initial diagnosis [12] [13] [14] . 93 Furthermore, indirect immunologic evidence of SARS-CoV-2 antigen persistence has been observed, 94 most notably reflected in the maturation profile of SARS-CoV-2 specific memory B cells [15] . 95The presence of persistent viral antigen and/or infection-attendant inflammation is associated with 97 SARS-CoV-2 specific cellular immune response was observed between these two groups when stratified 163 by the duration of self-reported COVID-19 symptoms (Figure 2A, Supplemental Figure 1 ). When 164 further stratified by viral antigen, no difference in the level of reactivity against N, 165 and M was observed between individuals with either a short or long duration of COVID-19 symptoms 166 ( Figure 2B ). A statistically significant higher level of ORF3a and OFR7a reactivity was observed in 167 individuals with longer periods of COVID-19 symptoms than in individuals with a short period of 168 COVID-19 associated symptoms ( Figure 2B ), but most of these responses fell under the 50 SFC/10 6 169 PBMC threshold for positivity ( Table 1) . 170To further define the profile of SARS-CoV-2 specific cellular immunity and how it stratifies by 172 COVID-19 symptom duration, we assessed the multi-parametric antigen reactivity pattern captured in 173 our ELISPOT analysis. Most individuals included in this analysis exhibited cellular immunity against 174 two-or-more SARS-CoV-2 antigens, with 71.3% of individuals with a short period of COVID-19 175 symptoms and 68.4% of individuals that experienced a long period of COVID symptoms exhibiting a 176 multivalent antigen response ( Figure 2C) . The most common multi-antigen reactivity pattern observed 177 in individuals with a short duration of COVID-19 symptoms was a trivalent response against SARS-178immunity in convalescent COVID-19 patients correlated with the duration of self-reported symptoms, 232 and if the magnitude of seasonal human coronavirus cellular immunity correlated with SARS-CoV-2 233 specific cellular immunity. 234To this end, we utilized overlapping peptide pools spanning the Spike proteins of the human seasonal 236 coronaviruses 229E and NL63 to stimulate PBMC from the same donors described above in a parallel 237 IFN-γ ELISPOT assay. While the majority of subjects exhibited reactivity against the Spike protein from 238 both 229E and NL63, persistent COVID-19 symptoms did not statistically impact magnitude of 229E 239 ( Figure 5A ) or NL63 ( Figure 5B ) Spike protein reactivity as assessed by IFN-γ ELISPOT. While the 240 magnitude of 229E and NL63 reactivity within a given subject correlated with each other, the magnitude 241 of SARS-CoV-2 Spike protein reactivity observed in a given subject does not correlate with their 242 reactivity to Spike from 229E or NL63 (Figure 5C ), suggesting that these cellular populations may be 243 distinct in convalescent COVID-19 patients. Interestingly, despite the lack of correlation between 244 NL63/229E Spike reactivity and SARS-CoV-2 Spike reactivity, the presence of either NL63 or 229E 245In this study, we examined the relationship between the duration COVID-19 symptoms and the 256 magnitude and functional profile of SARS-CoV-2 specific cellular immunity in individuals recently 257 recovered from mild/moderate COVID-19. We observed that patients with prolonged COVID-19 258 symptoms overall exhibited similar levels of SARS-CoV-2 specific cellular immunity as individuals 259 who rapidly resolved their symptoms. No defect was observed in the magnitude of the SARS-CoV-2 260Spike specific CD4 and CD8 T cell response in individuals with prolonged COVID-19 symptoms when 261 assessed using flow cytometry, and the transcription profile of SARS-CoV-2 specific CD4 T cells was 262 observed not to be influenced by the duration of COVID-19 symptoms. Finally, while significant levels 263 of cellular immunity against the seasonal human coronaviruses 229E and NL63 was observed in all 264 convalescent COVID-19 patients analyzed in the study, the magnitude of this immune response did not 265 correlate with the duration of COVID-19 symptoms. These data suggest that prolonged symptomatic 266 COVID-19 does not significantly impact the development of SARS-CoV-2 specific cellular immunity in 267 patients with mild/moderate disease. 268The development of SARS-CoV-2 specific cellular immunity has been ubiquitously observed following 270 the resolution of COVID-19 symptoms and may be a more sensitive immunologic indication of SARS-271Information regarding the timing and duration of acute COVID-19 symptoms -such as fever, shortness 308 of breath, sore throat, cough that impacted activity, and fatigue that impacted activity -were self-309",USA,first author,2021-02-01,02
7e27248cf8655ae9809d0195d210980e2fb0454e,"Confirmation of an Inverse Relationship between Bioaerosol Count and Influenza-like Illnesses, Including COVID-19. On the Contribution of Mold Spores","Influenza-like illnesses (ILIs) attributable to influenza viruses and to coronaviruses are sharply seasonal. 1, 2 Importantly, recent data from The Netherlands indicate there exists an inverse relationship between the seasonal incidence of influenza-like illnesses, including COVID-19, and pollen count. 3, 4 To discern whether such a relationship might be the case generally, pollen count in Chicago was related to ILIs reported by local emergency departments. In Chicago, as in The Netherlands, ILIs fall as total pollen count rises.Because bioaerosols measured in Chicago include not only pollens but also mold spores, ILIs were related to counts of both. Just as they do for pollens, ILIs fall as mold spore count rises. In contradistinction to their temporal relationship with pollens, however, ILIs remain low when mold spore count is high, rising again when mold spore count falls. bioaerosol burden. For the studies reported herein, both pollens and mold spores were counted. Those counts were then analyzed, in aggregate and individually.Usually, pollens and mold spores in Chicago are monitored from ~ mid-March to ~ mid-October, the period most problematic for persons suffering from seasonal allergies. As expected, the data indicate bioaerosol expression is cyclical with a periodicity of ~ 1 year, Fig. 1B . The total bioaerosol count peaks during ~ mid-September and falls sharply thereafter. Unfortunately, data following the peaks are somewhat limited, their collection being truncated on an arbitrary end date, i.e., ~ mid-October.In the case of pollens, the seasonal distribution is bimodal, with a dominant first mode that peaks in ~ mid-May and a smaller second mode that peaks in ~ late August, Fig.  1C . The pollens that constitute the second mode, here termed 'late pollens', are predominantly Ambrosia and the other Asteraceae. Importantly, the peak of the second mode always coincides with the leading bump in ILI presentations, Figs. 1A and 4. The potential relevance of this is addressed under Discussion. In the case of mold spores, which constitute the bulk of the measured bioaerosols, Figs. 1B and 1D, and Table 2 , the peak count, which occurs during ~ late September, falls precipitously by ~ mid-October, with an empiric half-life of ~ 10 d, Table 3 .Although these data substantiate the claim of an inverse relationship between the onset of pollen season and the end of flu season, pollen count declines rapidly and is not elevated when ILI presentations, Fig. 5A , and COVID-19 presentations, Fig. 6A , are low. Mold spores, on the other hand, increase continuously in first-order fashion, Table  3 and Fig. 7 , beginning just prior to or coincident with the fall in ILI, Fig. 5B , and COVID-19 presentations, Fig. 6B , and across the entirety of the summer months, when influenza and COVID-19 cases are low.If one assumes ILI and COVID-19 presentations are consequences of the binding of relevant viruses to specific receptors, then one can treat the presentations as proxies for those receptors, for which mold spores compete. Toward that end, ILI and COVID-19 presentations were plotted as functions of total mold spore count, Fig. 8 . Because the curvatures of the plots suggest true equilibria, the data of each were fit to the equation P = P o /(1+C/K d ) + B, where P is the observed number of presentations to emergency departments, P o is the maximum number of such presentations, C, in mold spores/m 3 , is the measured mold spore count, K d , in mold spores/m 3 , is the apparent dissociation constant of the receptor -mold spore complex, and B is a constant representing presentations not influenced by mold spores. As shown in the figures, the data of each plot fit reasonably well the theoretical model. presentations. The most parsimonious explanation for the near equivalence of the apparent dissociation constants is a shared receptor.The data presented herein are consistent with those presented earlier by others, 3, 4 namely, the incidence of ILIs falls as pollen count rises. Because the data of the present study derive from an urban area in North America (Chicago, IL USA: latitude 41.85003, longitude -87.65005) whilst those of the earlier study derive from North Central Europe (Helmond, The Netherlands: latitude 51.48167, longitude 5.66111), it appears the inverse relationship may be generally valid.With special regard to the late pollens, changes in their atmospheric concentration invariably coincide with the annual leading bump in ILIs. Inasmuch as Ambrosia, the dominant species, is a major respiratory allergen, the leading bump may represent ragweed sensitivities manifesting as ILI. Regardless, the peak in late pollen count --as if a switch --presages the major upswing in ILI, Fig. 4 , and COVID-19, Fig. 6C , presentations. Thus, aside from any contribution to mechanistic understanding it might provide, the peak in late pollens could be exploited when contemplating an upcoming ILI season.Separate and distinct from pollen count, mold spore count in Chicago correlates inversely with ILIs. Indeed, given their higher atmospheric concentration as well as the duration of their seasonal expression, mold spores seem more likely than pollens to be principals in any abatement of ILIs, including COVID-19. Mold spores and pollens could abate viral activity by either direct or indirect means. By direct means, they might produce substances that limit viral propagation or they might complex with viruses, limiting viral infectivity. 13, 14 But if direct antiviral activity is an attribute of the bioaerosols themselves, then one would not expect, a priori, significant disparity between individual susceptibilities to severe flu or COVID-19. 15, 16 As indirect means, others have proposed pollens stimulate the human immune system in such a way as to either potentiate endogenous antiviral activity or elicit a protective allergic response. 3 Against these proposals, asthma does not confer protection against either influenza or COVID-19. [17] [18] [19] The similarity of the proposed mold spore dose dependencies for abatement of flu and COVID-19 suggests a shared receptor. Although much attention has been given to angiotensin-converting enzyme 2 (ACE-2) and its role in COVID-19, 20,21 there are compelling reasons to believe TLR4, which binds the SARS-CoV-2 spike protein with greater affinity than does ACE-2, 22 is also operative: 1) TLR4 is implicated in the inflammatory response triggered by sharply seasonal respiratory viruses, 23-25 2) TLR4 has a significant role in innate defense against multiple species of fungi, 26,27 and polymorphisms in TLR4 are associated with invasive fungal disease, 28,29 3) COVID-19 prognosis correlates with radiographic involvement of alveolar spaces, 30,31 the epithelial surfaces of which are poor in ACE-2 32,33 but rich in TLR4, 34 4) inflammation of the sort associated with acute lung injury is mediated by TLR4, 35-44 and 5) age-dependent hyper-responsiveness of TLR4 45 , especially in the context of interactions with TLR5, 46,47 can account for the age-dependent severity of COVID-19. That TLR4 may be involved in the processing of bioaerosols is also expected on phylogenetic grounds: the receptor has been retained by some fish that breathe air, but lost by those that do not, 48 and the eponymous Toll receptor controls the antifungal response of Drosophila. 49 Given these, one can imagine the engagement of TLR4 by aerosols of all sorts, including, but not limited to, viruses, pollens and mold spores, in a fashion analogous to the engagement of hook-and-loop adhesives, i.e., Velcro ® . Instead of loops, however, spinous processes of the various aerosols engage TLR4 'hooks,' effecting an innate immune response, the nature of which depends on the arrangement and density of the engagement. And just as hook-and-loop adhesives can be rendered nonfunctional/dysfunctional by nonspecific adherence of extraneous materials, so, too, might TLR4 hooks become saturated with one ligand, e.g., mold spores and/or pollens, to the exclusion of another, e.g., a respiratory virus.The data presented herein bring new appreciation and understanding to seasonality and suggest a remarkable interplay between bioaerosols that influence the health of man. Indeed, inasmuch as humans have co-existed with plants, fungi and viruses for some time, it stands to reason that, over the course of evolution, the respiratory system of the former would have developed means to cope with the significant recurring, i.e., annual, inhalational exposure to reproductive elements of the latter. As the environment-facing interface of the respiratory tree, epithelial cells and their entourage of innate immune effectors seem ideally positioned to provide that coping mechanism.A volumetric spore trap (Burkard Manufacturing, Hertfordshire, England) equipped with a 24 h sampling head was used to collect pollens and mold spores. The trap was fixed ~ 70 feet above ground, on a roof in Melrose Park, Il, USA. A standard glass microscope slide coated with grease was placed in a carriage that moved at a rate of 2 mm/h past the trap orifice (14 mm x 2 mm). Air was drawn through the orifice at a rate of 10 l/min, thereby impacting airborne particles against the greased slide. Slides so exposed were stained with glycerin jelly supplemented with basic fuchsin. After applying a coverslip, a slide was evaluated microscopically for both pollens and mold spores, Table 4 . A new slide was placed in the trap daily, and the carriage was reoriented to its start position. Bioaerosol counts were made Monday through Friday, generally between mid-March and mid-October.ILI data pooled from 23 large hospitals in Chicago over the period January 9, 2015 through July 18, 2020 were obtained from the Chicago Department of Public Health (CDPH). The 23 hospitals were chosen because they alone of Chicago-area hospitals consistently reported ILI presentations over the entirety of the study interval. The data are included in the Supplement, Table S1 . COVID-19 data from all Chicago hospitals were obtained through portals of the CDPH, https://www.chicago.gov/city/en/sites/ covid19/home/covid-dashboard.html and https://data.cityofchicago.org/browse?limitTo= datasets&sortBy=alpha&tags=covid-19. Those data are also included in the Supplement, Table S2 .Time-or dose-dependent data were paired with the corresponding time or dose and fit to equations described in the text. The best values for the parameters of the equations, as well as their corresponding 95% confidence intervals, were then determined using the paired data and a nonlinear least squares regression method. 50 Acknowledgment D.A.R. and G.S.R. thank their children, Andrew, Jonah, Ruth and Damien, for inspiration.R.B.S. collated all the data, and contributed to preparing and writing the manuscript. R.D.S. collected the pollen and mold spore data, and contributed to writing the manuscript. D.G.R. processed and analyzed the data, and contributed to preparing and writing the manuscript. A.C.R. analyzed the data and contributed to preparing and writing the manuscript. D.A.R. conceived parts of the manuscript and contributed to its preparation and writing. G.S.R. conceived and designed the study, processed and analyzed the data, and contributed to preparing and writing the manuscript. Table 4 Bioaerosols of this study. The measured bioaerosols of this study, i.e., pollens and mold spores, are those listed here. They were collected and quantified as described in the text.All rights reserved. No reuse allowed without permission.The inset shows the expected linearity of the same data when plotted according to the method of Kézdy, 12 in this case ILI presentations day n vs. ILI presentations day n+1 . Data shown in red are solely the counts of late pollens, most of which are Ambrosia and other Asteraceae. Superimposed on them are the ILI data of Fig. 1A . As if a switch, the peak in the count of late pollens always occurs coincident with onset of the bump in seasonal ILI presentations. See text for additional details.",USA,first author,2021-02-16,02
c0a71bdfc0d2fbfa598184c4fbbd13cdbafc75f1,Role of IgG against N-protein of SARS-CoV2 in COVID19 clinical outcomes,"Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) and its resultant disease, Coronavirus Disease 2019 (COVID19), has spread rapidly since its first report in Wuhan, China, to become a public health threat of global importance 1, 2 . According to the World Health Organization, there are over 30 million cases worldwide as of February 1st 2021, with the United States accounting for 26 million cases and over 440,000 deaths alone. This prolific virus is a positive-sense single-stranded RNA belonging to the Betacoronavirus genus.SARS-CoV-2 has four key structural proteins. The Nucleocapsid Protein (N Protein) is found in the viral core 3 . The Spike Protein (S Protein), Matrix Protein (M Protein) and Envelope Protein (E Protein) 3 are all found on the virus's outer surface. The S Protein is a key determinant in the viral host range and possibly infectivity 4 . Immunoglobulin G (IgG) developed against the S protein is believed to be a neutralizing antibody immune response and is currently the primary target for COVID19 vaccine trials. The M protein is the most abundant protein on the viral surface and is believed to play a role in viral budding from the host cell membrane 5, 6 . The E protein is the smallest protein whose function is poorly defined, but it is thought to contribute to intracellular viral trafficking and viral protein assembly 7 .Although the functionality of the N protein is not well understood, it has been well studied in SARS-CoV1 8 . The N protein is closely associated with viral RNA structure and function and plays a vital role in viral transcription and assembly while functioning as an RNA chaperone 9 . The N segment of the RNA has 3 distinct regions; a motif responsible for length of amino acids of N protein, a sumoylation motif (lysin residue), and a serin residue responsible for phosphorylation by a cyclin-dependent kinase complex 8 . Study design and sampling of peripheral blood. The study population included individuals admitted to the University of Miami Hospital with COVID19 infection confirmed via RT-PCR from nasopharyngeal swabs. Four hundred RT-PCR confirmed COVID19 patients were enrolled. Out of the 400 COVID-19 patients, 100 were consented to participate in the COVID19 biobank. Figure 1 shows the study algorithm. Serum samples were used to measure IgG against N-protein and whole blood was used for SARS-CoV2 RT-PCR.All 100 serum samples were enrolled for IgG measurement. The single to cut off (S/Co) ratio was measured for all samples.Fifteen patients were randomly selected for whole blood RNA extraction. Five patients with high IgG titers (defined as S/Co ratio > 1.5), 5 with positive IgG but S/Co ratio < 1.5, and 5 with undetectable IgG levels were selected at enrollment. www.nature.com/scientificreports/ Peripheral blood samples were collected following enrollment and processed by centrifugation at 1800 g for 30 min. Serum and whole blood were aliquoted into 2 ml cryogenic tubes and stored at -80 C immediately for later analysis.Data collection and outcomes. Demographic, clinical, and outcome data were collected from the electronic medical record system for each patient. Charlson Comorbidity Index (CCI) was calculated using the comorbidities and age data for each patient. The main outcomes were ICU admission, length of stay in ICU, and in-hospital mortality. In-hospital mortality was defined as death occurring during the hospital stay.ELISA test. Serum samples were processed and analyzed for SARS-CoV-2 IgG antibodies and anti N-protein IgG levels using an ELISA kit for IgG by Epitope Diagnostics 16 according to manufacturer's protocol. The average value of the absorbance of the negative control (xNC) was calculated. Cut off values for positive tests were determined by the manufacturer's formula [1.1 X (xNC + 0. 18) ]. To assure the validity of the results each assay must include both negative and positive controls. The average value of the absorbance of the negative control is less than 0.25, and the absorbance of the positive control is not less than 0.30. Moreover, all assays include the laboratory's own controls in addition to those provided with this kit 17 . Signal to cut-off ratio was calculated for each sample.RNA isolation. RNA isolation from whole blood samples was performed by using a kit from ZymoResearch (Orange, CA, USA) according to the manufacturer's recommendations.The Express Gene SARS-CoV2 RT-PCR Diagnostic Panel was used to detect SARS C on extracted RNA from blood samples. The Express Gene SARS-CoV2 RT-PCR Diagnostic Panel is authorized for COVID-19 detection by the FDA (EUA200423). To prevent contamination, all reagents were prepared in a PCR amplicon-free workstation. All RNA samples and components were kept on ice during use. The TaqPad Combo kit was used for detection of N gene, S gene and ORF1ab targets on COVID-19 tests. One Positive Control (1 × 104 copies/μL) and one Negative Control were included on the RT-PCR plate. RNA samples were thawed on ice, then 2.5 µl RNA samples containing 15 ng total RNA were used for RT-PCR master mix together with primer and probes. One-step RT-PCR reaction mix (ThermoFisher) was used for RT-PCR reaction. All samples were run in triplicate. The Express Gene SARS-CoV2 RT-PCR Diagnostic Panel can detect quantities as low as 2 copies of N gene, 4 copies of ORF1ab, and 10 copies of S gene from COVID-19 viral genome per reaction volume. This information is part of our approved FDA Emergency Use Authorization (EUA200423) and can be found on the FDA website.Statistical analysis. Categorical variables were presented as numbers and percentages and examined with the Mantel-Haenszel test. Continuous variables were compared using Student T-test (normally distributed) and Wilcoxon rank-sum (non-normally distributed) variables. A univariate analysis was subsequently performed to compare differences in categorical and continuous variables for each outcome. To determine risk factors for each outcome, a multivariable analysis was performed using a stepwise logistic regression model. Cox regression was performed to determine risk factors associated with in-hospital mortality. Clinically relevant factors were found based on our and other studies and added into the models [18] [19] [20] [21] . We used the Charlson comorbidity index because we expected a low number of outcomes for each outcome variable and were able to include only a limited number of potential confounders from the comorbidities in the model (CCI) 22 . The statistical significance was accepted when the p value was less than 0.05. Statistical analysis was performed using IBM SPSS version 26.Informed consent was obtained from all participants.A total of 400 patients were diagnosed with COVID19 infection during the study period. The demographic and clinical data of patients are reported in supplementary Table S1 . Emergency physicians admitted 248 (62%) of the patients and the rest were discharged. Among the patients who were admitted to the hospital, the mean (SD) age was 63 (17.2) years old and 141 (57%) were male, 147 (61%) were White, while 65 (44.4%) of them were White Hispanic. Sixty-two (24.5%) of admitted patients were African American and the rest multiracial.During hospitalization, 76 (30%) patients were admitted to the MICU. In univariant analysis, patients were found to be more likely to be admitted to the MICU if they were on chemotherapy, had consolidation or bilateral opacities in chest images, or had laboratory findings of higher leukocyte counts, lower platelet counts, higher levels of BUN, serum IL6, CRP, LDH, or lower serum albumin levels (Table S2 ). Patients presenting complaints of dyspnea, fever, abdominal pain (but not chest pain) were more likely to be admitted to the MICU (Table S3 ). The mean CCI was higher in patients admitted to the MICU compared to non-MICU patients, 3.67 vs 2.99 (P = 0.047), respectively. Patients with diabetes mellitus (OR = 2.4) had higher risk for admission to MICU. Patients admitted to the MICU had higher odds of in-hospital death (OR = 7.85). Among CRP levels, IL6 levels, CCI, and dyspnea, only dyspnea was found to be independently associated with increased risk of admission to the MICU, using the multivariable logistic regression model. (Table 1 ). , S5 ). The Cox regression model for in-hospital mortality showed that between CCI, high concentrations of LDH and IL6, using ACE inhibitors before admission, only CCI and IL6 were independently associated with in-hospital mortality ( Table 2) .Out of the 248 patients admitted with COVID-19, 100 consented to participate in the serology study. The mean (SD) age was 63 (16.9) with a median of 64, and 49 (49.5%) were male. 61 (62%) were White, while 50 (82%) were White Hispanic.Anti-N protein IgG was positive in 55 (55%) patients at the time of admission. Tables 3 and 4 show the demographic and clinical data of the study population.In univariate analysis, an S/Co ratio greater than 1.5 was found to be associated with increased likelihood of admission with symptoms of dyspnea (p = 0.01, OR = 4.57) and cough (p = 0.041, OR = 3.10). Patients with S/Co ratio > 1.5 were more likely to have bilateral infiltrates on admission (p = 0.036, OR = 2.87). There was a significant difference (p = 0.035) in mean hematocrit percentage in patients with an S/Co ratio > 1.5 (M = 35.40 ± 7.63) vs those with lower S/Co ratio (M = 38.98 ± 6.81). There were also significant (p = 0.017) differences in albumin levels for patients who had an S/Co ratio > 1.5 (3.67 ± 0.50 g/dl) and those who did not (3.35 ± 0.53 g/dl). There were also significant (p = 0.022) differences in mean lymphocyte levels for patients with an S/Co > 1.5 (2.42 ± 4.90 × 10 3 cells/ml) and patients who did not have an S/Co > 1.5 (1.06 ± 0.67 × 10 3 cells/ml). S/Co ratio > 1.5 was associated with increased likelihood of ICU admission (p = 0.047, OR = 2.63 days). S/Co > 1.5 was also associated with increased likelihood of staying in the hospital for more than 16 days (p = 0.006, OR = 4.06) and MICU stays of more than 8 days (p = 0.004, OR = 32.50) ( Table 4 ). There was a significant correlation between IgG S/Co ratio and days in MICU as shown in Fig. 2 .The multivariable logistic regression model for MICU admission showed that between African American, CCI, lymphocyte counts, and S/Co ratio > 1.5, only S/Co ratio were independently associated with MICU admission (Table 5 ). In multivariable analysis for hospital stays of more than 16 days, S/Co ratio > 1.5 (p = 0.047, OR:2.63) was again the only independent factor among factors the mentioned variables (p = 0.006 OR:4.1) ( Table 6) .Whole blood RT-PCR. The RT-PCR reaction indicated undetermined levels of N gene, S gene, and ORF1ab nucleotides sequences on prepared RNA samples from subjects with negative, low, and high concentrations of IgG. RT-PCR data is shown in the supplemental Excel file.This study indicates that elderly males with COVID19 and a higher number of comorbidity scores were more likely to be admitted to the hospital. Among hospitalized patients, we found only high levels of dyspnea independently predicted MICU admission. We also demonstrated that higher CCI and higher IL6 levels were independently associated with in-hospital mortality. www.nature.com/scientificreports/ COVID19-confirmed patients admitted to the hospital for hypoxemia are likely to have developed a high concentration of IgG against the N protein of SARS-CoV2. High IgG levels are associated with a higher risk of admission to the MICU and a more extended stay in the hospital. We also found no evidence of viremia in our hospitalized COVID19 patients.The present investigation is the first to report an association of high concentration of IgG against the N protein with poor outcome in COVID19. Prior studies reported detectable levels of total IgG in COVID19 patients in the first week of the disease 23, 24 . We found that a high concentration of IgG against N-protein caused a threefold increase in risk of admission to the MICU. It could be theorized that N protein IgG may favor a higher inflammatory response during infection. Neutralizing Abs are usually produced against viral entry proteins [25] [26] [27] . The IgG against intact S protein or the S1 subunit of S protein is accepted as a neutralizing antibody against SARS and COVID19 [28] [29] [30] . The IgG targeting S protein is likely protective, and it has become the primary target for COVID19 vaccine development 31 . There is no evidence to suggest that S protein IgG (via vaccine or passive IgG infusion) induces lung pathology via the ADE effect 32 . Although the potential role of ADE in COVID19 remains unknown, the current study suggests that the IgG levels of non-neutralizing nucleoprotein may be a reason for poor outcomes in COVID19 subjects. Little is known about the mechanism of ADE in SARS-CoV-2 infection. The effect of macrophases in viral spread, excessive inflammation and activation-induced lymphocytic cell death during SARS-CoV-2 infection has been suggested as a Trojan Horse in COVID19. Severe lymphocytic apoptosis www.nature.com/scientificreports/ in post-mortem subscapular lymph nodes and spleens of patients who died from COVID19 indicates an underlying mechanism of lymphopenia in severe COVID19 patients. Feng et al. found viral nucleocaspid protein in ACE2 + cells, CD169 + macrophages, but not in CD3 + T cells or B220 + B cells in spleens and lymph nodes. The CD68 + CD169 + macrophages were detected in the splenic marginal zone and in marginal sinuses of lymph nodes contained SARS-CoV-2 nucleoprotein antigen which could induce upregulation of IL-6. The infected immune cells respond with cytokine production, and autophagy 33 . Interestingly, a higher rate of reported pulmonary embolism and thrombosis in patients with severe COVID19 34-36 may be attributed to platelet activation after direct infection with the virus and secondary autophagy 37, 38 .Another possible pathologic mechanism could be antibody-mediated cellular cytotoxicity in infected cells expressing N protein particles in the cell wall. Natural killer cells, neutrophils, and macrophages interact with IgG and eliminate the target cells [39] [40] [41] . Immune complex development against N protein is a fascinating potential www.nature.com/scientificreports/ mechanism. Berger and his colleagues showed that the immune complex induces IL6 secretion by immune cells and activates a network of proinflammatory cytokines and profound systemic inflammatory response 42 . Immune complex against N protein may contribute to the hyperinflammatory response that has been reported in COVID19 43 . The role of ADE in the pathogenesis of dengue has been reviewed previously 44 . In animal models studying the pathogenesis of the dengue virus, ADE was associated with higher viremia [45] [46] [47] . However, the current study suggests that the pathogenesis of SARS-CoV2 may not correlated with higher ADE-associated viremia. Our observation may suggest that SARS-CoV2 might stay in the lymphatic system and avoid the bloodstream. Further investigation is urgently needed to confirm our findings.The major limitation of our study is that we did not measure total non-neutralizing IgG and non-neutralizing anti-S and other proteins. In addition, we were unable to show the effect of IgG targeting N protein on mortality of COVID19 patients in the multivariable analysis due to sample size limitations. Moreover, this limitation could also be a contributing factor to the lack of viremia in our studied patients. This study has not yet been validated in another cohort of COVID19 patients.Further investigation is urgently needed to assess the pathologic mechanisms of IgG for N-protein in severe COVID19. In particular, a larger multicentric study should be conducted to investigate the role of IgG targeting N protein on COVID19 mortality. A better understanding of the role of ADE in platelet activation may shed light on the hypercoagulable state in COVID19 and generate new therapeutic modalities.In summary, this study recommends that during the initial assessment of patients with COVID19, IgG targeting N-protein of SARS-CoV2 should be included among the measures. The high concentration of this immunoglobulin may predict poor outcomes, although further validation is needed.Received: 29 September 2020; Accepted: 29 January 2021",USA,first author,2021-02-10,02
db3dbfeec25904ea17b4ec1b572c2670e952e6cc,The functions of SARS-CoV-2 neutralizing and infection-enhancing antibodies 1 in vitro and in mice and nonhuman primates (103 characters) 2 3,"The severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) has caused a global pandemic with over 58 96 infected with SARS-CoV-1 ~17 years prior to sample collection (Figures 1A-B, S1 and S2) . We isolated and 102 characterized 1,737 antibodies that bound to SARS-CoV-2 S or nucleocapsid (NP) proteins ( Figure 1C ; Table S1 ).We selected 187 antibodies for further characterization, and examined neutralization of SARS-CoV-2 pseudovirus 104 and replication-competent SARS-CoV-2. Forty-four of 81 recombinant RBD antibodies exhibited neutralization 105 when assayed in 293T/ACE2 cell pseudovirus, SARS-CoV-2 microneutralization, or SARS-CoV-2 plaque 106 reduction assays (Figures S3A-F; Tables S2-S3 ).Ten of forty-one NTD antibodies neutralized in the 293T/ACE2 pseudovirus and plaque reduction assays, 108 with the most potent antibody neutralizing pseudovirus with an IC50 of 39 ng/mL (Figures S3G-I; Tables S4-S5) .In addition, 5 non-neutralizing NTD antibodies enhanced SARS-CoV-2 pseudovirus infection in 293T/ACE2 cells 110 by 56% to 148% (Figure 1D) . Infection of replication-competent SARS-CoV-2 nano-luciferase virus (Hou et al., 111 2020) also increased in the presence of each of the 5 non-neutralizing NTD antibodies ( Figure 1E) . Analysis We compared the phenotypes and binding modes to S protein for five infection-enhancing RBD antibodies 134 and three RBD antibodies that lacked infection enhancement to elucidate differences between these two types of 135 antibodies. The selected RBD antibodies neutralized SARS-CoV-2 pseudovirus and/or replication-competent virus 136 in ACE2-expressing cells (Figures 2A and S5) , despite five of these antibodies mediating infection enhancement 137 in ACE2-negative, FcR-positive TZM-bl cells (Figures 1F-L, 2A, and S5 (Figures 2A and S10) . The remaining two RBD 151 antibodies, DH1045 and DH1047, cross-reacted with both SARS-CoV-1 and SARS-CoV-2 S (Figures 2A, S4, 152 S31). DH1047 also reacted with bat and pangolin CoV spike proteins (Figures 2A, S4, S31 Figure 2E) . Thus, S protein antibody epitopes and binding modes were associated with FcR-167 independent, infection-enhancing activity of NTD antibodies. The five neutralizing antibodies bound the same 168 epitope as antibody 4A8 (Wrapp et al., 2020a) , with three of the five having the same angle of approach as 4A8 169 ( Figure S11) . Interestingly, the NTD antibodies with the same angle of approach as 4A8, were also genetically 170 similar to 4A8, being derived from the same VH1-24 gene segment (Table S8) NTD antibodies also segregated into two clusters based on their ability to block each other ( Figure 3A ).Neutralizing NTD antibodies blocked each other and formed one cluster, while infection-enhancing/non-185 neutralizing NTD antibodies blocked each other and formed a second cluster (Figures 3A, 3C , S12 and S13).NSEM reconstruction of SARS-CoV-2 S trimer bound with Fabs of neutralizing NTD antibody DH1050.1 and 187 infection-enhancing NTD antibody DH1052 confirmed that the two antibodies could simultaneously bind to 188 distinct epitopes on a single SARS-CoV-2 S trimer ( Figure 3D ). DH1054 was unique as it was able to block both 189 infection-enhancing and neutralizing NTD antibodies (Figures 3C and S13 ).NTD antibodies did not compete with RBD antibodies for binding to S trimer ( Figure 3A ). This result gave 191 rise to the notion that in a polyclonal mixture of antibodies, the SARS-CoV-2 S trimer could bind both RBD and 192 NTD antibodies. To determine the potential for this complex to form, we liganded SARS-CoV-2 S trimer with Fabs 193 of each type of antibody and visualized the complex using NSEM. NSEM showed that neutralizing RBD antibodies 194 9 could also bind to the same S protomer as neutralizing NTD antibodies DH1050.1 or DH1051 ( Figure 3E ).Moreover, we found that a single S protomer could be simultaneously occupied by two RBD antibodies (DH1043 196 and DH1047) and an NTD antibody (DH1050.1) ( Figure 3F) . Thus, the S trimer could simultaneously bind to 197 multiple RBD and NTD neutralizing antibody Fabs. We observed that the primary epitopes of DH1041 and DH1043 were centered on the Receptor Binding Motif 237 (RBM; residues 483-506) of the RBD (Figures 4A-B , S17 and S18), providing structural basis for the ACE-2 238 blocking phenotype of these antibodies. While DH1041 utilized its heavy chain complementarity determining 239 regions (CDRs) to contact the RBM, the DH1043 paratope included both its heavy and light chains. (Figure 5A) . Throughout the four days of infection, DH1052-infused 283 mice exhibited similar levels of body weight loss and higher survival than mice given negative control IgG (2/9 284 control mice died while 0/10 DH1052-treated mice died) (Figures 5B-C) . In addition, DH1052-treated mice 285 exhibited lower lung hemorrhagic scores, lower lung viral plaque-forming unit (PFU) titers and lower lung tissue 286 subgenomic RNA levels compared to control IgG-infused mice (Figures 5D-F) Antibody infusion resulted in human antibody concentrations ranging from 11 to 238 μg/mL in serum at day 2 298 post-challenge (Figures 5H-I and S23A-D) . Sera with DH1050.1 neutralized SARS-CoV-2 pseudovirus at a mean 299 ID50 titer of 19 (Figure 5J) , and neutralized SARS-CoV-2 replication-competent virus at a mean ID50 titer of 192 300 ( Figure 5K) . In contrast, the presence of DH1052 or control antibody CH65 in serum did not neutralize SARS-301 CoV-2 (Figures 5J-K) . Four of 5 macaques that received DH1052 had comparable lung inflammation to control 302 CH65-infused macaques four days after infection (Figures 5L, S24 and S25A) . However, one macaque (BB536A) 303 administered DH1052 showed increased perivascular mononuclear inflammation, perivascular and alveolar edema 304 13 (Figure S25B) , and multiple upregulated bronchoalveolar fluid (BAL) cytokines (Figures S26-S27 ) compared to 305 either control antibody-infused animals or the four other monkeys in the DH1052-treated group. Immunohistologic 306 analysis with markers of macrophage subsets demonstrated alveolar and perivascular infiltration of M2-type 307 macrophages in both monkey BB536A with histologic appearance of alveolar edema and in control antibody-308 treated monkey BB785E (Figure S28) .In contrast, macaques administered DH1050.1, a neutralizing NTD antibody, had lower lung inflammation 310 than CH65-infused macaques (Figures 5L, S24 and S25A ) and fewer infiltrating macrophages (Figure S28 ).Infusion of either neutralizing NTD DH1050.1 or in vitro infection-enhancing antibody DH1052 reduced viral 312 nucleocapsid antigen in the lung (Figures 5M, S24 and S25A) . Envelope (E) gene subgenomic RNA (sgRNA) and 313 nucleocapsid (N) gene sgRNA in the BAL were also reduced in macaques that were administered DH1050.1 or 314 DH1052 compared to macaques treated with negative control antibody (Figures 5N-O and S23G) . In nasal swab 315 fluid, macaques showed reduced E and N gene sgRNA when neutralizing antibody DH1050.1 was infused (p < 316 0.05, nonparametric exact Wilcoxon test) (Figures 5P-Q, S23E-F and S23H-I) . With DH1052 infusion, there was 317 a trend to viral control but not significant.Since DH1052-mediated infection enhancement in vitro increased as the antibody concentration increased 319 ( Figures 1D-E) , we performed an additional challenge study in 6 additional cynomolgus macaques with either 30 320 mg/kg of DH1052 or CH65 control antibody ( Figure S29A ). After challenge, the infection-enhancing, non-321 neutralizing NTD antibody DH1052 again showed a trend to suppress BAL viral load (Figures S29B-D) , and 322 significantly reduced viral replication in nasal swab samples (p < 0.05, nonparametric exact Wilcoxon test) 323 ( Figures S29E-G) compared to the negative control antibody CH65. Moreover, DH1052-treated macaques showed 324 equivalent lung inflammation (Figures S29H-I) , antigen expression (Figures S29J-K) , and cytokine expression 325 ( Figure S30 ) compared to CH65 control-treated macaques. Thus, with high dose (30mg/kg) of DH1052 antibody, 326 there was no enhanced lung pathology or elevated BAL cytokine levels post-SARS-CoV-2 challenge. These results 327 raised the hypothesis that the lung pathology seen in monkey BB536A was rare and may not have been caused by 328 antibody infusion.We next tested RBD neutralizing antibodies that also mediated infection enhancement in TZM-bl cells 332 expressing FcRI or FcRII in a SARS-CoV-2 acquisition mouse model (Figures 6A-B) . Aged (Figures 2A, S4A-B, S5E-H and S31) . Both of these RBD antibodies mediated FcR-dependent, in 345 vitro SARS-CoV-2 infection enhancement of TZM-bl cells that lacked ACE2 expression (Figures 1F-L) . To 362   1 and 6E) . After antibody infusion at 10 mg of antibody per kg of macaque body weight, serum human IgG 363 concentrations reached 11-228 μg/mL at day 2 post-challenge (Figures 6F-G and S23A-D) . The same macaque 364 serum containing the RBD antibodies exhibited a wide range of neutralization potency (ID50 titers) against SARS-365 CoV-2 pseudovirus or replication-competent virus, commensurate with the neutralization potency of each antibody 366 (Figures 6H and 6I) . Infusion of RBD antibody DH1041, DH1043, or DH1047 resulted in vivo protection from 367 SARS-CoV-2 infection. In macaques administered DH1041, DH1043, or DH1047, lung inflammation was reduced 368 and lung viral antigen was undetectable compared to control (Figures 6J-K, S24 and S25A ). E gene sgRNA and N 369 gene sgRNA were significantly reduced in the upper and lower respiratory tract based on analyses of 370 bronchoalveolar lavage fluid, nasal swabs, and nasal wash samples (Figures 6L-O and S23E-I) .RBD antibody DH1046, a weaker neutralizing Ab compared to DH1041, DH1043 or DH1047 (Figure 2A) , 372 did not enhance sgRNA E or N in BAL or nasal swab samples (Figures 6L-O and S23E-I) , but protected only a 373 subset of infused monkeys. Three monkeys treated with RBD antibody DH1046 exhibited the same or lower levels 374 of lung inflammation compared to monkeys that received control IgG (Figure 6J) . Two DH1046-infused monkeys 375 had increased lung inflammation scores of 8 and 10 due to increased total areas of inflammation compared to 376 control antibody monkeys (Figures 6J, S24 and S25) , but had no evidence of perivascular or alveolar edema nor 377 evidence of abnormal BAL cytokines (Figures S26 and S27) . Thus, these two animals had more lung involved 378 with inflammatory macrophage infiltration but did not have pathological evidence of vascular leakage. 379Comparing the DH1046 group to the control IgG group, viral nucleocapsid antigen in the lung was reduced 380 (Figures 6K, S24 and S25A ) . Cross-blocking activity of RBD and NTD neutralizing antibodies tested by surface plasmon resonance (SPR). Soluble, stabilized SARS-CoV-2 S trimer (S-2P) was captured by the antibody on the Y-axis followed by binding by the antibody on the X-axis. Antibody binding was considered competitive (red squares) if the binding antibody did not react with the captured S protein.(B) 3D reconstruction of simultaneous recognition of SARS-CoV-2 S-2P trimer by two RBD antibodies DH1041+DH1047, or DH1043+DH1047. All three antibodies are SARS-CoV-2 infection-enhancing in ACE2-negative/FcγR-positive cells, but neutralizing in ACE2positive/FcγR-negative cells. (C) Cross-blocking activity of neutralizing antibodies and infection-enhancing NTD antibodies tested by SPR. SARS-CoV-2 S-2P trimer was captured by the antibody on the Y-axis followed by binding by the antibody on the X-axis. Antibody binding was considered competitive (red squares) if the binding antibody did not react with the captured S protein. ",USA,first author,2021-02-18,02
fb86372381380562b2be4c7007240895648a1564,Differential roles of RIG-I -like receptors in SARS-CoV-2 infection,"Coronaviruses (CoV) are enveloped, positive sense single-stranded RNA viruses with the largest genomes (~30kb) among the known RNA viruses 1 When invaded by a virus, a host cell produces a rapid innate immune response initiated by pathogen pattern recognition receptors (PRR), including C-type lectins, Toll-like receptors (TLR), retinoic acid-inducible gene I (RIG-I) like receptors (RLR), the cyclic GMP-AMP (cGAMP) synthase (cGAS), and nucleotide-binding oligomerization domain (NOD)-like receptors (NLR) etc. Once engaged by viral RNA, the cytoplasmic RLRs translocate and bind to a mitochondrion transmembrane protein, mitochondrial antiviral signaling protein (MAVS), which ignites a signaling event, leading to transcription of immune genes, in particular interferons (IFN) that provide an instant protection to the host 5 . The relative contribution of different classes of PRRs to innate antiviral immune responses may vary with viral species and tissue cell types. The cytoplasmic RLRs (RIG-I and melanoma differentiation-associated protein 5, MDA5) are the essential PRRs to control RNA virus infection, while they show differential preference to different RNA viruses 6 . MDA5 is essential for induction of the type I/III IFN response during mouse hepatitis virus (MHV), a murine coronavirus, infection in mice 7, 8 ; while both RIG-I and MDA5contribute to the type I IFN response in oligodendrocytes during MHV infection 9 . Little is known about the differential role of RLRs in SARS-CoV infection, although they can be hijacked by SARS-CoV proteins to evade host immune responses 10 11 .We investigated the differential role of RIG-I and MDA5 in controlling SARS-CoV-2 infection and mounting immune responses in a human lung epithelial cell lines Calu-3. We generated individual RIG-I, MDA5 and MAVS knockout using CRISPR-Cas9 and validated by immunoblotting (Fig.1a) . To prove that these gene function was precisely silenced, we infected mutant cells with vesicular stomatitis virus (VSV specifically activates RIG-I-MAVS) with an green fluorescence protein (GFP) integrated into its genome. As expected, RIG-I -/or MAVS -/cells presented a much higher VSV-GFP load than wild type (WT) cells, while MDA5 -/cells had a similar viral load as WT (Fig.1b) . These results demonstrate precise disruption of each gene function of interest by CRSIPR-Cas9. We then compared SARS-CoV-2 infection and interferon responses in these knockout cells in parallel. The intracellular viral RNA load was increased by ~2-3.5-fold in all knockout cells at 24hrs post infection (p.i.), by 5-12-fold at 72hrs p.i. (Fig.2a) .Consistently the extracellular viral titers were also much higher from all knockout cells than WT ( Fig.2b) . We confirmed these observations in A549 cells (Fig.2c) . Although primarily sensing DNA viruses, the cGAS-STING signaling pathway also restricts many RNA virus infection 12, 13 .We noted a slight increase in SARS-CoV-2 load in STING -/cells ( Fig.2 d, e) , suggesting that STING signaling is largely dispensable. So was one of interferon-stimulated gene (ISG15) (Fig.3a) . The concentrations of IFN-β and C-X-C motif chemokine ligand 10 (CXCL10) proteins in the cell culture supernatants from MDA5 -/and MAVS -/were much lower than WT cells (Fig.3b) . However, the type I/III IFN and ISG15 expression was higher in RIG-I -/than WT cells (Fig.3a) , suggesting that RIG-I interferes with SARS-CoV-2 replication independently of IFNs. Of note, the angiotensin-converting enzyme 2 (ACE2, a major cell entry receptor for SARS-CoV-2) mRNA expression was continuously upregulated during the course of infection in WT cells, and it was ~2.5-fold higher in RIG-I -/than that in WT other knockout cells (Fig.3c) , suggesting that RIG-I represses ACE2 mRNA expression. Thus, herein we only focused on RLRs in lung epithelial cells. Our results demonstrate that MDA5 is the predominant RLR, because MDA5 deficiency led to a similar effect on viral replication and type I/III IFNs as MAVS deletion did (Fig.2, 3) . However, in neither MDA5 nor MAVS knockout cells, induction of IFNs was completely abolished (Fig.3) , suggesting that other PRR signaling pathways may collectively play a role. Surprisingly, RIG-I deletion had no negative impact on induction of IFN responses by SARS-CoV-2, but still increased viral replication (Fig.2, 3) , suggesting that RIG-I plays a MAVS-IFN-independent antiviral role. Of Sendai, influenza A, and human parainfluenza 3 viruses) 18 . During the submission of this manuscript, a study showed an important anti-SARS-CoV-2 role of MDA5 that is consistent with our results, however dispensable function of RIG-I in limiting SARS-CoV-2 infection 19 . This discrepancy could be due to a difference in the cell line and gene knockout method. The rabbit anti-MDA5 (Cat# 5321) SARS-CoV-2/VSV-GFP was added to cells at a multiplicity of infectivity (MOI) of 0.5 respectively, and incubated at 37°C, 5% CO2 for 1-2hrs. The viral inoculum was then removed completely, and replaced by fresh culture medium. The cells and medium were collected immediately (1hr or 2hrs as a baseline), or 24-72hrs after inoculation.A gene specific guide RNA was cloned into lentiCRISPR-V2 vector and co-transfected into HEK293T cells with the packaging plasmids pVSV-G and psPAX2. Forty-eight hours after transfection, the lentiviral particles in the cell culture media were applied to A549 or Calu-3 cells for 48 hours. The transduced cells were then selected with puromycin at 2μg/ml for 4-5 days until non-transfected control cells completely died. The guide RNA for human RIG-I, MDA5 and MAVS was TCCTGAGCTACATGGCCCCC, CTTTCTGCCTGCAGAGGTGA, and AAGTTACCCCATGCCTGTCC respectively 23, 24 . The wild type control was lentiCRISPRv2 vector only.Quantification of infectious viral particles in cell culture supernatant was performed on Vero cell monolayer 25 . Briefly, serial dilutions of supernatants was applied to confluent Vero cells (6-well plate) at 37 °C for 2 h. The inoculum was then removed and replaced with 2 ml of DMEM complete medium with 1% SeaPlaque agarose (Cat# 50100, Lonza). Plaques were visualized using Neutral red (Sigma-Aldrich) after 3 days of incubation at 37 °C, 5% CO2.Up to 1 × 10 6 culture cells were collected in 350 µl of RLT buffer (QIAGEN RNeasy Mini Kit).RNA was extracted following the QIAGEN RNeasy manufacturer's instructions. Reverse transcription of RNA into complementary DNA (cDNA) was performed using the BIO-RAD iScript™ cDNA Synthesis Kit. Quantitative PCR (qPCR) was performed with gene-specific primers and SYBR Green PCR master mix. Results were calculated using the -ΔΔCt method and a housekeeping gene, beta actin, as an internal control. The qPCR primers and probes for immune genes were reported in our previous studies 24 . The primers for SARS-CoV-2 were forward: 5'-GAC CCC AAA ATC AGC GAA AT-3' and reverse: 5'-TCT GGT TAC TGC CAG TTG AAT CTG-3'.We used a LEGENDPlex (Biolegend, San Diego, CA 92121, USA) bead-based immunoassay to quantify the cytokine concentrations in the cell culture supernatant of SARS-CoV-2 infected cells. The procedures were exactly the same as in the product manual. Briefly, the supernatants or standards were mixed with antibody-coated microbeads in a filter-bottom microplate, and incubated at room temperature for 2hrs with vigorous shaking at 500 rpm. After removal of unbound analytes and two washes, 25 µL of detection antibodies were added to each well, and the plate was incubated at room temperature for 1hr with vigorous shaking at 500 rpm. 25 µL of SA-PE reagent was then added directly to each well, and the plate was incubated at room temperature for 30min with vigorous shaking at 500 rpm. The beads were washed twice with wash buffer, and then transferred to a microfuge tube. The beads were fixed with 4% PFA for 15min and resuspended in FACS buffer. The beads were run through a BIORAD ZE5 and the concentrations of analytes were calculated with the standards included using the LEGENDPlex software.",USA,first author,2021-02-11,02
5a2fb4d55819169c3043c5ad9964a9d8e2223659,"The drug war must end: The right to life, liberty and security of the person during the COVID-19 pandemic for people who use drugs","Since 2016, the start of the synthetic opioid epidemic, we at the Vancouver Area Network of Drug Users (VANDU), the longest running harm reduction and peer-run drug user advocacy group in North America, have lost countless leaders in our community in the war on drugs [1] . Vancouver's Downtown Eastside community has produced the founding of the Western Aboriginal Harm Reduction Society (WAHRS), the British Columbia Association People on Opiate Maintenance (BCAPOM), and the SALOME-NAOMI Association of Patients. These are powerful examples of leadership in the civil rights of drug users and would not have been possible without the tireless activism of our comrades and friends who lost their lives too soon [2, 3] .We at VANDU, WAHRS, and BCAPOM are alarmed at the B.C. and Federal government's inaction on the increasing mortality of our members and of drug users throughout Canada. Overdose cases in B.C. linked to powerful synthetic opioids have spiked dramatically during pandemic conditions; this despite several novel Open Access *Correspondence: eja2@sfu.ca 5 UBC Faculty of Dentistry|Nobel Biocare Oral Health Centre, 2151 Wesbrook Mall, Vancouver, BC V6T 1Z3, Canada Full list of author information is available at the end of the article announcements by the provincial government to provide an alternative, pharmaceutical, supply for drug users asked to self-isolate due to the COVID-19 pandemic [4] . These strategies [5] -permitting physicians to prescribe other substituting therapies (such as hydromorphone and dextroamphetamine)-have not been successful in reducing the overdose mortalities in the Province of B.C., as the latest figures show an average of over 5 deaths per day linked to drug overdoses [4] [5] [6] [7] . In reality, these efforts at creating alternative prescribing have yet to be implemented anywhere near consistently or on a scale that reflects the scale of the epidemic; particularly in rural or other parts of the province [8, 9] . The opioid crisis has deepened during the COVID-19 pandemic. Recent data from the B.C. Coroners Service reported a 116% increase in mortalities linked to toxic illegal drugs in October 2020 compared to October 2019 [4] . Government action to end the drug war is needed more than ever. In this 21st year of the twenty-first century we desperately need a national drug policy based on science and the lived experience of users.We therefore support the unanimous vote by Vancouver City Council in November to fully decriminalize small amounts of illegal drugs for personal use, and urge the federal government to approve their request, without delay or modification [10] . This vote follows the call by the Canadian Association of Chiefs of Police and the Toronto Board of Health, who also urged Ottawa to decriminalize simple possession in June, 2020 [11] . We believe that Honorable Patty Hajdu, the federal Minister of Health, not only has the power to grant an exemption under the Controlled Drugs and Substances Act to allow decriminalization across Canada, but that she is morally obliged to do so immediately to protect the rights to life, liberty and security of person-Sect. 7 of The Canadian Charter of Rights and Freedoms-so that people who use drugs are given a chance to live.VANDU, WAHRS, and BCAPOM have been advocating for the full decriminalization of small possession for personal use for decades. While we in the drug users' liberation movement feel vindicated in seeing the government's long-overdue first steps towards decriminalization, we mourn for the lives of those who were needlessly lost in the drug war. We mourn, but we continue to organize. Decriminalization is just the beginning of our fight to live and flourish with dignity.",Canada,abstract,2021-02-17,02
79c46af53be255d5b7ed5def980c532c3ff3ad31,A comparative analysis of SARS-CoV-2 antivirals in human airway models 1 characterizes 3CL pro inhibitor PF-00835231 as a potential new treatment for 2 COVID-19 3 4,"One such alternate SARS-CoV-2 target is its main protease, 3CL pro (M pro ), which plays 77 an essential role in the viral life cycle: Upon entry and uncoating of the viral particles, the 78 positive-stranded RNA genome is rapidly translated into two polyproteins which are 79 subsequently processed into functional proteins by PL2 pro and 3CL pro viral proteases 4 . 80 3CL pro is the main protease and is responsible for releasing 11 of the 13 individual 81 proteins, including the polymerase subunits, enabling their proper folding and assembly 82 into the active polymerase complex 5 . Thus, blocking 3CL pro activity effectively shuts down 83 the life cycle before viral transcription or replication occur, making it an enticing target for 84 intervention 6 . In addition, 3CL pro has a unique substrate preference (Leu-Gln ¯ {Ser, Ala, To test PF-00835231 and remdesivir in an additional, more physiologically relevant, yet 258 lower-throughput human model system, we generated polarized human airway epithelial 259 cultures (HAEC). HAEC contain multiple cell types of the airway epithelium and 260 recapitulate its typical architecture (Fig. 5a-d) , which makes HAEC arguably one of the 261 most physiologically relevant models for in vitro studies of human respiratory pathogens. 262HAEC are permissive to SARS-CoV-2 infections and were utilized to obtain the very first has previously been associated with loss of polarized organization as a consequence of 271 remodeling 39 and is likely to occur at a low level at steady-state in HAEC. Recapitulation 272 of the major cell types and physiological conditions of the lung epithelium provided 273 molecular confirmation for the HAEC system in assessing SARS-CoV-2 infection. 274To establish the use of PF-00835231 in HAEC, we determined its cytotoxicity profile and 275 compared it to that of remdesivir. We added PF-00835231 or remdesivir to the basolateral 276 chamber of HAEC (Fig. 5a) , and determined tissue morphology by histology and integrity 277 of the epithelial layer by measuring trans-epithelial resistance (TEER; Fig. 5c -e). Neither 278 drug caused measurable adverse effects on the morphology of the cultures (Fig. 5c,d) . 279However, while remdesivir negatively impacted TEER over time, albeit not statistically significantly compared to untreated cultures, we did not observe this trend for PF-281 00835231 (Fig. 5e) . 282To complement our assessment of how well human epithelium tolerates these inhibitors, 283we took advantage of an alternative cytotoxicity assay on BCi-NS1.1 cells, the basal-like 284 undifferentiated precursor cell monolayers used for generation of HAEC. We treated 285 these monolayers with a dose range of PF-00835231 or remdesivir for 48 hours, and 286 quantified ATP as a measure of cell viability, similar to previous experiments with 287 A549 +ACE2 cells. We did not detect a decrease in ATP upon PF-00835231 treatment, even 288 at the highest amount of drug (10 µM) tested. In contrast, 10 µM of remdesivir caused a 289 reduction in ATP levels compared to carrier control, albeit not statistically significantly 290 (Fig. 5f) . These experiments demonstrate that both drugs are well-tolerated in our model 291 of polarized human airway epithelium. 292 293 PF-00835231 exhibits potent anti-SARS-CoV-2 activity in HAEC. To determine PF-294 00835231's anti-SARS-CoV-2 activity in HAEC, we added either 0.025, 0.5 or 10 µM PF-295 00835231 or remdesivir, or DMSO carrier control, to the basolateral chamber of HAEC 296 ( Fig. 6a-c) . We then challenged HAEC apically with SARS-CoV-2 USA-WA1/2020, and 297 determined viral infectious titers from apical washes collected at 12-hour increments. 298We first detected progeny viral particles in apical washes from DMSO-treated cultures at 299 12 hpi (Fig. 6a, b) , indicating that the SARS-CoV-2 life cycle in HAEC cells is completed 300 by that time. Both PF-00835231 and remdesivir potently inhibited SARS-CoV-2 titers in a 301 dose-dependent manner, with the 10 µM doses resulting in viral titers below the limit of 302 detection at most time points (Fig. 6a, b) . 303To visualize SARS-CoV-2 infection in HAEC during drug treatment, we fixed infected 304 HAEC at the 72 h endpoint and stained them for SARS-CoV-2-N-expressing cells (Fig.  305 6c). In carrier control cultures, we observed robust infection. Upon treatment with 10 µM 306 PF-00835231 or remdesivir, we found in both cases the number of infected cells 307 significantly reduced. Taken together, both remdesivir and PF-00835231 potently inhibit 308 SARS-CoV-2 infection in our model of polarized human airway epithelium. determining PF-00835231's in vitro efficacy was the action of the multi-drug efflux 313 transporter P-glycoprotein (also known as MDR1 or ABCB1). However, these earlier 314 studies were performed in the monkey kidney cell line Vero E6 9,14 . MDR1 was found to 315 efficiently export PF-00835231, thereby reducing intracellular PF-00835231 levels, and 316 likely underestimating PF-00835231's potency. In those studies, chemical inhibition of 317 MDR1 in Vero E6 cells significantly increased PF-00835231's antiviral efficacy 9,14 . 318Given the previously reported species differences in P-glycoprotein-mediated drug 319 transport activity of MDR1 and the variability in expression levels of the ABCB1 gene that 320 encodes this drug transporter among cell types and tissues 40 , we sought to determine a 321 potential role of MDR1 in our human in vitro airway models. We measured PF-00835231 322 anti-SARS-CoV-2 activity while chemically blocking MDR1 function, using the drug CP-323 100356 in the A549 +ACE2 cell line and in HAEC (Fig. 7a) . We observed no changes in 324 antiviral efficacy when blocking MDR1 activity ( Fig. 7b-d) , suggesting that, in contrast to 325Vero E6 cells, this transporter does not play a role in our human airway model systems. Thus, we conclude that MDR1 is unlikely to significantly impact PF-00835231 efficacy 359 during SARS-CoV-2 infection of the respiratory epithelium. In addition, our findings 360 highlight the importance of using appropriate in vitro models for the evaluation of antiviral 361drugs.The current public health emergency caused by COVID-19 has illustrated our dire need show that PF-00835231 has at least similar or better potency than the pre-clinical 3CL pro 374 inhibitor GC-376, or remdesivir. In HAEC, we find both remdesivir and PF-00835231 375 similarly potent. 376The lack of inhibitors specific to SARS-CoV-2 early in the pandemic prompted off-label 377 testing of protease inhibitors approved for other viruses, albeit with limited success 47 . This 378 failure highlighted the need for novel compounds of greater specificity. A number of 3CL pro 379 inhibitors have since been identified and characterized in in vitro assays, including the 380 cancer drug carmofur (1-hexylcarbamoyl-5-fluorouracil) 12 , an alpha-ketoamide inhibitor 381 named 13b 7 , and a dipeptide-based inhibitor named GC-376 48 . GC-376, licensed for 382 veterinary use 29 , was recently shown to inhibit SARS-CoV-2 in Vero E6 cells at an EC50 383 of 0.9 µM 11 . A different study showed PF-00835231 to inhibit SARS-CoV-2 at an EC50 of 384 0.27 µM in Vero E6 cells 9 . As such a comparison of historical data is problematic, we directly compared the antiviral efficacy of PF-00835231 and GC-376 side-by-side in the 386 same assay (Fig. 3) . We find that PF-00835231 is more potent that GC-376 in inhibiting 387PF-00835231 compared to other, preclinical, 3CL pro inhibitors, such as GC-376. 389In coronaviruses, the genetic barrier to standard-of-care remdesivir or the pre-clinical drug 390 ß-d-N4-hydroxycytidine is high, as mutations conferring resistance significantly reduce 391 viral fitness, and cross-resistance between remdesivir or ß-d-N4-hydroxycytidine has not 392 been documented 33,46 . A high resistance barrier to 3CL pro -targeting drugs due to a high 393 fitness cost has also been demonstrated for the beta-coronavirus murine hepatitis virus 394 (MHV) 49 P-glycoprotein (also known as MDR1, and encoded by gene ABCB1) 9 , is a membrane-419 associated ATP-dependent efflux pump capable of removing cytostatic drugs from target 420 cells. The endogenous function of this transporter remains to be fully elucidated, but it is 421 expressed across several immune cell types and other metabolically active cells. P-422 glycoprotein appears to be critical for maintenance and effector function of a range of 423 cytotoxic immune cells [56] [57] [58] [59] . Two recent studies suggested that PF-00835231 is a 424 substrate for P-glycoprotein. This might pose a concern regarding the bioavailability of 425 PF-00835231 in SARS-CoV-2-infected cells. We addressed this concern in two ways: and imaged using CellInsight CX7 LZR high-content screening platform. Images were 556 analyzed and quantified with HCS Navigator software. Syncytia were imaged using the 557Keyence BZ-X810 microscope at 60X magnification on A549 +ACE2 cultured on chambered 558 slides followed by 48 hpi SARS-CoV-2 infection and staining with SARS-CoV-2 N, 559AlexaFluor 647 secondary antibody, and DAPI. 560 561 SARS-CoV-2 growth kinetics on A549 +ACE2 cells. A549 +ACE2 cells were seeded into 6-562 cm dishes at 70% confluency. The next day, media was removed and cells were washed 563 twice with PBS with calcium and magnesium to remove residual medium. Cells were then 564 For additional determination of cytotoxicity in undifferentiated HAEC precursor cells, Bci-690 NS1.1 cells were seeded into opaque white wall 96-well plates. The following day, media 691 was removed, replaced with media containing compound/carrier or staurosporine, and 692 incubated for 24 or 48 hours, respectively. At these timepoints, ATP levels were 693 determined by CellTiter-Glo 2.0 (Promega, cat no. G9242) using a BioTek Synergy HTX 694 multi-mode reader. 695 ≥50% effect. Geometric means and 95% confidence intervals were generated in 766ActivityBase. Statistical comparisons were performed by log transforming the EC50 and 767 ",USA,first author,2021-02-19,02
4181f949294aac255207e985e92c03449789ef63,Impact of COVID-19 on Mental Health: A Longitudinal Study Using Penalized Logistic Regression,"Since the outbreak of the COVID-19 pandemic, people's life style has been changed significantly. Isolation and social distancing have been broadly implemented, and virtual social interactions have been encouraged. These changes have presented great challenges to people's work, study and living. Furthermore, they considerably affect people's psychological reactions to the disease, with more occurrence of emotional distress and social disorder during, and probably after, the outbreak. Despite these facts, no sufficient resources have been available to manage or attenuate the pandemic effects on mental health and well-being (Taylor, 2019) . Psychological reactions to the pandemic typically include maladaptive behaviours, emotional distress, and defensive responses (Taylor, 2019) . Individuals with psychological issues are especially vulnerable, and those who are unable to adjust to the new life style become prone to mental health issues.A number of studies have been conducted to investigate how the COVID-19 pandemic may affect people psychologically. Cao et al. (2020) conducted a survey on college students in China and showed that more than 24% of the students were experiencing anxiety. Moreover, living in urban areas, family income stability and living with parents are protective factors against anxiety, and having relatives or acquaintances infected with COVID-19 increases anxiety. Spoorthy et al. (2020) investigated the mental health problems faced by healthcare workers during the COVID-19 pandemic. Kang et al. (2020) conducted a cross-sectional study on 994 medical and nursing staffs in Wuhan, China. They found that 36.9% of the study subjects had subthreshold mental health disturbances, 34.4% had mild disturbances, 22.4% had moderate disturbances, and 6.2% had severe disturbances. Cai et al. (2020) carried out a cross-sectional observational study including doctors, nurses, hospital staffs throughout Hunan province of China between January and March 2020; they reported that the medical staffs experienced emotional stress during the COVID-19 pandemic.While those studies provided descriptive results by summarizing the information obtained from the questionnaire which are typically collected at a certain time point, important questions remain unanswered. Notably, it is unclear how the impact of COVID-19 changes over time; what factors are relevant to describe the impact of the pandemic; and how the severity 1 of the pandemic is quantitatively associated with the risk factors. In this paper, we examine these questions and aim to provide quantitative insights. Our explorations are carried out using a large scale online public survey database from U.S. Census Bureau. The data include twelve datasets with different sizes collected over 12 consecutive weeks from April 23, 2020 to July 21, 2020, in which the smallest dataset contains 41,996 subjects and the largest dataset has 132,961 individuals. The participants in the survey age from 18 to 88 and come from the 50 states and Washington, D.C. in the US. The survey includes multiple questions perceived to be relevant to understand the impact of the pandemic on the public. To quantitatively identify the risk factors for impacting the mental status by the pandemic, we engage penalized logistic regression, specifically with the least absolute shrinkage and selection operator (Lasso) method (Tibshirani, 1996) , to conduct simultaneous variable selection and parameter estimation. However, a direct application of the Lasso method is not possible for the data because they have missing observations with the rates ranging from 12.8% to 14.5% over the 12 weeks. To overcome this issue, we employ the multiple imputation by chained equations (MICE) (Raghunathan et al., 2001; Yu et al., 2007) to impute missing values. Further, survey data commonly involve measurement error due to recall bias, inability of providing precise descriptions of some answers, and reporting errors, it is imperative to address this issue when pre-processing the data. To this end, we combine the levels of those highly related categorical variables to mitigate the measurement error effects.The remainder of the manuscript is organized as follows. Section 2 introduces the data and describes how the data is pre-processed. Section 3 discusses the MICE method and reports the features of the resultant imputed data. In Section 4, the Lasso framework under logistic regression is introduced. In Section 5, we apply the Lasso logistic regression to analyze the pre-processed data and report the findings. Lastly, we conclude the paper with discussion in Section 6.The data used in this project are from phase 1 of the Household Pulse Survey, conducted within 12 weeks from April 23, 2020 to July 21, 2020 by the U.S. Census Bureau (https: //www.census.gov/). The survey aims to study the pandemic impacts on the households across the US from social and economic perspectives. The participants of the survey come from the 50 states and Washington, D.C. of the US, aging from 18 to 88. The gender ratio (the ratio of males to females) remains fairly stable ranging between 0.6 and 0.7 over the 12 weeks. Figure 1 displays the counts of the participants by the status of their states which are classified into four categories according to the severity of the pandemic: mild, moderate, large daily increase, and serious; such a classification is conducted based on the trend of the cumulative cases over time, as shown in Figure 2 which is generated by the data from the Centers for Disease Control and Prevention (https://data.cdc.gov/). The states whose curves of the number of cumulative cases are on the very top are classified in the class of serious. The states whose curves of the number of cumulative cases stay at the bottom are regarded as the mild pandemic states. In-between, the states with steep curves are taken to be in the class with large daily increases, and the states with less steep curves are regarded as the states with moderate daily increases. It is seen that the majority (72.5%) of the participants come from the states with mild pandemic and the least proportion (2.3%) of subjects are from the states with a serious pandemic. Table 1 lists the state members for each category.The survey is conducted on a weekly basis for 12 consecutive weeks, giving rise to 12 datasets each for a week. Missing observations and measurement error are typical features involved in the datasets. Before we conduct a formal analysis of the data, we implement a pre-processing procedure to mitigate the effects due to missingness and measurement error. In Section 3, we describe the steps of handling missing observations. Here we pre-process error-prone data to reduce the measurement error effects by combining questions to create new variables or by collapsing levels of variables to form binary variables.Four questions in the survey measure people's mental health status concerning four aspects: anxiety, worry, loss of interest, and feeling down. Each of them is a four-level Likert item (Joshi et al., 2015) measuring the frequency (1: Not at all; 2: Several days; 3: More than half the days; 4: Nearly every day) of each aspect happening during the past 7 days prior to the survey time. Using the middle point of those values as the threshold, we combine the four variables as a single binary response to reflect the mental health status of an individual. An individual is regarded to have mental health issues if the average of the four variables is greater than 2.5, and not otherwise.Two variables describe the loss of work: Wrkloss indicates whether an individual in the household experiences a loss of employment income since March 13, 2020; Expctloss indicates if the individual expects a member in the household to experience a loss of employment income in the next 4 weeks because of the COVID-19 pandemic. These two variables are combined to form a single indicator which is denoted Wrkloss, with value 1 indicating that at least one of these two events happens. Two ordinal variables, Prifoodsuf and Curfoodsuf, are used to describe the food sufficiency status before the pandemic and at present, respectively. The Foodcon.change variable is constructed by comparing the current and the previous food sufficiency status, which is a binary variable taking 1 if the current food sufficiency status is no worse than the food status before the pandemic, and 0 otherwise. Variable Med.delay.notget is combined from two indicator variables Delay (indicating if medical care is delayed) and Notget (indicating if the medical care is not received), taking value 1 if either medical care is delayed or no medical care is received, and 0 otherwise. Predictor Mort.prob is combined from one binary variable and an ordinal variable, taking 1 if a participant does not pay last month's rent or mortgage or does not have enough confidence in paying the next rent or mortgage on time, and 0 otherwise. In addition, three ordinal variables, Emppay, Healins and Schoolenroll, are modified by collapsing their levels to form binary categories. Emppay has value 1 if he/she gets paid for the time he/she is not working, and 0 otherwise. Healins has value 1 if an individual is currently covered by the health insurance, and 0 otherwise. Schoolenroll has value 1 if there is a child in the household enrolled in school, and 0 otherwise. Except for the variables discussed above, the remaining variables are kept as the original.The final data include the binary response (indicating the mental health status of an individual) and 25 predictors measuring various aspects of individuals. To be specific, nine predictors show basic information: State, Age, M ale, Rhispanic, Race, Educ, M aritalstatus, N umper (the number of people in the household), and N umkid (the number of people under 18 in the household); five varaibels concern the income and employment: Income, W rkloss, Anywork, Kindwork, and Emppay; five variables are related to food: F oodcon.change, F reef ood, T spndf ood, T spndprpd, and F oodconf ; three variables pertain to health and insurance: Hlthstatus, Healins, and M ed.delay.notget; one variable, M ort.prob, is for mortgage and housing; and two variables, Schoolenroll and T tch Hrs, reflect child education. The variable dictionary for the pre-processed data is shown in Table 2 . The presence of missing values in the dataset brings in a challenge for data analysis and model fitting. Leaving out the observations with missing features would not be the best strategy, and it would eliminate potential valuable information from the dataset or even yield biased results. A useful approach to handle missing observations in a complex dataset is multiple imputation by chained equations (MICE), which invokes fully conditional specification (FCS) under the assumption of the missing at random (MAR) mechanism. Each incomplete variable is imputed by its own imputation model which generates plausible values to replace the missing ones. MICE can be used for various types of variables with missing values, such as binary, continuous, nominal, and ordinal data. Technical details can be found in van Buuren et al. (2015) .Here we employ the MICE method to accommodate missing observations in the datasets. In each week, 5 distinct complete imputed datasets are created based on the original survey data by employing the same algorithm with different random seeds.To compare the 5 imputed datasets to the original data for each week, we take week 6 as an example and show the distributions of the imputed data for both categorical and continuous variables. The density plots for three continuous variables T spndf ood, T spndprpd and T tch hrs are shown in Figure 4 . The displays show that the distributions of the continuous variables in the imputed data are very similar to those in the original data. Three categorical variables Anywork, Kindwork and Income are selected as examples and their distributions are shown in Tables 3-5. Again, the proportions of different levels of each variable in five imputed datasets are fairly close to those in the original data.In this section, we employ the Lasso method to logistic regression to analyze the mental health data which contain a binary response and 25 predictors. For i = 1, ..., n, let Y i represent the binary response with value 1 indicating that the mental health problem occurs for subject i and 0 otherwise. Let X ij denote the jth covariate for subject i, where j = 1, ..., p, and p is the number of predictors. Write X i = (X i1 , X i2 , ..., X ip ) T and let π i = P (Y i = 1|X i ). Consider the logistic regression modelwhere β = (β 0 , β 1 , ..., β p ) T denotes the vector of regression parameters. The odds of the occurrence of mental health problems is defined by the ratio of the probability of having mental health problem happening to that of not having mental health issues i.e., π i 1−π i . The log-likelihood function for β is given bywhere λ is the tuning parameter that controls the complexity of the model; variable selection is realized by tuning the value of λ. A proper value of the tuning parameter λ is data-driven and can be chosen by K-fold cross-validation, with K being user specified. In our analysis below, K is chosen as 10. We use the ""one-standard-error "" rule (Hastie et al., 2009, p. 60) to pick the most parsimonious model within one standard error of the minimum cross-validation misclassification rate. This rule was also used by other authors, such as Krstajic et al. (2014) .Each of the five imputed datasets obtained in Section 3.2 is considered as a complete surrogate of the original incomplete data. Now we apply the Lasso logistic regression to each imputed data for each week. The predictors corresponding to the nonzero coefficient estimates are the factors selected, which are basically different across five surrogate datasets for each of the 12 weeks. To have explorations in a full spectrum, we start with two extreme models, called the full model by including the union of all those selected factors, and the reduced model by including only the common factors selected for all five surrogate datasets in any week. The full model includes all the 25 predictors in the original data, and the reduced model contains 11 predictors: Age, M ale, M S, N umkid, W rkloss, Anywork, F oodconf , Hlthstatus, Healins, M ed.delay.notget, and M ort.prob. We expect the predictors in the final model to form a set in-between the sets of the predictors for the reduced model and the full model. Now, the problem is how to find the final model using the reduced and full models. To tackle this, we carry out the following steps.InStep 1, we fit logistic regression with predictors in the full model and in the reduced model, respectively, to each of the five surrogate datasets for each of the 12 weeks. In Step 2, the estimates and standard errors of the model coefficients for a given week are obtained using the algorithm described by Allison (2000) . To be specific, let M be the number of surrogate datasets for the original incomplete data, which is 5 in our analysis. Let β j be the jth component of the model parameter vector β. For k = 1, ..., M , letβ j (k) denote the estimate of the model parameter β j obtained from fitting the kth surrogate dataset in a week and let S (k) j be its associated standard error. DefinêandThenβ j is taken as the point estimate of β j , and se(β j ) is used as the associated standard error. The results of the full and reduced models for the 12 weeks are displayed in Tables 6  and 7 , respectively. InStep 3, we combine those 11 predictors in the reduced model with the five additional variables in the full model that are significant (under the significant level 0.05) in the analysis fromStep 2 for at least 6 weeks' data, which are State, Rhispanic, Race, N umper, and Schoolenroll.InStep 4, we construct the final model by using the model form (1) to include the selected variables in Step 3 as predictors. To do so, we re-express discrete variables with multiple categories using dummy variables. State, Race, M S, F oodconf , and Hlthstatus are expressed using 3, 3, 4, 3, 4 dummy variables, respectively. That is, the final model is given bywhere β j is the regression coefficients for j = 0, 1, ..., 28. Then, we fit the final logistic model (6) to the surrogate datasets for each of the 12 weeks. Using the algorithm of Allison (2000) again, we obtain the point estimates of the model parameters and the associated standard errors in the same manner as indicated by (4) and (5). The results are reported in Table 8 .For intuitive visualization, we plot the estimates for the significant coefficients for the 12 weeks in Figure 5 . It is seen that the absolute value of coefficient estimates for some levels of variables Hlthstatus and F oodconf are greater than 1. The coefficient estimates of M ed.delay.notget along 12 weeks are between 0.5 and 1. Other variables have coefficient estimates between -0.5 and 0.5. Next, we interpret the average effects of the predictors for the 12 weeks. We first look at the estimate results for State. Considering the States with large daily increases of cases as the baseline and on the average of 12 weeks, people from mild pandemic States exhibit a 13.01% decrease in the odds of having mental issues; people from the States with small daily increases show a 5.17% decrease in the odds; people from serious pandemic States are generally associated with a 3.80% decrease in the odds. It is worthwhile to point out that the coefficient estimates for State.mild have a decreasing trend along 12 weeks (shown in Figure 5 ), with the absolute values increase. This indicates that the pandemic effect on the mental health problems in the States with mild pandemic increase as time goes by.For variable Race, considering the White people as the baseline, the Black and the Asian tend to have less odds of getting mental health problems. The 12-week mean of coefficient estimates for the Black and the Asian are -0.4464 and -0.2620, respectively, yielding that the odds of occurrence of mental health issues for the Black and the Asian are 1−exp(−0.4464) ≈ 36% and 1 − exp(−0.2620) ≈ 23.05% less relative to the White people.For M S (Marital status), considering now married as the baseline, the results suggest that people who are widowed, divorced, separated, or never married are associated with a 22.90%, 26.63%, 27.39%, and 19.85% increase in the odds of having mental issues, respectively, relative to the people who are now married.For predictors N umper and N umkid, the results show that the increase of the number of people and kids in the household is associated with the decrease of the odds of having mental issues. Specifically, one person increase in the household is associated with 2.36% decrease in odds, and one more kid in the household is associated with 10.03% decrease in the odds.For the work-related factors W rkloss and Anywork, the results indicate that experiencing a loss of employment income since March 13, 2020 is associated with a 42.16% increase in the odds of having mental issues, and doing any work during the last 7 days is associated with a 13.19% decrease in the odds.The results of F oodconf show that an increase in the confidence of food affordability is negatively associated with the odds of having mental issues. On average of 12 weeks, the more confident in the food affordability, the less the odds of having mental issues. For example, people confident in the food affordability for the next four weeks demonstrate a 74.03% decrease in the odds of having mental issues.For Hlthstatus, using the health condition excellent as the baseline, the results say that the worse the self-evaluated health condition, the larger the odds of having mental issues. Considering the worst level of health condition poor as an example, people who think they are in poor health conditions have an odds of having mental issues 7.55 times higher than that of excellent people.The results for other health-related predictors, Healins and M ed.delay.notget, indicate that, on average of 12 weeks, people who are currently covered by health insurance are associated with a 7.95% decrease in the odds of mental issues occurrence, and people who are not get medical care or have delayed medical care are generally associated with a 98.18% increase in the odds.The estimates on M ort.prob and Schoolenroll, on average of 12 weeks show that people having rental or mortgage problems are associated with a 26.15% increase in the odds of having mental health problems, and that people whose household has kids enrolled in school are associated with a 11.53% increase in the odds of having mental issues.In summary, the factors associated with a reduction in the odds of having mental health problems are: States not having large daily increases of cases, the increase of age, being male, having a Hispanic, Latino or Spanish origin, being non-White, the increase in number of people or kids in the household, having job during the last 7 days, having confidence in the food affordability in the future, and being covered by insurance. The factors associated with the increase in the odds of getting mental issues are: not married, experiencing loss of job, poor self-evaluations on the health condition, having problems in getting medical care and mortgage, and having kids enrolled in school. Among all the predictors in the final model, State and M ale are two predictors having apparent trends along 12 weeks. Specifically, the effect of State decreases and the effect of gender increases over time.This paper quantitatively investigates the impact of the COVID-19 pandemic on the public mental health issues using the data in the United States for the period of April 23, 2020 -July 21, 2020. Multiple imputation and data pre-processing procedures are implemented to account for the effects due to missingness and the error-prone values in the original data. We employ the penalized logistic regression with the Lasso penalty to identify significant risk factors on mental health issues. Our analysis shows that health-related factors and confidence in the future food are important predictors related to the occurrence of mental health problems. The effects of most of the predictors are fairly stable along 12 weeks, except for States and age.While this study offers us quantitative evidence how the COVID-19 pandemic can psychologically challenge the public, several limitations need our future explorations. Firstly, the data used in this project are from an online survey studying how the coronavirus pandemic is impacting households across the US from social and economic perspectives. Thus, the data may not contain enough necessary factors related to mental health issues. Secondly, the interaction effects between the predictors are not considered in our analysis, so the capacity of the model may be somewhat limited. Lastly, while an imputation method is used to handle missing observations, due to the large proportion of missing values in the data, the analysis results incur extra variability induced from the additional data management procedure.The analysis here provides us evidence-based findings on the pandemic impact on the public mental health, which, in turn, offers us the guidance on the prevention of people from having negative emotions, such as depression, anxiety, and stress. Basically, it is very important to improve the welfare and take actions to ensure the public health care, for example, trying to improve the proportion of people covered by the insurance. Secondly, improving public confidence in future food conditions is also crucial. Lastly, actions and policies should be adopted to deal with the current low employment rate. In the end, more psychological counseling and psychotherapy services should be provided to the public to help them face the great change in the life because of the COVID-19 pandemic. Mort.prob Indicator variable indicating if there is any problem on rental or mortgage, including last month's rent or mortgage is not paid on time, or the participants do not have enough confidence that they will be able to pay their next month rent or mortgage on time. 1: yes; 2: no.Indicator variable indicating if there is any child in the household enrolled in the school. 1: yes; 2: no.Continuous variable indicating the hours that the household members spend on all teaching activities with children during the last 7 days.Week 5Week 6Week 7Week 8 Week 9Week 10Week 11Week 12 Week 10Week 11",Canada,first author,2021-02-25,02
442baf806e7bf2d6d7566b56d243767492bbbffe,Journal Pre-proof Nanoluciferase complementation-based bioreporter reveals the importance of N- linked glycosylation of SARS-CoV-2 Spike for viral entry,"As of December 22, 2020, there are globally over 75 million confirmed SARS-CoV-2 4 47 infections resulting in nearly 1.7 million deaths 5 and with no signs of the pandemic 48 ebbing in the near future, effective therapeutics and vaccines are desperately needed. 49Spike (S) protein that binds to the Angiotensin Converting Enzyme 2 (ACE2) cell 51 receptor and initiates fusion of the viral and cell membranes. This critical role in the 52 virus infection cycle has made the S protein the focus of therapeutic development 53including the identification of neutralizing antibodies 7 , peptide-based S protein binders 6 54 and small molecule inhibitors of proteases involved in S protein maturation 3 . Like many 55 enveloped virus surface proteins, S is heavily glycosylated and it is has been 56 speculated that these post-translational modifications could facilitate immune evasion or 57 perhaps play a fundamental role in the determination of virus tropism 6 . Interestingly, 58 two N-linked glycan modifications occur within the conserved Receptor Binding Domain 59 or RBD of the S protein. The RBD mediates the binding of the S protein to ACE2 7, 8 and 60while there have been a number of documented polymorphisms in the amino acid 61 sequence of the RBD from clinical isolates around the world 9 , these two glycosylation 62 sites are uniformly conserved. This suggested to us the possibility that glycosylation of 63 the RBD is important for its binding to the cellular ACE2 receptor or as suggested earlier 64 inhibits immune recognition. To test these ideas, we constructed a bioreporter to rapidly 65 assess the interactions between RBD variants and the ACE2 receptor. We took 66 advantage of the recently developed NanoLuc Binary Technology (NanoBiT) 10, 11 12 to 67 J o u r n a l P r e -p r o o f create a surrogate assay for virus:host cell interactions. Our bioreporter provides a 68 simple and rapid system to carry out a structure-function analysis of critical amino acids 69 in the RBD that modulate its interaction with ACE2, as well as screen potential inhibitors 70 of this host-virus interaction. We demonstrate that the two conserved N-glycan 71 modifications in RBD are required for efficient binding to ACE2 and infection with S 72 pseudotyped viruses. 73 74Several different reporter fragment complementation-based strategies have been 77 employed to interrogate protein-protein interactions 13 , including split-luciferase 78 schemes 14-16 17 . Conventional split-luciferase bioreporters can be limited in their 79 application due to their relatively large sizes, poor stability, and the short half-lives of 80 their catalyzed luminescent reactions. The recently reported Nanoluciferase (or 81 NanoLuc from Oplophorus gracilirostris) 18 does not possess these limitations, and a 82 NanoLuc-based fragment complementation system has been reported 10, 11 12 . Our 83 bioreporter employs NanoLuc fragments linked to RBD and ACE2 creating a bioreporter 84 that can rapidly and sensitively serve as a surrogate for virus:host cell interactions (Fig. 85 1A). Using published sequences and structural homology analysis 7, 8, 19, 20 , we designed 86 a SARS-CoV-2 RBD sequence spanning residues 331 to 524 of the S protein (194 87 amino acids; Fig. S1 ) for one component of the bioreporter. For the other component 88 we used the soluble ectodomain of ACE2 (residues 1 to 740) as this has been shown to 89 be sufficient to interact with RBD 21 . Since RBD is the smaller protein of the two partners 90 J o u r n a l P r e -p r o o f ACE2 residues 82-84 (amino acids NFS) into the human ACE2 (hACE2) sequence was 160 previously shown to strongly impair the hACE2-RBD interaction with SARS-CoV 1 . 161 Introduction of the NFS residues into SmBiT-ACE2 similarly impaired the SARS-CoV-2 162 ACE2-RBD bioreporter ( Fig. 2B-C, Fig. S4B ), suggesting these ACE2 residues 163 contribute to the species tropism of SARS-CoV-2. 164We next utilized previous mutational analyses with SARS-CoV RBD to guide our study 165 of the critical SARS-CoV-2 RBD residues mediating the ACE2 interaction 21 . SARS-CoV 166 RBD cysteine residues 348, 467 and 474 as well as the acidic residues E452 and D454, 167 were shown to be critical to this domain's interaction with ACE2 21 (Fig. 2D ). The 168 homologous residues in SARS-CoV-2 RBD (corresponding to C361, E465, D467, C480, 169 and C488) were mutated to alanine in the RBD-LgBiT construct in order to evaluate 170 their role in ACE2 association. Four of the mutations caused a major loss (>80%) of 171 luminescent signal produced by the bioreporter assay (C361A, D467A, C480A, and 172 C488A) -suggesting these residues in SARS-CoV2 RBD are critical for ACE2 173 interaction ( Fig. 2E-F, Fig. S4C ). On the other hand, the E465A mutation caused a 174 modest drop in signal, suggesting that this residue is less critical for SARS-CoV-2 in 175 mediating an interaction with ACE2 in comparison to 177 Since our bioreporter is sensitive to the initial point mutations we examined, we 178 expanded our mutational analyses to include other potential critical residues, based on 179 analysis of the 3D crystal structure of ACE2-RBD binding interface ( Fig. 3A-E) . We 180 used site directed mutagenesis to create an additional alanine mutations in RBD (Fig.  181 3F) and analyzes their impact on ACE2-RBD interactions ( Fig. 3G-H) . We 182 demonstrated 21 out of the 25 tested SARS-CoV-2 RBD mutations significantly reduced 183 binding to ACE2 (Fig. 3H ). To further illustrate the potential of the assay in a high-184 throughput screen, we analyzed its reproducibility in a 384 well plate assay (Fig. S6 ) 185 and found minimal variability. Collectively, these mutational analyses along with high 186 reproducibility of the assay demonstrate the bioreporter is a useful tool for high-187 throughput structure-function analysis of viral and host determinants of the ACE2-RBD 188 interaction. 189The SARS-CoV-2 bioreporter is sensitive to neutralizing antibodies 191Monoclonal antibodies targeting RBD are under consideration as SARS-CoV-2 192 therapeutics 25 . We screened 13 different commercially available monoclonal CoV-2 Spike RBD antibodies with the SARS-CoV-2 bioreporter (Fig. 4A ). Seven of 194 these antibodies 1414, 40592, 9A9C9, 5B7d7, 11D5D3, 6D11F2, 10G6H5) are reported 195 to not only bind RBD but also neutralize infection of cells with an S pseudotyped 196 lentivirus. Interestingly these seven monoclonal antibodies were the most effective at 197 blocking RBD-ACE2 interactions measured with the SARS-CoV-2 bioreporter. We 198 applied the antibody collection to the SARS-CoV-1 bioreporter and found that while 199 most SARS-CoV-2 antibodies did not cross-react, antibodies 5B7d7 and11D5D3 200 showed some ability to disrupt RBD-ACE2 interactions for both virus strains. Non-201 specific mouse IgG and monoclonal antibody 1A9, which binds to the S2 subdomain of 202 the Spike protein, did not disrupt the signal generated by the SARS-CoV-2 bioreporter 203 supporting the specificity of the signals were observed. We tested our bioreporters with 204 serum from two patients recovered from SARS-CoV-2 infections at the Ottawa Hospital 205 and pooled serum from three healthy volunteers (Fig. 4B ). In these experiments, we 206 compared our SARS-CoV-2 bioreporter to a widely used, commercially available ELISA 207 kit that is designed to act as surrogate for virus neutralization (Fig. 4C) 26 . For the 208 bioreporter experiments, SARS-CoV-2 RBD-LgBiT was co-incubated with sera for 25 209 min, followed by the addition of SmBiT-ACE2 for an additional five minutes. At this 210 point, substrate was added and luminescence measured. The bioreporter was able to 211 distinguish seroconverters from healthy donors as both convalescent patients' sera 212 significantly reduce the bioreporter signal ( however, the NanoBiT assay is a more rapid (25 minutes compared to over 1.5 hours 218for the ELISA-based assay) and more accessible, in terms of cost and technical 219 feasibility. 220 SARS-CoV-2 genome sequencing has revealed the emergence of RBD 221 mutations in global strains. We investigated the influence of six emerging RBD 222 mutations found in SARS-CoV-2 genome sequences worldwide on the ACE2-RBD 223 interaction: V367F (France and Hong Kong/China), N354D (China), A435S (Finland), 224 F342L (England), K458R and V483R (United States) 27 (Fig. 4D ). The bioreporter assay 225 revealed that these SARS-CoV-2 variants displayed variable binding to ACE2 (Fig. 4E -226 F). Interestingly, the V367F mutant displayed over 3-fold enhanced interaction with 227 ACE2, while the F342L mutation decreased reporter activity 2-fold. The enhanced 228 J o u r n a l P r e -p r o o f affinity of V367F RBD mutation to ACE2 is consistent with a recent study describing 229 enhanced viral entry in HEK293T-ACE2/TMPRSS2 cells with lentivirus pseudotyped 230 with V367F Spike compared to wildtype Spike 9 . Similarly, these mutations also have 231 the potential to impact the efficacy of RBD-targeted monoclonal antibodies and 232 vaccination strategies. We analyzed the cross-reactivity of two SARS-CoV-2 RBD-233 targeted monoclonal antibodies towards the different RBD variants using the bioreporter 234 assay ( Fig. 4G-H) . Our results demonstrated that both monoclonal antibodies tested 235 could effectively block all the mutants' interactions with ACE2 -highlighting that specific 236 monoclonal RBD antibodies have the potential to work effectively against multiple 237 circulating SARS-CoV-2 strains encoding the different RBD variants. 238We found that bacterially produced recombinant SARS-CoV-2 RBD was not able to 241 block SmBiT-ACE2's interaction with SARS-CoV-2 RBD-LgBiT (Fig. S5A ), in contrast to 242 our results with recombinant RBD produced in mammalian cells (Fig. 1G ). An important 243 distinction with bacterial expression systems is their inability to produce mammalian-244 type glycosylation, suggesting a potential role for protein glycosylation in the ACE2-RBD 245 interaction. As discussed earlier, a recent study demonstrated that the spike protein We then used site-directed mutagenesis to create full-length Spike mutants (N331A and 281 N343A) and used these to create S pseudotyped lentiviruses. Consistent with our 282 SARS-CoV-2-NanoBiT data (Fig. 5E ), both mutations produced significant decreases in 283 S pseudotyped lentivirus infectivity (Fig. 5G, Fig. S5F -G). Overall, these data provide 284 direct evidence that SARS-CoV-2 S depends on N-linked glycosylation of RBD to 285 mediate its interaction with the ACE2 ectodomain. 286SARS-CoV-2 S is glycosylated with oligomannose-and complex-type glycans 6 . We 289 sought to examine the therapeutic potential of targeting these N-linked glycans by 290 testing mannose-binding plant lectins for anti-viral effects. We screened lectins from 291Canavalia ensiformis (jack bean), Pisum sativum (pea), Galanthus nivalis (snow drop), 292Datura stramonium (jimson weed/thorn apple), Musa acuminata (banana), and Lens 293 culinaris (lentil) for their ability to disrupt the SARS-CoV-2 RBD-ACE2 interaction using 294 our bioreporter ( Fig. 5H; Fig. S5H ). Our results demonstrate a diverse range of antiviral 295 effects. While the lentil lectin displayed no significant inhibition of the interaction across 296 the tested concentration range (8-1000 ng/µL), other lectins showed some efficacy, with We sought to examine the possibility that deglycosylation of Spike/RBD was disrupting 311 protein conformation. To investigate this, we also analyzed cell surface RBD 312 expression of the Spike glycosite mutant (N331A/N343A). In our models, we observed 313 no major differences in cell surface expression of the Spike N331A/N343A double 314 mutant relative to the wildtype protein, using either immunofluorescence or flow 315 cytometric analyses ( Fig. 6A-B) . Further, Native-PAGE analyses revealed that the 316 Spike mutant retained its ability to trimerize (Fig.6C ). Taken together, these data 317 suggest the glycosite mutations do not cause major structural changes. Our data 318 cannot exclude, however, that minor conformation changes in the proximity of the RBD 319 glycosites result in a reduced ACE2 binding capacity. Similar to the wildtype construct, 320we demonstrated that the N331A/N343A RBD-TMD construct maintained its ability to 321 trimerize and localize to the cell surface as demonstrated by immunofluorescence ( Fig 7F) . However, the glycosidase-treated lysate was only recognized by the non-364 neutralizing antibody. This pointed towards the importance of N-linked glycosylation to 365 RBD antigenicity. Similar results were observed using sera from convalescent COVID-366 19 patients to perform dot blot analysis on N331A and N343A Spike mutants. While the 367 N331A mutation had minimal impact on sera binding, the N343A cause a major drop in 368 patient sera binding -suggesting an important role for N-linked glycosylation of Spike 369 N343 in the protein's antigenicity (Fig. S7E) . This was further supported by the fact that 370 recombinant RBD from bacteria, which are incapable of matching mammalian 371 glycosylation profile, was poorly recognized by 1414 and the mouse sera (Fig. 7G ). An Previous studies using split-luciferase reporters have examined viral protein 380 interactions 36, 37 , however we believe the data presented here is the first report of a 381 NanoLuc complementation reporter-based assay to probe virus binding to host receptor 382 ACE2. While the RBD in our bioreporter may not capture trimerization-related and full 383 length-Spike epitopes, we have validated the system's ability to successfully test 384 potential therapeutics, including monoclonal antibodies and receptor decoys. The 385 bioreporter also enabled the evaluation of emerging RBD mutations on SARS-COV-2 386 infectivity and monoclonal antibody efficacy. This represents a valuable application as 387 we begin to identify the novel emerging SARS-CoV-2 spike mutants in the global 388Our observation that monoclonal RBD antibodies have conserved efficacy against 391 various RBD variants suggests that vaccines capable of inducing a strong neutralizing 392 antibody response against SARS-COV-2 RBD should display strong cross-reactive 393 efficacy in the global population. Although it has been speculated that glycan clusters on 394 the Spike protein could impede immune recognition or antibody activity, our bioreporter 395 data suggests that, for SARS-CoV-2 Spike RBD, this may not be the primary role of 396 glycosylation. Indeed, given the strong conservation of these glycosylation sites in 397 clinical isolates around the world we believe that appropriate glycosylation at N331 and 398 N343 could provide a conserved target for vaccine development. 399We believe that our data provides direct evidence demonstrating that N-linked 400 glycosylation of SARS-CoV-2 RBD is an important mediator of ACE2 binding. This is Lectins or another carbohydrate binding agent may similarly act as a lead candidate to 412 enable the development of a SARS-CoV-2 spike glycan-targeted lectin. Alternatively, 413 our finding that glycosylation is essential for RBD binding to ACE2 suggests that it may 414 be possible to use specific glycosylation inhibitors as an antiviral approach to blunt 415 SARS-CoV-2 infections especially if given acutely in a locoregional fashion. For 416 example, iminosugars that disrupt appropriate processing of N-linked glycan groups 417have been shown to act as broad-spectrum antivirals against viruses which dependent 418 on one N-linked glycan on a glycoprotein for infectivity 43 . Our results are consistent 419 with a recent study describing an important role for the N331 and N343 glycosites in 420 viral entry 39 . 421Previous studies have highlighted the importance of glycosylation on viral 422 antigenicity. In fact, several HIV neutralizing antibodies have been shown to be glycan-423 dependent, with viral escape associated with deletion of a glycan 44, 45 . Our study 424 establishes a similar role for N-linked glycosylation in the antigenicity of RBD (Fig. 7E-425 G). Specifically, our data suggests that the N343 glycan regulates epitope recognition 426 of several RBD-targeted neutralizing antibodies. This is also consistent with a recent 427 reports describing potent neutralizing antibodies forming directed interactions with the 428 N343 glycan 46 . 429Whereas several other SARS-CoV-2 regions are less conserved, the RBD 431 glycopeptide is highly conserved and represents a prime immunogen to drive 432 neutralizing antibody responses. Our study illustrates that the immunogenicity of RBD 433 is strongly influenced by N-linked glycosylation (Fig. 7A-D) . Mutational analyses 434 revealed that the N343 glycan was critical for RBD's recognition by neutralizing 435 antibodies and, in the context of an RBD-targeted vaccine, the N343A mutation 436 significantly decreased the immunogenicity as measured by blunted induction of anti-437 RBD IgG and neutralizing antibodies (Fig. 7B-D) . These results suggest that a crucial 438 consideration for vaccines using RBD as an immunogen is the utilization of a production 439 system that will generate the proper glycosylation of RBD as this influences the efficacy 440 of the neutralizing antibody response. Inserts outlined in Table S1 were ordered from GenScript. Bioreporter subunits were 453 Center, Seattle, WA) 29 . For glycosite mutants, HDm-IDTSpike-fixK was mutated using 508QuikChange SDM kit (Stratagene) using the primers listed in Table S1 , as per 509 manufacturer's protocols. Briefly, HEK293 cells were co-transfected with HDM-510IDTSpike-fixK, pHAGE-CMV-Luc2-IRES-ZsGreen-W, and pSPAX2. 48 hours post-511 transfection, cell supernatants containing virus were collected and treated with either 512 PNGase F or EndoH for 1 hours. HEK293T-ACE2 cells were subsequently transduced 513 and transduction efficiency was assessed by luciferase assay using the Bright-Glo 514Luciferase Assay system (Promega) or fluorescence microscopy (EVOS Cell Imaging 515 System, Thermo Fisher). Where indicated, lentivirus titers were measured using Lenti-516 X GoStix Plus (Takara) as per manufacturer's protocols. For lectin inhibition assays, 517Spike pseudotyped lentivirus was co-incubated with lectins for 1 hour, and then 518 virus/lectin mixture was applied to HEK293-ACE2 cells as described above. 519 520Receptor-ligand binding ELISA was performed as per manufacturer's protocols 522 (GenScript L00847). 523 524All graphs and statistical analyses were generated using Excel or GraphPad Prism v.8. 526Means of two groups were compared using two-tailed unpaired Student's t-test. Means 527 of more than two groups were compared by one-way ANOVA with Dunnett's or Tukey's 528 multiple comparisons correction. Alpha levels for all tests were 0.05, with a 95% 529 confidence interval. Error was calculated as the standard deviation (SD). Measurements Inserts (See Table S1 for detailed sequences) were ordered from GenScript 541 (Piscataway, NJ, USA). SARS-CoV-2 RBD-TMD constructs were cloned into the 542VSV∆51 viruses expressing SARS-CoV-2 wildtype or mutant RBD-TMD were rescued 544 as previously described 48 . 545 546Female 6 week-old BALB/C mice (Charles River Laboratories, Malvern, PA) were 548 vaccinated intravenously with 1E7 PFU of VSV∆51 expressing RBD-TMD wildtype or 549 mutants (N331A or N343A). Mice sera was collected using saphenous vein bleeds at 550 days 7 and 14 post-inoculation using sera collection tubes. Blood was incubated on ice 551 for 30 min and then centrifuged to separate sera. LgBiT-YAP15 and 14-3-3-SmBiT plasmids were gifts from Dr. Yang (Queen's 623 Editing. Jean-Simon Diallo: Writing -Reviewing and Editing. John C. Bell -Supervision, 644 WT  C361A  K417A  V445A  G446D  Y449A  Y453A  L455A  F456A  E465A  D467A  Y473A  A475D  C480A  F486A  N487A  C488A  Y489A  Q493A  G496D  Q498A  P499A  T500D  N501A  G502D C361A  E417A  V445A  G446D  Y449A  Y453A  L455A  F456A  E466A  D467A  A475A  C480A  F886A  WT  N487A  C488A  Y489A  Q493A  G496D  Q498A  P499A  T500D  G502D  N501A  G502D WT Y473A ",Canada,first author,2021-02-10,02
9effc9675d36e7a8a6f22170eb004f460b9a6dd9,Acute kidney injury in patients with severe COVID-19 in Mexico,"a1111111111 a1111111111 a1111111111 a1111111111 a1111111111In December 2019, a series of pneumonia cases of unknown cause emerged in Wuhan, Hubei Province, China, with clinical presentations resembling viral pneumonia [1] . The pneumonia spread quickly to other provinces of China and overseas. A novel coronavirus was identified by the Chinese Center for Disease Control and Prevention from the throat swab sample of a patient and was provisionally named 2019-nCoV by the World Health Organization (WHO) [2] . Based on phylogeny, taxonomy and established practice, the International Committee on Taxonomy of Viruses renamed the virus as Severe acute respiratory syndrome coronavirus-2 (SARS-CoV-2) [3] . WHO subsequently declared coronavirus disease 2019 (COVID-19) a public health emergency of international concern [4] . COVID-19 is primarily manifested as a respiratory tract infection, but emerging data indicate that it should be regarded as a systemic disease involving multiple systems, including cardiovascular, respiratory, gastrointestinal, neurological, hematopoietic, immune and renal [5] [6] [7] [8] . Of note, after lung infection, the virus may enter the blood, accumulate in the kidney and cause damage to resident renal cells, with a significantly higher risk for in-hospital death [8] . Thus, understanding how the kidney is affected by SARS-CoV-2 is particularly relevant. The incidence of acute kidney injury (AKI) in hospitalized patients with COVID-19 varies across populations, but a large multicenter retrospective cohort study in New York reported AKI in 37% of hospitalized patients, and 35% of those died [9] . AKI initiation coincides with the development of Acute Respiratory Distress Syndrome (ARDS), and these alterations are typical of patients progressing to the most severe stage of illness involving extra-pulmonary systemic hyperinflammation [10] .The National Institute of Respiratory Diseases (INER) is the largest third-level national referral center for COVID-19 in Mexico City. Since early January 2020, this institution was gradually repurposed for the treatment of patients with COVID-19 exclusively. Since February 28, 2020, when the first Mexican patient was diagnosed with COVID-19, a high proportion of critically ill patients have been admitted at the INER. The aim of this study was to describe the factors associated with the development of AKI and explore the relation of AKI and mortality in the Mexican population with severe COVID-19.The study was conducted at the INER, the largest third-level institution designated by the Mexican Government for COVID-19 care. All medical records of individuals with severe pneumonia caused by SARS-CoV-2 hospitalized at the INER between March and April 2020 were retrospectively reviewed. The Institutional Review Board (Comité de Ética en Investigación and Comité de Investigación del INER) approved the study and waived the requirement for informed consent due to the retrospective design of the study . Data were fully anonymized before being accessed. We included individuals with diagnosis of severe pneumonia caused by SARS-CoV-2, confirmed by real-time reverse transcription-polymerase chain reaction (rRT-PCR); 18 years of age or older; with no history of chronic kidney disease (CKD), as indicated by kidney ultrasound and direct interrogation of patients about CKD medical history; and ratio of partial arterial oxygen pressure/inspired oxygen fraction (PaO 2 / FiO 2 ) <300 mm Hg on admission. Pregnant women were not included in the study. Patients with incomplete clinical records were excluded. Patients with SARS-CoV-2 severe pneumonia were defined as those with clinical data of respiratory distress, bilateral alveolar opacities in 2 or more lobes, a ratio of PaO 2 /FiO 2 < 300 mm Hg and a positive result for SARS-CoV-2-rRT-PCR assay [11] in nasopharyngeal swab. Prone ventilation was used for the treatment of ARDS as a strategy to improve oxygenation when traditional modes of ventilation failed.The primary outcome was the development of AKI. The secondary outcome was 30-day mortality in the group with AKI and the group without AKI. Recorded variables included demographic and anthropometric variables, symptoms, comorbidities, treatments, critical care variables, blood chemistry, blood count, initiation and termination dates of invasive mechanical ventilation (IMV), days in hospital, initial mechanical-ventilator settings, early use (in the first 24 hours after admission) of vasoactive drugs and outcomes.AKI staging was based on serum creatinine (sCr) levels. The urine output criterion was not used for diagnosis of AKI since nursing records were out of reach, in COVID-19 areas. The baseline sCr level was defined as the minimum inpatient value during the first 7 days of admission [12] . Diagnosis of AKI was based on the Kidney Disease Improving Global Outcomes (KDIGO) criteria [13] . AKI stage 1 corresponded to an increase in sCr by � 0.3 mg/dL within 48 hours or increase in sCr 1.5 to 1.9 times baseline within the prior 7 days; AKI stage 2 corresponded to an increase in sCr of 2.0-2.9 times baseline; and AKI stage 3 corresponded to an increase in sCr of �3 times baseline or initiation of renal replacement therapy (RRT).Patients with AKI underwent the furosemide stress test (FST) for prediction of AKI severity. They were euvolemic before undertaking the furosemide challenge. The test was performed by administrating 1 mg/kg of furosemide i.v. or 1.5 mg/kg if the patient had received furosemide within the preceding 7 days, followed by observation of the urinary output in the first 2 hours. The result was considered positive if the patient urinated more than 200 ml per hour, in the following 2 hours after furosemide administration [14] .We performed descriptive statistics including means and standard deviations for normally distributed continuous variables, medians and interquartile ranges for non-parametric distributions, and proportions for categorical variables. Comparisons of the AKI vs. the non-AKI groups were made using Fisher´s exact test for categorical variables and U Mann-Whitey for continuous variables. Comparisons across AKI stages were made using Kruskal-Wallis rank sum test. Logistic regression analysis was used to identify the association between relevant covariates with AKI and mortality. No violations of the assumptions were detected. The multivariate models were built using a stepwise procedure, and variables were entered into the models when the alpha level of risk factor was <0.15 in the univariate analysis. All statistical tests were two-sided, and a P value <0.05 was considered statistically significant.We also performed the Kaplan-Meier survival analyses for the time to death, comparing the group with AKI vs. the non-AKI group. Statistical analyses were performed using R version 3.6.3. Additionally, a Receiver Operating Characteristic (ROC) curve was constructed in order to define the optimal cut-off points of the variables for prediction to AKI stage 3. Sensitivity, specificity, and the area under the curve (AUC) were calculated with 95% confidence intervals and p values <0.05.During the period between March 1 st , 2020 and April 30, 2020, a total of 280 individuals were admitted at the INER due to suspected COVID-19. Of those, 12 died during the first 48 hours and 78 had a negative result for the SARS-CoV-2 rRT-PCR test. Therefore, we reviewed the clinical files of 190 individuals. Of those, 12 had pneumonia due to other causes; 19 were transferred to other hospitals due to local saturation; and 60 had incomplete clinical files. Thirty-six patients of the group with incomplete clinical files were not hospitalized because they had a ratio of PaO 2 /FiO 2 > 300 mm Hg, with acceptable metabolic control (glycemic, kidney and hepatic functions). Therefore, they were trained on the use of supplemental oxygen, the recognition of worsening symptoms, and were monitored from home. The clinical files of the remaining 24 patients were unavailable due to the accelerated reconversion of our institution for exclusive treatment of patients with COVID-19. From the electronic records, we confirmed that five of those patients died and none of them developed AKI during the observation period at hospital. We thus included 99 individuals in the study (Fig 1) .Of the 99 patients included, 74 were male (74.7%); the median age was 52.9 years (SD±13.27); 30 had hypertension (29.7%); 27 had diabetes (26.7%); and 56 had obesity (55.4%; Table 1 ). Fig 2) . In-hospital mortality was significantly higher in patients with AKI stage 3 (79.3%) and AKI stage 2 (68.7%) compared with those with AKI stage 1 (25%; p = 0.01). The body mass index (BMI) was significantly higher in the AKI group (31.1 kg/m 2 vs. 27.6 kg/m 2 in the non-AKI group; p = 0.01). Obesity was more frequent in the AKI group (28 patients, 50.9%) than in the non-AKI group (10 patients, 25.6%; p = 0.01). The median time to AKI development was 6.5 days (SD±8.33).Fifty-three patients underwent the furosemide stress test. Of those, 39 had a positive result (73.5%) and 14 had a negative result (26.4%). Of the 53 patients undergoing the FST, 12 progressed to AKI stage 3 (22%). The ROC curve for the FST had an AUC of 0.681 (95% confidence interval (CI) = 0.514-0.847, p = 0.009), with a sensitivity of 81.6% and a specificity of 54.5% (Fig 3) .A total of 11 patients (22.4%) required renal replacement therapy (RRT). Of those, 5 used continuous RRT, 3 used intermittent hemodialysis (IHD), and 3 used prolonged intermittent renal replacement therapies (PIRRT). The median time to RRT initiation after AKI initiation was 4.18 days (SD±3.8) and median time under RRT was 4.29 days (SD± 2.82). Five patients died after 30 days of follow-up, 2 of them had been discharged due to clinical improvement and 3 were hospitalized.Some inflammation markers were higher in the AKI group, including C-reactive protein: 19 .57 (±9.5) mg/dl in the AKI group vs. 15 Table 2 ). On admission, 82.8% had a positive result for SARS-CoV-2-rRT-PCR, but all patients had a positive result when the test was performed for the third time. Sixty-five patients (64.3%) required IMV. The median positive end-expiratory pressure (PEEP) level was 11.5 cm H 2 O (SD ±2.4); and 28 required prone ventilation due to refractory hypoxemia. Forty-nine patients The univariate analysis indicated that patients with AKI were older (unadjusted odds ratio (OR) = 1.05, 95% CI = 1.01-1.08, p = 0.007); had a higher BMI (OR = 1.10, CI = 1.02-1.18, p = 0.012); a higher frequency of obesity (OR = 2.59, 95% CI = 1.11-6.04, p = 0.028); a higher requirement of IMV (OR = 6.78, 95% CI = 2.69-17.04, p = 0.001); a higher requirement of vasoactive drugs (OR = 4.26, CI = 1.08-10.06, p = 0.001); a higher ratio of platelet/lymphocyte (OR = 1.0037, CI = 1.0005-1.0068, p = 0.021); a lower count of lymphocytes (OR = 0.23, CI = 0.08-0.67, p = 0.007); a higher level of C-reactive protein (OR = 1.05, CI = 1.01-1.1, p = 0.028); and a lower level of albumin (OR = 0.26, CI = 0.11-0.64, p = 0.003). After adjusting for possible confounding variables, the multivariate analysis indicated that the risk factors for AKI were older age (OR = 1.07, 95% CI = 1.01-1.13, p = 0.024); obesity (OR = 6.58, 95% CI = 1.8-24.05, p = 0.040); and requirement of IMV (OR = 6.18, CI = 1.29-29.58, p = 0.023, Table 3 ).Risk factors for mortality. The univariate analysis indicated that deceased patients had a higher BMI (OR = 1.14, 95% CI = 1.06-1.23, p = 0.001); a higher frequency of obesity (OR = 3.6, 95% CI = 1.56-8.32, p = 0.003); a higher requirement of IMV (OR = 7.47, IC = 2.71-20.57, p = 0.001) and of vasoactive drugs (OR = 7.18, IC = 2.95-17.46, p = 0.001); a higher level of C-reactive protein (OR = 1.06, CI = 1.02-1.11, p = 0.008); a lower level of albumin (OR = 0.25, IC = 0.1-0.62, p = 0.003); and a higher frequency of AKI (OR = 12.96; IC = 4.63-36.28, p = 0.001). After adjusting for possible confounding variables, the multivariate analysis indicated that the risk factors for mortality were obesity (OR = 5.57, 95% Table 4 ).Multiple organ involvement including the liver, gastrointestinal tract and kidney have been reported in patients with COVID-19 [8] . Since information about causes leading to severe kidney disease in these patients is still limited, here we determined the factors associated with the development of AKI and explored the relation between AKI and mortality in Mexican population with severe COVID-19. In our cohort of patients with severe COVID-19, the risk factors for AKI were older age, obesity and requirement of IMV on admission. The risk factors for mortality were obesity, requirement of vasoactive drugs on admission and AKI. Moreover, in-hospital mortality was particularly elevated in patients with AKI stages 2 and 3.In contrast with initial studies reporting low incidences of AKI between 5-7% in hospitalized patients with COVID-19 in China [8, 15, 16] , the incidence of AKI in our cohort was 58.6%, and half of those had severe AKI (stage 3). Differences between studies might be partially explained by the fact that our institution is a national referral center for respiratory diseases, where mostly patients with COVID-19 severe disease are being admitted. Our study population was similar to that studied in another Mexican, third-level, national referral center for patients with severe COVID-19, reporting an AKI incidence of 60.7% [17] ; and to the cohort studied in a New York City medical center, where up to 78% of the patients developed AKI and most of them required IMV [18] .As previously reported, we found that older age was a risk factor for AKI in hospitalized patients with COVID-19 [9] . Obesity was a risk factor for AKI and mortality in our cohort, and it has been reported as a common comorbidity in hospitalized patients with COVID-19 [19, 20] , and as a risk factor for hospital admission and need for critical care [21] . This is particularly relevant for countries with high obesity rates, such as Mexico. In the adult Mexican population, the combined prevalence of overweight and obesity is approximately 71% [22] . It has been suggested that chronic inflammation in obesity is apparent, with an increased level of interleukin-6, adipokines and pro-inflammatory cytokines (e.g., TNF-alpha, interferon), inducing a chronic low-grade inflammatory state and impairing immune response [23, 24] . A possible mechanism related to COVID-19 severity in obese persons is speculated to occur through a functional restrictive capacity of the obese lung. It would also be interesting to understand whether the obese patients had higher PEEP or driving pressure that could account for the higher risk for AKI. Unfortunately, PEEP data retrieval was incomplete in our retrospective review of medical records, so we were unable to perform this analysis. The need for mechanical ventilation on admission was also a risk factor for AKI in our cohort. It is well known that the main causes of AKI are hypoxia, ischemia and nephrotoxicity. The kidney is particularly susceptible to ischemia and toxins, resulting in vasoconstriction, endothelial damage, and activation of inflammatory processes [25] . In hospitalized patients with severe COVID-19, the important relationship between AKI and respiratory failure was previously reported [9] . The requirement of vasoactive drugs on admission was a risk factor for mortality in our cohort. This is not surprising if we consider that vasoactive drugs are used in the most critically ill patients with septic shock and evidence of renal dysfunction [26] . In this context, early start of vasopressor support is aimed at having a more rapid restoration of blood flow in combination with lower fluid accumulation, allowing early restitution of tissue perfusion while avoiding fluid overload-mediated harm [27] .We found that elevated serum creatinine on admission was more common in patients with AKI, which was previously reported in a cohort in China [8] . This means that patients with kidney involvement on admission were more likely to develop AKI. Lymphopenia was more common in the group with AKI, and low lymphocyte counts have been associated with severe COVID-19 and longer hospital stay [28] . COVID-19-associated lymphopenia might derive from retention of lymphocytes in the lung. Also, lymphocytes express the angiotensin-converting enzyme 2 (ACE2) receptor on their surface [29] . Thus, SARS-CoV-2 infection may directly induce lysis of these cells. In addition, elevated levels of pro-inflammatory cytokines, may promote lymphocyte apoptosis.D-dimer elevation on admission was more common in patients with AKI. This molecule is a product of cross-linked fibrin degradation and is a sensitive marker of thrombosis and coagulation activation [30] . Elevated D-dimer level has been consistently reported in patients with COVID-19 [31, 32] , and its gradual increase during disease course is particularly associated with disease worsening [33] . Elevated C-reactive protein on admission was more common in patients with AKI. Higher C-reactive protein has been linked to unfavorable aspects of COVID-19 disease, such as ARDS development [34] , higher troponin-T levels and myocardial injury [35] , and death [36] .Troponin levels on admission were higher in the group with AKI. High-sensitivity cardiac troponin T (hs-cTnT) and cardiac troponin I (cTnI) have been associated with AKI and are useful plasma biomarkers of cardiac injury [37] . In patients with severe COVID-19, elevated troponin level might indicate cardiovascular stress resulting from direct SARS-CoV-2 infection of the heart [38] , hemodynamic changes, or underlying cardiac injury and dysfunction [39] .The original study describing the furosemide stress test for prediction of AKI outcome reported an AUC of 0.87 in the first two hours, with a sensitivity of 87.1% and specificity of 84.1% [14] . That study was performed in a heterogeneous population of patients exposed to different nephrotoxic factors (nonsteroidal anti-inflammatory drugs, aminoglycosides, amphotericin, contrast, post-cardiac surgery and sepsis). We found lower values of AUC (0.681), sensitivity (81.6%) and specificity (54.5%). Differences between studies may be partially explained by the fact that we only included patients with sepsis related with SARS-CoV-2 infection. Despite these considerations, we deem that the furosemide stress test is an easy, non-invasive and accessible technique which may contribute to predict the severity of AKI in patients with SARS-CoV-2 infection. Larger, prospective validations of the furosemide stress test in patients with severe COVID-19 are required because improving risk prediction in those with early AKI would be of high value for patient care and clinical decision making.The main limitation of our study was its retrospective design. Also, the number of patients included in the study was low. Another study limitation was that patients with incomplete clinical files or those who were transferred to other hospitals due to local saturation were not included in the study, and this may represent a selection bias.Considering that standardized definitions of AKI are based on sCr and urine output [40] , then inaccessibility to nursing records restricted to COVID-19 areas represents an important study limitation because urine output was not used for diagnosis of AKI, and sCr was not adjusted for fluid-balance. The lack of pre-hospital baseline sCr measurements was also a study limitation because baseline sCr values were an estimation. Since we could not assess the baseline renal status, we could not explore whether CKD itself is a risk factor for AKI in the context of COVID-19. One additional study limitation is that we retrieved information during hospitalization, but a longer observation period would have provided additional information regarding the clinical outcome and the impact of AKI in the population studied. That is, we were not able to report the proportion of individuals developing CKD in the group with AKI. Finally, our study was conducted at a national referral center for respiratory diseases receiving disproportionately more patients with severe COVID-19, and this represents a potential source of referral bias. Nevertheless, this particular cohort was suitable for identifying the risk factors for AKI in Mexican individuals with severe COVID-19.AKI was common in our cohort of patients with severe pneumonia caused by SARS-CoV-2 infection. The risk factors for AKI were older age, obesity and requirement of IMV on admission. The risk factors for mortality were obesity, requirement of vasoactive drugs on admission and AKI. Mortality was more frequent in patients with AKI stages 2-3. The FST had an acceptable predictive capacity to identify patients progressing to AKI stage 3. Still, larger, prospective validations of the FST in patients with severe COVID-19 are required. Visualization: Claudia Alvarado-de la Barrera.Writing -review & editing: Claudia Alvarado-de la Barrera.",Mexico,abstract,2021-02-08,02
3c4c83bac41da84c77416f4a24791e6def038061,Journal Pre-proof Human neutralizing antibodies against SARS-CoV-2 require intact Fc effector functions for optimal therapeutic protection Human neutralizing antibodies against SARS-CoV-2 require intact Fc effector 1 functions for optimal therapeutic protection 2 3,"RNA was more focal in the lungs of mice receiving intact COV2-2050 at D+2 with evidence of 150 cleared regions and a smaller affected proportion (Fig 2H) . Additionally, K18-hACE2 mice 151 receiving intact COV2-2050 at D+2, but not COV2-2050 LALA-PG, showed functional 152 improvement in pulmonary mechanics (e.g., inspiratory capacity, resistance, and elastance), 153 and lung compliance and distensibility (Fig 2I-J) .To expand on these results, we tested the therapeutic activity of three additional neutralized SARS-CoV-2 equivalently compared to parental COV2-2072 human IgG1 mAb ( Fig  S1A) . As expected, mIgG1 and mIgG1 D265A bound mFcγRI or mFcγRIV poorly compared to 180 the mIgG2a (Fig S1B) . Notably, D+1 administration of COV2-2072 mIgG1 or COV2-2072 181 mIgG1 D265A failed to protect mice from weight loss. In contrast, COV2-2072 mIgG2a 182 prevented weight loss and reduced viral titers similarly to the human IgG1 form of COV2-2072 183 (Fig S1C-D) . These data establish the importance of Fc effector functions to antibody protection 184 when administered in a corresponding system with murine Fc regions and murine FcγRs. (Fig 5B) . A similar large number of DEGs was observed in the lungs at 8 dpi from 233 mice treated at D+2 with COV-2050 or COV2-2050 LALA-PG (Fig 5B) . Gene ontology analysis 5C, Table S2 ). Pathways unique to the COV2-2050 D+1 treatment group compared to the Prkca, and Cdc42bpa), processes that are typically associated with wound repair programs 247 (Verboon and Parkhurst, 2015) (Fig 5D) . Pathways downregulated in the COV2-2050 D+1 248 group included genes involved in type I IFN and NFκB-dependent signaling (e.g., Irf7, Stat2, 249 Nfkb2, Bst2, Isg15, and Ikbk3) (Fig 5D) , which may in part be due to the lower levels of viral 250 RNA detected (Fig 2E-F) . The expression pattern of down-or up-regulated gene sets in the 251 COV2-2050 D+1 treated animals was similar to that in naïve animals, suggesting that the intact 252 antibody limited the transcriptional changes usually seen during SARS-CoV-2 infection.Pathways that were downregulated in the D+2 COV2-2050-treated group compared to 254 the isotype control or D+2 COV2-2050 LALA-PG-treated animals included S100A8-associated 255 innate immune signaling (e.g., Reg3g, Saa3, Itgma, Mmp8, and S100a8), oncostatin M receptor 256 associated signaling (e.g., Il6, Osmr, Csf1, and Socs3), and extracellular matrix remodeling 257 (e.g., Adamts15, Col5a1, Vcam1, and Lama4) (Fig S5, Table S2 ). Thus, COV2-2050 treatment 258 at D+2 and the resultant Fc-dependent effector responses may differentially modulate neutrophil 259 activation, gp130 signaling, and tissue damage due to matrix metalloproteinase activation. ( Fig 6B and S6) , mature neutrophils (anti-Ly6G) (Fig 6C and S6 ) or CD8 + T cells (anti-CD8) 277 (Fig 6D and S6 ) in combination with COV2-2050 treatment at D+1. Depletion of mature 278 neutrophils, NK cells, or CD8 + T cells had no impact on weight loss in the presence of COV2-279 2050 or the isotype control mAb (Fig 6B-D) . When monocytes were depleted, COV2-2050 failed 280 to prevent the weight loss phenotype seen in non-depleted, COV2-2050-treated mice (Fig 6A) .Monocyte depletion during COV2-2050 therapy also was associated with a loss of improvement 282 in lung pathology (Fig 6E) and higher levels of some cytokines and chemokines (CXCL10, G-283 CSF, IL-6, IFN-γ, CCL2) compared to treatment with COV2-2050 without cell depletion (Fig 6F   284 and S7). As expected, the numbers of monocytes and CD11b + DCs in the lung were lower after 285 anti-CCR2 treatment but other cell subsets were unaffected. As these myeloid cells show a less 286 inflammatory phenotype after COV2-2050 but not COV2-2050 LALA-PG treatment (Fig 4G-H) ,FcγR engagement may shape cellular responses to limit immunopathology independently of 288 viral clearance.Although monocyte depletion in combination with COV2-2050 treatment resulted in 290 increased weight loss, it was not associated with changes in viral RNA levels at 8 dpi (Fig 6H) , Consistent with observations in mice, passive transfer of intact COV2-2050 prevented weight 307 loss compared to isotype mAb-treated animals at 5 and 6 dpi, and this protection was lost in 308 animals treated with the COV2-2050 LALA-PG variant (Fig 7A) . Furthermore, hamsters treated 309 with intact COV2-2050, but not COV2-2050 LALA-PG, showed reductions in viral RNA levels at 310 6 dpi (Fig 7B) . The improved viral burden with COV2-2050 was associated with lower levels of 311 the inflammatory mediators Cxcl10, Ccl2, Ccl3, Ccl5, and Ifit3 (Fig 7C) . Thus, therapeutic 312 efficacy following neutralizing mAb administration also depends on Fc interactions in a second, Neutralizing mAbs against SARS-CoV-2 are a promising option for the treatment of (Chen et al., 2020), and the FDA granted Emergency Use Authorization to the anti-SARS-CoV-2 321 S mAbs Bamlanivimab and Casirivimab/Imdevimab for mild-to-moderately ill, high-risk patients. Lists of up-regulated and down-regulated genes comparing Isotype control mAb versus change values are shown.Lead contact. Further information and requests for resources and reagents should be equipment.Antibodies. The human antibodies studied in this paper were isolated from blood 760 samples from two individuals in North America with previous laboratory-confirmed symptomatic specimens after written informed consent were previously described (Zost et al., 2020b) and ",USA,first author,2021-02-12,02
72186c93e21622807d938b1af82532898aa3e19f,General medical publications during COVID-19 show increased dissemination despite lower validation,"a1111111111 a1111111111 a1111111111 a1111111111 a1111111111The coronavirus disease 2019 (COVID-19) pandemic has given rise to an unprecedented quantity of publications in a short period of time as researchers worldwide attempt to report their experiences to better understand this new disease and identify promising treatments [1] . This has contributed to a COVID-19 ""infodemic""-an overwhelming quantity of information, leading to the rapid dissemination of less stringently validated information [2] .Given the devastating severity of COVID-19, there is an understandable urgency to disseminate new findings. However, the rush to publish has potentially led to the compromise of scientific integrity [3] . This has led to advocacy for quality over quantity, cautioning that a crisis is no excuse for lowering scientific standards [3] [4] [5] . Yet, the COVID-19 pandemic has magnified traditional problems of ""uninformative"" clinical trials-those whose results are not useful to patients, clinicians, researchers, or policy makers [6, 7] .While specific concerns about COVID-19-related publications have been expressed [8] , a formal analysis of the extent to which the medical literature has shifted during the pandemic is lacking. In this analysis, we aimed to quantify how scientific publications changed at the outset of the COVID-19 pandemic by performing a cross-sectional bibliometric study of published studies in four high-impact medical journals to identify differences in the characteristics of COVID-19 related publications compared to non-pandemic related studies.This is a cross-sectional bibliometric study of original COVID-19 related research publications in the four general medical journals with the highest impact factors [9] -The Journal of the American Medical Association (JAMA), New England Journal of Medicine (NEJM), The Lancet, and Nature Medicine. This study followed the Strengthening the Reporting of Observational Studies in Epidemiology (STROBE) reporting guidelines [10] .We searched for original investigations related to SARS-CoV-2 and COVID-19 published in March and April 2020 through MEDLINE. MEDLINE alone was used because it contained entries for all publications within our four journals of interest. Accordingly, other databases were not consulted. As comparison groups, we retrieved all non-COVID-19 research publications over the same two-month period in 2019 and 2020. We included original scientific research, and excluded opinion, news, and educational pieces. Two reviewers verified studies for inclusion and two reviewers audited extracted data. Any discrepancies in eligibility assessment and data collection were resolved by consensus. Extracted data included publication characteristics, study characteristics, author characteristics, and impact metrics. Impact metrics (numbers of reads, citations, and tweets) were not normalized to the time since publication.Categorical data are presented as counts and percentages and continuous data as medians and interquartile ranges (IQRs). Our primary measure was principal component analysis (PCA) of publication characteristics and impact metrics across groups. In our study, we sought to discover any differences in multiple article metrics between the 2020 COVID period and historical controls. Principal component analysis allows for the determination of the largest contributors to the variance in the data across all article metrics, in an unsupervised fashion without biasing data segregation [11] . Using PCA allows us to identify the most important features that capture the maximum information about the dataset, reducing dimensionality without any significant loss of information. Comparisons between groups were conducted using Chi-square or Fisher's exact tests for proportions and non-parametric Kruskal-Wallis tests with Dunn's multiple comparison for continuous data. Data for each journal were aggregated for analysis. P values less than 0.05 were considered statistically significant. Analyses were performed using GraphPad PRISM software version 7.0 and RStudio version 1.3.1056.The initial MEDLINE literature search identified 1,119 total articles for consideration (262 COVID-related). We identified 402 publications that met inclusion criteria: 76 were related to COVID-19; 154 and 172 were non-COVID publications over the same period in 2020 and 2019, respectively (data available in S1 Dataset). Principal component analysis utilizing the collected bibliometric data revealed segregation of the COVID-19 literature subset from both groups of non-COVID literature (2019 and 2020), verifying that the bibliometric characteristics capture a change in publication metrics (Fig 1) . The most significant contributions to the PCA came from metrics representing article dissemination (reads, tweets, and citations with 57%, 54%, and 43% each towards the first principal component, PC1). The two non-COVID subsets of data possess a near overlap in the PCA, indicating a strong consistency between the two years analyzed and emphasizing the uniqueness of the COVID-related literature.To further evaluate how the published COVID-19 research literature differed from non-COVID-19 investigations, we first compared their publication characteristics (Table 1) . Publication characteristics segregated by individual journal are provided in the Table in S1 Table. COVID-19 publications were more likely to describe prospective observational (31.6%) or case series (41.8%) studies without industry funding as compared with non-COVID articles, which were represented primarily by randomized controlled trials (32.5% and 36.6% in the non-COVID literature from 2020 and 2019, respectively). Moreover, COVID-related publications had lower word counts with fewer citations of other medical literature. While the number of authors was unchanged, the number of author affiliations was decreased, suggesting a lower level of collaborative or multi-institutional studies. There was no observed difference in the proportion of female first or corresponding authors. For Nature Medicine, the only evaluated journal to report submission dates, COVID-related submissions were published in a much shorter amount of time (35.1 days versus 288.3 and 305.3 days for 2020 and 2019 non-COVID publications, respectively).The observed differences in publication characteristics presumably represents the initial effort to quickly provide clinicians and policymakers with information in the early phase of the pandemic, regardless of quality. To objectively evaluate the extent to which the COVID-19 literature was disseminated, we analyzed the number of accesses, tweets, and citations within our bibliometric dataset. Publications related to COVID had an order of magnitude greater accesses, tweets, and citations compared with non-COVID publications from the same period (Table 1 ). This absolute difference does not consider the greater time since publication of articles from 2019 and therefore may conservatively underestimate the unparalleled rate at which observational data spread across the international medical community.Using an unbiased approach, our PCA suggests that published pandemic-related studies have different article characteristics and impact metrics compared with non-COVID studies. They unbiased analysis suggests COVID-related publications differ from both concurrent and historic non-COVID publications.https://doi.org/10.1371/journal.pone.0246427.g001 generally consist of shorter articles reporting observational studies with less literature cited and fewer study sites, suggestive of more limited scientific support. Yet, pandemic-related research is associated with greater reach in terms of readership, citations, and tweets, which speaks to the strong appetite for pandemic-related findings. The publication characteristics described in our analysis reflect the urgency with which the medical, scientific, and lay communities sought information as the pandemic evolved. This on-going need, however, should be tempered with scientific and ethical oversight that is at least as rigorous as normal times with a focus on well-designed trials and not rapid dissemination of low-quality data. The potential harms of producing multiple iterations of lower-quality studies have been identified, including wasting of resources, lapses in the ethical standard of scientific reporting, delaying the conduct of higher-level evidence trials, diluting the quality of available evidence, and endangering the ethical responsibility to patients who enroll in trials with the expectation of assisting in medical and scientific advancement [6, 12, 13] . Researchers should endeavour to maintain high-quality research methods by increasing collaboration across multiple centres, helping to overcome limitations that may exist from single-centre efforts [3, 14] . International teams working in concert and not in competition on welldesigned studies would greatly improve the capacity to detect clinically meaningful effects to inform the international health system's efforts against COVID-19. For example, research consortia could establish research priorities and promote the implementation of master protocols with adaptive platforms [15] [16] [17] . This type of approach is designed for the perpetual investigation of multiple interventions with timely adaptation, an ideal framework for our evolving COVID-19 health crisis that would facilitate wider collaboration and mitigate against the production of low-quality evidence and poor scientific reporting.Efforts have also focused on the expanding COVID-19 literature itself using both manual and automated methods. Content experts have been vetting the published literature to provide health care workers and policymakers with curated digital compendiums of high-quality research papers, such as the 2019 Novel Coronavirus Research Compendium [18] . Computational approaches are being used to mine the published COVID-19 literature to answer key questions related to the pandemic [19] . As these resources continue to grow, increasing effort will be required to ensure that the medical, scientific, and lay communities can engage with the resulting data and analyses in a meaningful way.Our analysis, however, has limitations. We focus on the earliest phase of pandemic in order to capture how the medical community first pivoted to acquire and disseminate COVID-19-related knowledge. This potentially biases our results towards observational studies as there would be limited time to advance and report more rigorous study designs, such as randomized controlled trials. Moreover, to efficiently disseminate medical knowledge, the included journals made pandemic-related content freely available, which may have contributed to the observed increase in impact metrics. Lastly, our bibliometric analysis does not consider the root cause of the disparity between COVID and non-COVID publications. This is likely multifactorial but could, in part, reflect the feasibility of a timely study completion, variable adherence to reporting standards, and a strained peer review system. Ongoing evaluations of the publication process over the entirety of the pandemic will inform how the scientific community can most effectively, safely, and ethically disseminate valuable medical knowledge in a time of acute crisis.COVID-19 led to a significant change in the characteristics of research studies across highimpact general medical journals. During this pandemic, the rapid and broad dissemination of research findings, regardless of underlying quality, were amplified and potentially contributed to the infodemic of misinformation at a time when best evidence needs to be emphasized. Ultimately, relaxing the rigorous standards for scientific research, although tempting for many altruistic reasons during a pandemic, may not actually achieve the objective of producing a solid evidence-based foundation upon which patients, clinicians, and policymakers can make meaningful decisions. The scientific and medical communities must strongly advocate for the thoughtful selection of high-quality research that will ensure the generation of meaningful knowledge and that participants of scientific trials who volunteer their health experience do not do so in vain.Supporting information S1 Dataset. The dataset used for the analyses in this study. (XLSX) S1 ",Canada,first author,2021-02-02,02
2a55cb48e473079bb381464dd7237aa4462d6b6d,,"Infections represent highly dynamic processes, characterized by evolutionary changes and events that involve both the pathogen and the host [1] and can be understood at two levels, namely the intra-and the inter-host levels [2] . Among infectious agents, viruses have a particularly high mutation rate, which is even more relevant in terms of public health control and management considering their short generation times and relatively large population sizes [1] . It is of paramount importance to take into account the mutational landscape of an infectious agent, to shed light on its evolution capability over time, to be able to capture events leading to a rapid and effective adaptation to the host environment, impacting its fitness and transmissibility to new hosts [3] .Pathogen evolution and recombination can result in escaping the host immune system, causing drug failure and leading to the insurgence of anti-microbial drug resistance. Further, it can compromise the effectiveness of existing vaccines making infection prevention and control more challenging [3] .The ""Severe Acute Respiratory Syndrome-related Coronavirus type 2"" (SARS-CoV-2) is the infectious agent responsible for the currently ongoing ""Coronavirus disease 2019"" (COVID-2019) pandemic. COVID-19 is a generally mild but sometimes severe and even life-threatening communicable disease [4] . This novel, emerging coronavirus exhibits a constantly and dynamically evolving mutational landscape, with a relatively abundant genetic diversity [5] and a high evolution capability over time [6] As new, more infectious strains of COVID-19 emerge around the world [7] , it is imperative to estimate when these new strains may overtake the wild-type strain in different populations. Therefore, we developed a general-purpose framework for estimating takeover of mutant strains of emerging infectious diseases. In the this study, we used COVID-19 as a case-study, but the model is also adapted to any emerging pathogen. first presented in [8] is modelled by the below equations:wheret is time in the units of infectious lifetime, R 0 is the basic reproduction number, M (t) is a mitigation function that describes non-pharmaceutical interventions, N is the population of the region, p is the relative infectiousness of severe cases to mild cases, r is the average reporting rate of mild cases, and p s is the probability that a case is severe.The model comes with a set of assumptions that are discussed in [8] , highlighted below:1. Reporting is relatively consistent.2. The total population in a region is constant.3. All severe cases are reported.We note that second assumption implies that the model is for short-term projection and third assumption implies that severe cases will always require medical intervention and is thus always reported. We also point out that first assumption and by virtue of the model itself, this model assumes that an outbreak is mainly being driven by community transmission.Using a least square method, we fit C K to reported cumulative case data in the province of Ontario and get estimates for total cases and active mild/severe cases.With base parameters we can then extend the model to account for a more infectious variant. We still fit to the same known infections, C K , but we require the wild-type given by I m and I s as well as a mutant strainĨ m andĨ s . The full model with both strains is then given by3 All rights reserved. No reuse allowed without permission.perpetuity.No vaccination, no relaxationWe can use fits from September 9, 2020 up to December 9, 2020 instead of our more recent fits. This approach will treat the weeks around Christmas as an anomaly. A posteriori, we can see that this indeed likely as caseloads have fallen again in January. Using these fits, along with our candidate vaccination strategy and May 1 relaxation we see that the proliferation of a new, more infectious strain is likely to create a prolonged 'peak' new daily infectious. However, if the vaccine is effective against the new strain, the time to herd immunity remains largely unchanged. This is shown in Figure 9 .SARS-CoV-2 is an emerging coronavirus responsible for the still ongoing COVID-19 pandemic. Ontario, Canada, as well as other territories and countries worldwide have experienced multiple waves, and have been struggling to find a difficult compromise between, on the one hand, ensuring and guaranteeing safety and, on the other hand, preserving at least essential businesses by modulating the stringency of public health interventions, strengthening/relaxing them based on up-to-date epidemiological data. One year after the initial outbreak that emerged in December 2019, a number of vaccines have been approved, even though new variants characterized by higher transmissiblity have been detected.Like other viruses causing widespread transmission in the population, SARS-CoV-2 has mutated many times since its initial insurgence (an outbreak of pneumonia of unknown etiology occurred in Wuhan, province of Hubei, mainland China). Based on its genomic profile, SARS-CoV-2 can be subdivided into various genetic groups, known as clades. A set of specific mutations would enable researchers to distinguish between viral groups currently dominating and circulating worldwide. These groups are generally called lineages, even though the precise nomenclature and the taxonomic hierarchy of SARS-CoV-2 are still under debate and, generally speaking, classifying viral variety and diversity is a rather challenging task [11, 12] .Mutations arise spontaneously as a consequence of a complex, multi-factorial series of macro-and micro-evolution processes as well as the result of selection pressures [7] . However, some of these mutations (termed as ""variants of concern"", VOCs) may be particularly clinically meaningful, especially from the public health perspective, being associated with higher force of infection, transmissibility as well as mortality [7] . In particular, since December 2020, some VOCs have been reported by national public health authorities to the World Health Organization (WHO), including VOC-202012/01 (also known as lineage B.1.1.7, commonly referred to as the ""UK variant"" or the ""British variant"") , 20I/501Y.V2 (known as lineage B.1.351, commonly termed as the ""South African variant"") and lineage B.1.1.28 (known as the ""Brazilian variant""). Other variants are under investigation and strict follow-up from international public health bodies, including the ""Japanese variant"" (variant P.1, lineage B.1.1.28) and the ""USA variant"" (L452R). This topic is constantly under flux as identifying the impact of a variant is of paramount importance. Once introduced in the population, a highly transmissible variant could become more and more prevalent, leading to the replacement of the original wild strain and making infection control and management particularly difficult.Our findings have important practical implications in terms of public health as policy-and decision-makers are equipped with a mathematical tool enabling the estimation of the take-over of a mutation strain of an emerging infectious disease, such as the previously mentioned VOCs. Moreover, in this paper, we identified that, in the context of under-reporting and the current case levels, a variant strain is unlikely to dominate until March/April 2021. Current NPIs in Ontario need to be kept in place for longer even with vaccination in order to prevent another outbreak. The proliferation of a variant strain in Ontario will mostly likely be observed by a widened peak of reported daily cases. If vaccine efficacy is maintained across strains, then it is still possible to have an immune population by end of 2021. A limitation of this model is that it does not account for importation of cases which could prolong outbreaks. With new rules in place by the Government of Canada surrounding international travel, the practical effects of importation are low.",Canada,first author,2021-02-05,02
00edc4f0c99f163070805045ac9454b4dbf8fb38,Problems with Evidence Assessment in COVID-19 Health Policy Impact Evaluation (PEACHPIE): A systematic review of evidence strength,"Policy decisions to mitigate the impact of COVID-19 on morbidity and mortality are some of the most important issues policymakers have had to make since January 2020. Decisions regarding which policies are enacted depend in part on the evidence base for those policies, including understanding what impact past policies had on COVID-19 outcomes. 1, 2 Unfortunately, there are substantial concerns that much of the existing literature may be methodologically flawed, which could render its conclusions unreliable for informing policy. The combination of circumstances being difficult for strong impact evaluation, the importance of the topic, and concerns over the publication environment may lead to the proliferation of low strength studies.High-quality causal evidence requires a combination of rigorous methods, clear reporting, appropriate caveats, and the appropriate circumstances for the methods used.2-5 Rigorous evidence is difficult in the best of circumstances, and the circumstances for evaluating non-pharmaceutical intervention (NPI) policy effects on COVID-19 are particularly challenging. 3 The global pandemic has yielded a combination of a large number of concurrent policy and non-policy changes, complex infectious disease dynamics, and unclear timing between policy implementation and impact; all of this makes isolating the causal impact of any particular policy or policies exceedingly difficult. 4 The scientific literature on COVID-19 is exceptionally large and fast growing. Scientists published more than 100,000 papers related to COVID-19 in 2020. 5 There is some general concern that the volume and speed 6, 7 at which this work has been produced may result in a literature that is overall low quality and unreliable. [8] [9] [10] [11] [12] Given the importance of the topic, it is critical that decision-makers are able to understand what is known and knowable 3, 13 from observational data in COVID-19 policy, as well as what is unknown and/or unknowable.Motivated by concerns about the methodological strength of COVID-19 policy evaluations, we set out to review the literature using a set of methodological design checks tailored to common policy impact evaluation methods. Our primary objective was to evaluate each paper for methodological strength and reporting, based on pre-existing review guidance developed for this purpose. 14 As a secondary objective, we also studied our own process: examining the consistency, ease of use, and clarity of this review guidance.Overview This systematic review of the strength of evidence took place in three phases: search, screening, and full review. The protocol for this study was pre-registered on OSF.io 15 based on PRISMA guidelines. 16 Deviations from the original protocol consisted largely of language clarifications and error corrections for both the inclusion criteria and review tool, an increase in the number of reviewers per fully reviewed article from two to three, and simplification of the statistical methods used to assess the data. Notably, this protocol differs in many ways from more traditional systematic review protocols, as instead of being a review summary of the evidence of a particular topic, this is a systematic review of methodological strength of evidence.The following eligibility criteria were used to determine the papers to include:• The primary topic of the article must be evaluating one or more individual COVID-19 policies on direct COVID-19 outcomes ○ The primary exposure(s) must be a policy, defined as a government-issued order at any government level to address a directly COVID-19-related outcome (e.g., mask requirements, travel restrictions, etc). ○ COVID-19 outcomes may include cases detected, mortality, number of tests taken, test positivity rates, Rt, etc. ○ This may NOT include indirect impacts of COVID-19 on things such as income, childcare, trust in science, etc.• The primary outcome being examined must be a COVID-19-specific outcome, as above.The study must be designed as an impact evaluation study from primary data (i.e., not primarily a predictive or simulation model or meta-analysis).• The study must be peer reviewed, and published in a peer-reviewed journal indexed by PubMed.• The study must have the title and abstract available via PubMed at the time of the study start date (November 26).The study must be written in English.These eligibility criteria were designed to identify the literature primarily concerning the quantitative impact of one or more implemented COVID-19 policies on COVID-19 outcomes. Studies in which impact evaluation was secondary to another analysis (such as a hypothetical projection model) were eliminated because they were less relevant to our objectives and/or may not contain sufficient information for evaluation. Categories for types of policies were from the Oxford COVID-19 Government Response Tracker. 17 Reviewer recruitment, training, and communication Reviewers were recruited through personal contacts and postings on online media. All reviewers had experience in systematic review, quantitative causal inference, epidemiology, econometrics, public health, methods evaluation, or policy review. All reviewers participated in two meetings in which the procedures and the review tool were demonstrated. Screening reviewers participated in an additional meeting specific to the screening process. Throughout the main review process, reviewers communicated with the administrators and each other through Slack for any additional clarifications, questions, corrections, and procedures. The main administrator (NH), who was also a reviewer, was available to answer general questions and make clarifications, but did not answer questions specific to any given article.The search terms combined four Boolean-based search terms: a) COVID-19 research,17 b) regional government units (e.g., country, state, county, and specific country, state, or province, etc.), c) policy or policies, and d) impact or effect. The full search terms are available in Appendix 2.The search was limited to published articles in peer-reviewed journals. This was largely to attempt to identify literature that was high quality, relevant, prominent, and most applicable to the review guidance. PubMed was chosen as the exclusive indexing source due to the prevalence and prominence of policy impact studies in the health and medical field. Preprints were excluded to limit the volume of studies to be screened and to ensure each had met the standards for publication through peer review. The search was conducted on November 26, 2020.Eight reviewers screened the title and abstract of each article for the inclusion criteria. Two reviewers were randomly selected to screen each article for acceptance/rejection. In the case of a dispute, a third randomly selected reviewer decided on acceptance/rejection. Training consisted of a one-hour instruction meeting, a review of the first 50 items on each reviewers' list of assigned articles, and a brief asynchronous online discussion before conducting the full review.The full article review consisted of two sub-phases: the independent primary review phase, and a group consensus phase.Each article was randomly assigned to three of the 23 reviewers in our review pool. Each reviewer independently reviewed each article on their list, first for whether the study met the eligibility criteria, then responding to methods identification and guided strength of evidence questions using the review tool, as described below. Reviewers were able to recuse themselves for any reason, in which case another reviewer was randomly selected. Once all three reviewers had reviewed a given article, all articles that weren't unanimously determined to not meet the inclusion criteria underwent a consensus process.During the consensus round, the three reviewers were given all three primary reviews for reference, and were tasked with generating a consensus opinion among the group. One randomly selected reviewer was tasked to act as the arbitrator. If consensus could not be reached, a fourth randomly selected reviewer was brought into the discussion to help resolve disputes.This review tool and data collection process was an operationalized and lightly adapted version of the COVID-19 health policy impact evaluation review guidance literature, written by the lead authors of this study. All reviewers were instructed to read and refer to this guidance document to guide their assessments. Additional explanation and rationale for all parts of this review tool is available in Haber et al., 2020 14 .The review tool consisted of two main parts: methods design categorization and full review. The review tool and guidance categorizes policy causal inference designs based on the structure of their assumed counterfactual. This is assessed through identifying the data structure and comparison(s) being made. There are two main items for this determination: the number of pre-period time points (if any) used to assess pre-policy outcome trends, and whether or not policy regions were compared with non-policy regions. These, and other supporting questions, broadly allowed categorization of methods into cross-sectional, pre/post, interrupted time series (ITS), difference-in-differences (DiD), comparative interrupted time-series (CITS), (randomized) trials, or other. Given that most papers have several analyses, reviewers were asked to focus exclusively on the impact evaluation analysis that was used as the primary support for the main conclusion of the article. Studies categorized as cross-sectional, pre/post, randomized controlled trial designs, and other were set aside for no further review for the purposes of this research. Cross-sectional and pre-post designs were considered inappropriate for policy causal inference for COVID-19 due largely to inability to account for a large number of potential issues, including confounding, epidemic trends, and selection biases. Randomized controlled trials were assumed to broadly meet key design checks. Studies categorized as ""other"" received no further review, as the review guidance would be unable to assess them. Additional justification and explanation for this decision is available in the review guidance.For the methods receiving full review (ITS, DiD, and CITS), reviewers were asked to identify potential issues and give a category-specific rating. The specific study designs triggered sub-questions and/or slightly altered the language of the questions being asked, but all three of the methods design categories shared these four key questions:• Graphical presentation: ""Does the analysis provide graphical representation of the outcome over time?"" • Functional form: ""Is the functional form of the counterfactual (e.g., linear) well-justified and appropriate?"" • Timing of policy impact: ""Is the date or time threshold set to the appropriate date or time (e.g., is there lag between the intervention and outcome)?"" • Concurrent changes: ""Is this policy the only uncontrolled or unadjusted-for way in which the outcome could have changed during the measurement period [differently for policy and non-policy regions]?""For each of the four key questions, reviewers were given the option to select ""No,"" ""Mostly no,"" ""Mostly yes,"" and ""Yes"" with justification text requested for all answers other than ""Yes."" Each question had additional prompts as guidance, and with much more detail provided in the full guidance document. Graphical representation is included here primarily as a key way to assess the plausibility and justification of key model assumptions, rather than being necessary for validity by itself.Finally, reviewers were asked a summary question:• Overall: ""Do you believe that the design is appropriate for identifying the policy impact(s) of interest?""Reviewers were asked to consider the scale of this question to be both independent/not relative to any other papers, and that any one substantial issue with the study design could render it a ""No"" or ""Mostly no."" Reviewers were asked to follow the guidance and their previous answers, allowing for their own weighting of how important each issue was to the final result. A study could be excellent on all dimensions except for one, and that one dimension could render it inappropriate for causal inference. As such, in addition to the overall rating question, we also generated a ""weakest link"" metric for overall assessment, representing the lowest rating among the four key questions (graphical representation, functional form, timing of policy impact, and concurrent changes). A ""mostly yes"" or ""yes"" is considered a passing rating, indicating that the study was not found to be inappropriate on the specific dimension of interest.A ""yes"" rating does not necessarily indicate that the study is strongly designed, conducted, or is useful; it only means that it passes a series of key design checks for policy impact evaluation and should be considered for further evaluation. The papers may contain any number of other issues that were not reviewed (e.g., statistical issues, inappropriate comparisons, generalizability, etc.,). As such, this should only be considered an initial assessment of plausibility that the study is well-designed, rather than confirmation that it is appropriate and applicable.The full review tool is available in the supplementary materials.Graphical representation of the outcome over time was relatively well-rated in our sample, with 74% (n=20/27) studies being given a ""mostly yes"" or ""yes"" rating for appropriateness. Reasons cited for non-""yes"" ratings included a lack of graphical representation of the data, alternative scales used, and not showing the dates of policy implementation.Functional form issues appear to have presented a major issue in these studies, with only 19% receiving a ""mostly yes"" or ""yes"" rating, 78% (n=21/27) receiving a ""no"" rating, and 4% (n=1/27) ""unclear."" There were two common themes in this category: studies generally using scales that were broadly considered inappropriate for infectious disease outcomes (e.g., linear counts), and/or studies lacking stated justification for the scale used. Reviewers also noted disconnects between clear curvature in the outcomes in the graphical representations and the analysis models and outcome scales used (e.g., linear). In one case, reviewers could not identify the functional form actually used in analysis.Reviewers broadly found that these studies dealt with timing of policy impact (e.g., lags between policy implementation and expected impact) relatively well, with 70% (n=19/27) rated ""yes"" or ""mostly yes."" Reasons for non-""yes"" responses included not adjusting for lags and a lack of justification for the specific lags used.When reviewers were asked if sensitivity analyses had been performed on key assumptions and parameters, about half (56% n=15/27) answered ""mostly yes"" or ""yes."" The most common reason for non-""yes"" ratings was that, while sensitivity analyses were performed, they did not address the most substantial assumptions and issues.As shown in Figure 4 , the consensus overall proportion passing (""mostly yes"" or ""yes"") was a quarter of what it was from the initial independent reviews. 45% (n=34/75) of studies were rated as ""yes"" or ""mostly yes"" in the initial independent review, as compared to 11% (n=4/36) in the consensus round (RR 0.25, 95%CI 0.09:0.64). The issues identified and discussed in combination during consensus discussions, as well as additional clarity on the review process, resulted in reduced overall confidence in the findings. Increased clarity on the review guidance with experience and time may also have reduced these ratings further.The large majority of studies had at least one ""no"" or ""unclear"" rating in one of the four categories (74% n=20/27), with only one study whose lowest rating was a ""mostly yes,"" no studies rated ""yes"" in all four categories. Only one study was found to pass design criteria in all four key questions categories, as shown in the ""weakest link"" column in Figure 4 .During independent review, all three reviewers independently came to the same conclusions on the main methods design category for 33% (n=12/36) articles, two out of the three reviewers agreed for 44% (n=16/36) articles, and none of the reviewers agreed in 22% (n=8/36) cases. One major contributor to these discrepancies were the 31% (n=11/36) cases where one or more reviewers marked the study as not meeting eligibility criteria, 64% (n=7/11) of which the other two reviewers agreed on the methods design category.Inter-rater reliability of the primary independent reviews was relatively low across the board for the key questions. For the overall scores, Krippendorff's alpha was only 0.16 due to widely varying opinions between raters. The four key categorical questions had slightly better inter-rater reliability than the overall question, with Krippendoff's alphas of 0.59 for graphical representation, 0.34 for functional form, 0.44 for timing of policy impact, and 0.15 for concurrent changes, respectively.The most consistent point of feedback from reviewers was the value of having a three reviewer team with whom to discuss and deliberate, rather than two as initially planned. This was reported to help catch a larger number of issues and clarify both the papers and the interpretation of the review tool questions. Reviewers also expressed that one of the most difficult parts of this process was assessing the inclusion criteria, some of the implications of which are discussed below.This systematic review of evidence strength found that only four (or only one by a stricter standard) of the 36 identified published and peer-reviewed health policy impact evaluation studies passed a set of key checks for identifying the causal impact of policies on COVID-19 outcomes. Because this systematic review examined a limited set of key study design features and did not address more detailed aspects of study design, statistical issues, generalizability, and any number of other issues, this result may be considered an upper bound on the overall strength of evidence within this sample. Two major problems are nearly ubiquitous throughout this literature: failure to isolate the impact of the policy(s) of interest from other changes that were occurring contemporaneously, and failure to appropriately address the functional form of infectious disease outcomes in a population setting. Similar to other areas in the COVID-19 literature, 24 we found the current literature directly evaluating the impact of COVID-19 policies largely fails to meet key design criteria for useful inference.The framework for the review tool is based on the requirements and assumptions built into policy evaluation methods. Quasi-experimental methods rely critically on the scenarios in which the data are generated. These assumptions and the circumstances in which they are plausible are well-documented and understood, 2, 3, 14, [25] [26] [27] including one paper discussing application of difference-in-differences methods specifically for COVID-19 health policy, released in May 2020. 3 While ""no uncontrolled concurrent changes"" is a difficult bar to clear, that bar is fundamental to inference using these methods.The circumstances of isolating the impact of policies in COVID-19 -including large numbers of policies, infectious disease dynamics, and massive changes to social behaviors -make those already difficult fundamental assumptions broadly much less likely to be met. Some of the studies in our sample were nearly the best feasible studies that could be done given the circumstances, but the best that can be done often yields little useful inference. The relative paucity of strong studies does not in any way imply a lack of impact of those policies; only that we lack the circumstances to have evaluated their effects.The review process itself demonstrates how guided and targeted peer review can efficiently evaluate studies in ways that the traditional peer review systems do not. The studies in our sample had passed the full peer review process, were published in largely high-profile journals, and are highly cited, but contained substantial flaws that rendered their inference utility questionable. The relatively small number of studies included, as compared to the size of the literature concerning itself with COVID-19 policy, may suggest that there was relative restraint from journal editors and reviewers for publishing these types of studies. The large number of models, but relatively small number of primary evaluation analyses is consistent with other areas of 29 At minimum, the flaws and limitations in their inference could have been communicated at the time of publication, when they are needed most. In other cases, it is plausible that many of these studies would not have been published had a more thorough or better targeted methodological review been performed.This systematic review of evidence strength has limitations. The tool itself was limited to a very narrow -albeit critical -set of items. Low ratings in our study should not be interpreted as being overall poor studies, as they may make other contributions to the literature that we did not evaluate. While the guidance provided a well-structured framework and our reviewer pool was well-qualified, strength of evidence review is inherently subjective. It is plausible and likely that other sets of reviewers would come to different conclusions.Most importantly, this review does not cover all policy inference in the scientific literature. One large literature from which there may be COVID-19 policy evaluation otherwise meeting our inclusion criteria are pre-prints. Many pre-prints would likely fare well in our review process. Higher strength papers often require more time for review and publication, and many high quality papers may be in the publication pipeline now. Second, this review excluded studies that had a quantitative impact evaluation as a secondary part of the study (e.g., to estimate parameters for microsimulation or disease modeling). Not only are these assessments not the primary purpose of those studies, they also typically lack the detail requisite to make a critical assessment of the study design and methods used. Third, the review does not include policy inference studies that do not measure the impact of a specific policy. For instance, there are studies that estimate the impact of reduced mobility on COVID-19 outcomes but do not attribute the reduced mobility to any specific policy change. Finally, a considerable number of studies that present analyses of COVID-19 outcomes to inform policy are excluded because they do not present a quantitative estimate of specific policies' treatment effects.",USA,first author,2021-02-08,02
6af0014cdfed816f33e73aabf4585713b378005e,"Transitioning a home-based, motivational interviewing intervention among families to remote delivery during the COVID-19 pandemic: Key lessons learned","On March 11, 2020 the World Health Organization declared COVID-19 a global pandemic and called for every country to take ""urgent and aggressive action"" to slow the spread of the virus [1] . Following this announcement, stay-at-home directives began in Canada which resulted in minimizing physical contact and providing in-person healthcare services only where essential. While traditional healthcare involves patients receiving in-person care from a clinician, the COVID-19 physical distancing recommendations resulted in healthcare practitioners transitioning in-person visits to remote delivery where possible via telephone and/or online video platforms.Research conducted prior to COVID-19 found that remote delivery of motivational interviewing (MI) has been well accepted among adults with chronic disease [2] [3] [4] . MI is a patient-centred, collaborative conversation to help patients commit to behaviour change. [5] MI requires sophisticated skills including open-ended questions, complex reflections, and summarizations [5] . For example, research has shown that telephone-based MI may help improve medication adherence [6] and may increase physical activity and reduce metabolic risk among older women when included as a component of a health behavior care plan [7] . A study by van Keulen et al. (2011) found that telephone-based MI was successful with improving physical activity, fruits and vegetable consumption among men and women compared to those that did not receive the intervention [8] . However, this study also found that targeted print communication was equally successful with improving those health behaviors as telephone-based MI [8] .Pre-COVID-19 research has also shown that telephone-based MI is feasible and successful for families of young children. In a study by Akçay & Emiroğlu (2019) , researchers found that an intervention that used two in-person MI sessions and two telephone-based MI sessions was successful in reducing the aggressive behaviors of young children [9] . These findings were supported by another study that found telephone-based MI used to reinforce lifestyle behavior J o u r n a l P r e -p r o o f change goals developed during in-person clinic visits with a nurse was successful in improving the confidence and motivation of parents, and adherence to their behavior change goals [10] .However, transitioning to remote healthcare delivery during COVID-19 may present additional challenges. For example, a study by Sasangohar et al. (2020) found that a single platform may not fit the needs of all patients, and therefore a variety of options may be necessary to deliver patient-centered counseling. This study also found that technological literacy and creating and sustaining interpersonal connection to be a challenge with remote delivery of healthcare [11] . While a number of studies have examined the transition of primary healthcare from in-person to telephone or online videocalls during COVID-19 [12] [13] [14] [15] [16] [17] , no research has examined the transition of MI-counseling for health behavior change from in-person to remote delivery during COVID-19. In addition, existing research on remote delivery of MI has been limited to telephone-based MI and does not examine the feasibility or acceptability of MI-counseling among families using an online video platform. This is an important consideration as research suggests the use of online video platforms for remote delivery of healthcare is likely to continue as we transition into a post-COVID-19 era [18] .The current study aimed to address these gaps by examining Health Educator's (HEs) experiences with and perceptions of transitioning from home visits to remote delivery of MI using both telephone and online videocalls within an existing trial of a family-based health promotion intervention. The study also aimed to identify key recommendations for other healthcare practitioners navigating the delivery of remote MI-counseling.The Guelph Family Health Study (GFHS) is a randomized controlled trial designed to test the impact of a home-based obesity prevention intervention on children's weight outcomes and their sleep habits, screen time, physical activity, dietary intake, and family meals.Between December 2015 and March 2020, the GFHS team enrolled 285 families with children between the ages of 1.5 and 5 years. Families participating in the GFHS were randomized into two groups: intervention or control. Families in the intervention arm of the study received four visits with a HE, bi-weekly emails that aligned with their health behavior goals, and mailed incentives that provided a child-centered physical support item to reinforce their health behavior change goal for that week. HEs are registered dietitians who completed a two-day MI training before the study began and advanced follow-up training once each year.At each home visit with a HE, families evaluated and rated their current family habits and routines on a scale of 1 (very unsatisfied) to 10 (very satisfied), a skill learned from MI training. HEs then used MI to prompt discussion that taps into the family's personal values and beliefs, in order to support the families in meeting behavior change goals that are meaningful to them. To support families with goal development, resources included a MI focused tool developed by the GFHS team called the Health Behavior Wheel. To engage children with family goals, families J o u r n a l P r e -p r o o f were provided with a magnetic goal tracking resource where children could track their health behavior goals by using health-themed magnets to indicate when they had achieved their goal for that day or week. Subsequent follow up visits typically lasted 30 minutes to 1-hour and families had the chance to again rate their health behaviors on the Health Behavior Wheel. Their rating was based on their perceived feeling of success with their goals from the previous four weeks. Families then either set new goals or continued working on previously stated goals for the upcoming four weeks. Families were encouraged to check-in with the HEs between visits via email for resources, questions about their goals, and for any needed support.Due to the COVID-19 physical distancing requirements, HE visits transitioned from in-person visits delivered in the home to remote delivery to help ensure the safety of participants and staff.Standardized emails were sent to all families who had yet to complete their home visits (n= 22) explaining that the GFHS home visits were transitioning to remote delivery, and that families would have the option to choose between online videocalls and phone visits. The email also provided an explanation of how to use the Microsoft (MS) Teams virtual platform and described the security features associated with the platform. MS-Teams is the collaboration tool approved for use by the University of Guelph. One family declined the transition to remote delivery and opted out of their remaining visits. Of the 21 families who agreed to participate in the remote delivery, sixteen families had at least one in-person home visit before transitioning to remote delivery of MI-counseling, and five families were randomized after physical distancing recommendations and therefore only received remote delivery of the intervention. Of the 21 families who received remote visits, 10 families completed their visits via phone calls, 8 families used online videocalls, and 3 families completed their visits through a combination of both phone and online videocalls. MI-counseling visits were, on average, 10-minutes longer when done through an online videocall (31.5 minutes) versus a phone call (21.8 minutes).With the transition to remote delivery, all required resources were shared with families via email in advance of the remote MI visits. Then, the HEs had the families follow along in real-time as the HE reviewed the materials via phone or videocall.Three HEs participated in a one-hour focus group discussion focused on their experiences and learnings regarding the transition of HE visits to remote delivery. This focus group discussion was hosted by the lead HE (LT) and was video recorded using Microsoft Teams. LT had four prepared questions for discussion: 1) What challenges did you encounter during the transition?, 2) Successes: what worked well?, 3) How does remote delivery differ with regards to encouraging and maintaining participant (whole family) engagement?, 4) What supports and resources were helpful for you? Using Braun & Clarke (2013) as a guide, LT conducted thematic analysis to identify themes as the unit of analysis [19] . Analysis of the meeting involved two phases. In phase one, LT listened to the video recording four times in order to take detailed notes of the discussion. To enhance credibility of the data, member-checking was completed by RL J o u r n a l P r e -p r o o f and JB, who individually reviewed the written notes to ensure accuracy and trustworthiness of the data. RL and JB provided additional thoughts and detail to the transcript. In phase 2, LT immersed herself in the data by reading and coding the detailed notes. These codes were then used to as the building blocks of themes [20] and subthemes that were subsequently generated from the data. Once developed, themes and subthemes were reviewed against the transcript by all HEs (LT, RL, & JB) to ensure they were supported by the data and reflective of what was discussed at the meeting.Ninety-five percent of the families interviewed were from 2-parent households. Of the 21 families that took part in remote MI-counseling, 14% had 1 child, 53% had 2 children, and 33% had 3 or more children. Qualitative analysis of the group discussion with HEs revealed 5 themes: 1) Impact of COVID-19 on families; 2) Scheduling, no-shows, and cancellations; 3) Preference of online video versus phone; 4) Building rapport with remote delivery; 5) HE work satisfaction.It became obvious to HEs that challenges associated with the transition from home-based MI visits to remote MI visits was made more complex by the COVID-19 pandemic. HEs were transitioning families to remote visits, while families were adapting to the rapidly changing physical distancing restrictions, and disruptions within their own workplaces. Recognizing the transition was unique for every family was important as HEs sought to engage and tailor their interaction with the families. For example, the experience of COVID-19 was especially difficult for families who were front-line workers. This was also true for those families who had high-risk members living in the home, lost their job due to COVID-19, or were adapting their businesses for remote services. HEs worked to understand the experience of each family using open-ended questions about changes in the family's routines and structures due to COVID-19, recognizing that the lived experiences of COVID-19 differed for each family.HEs identified that one of the initial challenges with some families was scheduling a remote visit. Given that parents were adapting to having children home full-time and, for many parents, adapting to working from home, it was difficult for families to take time from their newly developing and in-flux schedules for a MI-counseling visit. Some families were concerned about the time-commitment associated with the visit, and the ""burden of finding time"" to dedicate to a visit required HEs to be patient and flexible with scheduling visits. HEs found it necessary to acknowledge families' feelings and remain flexible and understanding of their timeline when scheduling remote visits.While scheduling remote visits was challenging for some families, HEs identified that for others scheduling remote visits was easier than booking in-person visits as families had more availability and appreciated the flexibility in location remote visits offered. One HE said, ""families seemed to like the remote visits, perhaps because we are not actually entering their J o u r n a l P r e -p r o o f home … they just seemed more flexible"". For example, HEs conducted remote visits with families who were at the park or sitting in traffic.The HEs identified an increase in no-shows i.e., families forgetting about the scheduled visit, for remote visits compared to in-home visits. HEs found the best way to avoid no-shows with remote delivery was to book the visit within a few days of the actual visit date. This was different from home visits, where booking further in advance and sending reminders was more effective in reducing no-shows.While no-shows increased with remote delivery, HEs identified that cancellations of scheduled visits due to illness or a scheduling conflict was lower with remote delivery compared to inhome visits. Most rescheduling for in-person visits was due to family members having a cold or seasonal flu symptoms, and not wanting to spread germs. Remote visits eliminate that challenge. If family members are feeling well enough to meet remotely, they can continue with the planned visit. Another common reason for cancellation pre-COVID-19 was a parent being called into work. HEs found that remote visits were often conducted in between parents' work commitments when working from home, thus eliminating the need to cancel the visit.When comparing phone verses online videocalls, MI-counseling via phone presented more of a challenge with engagement. Although families were typically receptive and engaged with inperson MI-counseling visits, the phone visits sometimes ""seemed rushed, and it seemed the families wanted to move quickly through the visit"". HEs described families as seeming more distracted on the phone and provided shorter answers that seemed to lack deep reflection. One HE noted that families ""seemed to be multitasking during the phone visit, whereas with online videocalls, families were more dedicated to the conversation and focused on thinking through their behavior change goal"". Another HE described phone visits as getting the feeling families wanted to ""get it over with"", because they had ""less commentary and less verbal conversation"" compared to online videocalls. The HE went on to say that online videocalls ""felt like more like an actual session with more intimate and detailed conversation"", and that online videocalls ""were more amenable to motivational interviewing compared to phone visits"". Taken together, it seemed that the online videocalls were more purposeful for families resulting in more in-depth reflection on personal values and goals.While HEs identified that online videocalls elicited better focus and commitment to the visit from the families, the online format was not without its challenges. A lack of familiarity with the MS-Teams platform was a challenge for some families. Some families worried about their privacy and whether the online platform could be hacked, or sessions would be recorded. To address these challenges, HEs provided families with an explanation of platform use and assurances regarding maintaining privacy while using MS-Teams. Providing this information to families took additional time compared to the time required to setup in-person visits. HEs needed to account for the additional time required to setup each MI-counseling visit. Families were appreciative of the additional information which helped increase their comfort level with remote visits.HEs discovered that building and maintaining rapport with families during remote MIcounselling was possible. However, there were differences in the ability to build and maintain rapport among families who received MI-counseling via online videocalls and those who received their visits via phone. The ability to see faces on an online platform seemed to help HEs build better connections and trust with families and to read non-verbal cues, compared to phone visits. HEs learned that successful phone visits required an understanding that non-verbal cues were not possible, and strategies were needed to mitigate this limitation. Specifically, HEs needed to be ""comfortable with the silence"" in order to provide ample time for the participant to reflect and respond on the phone. Further, because HEs depended solely on verbal communication during phone visits, HEs found success by asking more probing questions such as ""tell me more about that"", and ""what are you not saying?"".During in-home visits, HEs also worked toward building rapport with the children of the family. This was easy to do at home visits by reading, playing, or talking with the children. HEs reported on the importance of remembering to build rapport with the children during remote visits. However, rapport building with children was only possible when using a virtual platform, and not possible when conducting a phone visit. HEs accomplished rapport building with children by involving them in the meeting. Specifically, HEs would ask the child(ren) questions about a health behavior (e.g. ""tell me about how you get ready to go to sleep?"") or giving them a specific task, for example, asking them to draw a picture of their favorite outdoor activity, and show that picture to the HE via the camera during the meeting. In doing this, children were less likely to distract their parents from the meeting, felt involved in discussion, and seemed more excited about engaging in the family visit to help their parents with creating health behavior goals.HEs described the transition to remote visits during the pandemic as a rewarding experience. HEs reported a sense of accomplishment while ""supporting families as they restructured their family routine to find a new-normal and helping families to maintain those health behaviors that are so important to them, during these very challenging times"". One HE said ""families seemed really receptive to online MI visits and were appreciative that we [HEs] are continuing to support them during COVID"" which provided this HE a feeling of satisfaction. Finally, HEs felt a strong sense of achievement having developed a new skill, specifically remote MI-counseling, which they feel increased their competence, knowledge, and marketability as they move forward with their careers.Helping to contribute to work satisfaction among HEs was the appreciation expressed by families to the HEs about continuing to provide support during COVID-19. One HE described a family as being grateful to ""have someone to discuss their challenges with and someone to bounce ideas and thoughts off of"". Families also appreciated hearing what other families in a J o u r n a l P r e -p r o o f similar situation were doing during the pandemic, often asking questions like ""what are some other families you're seeing doing"" in relation to meals, physical activity, or other health behaviors. One HE described a family's response to online learning: ""one family said that they got a lot more out of the visits than they were expecting they would. They didn't know what to expect and the visits exceeded their expectations"". HEs reported that this overwhelmingly positive response from families provided a feeling of accomplishment and work satisfaction. Families were thankful to have the GFHS visits to hold them accountable when building routines through the changes that a global pandemic brought to their family. Finally, families reported that they thought the online visits were ""cool"", ""easy"", and ""convenient"", and really like the flexibility that this new way of engaging in health behavior change support brought to their life.The goal of this study was to examine the HEs experiences with and perceptions of transitioning to remote delivery of MI-counseling in a home-based obesity prevention intervention that used family-targeted MI to support behavior change. HEs identified the unique family circumstances of COVID-19 as being an important consideration when working with families to provide MIcounseling remotely. Although connectivity was a challenge in the beginning, HEs found that online videocalls were superior to phone calls for remote MI-counseling. Online videocalls provided a more focused, formal, and intentional MI-counseling session that provided participants with better opportunity to reflect on their own values and beliefs to create meaningful health behavior change goals compared to telephone-based MI-counseling. Further, online videocalls provided a better opportunity for building rapport and trust between participant and HE, thereby creating a space for meaningful reflection and counseling. Based on these findings, key recommendations for transitioning or using remote MI-counselling among families were identified (Table 1) .Recommendations for transitioning to a remote platform for MI-counseling identified by Health Educators during the transition to remote delivery of MI-counseling for health behavior change among families with young children.PlatformVisit no-shows with remote visits  Use an online video platform instead of phone calls for MI-counseling when possible. Provide families a detailed explanation of the remote platform being used, and steps taken to protect families' privacy.  Provide the necessary technical support to assist client with setting-up of the virtual platform. Book visits within a few days of the expected visit date, no more than 1-week in advance, to reduce no-show rate.Reduction or elimination of ability to see non-verbal cues.Rapport building remotelyInclude the child(ren) Ask more probing questions that elicit reflection about their thoughts and feelings such as ""tell me more about that"", ""can you explain to me how that made you feel?"", and ""what are you not saying?"".  Be comfortable sitting with the silence. Recognize that the lived experiences of COVID-19 differ for each family and prioritize understanding, flexibility, and support.  Acknowledge the family's struggle and be adaptable to their timeline and preferences. Ask more questions that elicit reflection into personal values and beliefs such as ""what is important to you about this?"" and ""what is the gift in this?""  Provide more frequent check-ins to demonstrate a commitment to the family's success such as ""how will you measure your success?"" and ""on a scale of 1 to 10, how confident are you with this?"". Provide child(ren) a task, such as asking them to draw a picture of their favorite fruit or vegetable or draw a picture of an activity they would like to do as a family and show it to the camera.  Involving children in the conversation about the family's previous goals was also helpful. For example, questions could include: ""tell me about the most exciting thing you did outside with your family?"" or ""do you remember all the vegetables and fruits you ate today?""  Ask children age-appropriate questions that help them to consider their own goals for health behavior change. For example, ""tell me about one thing you did outdoors with your family that you would like to do again"", or ""what do you think is something you could do to help make dinner?""Overall, HEs found that online videocalls provided for a better MI-counseling visit compared to a phone visit. For this study, HEs used MS-Teams because it is the collaboration tool approved for use by the university institution, but any online video platform (e.g. Zoom, Skype) would likely work well. Although not quite as good as in-person visits, HEs were able to see non-verbal communication with online videocalls which was not possible during a phone visit. Although limited by the camera view, live video provided HEs non-verbal insight into the family's reactions and feelings toward their health behavior change goals. MI-counseling via phone did achieve the purpose of the visit, but it did not seem as ""intentional"" compared to an online videocall. These findings are supported with previous research by Aafjes-van, et al. (2020) where they surveyed 141 therapists who transitioned to online video therapy during COVID-19. Authors found that 41% of clinicians reported feeling less connected with their patients through remote services compared to in-person counseling, and 37% had difficulty reading the patients emotions [21] . However, a systematic review by Irvine et al., (2020) revealed that there are few differences in interactionality between therapy sessions conducted over the phone versus face-toface sessions, though phone sessions were significantly shorter and therefore potentially less fruitful [22] . Our finding that online videocalls are preferable to phone visits from the provider perspective may provide some guidance to clinicians who are unsure of the best method to build rapport with clients while delivering counseling remotely.HEs found it helpful to provide families information about the virtual platform used for online videocalls. Providing families information about how to use MS-Teams without downloading the program and assuring them it would not be recorded was helpful in increasing their comfort level with the virtual platform and their likeliness to use the virtual platform over the phone. A study by Madden et al. (2020) supports these findings. The authors examined advantages, barriers, and provider attitudes of the transition to telehealth for prenatal care [14] . The results revealed that patients felt anxiety around using technology, and 78% of care providers reported that patient difficulty in using and accessing technology was most common barrier to the delivery of telehealthcare [14] . These findings reinforce our own results and emphasize the importance of providing clients with education and support for use of virtual platforms.HEs recognized that the transition to remote delivery of MI was complicated by the COVID-19 pandemic, as families worked to navigate the effects of physical distancing and stay-at-home directives on their families. Liu and Doan (2020) describe COVID-19 as a chronic stressor that could potentially result in long-term health concerns [23] . In a study that examined the individual and dyadic experiences of families with children aged 2-14 during stay-at-home orders in Italy, it was found that families who reported more difficulty during quarantine had higher levels of stress [24] . Specifically, parents who reported difficulty with managing additional tasks associated with the quarantine (e.g. supporting children's learning) with their pre-pandemic tasks were more stressed [24] . Results of this study demonstrated that additional stress negatively influenced children's well-being [24] . These findings build on previous research that found quarantine can lead to psychological distress and poorer wellbeing among adults [24] . These research findings highlight the importance of continued MI-counseling for health behavior change among families amid a pandemic that includes stay-at-home directives. Families were more willing to engage in remote delivery of MI-counseling when HEs recognized that the lived experiences of COVID-19 differed for each family, and through verbal and written communication expressed that understanding with families. HEs put this recognition into action by prioritizing flexibility, support, and understanding with families. HEs verbally and through their emails acknowledged the family's struggle and remained adaptable to the family's timeline and preferences. These strategies may be useful for other health practitioners struggling to work remotely with families during a time of stress and uncertainty.Finally, HEs agreed that transitioning to a remote platform was an exceptional learning experience and personally rewarding. These findings are consistent with a study by Smith, et al.(2020) who found that transitioning to remote healthcare delivery was satisfying for their service providers [25] . HEs were able to develop skills in building rapport in an online setting with families and developed skills in virtual platform use in order to troubleshoot problems with families as they setup and began to use the virtual platform. HEs also developed MI-counseling skills that were specific to remote counselling. This is an important skill as research has shown that clinicians perceive MI-counseling to be both rewarding and useful [26] [27] [28] , and developing skills for remote MI-counseling may be critical as remote healthcare services are likely to continue post-COVID-19 [18] .Although the current study provides valuable insights into the experience of HEs during the transition to remote delivery of MI-counseling in a home-based obesity prevention intervention, there are limitations that should be considered when interpreting results. Specifically, this study took place in Guelph, Ontario, Canada and thus all families were exposed to Public Health directives and bylaws that impacted this specific community. Therefore, the experiences of GFHS families and HEs when working with these families are not necessarily generalizable to the broader Canadian or world population. Further, there was a relatively small sample size of families who transitioned to remote visits, and therefore qualitative findings may not be suitable to generalize to the broader population.Our study found that remote delivery of MI counselling was well accepted by families of young children Specific considerations regarding rapport building including more frequent check-ins to demonstrate commitment to the family's success, and effective communication strategies including asking more probing questions that elicit complex reflection can support successful transition of MI-counseling from in-person to remote delivery among families with young children. Healthcare providers should consider these key strategies identified in this paper when transitioning to remote delivery of service.Our practice recommendations such as using an online video platform over phone counseling where possible to elicit better focus and commitment based on key learnings from HEs during the transition from in-person to remote MI-counseling can support healthcare professionals working to transition MI-counseling services to remote delivery.CRediT authorship contribution statement: ",Canada,first author,2021-02-25,02
df5dd7c0d984ae80f3cd3104ad628c0a16026c53,N-Terminal finger stabilizes the reversible feline drug GC376 in SARS-CoV-2 M pro 1 2 3,"In late 2019, a respiratory infection initially detected in China, was sparking fear of a viral 72 outbreak [1] . This respiratory infection attributed to severe acute respiratory syndrome coronavirus 73 2 (SARS-CoV-2), led to an ongoing coronavirus disease 2019 (COVID-19) pandemic with 74 millions infected worldwide (https://coronavirus.jhu.edu/map.html). This respiratory illness was 75 similar to a previous infection by SARS-CoV that led to a SARS outbreak in 2002/3 as well as the 76Middle East respiratory infection (MERS) outbreak in 2012 [2,3]. All of these outbreaks stem from 77 related betacoronavirus infections, suggesting these strains will likely lead to future viral 78 outbreaks. Vaccines have been developed and will be important for prevention of new infections 79 in the future. However, even with a 95% immunity rate, there will be a significant proportion of 80 people worldwide who will require therapeutic treatment. Antiviral development remains a priority 81 because of importance of immediate mitigation of acute infections, vaccine hesitancy, and the 82 inability to vaccinate some individuals. The outbreak of SARS in 2003 and MERS in 2012 along 83 with the current pandemic reminds us that pan-inhibitors may provide a means for initial control 84 of outbreaks, thereby preventing or quickly controlling pandemics in the future [4] . 85 SARS-CoV-2 is a 30-kb positive-sense single-stranded RNA virus that is translated by the 86 host's cellular machinery to generate two alternatively spliced long polypeptides, PP1a and PP1ab. 87These long polypeptides release non-structural proteins (nsps), including the RNA-dependent 88 RNA polymerase, that are essential for viral replication after proteolytic cleavage by proteases 89 from domain nsp3 and nsp5, respectively, a papain-like (PL pro ) protease and a chymotrypsin-like 90 main protease (M pro or 3CL pro ) [5] . Similar to SARS-CoV, the SARS-CoV-2 M pro enzyme 91 recognises the sequence of Leu-Gln↓Ser-Ala-Gly, where ↓ marks the cleavage site and this 92 sequence is widely employed for generation of substrates for kinetic analysis and for development 93 Reversibility was tested by measuring catalytic activity post dialysis. Incubation of SARS-CoV 163 M pro and SARS-CoV-2 M pro with the GC376 followed by dialysis resulted in increase in enzymatic 164 activity over time, indicative of a reversible dissociation of inhibitor (Fig. 3) . We observed a 165 recovery of 10% of activity after 22 hours of dialysis, which reached 30 -40% of initial activity 166 for SARS-CoV and 40-60% for SARS-CoV-2 after 4 days of dialysis, suggesting over time the 167 substrate competed for the enzyme binding site. To ensure the proteins remained stable over this 168 time period, we also monitored the stability of uninhibited enzymes, which was compared with the 169 activity of recovered enzymes. After 4 days the residual protease activity for the uninhibited M pro 170 of SARS-CoV and SARS-CoV-2 was 30-40%, which allowed us to conclude that the drug was 171 fully reversible. 172 173After observing the high kinetic stability of both viral proteases at room temperature, we 175 characterized their thermal stability and assessed their thermodynamic parameters including 176 activation energies of inactivation. Thermal stability is a characteristic used to describe the kinetic 177 stability of enzymes, and many individual proteins or protein complexes are known to have high 178 kinetic stability [27] [28] [29] [30] [31] . For viral proteins, particularly the structural ones, this feature is crucial 179 because virus particles must be able to resist harsh environmental conditions until they find a new 180 host to infect and also remain stable during infection [10,13,32]. For example, determination of 181 thermodynamic parameters of the HIV protease in the presence of various inhibitors was used to 182 reveal the differences in protein stability upon forming inhibitor-protein complexes, which 183 informed on inhibitor design [33] . 184Thermal inactivation of SARS-CoV M pro (Fig 4A and 4B ) and SARS-CoV-2 M pro (Fig 4D  185 and 4F) was studied at the temperature range of 24-70 º C in a time-dependant manner. The 186 semilogarithmic plots of residual activity versus incubation time were linear at all temperatures 187 for both proteins, which was indicative of a simple first-order monophasic kinetic process. From 188 the slopes of semilogarithmic plots inactivation rate constants were calculated and are given in 189 Table 2 . For both proteases, the rate constant progressively increased with increasing temperatures 190 whereas half-life (t1/2) and the decimal reduction time (Dt), two important parameters used in 191 characterization of enzyme stability, decreased. 192The dependence of inactivation rate constants on temperature was plotted using the 193 Arrhenius equation (Fig 4C and 4F) , from which apparent activation energies of inactivation (Ea) 194 were calculated. Interestingly, Arrhenius plots for both proteases were not linear and showed 195 upward curvature suggesting two denaturation processes each with its own temperature 196 dependence and activation energy. At temperatures above 37 º C inactivation is a result of protein 197 unfolding with high activation energy, with the rate of this process strongly dependant on 198 temperature. At temperatures of 37 º C and below this rate becomes insignificant and other 199 processes with low activation energy prevail. The activation energies for the high temperature 200 range were found to be high and similar for SARS-CoV M pro (Ea=243.6 kJ/mol) and SARS-CoV-201 2 M pro (Ea=234.2 kJ/mol). However, for the low temperature range the activation energies were 202 10-20% of those determined at high temperature, confirming that M pro inactivation involves both 203 high-and low-activation energy processes. Interestingly, the parameters of the inactivation process 204 at low temperature range (24-37 º C) are different for M pro from SARS-CoV and SARS-CoV-2, 205showing Ea of 16.4 kJ/mol and 41.4 kJ/mol and t1/2 (at 24 º C) of 38.5 h and 57.7 h respectively, 206 suggesting higher stability for SARS-CoV M pro . 207Determination of all thermodynamic parameters of inactivation can provide further 208 information on enzyme stability. ΔG value, the Gibbs free energy, which is the energy barrier for 209 enzyme inactivation, is directly related to protein stability. We see a significant decrease in ΔG for 210 the temperatures above 55 º C indicating that the destabilization process occurs rapidly in this 211 temperature range ( Table 2) . 212To gain a deeper insight into the driving forces of SARS-CoV M pro and SARS-CoV-2 M pro 213 stability, the Gibbs free energy was decomposed into its enthalpic and entropic contributions. 214Enthalpy, ΔH, measures the number of non-covalent bonds broken during transition state 215 formation for enzyme inactivation, allowing us to compare the energy landscapes of both SARS-216CoV M pro and SARS-CoV-2 M pro . For temperature ranging from 37 º C to 70 º C we observed 217 consistent high ΔH values, which is in agreement with a temperature-dependent inactivation 218 process. Interestingly, at the 24 º C and 37 º C temperature interval a significant jump in ΔH occured 219 for both proteases, however, with different initial enthalpy values for SARS-CoV M pro and SARS-220CoV-2 M pro at 24 º C (13.9 and 38.9 kJ/mol respectively), again highlighting higher stability of 221 latter at physiological temperatures ( Table 2 ). The compactness in the protein molecular structure 222 as well as enzyme and solvent disorder can be inferred through the quantitative analysis of entropy 223 ΔS values [34, 35] . Small negative entropy values at 24 º C for both SARS-CoV M pro and SARS-224CoV-2 M pro confirmed no disorder in protein structure upon inactivation; however, at higher 225 temperatures all values of ΔS were positive and similar, suggesting that unfolding is a rate-limiting 226 step at this range ( Table 2) . 227 228We previously reported increased catalytic activity of SARS-CoV-2 M pro in comparison to 230 SARS-CoV M pro with the catalytic turnover rate being almost 5 times higher for the former using 231 a FRET-peptide as substrate [13] . We were interested in structural comparison of the M pro from 232 SARS-CoV and SARS-CoV-2, for both apo and drug-bound forms to reveal differences that 233 account for the enhancement in activity. Crystal structures of apo-M pro from SARS-CoV and 234 SARS-CoV-2, and bisulphite prodrug (GC376) and the aldehyde drug (GC373) bound forms were 235 determined. The two proteins share 96% sequence identity with only 12 out of 306 residues being 236 different (S1 Fig) . Therefore, as expected, there is little change in the overall structures of apo-237 SARS-CoV and SARS-CoV-2 M pro (Fig 5) , with an RMSD of 0.6 Å. We observed a new helical 238 feature at ƞ2 (residues 47-50) in SARS-CoV-2, which is unfolded in SARS-CoV, (S1 and S2 Fig) . analysis of the biological dimer of the two proteases revealed that the main differences are located 246 at the dimer interface. In the M pro of SARS-CoV-2, we observed a slight shift of the chymotrypsin-247 like domains away from each other, compared to the M pro of SARS-CoV (Fig 5B) . However, the 248 biggest change is the difference in association between the dimerization domains (Fig 5C and  249   5D ). The dimer interface of SARS-CoV and SARS-CoV-2 M pro is facilitated by several 250 interactions between the two protomers, one of which is between the helical domain III of each 251 protomer comprising of residues 284-286, specifically Ser-Thr-Ile (STI) in SARS-CoV M pro and 252Ser-Ala-Leu (SAL) in SARS-CoV-2 M pro . This unstructured loop self-associates between 253 protomers in the dimer. Importantly, this region harbors a non-conservative residue in sequence at 254 the dimer interface, where the Thr285 in SARS-CoV M pro is altered to Ala285 in SARS-CoV-2 255 M pro (Fig 5E and 5F ). The SAL-motif forms a tight van der Waals interaction and the residues 256 from each protomer interdigitate to form a complementary interface that readily explains the 257 observed enhanced stability. 258We recently presented the structure of GC373 with the SARS-CoV-2 M pro [13]. The 262 structure of SARS-CoV-2 M pro with drug GC373, as well as prodrug GC376 that converts to 263 GC373, reflects the specificity of the enzyme for a glutamine surrogate in the P1 position and a 264 leucine, which is preferred in the P2 position. A benzyl group is in the P3 position. Here we 265 determined the crystal structure of the SARS-CoV M pro with the prodrug GC376 and drug GC373 266 to examine features that determine its efficacy and compare this with the previously determined 267 SARS-CoV-2 structure (Fig 6) . 268 SARS-CoV M pro was incubated with GC373 and GC376, prior to crystallization. The best 269 crystals diffracted to 2.0 Å, and the data was refined with good statistics (Table 3) . Overall 270 comparison of SARS-CoV M pro and SARS-CoV-2 M pro structures with GC373 showed similar 271 agreements with the apo-M pro structures, with an RMSD of 0.6 Å (Fig 6) . The drug binding is 272 supported by H-bonding with the main chain of oxyanion hole residues Asn142, Gly143 and 273 Ser144, which are identical for both proteases (Fig 6B, S4 Fig and S5 Fig) . A good fit was 274 observed for both the P1 and P2 positions, supported structurally by hydrogen bonding and van 275 der Waals interactions respectively with H-bonds for the P1 position being identical for M pro from 276 SARS-CoV and SARS-CoV-2 (Fig 6C, S4 Fig and S5 Fig) . CoV-2 M pro and SARS-CoV M pro , we observe the N-termini interact with residues near S1 283 substrate-binding subsite in a hairpin adjacent to the oxyanion hole of the active site (Fig 7) . (Fig. 8) , likely 291 adding to its increased catalytic activity. The proper conformation of S1 pocket is also important 292 for the drug binding and importantly, P1 position of GC373 is also stabilized by hydrogen bonding 293 between the side chain of Glu166 (3.3 Å) and backbone carbonyl of Phe140 (3.3 Å) residues (Fig  294   8) . Thus, a hydrogen bond network between the dimer in M pro stabilizes the S1 substrate for 295 substrate binding and hence inhibitor binding. CoV-2 M pro are very similar, however, one key change at the domain III interface, namely 338Thr285Ala in SARS-CoV-2 M pro , results in a significant alteration in the distance between the 339 domains of the protomers in the SARS-CoV-2 M pro dimer compared to SARS-CoV M pro (Fig 5) . 340This mutation leads to residues in the domain III interface forming a hydrophobic zipper clearly 341 aligning the two domains, and thus likely enhancing the t1/2 at low temperatures as we have 342 observed above. The high degree of stability of the enzymes for both SARS-CoV and SARS-CoV-343 2 is an interesting feature that likely contributes to viral potency. 344Another structural feature that might explain the increased activity and stability is a closer 345 association between the N-finger Ser1 and Phe140 in the oxyanion loop in the M pro of SARS-CoV-346 2 compared to SARS-CoV (Fig 8) . This interaction plays a critical role for activity since it sustains 347 the correct conformation of the oxyanion loop, therefore precise coordination of the N-finger in We demonstrated that the NH group of Ser 1 donates H-bonds to Phe140 and Glu166, the 360 residues that coordinate the N-termini of each protomer in the dimer. Importantly, these residues 361 also interact with the P1 position of GC373 in both SARS-CoV and SARS-CoV-2, demonstrating 362 a strong hydrogen bond network near the active site, and stabilization of the S1 subsite pocket. The 13 C-labelled GC376 inhibitor was synthesized according to previously documented 422 procedures, and initial HSQC NMR experiments involving only enzyme, only inhibitor, and both 423 co-incubated were prepared as previously described [13] . The sample used for the reversibility 424 experiment was prepared by subjecting a previously co-incubated sample containing both enzyme 425 and inhibitor to washing steps with buffer (D2O, 50 mM phosphate, pD 7.5 with 20 mM DTT). 426This involved depositing the sample in an Amicon micro-spinfilter with a 10 kDa cutoff and 427 spinning down the sample at 6600 g for 15 min. The sample was then diluted to 300 µL and the 428 spin down and dilution steps were repeated once more, to a final volume of 300 µL. This sample 429 was then analyzed by NMR in an HSQC experiment, following protocols identical to those 430 previously described [13] . 431 432Reversibility of 3CL protease inhibition with GC376 was determined by dialysis method. The 434 proteases were incubated with a single concentration (20 µM) of the GC376 compound for 15 min 435 at RT to allow for full inhibition. Then the enzyme-inhibitor mixture was placed in a 6-8 kDa 436 MWCO dialysis membrane (Fisher Scientific, Canada) and dialyzed against 2 L of 50 mM Tris-437 HCl, pH 7.8, 150 mM NaCl, 5% glycerol, 1mM DTT at RT. The dialysis buffer was changed every 438 24 hours. Control experiments, which included dialyzing apo-proteases at the same concentration 439 in the same dialysis buffer but different beakers, were performed simultaneously. The aliquots of 440 dialyzing samples were taken out at certain time points and used for activity measurements. The 441 data was represented as a percent of initial protease activity at a zero time point. 442The thermal stability was determined by heating 2 µM solution of M pro SARS CoV or M pro SARS-443CoV-2 in 50 mM Tris-HCl, pH 7.8, 150 mM NaCl, 5% glycerol, 1mM DTT buffer in a 444 thermostatted water-bath at various temperatures. 30 µl protein samples were taken out at specific 445 time points and immediately incubated on ice until activity measurements were performed as 446 described above. Residual activities were expressed as relative to the maximal activity, which was 447 the activity of proteases at zero time point. 448The enzyme inactivation over time is described by a first-order equation: 449where A represents enzyme activity at time t, A0 is the initial activity at time zero, k is the rate 451 constant (min −1 ), and t is time (min). Inactivation rate constants (kd) were obtained from slopes of 452 semi-logarithmical plots of residual activity versus incubation time at each temperature. Calculated 453 rate constants were replotted in Arrhenius plots as natural logarithms of k versus the reciprocal of 454 absolute temperature. Arrhenius law describes the temperature dependence of rate constant as 455where Ea is the activation energy, R is the universal gas constant (8.31 J mol -1 K -1 ), and T is the 457 absolute temperature. Ea was calculated from the slope of Arrhenius plot. 458The half-life of proteases (t1/2), defined as time after which activity is reduced to 50% of initial 459 value [46] , was determined as 460Another common way to present inactivation rate is as D value -decimal reduction time, which is 462 the time required to reduce activity to 10% of the original value and calculated as: ",Canada,first author,2021-02-16,02
ec628ce597cd6e279713416a4782a1e67700fb51,CD8+ T cell responses in COVID-19 convalescent individuals target conserved epitopes from multiple prominent SARS-CoV-2 circulating variants,"Due to the proofreading ability of the coronavirus (CoV) RNA-dependent RNA polymerase, the evolution of the global SARS-CoV-2 viral population during the current pandemic has been relatively constrained as compared to other endemic RNA viruses that do not possess this ability [1] . However, during late 2020, three distinct variants that each possessed a significantly increased amount of amino acid polymorphisms were identified in association with spikes in cases of COVID-19 in the United Kingdom [2] [3] [4] .These variants all possess the N501Y mutation in the receptor-binding domain (RBD) of the SARS-CoV-2 spike protein, a primary target for neutralizing antibody (NAb) binding. They also all contain unique additional mutations throughout the genome, and are not phylogenetically linked, indicating that they evolved independently (Table S1 ). Due in part to the mutations found in the RBD and other areas of the spike protein, these primary viral variants, or pseudoviruses expressing the combination of polymorphisms found in each variant, have been examined for their sensitivity to NAb responses detected in plasmas from COVID-19 convalescent donors, preclinical or clinical trial post-vaccination plasmas, and monoclonal antibodies [4] [5] [6] [7] . These studies have shown that the variants are variably susceptible to neutralization, with B.1.1.7 exhibiting only minor decreases in susceptibility to convalescent and post-vaccination plasma. In addition, preliminary press reports from ongoing Phase 2b/3 vaccine trials performed in the United Kingdom during the rise of B.1.1.7 suggest that the efficacy of spike-based vaccines has not diminished significantly; however, these studies have not been published or peer-reviewed. Conversely, the B.1.351 variant has demonstrated a significant increase in resistance to neutralization by some individuals' convalescent plasma, as well as a decline in neutralization potential for the mRNA based vaccine induced NAb responses; although it should be noted that this neutralization potential was still estimated to be high enough to confer complete protection [4] [5] [6] [7] . Of greater concern, two ongoing Phase 2/3 vaccine trials of a recombinant protein-based and an Adenovirus-based vaccine have reported a slight decrease in efficacy of the vaccines in preventing symptomatic COVID-19 in South Africa where the infections were predominantly caused by B.1.351. These data have not been published or independently reviewed. Interestingly, these same reports claimed that there was no difference in the effectiveness of the vaccines to prevent serious illness between the two countries, suggesting that while protection from initial infection may be somewhat hindered, the vaccines ability to prevent further disease progression is preserved.Previously, our group reported a detailed analysis of the CD8+ T cell epitopes and cytokine responses to the original strain of SARS-CoV-2 in a collection of convalescent individuals from North America with varying levels of disease and NAb responses [8] . This earlier report identified a broad CD8+ T cell response in these individuals with virtually all subjects having detectable responses to several viral epitopes.Detailed methods of the previous study have been previously published [8] . Figure S1 ; Table S1 ).This study was approved by the Johns Hopkins Institutional Review Board, and all participants provided informed consent.for use under a CC0 license.Of all the mapped mutations, insertions, and deletions (n=45), only one mutation was found to fall within one of the 52 unique epitopes identified in the previous study (Fig 1, S1 ). This mutation is the D80A mutation in the viral Spike protein, and occurs in the third residue of the RFDNPVLPF epitope. This is a HLA*A24:02-restricted epitope for which a CD8+ T cell response was detected in only one individual, and at a low frequency, indicating this is not a high-prevalence epitope within the studied cross-sectional sample. As the global SARS-CoV-2 pandemic continues, it is inevitable that new viral variants will emerge.Many of these variants will disappear unnoticed due to a combination of incomplete or non-existent genotypic surveillance, changes that have deleterious impact on viral fitness, and conditions that do not promote their further spread in the population. However, some variants, like the three examined here, will for use under a CC0 license.It should be noted that this study had several limitations including the relatively small size of the population examined. In addition, the participants in the study were all from North America and were selected in part on the presence of one or more of the target HLA types examined (73% coverage of the continental US population). It will be important to examine for T cell escape in more diverse HLA types moving forward.",USA,first author,2021-02-15,02
8f260642a219fe5f7e71cabab32cff7c8e8897b8,Modeling the Effect of Population-Wide Vaccination on the Evolution of COVID-19 Epidemic in Canada,"BioNTech's COVID-19 vaccine on December 14, 2020, kicking off the largest immunization campaign in the country's history. Obviously, the vaccination campaign comes at a cost, but it is crystal clear that saving human lives is priceless. In an analysis conducted by Quadrant Health Economics for Moderna [21] it was stated that a ""cost-conscious payer should be willing to pay up to $300 for a COVID-19 vaccination course with an efficacy of only 60%"". According to a study, which considers direct medical costs and productivity losses due to COVID-19, the PHICOR group at CUNY, claims that if the vaccine were to only reduce the risk of severe disease, it would be cost saving up to $200 − $800 for the two-dose regimen, depending on the vaccine efficacy [19] . Some politicians have also tossed the idea of paying people to get vaccinated. For instance, as reported in [39] , a former US congressman suggested paying $1, 500 to every adult with a proof of vaccination, which will cost approximately $383 Billion if every adult took advantage of this program. He also claims that this program is worth the cost because it would save lives and accelerate the reopening of the economy. As per [39] , the policy of paying people for COVID-19 vaccination should be adopted only in the worst case scenario where the number of voluntary vaccinated people is insufficient to promote herd immunity within a reasonable period of time [22] .A legitimate question that one may ask is what is the best vaccination strategy that healthcare policymakers should implement and how this vaccination strategy would impact the evolution of the COVID- 19 pandemic. To answer this question, we developed a new mathematical prediction model referred to as the SIRV model, with Susceptible (S), Infected (I), Removed (R) and effectively-Vaccinated (V) compartments. This model, incorporating the daily-vaccination rate and the vaccine efficacy as control inputs, allows to predict the evolution of COVID-19 epidemic under the influence of the vaccination. We consider the most effective and easy-to-implement vaccination strategy, which consists of a vaccination campaign at a maximum possible daily rate over a given time-horizon. We then use our SIRV model to predict the evolution of the pandemic, for different vaccination rates and vaccine efficacy, in Canada and its most affected provinces (Ontario, Quebec, British Columbia, Alberta, Saskatchewan, and Manitoba). Note that several predictive mathematical models for epidemics, with different levels of sophistication, have been proposed or used in the literature, see for instance [1, 6, 4] and references therein. Epidemiological models incorporating the effect of vaccination have been also studied in different contexts [5, 2, 3] . Recent studies that focus on modelling and prediction of the ongoing COVID-19 pandemic can be found, for instance, in [23, 44, 17, 7 , 42] but do not consider the effect of vaccination. We find it timely and important to propose a prediction approach to asses the outcomes of COVID-19 pandemic under the effect of population-wide vaccination and vaccine efficacy. Of course, our approach can be extended to other existing models to reflect the impact of the vaccination on the outcome of the predicted variables. Moreover, we believe that our proposed model is suitable for future studies on vaccine efficacy when abundant and consistent vaccination data becomes available.This work provides an assessment of the epidemiological trends of the COVID-19 pandemic in Canada and its most affected provinces, under the influence of vaccination. Our predictions are based on our newly developed mathematical model that takes into account the daily vaccination rates and vaccine efficacy as detailed in the Methods section. Our proposed prediction model, referred to as SIRV, is an extended version of the SIR model with a new state V representing the effectively vaccinated sub-population, and two inputs consisting of the daily-vaccination rate u and the vaccination efficacy α. The total population is partitioned into 4 sub-populations: S, susceptible (non-infected without immunity); I, infected (active cases); R, removed (closed cases, recovered or dead); V , effectively vaccinated (non-infected individuals that were effectively vaccinated, immune). In our results, the daily vaccination rates used for our epidemic predictions represent the daily vaccination rate of fully vaccinated individuals (i.e., non-infected individuals that received the two doses of the vaccine).We would like to recall that the infection rate is tightly dependent on the safety measures implemented such as lock-downs, social distancing, face covering, hygiene, quarantine,...,etc. Our predictions are based on the assumption that the current infection rate is constant and, therefore, the aforementioned results could be much worse if these measures are to be weakened even in the presence of the vaccine.Canadian provinces. The heavy victim toll, caused by COVID-19 in Canada, would be unevenly distributed between the provinces across the country as shown in Table 1 and Table 2. The highest maximum daily deaths per million will be recorded in Manitoba (112.4) at the pandemic peak which will occur in late March 2021. The lowest maximum daily deaths per million will be recorded in Ontario (17.96) at the pandemic peak which will occur in late July 2021. The highest demand for ICU beds needed at the pandemic peak will be recorded in Saskatchewan (522.3 beds per million) in early to mid July 2021. This may be due to the fact that this province has the highest reproduction number and the lowest removal rate among all the provinces. The lowest ICU beds needed at the peak time will be recorded in Quebec (130 beds per million) in late June 2021. This may be due to the relatively low reproduction number and relatively high removal rate of this province. Scenario 2 (low vaccination rate with 95% vaccine efficacy): At a daily vaccination rate 1/2 vaccine per 1, 000 population, our models predicts better outcomes than the scenario without vaccinations. The trends remain similar in terms of the provinces that will have the highest and lowest burdens in terms of the maximum daily mortality and ICU beds needed at the peak times. In this scenario, the cumulative deaths that will be recorded, up to the end of this year, will toll 33, 688 in Ontario (43.4% saved lives with respect to Scenario 1) and 30, 416 in Quebec (36.9% saved lives with respect to Scenario 1). Scenario 3 (Moderate vaccination rate with 95% vaccine efficacy): At a daily vaccination rate of 1 vaccine per 1, 000 population, our models predicts better outcomes than scenario 2. The trends remain similar in terms of the provinces that will have the highest and lowest burdens in terms of the maximum daily mortality and ICU beds needed at the peak times. In this scenario, the cumulative deaths that will be recorded, up to the end of this year, will toll 20, 431 in Ontario (65.7% saved lives with respect to Scenario 1) and 21, 020 in Quebec (56.4% saved lives with respect to Scenario 1). Scenario 4 (High vaccination rate with 95% vaccine efficacy): At a daily vaccination rate of 2 vaccines per 1, 000 population, our models predicts better outcomes the previous scenarios. The trends remain similar in terms of the provinces that will have the highest and lowest burdens in terms of the maximum daily mortality and ICU beds needed at the peak times. In this scenario, the cumulative deaths that will be recorded, up to the end of this year, will toll 11, 321 in Ontario (81% saved lives with respect to Scenario 1) and 13, 582 in Quebec (71.8% saved lives with respect to Scenario 1).One of the earliest and well-studied mathematical models for the prediction of humanto-human propagation of infectious diseases across population is the SIR model [1] . This model relies on the time-evolution of three state variables: susceptible (S), infected (I) and removed (R). In this work, we develop a new SIRV model which extends the standard SIR model by adding the effectively vaccinated population V (t) as a state variable and the dailyvaccination rate u(t) and the vaccine efficacy α ∈ (0, 1] as control inputs. This model relies on the principle that the susceptible population rate at time t will, instantaneously, decrease by αu(t) corresponding the efficacy-weighted vaccination rate. Of course, this model can be refined further by incorporating the delay between the time the vaccine was administered and the time where the vaccine will provide the expected protection and the announced efficacy. This addition was not deemed necessary at this point in time since its impact on our results and conclusions will be insignificant.The extended SIR model with vaccination rate and vaccine efficacy inputs is depicted in Figure 1 and can be mathematically described as follows:where the model state variables and parameters are defined as:• S(t): represents the susceptible sub-population at time t. These are individuals not yet infected with the disease at time t and do not have an immunity against a potential infection.• R(t): represents the removed sub-population at time t (a.k.a. closed cases). These are individuals who have been infected and then removed from the disease, either due to being recovered or dead.• V (t): represents the effectively vaccinated sub-population at time t. These are individuals who have received the vaccine and have gained full immunity against the infection. Note that not all vaccinated people become necessarily immune.• β: denotes the infection (transmission) rate. It represents the number of contacts per capita per unit time, multiplied by the probability of disease transmission in a contact between a susceptible and an infectious individual. This parameter can be modified, for example, by social-distancing and lockdowns.• γ: denotes the removal rate which is the fraction of infected sub-population that is leaving the infection stage, at time t, to enter the removed stage. The quantity 1/γ represents the average infectious period.• α: denotes the vaccine efficacy. It represents the ratio between the number of individuals who have received the vaccine and acquired full immunity against the disease and the total number of vaccinated sub-population.• u(t): denotes the daily vaccination rate. It represents the number of vaccines administered at time t.By November 6, 2020, there were only 17 reasonably well demonstrated cases of SARS-CoV-2 reinfection worldwide confirmed by RT-PCR and viral sequencing [33] which suggests that the reinfection rate value is negligible and can be omitted [31] . Therefore, our model assumes reasonably that the recovered cases are immune and cannot be reinfected. Moreover, our model does not take into account vital dynamics (demographic births and deaths) as these are assumed slowly varying. The total number of population remains constant, i.e.,where N denotes the total number of the studied population. We assume that the cumulative number of deaths at a given time t, denoted D(t), is a fraction of the removed sub-population, i.e.,To fit our model and infer the corresponding model parameters, we used real data provided by the Public Health Agency of Canada (PHAC) from January 30, 2020 to January 8, 2021. However, the collected data was not very reliable and consistent in the early stages of the COVID-19 pandemic due to different logistic factors as well as the fluctuations in the measures taken by the government (social distancing restrictions, quarantine, testing,...etc.) during the first weeks-to-months of the pandemic. Nevertheless, we have observed that the data became more consistent after July 17, 2020 as people got used to the transmissionbarrier measures (face covering, disinfection, social distancing, etc.) and the governmental regulations. Canada has administered the first COVID-19 vaccine (by Pfizer-BioNTech) on December 14, 2020 and since then more than 260, 000 individuals have received the COVID-19 vaccine (up to January 8, 2021) which suggests a vaccination rate of around 10, 000 administered vaccine per day. The 3 weeks data, since the start of the vaccination campaign, is not enough to determine its efficacy α due to the low number of samples as well as the way the vaccine is administered (two shots, three to four weeks apart). This motivated us to considered the efficacy α as a control input in our model. The aforementioned observations and facts have motivated us to consider data samples collected between July 17, 2020 and January 8, 2021 in the estimation of the remaining model parameters β and γ by neglecting the very few vaccinated sub-population up to January 8, 2021, i.e., assuming u(t) = 0 during this period of time.Fitting the model (1)- (3), to the COVID-19 epidemic data consists in finding the best pair of parameters (β, γ) that minimizes the root-mean-square error (RMSE) between the predicted state variables and their measured values. First, we note that dividing equation (1) by (3) and integrating both sides between two time instants t s (data start date) and t e (data end date), yields the following formula:The integral in the right hand side of the above equation is calculated using the trapezoidal integration rule. The removal rate γ is obtained by minimizing the sum of the squares of the errors between the true values of R(t) − R(t s ) (from the data) and the ones predicted by the model, i.e., the integral in (8) . The infection rate β is obtained from β = R 0 γ. An important challenge in tuning the model is that the initial data are affected by statistical distortion and, therefore, the model fitting process must take this problem into account. For this reason, the aforementioned obtained values of β and γ are further refined using a nonlinear programming solver that takes these values as initial conditions and searches for the best values that minimize the RMSE between the real data and the predicted samples (best-fit approach). The final estimated parameters (for Canada) are β = 0.0976, γ = 0.0781, and R 0 = 1.25 with a (normalized) RMSE = 4.5 × 10 −4 . We also perform another linear regression to determine the mortality rate µ from the relation in equation (6), which is found to be µ = 0.0164. The predicted data from the model and the real data are plotted in Fig. 9 . The fitting process was also conducted for the six worst affected provinces: Ontario, Quebec, British Columbia, Alberta, Saskatchewan, and Manitoba. The parameter estimates for each of these provinces are reported in Table 3 while the comparisons between the predicted data from the model and the real data for each province are reported in Figures 10-15 . The estimated population number N for each province is taken from Statistics Canada [12] . Finally, according to the Public Health Infobase (https://health-infobase.canada.ca/COVID-19/ epidemiological-summary-COVID-19-cases.html) 5.5% of the COVID-19 cases needed hospitilization and around 1% of them were admitted to the Intensive Care Unit (ICU). We therefore used the a rate of 1% from the active cases when calculating the ICU beds needed at the peak time, as reported in Table 1 and Table 2 .where u max is the maximum population that can be vaccinated per day (maximum vaccination rate). Based on our proposed SIRV model (1)-(4) under the control input (9), we studied the effect of the daily vaccination rate on the evolution of the COVID-19 pandemic in Canada and its most affected provinces and the results are discussed in the Results section. This is done by integrating the nonlinear dynamics (1)-(4) using forward Euler method with a step size equals 1 hour (1/24 days). The initial states (on July 17, 2020) can be read from the first row of the data table in the Source data. The states are propagated, using the estimated parameters as discussed in Section 3.2 and shown in Fig. 9 , from July 17, 2020 to January 8, 2021 under no vaccination input and the effect of vaccination is then introduced on January 8, 2021.The code used for the predictions reported in this work is publicly available online (http:// flash.lakeheadu.ca/~tayebi/SIRV_code/). Analyses were carried out using MATLAB version R2020b, Curve Fitting Toolbox version 3.5.12, Signal Processing Toolbox version 8.5, and Statistics and Machine Learning Toolbox version 12.0.[11] David R Boulware et al. ""A randomized trial of hydroxychloroquine as postexposure prophylaxis for Covid-19"". In: New England Journal of Medicine 383.6 (2020), pp. 517-525.",Canada,abstract,2021-02-08,02
fb3464c5536d253b3b0048ccd69c3f1de6acd302,COVID-19 Hospitalizations in Five California Hospitals SARS-CoV-2 = Severe Acute Respiratory Syndrome Coronavirus 2,"and/or death) was 27.4% (1,298/4,730) . While controlling for comorbidities, patients of age 75-84 (OR 1.47, 95% CI: 1.11-1.93) and 85-59 (OR 1.39, 95% CI: 1.04-1.87) were more likely to experience a composite outcome than 18-34 year-olds. Males (OR 1.39, 95% CI: 1.21-1.59), and patients identifying as Hispanic/Latino (OR 1.35, 95% CI: 1.14-1.61), and Asian (OR 1.43, 95% CI: 1.23-1.82), were also more likely to experience a composite outcome than White. Patients with 5 or more comorbidities were exceedingly likely to experience a composite outcome (OR 2.74, 95% CI: 2.32-3.25).Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), the virus causing coronavirus disease 2019 has been a devastating pandemic, with over 91 million confirmed cases and nearly 2 million deaths worldwide. 1 In the United States, the state of California (hereafter referred to as CA) leads the charts for the worse surge across the nation, with a total of 70,561 confirmed cases per million residents, 1,176 confirmed deaths per million residents, and potentially 1,173 ICU beds available for a population of nearly 40 million (January 12, 2021).Advanced age, chronic underlying conditions (including hypertension, diabetes, chronic kidney disease, among others), and being male are associated with an increased risk of hospitalization and death from There is additional, mounting evidence that some racial and ethnic minority groups are at disproportionate risk. 3, 5, 6, 11 Nation-wide, the Black/African American, Hispanic/Latino, Asian, and American Indian/Alaskan Native (AIAN) populations have seen elevated crude rates of infection, hospitalization, and/or mortality compared to the White population. 15 In trends similar to other states, estimates from CA indicate that the Hispanic/Latino population make up 55% of confirmed cases and 47% of deaths and only 39% of the total population the Black/African American population represent 4% of confirmed cases and 7% of deaths and only 6% of the total population; and the Asian population represent 7% of all cases but 12% of all deaths. Multiple informal analyses report that Asians have low rates of confirmed cases but concerningly high case fatality rates, 16 but few studies have been large enough to capture associated risk factors in this population.More diverse, localized information is needed about who is being hospitalized with COVID-19and their outcomes in the United States, and California in particular, especially since the second All rights reserved. No reuse allowed without permission.In this retrospective cohort study, we identified patients who were hospitalized with laboratoryconfirmed SARS-CoV-2 infections at any of the five UC Health hospitals between December 13, 2019 and January 6, 2021 by extracting electronic medical records (EMRs) from The COVID Research Data Set (CORDS). The index date corresponds to the first confirmed COVID-19 diagnosis. A hospitalization was included if test confirmation occurred within 21 days or during an inpatient admission. SARS-CoV-2 positive status was determined by PCR or SNOMED code 840539006 (Disease caused by Severe acute respiratory syndrome coronavirus 2) during their earliest hospitalization (Supplemental eTable 1).Patient characteristics, including race/ethnicity, sex, comorbidities, and clinical outcomes were collected. Data was queried on January 8, 2021 and tabulated by January 10, 2021. We captured comorbidities using the International Statistical Classification of Diseases and Related Health Problems, Tenth Revision (ICD-10) classification (Supplemental eTable 2). Self-identified race/ethnicity was categorized into White, Hispanic/Latino, Black/African American, and Asian;Other includes AIAN (n=9, 0.19%), Native Hawaiian or Other Pacific Islander (n=53, 1.12%), Other (n=169, 3.57%), Unknown (n=246, 5.20%), and those that identified with multiple race/ethnicity (n=46, 0.97%).All rights reserved. No reuse allowed without permission.Univariate and multivariable logistic regression was used to estimate the risk of admission to the ICU, in-hospital mortality, and the composite outcome of ICU admission and/or death during the hospitalization. The multivariable model adjusted for age in years at admission, sex, and race/ethnicity. Odds Ratios (OR) and 95% confidence intervals (95% CI) were reported. All rights reserved. No reuse allowed without permission.We described patterns in cumulative hospitalizations during the study period over time by using change-point analysis to discern specific time points where abrupt changes in the mean occurred.This algorithm detects multiple points of change in time-ordered data through binary segmentation. 18-20 First, we applied a change-point statistical test to the entire time series of hospitalization cases. Then, we split the series into two new ones when a point change was found. We repeated this procedure several times until there were no further significant change points. Statistical analyses was conducted using SAS software, version 9.4 (SAS Institute, Cary, NC, USA), changepoint package (binary segmentation algorithm) in R version 4.0.1 (R CoreTeam 2020), and Python. Data were analyzed from January 8 to January 20, 2021.All rights reserved. No reuse allowed without permission.A total of 4,730 hospitalized patients with positive SARS-CoV-2 assays were included (median age 61 years, IQR: 46-73) ( Table 1) . 56.4% were male; one patient was missing sex data. A total of 339 (7.2%) identified as Black/African American, 2,161 (45.7%) as Hispanic/Latino, 489 (10.3%) as Asian, 523 (11.1%) were documented as Other/Unknown, and 1,218 (25.8%) identified as White. A moderate fraction of patients did not have documented comorbidities (n=1,806, 38.2%). The most common comorbidities were hypertension (35.2%), cardiac disease (33.3%), diabetes (24.0%), pulmonary disease (17.8%), obesity (17.3%), and renal failure (15.3%). Coagulopathy (11.8%), smoking (10.2%), depression (9.4%), liver disease (8.8%), and cerebrovascular disease (7.8%) were also reported. Among the possible 22 comorbidities documented for each individual patient, we found that 457 (9.7%) patients had one, 488 (10.2%) had two, 468 (9.9%) had three, 430 (9.1%) had four, 355 (7.5%) had five, and 726 (15.4%) had six or more comorbidities.We quantified the network of comorbidities and visualized correlations that were positive and significant by linking chronic conditions in a visual network (Figure 1 ). Figure 1A displays correlations across the total cohort, of which hypertension and heart disease showed the strongest correlation; Figure 1B displays the correlation network among patients that did not experience a composite outcome; and Figure 1C describes the correlation network of comorbidities for patients that experienced a composite outcome. Figures 1B and 1C together suggest that hypertension, diabetes, cardiac disease, renal failure, neurological disease, and depression, among other diseases, tend to be more comorbid in individuals that experienced a composite All rights reserved. No reuse allowed without permission.We identified 1,194 (25.2%) patients who were admitted to the intensive care unit with confirmed infection with SARS-CoV-2 (Table 1 ). In unadjusted univariate analyses, patients of age 55-74 and 75-84 years were more likely to be admitted to the ICU than 18-44 year-olds, and ICU admission was more likely in male patients than female. Hispanic/Latino, Black/African American, and Asian patients were no more or less likely to be admitted to the ICU once in the hospital than White patients, though Other races/ethnicities were (OR 1.36, 95% CI: 1.08-1.71).Among the common comorbidities, the most likely to be admitted to the ICU were those patients with neurological conditions (OR 2.84, 95% CI: 2.40-3.35), coagulopathy (OR 2.66, 95% CI: All rights reserved. No reuse allowed without permission.Diabetes, hypertension, liver disease, pulmonary disease, renal failure, and a current smoking history also increased the odds of in-hospital mortality.Overall, 27.4% (1,298/4,730) of patients requiring a hospitalization for COVID-19 were admitted in the ICU and/or died during their hospitalization, defined here as a ""composite outcome."" The rate of patients with a composite outcome differed across the five UC Health All rights reserved. No reuse allowed without permission.In this study of 4,730 patients with COVID-19 requiring hospitalization at five hospitals in California, 25.2% were admitted to the ICU, and 7.0% died. Patients were older (20% greater than 75 years), largely Hispanic/Latino (45.7%), with moderate representation of White (25.8%), Asian (10.3%), and Black/African American (7.2%). The 1-year cumulative ICU admission rate for COVID-19 is equitable to previous reports, but the in-hospital mortality rate is smaller than observed in case studies from earlier in course of the pandemic: ICU admission rates ranged from 14.2% to 35.7% in March-May 2020, where mortality rates ranged from 21.0% to 29.1% over the same period. 2, 9, 11, 21 Our study captured the experience of patients hospitalized for COVID-19 in five hospitals in California, across which the rates of composite outcome ranged from 18.2% to 34.2%. The variability of this outcome by hospital is likely influenced by differences in patient severity and treatment practices for COVID-19 across hospital settings, which have evolved throughout 2020, and regional fluctuations in the scope of the pandemic. All rights reserved. No reuse allowed without permission.The associations with older age, comorbidities, and race/ethnicity with poor outcomes linked to COVID-19 hospitalization are largely consistent with previous findings. This study also highlighted the increased risk of poor outcomes in the Asian population of California. In most states and counties, the relatively small proportion of Asian in the population makes awareness of cases and deaths in this community more challenging, as general samples large enough to make conclusions from are difficult to come by. California is one of few states with a sufficiently sizable Asian population for their COVID-19 burden to become unmistakable in the aggregate.There is growing recognition of the burden of COVID-19 among Asian, but data on outcomes among Asian ethnic subgroups remain extremely limited. A recent systematic review and metaanalysis of 50 studies from the US and United Kingdom found higher risk of COVID-19 All rights reserved. No reuse allowed without permission.The composite outcome in this study involved an ICU admission and/or in-hospital mortality, which occurred in 27.5% of patients. We reported rates only for patients who were discharged alive or died during the hospitalization by the end of the study period. 61.8% of patients had 1 or more relevant comorbidities and nearly 23% had 5 or more of these pre-existing conditions, which substantially increased the odds of a poor outcome. Using a network-based approach, we found that hypertension, cardiac disease, diabetes, and renal failure are positively and significantly associated to each other in the overall population, a relationship even more evident in patients with a composite outcome.This study has several limitations. Our findings represent the experience of five hospitals within the UC Health system and therefore may have limited external generalizability to other health care settings, especially outside of California. Since our sample was drawn from electronic medical records and not full chart reviews, our data was also missing reported symptoms and the patients' stated reasons for seeking COVID-19 tests, which could be one or a combination of the presence of COVID-19 symptoms, notification of exposure through contact tracing, or seeking a All rights reserved. No reuse allowed without permission.year of the pandemic. Particularly relevant is the captured experience of Asians hospitalized due to COVID-19, and the differences in demographic characteristics and associations of comorbidities with each other and with poor outcomes.In this study, we found that older patients, with multiple comorbidities, identifying as Hispanic/Latino or Asian were more likely to be admitted to the intensive care unit and/or die during hospitalization at five UC Health medical centers. The overall mortality rate observed is significantly lower than what has been documented in hospitalized patients with COVID-19 from the early stages of the pandemic, despite the reported high levels of comorbidities. These findings provide additional evidence of the impact of COVID-19 in system of hospitals in California. While the comparatively low mortality rate is reassuring, the differential impact on racial/ethnic minorities requires the implementation of an equitable solution.All rights reserved. No reuse allowed without permission.The authors declare that there is no conflict of interest.The Limited Dataset used for this study AUTHOR CONTRIBUTIONS: Dr. Nuño had full access to the limited dataset in the study and takes full responsibility for the integrity of the data and accuracy of the analysis.Concept and Design: Nuño, Rajasekar. Acquisition, analysis, or interpretation: All Authors.Drafting of Manuscript: Nuño, Schmidt.Statistical Analysis: Nuño, García, Pinheiro.All rights reserved. No reuse allowed without permission.. C  e  n  t  e  r  s  f  o  r  D  i  s  e  a  s  e  C  o  n  t  r  o  l  a  n  d  P  r  e  v  e  n  t  i  o  n  .  C  o  r  o  n  a  v  i  r  u  s  D  i  s  e  a  s  e  2  0  1  9  (  C  O  V  I  D  -1  9  )  :   C  a  s  e  s  i  n  t  h  e  U  S  .  h  t  t  p  s  :  /  /  w  w  w  .  c  d  c  .  g  o  v  /  c  o  r  o  n  a  v  i  r  u  s  /  2  0  1  9  -n  c  o  v  /  c  a  s  e  s  -u  p  d  a  t  e  s  /  c  a  s  e  s  -i  n  u  s  .  h  t  m  l  .  P  u  b  l  i  s  h  e  d  M  a  y  2  5  ,  2  0  2  0  .  A  c  c  e  s  s  e  d  M  a  y  2  5  ,  2  0  2  0  .   1  6  .  Z  h  o  u  F  ,  Y  u  T  ,  D  u  R  ,  e  t  a  l  .  C  l  i  n  i  c  a  l  c  o  u  r  s  e  a  n  d  r  i  s  k  f  a  c  t  o  r  s  f  o  r  m  o  r  t  a  l  i  t  y  o  f  a  d  u  l  t  i  n  p  a  t  i  e  n  t Hospitalized for COVID-19 in UC Health Hospitals.All rights reserved. No reuse allowed without permission.All rights reserved. No reuse allowed without permission.",United States,first author,2021-02-01,02
6cf0c85d74e1fdd7414acc66268164e53e98eb2b,Environmentally-induced mdig is a major contributor to the severity of COVID-19 through fostering expression of SARS-CoV-2 receptor NRPs and glycan metabolism,"The global outbreak of COVID-19 caused by the newly identified SARS-CoV-2 virus, is having a devastating impact on both public health and social economics.According to the World Health Organization (WHO), as of January 30, 2021, there had been more than 101 million confirmed cases of COVID-19 worldwide, leading to almost 2.2 million deaths. The SARS-CoV-2 virus has a large number of trimeric spikes (S) on its surface. Each S protein has two subdomains, S1 and S2. Upon direct binding of S1 to the ACE2 on the surface of the host cells, membrane-associated proteases of the host cells, including furin, TMPRSS2, and others, cleave S proteins at the RRAR/S motif located at the S1-S2 boundary, or the motif of PSKR/S, the so-called S2' site, in S2 region, followed by S2-mediated membrane fusion 1, 2 . In addition to ACE2, the C-terminal RRAR motif of the S1 protein from the cleaved S protein may bind to cell surface neuropilin-1 (NRP1) or NRP2 for sufficient viral entry into the host cells [3] [4] [5] . After membrane fusion, the virus is shuttled in the cytoplasm through the endosomes and lysosomes, during which several cathepsin family proteases cleave S proteins further and other viral proteins, leading to the release of the RNA genome of SARS-CoV-2 into the cytoplasm 2 . Indeed, some inhibitors targeting endosome, lysosome or cathepsin, such as ammonia chloride, bafilomycin A and teicoplanin, had been shown to be effective in blocking viral entry in cell-based experiments 2, 6 . The viral RNA genome can hijack the protein translational machinery of the host cells for the expression of viral polyproteins that can be processed to generate replicase, proteases, transcriptases, and other viral structural proteins for assembly of the new virion. Some of these newly generated viral proteins can antagonize the anti-viral responses of the interferon signaling, whereas others are highly capable of activating the inflammasome for cytokine storm and pyroptosis of the host cells in the lung and other organs, leading to an increased likelihood of fatality of the COVID-19 patients 7 .Both S protein and ACE2 are known to be extensively glycosylated through covalently linked oligosaccharides (glycans). It is believed that glycosylation may enhance the infectivity of the virus. Many glycoconjugates on the surface of the host cells are also modified by sialic acid, a specific form of glycosylation--sialylation, which may facilitate membrane fusion of the virus and cells. It is also very likely that alteration in ACE2 and membrane glycan profile may determine the inter-individual variation on the outcomes of viral infection 8 .Human lung is the first line of attack by the SARS-CoV-2 virus. The fatality of COVID-19 has been largely attributed to the massive alveolar damage and progressive respiratory failure resulted from cellular fibromyxoid exudates, formation of hyaline (hyaluronan) membrane, pulmonary oedema, inflammation, and interstitial fibrosis [9] [10] [11] .Most environmental risk factors, such as air pollution and PM2.5, can induce chronic inflammation and make the lung more vulnerable to viral attacks. Indeed, a recent nationwide epidemiological study in the US had shown that an increase of only 1 g/m 3 in PM2.5 is associated with an 8% increase in the COVID-19 death rate, clearly indicating that environmental factors may contribute to the severity of the disease outcomes among individuals with COVID-19 12 . This notion is complementarily supported by the fact that the areas, such as Lombardy, Emilia-Romanga, Piemonte, and Veneto of Italy, and Madrid of Spain, with worse air quality due to higher level of nitrogen dioxide (NO2), are the hardest-hit areas with deaths from COVID-19 13 .The mineral dust-induced gene mdig was first identified in alveolar macrophages from people with chronic lung diseases associated with occupational exposure 14 , and additional studies concluded that mdig can be induced by a number of environmental hazards, such as silica particles, arsenic, tobacco smoke, and PM2.5 14 . This gene was independently discovered as myc-induced nuclear antigen (mina53) and nucleolar protein NO52, respectively. Functional tests suggested that mdig may have hydroxylase activity on ribosomal protein L27a, and accordingly, an alternative name, Riox2, was given 14 .The mdig protein contains a conserved JmjC domain that was considered as a signature motif of the histone demethylase family members. In human bronchial epithelial cells, lung cancer cell line A549, and breast cancer cell line MDA-MB-231 cells, knockout of mdig gene by CRISPR-Cas9 gene editing, resulted in a pronounced enrichment of histone H3 lysine9 trimethylation (H3K9me3) as well as H3K27me3 and H4K20me3 in ChIP-seq analysis, esp. in the gene loci encoding proteins in inflammation and fibrosis, such H19, TGF signaling, collagens, and cell adhesion molecules 15 . Data from mice with heterozygotic deletion of mdig gene indicated that mdig is a master regulator of inflammation and tissue fibrosis 15, 16 . In the present report, we further demonstrated that mdig may exacerbate the severity of COVID-19 in response to environmental exposure.We had used non-cancerous bronchial epithelial cell line BEAS-2B to establish mdig knockout (KO) cells through CRISPR-Cas9 gene editing, and used the cells subjected to gene editing but without mdig depletion as wild type (WT) cells 15 Unexpectedly, six of the twenty-two top-ranked Reactome pathways are centered on protein glycosylation or glycan metabolism, indicating that in addition to ECM, mdig is critical for the post-translational modification of proteins by carbohydrate moieties.A previous study showed that knockout of mdig in BEAS-2B cells caused significant enrichments of H3K9me3, H3K27me3, and H4K20me3 on the merged peak regions as determined by ChIP-seq 15 . Re-analysis of the ChIP-seq data from the WT and mdig KO cells by pairwise Pearson correlation analyses, through plotting the tag numbers of H3K4me3, H3K9me3 and H3K27me3 in the promoter region in mdig KO cells against the corresponding tag numbers in WT cells, revealed a significant enhancement of H3K9me3 and H3K27me3 in gene promoters in mdig KO cells ( Fig. 2A) . Clustered heatmaps as depicted in Fig. 2B suggested that the enrichment of H3K9me3 and H3K27me3 were drastically enhanced in clusters 2 and 3 of the mdig KO cells, while little to no changes in the enrichment of H3K9me3 and H3K27me3 were observed in clusters 1, 4 and 5. The enhanced H3K9me3 in mdig KO cells was also supported by the significantly increased number of H3K9me3 peaks in ChIP-seq. In WT cells, the normalized number of H3K9me3 peaks is 12,094, whereas in KO cells, this number is 32,264 (data not shown). To determine which sets of genes are enriched with H3K9me3 in mdig KO cells, we conducted Reactome pathway assay for those H3K9me3-enriched genes. It is interesting to note that the top-ranked pathways are mostly associated with protein glycosylation and glycan regulation (Fig. 2C ), which is highly correlated to the pathways of the down-regulated genes in RNA-seq of the mdig KO cells (Fig. 1C ). These data, thus, provide an unequivocal evidence indicating that mdig fosters the expression of genes in glycosylation and glycan metabolism through antagonizing the repressive histone methylation marker H3K9me3 as well as H3K27me3.Considering the fact that knockout of mdig reduced cleavage of SARS-CoV-2 spike (S) protein ( Fig.1A) , we narrowed down our analysis of ChIP-seq and RNA-seq data to several key proteins important for S protein binding, intracellular vesicle trafficking and fusion. Upon close examination, we found that genes involved in key aspects of SARS-CoV-2 entry into the host cells, including NRP1, NRP2, DPP4, TMPRSS15, RAB6B, IQGAP2, and others, are enriched with the repressive histone trimethylation marker, H3K9me3 or H3K27me3, along with a decreased expression of these genes as determined by RNA-seq, in mdig KO cells (Fig. 3A ). NRP1 and NRP2 are transmembrane proteins serving as receptors for growth factors and semaphorins. Fig. 1A . Increased level of H3K9me3 was also seen on the gene bodies of CTSE, CTSL1, CTSL3P, and CTSL1P8 in mdig KO cells (Fig. 3B) . Results from RNAseq showed that except CTSF, the expression levels of all other members of the CTS family are significantly declined following mdig knockout (Fig. 3C) . It had been well-documented that CTS members are the dominating proteases for further degradation of SARS-CoV-2 S proteins in lysosomes 20, 21 , which is essential for the release of the viral RNA genome into the cytoplasm.Glycosylation creates great structural and functional diversity of the target proteins.During SARS-CoV-2 infection, glycosylation of the viral proteins is essential for the assembly of the virion and is able to shield the virus from the host immune response. One of the major glycosylation pathways is the hexosamine biosynthetic pathway (HBP) from glycolytic metabolism of the glucose, which generates uridine diphosphate Nacetylglucosamine (UDP-GlcNAc), the founding molecule for N-and O-glycosylation, sialylation, formation of hyaluronan, and biosynthesis of glycosylposphatidylinosital (GPI) (Fig. 4A ). In the mdig KO cells, we observed a strong enrichment of the repressive histone marker, H3K9me3, on the genes in this pathway, such as ST3GAL1 (Fig. 4B ) and HAS3 ( Fig. 4C ). RNA-seq confirmed a decreased expression of these two genes and other genes as indicated in Fig. 4A . Interestingly, most of the GalNAc kinases (GALs) that exhibited increased enrichment of H3K9me3 or H3K27me3 in ChIP-seq, are downregulated as determined by RNA-seq in the mdig KO cells (Fig. 4D) . Accordingly, we believe that in the normal cells, induction of mdig will enforce the overall glycosylation for both viral and host cell proteins.Inflammatory cytokine storm is the most important mortality factor of COVID-19 patients. Our recently published data demonstrated that mdig controls the expression of genes involved in inflammation, including TGF signaling, collagens and cell adhesion molecules 14, 15 . In addition, heterzygotic knockout of mdig in mice ameliorated silicainduced lung fibrosis along with a significant decrease of Th17 cell and macrophage infiltration into the lung interstitium 15, 16 . Re-analyzing of the ChIP-seq and RNA-seq data from the WT and mdig KO cells further unraveled that mdig regulates a wide spectrum of inflammatory genes, such as several receptor genes for IL17 and IL1 (Figs. 5A and 5B).Knockout of mdig caused an elevated enrichment of H3K27me3 and H3K9me3, both are repressive markers for gene transcription, on IL17RD. Meanwhile, the expression of some TLR and NLRP members involved in inflammasome-mediated inflammation are also compromised in the mdig KO cells (Figs. 5C and 5D ). On the genes encoding prostaglandin E2 receptors 2, 3 and 4, although there was no significant gain of H3K9me3 and H3K27me3, a notable reduction of H3K4me3, an active marker for gene transcription, on these genes was observed in the KO cells (Fig. 5C ).Pulmonary fibrosis is one of the major contributing factors to the acute respiratory distress syndrome (ARDS) of the COVID-19 patients, which is also a common sequela in some COVID-19 survivors 22, 23 . Many fibrotic damages are irreversible and may cause lifelong functional impairment of the lung. The pro-fibrotic role of mdig was first demonstrated in silica-induced lung fibrosis in mice [14] [15] [16] . It is unknown whether mdig is also important in the development of lung fibrosis in humans. To answer this question, we screened mdig expression through immunohistochemistry in tissue microarrays containing 17 normal human lung tissues and 26 cases of fibrotic lung tissues collected from patients with cancer, chronic bronchitis or chronic pneumonia. In agreement with earlier reports that mdig was barely detectable in normal lung tissue 24, 25 , in this analysis, only 24% of normal lung tissues showed some faint staining of mdig. In contrast, the majority of fibrotic lung tissues, 85%, exhibited a strong signal of mdig expression (Fig.   6 ). Although we cannot distinguish the question of whether mdig promoted fibrosis or fibrosis caused a higher expression of mdig in human lung tissues, based on previous mouse model with mdig knockout and the fact that mdig is a master regulator of inflammation [14] [15] [16] , we believe that mdig is a critical driving factor for the development of lung fibrosis associated with some disease conditions, such as COVID-19, chronic bronchitis, pneumonia, and cancer.The COVID-19 pandemic due to SARS-CoV-2 infection has many destructive effects on public health and social-economics on a global scale. Despite a large amount of molecular detail is known about the virology of SARS-CoV-2 and the pathology of COVID-19, little is currently known about why some COVID-19 patients showed mild or no symptoms but others, even who are at young ages and have no pre-existing disease conditions, have severe or fatal outcomes. A number of studies had demonstrated that several environmental factors, including air pollution, temperature, humidity, wind speed, etc. had a significant influence on the mortality of COVID-19 12, 13, 26 . However, to the best of our knowledge, no detailed studies have investigated how these suspected environmental factors intensify the severity or mortality of COVID-19. In this report, we provided evidence suggesting that mdig, a potential oncogenic gene induced by several common environmental hazards 14, 27 , may augment the infectivity of SARS-CoV-2 and the severity of COVID-19 through upregulating S protein receptors NRP1 and NRP2, several proteases and the genes in the pathways of glycan metabolism and inflammation.It has been a general assumption that ACE2 is abundantly expressed in bronchial epithelial cells and other lung cells, and serves as the main receptor for the S protein of SARS-CoV-2 28 . It was beyond our expectation that ACE2 was barely detected by RNA- Accordingly, it is very likely that NRP1 and NRP2 are critically required for efficient viral entry into the host cells in the lung. The dependence of mdig on the expression of NRP1 and NRP2 was also observed in two additional cell lines, MDA-MB-231 (sFig.1 and sFig.2) and A549 (sFig. 3). Thus, it is plausible to speculate that mdig dependent expression of NRP1 and NRP2 can enhance the infectivity of SARS-CoV-2, leading to the worsening effect of environmental exposure on the severity of COVID-19.Sequential cleavage of the S protein at S1-S2 boundary and S2' site by host proteases is a prerequired step for conformational changes and membrane fusion of the 32 . More importantly, in addition to intensify the infectivity of the SARS-CoV-2, amplified glycosylation resulted from the excessive generation of hyaluronan that forms liquid jelly-like structure in both alveolar space and the interstitial area is fatal for COVID-19 patients 33 . Inflammatory cytokine storm is one of the contributing factors for the excessive generation of hyaluronan based on the fact that these cytokines are strong inducers of hyaluronan synthase-2 (HAS2) 34 . The present report unfolded that mdig is largely responsible for the expression of inflammatory cytokines and the key component of the inflammasome, as well as most of the genes in glycan metabolism, such as Has1, Has2 and Has3 for hyaluronan generation, and GALs for O-glycosylation (Fig. 4) . These effects of mdig are also attributable to the pulmonary fibrosis among some COVID-19 survivals 22, 23 . The elevated level of mdig in fibrotic human lung tissues (Fig. 6 ) supports this notion. Thus, over-expression of mdig, either under some chronic disease conditions or environmental exposure, possibly indicates the pathogenetic mechanism behind the severity or mortality of COVID-19. It also yields a conceivable explanation of how environmental exposure exacerbates the severity and/or mortality of COVID-19. A more complete understanding of mdig or its regulatory pathways, accordingly, could catalyze effective management strategies that will ameliorate the infectivity of SARS-CoV-2 and improve the outcomes of the COVID-19 patients.The human bronchial epithelial BEAS-2B cells were purchased from America Type Culture Collection (ATCC). BEAS-2B cells were cultured in DMEM-high glucose medium (Sigma, cat.no. D5796) supplemented with 5% FBS, 1% penicillin-streptomycin (Gibco, cat.no. 15140122), and 1% L-Glutamine (Gibco, cat.no. 25030164). Cells were maintained in a humidified incubator at 37 °C with 5% CO2.For generation of CRISPR-Cas9 plasmids, sgRNA (5'-AATGTGTACATAACTCCCGC-3') was selected and cloned into pSpCas9(BB)-2A-Blast vector as described 15 Ten million WT or KO Beas-2B cells were fixed and subjected to ChIP with ChIP-grade antibodies against H3K9me3, H3K27me3, and H3K4me3 (Active Motif, CA). ChIP, input/control DNA libraries, NGS sequencing, and data analysis were performed as we previously described 15 .Two million WT or KO BEAS-2B cells were collected for total RNA isolation, libraries preparation and NGS sequencing. The procedures and data analysis were followed as we previously reported 15 .Pulmonary Interstitial Fibrosis tissue microarray LC561 was purchased from the USBiomax, Inc. Tissue microarray slides were processed for immunohistochemical staining for mdig as described previously 24 . Briefly, paraffin-embedded tissue sections were deparaffinized with xylene and hydrated in a series of alcohol gradients. To quench endogenous peroxidase activity, slides were incubated with 1.5 to 3% H2O2 in PBS for 20 min at room temperature. Heat-mediated antigen retrieval was performed by boiling tissue sections in citrate buffer with pH 6.0 for 20 min in a microwave. To block nonspecific binding of immunoglobulin, slides were incubated with a solution containing 5% goat serum, 0.2% Triton X-100 in PBS for 2 h at room temperature, followed by incubation with Expression profiles of GSE149312, GSE150392, and GSE147507 were obtained from the public NCBI-GEO database. Gene set enrichment analyses comparing RNA-seq analyses were performed using the online public database Enrichr Enrichment of H3K27me3 and H3K9me3 on the NLRP gene loci that encode the key components of inflammasomes. ",USA,first author,2021-02-01,02
cb4765b460ec146ab98de1b4f3d2761ca3ca14a4,Creating an Automated Health Attestation System During the COVID-19 Global Pandemic Using Google's G Suite,"On March 11, 2020, the World Health Organization declared the COVID-19 outbreak a global pandemic (Hur & Cheol Chang, 2020) . At the time of this writing, COVID-19 has contributed to the deaths of over 1,000,000 people globally and almost 250,000 in the United States alone (Johns Hopkins University, 2020). Nonessential businesses, schools, and many other entities have been forced to close or drastically alter their operational protocols to comply with governmentissued health mandates. Mass layoffs and furloughs have forced many workplaces to determine a way to keep employees safe while attempting to maintain productivity in the workplace. In the field of mental and behavioral health, the COVID-19 pandemic has interrupted services and created new challenges for professionals and businesses providing these services (Torales et al., 2020) .As health care businesses look to move forward, the adoption of mitigation strategies has become crucial. As explained by Dubuque et al. (2020) , many health care professions' codes of ethics contain language that ensures professionals and companies promote client well-being and provide ongoing treatment, services, and training. The COVID-19 pandemic brings unique challenges for these providers as they try to simultaneously provide services for their clients and mitigate the spread of the virus. Although mask wearing, testing, social distancing, handwashing, and contract tracing (Güner et al., 2020) take the forefront of many health protocols, health attestations can be another important mitigation strategy that businesses can implement to reduce the transmission of COVID-19.Self-attestations and screenings are strategies that are already being used to monitor travel during the pandemic (Gostic et al., 2020) . Although self-attestation screenings may miss some infected people due to a lack of symptoms at the time of screening, the accessibility and information offered still make it a valuable tool for businesses' mitigation strategies (Gostic et al., 2020; Jeong et al., 2020) . When paired with proper hygienic behaviors, mask wearing, social distancing, and contact tracing (Güner et al., 2020) , self-attestation screening tools can help reduce the risk and liability for health care professionals providing services by preventing those who are showing symptoms from coming into contact with those who are not currently symptomatic or infected (Figs. 1, 2 and 3) .Recently, Dubuque et al. (2020) shared a tutorial that described how to create an automated COVID-19 health attestation system using Microsoft Forms, Power Automate, and Outlook. The purpose of that tutorial was to help organizations mitigate the spread of COVID-19 and reduce liability if an employee or consumer became infected with the virus. The current tutorial attempts to achieve the same purpose by showing how a similar automated health attestation system can be created using the tools available through Google's G Suite.G Suite contains multiple base applications and add-on programs. This tutorial requires the reader interact with three of them: Google Forms, Google Sheets, and Google Apps Script. The steps outlined are not the only way to set up an automated health attestation system in G Suite. There are addo n s ( e . g . , B o o m e r a n g f o r G m a i l , h tt p s : / / w w w . boomeranggmail.com/; Mail Merge, https://chrome.google. c o m / w e b s t o r e / d e t a i l / m a i l -m e r g e -f o r -g m a i l / hcdbcahipmenkfgfpfmiodkncfkeannn?hl=en) that can be downloaded that create functionality like what is described. However, these other options are usually dependent on a third party or operate as a subscription-based service. This tutorial avoids these extraneous programs and asks the reader to engage in a little extra response effort for potentially more security and less cost.The sample language used in the tutorial does not constitute legal advice. Organizations should consult with their attorneys and adjust this language to reflect the current health recommendations from trusted medical professionals. Each organization is responsible for ensuring that the language used within their own health attestation forms reflects their unique needs while ensuring compliance with all applicable laws (e.g., the Health Insurance Portability and Accountability Act [HIPAA], the Family Educational Rights and Privacy Act [FERPA]; U.S. Department of Education, 2020; U.S. Department of Health and Human Services, 2020). Finally, the health attestation system described herein will not work as intended if it is not supported by actionable policies and procedures. For example, the organization may specify that health attestations must be filled out by a certain time each day or within an hour of receiving or delivering services. Likewise, the organization may adopt a policy that specifies who is responsible for checking and following up with staff or consumers who fail to fill out their forms or indicate exposure to COVID-19. Finally, an organization would need to develop policies around how it should respond when a COVID-19 exposure is indicated on the attestation form. If a health attestation system is adopted by an organization, it should only be considered as one potential tool that may help mitigate the spread of COVID-19.This tutorial assumes the organization already has a G Suite Basic, Business, or Enterprise subscription and that the reader has full administrative access to the Google Forms, Google Sheets, and Google Apps Script applications used to create the automated health attestation system. It is strongly recommended that readers create and maintain the automated health attestation system described under a designated organizational email account (e.g., attestation@organization.com). Likewise, the roles that organizational staff should adopt in managing the system should be clearly specified. For example, the organization's legal team could help draft the health attestation language used in the form. Additionally, the organization's human resources department and executive team could work together to develop policies for running the system. Finally, the organization's scheduling department could be responsible for receiving submitted attestation forms when COVID-19 exposure is identified so they can respond quickly.The following steps describe how to create a health attestation form using Google Forms. This tutorial is only designed to cover the functionality for establishing a basic health attestation system and does not describe unrelated steps such as theming the form to match an organization's branding.1. Direct a browser to the https://docs.google.com/forms website. 2. Log in using the appropriate Google or G Suite account credentials if prompted. 3. If prompted, click the ""Blank"" option to open a new form. Otherwise, a new blank form will automatically open. 4. Click on the ""Untitled form"" text box located toward the center of the screen and type ""COVID-19 Health Attestation Form"" in the space provided. 5. Click on the ""Form description"" text box located directly under the form title and type the following statement: ""The organization reserves the right and sole discretion to temporarily discontinue work if the following health attestation form is not filled out when required, if your form indicates that you or those you are in direct contact with are at risk of a COVID-19 infection, or if you do not acknowledge and agree with all of the compliance and risk acknowledgment statements below."" 6. Click once on the ""Untitled form"" form name located in the top-left corner of the screen to automatically change the form name to the form title entered earlier. 7. Click the ""Untitled Question"" text box and type ""Health Assessment"" in the space provided. By default, the question type should be set to ""Multiple Choice."" 8. Click on the ""Option 1"" text box and type the following statement: ""I hereby acknowledge that within the last 14 days, I and the people I remain in close physical contact with have not knowingly been within 6 feet of someone who has a laboratory-confirmed COVID-19 diagnosis OR experienced a fever, cough, difficulty breathing, chills, muscle pain, headaches, sore throat, and/or new loss of taste or smell."" 9. Click on the circled ""+"" button located to the right of the question to add another question. 10. Type ""Compliance Acknowledgment"" in the question text box. 11. Click ""Option 1"" text box and type the following statement: ""I hereby acknowledge my compliance with the policies and procedures of the organization as the same may be updated from time to time, including those related specifically to addressing coronavirus (COVID-19) and the prevention thereof."" 12. Click on the circled ""+"" button located to the right of the question to add another question. 13. Type ""Risk Acknowledgment"" in the question text box. 14. Click ""Option 1"" text box and type the following statement: ""I acknowledge that people with certain conditions are recognized by the Centers for Disease Control (CDC) as being at a higher risk for COVID-19. To the extent any of these conditions apply to me, I agree to take all appropriate extra precautions including any such precautions advised by my licensed physician."" 15. Click on the circled ""+"" button located to the right of the question to add the final question. 16. Type ""Health Attestation"" in the question text box. 17. Click on the ""Multiple choice"" drop-down menu and selectthe ""Short answer"" option to change the question format. 18. Click the switch located next to the ""Required"" option to make the question nonskippable. 19. Click the three vertical dots located to the right of the ""Required"" option. 20. Click the ""Description"" option. 21. Click the ""Description"" text box and type the following statement: ""By submitting this form, I hereby represent and warrant that (a) all information I provided herein is accurate and true as of the date hereof, (b) I completed this attestation at the request of the organization, and (c) my full name is:"" 22. Click the gear icon located in the top-right corner of the screen. Check the ""Collect email addresses"" option to automatically add a question to the form that requests an email address. 24. Check the ""Response receipts"" option to give respondents an option to receive an emailed copy of their submission. The default setting provides the respondent with an opportunity to receive a copy of their submission, but it can be set to ""Always"" if preferred. 25. If creating the form within a G Suite account, uncheck the ""Restrict to users in [organization name] and its trusted organizations"" option to allow anyone to access the form. This option is not available on personal Google accounts. 26. Click the ""Save"" button. 27. Click the ""Send"" button located in the top-right corner of the screen. 28. Click the link icon located between the envelope and chevron (< >) icons. 29. Click the ""Shorten URL"" checkbox to create a shorter address link to the form. 30. Click the ""Copy"" button to copy the link. 31. Paste the hyperlink in a safe place, as it will be used later to share access to the form with potential respondents. 32. Click the ""X"" button to close the pop-up window.Automated email notifications are an excellent way to quickly inform the organization when potential exposure to COVID-19 has been indicated on a health attestation form submission. These notifications can be sent to designated individuals as soon as the form is submitted allowing for a quick response (e.g., cancel the appointment, start contact tracing). In this section, the steps for creating customized notifications when respondents submit health attestation forms will be described. Normally, setting notifications when respondents submit forms is straightforward using Google Forms. However, for the health attestation system to manage large groups of respondents, notifications should only be sent when a respondent submits a health attestation form that requires follow-up. In other words, all form submissions should be time-stamped and logged, but the only time an administrator should be notified by email is when a submission indicates exposure to COVID-19 or failure to comply with policies or acknowledge risk. This allows an organization to respond quickly when necessary without having to search through multiple email notifications. 4. Click the ""Responses"" tab located in the top middle of the webpage. 5. Click the green spreadsheet icon located in the upperright corner of the screen above the ""Accepting responses"" option. 6. Click the ""Create"" button when the pop-up window appears to create a new spreadsheet. 7. Click ""Tools,"" then ""Script Editor"" in the top menu bar to open a new tab in the browser. 8. Click the ""Untitled project"" text box located in the topleft corner. 9. Type ""notifications"" in the ""Edit Project Name"" pop-up box. 10. Click the ""OK"" button. 11. Clear the main code window by highlighting and deleting the following text:12. Enter the following replacement code into the main code window: 2 13. Within the code from the previous step, replace the ""INSERT EMAIL(S) HERE"" text with the email addresses of anyone that should receive the notification. The email addresses must remain within quotation marks. Multiple email addresses should be separated by a comma. For example: var email = ""attestation@organization.com, scheduler@billing.com""; 14. Click ""File,"" then ""Save"" in the top menu bar. 15. Click ""Edit,"" then ""Current project's trigger"" in the top menu bar to open a new tab in the browser. 16. Click the ""+ Add Trigger"" button located in the bottomright corner of the screen. 17. Under the ""Select event type"" header, click the ""On form submit"" option from the drop-down list. 18. Click the ""Save"" button. 19. Click the G Suite email address connected to the account. 20. If the ""This app isn't verified"" message appears, click the ""Advanced"" link.Click the ""Go to notifications (unsafe)"" link. 22. Click the ""Allow"" button.The following steps describe how to set up automated email reminders for respondents expected to fill out the health attestation forms on a regular basis. For example, these steps can be used to automatically send reminders to employees or recipients of services every morning between 6:00 a.m. and 7:00 a.m.1. Direct a browser to the https://docs.google.com/ spreadsheets website. 2. Log in using the appropriate G Suite account credentials if prompted. 3. Click the ""Blank"" option located under the ""Start a new spreadsheet"" header. 4. Click on the ""Untitled spreadsheet"" text box located in the top-left corner. 5. Type ""Reminder"" in the text box. 6. Click cell A1 and type ""Email."" 7. Starting in cell A2, enter the email addresses of the individuals who should receive the reminder message. Email addresses entered into the cell should be separated by commas (e.g., janedoe@gmail.com, smith@outlook.com, mohammad@gmail.com). 3 8. Click cell B1 and type ""Subject."" 9. Click cell B2 and type ""Health Attestation Reminder."" 10. Click cell C1 and type ""Message."" 11. Click cell C2 and type ""This is a reminder for you to fill out the health attestation form found at"" followed by a link to the health attestation form created earlier. 12. Click ""Tools,"" then ""Script Editor"" in the top menu bar to open a new tab in the browser. 13. Click the ""Untitled project"" text box located in the topleft corner. 14. Type ""sendEmails"" in the ""Edit Project Name"" pop-up box. 15. Click the ""OK"" button. 16. Clear the main code window by highlighting and deleting the following text:17. Enter the following replacement code into the main code window: 18. Click ""File,"" then ""Save"" in the top menu bar. 19. Click ""Edit,"" then ""Current project's trigger"" in the top menu bar to open a new tab in the browser. 20. Click the ""+ Add Trigger"" button located in the bottomright corner of the screen.Under the ""Select event source"" header, click the ""Timedriven"" option from the drop-down list. 22. Under the ""Select type of time based trigger"" header, click the ""Day timer"" option or choose a different option that reflects how frequently you would like respondents to be reminded to fill out the health attestation form.23. Under the ""Select time of day"" header, click the ""6am to 7am"" option or select a different time frame when you would like the reminder email sent out. 24. Click the ""Save"" button. 25. Click the G Suite email address connected to the account. 26. If the ""This app isn't verified"" message appears, click the ""Advanced"" link. 27. Click the ""Go to sendEmails (unsafe)"" link. 28. Click the ""Allow"" button.The experience of owning, managing, and consulting with a variety of behavior-analytic clinics, schools, and businesses gives us broad vantage to propose a solution that should help across many different contexts. Specifically, it is important to recognize the value in customizing an organization's attestations and to have a system controlled by the entity. This importance is especially apparent during the pandemic when regulatory recommendations, guidelines, and requirements change. Organizations must flexibly and rapidly adapt to such changes while maintaining required HIPAA, FERPA, and other confidentiality needs. Although attestations are but one part of the solution, the following examples will illustrate a variety of ways in which they can be helpful.Consider a variety of cases in which this system may be used. In the case of home-based care, the organization may require that an attestation must be completed by both parties (staff and consumer) before a session can commence. If the organization delivers two sessions per day, this might require a total of three attestations. Failure to get any one of those may create service barriers and delays on a frequent basis. Likewise, in a center-based program, the process used for collecting attestations may differ. The consumer attestation can occur at drop-off and can be accomplished with a center-owned device and internet connection. Additionally, staff members can attest at drop-off, before they enter, but while still on site. Although there may be multiple sessions per day, the number of attestations may be reduced because the environment is more controlled, and the influx of new people is limited. Finally, a school-based setting may share similarities with the center-based therapy settings, except that sometimes the drop-off and pickup are done via transportation. This means that if third-party transportation drops off a learner, and an attestation has not been completed, a problematic situation arises. In such situations, it will be important to have a plan of action ready to avoid such risks and vulnerabilities.In conclusion, this tutorial provides a low-cost option for small businesses, but one that is also equally accessible and scalable as organization size increases. As with all solutions, there are limitations, as noted previously, and once understood, the attestation process is adjusted for each instance. Foremost is that any use of electronic technology and webbased solutions means that all participants will need access to electronic hardware (computers or mobile devices) and the internet. If this technology is not readily available to all members of an organization, it will limit the usability of the system, potentially leaving gaps in the protection afforded by the attestation in the first place. For instance, if some of the consumers or employees do not know how to complete the forms, and the system operator makes occasional allowances, these vulnerabilities can defeat the purpose (precluding infection spread). For an organization, this means that although you may have access to free software, and this tutorial provides the means to develop an attestation system, the organization still has some work to do. Specifically, there need to be systems of training and compliance to make sure that all who need to attest have the access, tools, and knowledge to implement and submit their attestations. Second, there will need to be a system that compares attestation submissions with expectations and flags any discrepancies for review and intervention. If, for instance, an organization creates an attestation requirement prior to session delivery on a daily basis, there needs to be a system to enforce the requirement, or the organization is simply creating a sense of false security for all the members and potential legal issues in terms of health injury and potential discrimination litigation.Finally, the sample language used does not provide any legal or health protection; rather, the purpose of this article was to describe a technology that can be used to deliver communication and receive input. The advantage of this limitation, however, is that once an organization has used this technology, they may find that other problems can be solved using a similar automated communication system.",USA,first author,2021-02-09,02
ff03a27dffce41cebc8fc75007f8f00e678ca23c,The impact of the COVID-19 pandemic on neurofibromatosis clinical care and research,"Neurofibromatosis type 1 (NF1), neurofibromatosis type 2 (NF2), and schwannomatosis (SWN) are a group of genetic tumor predisposition syndromes, collectively called the neurofibromatoses (NF). All types of NF predispose to nerve sheath tumors (i.e., neurofibromas or schwannomas) throughout the body and affect up to 1 in 3,000 individuals. There is significant variability in the timing, severity, and presence of specific clinical manifestations in individuals with NF. Each type of NF is progressive and requires lifelong medical monitoring and care [1] . Although there is no cure and there are limited treatments for NF, selumetinib (Koselugo) received FDA approval in April 2020 for the treatment of symptomatic, inoperable plexiform neurofibromas in pediatric NF1 patients [2] . There is an urgent need to identify new treatments for NF1, NF2, and SWN, for which clinical trials are highly concentrated in specialty clinics [3] .The NF Clinic Network (NFCN) is a group of member NF clinics in the US that have been approved by the Clinical Care Advisory Board of the Children's Tumor Foundation (CTF) based on NF expertise, patient volume, multidisciplinary approach, and research support [4] . There are currently 63 NFCN clinics located in 32 states [5] .*Correspondence: hradtke@ctf.org 1 Children's Tumor Foundation, New York, NY, USA Full list of author information is available at the end of the articleThe coronavirus disease 2019 (COVID-19) first appeared in late 2019 and spread quickly worldwide [6] . During the initial wave of the U.S. pandemic in March 2020, many states initiated stay-at-home orders and health safety guidelines [7] . These regulations had a drastic effect on all aspects of life, including both access to and provision of medical care. As resources were diverted to care for COVID-19 patients, routine clinical care and elective procedures were temporarily paused in many locations. While such measures were important to address the pandemic, there were likely negative collateral effects on the management of chronic conditions [8] . To date, the impact of COVID-19 on clinical care and research for genetic disorders has largely been unexamined. The goal of this survey was to investigate the impact of COVID-19 on NF care delivery and research.NFCN member clinics were invited to participate in an online survey administered by SurveyMonkey. (Additional file 1) NFCN clinic directors come from a variety of disciplines including genetics (40%), neurology (26%), neuro-oncology (17%), hematology/oncology (7%) and other subspecialties. The majority of clinics provide both pediatric and adult NF care. Over one-half of clinics report that they have on-site clinical trials or NF research and 18/63 clinics are part of the NF Clinical Trials Consortium [9] . Together, the NF clinics provide care to over 15,000 individuals with NF per year [5] .One response per clinic was requested from each clinic. Invitations were emailed on May 7, 2020 with one follow up email to non-responders on May 22, 2020. The survey was closed on June 2, 2020. Respondents were asked a series of questions related to current clinical care and research practices, as well as estimated relative clinic volume between April 1-30, 2020, to allow consistent comparison between clinics. Clinician satisfaction with NF care provision by telehealth was assessed using a Likert rating scale (1: very satisfied to 5: not at all satisfied) ( Fig. 1) . Respondents were offered a $15 gift card for completion of the survey, which took an average of 10 min to complete. Sixty surveys were completed. Eight responses were excluded from analysis (N = 4 duplicate response from same clinic; N = 4 incomplete survey response). Response rate was 83% (52/63 clinics) and respondents included 47 clinic directors and 5 clinic coordinators. Main clinic focus was identified as pediatric (36%), adult (10%) or a combination of pediatric and adult (54%), with representation from all over the US.Two clinicians (one geneticist and one neurologist) were required to be redeployed to another service and/or on the frontline to assist with COVID-19 patients and two (neurologists) volunteered to do so. Six (12%) of the directors were partially furloughed with reduction in clinical hours.Clinics were asked to provide an estimate of patient volume during April 2020, compared to pre-COVID average volume (including both in-person and telehealth visits) ( Table 1 ). The typical number of NF patients seen in each clinic before the pandemic ranged widely from 3 to 35 patients per week. Thirty-four clinics (65%) reported reduced clinic volume by ≥ 50%; within these, 18 clinics (35%) with volume reduction by ≥ 75%, and 3 clinics (6%) with no reported clinic volume (100% reduction). Two clinics reported > 100% of their pre-COVID clinic volume.Most clinics continued to see urgent NF patients (92%), and most clinics (79%) reported that they were conducting urgent visits via telehealth. All clinics reported that patients were able to have urgent MRIs or testing done at the onsite medical center or an affiliate site; 41% reported that patients could similarly have routine non-urgent MRIs or testing. However, 43% of directors reported nonurgent MRIs and testing were being electively deferred and 16% indicated that non-urgent testing could not be performed.Selumetinib (Koselugo) for the treatment of plexiform neurofibromas in pediatric NF1 patients received FDA approval during the COVID-19 pandemic. While 22% of NF clinics had already treated or discussed treatment with eligible patients, 63% were waiting to discuss treatment until patients' next appointments (which as noted, had been delayed due to COVID-19 for many patients) and 12% were deferring starting new patients on treatment until after resolution of the pandemic.Respondents were asked about their institution's current policy regarding NF clinical trials and could select more than one response given that clinics may have more than one clinical trial at their institution. Although 39% of clinics were able to continue recommended treatment and surveillance protocols, in over half of currently enrolled patients, protocols were either modified (37%) or temporarily deferred (14%). In addition, 43% of clinicsBased on respondent estimates, a vast majority of clinics reported a decrease in patient volume in April 2020 compared to prior to the pandemic, and most clinics were using telehealth for a majority of their NF clinic patients *Excludes three clinics reporting no patient visits in April 2020 Estimated patient volume in April 2020 compared to pre-COVID-19 pandemic (n = 52) Only one of the clinics surveyed was using telehealth for follow-up patient visits prior to COVID-19. The most common reported barriers reported for not using telehealth prior to the pandemic were: insurance/reimbursement concerns (63%), lack of institutional setup for telehealth services (59%), and safety concerns, which included limitations of physical exam using telehealth (49%). Additional concerns raised included technological issues or difficulties using a telehealth system (37%), legal concerns (e.g., medical licensure issues; 35%), security/privacy concerns (24%), lack of interest in using telehealth by leadership and/or colleagues (24%), and no identified need for telehealth (24%) . Within the openended narrative response, some concerns regarding access issues were raised including challenges patients may have accessing video televisits and challenges with integrating interpreter services to address hearing difficulties, which are common with NF2.Since the COVID-19 pandemic, 51/52 (98%) of clinics were using telehealth for NF patients; the remaining clinic planned to begin telehealth in the next three months. A majority of clinics reported seeing at least half of patients by telehealth at the survey endpoint, less than 3 months from the beginning of the pandemic (Table 1) . New, follow-up, and genetic counseling appointments included full evaluations (84%), problem-focused discussions of medical issues (80%), follow up of previous recommendations (73%), discussion of results (65%), and problem-focused discussions of neurocognitive/ psychosocial issues (51%). Clinics used a wide variety of telehealth platforms, some of which were integrated within the electronic medical record systems. The most frequently used platforms used were Zoom (58%) and Doximity (23%).As indicated above and in Table 1 , most clinics (86%) reported that the majority of their total clinic volume was currently seen via telehealth. Use of video conferencing was more common than use of telephone alone for appointments.Clinic satisfaction with telehealth is indicated in Fig. 1 . Overall, 63% of respondents were satisfied or very satisfied with the use of telehealth services for NF patient care. The ease of use of telehealth by clinicians was the highest area of satisfaction, with patient ease of use and billing reimbursement rated as neutral to positive. Technical issues and connection difficulties were rated in the neutral to negative range. The lowest satisfaction was with the ability to perform a physical examination, with 29 clinicians (72%) indicating that they were not satisfied or not at all satisfied with this aspect of telehealth.A majority (84%) of clinics indicated they would continue to use telehealth for NF patient care, provided maintenance of adequate insurance coverage. The remaining clinics said they were unsure whether they will continue telehealth. Within the open-ended narrative response, some clinicians reported that telehealth would be used only in certain cases, such as for stable or uncomplicated follow-up patients, families traveling a distance or reluctant to come to the hospital, triaging of patient needs; telehealth visits in those circumstances would be alternated with in-person visits.This study, conducted fairly early in the course of the pandemic, elucidates the impact of the COVID-19 pandemic on clinical care for a group of rare, neurogenetic disorders [the neurofibromatoses (NF)]. Immediate impact includes changes to clinician roles, patient volume, and medical treatment/surveillance protocols that reduced the availability of routine NF-specific care. Delays in appointments or testing, even in routine situations, may postpone recognition of NF-related complications. The pandemic prompted a pivot from face-to-face medical care to telehealth, in order to meet healthcare needs. Clinical trials participation was also impacted, with half of clinics reporting either modification or deferral of existing clinical trials protocols and delays or suspensions with new research protocols. Given the lack of approved treatment options for most manifestations of NF, even temporary delays in clinical trial research may be devastating to many NF families and may slow NF research directed towards finding new treatments. Further research is needed about the specific considerations for use of telehealth approaches within clinical trials research.Despite these challenges, telehealth was rapidly adopted by NF specialty clinics within 2-3 months, going from 2% of clinics pre-pandemic to 98% of clinics during the pandemic. A majority of clinics reported that this will likely continue for at least some patients if insurance reimbursement for these services continues. Further exploration of barriers to telehealth and clinician/patient satisfaction ratings of telehealth will guide future provision of remote care for rare, genetic disorders. Remote care options may be especially beneficial for individuals with rare conditions and their families given that clinicians expert in their care may not be readily accessible locally [4] .",United States,abstract,2021-02-01,02
0ea0311656f9d877c323f5168c853f339897f809,Cryo-EM Structures of the N501Y SARS-CoV-2 Spike Protein in Complex with ACE2 and Two Potent Neutralizing Antibodies Short title: Structures of N501Y Spike Protein with ACE2 and Two Antibodies,"The rapid international spread of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), the causative agent of COVID-19, is associated with numerous mutations that alter viral In December 2020, new variants of SARS-CoV-2 carrying several mutations in the spike protein were documented in the UK (SARS-CoV-2 VOC202012/01) and South Africa (501Y.V2) (14, 15) . Early epidemiological and clinical findings have indicated that these variants show increased transmissibility in the population (16) . Despite being phylogenetically distinct, a common feature of both UK and South African variants is the mutation of residue 501 in the RBD from Asn to Tyr (N501Y). X-ray crystallography and cryo-electron microscopy (cryo-EM) structural studies have identified N501 as a key residue in the spike protein at the interface between RBD and ACE2 that is involved in critical contacts with several ACE2 residues (5, 6, 10, 13) . Studies carried out in a mouse model before the identification of the new UK variant have suggested that mutations of residue 501 could be linked to increased receptor binding and infectivity (17, 18) . Understanding the impact of N501Y on antibody neutralization, ACE2 binding, and viral entry is therefore of fundamental interest in the efforts to prevent the spread of COVID-19.To understand the structural effects of the N501Y mutation on ACE2 binding, we expressed and purified spike (S) protein ectodomains with and without the N501Y mutation in Expi293 cells, and conducted microscopy studies on the ACE2-spike complexes. A cryo-EM structure of the spike protein ectodomain with the N501Y mutation was obtained at an average resolution of ~2.8 Å ( Figure S1 ). The structure shows no significant global changes in secondary or quaternary structure as a result of the mutation when compared to the previously published structure of the spike protein ectodomain with an Asn residue at position 501 (referred to here as the ""unmutated"" form; Figure S2 ) (7) .Cryo-EM structural analysis of the complex formed between the N501Y spike protein ectodomain and the ACE2 receptor ectodomain provides a detailed glimpse of both the overall structure of the receptor and the binding interface between the RBD and ACE2 (Figures 1, S3) .The ACE2 receptor is bound to the ""up"" position of the RBD ( Figure 1A ). The overall structure of the complex was determined at a global resolution of 2.9 Å. Local refinement of the RBD-ACE2 interface improves the local resolution at the binding interface to ~3.3 Å ( Figure 1B) , resulting in unambiguous delineation of the Y501 side chain and other residues in the vicinity ( Figure 1C ). The overall structure at the binding site is almost identical to that of the unmutated version ( Figure 1D ) (7) , with the exception of local rearrangements that result in the aromatic ring of Y501 being accommodated in a cavity that is sandwiched between Y41 and K353 from the ACE2 receptor ( Figure 1E ). Y501 in the spike protein and Y41 in the ACE2 receptor form a perpendicular y-shaped p-p stacking interaction (19) .Potent neutralization of SARS-CoV-2 has been achieved with a number of antibodies, including two recently reported examples VH Fc ab8, and IgG ab1, both derived from a large human library of antibody sequences (20, 21) . We compared the efficiencies of these two antibodies, as well as the ACE2 receptor ectodomain, to bind spike proteins with and without the N501Y mutation. We also determined the relative efficiency of neutralization of pseudoviruses expressing either the N501Y mutant or unmutated forms of the spike protein.To test the influence of the N501Y mutation on ACE2 binding, we used a luciferase reporter to measure the infectivity of pseudotyped viruses presenting N501Y or unmutated spike proteins for cells overexpressing ACE2. The higher relative luminescence units (RLU) intensity from cells infected by the N501Y mutant (6000 ± 2000 RLU, mean ± standard deviation) compared to control viruses expressing the unmutated form (3000 ± 800 RLU) demonstrates that the N501Y mutation results in increased infectivity. To verify that this was a result of the increased binding strength of the mutant RBD to ACE2, we measured the binding parameters between ACE2 and of either unmutated or N501Y spike protein ectodomain trimers via biolayer interferometry (BLI). This revealed that the N501Y mutation confers an increase in affinity for ACE2, mainly driven by a reduction in dissociation rate constant (koff) (Figures 2A, B) . We also measured the efficiency of exogenously added soluble ACE2-mFc proteins to neutralize unmutated and N501Y pseudoviruses ( Figure 2C ). The comparison of neutralization profiles show that the IC50 for neutralization of the N501Y mutant is lower. Taken together, these three results are consistent with the hypothesis that the greater infectivity of the N501Y mutant stems from improved binding to ACE2.Next, we tested the effect of the N501Y mutation on the relative strengths of binding and neutralization potency of VH Fc ab8 and IgG ab1 ( Figures 2D-G) . ELISA analysis of IgG ab1 and VH Fc ab8 interactions with unmutated or N501Y spike ectodomains demonstrate the N501Y mutation has no significant effect on VH Fc ab8 binding but results in a slightly higher EC50 for IgG ab1 ( Figure 2D ). Second, competition experiments establish that IgG ab1 is more efficiently displaced by ACE2 when binding the N501Y mutant compared to unmutated ectodomains ( Figure 2F ), while the displacement of VH Fc ab8 by ACE2 is similar for unmutated and N501Y mutant spike proteins ( Figure 2G ). This is further confirmed by negative stain experiments, where VH ab8 interferes with ACE2 binding in both the unmutated and N501Y spikes ( Figure S4 ).shows that it can neutralize the N501Y mutant with a potency similar to that of the unmutated form, while IgG ab1 exhibits a slightly diminished neutralization potency for the N501Y mutant relative to pseudoviruses expressing the unmutated form ( Figure 2E ). Overall, binding and neutralization analyses show that the N501Y mutation results in enhanced ACE2 binding, minimal effects on the binding and potency of VH Fc ab8, and a small reduction in the binding and potency of IgG ab1. To understand the effects of these antibodies at a structural level, we next determined cryo-EM structures of the complexes formed by VH ab8 and Fab ab1 with the N501Y mutant spike protein ectodomain.Cryo-EM structural analysis of the complex formed between VH ab8 and the N501Y spike protein ectodomain shows a single dominant conformation with two VH ab8 fragments bound to RBDs in the down conformation and weak density for the other RBD, which is flexible and primarily in the up position ( Figures 3A, S5) . The global average resolution of the map is ~2.8 Å, with lower local resolution in the RBD regions, but local refinement yields maps of the VH ab8-RBD interface at a resolution of ~3 Å ( Figures 3B, S5 ). Cryo-EM density maps unambiguously show the location of residue 501 in the N501Y mutant spike protein ectodomains ( Figure 3C ).The interface between the RBD and VH ab8 is well-defined with key interactions at the interface mediated by residues in the stretch between V483 and S494, along with a few other interactions contributed by non-contiguous RBD residues ( Figures 3D, E) . Residue 501 of the spike protein RBD is at the periphery of the footprint of ab8 and shows no evidence of interactions with the antibody. The presence of the mutation thus appears not to influence interactions between the RBD and VH ab8.Similar cryo-EM analyses of the complex between the mutated spike protein and Fab ab1shows that in contrast to the VH ab8 complex, Fab ab1 binding involves either two or three RBD domains, all being in the up position ( Figures 4A, B, S6 ). Local refinement of the RBD-Fab ab1 interface improves the resolution to ~3 Å, enabling unambiguous placement of Y501 as well as the residues involved in the contact between the RBD and Fab ab1 ( Figures 4C, D, S6 ). Residue 501 is at the periphery of the Fab ab1 footprint, with Ser 30 of Fab ab1 in a position to interact with the spike protein ( Figures 4E, F) . The N501Y mutation would thus be expected to have a small effect on the antibody binding epitope. Together, the cryo-EM structures are fully consistent with the studies presented in Figure 2 that show a small but significant effect of the N501Y mutation on Fab ab1 binding and neutralization, but with no measurable effects on VH ab8 binding or neutralization.Comparison of the structures reported here with those reported for the ACE2-RBD complex from earlier X-ray crystallography and cryo-EM studies enable visualization of the similarities and differences in the modes of binding ( Figure 5 ). There are several regions such as the portion of the epitope in the vicinity of residue F486 that are shared across ACE2 and the two antibodies ( Figures 5A-C) . However, there are marked differences near residue 501, which is completely within the ACE2 footprint, at the very edge of the ab1 footprint, and well outside the ab8 footprint (Figures 5D-G). ACE2 binding has been observed only to RBDs in the up position, likely because of steric constraints in accommodating ACE2 in the down conformation. However, the stoichiometry of ACE2 binding to the trimeric spike can be variable. Negative stain experiments show that populations of spike proteins with one, two, or three ACE2 receptors bound are obtained ( Figure S4 ) and consistent with the binding studies, we find that a higher number of ACE2 receptors bind N501Y spikes as compared to unmutated spikes when the incubation is carried out under similar conditions. In cryo-EM experiments, Fab ab1 also binds the RBD in only the up position ( Figures 4A, B) , but in contrast, the much smaller VH ab8 fragment binds the RBD in both up and down positions ( Figure 3A ). Despite these differences, and the fact that ACE2, VH ab8, and Fab ab1 each have distinctive directions of approach in their contact with the RBD, there is a good match in the RBD binding footprint between VH ab8, Fab ab1, and ACE2 ( Figures 5A-C) , accounting for the potent neutralization by the VH Fc ab8 and IgG1 ab1 antibodies ( Figures 5D-G) . (19) . The location of residue 501 at the outer edge of the contact zone between RBD in the Fab ab1 complex and outside the zone of contact of VH ab8with RBD provides a structural rationale for the findings we describe here on the differential effects of the N501Y mutation on binding and neutralization by these two antibodies ( Figure 5 ).Our studies with the N501Y mutant confirm the expectation that the rapid spread of the UK variant of SARS-CoV-2 is likely due to the viruses being more infectious. While there can be multiple origins for the increased infectivity, our biochemical and structural studies establish that the N501Y mutation results in increased ACE2 binding efficiency. Competition assays with a strongly neutralizing antibody show that it competes for binding with the spike trimer-ACE2 interaction in a concentration-dependent manner. Our results suggest that despite the higher infectivity of SARS-CoV-2 viruses carrying the N501Y mutation, the availability of the extended epitope surface on the RBD enables effective neutralization by VH ab8 and Fab ab1. The footprints of these antibodies are comparable to that of other antibodies recently described (22) (23) (24) (25) , suggesting that at least some antibodies elicited by immunization with vaccines that are currently in production may also retain the ability to neutralize the N501Y mutant. With the continued spread of SARS-CoV-2, it appears likely that further mutations that enhance viral fitness will emerge. Cryo-EM methods to rapidly identify footprints of antibodies that are generated by current and future generations of vaccines could thus add a critical tool to the arsenal of efforts to prevent and treat COVID-19.The wild type SARS-CoV-2 S HexaPro expression plasmid was a gift from Jason McLellan (7) imidazole. The protein was eluted with elution buffer (20 mM Tris pH 8.0, 500 mM NaCl, 500 mM imidazole). Elution fractions containing the protein were pooled and concentrated (Amicon Ultra 100-kDa cut off, Millipore Sigma) for gel filtration (GF). Gel filtration was conducted using a Superose 6 10/300 GL column (Cytiva) pre-equilibrated with GF buffer (20 mM Tris pH 8.0, 150 mM NaCl). Peak fractions corresponding to soluble protein were pooled and concentrated to 4.5-5.5 mg/mL (Amicon Ultra 100-kDa cut off, Millipore Sigma). Protein purity was estimated as >95% by SDS-PAGE and protein concentration was measured spectrophotometrically (Implen Nanophotometer N60, Implen).For negative stain, purified S protein (0.05 mg/mL) was mixed with soluble ACE2 (0.05 mg/mL) and incubated on ice for 15 min. For the competition experiment, the S protein (0.05 mg/mL) was first incubated on ice with VH ab8 (0.02 mg/mL) for 30 min, followed by addition of ACE2 (0.05 mg/mL) for another 30 min. Grids (Copper 200 or 300 mesh coated with continuous ultrathin carbon) were plasma cleaned using an H2/O2 gas mixture for 15 s in a Solarus II plasma cleaner (Gatan Inc.) or 10 s in a PELCO easiGlow glow discharge cleaning system (Ted Pella Inc.). The protein mixtures (4.8 µL) were applied to the grid and allowed to adsorb for 30 s before blotting away excess liquid, followed by a brief wash with MilliQ H2O.Grids were stained by three successive applications of 2% (w/v) uranyl formate (20 s, 20 s, 60 s).Negative stain grids were imaged using a 200 kV Glacios (ThermoFisher Scientific) transmission electron microscope (TEM) equipped with a Falcon3 camera operated in linear mode.Micrographs were collected using EPU at nominal 92,000x magnification (physical pixel size 1.6 Å) over a defocus range of -1.0 µm to -2.0 µm with a total accumulated dose of 40 e -/Å 2 . For cryo-EM data, motion correction in patch mode (EER upsampling factor 1, EER number of fractions 40), CTF estimation in patch mode, reference-free particle picking, and particle extraction (extraction box size 640, Fourier crop to box size 320) were performed on-thefly in cryoSPARC. After preprocessing, particles were subjected to 2D classification and 3D heterogeneous classification. The initial consensus maps were obtained by 3D homogeneous refinement. Then particles were re-extracted with box size 800 and then binned to 400. Final 3D refinement was done with per particle CTF estimation and aberration correction. Local refinements with a soft mask covering a single RBD and its bound VH ab8 or ACE2 resulted in improvement of the binding interfaces. C3 symmetry expanded particles were used for local refinement of RBD and its bound Fab ab1. Overall resolution and locally refined resolutions were according to the gold-standard FSC (29) .Coordinates of PDB 6WGJ and 7CH5 were used as initial models to build the VH ab8 and Fab ab1, respectively. Individual domains of SARS-CoV-2 HexaPro S trimer (PDB code 6XKL) were docked into cryo-EM density using UCSF Chimera v.1.15 (30) . Initial models were first refined against sharpened locally refined maps, followed by iterative rounds of refinement against consensus map in COOT v.0.9.3 (31) and Phenix v.1.19 (32) . Glycans were added at N-linked glycosylation sites in COOT. Model validation was performed using MolProbity (33 SARS-CoV-2 S N501Y plasmid was obtained from SARS-CoV-2 S plasmid (HDM-IDTSpike-fixK) by site-directed mutagenesis (Q5 Site-Directed Mutagenesis Kit, New England Biolabs). SARS-CoV-2 S and SARS_CoV-2 S N501Y pseudotyped retroviral particles were produced in HEK293T cells as described previously (29) . Briefly, a third-generation lentiviral packaging system was utilized in combination with plasmids encoding the full-length SARS-CoV-2 spike, along with a transfer plasmid encoding luciferase and GFP as a dual reporter gene. ",Canada,first author,2021-02-09,02
7fcaa9e0c2f1c52a72099ef14dd841ead7f81928,Probing the SAM Binding Site of SARS-CoV-2 nsp14 in vitro Using SAM Competitive Inhibitors Guides Developing Selective bi-substrate Inhibitors,"(ORFs) 6 , encoding 16 non-structural proteins (nsp) and four main structural and accessory proteins. 7 The 16 non-structural proteins (referred to as nsp1 to nsp16) are more conserved amongst coronaviruses compared to the structural and accessory proteins. 8 These nsps in coronaviruses form a replicase-transcriptase complex and are essential for the transcription and replication of the virus. 9 Among these, nsp14 and nsp16 are RNA methyltransferases involved in RNA capping. 10 Nsp14 is a bi-functional protein with a C-terminal methyltransferase domain catalyzing N7guanosine methylation, and an N-terminal exoribonuclease domain (Supplementary Fig. 1 ). In the replicase-transcriptase complex of coronaviruses, nsp14 functions as an exoribonuclease and is involved in maintaining the fidelity of coronavirus RNA synthesis. 11 Nsp14 in complex with nsp10 can function as a proofreading exoribonuclease and removes 3′-end mismatched nucleotides from dsRNA. 12 Breaking this interaction between nsp10 and nsp14 results in a decrease in virus replication fidelity. 13 Besides nsp10, nsp14 also interacts with the nsp7-nsp8-nsp12 complex where the exonuclease function of nsp14 decreases the incidence of mismatched nucleotides 14 by erasing the mutated nucleotides. 11 While complex formation between nsp10 and nsp14 is required for enhanced exoribonuclease activity, the MT activity of nsp14 is independent of nsp10-nsp14 complex formation. 15, 16 The nsp14 SAM-dependent methyltransferase (MTase) activity is essential for viral mRNA capping. 16, 17 The cap1 structure at the 5′ -end of viral RNA helps in masking the virus from the host immune system. 18, 19 Cap (GpppN) structure in nascent RNA of coronaviruses is formed by nsp13 20,21 and a guanylyltransferase (GTase). Nsp14 methylates this cap structure at the N7 position of the guanosine, forming a cap-O (N7mGpppN). 17 Nsp16 further 2′-O-methylates the product of the nsp14 methyltransferase activity, completing the capping process (N7mGpppNm). 16, 22 Nsp14 is conserved amongst the seven coronaviruses known to infect humans to-date ( Supplementary Fig. 2 ). 23 The SARS-CoV-2 nsp14 overall amino acid sequence shows 95.1, 62.7, 57.8, 58.5, 52.9 and 53.7% identity with nsp14 from SARS-CoV, MERS-CoV, OC43, HKU1, 299E and NL63, respectively. This suggests the possibility of SARS-CoV-2 nsp14inhibitors also inhibiting nsp14 methyltransferase activity of other coronaviruses. Such pan inhibitors would be priceless for developing pan anti-viral therapeutics for COVID-19 that would be also effective on future coronaviruses which may jump to humans. In this study, we first developed a radiometric high throughput activity assay for SARS-CoV-2 nsp14 methyltransferase activity and screened a library of 161 S-adenosylmethionine (SAM) competitive methyltransferase inhibitors we previously synthesized, and SAM analogs. We identified seven reproducible hits which we mapped on the active site of SARS-CoV-2 nsp14. The data shows for the first time a clear path towards the development of potent and selective bi-substrate nsp14 inhibitors that may lead to a novel class of therapeutics for COVID-19 and possibly other coronaviruses to come.Developing therapeutics for COVID-19 and other coronaviruses requires reliable high throughput screening assays. Radiometric assays have been widely used for developing potent substrate and SAM competitive inhibitors for human methyltransferases within the last decade. 24 Using biotinylated RNA substrate, a radiometric nsp14 methyltransferase (MTase) activity assay was developed with 3 H-SAM as a methyl donor (Fig. 1) . Nsp14 MTase activity was evaluated in various buffers, pH and additives (Supplementary Fig. 3 ). The highest MTase activity was observed in Tris HCl buffer at pH 7.5. No significant effect was observed for DTT up to 10 mM and it was included in the assay reaction mixture at 5 mM to maintain reducing conditions. Triton X-100 at 0.01% was added to the reaction buffer to minimize binding of proteins and compounds to plates. DMSO at concentrations up to 10% had little effect on nsp14 MTase activity. However, MgCl2 was only tolerated at concentrations below 1 mM (Supplementary Fig. 3) . The assay optimization resulted in selecting 20 mM Tris HCl pH 7.5, 250 µM MgCl2, 5 mM DTT and 0.01 % Triton X-100 for testing nsp14 MTase activity and determining its kinetic parameters.Using optimized assay conditions, linearity of initial velocities (activity versus time) was assessed at various concentrations of RNA at fixed SAM concentration (1 µM) (Supplementary Fig. 4a Fig 1a) and 52 ± 1 h -1 (SAM ; Fig 1b) , were reasonably close. Addition of nsp10 at various molar ratios from 1 (nsp10):1 (nsp14) to 20 (nsp10):1 (nsp14) did not have any significant effect on nsp14 methyltransferase activity (Supplementary Fig. 5 ).In small molecule screening campaigns, typically the assays are performed at Km of the substrates to allow potential inhibitors to compete with the substrates and allow their binding to be detected.However, the activity of the enzyme should be linear during the assay period. As the radiometric methyltransferase assays are endpoint assays, lack of linearity may mask inhibition of some compounds. Testing the activity of nsp14 at 50 µM RNA and 250 nM SAM indicated that the assay can be run for at least 20 minutes while maintaining the linearity (Fig. 1c) . To determine the reproducibility of such conditions for high throughput screening, the assay was performed in the presence (1 µM) and absence of sinefungin, a pan methyltransferase inhibitor that inhibits nsp14MTase activity with an IC50 value of 0.019 ± 0.01 µM (Supplementary Fig. 6) . A Z′-Factor of 0.69 was calculated for nsp14 screening indicating suitability of the assay for high throughput screening (Fig. 1d) .An in-house library of 161 SAM competitive methyltransferase inhibitors and SAM analogs was screened against nsp14 at 50 µM, and 19 compounds were identified that inhibited nsp14 MTase activity more than 75% (Fig. 1e) . Compounds that interfered with the readout signal or were not reproducible were eliminated. The remaining seven compounds ( Fig. 2 Supplementary Fig. 7 ).This limited and focused screening exercise provided important insights on the structural chemistry of SARS CoV-2 nsp14 inhibition ( Table 1) . First, we noted that the de-methylated Table 1 , Fig 3) . Interestingly, compound DS0464, where the amino-acid moiety is replaced with a physico-chemically more favorable phenyl-ethyl-urea, retains significant inhibitory activity (IC50: 1.1 ± 0.2 µM). Since all residues lining SAH and the substrate RNA cap GpppA in the SARS-CoV-1 nsp14 structure are conserved in SARS-CoV-2 ( Supplementary Fig.   8 ), the SARS-CoV-1 structure was used to dock DS0464 (Fig. 4) . The model revealed a possible arrangement where the adenosine end of the inhibitor overlays with the adenosine of the bound cofactor, and the terminal phenyl group recapitulates stacking interactions observed between the guanine ring of the RNA cap and surrounding residues (Y420, F426, F506, N386) ( Fig. 4) . Such a binding mode suggests a mechanism of action where DS0464 behaves as a bi-substrate inhibitor.This possibility was further tested by performing mechanism of action (MOA) studies with DS0464 which revealed that DS0464 competes against both SAM and RNA and can act as a bifunctional inhibitor (Fig. 5, Supplementary Fig. 9 ).The selectivity of all seven compounds was tested against the human RNA methyltransferases BCDIN3D, and METTL3-METTL14 complex (METTL3-14), the RNA demethylase ALKBH5, and protein lysine methyltransferases G9a and SETD3 ( Table 1 , Supplementary Fig. 10-14) .Interestingly, none of the compounds inhibited G9a or ALKBH5 activities indicating some level of selectivity. SS148 and DS0464 potently inhibited BCDIN3D with IC50 values of 0.03 ± 0.002 and 46 ± 9 µM, respectively, but not G9a, SETD3 or ALKBH5 ( Table 1) . G9a and SETD3 are SET domain methyltransferases that are structurally distinct from class I methyltransferases such as nsp14, BCDIN3D or METTL3-METTL14, which could explain the observed specificity profile. 25 For instance, the channel separating the substrate and cofactor binding sites is wide in nsp14 but narrow in G9a. Additionally, a cavity that can accommodate the nitrile group of SS148 in nsp14 and BCDIN3D is absent in G9a, in agreement with the obtained IC50 values (Fig 6) . To further characterize our nsp14 inhibitors, the selectivity of SS148 and DS0464 was evaluated against a larger panel of lysine, arginine, DNA and RNA methyltransferases ( Table 2 , Fig. 7 ). As expected, while SS148 inhibited arginine, DNA and RNA methyltransferases (all class I methyltransferases), it did not inhibit any of the 20 SET domain lysine methyltransferases (Fig. 7 , Table 2 , Supplementary Fig. 15 ). DS0464 was even more selective and inhibited only PRMT4, PRMT5, PRMT7, DOT1L and BCDIN3D, but none of the protein lysine methyltransferases tested.( Table 2 , Supplementary Fig. 16 ).The frequent emergence in the last two decades of novel coronaviruses as human pathogens, highlighted by the current COVID-19 pandemic, urgently needs to be addressed, preferably with pan-coronavirus drugs. Nsp14 is an essential methyltransferase in RNA cap formation which is required for protecting viral RNA and proper replication of coronaviruses. Therefore, targeting nsp14 methyltransferase activity would be a viable option towards developing anti-viral therapeutics. 26 Methyltransferases are druggable. 27 In the last decade, a significant number of selective and cell-active small molecules (chemical probes) have been discovered for human methyltransferases 24, 28, 29 and some are in clinical trials for various cancers. 28, 29 Key to a successful discovery campaign of such chemical probes is the availability of reliable screening methods that could enable medium to high throughput screening with low false-positive and false-negative rates. Various assays including mass spectrometry 30-32 , fluorescence 33 , and radiometric assays 24 have been used for screening libraries of compounds. Mass spectrometrybased assays require more expensive instrumentation and expertise. Fluorescence assays can be performed in any lab, however, many fluorescent compounds in chemical libraries may increase the background and lead to high numbers of false positives to triage following screening large libraries. Radiometric assays are typically more reliable and have fewer false positives leading to identifying more reliable screening hits. 24 In this study, we have developed a radiometric assay for nsp14 and employed this assay for screening a small library of selected SAM competitive inhibitors and analogs.Targeting the SAM binding site has successfully led to the discovery of chemical probes for human methyltransferases such as DOT1L 34, 35 , EZH2/EZH1 36 , and SMYD2 37 . SS148 (nsp14 IC50: 70 ± 6 nM) was reported as a DOT1L inhibitor with a nitrile as a non-traditional replacement for heavy halogen atoms. 38 This is consistent with the selectivity of SS148 against all other protein lysine methyltransferases (PKMTs) due to narrower active sites that could not fit the added nitrile group ( Fig. 4) . Keeping this substitution in designing future nsp14 inhibitors will provide selectivity against PKMTs. WZ16 39 In this study, we developed a radiometric assay for nsp14 methyltransferase activity, determined the kinetic parameters and optimized the assay for high throughput screening. Through limited screening of SAM competitive inhibitors, we identified seven confirmed hits that we used to probe the active site of nsp14. Our study revealed a path towards developing selective bi-substrate inhibitors for nsp14.S-adenosylhomocysteine (SAH) and sinefungin were purchased from Sigma-Aldrich. S-adenosyl-L-methionine, 3 Expression and purification of SARS-CoV-2 nsp14 is provided as supplementary data.Methyltransferase activity of nsp14 was measured using a radiometric assay. The transfer of 3 To evaluate the effectiveness of the nsp14 assay for screening purposes, the Z′-factor was Nsp14 was screened against the in-house library of 161 compounds at 50 µM in 1% DMSO.Compounds with inhibition of more than 75% were selected as screening hits for further analysis.The hits were tested for assay signal quenching at 50 µM. The signal was generated using 0. Selectivity assays were performed as previously described. 24 Briefly, compounds were tested at 50 µM in duplicate using radiometric assays. IC50 values were determined for compounds with higher than 50% inhibitory effect, as described above.KD values for initial screening hits for nsp14 was determined by Surface Plasmon Resonance (SPR) using a Biacore T200 from GE Healthcare. N-terminally biotinylated nsp14 (aa 1-527) andC-terminally biotinylated SETD3 (aa 1-605, as control), were coupled on a CM5 SPR Sensor chip (GE healthcare). Compounds were injected into the sensitised chip at 5 concentrations (0.6, 1. Table1: Confirmation and selectivity of nsp14 screening hits. The screening hits were tested for binding to nsp14 by SPR and for inhibition of methyltransferase activity of nsp14 and selected methyltransferases by activity assays. All values are from experiments presented in Figure 3 , and Supplementary Fig. 7, 10 Table 2 . Table 1 . ",Canada,first author,2021-02-19,02
a3f50b5e8d44a0df716e4080c6eacbd50f8ec91d,Original Investigation Title: Role of Heterogeneous Transmission in the Decline of COVID-19 Cases During Winter of 2020/2021 in Massachusetts,"The intensity of transmission of the novel coronavirus disease 2019 (COVID- 19) varies significantly across towns of Massachusetts (MA). Figure 1 shows the frequency distribution of the total accumulated COVID-19 cases before the January 12 th , 2021 peak (hereafter referred to as accumulated cases), and their spatial distribution. The mean of accumulated cases is 44.5 per thousand people and the standard deviation is 26 per thousand indicating significant heterogeneity in the transmission of the disease.The recent consistent and widespread decline of COVID-19 prevalence in MA, as well as the USA, gives us a strong motivation and context for the investigation of heterogeneous disease dynamics. The main objective of this study is to investigate the role of heterogeneous transmission in shaping the dynamics of COVID-19 in MA, especially the significant decline during winter of 2020/2021.Weekly data on confirmed COVID-19 cases, number of tests, and positivity rate (i.e., total number of positive test as a fraction of the total number of tests) at the scale of different towns within the state of MA, for the period April 15 th , 2020 to February 9 th , 2021, are accessed from an archive of COVID-19 weekly public health reports (available at https://www.mass.gov/info-details/archive-of-covid-19-weekly-publichealth-reports). The data for April 15 th 2020 includes accumulated cases before that date. We applied a count of confirmed cases per one thousand people to assess the overall impact of a COVID-19 pandemic on towns of different population sizes in MA. Among a total of 351 towns in MA, this study considered 310 towns where total accumulated confirmed COVID-19 cases on January 12 th 2021 are not zero and there are no missing values during the analysis period.Town-level population data are taken from the annual estimates of the resident population for incorporated places in Massachusetts. 14 With this data, the density of population is calculated by dividing the population by area which is available at https://en.wikipedia.org/wiki/List_of_municipalities_in_Massachusetts. To identify the potential effect of poverty on COVID-19 spread, median house income data is utilized, which is available at https://en.wikipedia.org/wiki/List_of_Massachusetts_locations_by_per_capita_incom e. The results for this analysis are shown in Supplementary Material.Statistical relationships between accumulated confirmed COVID-19 cases on January 12 th , 2021 and several independent predictors (i.e., population density, and median house income) are developed using correlation analyses and presented in scatter plots (See Supplementary Material). p values are calculated using two-sided tests.We use the example of MA, whose recent trend is shown in Figure 2a (January 12 th to February 9 th , 2021), to analyze the variability in the dynamics of the disease across towns. We seek to determine how and why the magnitude of the decline varied across the different towns. In a homogeneous transmission mode, the magnitude of the decline would be uniform across the different towns. However, given the heterogeneous nature of the transmission in this state, and across the country, we would like to understand the origin and implications of this heterogeneity, and in particular if the associated variation in previous infection burden plays any role. This last point is important since we expect the distribution of immunity to reflect the heterogeneous transmission pattern. We will assume that exposure to the virus as well as level of acquired immunity are directly proportional to the accumulated cases. The more cases reported, the higher the level of immunity among the population.Starting around the 12 th of January 2021, the daily cases of COVID19 in MA started to decline significantly ( Figure 2a ). In about one month, the daily cases declined by 61% from 6.1 cases per thousand to 2.4 per thousand. This large decline reflects a similar trend in cases documented in the USA, with declines reported in most of the States, and an overall rate of decline larger than that of any downward trends since the emergence of this disease.When towns are sorted according to accumulated cases and split into two groups each with the same number of people of about 3.3 million, the pattern identified above persists. Defining the groups this way shifts the accumulated cases threshold from 40 cases per thousand to 61 cases per thousand. For towns with low accumulation, 10% of the towns reported an increase, while 90% reported a decline. For towns with relatively high accumulation, 1% of the towns reported an increase, while 99% reported a decline. This finding confirms that towns with relatively high accumulated cases are more (less) likely to show a decline (an increase) in cases compared to towns with relatively low accumulated cases. The patterns shown in Figure 2 (b and c) identifies these towns, at different thresholds of accumulated cases, 40 versus 61 cases per thousand.The number of cases reported in any town for the week of January 12 th 2021 is directly proportional to the total number of accumulated cases for that town. This relationship is shown in Figure 3 proportional to the reported cases on January 12 th , 2021, which is directly proportional to the accumulated cases in each town, according to Figure 3a . Figure 3 (b and c) show significant declines in observed cases and in positivity that are proportional to the accumulated cases. Towns with larger accumulated cases are reporting larger declines during the month following January 12 th , 2021.Consistent with the observed relationships presented in Figure 3 , the average confirmed cases for the week of January 12 th 2021 in the group of towns with high accumulated cases is about 6.9 cases per thousand, compared to 3.5 cases per thousand for the lower accumulated cases group, with the same population size ( Figure 4a) . Similarly, the declines for the two groups of towns are roughly 4.3 and 2 cases per thousand, over the period (January 12 th to February 9 th , 2021). If the reproduction number in the two groups of towns are identical you would expect, that the relative change in the cases among the two groups of towns would be the same.Our findings suggest that the heterogeneous nature of COVID-19 transmission is playing a significant role in shaping the rapid recent decline in reported cases in MA, and probably around the country. One of the scenarios for the elimination of COVID-19 from any population assumes that the level of natural immunity would increase to reach a threshold where new infections would be hampered and would occur at a rate lower than the rate of patients' recovery. Under such conditions, new transmission is increasingly made impossible, leading to elimination of the virus. This threshold defines ""herd"" immunity. Estimates for herd immunity in the US population, as communicated by federal public health officials, range from 60 to 80%. There have been suggestions, however, that due to heterogeneous nature of the transmission herd immunity may be achieved at significantly smaller levels of immunity of about 40%. 8Most of these proposals were based on theoretical studies. Our findings, based on analysis of data on reported cases, support the idea that heterogeneous transmission can be an important factor in shaping the dynamics of COVID-19 transmission.Therefore, we recommend that lower estimates of the threshold for ""herd"" immunity, suggested by some recent theoretical studies, may deserve further investigation by other research groups investigating ""herd"" immunity, and some attention from federal and state public health authorities concerned with the future evolution of the pandemic.",USA,first author,2021-02-23,02
5eec0a1daa0ef54ca0946bc546524e405c2dce20,The Journal of Emergency Medicine Maximize the Use of Point-of-care Ultrasound in the Emergency Management of COVID-19,"Objectives:We devised a pathway called COVUS that incorporates POCUS into the initial evaluation of 15 PUIs for COVID-19 to guide diagnosis and management.Discussion:The pathway was derived based on review of literature, consensus from the ultrasound faculty, 18 as well as feedback from the entire faculty group at one academic institution with high volumes 19 of COVID-19 patients. The scanning protocol utilizes a cardiac first, rather than lung first, 20 approach to identify potential concomitant organ failure that may immediately alter management. population, but had a significant impact on health care workers. 14 One recent study found that 63 over a third of health care providers who received testing in a large New York City health care 64 system tested positive for COVID-19. 14 We now also know that greater viral load is associate The pathway was derived based on existing evidence in literature as well as clinical experience.We developed this protocol partly in response to the overwhelming concentration of lung 85 POCUS in COVID-19 literature. We focused on organ systems that could make the biggest 86 difference in emergent management. As such, we had initially discussed only incorporating 87 cardiac POCUS into the clinical evaluation of PUIs to minimize exposure as the pulmonary 88 findings are relatively stereotyped. 9,11,12 However, we have witnessed 2 of our PUI for COVID-19 89 with other pulmonary complications, such as pneumothorax and empyema. Since these 90 pathologies can be easily and rapidly diagnosed by POCUS with minimal additional exposure to 91 the provider, lung POCUS was included in the COVUS pathway to assess pulmonary 92 complications, to establish a baseline for inpatient teams, as well as to provide a more 93 comprehensive evaluation of PUIs. However, we felt that a cardiac first approach was more 94 critical than the lung POCUS exam alone as it has the potential to provide more timely 95 information regarding underlying concomitant pathology that require more emergent intervention.We presented our pathway during an online departmental meeting and circulated the pathway We provide probable cardiac complications found in patients with COVID-19 in Table 1 .If there is any evidence of acute cardiac pathology, clinicians are encouraged to manage the 118 patient accordingly, which may include further imaging such as computed tomography, 119 consultation with other subspecialty services, and strongly consider admission to higher level of 120 care for closer inpatient monitoring. 4,6,7 The flow chart in Figure 1 ",USA,first author,2021-02-09,02
c46eda7efc061973c829b62fbfb55f35cf091cae,Air Quality Enhancement Districts: democratizing data to improve respiratory health,"On October 5, 2020, The U.S. Centers for Disease Control and Prevention (U.S. CDC) has officially acknowledged that the principal mode for SARS-CoV-2 (the virus that causes to spread is through airborne particulate matter (droplet and particles) (U.S. CDC 2020). Preliminary research on COVID-19 (e.g., Comunian et al. 2020; Liu et al. 2020; Mehmood et al. 2020; Wu et al. 2020) has also found that patients in areas with higher levels of fine air particulates, known as PM 2.5 , are more likely to die from a COVID-19 infection than patients in areas with cleaner air quality. The COVID-19 virus causes respiratory illnesses that can lead to acute respiratory distress syndrome, which in some cases requires a ventilator for survival, and may cause permanent lung damage (Cox 2020 ). Therefore, it is possible that COVID-19 will result in an increased number of individuals who are sensitive to poor air quality. Though the Trump administration engineered drastic rollbacks of environmental regulations, even in the midst of the COVID-19 pandemic, future steps may be needed to (1) equip individuals with better information about local air quality on poor air quality days, and (2) empower communities to modify activities and advocate air quality concerns in the short and long term to reduce exposure to air pollution.In this article, we use a multi-disciplinary approach, drawing from the fields of environmental health and engineering, as well as public administration and policy, to explain the link between COVID-19 and air quality and to propose a community-engaged solution. We propose specific ways in which low-cost air quality sensors and local air quality enhancement districts can improve our current regulatory structure and tools to protect public health during the pandemic and afterwards. We hope this information leads to collaborative deployment of sensors and networks in areas hardest hit by COVID-19 that are also more commonly exposed to poor air quality, including environmental justice communities. Following models from parallel structures, we describe the technology and management design to quickly implement air quality protective actions, and possibly save lives.Link between air quality and COVID-19 PM 2.5 refers to particulate matter with aerodynamic diameter equal or less than 2.5 micrometers, consisting of a complex mixture of both solid and liquid droplets suspended in the air. Tiny particles of these sizes are more likely to penetrate deep inside lungs and have the potential to cause significant adverse health effects, including difficulty breathing, heart-attacks, aggravated asthma, decreased lung function, and premature death (Wu et al. 2020; Wang et al. 2020) . In 2015 alone, exposure to PM 2.5 is believed responsible for approximately 8.9 million premature deaths worldwide, with 213,000 premature deaths in the USA and Canada alone (Burnett et al. 2018) .PM 2.5 is a complex pollutant because it can come in many different sizes and shapes, and can consist of hundreds of chemical species. Some of the PM 2.5 components can be attributed to direct emissions (such as construction and road dusts, power plants, biomass burning and motor-vehicles), while others may be formed through chemical reactions occurring in the air. The toxicity of PM 2.5 can also vary depending on its chemical composition, with vehicle exhausts and fire emissions found to be more harmful than others (Park et al. 2018) . While the underlying biological mechanism on how PM 2.5 adversely impacts heath is still a topic of investigation, PM 2.5 can trigger acute respiratory inflammation, damage human airways and weaken immune response, all of which may facilitate viral infections (Comunian et al. 2020; Lodovici and Bigagli 2011; Mehmood et al. 2020) .Recently, an increasing amount of research has suggested a statistical link between death or serious illness from COVID-19 in areas with higher levels of outdoor PM 2.5 concentrations (Comunian et al. 2020; Conticini et al. 2020; Fattorini and Regoli 2020; Mehmood et al. 2020; Wu et al. 2020; Yao et al. 2020; Zhu et al. 2020; Zoran et al. 2020) . Similar findings were reported during the SARS outbreak, which was also caused by a coronavirus. Cui et al. (2003) found that SARS patients from highly polluted regions in China were twice as likely to die from SARS compared with patients from relatively clean regions. In the USA, race and socio-economic status are highly correlated with exposure to harmful air pollution. Already, it is being reported that African Americans are more likely to die from COVID-19, with disproportionately higher death rates in the USA (Holmes et al. 2020) , and states like Illinois, Louisiana, Michigan, and Florida (Wolfe 2020; Santich 2020) . While there are numerous factors that contribute to this, such as access to healthcare and higher rates of front-line and service-industry jobs, many African Americans live in urban areas with poorer air quality. Studies show African Americans have higher rates of asthma, lung, and heart disease (Miranda et al. 2011) , which are associated with higher death rates from COVID-19 (Wu et al. 2020 ).Air quality in the USA continues to improve across the country, with significantly fewer areas designated as out of compliance with current ambient air quality standards. While there is much debate about how well these standards reflect the current state of science to protect public health (Heikkinen 2018; Wang et al. 2020; Parker 2016) , there has been a steady improvement in air quality for most pollutants across the country, including PM 2.5 (U.S. EPA 2019).The Air Quality Index (AQI) is an index for reporting daily air quality based on federally approved air quality monitors, with a focus on health impacts (U.S. EPA 2020). The AQI identifies different air quality categories with related health impacts, ranging from ""good"" with no health impacts expected to ""very unhealthy"" which recommends limiting or completely avoiding all outdoor activities based on health sensitivity. In 2019, approximately 26% of counties with a regulatory air quality monitor experienced at least one day where air quality was unhealthy for sensitive groups including people with heart or lung disease, older adults, and children.Due to COVID-19's long-lasting impact on lungs and respiratory health (Cox 2020) , the size of this sensitive group may grow considerably, particularly in areas hardest hit by COVID-19. Since many of these areas are already predisposed to lower air quality, this situation exacerbates the need for quick responses to poor air quality days. These areas are scattered throughout the USA, but are commonly located in high population corridors, such as the New York City-Philadelphia-Washington, DC area, and cities such as Atlanta, Houston, and Denver.Notably, air quality has improved in most parts of the country since stay-at-home orders have been put in place. There have been significant decreases in PM 2.5 and ozone, two of the main pollutants that affect human health, since mid-March, by as much as 30% in some areas such as the West Coast before the 2020 wildfires (Freedman and Tierney 2020) . The drastic improvement in air quality most likely stems from reduced vehicular travel, but more research needs to be done to measure this impact while controlling for other factors such as changes in the weather. The implication, though, is that governments can put into place localized restrictions or recommend residents stay-at-home to reduce the impact of a dangerous air quality forecast for hardest hit COVID-19 areas with a high at-risk population for respiratory distress.Despite these improvements, the Trump Administration rolled back over 95 environmental regulations from 2017-2020, many of these directly or indirectly affecting air quality (Popovich et al. 2019) . In March and April 2020, during the COVID-19 pandemic, the U.S. EPA rolled back vehicle emissions standards that directly impact PM 2.5 , and announced plans to leave the current National Ambient Air Quality Standard for PM 2.5 at the 2012 threshold after scientists recommended tightening it to be more reflective of the current state of knowledge regarding PM 2.5 impact on human health (Reilly 2020; Heikkinen 2018) . Studies show increased risk of premature death from fine particle pollution at levels much lower than the current PM 2.5 standards, and conclude that there is no threshold level without health risks .As has been the case in other elements of COVID-19 response, state and local agencies play an important role in protecting and prioritizing public health, especially when the federal response is slow and poorly coordinated. If the trends in relaxing federal air quality regulations continue, more localized networks better attuned to community needs will be needed to improve local air quality. For example, using the same reduction in death rates and PM 2.5 concentration data from the Harvard study (Wu et al. 2020) , we find that a 1 microgram per cubic meter reduction in long-term PM 2.5 averaged over 2000-2016 in New York City (approximately 8% reduction in PM 2.5 concentrations) could have saved 1915 lives that were lost to COVID-19 as of October 20, 2020 (NYSDH 2020) . This could bring the death rate from COVID-19 cases down from the current rate of 9.2% to 8.4% in New York City.To achieve the kinds of PM 2.5 reductions described in the previous section that could have saved approximately 2,000 or more lives in New York City, and that can save lives in the event of future respiratory infections, we recommend a monumental, but not unprecedented, governance innovation. Specifically, we recommend the creation of federally funded Air Quality Enhancement Districts (AQED) in high-risk neighborhoods and communities throughout the United States. In this section, we outline the model of AQEDs, including parallel structures designed for other policy aims. We also outline the specific technologies-low-cost air quality sensors-required to implement AQEDs successfully.Three core principles and outcomes guide the enactment of AQEDs. These are both principles and outcomes simultaneously, in that they are the foundation of a transformed local governance regime and the results that can occur so long as commitment to the same principles is not corrupted or manipulated by local political or commercial interests.The first principle is democratization of air quality data and empowerment of residents to use the data. A phrase that captures the essence of this idea emerged during the apartheid years in South Africa and has more recently been adopted for use by anti-poverty campaigners in parts of England (Bryer and Prysmakova-Rivera 2018): Nothing without us about us is for us. The meaning of this phrase is at once simple and complex. It is complex in that it raises a host of issues, such as the meaning and enactment of democratic accountability, representation, and empowerment.Applied to air quality and the notion of AQEDs, the logic is the same. Scientific and regulatory experts can use their scientifically engineered instruments to assess air quality at given places and times, make a judgement if the assessed air quality is safe for various levels of activity based on further scientific and medical judgement, and communicate to a passive citizenry with recommendations for a range of daily activities, such as opening home windows, running the air conditioner, or exercising outdoors.The approach suggested by the phrase-nothing without us about us is for us-challenges core assumptions of the expert model. For example, consider these scenarios:& Residents in a neighborhood enjoy coming together for a community cookout in the local park. The City or local construction firms under contract plan infrastructure improvements that will cause an increase in air pollution. Citizens, aware of the coming spike in pollutants, work with City officials to schedule these at times not important for the neighborhood. & Residents in a neighborhood have access to local air quality data every day, and they learn, over time, the changes in air quality that come with different weather conditions. They have more ability to plan events and activities for themselves, their families, and with their neighbors. & Residents detect prolonged periods of higher than normal air pollution. They have access to the data they need to share with each other and with government officials to determine the source and mitigate the pollution in the short and long term.In short, nothing without residents, particularly in urban environments, about the air breathed by residents, is done for the residents themselves. Policy actions might be taken based on scientific data, but the actions might be slow in coming and non-responsive to actual resident and neighborhood needs and interests. The underlying philosophy of this first principle is consistent with those values expressed by Agyeman (2005) in his book, Sustainable Communities and Challenges of Environmental Justice. Agyeman introduces both deliberative and inclusionary processes and procedures (DIPS) and community-based social marketing (CBSM) as means to ownership of environmental health to community members.The second principle is resident awareness of pollution within their neighborhoods, and vulnerability to disease. Through access to data and the ability to use data on air quality, residents can further, in this model, increase their knowledge of how pollution leads to higher risk for other health issues, with particular concern for respiratory ailments. Education of residents is further fodder that can instigate citizen action once they are properly armed with data (Conrad and Hilchey 2011; Riesch and Potter 2014) .The continuous involvement of residents through education and data collection, and ultimately to the third element stated next, are fundamentally the ingredients of participatory action research and engaged scholarship. These principles are consistent with the tenets of the Johns Hopkins Urban Health Institution communitybased participatory research model (Agyeman 2005) and specifically are grounded in the assumption that particularly low-income, less educated residents that predominate environmental justice communities are more likely to be disempowered and manipulated through standard governance practices. Empowerment through education and embedded as active citizen-scientists changes the power and thus policy-making dynamics within communities (Freire 1968 ).The first two elements combine to facilitate the third, policy change driven by residents with local governments (Mathews 2019) who are empowered and mobilized through data and awareness. Policy change occurs through multiple pathways, such as those described in Kingdon's multiple streams framework (1984) . At the heart of the framework is the idea of a policy window; something has happened, a focusing event, that draws attention to a problem to be fixed or opportunity to be leveraged. Coronavirus and the pandemic are focusing events, but so too can be prolonged heightened measures of air pollution. Once residents are equipped with the data, knowledge of how to use the data, and awareness of the health consequences of poor air quality, new solutions can be pushed through the window. Empowerment of the citizenry is critical for the window to open and remain opened, particularly if poor air quality is localized and not likely to catch the attention of a wide dispersion of residents. Policy change that occurs to enhance air quality at any given period of time can save lives in the event of a significant health risk, such a coronavirus, in the future.The AQED approach further allows for proactive, community-driven policy change, which is more likely to lead to sustainable and just environmental outcomes for historically underserved communities. Reactive policy changes might mitigate harms, but they fail to empower residents and policymakers to design spaces and systems that prevent environmental hazards from emerging at all (Agyeman 2005) .Understanding the status of current air quality is crucial for air quality management. Currently, concentrations of important pollutants including PM 2.5 are measured at stationary monitor networks using designated instruments that usually cost tens of thousands US dollars, and are expensive to operate and maintain (Hall et al. 2014) . Due to the cost restrictions, the number of stations is limited, though pollution concentrations are known to vary drastically spatially (Karner et al. 2010 ).The emerging low-cost air quality sensor is enabling a paradigm shift in the field of air quality monitoring (Snyder et al. 2013; Jiao et al. 2016) . These sensors are generally easy to use, require minimum maintenance, and can provide data in near real-time. Due to their low cost, these sensors can be quickly deployed to establish a smart and connected network to characterize spatiotemporally resolved pollutant concentrations (Yi et al. 2015; Jiao et al. 2016) . As a relatively new and still fast-evolving technology, the performances of low-cost air sensors vary considerably among models and are also impacted by environmental conditions such as temperature and humidity (Duvall et al. 2016 ). An active area of research is to develop methods for correcting sensor data, which we are currently working on using innovative modeling methods for remote calibration of sensors to improve sensor reliability (Miskell et al. 2019; Zheng et al. 2019) .Despite these shortcomings, the easy-to-use and lowmaintenance features of low-cost sensors enable genuine public participation in air quality monitoring, where affected or concerned communities and stakeholders can be involved throughout the entire process, such as monitor location selection, deployment, data collection and dissemination (English et al. 2017) . Such a community-engaged and stakeholderinvolved approach not only addresses the needs of the general public related to air quality, but it also provides new avenues for public education, advances citizen science, and contributes to sustainable social development (Conrad and Hilchey 2011; Riesch and Potter 2014) . However, areas that pursue AQEDs will need to consider how to cover the costs of the network, and best methods of education on sensor network use for the community.As commercial air quality sensors have become more available, the US EPA has developed new tools and information to help air quality managers and the public better understand how they work and how to use them. There is also an interest in using air quality sensors to measure pollutant concentrations in localized areas with known air quality issues, or help identify where federal air quality monitors might be needed. The US EPA and other local air quality management agencies, such as the California Air Resources Board, are currently using sensors for exploratory research and supplemental monitoring (U.S. EPA 2020; CARB 2020).The AQED model has historical and contemporary parallels. First is the Air Quality Management District (AQMD), or Air Quality Compliance District. These are instituted to ensure local air quality is in alignment with federal standards and are used throughout the USA. The AQMD approach is expertbased and does not include a natural driver to empower residents who can meaningfully engage in dialogue and advocacy to enhance air quality, including and beyond the point of compliance. Second, there are a number of community air monitoring systems using low-cost sensors, mostly located in California, that have received strong support from the State of California's Air Resources Board (CARB 2020) that more closely resemble our approach. While each of these in California and elsewhere vary to some degree on the level of community involvement, community collaboration is a key feature of the network. However, we suggest a program with stronger federal support and funding to protect the long-term sustainability of these projects, especially as state and local areas grapple with serious budget shortfalls due to the COVID19 crisis.Air quality enhancement districts with low-cost air quality sensors can provide important information for citizens to make better health-based decisions during and after the COVID-19 pandemic, especially in environmental justice communities. Since COVID-19 has been linked to higher mortality rates and causes permanent lung damage in some survivors, local air quality will be increasingly important in communities hardest hit by COVID-19. These urban, poor, or underrepresented communities tend to have higher levels of air pollution and exposure due to industry, traffic, wildfires, construction, or other sources that may not be well measured by our existing federal air quality monitoring network. Using more highly distributed and accessible air quality sensors in an equitably designed AQED will empower citizens and communities to make better health-based decisions to mitigate further damage from COVID-19.",USA,first author,2021-02-04,02
6e3ac8f3c5659a2992372696dde4e3e835b033e2,Just the facts: updates in COVID-19 therapeutics,"Convalescent plasma demonstrated promise early in the pandemic [4] . A Cochrane review with 19 studies (2 RCTs) found no clear evidence that convalescent plasma reduces mortality or improves clinical symptoms, with unclear side effects [5] . Thus, it remains uncertain whether convalescent plasma provides any benefit in patients with COVID-19, and we do not recommend it for routine use at this time [4] .Remdesivir is currently approved by the United State Food and Drug Administration (U.S. FDA) for use in COVID-19 [4] . One of the largest studies to date is the ACTT-1 trial, which included 1062 patients with confirmed COVID-19, of which 85% were classified as severe [6] . Patients receiving remdesivir demonstrated faster time to recovery (10 vs 15 days), but on subgroup analysis, this was only present in patients on low flow oxygen. This specific subgroup also demonstrated reduced mortality. Among those who were critically ill on mechanical ventilation or extracorporeal membrane oxygenation, there was no difference in time to recovery or mortality. In patients with non-severe disease, there is also no clear benefit. The ACTT-1 trial included 119 patients with mild-moderate disease, with no difference in time to recovery with remdesivir [6] . In a separate RCT of 584 patients with moderate COVID-19, the authors found no significant difference in clinical status based on a 7-point ordinal scale after a 10-day course of remdesivir [7] . Another RCT found no difference in mortality [8] .Remdesivir has only shown benefit in a very narrow clinical spectrum, and therefore routine use for all patients is not recommended.Bamlanivimab is a monoclonal antibody which recently received an emergency use authorization by the U.S. FDA for treatment of patients with confirmed mild to moderate COVID-19 within 10 days of symptom onset and risk of progressing to severe disease [9] . It requires intravenous infusion and is not authorized for patients requiring supplemental oxygen or those who are hospitalized [9] . As of late November 2020, the evidence is controversial in its ability to reduce the viral load or reduce hospitalizations, and the Infectious Diseases Society of America recommends against its routine use [10, 11] . Other monoclonal antibodies, alone or in combination, are under evaluation.While initially purported as a treatment strategy early in the pandemic, antimalarial agents (e.g., hydroxychloroquine, chloroquine) have not demonstrated significant benefit, while demonstrating significant risk of harm, including severe cardiac arrhythmias [3] . As a result, antimalarial agents are no longer recommended for the treatment of COVID-19.1. For patients with COVID-19 requiring supplemental oxygen, glucocorticoids (dexamethasone 6 mg) are recommended. 2. It is uncertain whether convalescent plasma provides any benefit in patients with COVID-19. 3. Remdesivir may benefit patients on low flow oxygen, but benefit is not present in other populations. Routine use for all patients is not recommended.4. It is uncertain whether bamlanivimab or other monoclonal antibodies reduce viral load or need for hospitalization. 5. Hydroxychloroquine and chloroquine have no benefit and may result in harm; thus, they are not recommended.Infographic. COVID-19 therapeutics updates.",USA,first author,2021-02-08,02
53953aa0764215f7d3c0289c1e0b00aa70900327,"Multiplexed, Microscale, Microarray-based Serological Assay for Antibodies Against All Human-Relevant Coronaviruses","in clinical use typically establish specificity using pre-pandemic serum samples which cannot conclusively show that pre-existing antibodies to the endemic coronaviruses do not cross react with SARS-CoV-2.Serological testing that assesses binding to a variety of coronaviruses is important for: (1) screening enrollees before trial admission to establish baseline antibody titers, (2) have highlighted the unknowns about pre-existing immunity to SARS-CoV-2. 16, 17 In light of these unknowns and recent discussion around the potential for antibody dependent enhancement, [18] [19] [20] monitoring the serological responses before and after immunization to other human coronaviruses, such as SARS, MERS, and the endemic coronaviruses including HKU1, OC43, NL63, and 229E, and comparing these responses to those from natural infection as a function of disease severity, will be critical for understanding the immune response and ultimately delivering a safe and effective vaccine.For effective application in vaccine clinical trials, a highly specific and highly quantitative assay is required to enable accurate quantitative assessment of antibody responses. Given the rapid timelines for vaccine development already underway, a multiplexed assay that can measure vaccine-induced antibody response to a variety of related antigens simultaneously is highly desirable for both time and cost savings. The VaxArray platform (InDevR, Inc., Boulder, CO) is a microscale, multiplexed, microarray-based immunoassay platform that has been well-validated for use in influenza vaccine antigen characterization, 21, 22 and has been adapted for serological analysis of coronaviruses with the recent availability of the Coronavirus (CoV) SeroAssay.Specifically, nine unique coronavirus spike protein antigens are printed in replicate in a microarray format, providing the ability to perform simultaneous analysis of antibody responses to all 9 antigens in a single, 2-hour assay. In comparison, one would have to run 9 parallel J o u r n a l P r e -p r o o f ELISA plates to obtain the same information content. The 9 proteins represented on the microarray are full-length spike, receptor binding domain (RBD), and the S2 extracellular domain of SARS-CoV-2, and the spike proteins from SARS, MERS, HKU1, OC43, NL63, and 229E. In addition, the platform is antigen-sparing, requiring ~200x less antigen to manufacture than a traditional plate-based ELISA, which is particularly important during this time of strained supply chains. Lastly, the CoV SeroAssay is provided as a validated, off-the-shelf kit to minimize user-to-user and laboratory-to-laboratory variability associated with in-house immunoassays, and the associated software provides automated analysis of the results to further increase ease of use.This study reports on the VaxArray CoV SeroAssay linear dynamic range, limit of detection, specificity, reproducibility, accuracy, and investigates assay performance on a retrospective set of 263 blinded, de-identified human serum and plasma specimens to demonstrate positive and negative percent agreement to a mixed reference method of RT-PCR on a patient-matched specimen and collection date prior to the COVID-19 outbreak. An easy-to-use, high information content assay with the capability to evaluate antibody response to a variety of coronavirus spike proteins will aid in monitoring the immune response during COVID-19 candidate vaccine clinical trials and ultimately facilitate the delivery of a safe and effective vaccine.The VaxArray Coronavirus SeroAssay Kit (#VXCV-5100, InDevR, Inc.) contains four microarray slides, printed with 16 replicate arrays per slide, an optimized Protein Blocking Buffer (VX-6305), Wash Buffer 1 concentrate (VX-6303), and Wash Buffer 2 concentrate (VX-6304). Prior to use, microarray slides were equilibrated to room temperature for 30 min in the provided foil pouch. Prepared standards and specimens were diluted at least 1:100 in Protein Blocking Buffer J o u r n a l P r e -p r o o f and applied to the microarray and allowed to incubate in a humidity chamber (VX-6200) on an orbital shaker at 80 rpm for 60 minutes. After incubation, samples were removed using an 8channel pipette, and the microarray was subsequently washed by applying 50 µL of prepared Wash Buffer 1. Slides were washed for 5 minutes on an orbital shaker at 80 RPM after which the wash solution was removed via 8-channel pipette. During sample incubation, Anti-human IgG Label (VXCV-7623) and/or anti-mouse IgG Label (VXCV-7620) were prepared by first diluting the label 1:10 in PBB, and aliquoting into 8-tube PCR strips after which 50 µL of label mixture was added to each array using an 8-channel pipette. Detection label was incubated on the slides in the humidity chamber for 30 minutes before subsequent, sequential washing in Wash Buffer 1, Wash Buffer 2, 70% Ethanol, and finally ultrapure water. Slides were dried using a compressed air pump system and imaged using the VaxArray Imaging System (VX-6000).A study to determine the lower limit of quantification and linear dynamic range of the different capture antigens represented was executed using monoclonal antibodies that target the spike proteins of SARS-CoV-1 (MRO-1214LC, CR3022, Creative Biolabs), SARS-CoV-2 (GTX632604, Genetex), MERS (40069-MM23, Sino Biological), and HKU1 (40021-MM07, Sino Biological). The CR3022 antibody targeting SARS-CoV-1 is known to bind the the nCoV(ii) RBD antigen, the SARS antigen (and the nCoV(i) full-length spike antigen to a much weaker extent), and the SARS-CoV-2 Genetex antibody is known to bind the nCoV(i) full-length spike antigen (and the nCoV(iii) S2 antigen to a much weaker extent). The four antibodies were mixed, and a 13-point serial dilution in Protein Blocking Buffer and three blank wells containing Protein Blocking Buffer without antibody were prepared, with each sample subsequently analyzed on the VaxArray CoV SeroAssay according to the operation manual with one exception: because the anti-SARS-CoV1 antibodies are human antibodies and the other three antibodies are mouse antibodies, antibodies were detected with a mixture of anti-mouse and J o u r n a l P r e -p r o o f anti-human IgG secondary antibody labels (VXCV-7620 and VXCV-7326, InDevR, Inc., respectively). After analysis, the median signals extracted from the VaxArray Imaging System software for each relevant capture antigen for each dilution as well as for the blanks were This value was then averaged over the 3 blanks. In addition, the linear dynamic range (LDR) was calculated as ULOQ/LLOQ for each relevant capture antigen.Because monoclonal antibodies binding to the OC43, NL63, or 229E capture antigens were not available at the time of testing, linearity and limit of detection for these 3 capture antigens was explored using a limiting endpoint dilution series of a pooled human serum sample known to be previously shown to produce positive responses on the CoV SeroAssay for all four human CoVs: OC43, NL63, HKU1, and 229E. The pooled human serum sample was used to create a 13-point serial dilution in Protein Blocking Buffer with all samples subsequently analyzed in duplicate on the VaxArray CoV SeroAssay according to the operation manual. Data was extracted in the same manner as for the mixed monoclonal antibody analysis to determine the signals at the ULOQ and LLOQ (without back-calculating to concentration based on the linear fits, as the concentration in each of the dilutions is unknown). The LDR was expressed as the signal at the ULOQ divided by the signal at the LLOQ. The limiting endpoint dilution titer was also presented as the highest dilution factor at which the signal exceeded the signal at the LLOQ.J o u r n a l P r e -p r o o fSpecificity of the capture antigens was investigated using the same 4 monoclonal antibodies described for use in the LLOQ and LDR analysis. No monoclonal antibodies were available at the time of testing that target OC43, NL63, or 229E, and so specificity for these capture antigens was not assessed. However, we did assess specimens positive for all 4 endemic coronaviruses that were collected prior to the SARS-CoV-2 outbreak to examine potential crossreactivity with any of the 3 SARS-CoV-2 antigens. A total of 132 serum samples known to be negative for the presence of antibodies to SARS-CoV-2 based on date of collection prior to December 2019, including 33 specimens from pediatric donors age 2-16, were analyzed via the standard VaxArray CoV SeroAssay procedure at a 1:100 dilution in PBB.To assess reproducibility and accuracy, a pooled human serum sample known to be positive for antibodies to SARS-CoV-2 (and known to bind all 3 SARS-CoV-2 antigens on the microarray) and all 4 of the endemic coronaviruses (HKU1, OC43, NL63, and 229E) was prepared in adequate volume to run a large number of replicates. This sample did not contain any antibody reactive to the MERS capture antigen, and therefore, reproducibility and accuracy of the assay's ability to detect antibodies that bind to the MERS spike protein was not assessed. This study examined a single operator over three days of testing, as previous studies (data not shown) indicated little user-to-user or instrument-to-instrument variability. On days 1 and 2 of testing, a single slide containing an 8-point calibration curve (7 standards and a blank, analyzed at replicates analyzed are presented. Precision and accuracy data can be found in Table 3 .To determine the positive (PPA) and negative (NPA) percent agreement of the VaxArray CoV SeroAssay with a known result, 263 retrospective, deidentified human specimens (260 serum, 3 plasma) were obtained from the authors' institutions, collaborators, and commercial sources. The reference method used for specimens positive for SARS-CoV-2 antibodies was an RT-PCR result for a donor-matched specimen. The reference method used for specimens negative for J o u r n a l P r e -p r o o f antibodies to SARS-CoV-2 was either a negative RT-PCR result for a donor-matched specimen or a known collection date prior to the COVID-19 outbreak in late 2019. All specimens obtained from Colorado Children's Hospital were also analyzed independently by ELISA in a CLIAcertified laboratory using either an NP-based ELISA (Epitope Diagnostics, San Diego, CA) or by an S1-based ELISA (Euroimmun Ag, Germany), with a significant number of these specimens analyzed by both additional ELISAs. These ELISA results were used as orthogonal information to further investigate discrepant results. Testing personnel were blinded to these orthogonal results prior to completing VaxArray CoV SeroAssay analysis. The VaxArray CoV SeroAssay is a multiplexed immunoassay that consists of 9 coronavirus spike proteins printed in a microarray format as schematically illustrated in Figure 1 . Each of 9antigens are printed in 9 replicate spots in a single microarray, with 16 identical microarrays printed on each slide. Details regarding the capture antigens are found in Table 1 . The nCoV(i) full-length spike protein and nCoV(ii) receptor binding domain (RBD) protein were licensed from Icahn School of Medicine at Mount Sinai, and are described in Amanat et al. 23 All other antigens were obtained from commercial sources. For quantitative analysis, serum samples diluted in a blocking buffer are analyzed alongside a serial dilution of an appropriate standard material, which is utilized to quantify the antibody binding to each of the 9 antigens on the microarray.Antibodies in serum are captured by the printed antigens and are subsequently labeled with a fluorescent species-specific IgG label for detection. Spatial separation of the 9 antigens enables multiplexed analysis of antibody binding to a variety of coronavirus antigens. For qualitative analysis, serum specimens are diluted in a blocking buffer and analyzed at a single dilution factor and compared to an established cutoff value based on responses from a bank of known negative samples.To demonstrate the quantitative ability of the assay, a study was executed using a mixture of mouse and human monoclonal antibodies (mAbs) that target SARS-CoV-1, SARS-CoV-2, MERS, and HKU1 (see the Methods section for details). The 4 antibodies were mixed, and a 13-point dilution was analyzed using a mixture of anti-mouse and anti-human IgG labels. Figure   J o u r n a l P r e -p r o o f (ii), and (iii) antigens, respectively. Lower limits of quantification (LLOQ) for the 6 targeted antigens ranged from 0.32 ng/mL to 1.99 ng/mL, with associated linear dynamic ranges (LDR) from 76 -911x. Because there were no available monoclonal antibodies for OC43, NL63, or 229E at the time of testing, the linearity with dilution of the assay for antibody binding to these antigens was investigated by determining a limiting endpoint dilution titer using a pooled human serum sample known to be positive for all 4 endemic human coronaviruses. Table 2 shows the calculated LLOQ, upper limit of quantification (ULOQ), and LDR for the captures for which mAbs were available, as well as the limiting endpoint dilution titers (which range from 4000 to 16000) and LDRs for OC43, NL63, and 229E (which range from 16x to 32x).Monoclonal antibodies reactive to SARS-CoV-2, SARS-CoV-1, MERS, and HKU1 were analyzed to investigate specificity, with representative images shown in Figure 3 . No monoclonal antibodies were available at the time of testing that specifically target OC43, NL63, or 229E. One hundred thirty-two (132) human serum specimens negative for antibodies to SARS-CoV-2 were analyzed, and none showed reactivity to the nCoV(i) full-length spike or nCoV(ii) RBD antigens. Thirteen (13) To assess reproducibility and accuracy, a pooled human serum sample positive for antibodies to SARS-CoV-2, and also known to be reactive to the SARS antigen and the 4 endemic Table 3 shows the % CV in the back-calculated concentration value obtained on each relevant capture antigen for all 216 replicate measurements over all 3 days and all three lots of slides, with values ranging from 7 to 19 %CV for the 9 antigens. In addition, the %CV of the 8 replicates run on each slide in the study was analyzed to assess the intra-slide precision, resulting in an average intra-slide CV that ranged from 5% -8% for each of the 9 antigens, for an overall intra-slide CV of 6%.The data generated for the reproducibility study were also used to assess accuracy expressed as % of expected result (% recovery), where the expected result for all replicates was 0.4 J o u r n a l P r e -p r o o f arbitrary concentration units (highest standard assigned a value of 1, and other standards assigned based on dilution factor). The calibration curves generated using the quantitative mode of the VaxArray Imaging System software were utilized to back-calculate the measured concentration present for all the replicates for each of the relevant antigens. The concentrations determined were then averaged for all 216 replicates and compared to the expected concentration. These accuracy data are presented in Table 3 and range from 88 to 97% for the various capture antigens for an overall average accuracy of 92.5%.Two hundred sixty-three (263) deidentified specimens (260 serum, 3 plasma) were received for testing. The sample set included 132 specimens known to be negative for COVID-19 by RT- To demonstrate the range of underlying quantitative responses obtained from these clinical specimens, Figure 5 shows a scatter plot of signal to background ratios obtained for the nCoV(i) capture antigen for the 131 specimens from donors expected to be positive by RT-PCR, with signal to background ratios sorted from low to high. The data show that the antibody responses of these specimens from COVID-19 positive donors are highly variable.The availability of an accurate, precise, sensitive and specific multiplexed antibody Using monoclonal antibodies, we demonstrated the VaxArray CoV SeroAssay shows the expected specific response for 6 of the 9 antigens, with the monoclonal antibody to SARS-CoV-1 (CR3022) producing signal on both the nCoV(ii) RBD antigen and the SARS antigen (SARS-CoV-1 spike protein). This is not surprising given that SARS-CoV-1 and SARS-CoV-2 share a cellular receptor and have significant sequence homology. 2 The SARS-CoV-2 monoclonal antibody (Genetex) bound to both the nCoV(i) full-length spike protein and nCoV(iii) S2 extracellular domain. Importantly, though, neither of these antibodies bound to any of the human endemic coronavirus antigens on the array. As there were no specimens available from donors previously infected with COVID-19 but known to be negative for previous infections with all 4 endemic coronaviruses (likely due to the very high proportion of seropositivity to some or all of the endemic CoVs in the human population), 25 examining specificity of the polyclonal antibody response in humans in this manner is difficult. However, in our analysis of 132 human serum J o u r n a l P r e -p r o o f specimens from COVID-19 negative donors, no samples produced a signal to background value exceeding the threshold for the nCoV(i) or nCoV(ii) antigens. Thirteen (13) samples produced a signal to background value exceeding the threshold for nCoV(iii), indicating some crossreactivity of COVID-19 negative human serum on this antigen. Only one of the 13 specimens from COVID-19 negative donors that produced signal on nCoV(iii) was from a pediatric patient.In further analyzing pediatric specimens from COVID-19 negative donors, we note that a variety of responses to the endemic CoVs are present as shown in Figure 4 . As expected, younger children in general tend to have antibodies that bind to some of the 4 endemic coronaviruses, whereas older children and adolescents often show antibodies to all 4 in most cases. This is consistent with reports that seroconversion increases with age, with most adults showing seroconversion to all 4 human CoVs. 25 Importantly, in a pre-clinical or clinical trial for a candidate COVID-19 vaccine, specimens can be analyzed prior to vaccine administration to determine a baseline response to each of the antigens on the array. Therefore, serum reactivity to the nCoV(iii) antigen pre-vaccination can be accounted for by this baseline response. This response can then be compared to the response as a function of time post-vaccination, and any changes in reactivity to all 9 antigens can be quantitatively assessed to provide a broader profile of the antibodies produced after vaccination. That this can be accomplished in a single test with a 2-hour turnaround time means that serology analysis during a clinical trial can be completed in less time and for less cost.In a set of experiments involving 216 replicate analyses, the VaxArray CoV SeroAssay demonstrated good precision and accuracy, as shown in Table 3 . The data represented a single user testing over 3 days and on 3 unique lots of microarray slides (a total of 6 unique slides per lot). Within a single slide of 8 replicates, the average % CV of the measurements was 6%, indicating excellent precision on a single slide. This %CV ranged from 7% to 19% for the 9 J o u r n a l P r e -p r o o f antigens, averaging over all 3 days and all 3 lots. A higher %CV representing day-to-day and lot-to-lot variation is reasonable given the variables represented. As shown in Table 3 , nCoV(iii) demonstrated the highest variation. This was due to a single lot of microarray slides (lot 1) that produced a higher than expected 25% CV variation for this antigen, whereas lots 2 and 3 produced only 10% and 13% CV, respectively. Interestingly, however, the other 7 capture antigens investigated in this study did not experience a higher %CV for lot 1. This single lot may have experienced a printing artifact for this antigen, and the absolute signals generated on this nCoV(iii) antigen for this study were only ~2x LLOQ. Regardless of the root cause, printing optimization efforts are underway to improve the lot-to-lot consistency in performance of this antigen. Accuracy expressed as % recovery (% of expected result) was also quite good, ranging from 88% to 97% over the entire dataset of n=216 replicates. Unsurprisingly, nCoV(iii) also suffered from the lowest accuracy on the same lot of slides showing lower than expected precision. The average accuracy of the nCoV(iii) result was 80%, 85%, and 100% for lots 1, 2, and 3, respectively.The clinical specimen analysis summarized in Table 4 indicates the VaxArray CoV SeroAssay has excellent positive and negative percent agreement compared to a mixed reference method of RT-PCR status for a matched donor specimen or collection date prior to the COVID-19 outbreak in late 2019. The cutoff established for the VaxArray CoV SeroAssay takes advantage of the unique multiplexed capability of the assay by using a multi-antigen approach to thresholding to increase the confidence in a positive or negative call. Specifically, the signal on the nCoV(i) antigen was used as a first 'gate' to a positive call, and the sum of the three nCoV antigens was used as a secondary 'gate' to a positive call. Both cutoffs had to be exceeded in order to make a positive call, providing additional confidence against false positive results. This thresholding methodology resulted in 98.5% positive agreement (129/131) and 100% negative agreement (132/132) with the mixed reference method. The two specimens that produced false negative results by the VaxArray CoV SeroAssay were obtained from Children's Hospital of Colorado, and both were independently found to be negative by two alternative IgG-based ELISA assays, and both had very low titers by a virus neutralization assay (data not shown). All orthogonal analyses were conducted by Children's Hospital of Colorado, and InDevR staff analyzing the clinical specimens by the VaxArray CoV SeroAssay were blinded to these results.These additional serological analyses indicate concordance with the VaxArray CoV SeroAssay results, likely indicating that either the donors produced little to no antibody response after infection, or that the associated RT-PCR results were false positives.As an additional comparison, we also analyzed the PPA and NPA with the mixed reference method for both the Euroimmun and Epitope Diagnostics ELISAs that were run on the To convey the benefit of using this multi-antigen diagnostic approach for the VaxArray CoV SeroAssay over a single antigen approach such as that used in a standard singleplex ELISA, we also compared the PPA and NPA for that would result if each of the nCoV antigens on the CoV SeroAssay were assessed separately. In this case, nCoV(i) resulted in PPA of 98.5% and NPA of 100%, nCoV(ii) resulted in PPA of 96.2% and NPA of 100%, and nCoV(iii) produced the biggest difference from the multi-antigen approach with PPA of 83.2% and NPA of 91.7%.These data highlight that for this dataset, the performance of nCoV(i) alone produces the same PPA and NPA as the multi-antigen approach. In addition, these data highlight the previously mentioned cross-reactivity of the nCoV(iii) antibody in specimens known to be COVID-19negative. While these data highlight that a multi-antigen approach can produce more optimal J o u r n a l P r e -p r o o f performance than analysis of a single antigen response in a diagnostic algorithm, we note that there is also value in the ability to examine individual responses to each individual capture agent for assessment of comparative binding of vaccine antigens.To highlight the underlying quantitative response generated for these clinical serum specimens, Figure 5 shows the signal to background ratio produced on the nCoV(i) capture antigen for all 131 serum specimens from patients known to be COVID-19 positive by RT-PCR, sorted from lowest to highest. Given that all specimens were analyzed at the same 1:100 dilution and the analytical data indicating the quantitative ability of the assay, these data are indicative of relative SARS-CoV-2 antibody concentrations. The two clinical specimens that produced false negative results described above are the first two datapoints in the lower left closest to the origin, with corresponding signal to background ratios of 0.63 and 0.68. The remainder of these data show that a wide range of antibody responses were observed in the positive specimens, highlighting the quantitative capabilities of the assay for assessing antibody response in COVID-19 vaccine pre-clinical and clinical trials. In addition, tools such as the VaxArray CoV SeroAssay could easily be used to correlate severity of disease with antibody titer produced, and for a wide variety of other SARS-CoV-2 applications to add to our current understanding.Developers and manufacturers of candidate COVID-19 vaccines face the daunting challenge of bringing a safe and effective vaccine to market in record time to put a halt to the current global pandemic. As such, tools that empower developers and manufacturers to conduct vaccine clinical trials efficiently and to obtain the maximum amount of information in a rapid turnaround time are critical. The collective studies presented herein demonstrate that the VaxArray CoV SeroAssay is one of those tools, offering excellent analytical performance in terms of limits of quantification, high precision and accuracy and high clinical sensitivity and specificity. While most of the data herein demonstrated applicability to measurement of IgG antibodies in human J o u r n a l P r e -p r o o f serum, applicability to other animal models such as mouse or non-human primates is readily enabled using alternative anti-species label antibodies. We hope this tool will be utilized to maximize information content in the critical effort of delivering a safe and effective SARS-CoV-2 vaccine in record time. capture antigens labeled nCoV(i) through NL63, each printed as 9 replicate spots. Fiducial markers are shown as grey spots in rows above and below capture antigens. (c) Schematic of the immunoassay principle in which capture antigen binds target antibodies from serum, and target antibodies are labeled using a species-specific IgG secondary antibody label that contains a fluorescent tag. S refers to full-length spike, and S1, S2, and RBD refer to corresponding portions of spike as called out in Table 1 . commercially available HKU1(i) Mammalian S1 commercially available OC43(i) Mammalian S1 commercially available 229E(i) Insect Full length spike (S1 + S2) commercially available NL63(i) Mammalian S1 commercially available ",USA,first author,2021-02-25,02
31a2346443a4f984774e5a20e23f1de965e1d1ba,Application of a 27-protein candidate cardiovascular surrogate endpoint to track risk ascendancy and resolution in COVID-19,"The novel coronavirus disease 2019 caused by the SARS-CoV-2 virus has become a global public healthcare and socioeconomic emergency, with over 65 million confirmed cases contributing to over 1.5 million deaths worldwide as of mid-December 2020. 1 While risk factors for hospitalization and severe outcomes of COVID-19, including age, male sex, and the presence of comorbid chronic conditions affecting pulmonary, CV and metabolic systems have been identified, 2-4 the significant heterogeneity of clinical phenotypes amongst COVID-19 patients poses a burden in clinical care decision making and healthcare resource allocation. Therefore, prognostic tools that can more precisely identify individuals who are likely to encounter morbid outcomes serve the utility to inform healthcare management, enabling earlier and more personalized care. In addition, as emerging evidence suggests prevalent long-term pathological sequalae in COVID-19 survivors independent of disease severity, 5 understanding the biological determinants, identifying predictors and monitoring the resolution of prolonged adverse health outcomes is essential.While the most obvious clinical manifestation in hospitalized COVID-19 patients is viral pneumonia, likely a consequence of an overactive host immune response, many individuals display extrapulmonary manifestations including cardiac-related events. 2, 6 Multiple studies have reported that both the susceptibility to, and the severity of outcome to COVID-19 are significantly associated with cardiovascular disease. Pre-existing cardiovascular disease not only increases an individual's risk for death and severe course of illness, 7-9 but SARS-CoV-2 infection itself induces cardiac damage in a significant proportion of hospitalized patients. Cardiac injury in patients is significantly associated with higher risk for in-hospital mortality and occurs in a sizeable proportion of patients without pre-existing cardiovascular disease. [10] [11] [12] Elevations in traditional cardiac biomarkers such as high-sensitivity cardiac Troponin and N-terminal pro-BNP have demonstrated prognostic ability to predict severity of hospitalized COVID-19 patient outcomes 2,3 ; however, the clinical utility of these findings has recently come under debate 13 and the validity of these biomarkers in cases of milder disease course is unknown. Together this suggests that a more comprehensive blood-based biomarker of underlying sub-clinical cardiac dysfunction at COVID-19 presentation may serve value as a candidate surrogate endpoint for COVID-19 disease severity and mortality as well as enabling monitoring COVID-19 related CV risk across the course of illness into convalescence.We have recently developed and validated a 27 protein-only test highly predictive of residual future CV-event risk (four-year likelihood of myocardial infarction, stroke, hospitalization for heart failure or all-cause death) in a multiple cohort study of 18,165 higher risk individuals with relevance to COVID-19 outcome severity, including those with underlying CV complications, the elderly and diabetics. 14 In the current study we tested the ability of this validated residual cardiovascular disease (RCV) test to predict mortality and stratify severity risk groups in three independent cohorts of COVID-19 infected individuals with the aim of evaluating it as a novel prognostic tool for COVID-19 related outcomes with applicability beyond hospitalized patients. Additionally, we assessed in a total of 1,851 longitudinal samples obtained from all three cohorts the utility of this test to characterize the ascendancy and resolution of risk across the course of SARS-CoV-2 infection into convalescence in order to determine the value of the test beyond the acute phase and highlight its potential to serve purpose as a monitoring tool for post-COVID-19 adverse sequelae.Baseline and longitudinal patient samples utilized in the current study were obtained from patients with confirmation of SARS-CoV-2 positivity at time of study enrollment via PCR of nasopharyngeal or oropharyngeal swabs. Summary demographic characteristics of each cohort are shown in Table 1 . Details of this cohort have been previously published. 16 In brief, EDTA plasma samples were collected from 298 patients at day 0 (time of presentation to the emergency department). In a subset of patients still hospitalized, EDTA plasma samples were obtained at 3 and 7 days after the initial All rights reserved. No reuse allowed without permission.Patient clinical data was determined through extensive retrospective electronic health record and chart review. Two clinical outcomes of COVID-19 were investigated in the current study, death and maximum disease severity grade.Mortality rates of 20%, 14% and 8% were observed in cohorts 1, 2 and 3, respectively. The timeframes for assessment of death differed in each cohort based on the individual study design.Cohort 1: in-hospital death, cohort 2: within 28 days of baseline blood draw, and cohort 3: within follow up period, up to several months.All rights reserved. No reuse allowed without permission.Proteomic profiling of plasma samples was conducted using the SomaScan ® assay, a modified aptamer-based technology capable of quantifying plasma levels of ~5000 proteins. 19 Specificity and stability of the Assay has been extensively described. 20 The total number of samples in each cohort available for proteomic analyses are 458, 298, and 104 baseline samples and an additional 491, 335, and 165 follow-up longitudinal samples in cohorts 1, 2 and 3, respectively, after removal of samples that did not pass assay QC criteria.Machine learning techniques were employed to develop the RCV model, resulting in a 27-protein model of composite cardiac event risk within four years (including myocardial infarction, heart failure hospitalizations, stroke or all-cause death). The model was developed and validated on SomaScan ® plasma proteomic data from 18,163 individuals in six different clinical studies.Prognostic performance of this test was assessed in multiple high-risk, multi-morbid patient populations, outperforming existing cardiovascular risk predictors. This model also demonstrated sensitivity to detecting changes to cardiovascular risk with approaching events and following interventions in the EXSCEL and DiRECT trials. 14The goals of the statistical analysis had multiple components, with the overarching purpose of understanding the prognostic performance of the RCV SomaSignal test from the first blood draw and comparing this with other laboratory and clinical measures.Summary statistics (mean, standard deviation, range, percentages) were calculated on baseline demographics and lab measurements. The prognostic performance of the RCV model and competing metrics was assessed in two ways: 1) using regression models, which allowed us to characterize the effects of different covariates (e.g., RCV predictions, lab measurements) and determine which were statistically significant predictors of COVID-19 outcomes, and 2) using machine learning techniques and predictive metrics, which allowed to understand the predictive accuracy of the different covariates.The two endpoints of interest were death (as a yes/no status variable) and the maximum severity the subject reached over the course of the study (as an ordinal variable). For the death endpoint, logistic regression models were used, and for the maximum severity endpoint, ordinal regression models were used. For application of machine learning techniques, each cohort was split into an 80/20 training and test set, with 5 repeats of 5-fold cross-validation performed on the training set and validation of the cross-validated model performed on the test set. Logistic regression All rights reserved. No reuse allowed without permission.were assessed using the root-mean square error (RMSE).These analyses were performed to assess a number of components of the data. The first assessment was done on the RCV model predictions themselves in an effort to characterize how well the probabilities predict death and maximum severity from baseline. Following, this approach was used to examine the individual proteins in the RCV model, which allowed us to assess if a small subset of the proteins were driving the association between the RCV model predictions and COVID-19 outcomes. Lastly, this approach was used to quantify differences between the RCV model and various competing lab metrics as well as pre-existing heart conditions (this was done in the MGH cohort only, as it was the only cohort that had this clinical information). Only the baseline samples were used for this portion of the analyses.Another goal of the analysis was to characterize the trajectory of the RCV model predictions over the course of the illness using the longitudinal samples. To this end, a repeated measures linear regression model was used, with RCV model predictions used as the endpoint (which were logit transformed to satisfy normality assumptions). In this model, the only predictor included was time, with time at the peak RCV predicted probabilities centered at 0 in order to align different patients' natural histories, and time before peak probability as negative (with values farther away from zero being larger negative numbers) and time after peak probability as positive. Separate slopes were used to quantify the rate of RCV increase before peak severity and the rate of RCV decrease postpeak severity. This allowed us to predict a trajectory of RCV scores as well as determine if the rates of increase and decrease were statistically significant.All calculations were performed in R v3.6.3. All rights reserved. No reuse allowed without permission.Logistic regression models show a statistically significant increase in the risk of death as RCV predictions increase. Additionally, cross-validated models show AUC values of 82%, 79%, and 65% for the MSSM, MGH, and ISB test cohorts, respectively. See Table 2 for details.In a similar fashion, boxplots of the baseline RCV predictions, stratified by maximum COVID-19 severity status, show a strong trend of increase in probability as the COVID-19 severity increases (see Figure 1 ). Additionally, ordinal logistic regression models show RCV to be a significant predictor of maximum severity (p < 0.01 for all cohorts). See Table 2 for details.In an effort to understand if a certain subset of the proteins in the RCV model had a greater association with COVID-19 outcomes, regression models and predictive model metrics (AUC for the death endpoint, RMSE for the maximum severity score) were calculated on a univariate level for each protein as it related to each endpoint. Additionally, the effect sizes from the regression coefficients were compared to each other by calculating the percent each estimated effect had out of the sum of all 27 absolute effect sizes. Protein measurements were log-10 transformed and centered/scaled before analysis so that estimated effect sizes were comparable.Results are shown in Figure 2 (exact numbers are in Supplementary Table 3 ). It can be observed that, on a univariate level, protein effects range from 1% to 6.8% in percent effect size in prediction of death, which translates to a 120% to 380% increase in risk of death for every 1-unit increase in the standard deviation of the protein RFU measurement. It can also be observed that the predictive capabilities of each protein, on a univariate level, range from and AUC of 54% (marginally better All rights reserved. No reuse allowed without permission.In assessing the performance of the cardiovascular protein model, another key component was the comparison of the performance of the model predictions compared to other standard lab metrics.To this end, using the MGH cohort, we compared the RCV model predictions to commonly screened biomarkers of cardiac injury, inflammation and immune response including, C-Reactive protein (CRP), D-Dimer, ferritin, fibrinogen, interleukin-6 (IL-6), NT-proBNP, procalcitonin, and high sensitivity cardiac Troponin (Hs-cTn). In this analysis, all measurements were centered and scaled so that the effect sizes could be comparable, with results expressed in standard deviation units. In addition to comparison to the lab metrics, we also compared the model to clinical information on whether the individual had a pre-existing heart condition (yes/no) so that we could understand if the RCV model was only explaining existing comorbidities or was providing additional risk information.Results are shown in Figure 3 and full descriptive results outlined in Supplementary Table 4 . It can be observed that the RCV model has the highest estimated effect size for both endpoints at 40% and 30% for death and maximum severity score, respectively. The next largest percent effect sizes are for D-Dimer (at 10.8%) for association with death and CRP (18.5%) for prediction of maximum severity scores. Additionally, the RCV model predictions have the highest AUC (83.5%) and lowest RMSE (1.3985), with the next highest AUC equal to 81.4% for Hs-cTn and All rights reserved. No reuse allowed without permission.It is possible that the RCV model predictions follow a trajectory that elucidates a mechanistic timecourse of COVID-19 severity, independent of oxygen status or observed symptoms. To test this hypothesis, random effects models were calculated using the RCV model predictions as the All rights reserved. No reuse allowed without permission.Results from the model can be seen in Table 4 and Figure 4 . Most importantly, there were striking acute daily increases in predicted risks before the peak, and rapid decreases in scores after the peak which were are all statistically significant at the 0.05 level across all three cohorts, with rates of decrease similar to rates of increase. The predicted trajectories, along with the observed measurements, can be viewed in Figure 4 .All rights reserved. No reuse allowed without permission.The 27 proteins in the RCV test represent cardiac function, metabolism, immune activation, inflammation, and fibrinolysis. Proposed mechanisms of cardiac events and cardiac damage All rights reserved. No reuse allowed without permission.Additionally, given that all the proteins in the 27 protein model contributed to the prognostic prediction (each protein individually contributed 0.3-7.7% to the observed effect size), this suggests that the etiology of elevated RCV risk score in COVID-19 patients with severe outcomes is likely multifactorial and may explain why the RCV test offers greater predictive performance compared to traditional CV and immune biomarkers in the current study. As well as outperforming other blood-based biomarkers, our initial findings show that the RCV test may also outperform a number of other more complex, demographics-driven prognostic approaches recently published. 22, 23 Furthermore, since our model is protein-based and not dependent upon immutable factors, our analysis had the capability of extending beyond prognostication and allowed the natural history of biologic mechanisms associated with cardiovascular risk to be observed across the course of COVID-19 illness. We provide novel findings demonstrating the CV risk ascendancy and decline across acute COVID-19 infection into recovery. In this study we were not enabled to relate recovery RCV scores to subsequent cardiovascular event rates, but given that the 27-protein cardiovascular risk test has displayed prognostic sensitivity in other disease states, 14 and was also prognostic during the ascendancy of infection, this deserves further follow-up as it may represent a scalable method of tracking residual risk during recovery. All rights reserved. No reuse allowed without permission.However, we purposefully chose to not include those variables to a) allow greater sensitivity to change, and b) to favor the utility of the test in situations where extensive blood work, or chart review is not warranted i.e. in non-hospitalized settings.Another limitation is that the SomaScan ® platform, upon which this test is based, takes ~30 hours to deliver a result and is currently only available in a single central CAP/CLIA certified laboratory;near-patient use would require its translation onto another platform. This may mean that it is more useful during the recovery process than acutely, although this remains to be demonstrated. All rights reserved. No reuse allowed without permission.We conclude that the same cardiovascular risk mechanisms active in chronic disease and captured by the 27-protein surrogate endpoint are also acutely enhanced during COVID-19 infection, that a period of catastrophic risk-elevation of 8-12 days ensues, followed by a resolution period that needs further characterization; this could be tracked by means of the 27-protein surrogate used in this study.All rights reserved. No reuse allowed without permission.Covariate MSSM MGH ISB Average RCV score at peak 99.996% (< 0.01) 99.890% (< 0.01) 61.893% (0.281) Daily RCV increase approaching peak 76% (< 0.01) 191% (< 0.01) 1.5% (0.037) Daily RCV decrease post-peak 60% (< 0.01) 80% (< 0.01) 4.8% (< 0.01) Table 4 . The estimated trajectories for the RCV predictions for each cohort through the course of acute COVID-19 infection into convalescence (back-transformed from the logit scale). MSSM, Mt Sinai School of Medicine; MGH, Massachusetts General Hospital; ISB, Institute for Systems Biology.All rights reserved. No reuse allowed without permission.",USA,first author,2021-02-01,02
7198bfe6a8321805e96f00738e596a328a87cc6e,Stage 1 registered report: spatiotemporal patterns of the COVID-19 epidemic in Mexico at the municipality level,"At this date (October 15), the most affected WHO region by COVID-19 pandemic, with 18,090,384 confirmed cases, is the Americas. In this region, the countries that present the most substantial number of deaths are the USA, Brazil and, Mexico. According to the Mexican Health Secretary's records, the first confirmed cases of COVID-19 in Mexico were reported in February 2020, and community transmission started at the end of March. Since this date, COVID-19 has spread over the Mexican territory, with over 821,000 accumulated confirmed cases and 83,900 deaths by October 15, 2020 (https://www.gob.mx/salud/documentos/datos-abiertos-152127). Measures for containing virus spreading included a national campaign to promote social distancing, called ""Jornada Nacional de Sana Distancia"" (National Workday of Healthy Distance) and the closing of non-essential economic activities from March 23 to May 30, 2020. After this lockdown period, gradual reactivation of economic activities was initiated and tuned at the state level using color-coded restriction levels (Acuña-Zegarra, Santana-Cibrian & Velasco-Hernández, 2020) . The restrictions are determined taking into account hospital occupancy and its trend, and the incidence rates of each state and its neighbors. Schools, colleges and universities suspended classes and activities are carried out remotely.An integral comprehension of this epidemic, from different perspectives, is needed to prevent and control it. Presently, a large body of research has been accomplished, principally in the field of medicine. However, it is essential to improve our understanding of how COVID-19 spreads over a territory. For instance, the description of the epidemic characteristics, including spatio-temporal distribution and association with other features, may be useful for identifying covariates, modeling epidemic behavior, and providing reliable information for decision-making. Nevertheless, there are very few studies concerning the spatio-temporal dynamics of This study aims at investigating the spatial distribution patterns and dynamics of the COVID-19 in Mexico from the beginning of the epidemic, totalizing 6 months by carrying spatial analysis techniques as the computing of spatial autocorrelation and the identification of clustering patterns of the confirmed cases over time.This stage 1 registered report does not follow a standard report because this research is not based on an experimental design in which independent variables are manipulated and their effect on the dependent variable(s) is evaluated. However, the proposed study is based on robust geo-statistical methods and the statistical significance of the results will be tested. We will analyze the spatio-temporal patterns of the epidemic to test the following hypothesis:COVID-19 pandemic in Mexico is characterized by different clusters evolving in space and time as parallel epidemics. Connectivity based on a gravitational model allows explaining intermunicipality contagion better than other distances such as Euclidean, least-cost, and resistance distances.The data sets we will use for this study are composed of the epidemiological and geographical auxiliary data:The daily numbers of confirmed COVID-19 cases and deaths for the period from January 1 to October 15, 2020, reported by the Secretary of Health were obtained from the Mexican federal government open data platform (https://www.gob.mx/salud/ documentos/datos-abiertos-152127). Country-based COVID-19 statistics (Total COVID-19 deaths per million people and biweekly cases per million people) from https://ourworldindata.org (University of Oxford). Digital maps of municipality boundaries, human settlements, and road networks from the National Institute of Geography and Statistics (INEGI). Population projection produced by the National Population Council (CONAPO) to estimate the current population (CONAPO, 2014) .The records from the Secretary of Health contain additional information such as age, sex, foreign and immigrant status, co-morbidities as well as the state and municipality of residence, and the state of the health unit where consultation occurred. In the present study, focused mainly on spatial patterns, we will aggregate data at the municipal level.Due to the existence of many asymptomatic cases and the reduced number of diagnostic tests, the epidemiological surveillance of confirmed cases represents only a proportion of all infections. A seroepidemiological survey based on a robust sampling can provide precise estimates of seroprevalence in the population than analysis based on confirmed cases (Pollán et al., 2020) . However, Mexico carried out a reduced number of tests and confirmed cases dataset is the only available source at the national level. Limitations of this information are that confirmatory testing is strongly biased towards symptomatic cases, and each state makes its own data collection. However, since the federal government (Secretary of Health) mediates the data aggregation, there is some methodological consistency that allows for homogeneity and reasonable comparisons between states and municipalities. Mexico has had low levels of testing for the virus throughout the entire period. No large variations in the number of cases are expected due to an increase or decrease of the testing efforts.Since there is a delay in case reporting and confirmation, we will limit this analysis to the period between Jan 1st and October 10, 2020. We also will discard records in which the state of residence was different from the state where the patient did the consultation because these records correspond likely to patients who get infected outside of their municipality of residence. These records represent about 6% of the confirmed cases.All the analyses will be carried out using the R program (version 4.0.2) (R Development Core Team, 2020), in particular the packages FlexScan 0.2.0 (Tango & Takahashi, 2012) , gdistance 1.3-1 (van Etten, 2017), rflexscan 0.3.1 (Otani & Takahashi, 2020) , sf 0.9-6 (Pebesma, 2016), and spdep 1.1-5 (Bivand, Pebesma & Gómez-Rubio, 2008) .The geographical database is based on the Lambert conformal conic projection, a conic map projection established on two standard parallels, which minimizes deviation from the unit scale within a region comprising the two standard parallels. Its elaboration will be presented in ""Spatio-temporal dataset of COVID-19 outbreak in Mexico"" (submitted to Data in Brief; J.F. Mas, 2020, unpublished data For comparison purposes, we will plot the cumulative deaths per million inhabitants of Brazil, France, Mexico, and the US using the country-based data from the University of Oxford. As the epidemic began at different dates in these countries, the origin (day one) in the time axis will be defined as the day when one death per million inhabitants was reached.To simplify the data and avoid the day of the week bias, the daily information from the Secretary of Health will be aggregated to the weekly level. The number of new confirmed cases and the number of deaths will be computed for each municipality per week during the period the beginning of community transmission (End of March) and October 10, 2020.Spatial autocorrelation analysis enables users to test whether the observed value of a nominal or ordinal variable in one place is independent of values of the same variable in neighboring areas (Sokal & Oden, 1978) . In this case, the spatial autocorrelation assessment will enable us to evaluate if the municipalities with high or low infection rates tend to be spatially aggregated and form clusters. Moran's I index is a measure of spatial autocorrelation that can be used to explore the spatial distribution of diseases (Lawson, 2013) . It has been used in various studies concerning COVID-19 (Barrantes Sotela & Solano Mayorga, 2020; Cordes & Castro, 2020; Kang et al., 2020; Yang et al., 2020) . To depict the spatial association of COVID-19 cases over time, Moran's I statistic will be computed for each week (Eq. 1).where x i is the number of cases at location (municipality) i, n the number of municipalities, w ij is the weight between observation i and j, and S 0 is the sum of all w ij 's:In its simplest form, the weights take values 1 for close neighbors, and 0 otherwise. We will also set w ii = 0 because a region cannot be adjacent to itself.During an epidemic, it is crucial to implement spatio-temporal surveillance that can prioritize locations for specific interventions, rapid tests, and resource allocation. One such method is space-time exploration statistics (Kulldorff, 1997) , widely used for different types of diseases (Coleman et al., 2009; Zheng et al., 2014) including COVID-19 (Ballesteros et al., 2020; Desjardins, Hohl & Delmelle, 2020; Hohl et al., 2020) . As the following step, spatial scan statistic will be applied to detect and evaluate disease clusters using the ""flexibly shaped spatial scan"" approach proposed by Tango & Takahashi (2005) . This algorithm can detect irregularly shaped clusters such as those along with a linear feature as a road, while algorithms based on a circular window have difficulty in accurately detecting non-circular clusters and tends to define a more extensive cluster than the true one by incorporating surrounding regions (Tango & Takahashi, 2005; Tango & Takahashi, 2012) . In epidemic monitoring, the size of a cluster cannot be known a priori, and the population at risk is not evenly distributed. For instance, under the null hypothesis of equal risk of disease inside and outside the cluster, we expect more cases in an urban area compared to a rural area of similar size, due to the higher urban population density. No analytical solutions have been found to obtain the probabilities in these tricky conditions and the algorithm uses Monte Carlo hypothesis test to get the p-values (Kulldorff, 1999) .A large number of candidate clusters is obtained through the creation of irregularly shaped windows on each region (e.g., municipality) by connecting adjacent regions. For each candidate cluster, the number of observed cases will be compared to the number of expected cases of COVID-19, assuming that the COVID-19 cases follow a Poisson distribution. The null hypothesis is that the incidence of COVID-19 is randomly distributed over space, and the alternative hypothesis is that the incidence increases inside the cluster. In order to test whether the clusters are statistically significant, the log likelihood ratio (LLR) will be estimated by Monte Carlo randomization with 999 replications. The p-value is estimated by comparing the rank of the likelihood from the real data set with the likelihood values from the randomized data sets. If this rank is R, then p = R/(1 + N s ), where N s is the number of simulations. The non overlapping statistically significant clusters will be retained (p ≤ 0.05). Clusters will be estimated for each week, allowing to analyze their temporal evolution by computing the date of their first occurrence and their duration over time.For each cluster, the relative risk (RR) will be computed (Eq. 2). RR is the risk inside a cluster divided by the risk outside the cluster.where RR is the relative risk, c is the total number of cases in a cluster, e is the total number of expected cases in a cluster, and C is the total number of cases in the country. Finally, an attempt will be made to determine which type of distance measure is better suited to explain disease spreading. For that, the distance between municipalities will be calculated using different approaches: (1) Euclidean distance, (2) least-cost distance, (3) resistance distance, and (4) gravity model interaction.Euclidean distance is a straight line between two locations based only on their coordinates. The other distances, least-cost distance, and resistance distance are based on graph theory. Graphs are obtained by connecting each cell center with its nearest neighbors, which become the nodes of the graph. Weights are associated with each edge and express the conductance (inverse of the resistance). In the present study, the road network map will be rasterized using the speed limit as the value of conductance and a spatial resolution of one kilometer. Cells will be connected with their eight orthogonal and diagonal nearest neighbors (Moore neighborhood). The least-cost distance is the least costly path to travel from one point to another, taking into account the cost associated with moving through space. The distance is expressed in cost units, in this case, time (hours). The resistance distance allows the incorporation of multiple pathways, for instance, the least cost route and alternative ones using secondary roads.The gravity model enables geographers to model the amount of interaction between two places (Flowerdew & Aitkin, 1982) . The expected interaction between two places is proportional to the size of their populations P i and P j , and inversely proportional to the square of the distance between them (Eq. 3):where I ij is the interaction between places i and j, k is a constant, and P i , and P j are the population sizes of places i and j and, d ij the distance between these two places.To determinate the geographical position of each region, instead of using the coordinates of the municipality centroid, the coordinates of the municipality head cities will be used. This decision is based on the fact that, at this stage of the epidemic, most of the confirmed cases are found in largest cities (Villerías Salinas, Nochebuena & Uriostegui Flores, 2020) , and the distance between head cities represents the connection between municipalities better than the distance between centroids. Additionally, it is worth noting that the gravitational model will enable us to enhance the relationship between the largest cities.For each week, the municipality newly incorporated into a cluster will be identified (orange regions in Fig. 1 ). The first set of distances includes the distances between these municipalities and the municipalities already belonging to a cluster in the previous week (time t − 1). In contrast, the second group comprises distances between the municipalities which remained outside of any cluster (green regions in Fig. 1 ) and the municipalities already belonging to a cluster (red region). The distances will be calculated using the four approaches described previously. The type of distance that explains the spread of the epidemic better is expected to express a larger closeness between the Figure 1 Euclidean Distances between contaminated municipalities a time t − 1 and contaninated and non contaminated municipalities at time t. Other types of distance will be calculated using the same sets of municipalities.Full-size  DOI: 10.7717/peerj.10622/ fig-1 pre-existing clusters and the newly incorporated municipalities. Therefore, it will increase the difference between the mean distance of the two sets (Eq. 4).RD ¼ ðD c À D nc Þ D nc (4) where RD is the relative difference between the two sets of distances, D c is the mean distance between municipalities that belong to a cluster at weeks t − 1 and municipalities incorporated into clusters at time t. D nc is the mean distance between municipalities that belong to a cluster a week t − 1 and municipalities that not belong to any cluster at week t.The author received no funding for this work.",Mexico,abstract,2021-02-05,02
6614877fadd3a98ab27eedab7fc4255d44242c06,Decreased Mortality Rate Among COVID-19 Patients Prescribed Statins: Data From Electronic Health Records in the US,"In less than a year since its outbreak, the coronavirus disease 2019 (COVID- 19) pandemic has taken over one million lives to date (1). The severity of COVID-19 symptoms in patients is strongly associated with being older and having pre-existing medical conditions (2) . The severe respiratory illness of COVID-19 is primarily triggered by an intense pro-inflammatory host response (3) .Statins-medications routinely prescribed for cholesterol and lipid lowering-are also known to have anti-inflammatory and immunomodulatory properties, capable of reducing inflammatory responses and oxidative stress (4) (5) (6) . Furthermore, several observational studies have indicated that statin use may be effective in reducing mortality and hospitalization due to viral infections, such as influenza (7) (8) (9) . Statins have also been shown to be beneficial for patients with various autoimmune inflammatory conditions (5) via several pathways.The potential capability of statins to reduce the severity of COVID-10 outcomes has been investigated recently in several retrospective studies. Specifically, in a study of 13,981 COVID-19 patients in Hubei Province, China (10) and in a smaller study of 154 elderly patients in nursing home residents in Belgium (11) , the use of statins was associated with a reduced mortality rate. However, a meta-analysis that included nine studies (for a total of 3,449 patients) showed that statin use did not improve in-hospital outcomes of those with COVID-19 (12) . Furthermore, an increased mortality rate was observed among COVID-19 patients with Type-2 diabetes taking statins (13) . In addition, concerns regarding the use of statins and an increase in COVID-19 infections have been raised, as statins can increase the expression of angiotensin-converting enzyme 2 (ACE2), the primary receptor for the SARS-CoV-2 virus (14) . Electronic health records (EHR) provide an opportunity to study therapeutic effects on a population level. Our goal was to leverage data from electronic health records covering a comprehensive population of nearly 120,000 COVID-19 patients to investigate the potential effects of statin use in COVID-19 patients in a large, diverse population in the United States.Data were obtained and analyzed from Cerner's large COVID-19 EHR database, which contains records of 117,496 COVID-19 patients across 62 healthcare centers as of July 2020. Deidentified Cerner Real-World Data is extracted from the EHR of hospitals in which Cerner has a data use agreement. Encounters include admissions, clinical and microbiology laboratory, pharmacy (medication orders and dispensing), and billing information, which are all date and time stamped, providing a temporal relationship between treatment patterns and clinical information. All patients had an emergency room visit or were hospitalized. Only patients with a COVID-19 diagnosis confirmed by a laboratory test for SARS-CoV-2 (including nucleic acid amplification tests and immunoassays) and with known values for demographics (age at encounter, sex, race and ethnicity) between February 2020 and July 2020 were included in analyses. Among 27,130 patients with a positive lab test, 22,147 had complete demographic information (Figure 1) . COVID-19 patients with a medication order for a statin with an order status ""active"" or ""completed"" and without a designation of ""as needed"" (i.e., medication taken only when needed) at least once within a period of 10 days before and seven days after testing positive for COVID-19, were compared with COVID-19 patients who have no medication orders for statins. Individuals who were exposed to statins outside of this period of 10 days before and 7 days after testing positive for COVID-19 were excluded from our analysis (N = 3,681), resulting in total of N = 18,466 patients in the final cohort (Figure 1) Propensity score matching (PSM) (15) with a nearest neighbor method and a 1:2 ratio was used to match statin-treated patients with controls. The R Matchit package was used for the analysis (16) . Three PSMs were performed. The first matching was based on demographics (age, sex, ethnicity, race). The second matching was based on demographics and on comorbidities [hypertension, diabetes, obesity/high BMI, chronic obstructive pulmonary disease (COPD)]. The third matching includedin addition to all variables from the first two matchingsindications for a statin prescription (e.g., high cholesterol, hyperlipidemia, atherosclerotic cardiovascular disease). Welch two-sample two-sided t-test was performed to evaluate if there was a significant difference in the mean age when comparing the statin-treated group and the untreated group. Two-sample two-sided Mann-Whitney U test with continuity correction was performed to evaluate if there was a significant difference in BMI when comparing the statin-treated and untreated group. Pearson's Chi-squared test with Yates' continuity correction was performed to examine the association between statin use and the outcome of death in patients with COVID-19. For each of the three matchings, we carried out 10 iterations and evaluated mortality rate as follows. Each iteration included all statin patients and a subset of controls chosen by PSM. Due to a large number of controls, several controls could have had a same value of the propensity score value and therefore, some statin patients could be matched to more than two controls. To explore this variability and show the robustness of the results, 10 iterations were performed by varying the control patients who had a tie in their propensity scores. A total of 18,466 patients with a laboratory-confirmed COVID-19 diagnosis and complete demographic characteristic were identified, after filtering out those who were prescribed statins outside of the defined timeframe (Figure 1) . We found that 2,297 patients had an order for statins during the defined timeframe, and 16,169 patients had no orders for statins. Cohort characteristics are shown in Table 1 . After matching, the mean age among statin-treated patients (68.4 years) was similar to that of controls for the three matchings (matching 1: 68.4 years, p = 0.82; matching 2: 68.6, p = 0.54; matching 3: 68.4, p = 0.93). The median BMI among statin-treated patients (29.04 kg/m 2 ) was higher than the median BMI of controls for the three matchings (matching 1: 27.85-28.00 kg/m 2 , p < 1E-08; matching 2: 28.30-28.40 kg/m 2 , p < 1E-02; matching 3: 28.18-28.24 kg/m 2 , p < 1E-02); however, the calculated difference in BMI between the statin-treated and untreated groups was small (matching 1: 1.04-1.19 kg/m 2 ; matching 2: 0.64-0.74 kg/m 2 ; matching 3: 0.80-0.86 kg/m 2 ) (Supplementary Table 1 ). Among statin-treated patients, the mortality rate was 16.1%. For the 10 iterations of PSM by demographics, we observed a higher mortality rate among controls in each iteration (18.0 to 18.4%, Chi-squared test, p < 0.05 for 9 out of 10 iterations). Exact mortality rates and p-values for each iteration are shown in Table 2 . When carrying out 10 iterations of PSM by comorbidities as well as demographics, we also observed a significantly higher mortality rate in the controls (20.0 to 20.3%) in each iteration (Chi-squared test, p < 1.00E-03 for all iterations) ( Table 3) . When carrying out 10 iterations of PSM by medication indication as well as demographics and comorbidities, we again observed a significantly higher mortality rate in the controls (20.3 to 20.6%) in each iteration (Chi-squared test, p < 1.00E-04 for all iterations) ( Table 4 ).We observed a small, but statistically significant, decrease in mortality among COVID-19 patients prescribed statins when compared with propensity-score matched controls. Importantly, we did not find an increase in mortality associated with statin use. Our findings are in agreement with previous results indicating that statins may reduce COVID-19-related mortality (10, 11) . The mean age of statin-treated patients in the current study (68.4 years) was lower than that in the Belgium study (85.6 years) and comparable to that in the Wuhan study (66.0 years). Ours is the first study performed using a large, diverse population across the United States. In contrast, an increased mortality rate was observed among COVID-19 patients with type-2 diabetes taking statins (13) . One possible explanation is that this cohort focused only on high-risk patients hospitalized for COVID-19 who had Type-2 diabetes and therefore were at a higher risk for complications. Although ACE2 expression has been reported as variable in Type-2 diabetic patients independent of statin use (17) , it is conceivable that high ACE2 expression in some Type-2 diabetics might have been further increased with statin use, increasing the potential for viral entry into cells (17) (18) (19) . Several mechanisms by which statins may benefit COVID-19 patients have been proposed, although not proven. A recent study suggested that statins could be efficient inhibitors of the SARS-CoV-2 main protease (Mpro), a key coronavirus enzyme (19) . Inhibition of the MYD88-NF-κB pro-inflammatory pathway, blockage of the NLRP3 inflammasome, and upregulation of the stress-response protein, heme oxygenase (HO-1) (4, 11, (20) (21) (22) (23) (24) (25) have also been suggested. After entering the cell through ACE2, SARS-CoV-2 can cause a downregulation of ACE2 (20) and a pro-inflammatory host response via the TLR-MYD88-NF-κB pathway, causing increased cytokine levels, inhibition of HO-1, and coagulation dysfunction (20, 26, 27) . Statins have been shown to modulate the MYD88-NF-κB proinflammatory pathway, upregulate ACE2, and have anti-thrombotic properties, mainly through their effects on platelet function, all potentially important effects on patients with severe cases of COVID-19 (20, 23) .In addition, several recent studies have proposed the direct modulation of HO-1 as a potential therapeutic intervention for COVID-19 (28) (29) (30) as it can potentially prevent a ""cytokine storm, "" a dysfunctional anti-inflammatory response (26) . Statins can upregulate HO-1 leading to the production of iron (Fe 2+ ), carbon monoxide (CO) and biliverdin, which is rapidly reduced to bilirubin (31) (32) (33) (34) . These bioactive products have immunomodulatory, antioxidative, anti-inflammatory, vasodilatory, and anti-apoptotic properties, as well as antithrombotic properties, such as the inhibition of platelet aggregation and adhesion. Further support for the hypothesis that there might be therapeutic benefits of statins for COVID-19 patients is based on a known role of HO-1 in inducing type-1 interferon (IFN) expression and an established role of IFNs in inhibiting replication of various viruses including coronaviruses (28) .Finally, the gene expression of HO-1 is affected by the number of glutathione thymidine (GT) dinucleotide repeats in the HO-1 promoter region (26) , which greatly varies among populations. The presence of longer (GT)n repeats are associated with lower basal HO-1 expression, and a decrease response to a noxious stimulus, such as infection or any other myriad of factors that can trigger upregulation of the gene (35) . Because these individuals cannot sufficiently up regulate HO-1, to regain a non-inflamed state after an inflammatory stimulus (a normal physiologic response), possibly contributing to exacerbated acute or more chronic autoimmune inflammatory syndromes. The importance of there being differences in capacity to upregulate HO-1 among people is that it is plausible that those individuals with long (GT)n repeats could be at greater risk for a ""cytokine storm."" Thus, statins might be useful in boosting the expression of HO-1 in these individuals when they present with COVID-19. Interestingly, a baby born totally deficient in HO-1 died in infancy with multi-system organ failure caused by a systemic vasculitis (36) . While statins vary in their intended effectiveness of lipid reduction, as a class of drugs they share the above-described mechanistic generic qualities. One of the main limitations of our report is that it is, like others, retrospective, allowing us to only demonstrate an association between statin use and COVID-19 mortality, but not causal effects. Moreover, while records are available from 2015 and beyond for some individuals in this database, this was not the case for all individuals and as such, pertinent information including previous medication use and comorbidities for some individuals could be incomplete in this database. Statins can lower plasma LDL; however, we were unable to determine if there was a significant difference in baseline LDL levels between our statins-treated and untreated groups due to the low percentage (19 to 30%) of each group that has LDL values in the Cerner database (data not shown). Our study involved medication orders for statins with order statuses that ensured that the medications were administered to the individuals-an advantage compared to outpatient prescriptions where there can be uncertainty as to whether an individual fills the prescription or takes the medication. However, the administration of different statins and at various doses, which could have differing pleiotropic effects in lieu of their designed cholesterol-lowering effect, were not considered. Nonetheless, that any mitigating effect on COVID-19-related mortality was found is intriguing. While we considered several demographics and comorbidities known to be associated with COVID-19 outcomes, unaccounted confounding variables could alter this observed association.Overall, our findings are reassuring in that the use of statins was not associated with an increased mortality among elderly patients with COVID-19. However, the observation that there might be some increased risk associated with statin use in individuals with Type-2 diabetes warrants some caution. Considering what has been speculated about the potential beneficial effects of statins and what retrospective findings have been reported, our results should motivate further prospective studies to elucidate the potential mechanisms by which statins might be protective in some COVID-19 patients or harmful in others. Statins are widely used, low-cost medications that, if proven an effective mitigating treatment, could be an affordable option to reduce the mortality of COVID-19 even in lowincome countries.The data analyzed in this study is subject to the following licenses/restrictions: This was an observational study of Electronic Health Records that cannot be made publicly available. Requests to access these datasets should be directed to the Cerner Clinical Research Team, coviddatalab@cerner.com.DS proposed the hypothesis investigated in the paper and the main idea of the study, supervised the analysis, co-wrote the first draft of the manuscript with IM. MS acquired data and supervised the analysis. IM designed and performed the initial analysis for the study, co-wrote the first draft of the manuscript with DS. TO acquired data, performed the analysis, made the figure and tables, contributed to writing the manuscript. GS supervised the analysis. RW contributed to writing the manuscript. IK and BL contributed to the analysis. All authors discussed results, provided critical feedback and contributed to the final manuscript. ",United States,abstract,2021-02-03,02
765eb8d799ddbd3e597fcb748273d7504db801fd,We're Not Sure We Like It but We Still Want More: Trainee and Faculty Perceptions of Remote Learning During the COVID-19 Pandemic,"The impact of the COVID-19 pandemic on medical education has been profound. Within undergraduate medical education, the need for social distancing led to the cancellation of many forms of learning including lectures and clerkships [1, 2] . Similar steps were taken in graduate medical education, with many trainees experiencing disruptions such as reduced patient volume and abrupt schedule changes [3] [4] [5] .Social distancing requirements forced many programs to make major changes to the structure of didactic learning as well [6] . Anecdotal evidence suggests that many programs transitioned away from in-person learning to remote learning, including both synchronous (livestreamed) and asynchronous (prerecorded) forms [7] .Remote learning is not new, with the majority of residency programs using it at least some of the time [8] . What is novel about the COVID-19 pandemic, however, is the extent of remote learning use and the speed at which it was adopted. The urgency of the situation forced many institutions to implement remote learning within the span of a single week despite the existence of multiple longstanding barriers to adoption and without the opportunity to orient either instructors or learners to the new format [9] .While COVID-19 has restricted in-person gatherings for the time being, we hope that there will come a time when inperson learning becomes both safe and permissible again. For this reason, in this study, we aim to assess the perceptions of remote learning compared to in-person learning among both trainees and faculty in our department in order to inform recommendations for structuring didactic experiences at our institution and others. We also aim to assess the possible effects that a brief faculty training focused on best practices in online teaching would have on faculty perceptions of remote learning.In response to the COVID-19 pandemic, all in-person didactics for trainees at our institution were suspended in March 2020, and the curriculum was transitioned to remote learning via the Zoom videoconferencing platform. Following this transition, informal discussions among trainees and faculty indicated that remote learning presented a range of challenges for both learners and teachers.The purpose of the current study was to understand and address the challenges encountered during the transition from inperson to remote learning among trainees and faculty. First, we conducted a remote learning attitudes survey. The attitudes survey assessed trainees' and faculty's experiences with remote learning compared to in-person learning across domains such as engagement, connection, and convenience using Likert response scales. The survey was distributed to trainees and faculty approximately 3 months after the transition from in-person to remote learning. Eligible participants were all trainees in the adult psychiatry residency (n=59) and child psychiatry fellowship (n=14) as well as all faculty who had taught at least one lecture in the curriculum in the preceding academic year (n=116).Second, we conducted a 1-h faculty training on best practices in online teaching. The training included three key components: presentation of data from the remote learning attitudes survey, a review of the literature on the efficacy of remote learning, and an introduction to specific remote teaching tools. During this session, we disseminated the following best practice principles for online teaching:& Understand the literature on remote learning. Many faculty members perceive remote learning to be less effective than in-person learning [10] . Educating faculty on the literature supporting the efficacy of remote learning may help to improve attitudes towards its use. & Implement active learning. Active learning is an effective method of keeping learners engaged and is associated with increased knowledge retention [11] [12] [13] . We introduced several active learning resources (e.g., PollEverywhere and Kahoot) and demonstrated their use within the session itself. & Encourage learners to turn their cameras on. We encouraged faculty to request that all trainees turn their cameras on at the beginning of each lecture to help with engagement.& Use trust generators. Trust generators are specific techniques that educators can use to foster a sense of trust between teachers and learners [14] . Given that online platform such as Zoom may be associated with challenges in interpersonal connection [15] , the use of trust generators such as selective vulnerability, similarity of interests, and showing concern can be beneficial. & Use storytelling as a medium. Because listening to a story is an imaginative act, storytelling may survive the transition to remote learning better than other forms of teaching. This is consistent with data supporting the use of storytelling as a method of changing beliefs, attitudes, and behaviors [16] . & Think of remote learning as its own medium with inherent weaknesses and strengths. Finally, we found it helpful to acknowledge that remote learning platforms such as Zoom are inherently different than in-person lectures. In areas where remote learning platforms are less intuitive than in-person teaching, specific features (such as the whiteboard function and breakout rooms in Zoom) may help to bridge the gap. In other areas, remote learning platforms provide features such as the chat function that are not available with in-person teaching.To assess the impact of the faculty training session, a separate evaluation survey was distributed to all faculty in our department (n=334) in July 2020 approximately 2 weeks after the training. Items related to faculty members' knowledge, attitudes, and skills towards remote learning were measured by Likert response scales. Respondents were dichotomized into two cohorts: those who attended the training (attendees) and those who did not (non-attendees).Survey items for both the attitudes survey and the training evaluation survey were developed by program leadership and trainees knowledgeable about the program's educational curriculum. The protocol for all surveys was IRB exempt (IRB#20-001287), and data collection was anonymous.For the remote learning attitudes survey, responses are presented as proportions by trainee and faculty cohorts and discussed descriptively. For the faculty training evaluation survey, responses are dichotomized, and Fisher's exact testing was performed comparing responses from faculty who did and did not attend the training. P values are two-sided with significance set at 0.05, and Stata 16.1 was used for analyses.For the remote learning attitudes survey, the response rate among trainees was 68% (n=50/73: adult psychiatry residents, n=41/59 and child psychiatry fellows, n=9/14), with 66% (n=48/73) completing the entire survey. Response rates among trainees were similar by training year. Among faculty, the response rate was 61% (n=71/116: adult division, n=39, child division, n=20, and other departments such as the Geriatric Division, Psychology Department, and Volunteer Clinical Faculty, n=12), with 53% of faculty (62/116) completing the entire survey. Faculty respondents represented a range of experience, with 46% having finished training more than 10 years ago and 54% less than 10 years ago. For the faculty training evaluation survey, the response rate was 16% (55/334: attendees, n=19 and non-attendees, n=36).Trainees and faculty perceived in-person learning more positively than remote learning on the majority of items assessed (Table 1 ). For example, over half of trainees and faculty indicated overall enjoyment, concentration during lectures, connection between trainees and teachers, and participation in discussions was perceived more positively with in-person lectures than remote lectures. In contrast, trainees and faculty stated remote learning was more convenient compared to in-person learning. While 64% of faculty felt ""much more engaged"" seeing learners' faces during remote learning, only 2% of trainees reported ""always"" keeping their cameras on while attending remote lectures. Over a third of trainees reported ""frequent"" (n=13) and ""constant"" (n=4) distractions during remote lectures. Despite negative attitudes towards remote learning compared to in-person, only a minority of trainees (10%) and faculty (14%) felt that all lectures would be most effectively delivered in-person once this becomes safe and permissible.Among faculty who attended the training session on remote teaching, previous knowledge about specific techniques for improving remote learning was low. Prior to the training, attendees indicated that they had ""never heard"" of teaching techniques such as trust generators (21%), clicker response systems (5%), real-time collaboration on a document (16%), the Zoom white board feature (32%), and Zoom breakout rooms (5%). Among non-attendees, many faculty indicated they ""did not know"" of remote teaching techniques such as trust generators (50%), storytelling (8%), clicker response systems (14%), breakout rooms (8%), real-time collaboration on a document (6%), and the Zoom whiteboard function (22%).Faculty who attended the training felt more confident in their ability to teach remotely compared to those who did not attend (89% vs 56%, p=0.02). Feelings of optimism about teaching remotely did not differ between attendees and nonattendees (89% vs 63%, p=0.06). Compared to non-attendees, faculty attendees were more likely to state they would utilize trust generators (90% vs 25%, p<0.01) and storytelling (94% vs 69%, p=0.04) in future teaching sessions. No significant differences were observed between faculty attendees and nonattendees in their reported likelihood of using clicker systems, real-time collaboration on a document, the Zoom whiteboard function, Zoom breakout rooms, and advance rehearsal of the lecture ( Table 2 ).Findings from the remote learning attitudes survey indicate that both trainees and faculty prefer in-person learning to remote learning on a majority of domains during the initial period of the COVID-19 pandemic. Despite this, only a minority of trainees and faculty feel that a complete return to in-person learning would be the most effective option when this becomes possible. Given that convenience is the only item that respondents rated as being perceived more positively with remote learning than in-person learning, this suggests that convenience is more important to both trainees and faculty than many other factors. Future studies will be needed to Willingness to ask questions of learners n/a n/a n/ a  67  3  30  Enjoyment of lecture  61  18  20  82  10  8  Ability to concentrate  66  16  18  59 10 31 Ability to communicate material n/a n/a n/a 85 3 12 Comprehension of material 43 16 41 n/a n/a n/a Retention of material 49 13 38 n/a n/a n/ a  Connection between trainees and instructor  83  6  10  97  0  3  Connection between trainees and each other  74  22  4 n/a n/a n/a Convenience of coming to lecture 0 90 10 10 78 12IP better in-person, R better remote, ND no difference evaluate this further, as we did not ask survey respondents to assign relative weights to each item. There is discrepancy between trainees and faculty regarding the perceived efficacy of remote learning. While 85% of faculty indicated that communication of material was perceived more positively with in-person learning compared to remote, over half of trainees perceived that comprehension and retention of material were either no different or better with remote learning. These data may be reassuring to faculty. Trainee perceptions are also more in line with the pre-COVID-19 literature which is generally positive towards remote learning [17] . This provides additional evidence for a gap between perceptions of remote learning and its actual efficacy in teaching, a gap which has previously been reported in the literature [18] [19] [20] .It is possible that the rapid speed of adoption may have had an adverse effect on perceptions of remote learning, as COVID-19 forced all faculty in our department to engage in remote teaching regardless of prior experience or training. To examine the effect that additional training could have on faculty, we presented a 1-h training focused on best practices in online teaching. Faculty who attended this brief training reporting feeling more confident in their ability to teach remotely compared to faculty who did not attend the training. However, it is less clear that this cohort is more likely to use the specific techniques that were discussed, with only two techniques (trust generators and storytelling) being more likely to be used by attendees of the training compared to non-attendees. Both of these techniques are easily understandable, require little technical ability, and may feel intuitive to mental health professionals. In contrast, more technologically advanced methods such as clicker systems, real-time collaboration on a document, and breakout rooms were not associated with increased use after the training session. We believe this is because many faculty members had little direct experience with these technologies, and the training did not include stepwise instructions on how to use them. A single hour of training, while sufficient for changing attitudes about remote learning, may not be enough to change practices. For this reason, additional training focused on how to use a specific types of educational technology may be warranted.Ultimately, our study must be viewed in light of its limitations. Our data reflect perceptions at a single institution, raising concerns about generalizability. As our institution adopted primarily synchronous remote learning, it is possible that other departments who use asynchronous remote learning may have different experiences. There is also a risk of selection bias, as our response rates were between 50 and 65% for the attitudes survey and lower for the faculty training evaluation survey.In conclusion, our data provide preliminary evidence that, while remote learning is perceived less favorably than in-person learning by a majority of trainees and faculty alike in the initial period of the COVID-19 pandemic, most trainees and faculty felt that it would be most effective for remote learning to continue in some form even after in-person learning becomes possible. Our data also suggest that a brief faculty training can improve attitudes towards remote learning, although additional training may be needed to impact specific behaviors. It is worth highlighting that our study specifically assessed attitudes towards various forms of learning but did not directly involve more objective learning outcomes such as trainee performance on board examinations and the PRITE, which could be a direction for future study. We hope that additional research will be conducted to provide guidance to training programs desiring to maintain a high quality of didactic education not only in the era of COVID-19 but in the future as well.Disclosure The authors declare no conflict of interest. ",USA,first author,2021-02-17,02
b0abefe9e350776b25b69b1624c7ffd936fc5fb3,"and Adolescent Health and Ageing, World Health Organization","3 effectively promote and protect nurturing care during emergencies such as the COVID-19 pandemic.During the COVID-19 pandemic, there have been drastic changes in family life on every continent. There have been prolonged containment measures in many countries, with second waves and renewed lockdowns. Families are ""locked in"" together, without access to their usual forms of social support and with disruptions to services and programmes that protect and promote early childhood development (i.e., childcare, early childhood education, parenting programmes, health services). Global stakeholders have raised concerns that essential components of 'nurturing care' for early childhood development have been harmed during the pandemic [1, 2] . The World Health Organization (WHO), UNICEF, and World Bank Group advocate that young children require five inter-related components of nurturing care for optimal development and well-being: good health, adequate nutrition, a family environment rich in responsive caregiving, opportunities for formal and informal early learning, and protection from safety risks and maltreatment [3] . During the first years of life, parents, intimate family members and caregivers are the closest to the young child and thus the best providers of nurturing care. This is why secure family environments are important for young children. In order to provide caregivers with time and resources to provide nurturing care, multisectoral policies, services and community supports need to be in place. Health, nutrition, education, social welfare, and child protection all have a role to play in creating an enabling environment for nurturing care (for further details, see https://nurturing-care.org).Evidence shows that epidemics and pandemics are associated with disruptions to nurturing care and child development, stemming from increased caregiver social isolation and stress [4], disruption to family routines [5] , traumatic stress among caregivers [6] , household conflict and anxiety [7] , early termination of breastfeeding [8] , and reduced play among children and engagement in team-based sports [9] . This rapid review aimed to capture the emerging evidence on the effects of the COVID-19 pandemic on three components of nurturing care: responsive caregiving, early learning opportunities, and child safety and protection from violence and neglect. This is a broad inquiry that is explored through different outcomes that are critical for nurturing care and child development. For responsive caregiving, it includes good mental health of parents and caregivers, warm and responsive parent-child relationships, breastfeeding support (to promote emotional bonds and attachment), and fathers' engagement in caregiving. For early learning, it includes access to formal and home-based learning, parent-child reading and other early learning activities, and safe play spaces. For children's safety and security, it includes protecting children against injury, neglect and abuse, including child protection and referral services for suspected maltreatment. This review did not examine child health and nutrition, the other components of nurturing care, due to ongoing work and recently published reviews in these areas. The review findings can help identify and conceptualize priority issues for early years' policy and programming during emergencies such as the COVID-19 pandemic and identify the literature gaps where future studies are required.To generate evidence in a short time, we employed abbreviated systematic review methods. A single reviewer completed the study selection and data extraction with verification by a second reviewer, and we omitted quality assessments of the included studies. The population of interest is young children (birth to 8 years old) and their caregivers, including birth parents, adoptive parents, and formal caregivers. Studies involving children up to 18 years old and their caregivers are included as long as the studies also included results for children under 8 years old. Published quantitative or qualitative studies that document their full methodology are included, and preprints and the grey literature to ensure representativeness and due to the rapidly evolving nature of COVID-19 pandemic impact evidence.We focused on studies that reported on responsive caregiving during the COVID-19 pandemic (e.g., parental mental health, caregiver stress, parent-child interactions, family functioning, fathers' engagement in caregiving, gender roles and norms, breastfeeding, skin-toskin contact, social support). We also included studies that reported on opportunities for early learning during the pandemic (e.g., access to formal and home-based learning, parent-child reading and other early learning activities, outdoor play, physical activity, screen time, sedentary behaviour). Lastly, we included studies that reported on children's safety and security during the pandemic (e.g., child injuries, child maltreatment referrals, child physical or psychological abuse, family violence). We searched two databases (PubMed and ERIC) based on a search strategy developed and pilot-tested in collaboration with a librarian. Also, for the grey literature, the review team manually searched the websites of more than 80 multilateral and bilateral organizations, internal NGOs, foundations, and so forth. Lastly, we screened the reference lists of the included studies for further relevant citations. We restricted the search to papers available in English, French, Spanish, and Portuguese. Studies were published between 1 January 2020 and 25 October 2020.Identified records were exported and managed on Zotero. After removing duplicates, the titles and abstracts of the remaining records were screened against the eligibility criteria, followed by full-text screening. We extracted data from the studies using a standardized form, with a second reviewer assessing for completeness and accuracy. Data extracted included, but was not limited to, investigators/authors, year of publication, setting, context, details of the methods and data collection, participants, outcomes, results, and conclusions. Data extraction was guided by Preferred Reporting Items for Systematic reviews and Meta-Analyses (PRISMA) checklist items. The preliminary stages of the synthesis involved organizing the extracted data through itemizing the data into thematic areas and tabulating the results to systematically identify patterns within and between studies and variations across studies. Because of the heterogeneity of the available primary studies, we synthesized the results narratively in the report.Lastly, a relatively small number of studies addressed opportunities for early learning and play during the COVID-19 pandemic (18). These studies point towards increased screen time among children, and a reduction in outdoor play and physical activities. Evidence is limited on homebased learning for young children (age 3-5 years) during the COVID-19 pandemic. What is available suggests challenges, frustrations and inequitable access to distance learning for the youngest learners. Results include 95 quantitative studies (primarily cross-sectional due to the nature of the pandemic), nine qualitative studies, and eight mixed methods designs. Key findings of included studies are synthesized in the following sections, and a summary of each study can be found in the complementary table. While this evidence base is heterogeneous, with variations in the data, context, and methodology, the findings are generally consistent in revealing that the pandemic and its related policy response measures drive increases in caregiver stress and poor mental health. For example, a study of 192 Italian mothers found that 29% of mothers who had given birth during the COVID-19 lockdown had an Edinburgh Postnatal Depression Scale (EPDS) global score above the cut-off score of >12, compared to only 12% in the control group who had given birth during the same period the year before COVID-19 [45] . A study of 651 Finnish parents of children (aged 5 to 8 years old) found that 26% met the clinical EPDS cut-off score for potential depression during the pandemic, compared to 15% among the same sample parents with data collected between 2014 and 2019 [33] .Numerous studies found that parent and caregiver stress, depression, and anxiety during the COVID-19 pandemic was associated with reduced responsive caregiving, including, for example, lower parent-child closeness and more avoidant or harsher parenting attitudes and behaviours [10, 13, 16, 27, 28, 32, 37, 38, 41, 42, 48] . A New Zealand study found that parents of young children (aged 4-5 years old) who experienced more significant depressive symptoms and perceived stress during a COVID-19 lockdown reported harsher parenting and less warm/responsive parenting, as measured by the Parenting Styles and Dimensions Questionnaire (PSDQ); and parent-child relationships were also of lower quality [32] . A US study of lowincome families with preschool-age children found that parental job loss and income loss during the pandemic were strongly associated with parents' depressive symptoms, stress, diminished sense of hope, and negative parent-child interactions, including losing their temper or yelling at their child [27] . However, parents who lost their job but did not experience corresponding household income decline, perhaps due to economic stimulus relief for low-income families, were more likely to report enjoying spending time with their child during the COVID-19 pandemic and engaging in positive parent-child interactions, such as playing with or hugging their child, compared to those who experienced a decline in household income. These results suggest that efforts to ensure economic security may help address parents' and other caregivers' mental health needs and reduce adverse parenting risk. Studies also noted more couple conflict[50] and increased substance use [51] among parents and caregivers experiencing stress and anxiety during the pandemic.Nine studies reported that COVID-19 restrictions, such as the closure of schools and playgrounds, the cancellation of sports and activity classes, and reduced social interactions with peers, were linked to reduced outdoor play and physical activity and more sedentary behaviour among children [72,81-88]. One study found that nearly 9 out of 10 Canadian parents reported increased screen time since the beginning of the pandemic among young children aged 18 months old to 5 years old [81] . More than half of the parents in this study reported that children's physical activity decreased during the pandemic, citing challenges due to the lack of indoor space and the variety of available toys. Another study found a dramatic decline in children's outdoor physical activity and much higher screen time use (average of 5 hrs/day) during the initial period of the COVID-19 outbreak, compared with before the restrictions [83]. Play indoors did not seem to replace active play outdoors, resulting in a net decline in children's playbased activities. Cities and areas with the highest number of COVID-19 cases, and thus most stringent restrictions, had the most significant drop in children's outdoor play [84] . Living in houses (as opposed to apartments) was correlated with increased outdoor activities [86].These changes do not reflect an actual reduction in the incidence or prevalence of maltreatment.The decrease in referrals is likely due to the given lockdown measures that preclude children from having regular contact with educators and other mandated reporters. Although many school districts have transitioned to online learning during the COVID-19 pandemic, evidence suggests that educators typically receive inadequate education related to recognizing and responding to child maltreatment. Virtual formats for teaching do not lend themselves readily to the identification of child maltreatment. With reduced exposure to schools and other social services, there is widespread concern that child maltreatment victims are going undetected.Given previous evidence detailing the strong links between caregiver stress and the risk of child maltreatment, the economic-related impacts of COVID-19 may contribute to elevated rates of child maltreatment; however, this relationship has not yet been substantiated.Parents and other caregivers may have treated more minor injuries at home or, in some cases, may have avoided seeking medical attention due to the concern of contracting COVID-19 in hospital facilities. Physical distancing measures, including a ban on sports and children's use of playgrounds during lockdowns, is likely linked to the overall reduction in child injuries seen through emergency room admissions. At the same time, there may have also been a shift in careseeking behaviour, with parents and caregivers being more anxious about attending hospital due to the risk to themselves and the child of contracting COVID-19.Based on these findings, we suggest policy and programme responses for action by governments, civil society, international and community-based organizations (see Box 1) . All of these options should be pursued vigorously and simultaneously so that the pandemic does not break the continuity nor lower the quality of provision of nurturing care and wipe out decades of progress, especially for low-income families and children. These approaches must be coordinated across sectors and aligned with practical social safety support to families and other caregivers of young children who experience socioeconomic hardship.2. Improve access to and use of mental health and psychosocial support services for parents and other caregivers of young children are essential. Digital interventions for anxiety and depression might include information provision, connectivity and triage, automated and blended therapeutic interventions (such as apps and online programmes), and telephone calls and home visits, especially for those without connectivity. Given the need to disseminate affordable mental health support widely due to COVID-19, group-based telehealth interventions may allow for an increased reach of psychological services in a time of elevated need.3. More evidence is needed on scalable responsive caregiving interventions, responsive caregiving, early learning activities and play, appropriate for the conditions of physical distancing and lockdowns. Programs that foster peer support and online platforms should be evaluated to ensure acceptable efficacy in supporting caregivers with young children, particularly on aspects of early learning and play. Guidance and resources to help parents with balancing screen time with physically active, screen-free activities may be warranted.4. Child protection systems should be redesigned, and educators trained to identify signs of child abuse and neglect specific to a distance-learning model. Home visitation programmes, with appropriate protection of social service staff, should continue to the extent possible, particularly with high-risk families. To increase awareness and access to reporting hotlines and other maltreatment reporting resources, policy makers may consider a variety of dissemination means, including public signage, as well as broadcast and social media.The evidence in this rapid review was primarily collected during the pandemic's first stage of lockdowns, representing only the early phase of the pandemic. Future research must investigate the longer-term impact of the COVID-19 pandemic on families as we enter a period of a gradual relaxation of lockdown measures in some regions and second waves in others. Gaps in the evidence base remain, with a lack of studies in low-and middle-income countries. There is an urgent need for action-oriented implementation studies -those that go beyond identifying trends and begin to pinpoint ""what works"" to effectively promote and protect nurturing care during health emergencies such as COVID-19. In particular, there is a need to identify effective interventions and strategies for families experiencing income loss, food insecurity, mothers with young children, families with disabled children, and those with pre-existing mental health challenges. Also, further inquiry is needed into the effects of COVID-19 lockdowns on early learning and children's play, which is transformative for children, allowing them to creatively develop their imagination, dexterity, and growth. The relative absence of studies related to early learning and playful parenting indicates a need for additional evidence on the nature and prevalence of early learning and playful parenting and innovative ways to protect and promote them during health emergencies.An online survey fielded in June 2020 collected retrospective self-reports on everyday activities, stressors, and well-being of parents and caregivers at three timepoints: before local transmission, after local transmission but before ""circuit breaker"", and during ""circuit breaker"".Results showed significant changes in jobs and income, childcare arrangement, family dynamics, and parents' emotional well-being throughout the three timepoints. Both mothers and fathers reported to worry most about the health and safety of family members and self. Mothers' time spent on housework partially mediated the effect of lockdown on their emotional well-being, and parents' conflict with other adults in the household partially mediated the effects of both pandemic and lockdown on their emotional well-being. The effects of pandemic and lockdown were also moderated by parents' age, education level, and fathers' authoritarian values. Both men and women are spending more time on housework and childcare, but the distribution is unequal: with 68% of women spending more time in housework and only 40% of men. The percentages for childcare are 61% and 51%, respectively. Hence, while most of the burden has fallen on women, the additional childcare is more equally shared than housework. Yet this balance disappears when we consider the amount of time spent on housework: 64% of women and 58% of men increase the amount of housework they do. Another predictor of higher child-related workload is the age of the children: children younger than 10 years old require more time from both working mothers and fathers. Working women with children age 0-5 are those most likely to report it is difficult to balance work and family due to excessive domestic responsibilities. Mothers of school age children who maintained jobs in early closure states were 68.8% percent more likely than mothers in late closure states to not be working. In other words, mothers of school age children in early closure states were much more likely to take leave from work than women in general. There was no significant difference in leave time between fathers from early closure and late closure states. In most of the cases, both parents primarily or solely worked from home during the time of the study, and most of them were working full-time the whole period, even though some worked reduced hours due to the pandemic. The diary entries of the mothers in the study demonstrate a gendered reality in which they experience burdens that seem to have escalated during the pandemic. We find that increased need for childcare has put a strain on working parents of both genders, but overall, mothers have been carrying a heavier load on the provision of childcare. In households with children, 44% of women report being the sole provider of care for their children as compared to 14% of men. Even while currently working, women are 27 percentage points more likely to be the only providers of childcare than working men, and 41 percentage points less likely to report that their partner is the only provider of care. Among working parents who are married or living with a partner, women were 17 percentage points more likely than men to become the sole childcare provider during the pandemic. were not encouraged to breastfeed as soon as possible after birth, 24.6% were not given information on expressing milk, and 21.2% stated they received no breastfeeding support in hospitals. Overall, 68.7% of those still breastfeeding felt they had much more or a little more time to focus on breastfeeding. For some respondents the lockdown brought advantages, such as increased time at home and the presence of fathers and other co-parents. However, for many the time was one of very considerable stress. Women cited feeling rushed out of hospital, poor follow-up care and poor access to information and support once at home as the main barriers to establishing breastfeeding with their babies. Black or Black British respondents were least likely to have had any contact with breastfeeding support organisations or charities. Younger respondents (<25 years of age) were most likely to cite the following as main concerns, all of which were higher than their older counterparts: their mental health, financial worries, relationship with others, eating a healthy diet, getting reliable pregnancy information and housing issues. Greater numbers of respondents whose income is below £16k reported to have concerns for their emotional and mental health, financial worries, and housing issues. other new mothers in their social circle but reported sadness of not being able to have those experiences due to social distancing. A great benefit to all the mothers was having their partners at home with them due to social distancing. The 2020 NIEER survey reported frequencies of engaging in reading, singing, teaching activities, and arts and crafts were lower than those in the 2019 NHES. The percentage reporting storytelling three or more times in the past week was higher than before the pandemic. Nearly three-quarters (74%) of Most parents (92.7%) reported that their children had online learning experiences during the pandemic, and many (84.6%) spent less than a half-hour each time. The parents generally had negative beliefs about the values and benefits of online learning and preferred traditional learning in early childhood settings. They tended to resist and even reject online learning for three key reasons: shortcomings of online learning, young children's inadequate self-regulation, and their lack of time and professional knowledge in supporting children's online learning. Also, the hardship caused by the COVID-19 pandemic has made them suffer, thus more resistant to online learning at home. A majority (93.8%) of children were studying in private schools and attending online live classes (83.7%). About three-fourth of the parents/guardians reported that online classes were less comfortable (81.7%) and less satisfactory (78.5%); guardians reported that children had poor attention and concentration (80.6%), lower learning of theoretical and practical aspects of the subject (82.4%), and lower ability to sit satisfactorily for the duration of the class (78.6%). The most common reported distraction was surfing internet (52.2%) or online games (52.2%).Oct-20 Ethiopia N = 480 Parents of children <5Crosssectional mobile phone surveys to understand how parents and caregivers with preprimary aged children haveMore than half of respondents reported they do not have children's books or learning materials at home, especially caregivers who are not literate. A large difference between urban and rural locations was also observed for families' access to electricity and technologies to support children's learning. Most have received little support from schools or local governments. Only 10% of caregivers reported they have been in contact with pre-primary teachers or school principals, with significant differences by household wealth and across regions. Only half report they have engaged in supporting learning activities for pre-primary children, which favours families living in urban areas. Mothers are most likely to be responsible for supporting children's learning at home; yet mothers are less likely to be literate. Around three quarters reported they play more often with their child since the COVID-19 crisis than before, including telling stories or singing songs. However, caregivers from poorer households or who are illiterate are less likely to engage in such activities. Only 12% said they had used radio lessons with their children. 78% of parents said they were educating their child at home due to COVID19. Most (77.1%) reported use of online tools for at-home education, including educational apps, social media, and school-provided electronic resources. Most parents were spending more time involved in daily caregiving of their children since COVID-19. Content analyses of open-ended questions indicated that school closures were a significant disruption, followed by lack of physical activity, and social isolation. an electronic registry. Only 18% of children aged 3-5 had some live on-line classes, and 37% received some material from their teachers. 45% of children aged 3-5 were never involved in any school activity at the date of interview. Changes in reading to preschool children, who listen to their parents reading, increased by almost half an hour more per day. During lockdown, all children watched about twice as much TV (about 3 hours for kindergarten and primary school children). Labor market restrictions imposed during lockdown resulted in increases in fathers' involvement in childcare and homeschooling. Fathers' involvement had a positive association with child emotional well-being, but no impact on reading hours and educational progress. The rapid assessment was conducted from May 11-14, 2020 to assess food insecurity; education; and livelihoods among vulnerable families.Confirmed that home learning is very challenging for children for a variety of reasons, including limited availability of learning materials at home and limited support received by children. Technological barriers (bad internet connectivity, costs of internet connection and limited availability of a devise to connect) while significant were not the highest reported challenges. Overall, there was a consensus that school closures are going to lead to school dropout, which respondents link to the impact that COVID-19 is having on livelihoods and to the perceived increase in child labour. Many parents expressed concern about decreases in frequency and intensity of children's physical activity and increases in screen time. Parents reported physical activity is limited due to lack of space and variety in tools and toys. Parents also reported strategies used to increase physical activity, such as scheduling outdoor playtime. Specific resources that were frequently mentioned included resources on engaging children in physical activity or any other activities, e.g., crafts, cooking to decrease screen time, tips for grocery shopping during COVID-19, homeschooling, scheduling, and time management.de Lannoy, L. et al. Parents were asked about their child's physical activity, sleep, sedentary time, time spent outdoors and in outdoor play in the last week and were asked to compare behaviours before and during the COVID-19 outbreak.Change in child and youth outdoor behaviour ranged from 1 (much less play) to 5 (much more play) with 3 representing no change. Overall, we found that all regions exhibited a decrease in time spent outdoors and in outdoor play (i.e., below 3), with Ontario having experienced the greatest decline in both time spent outdoors and in outdoor play (p < 0.001). Examined monthly referral data for children and young people attending child protection medical examination as part of a child safeguarding assessment from January to April 2020 in comparison with the same months in the last 2 years.Results showed a one-third reduction in child protection assessments from January to April 2020, compared to previous years. The total number of assessments from January to April was 152 in 2018, 156 in 2019 and 99 in 2020.Branstetter, S., et al. Parents who were more impacted by COVID-19 experienced more parenting stress than those who felt they were less impacted by COVID-19, and parents who experienced more parenting stress indicated that they had used more harsh parenting and felt less close with their children in the past weeks. There was no evidence that parents' perceived impact of COVID-19 influenced harsh parenting or parent-child relationships independent of its effect on parenting stress. 56% of respondents reported there had been a reduction in the number of requests from clients, many expressed concerns that it is 'too quiet out there.' Refuge staff reported being most concerned about children. Refuge staff were concerned that children exposed to violence who were living outside of the refuge would no longer receive the help that they need from professionals; and, moreover, that the violence they experience would remain undisclosed, as contact between adults outside of the family and the abused child is dramatically reduced. Closed schools and daycare centres are of particular concern as school represents normality and a zone free from the abusive parent. Over 1 in 5 parents/caregivers (22%) surveyed reported an increase in their use of negative or violent parenting methods. 32% of households had a child and/or parent/caregiver reporting that violence had occurred in the home, including children and/or adults being verbally or physically abused. The vast majority of parents/caregivers (89%) reported an increase in negative feelings due to the COVID-19 pandemic. While 83% of the parents/caregivers reported an increase in negative feelings when schools were closed between 1 to 4 weeks, the reports of negative feelings were higher for the vast majority of adults (95%) when schools had been closed for 17 to 19 weeks. Reviewed the incidence of suspected acute head trauma at an urban hospital between 23 March and 23 April 2020-the month that the United Kingdom entered a period of national self-isolation-and compared this with the incidence in the previous 3 years.Review of the incidence of suspected abusive head trauma indicated a 1493% increase per month compared to the same period over the previous 3 years (10 cases in comparison with a mean of 0.67 cases per month). All families live in areas with a higher than average Index of Multiple Deprivation and 70% of parents had significant underlying vulnerabilities (e.g., criminal histories, mental health disorders, financial concerns). Results pointed towards challenges to facilitating children's protection during the pandemic. CPWs reported more difficulty identifying children and families in need; a decrease in referrals from the formal network (typically schools and kindergartens); perception of overload of the work by the networking partners; and a drop in provision of services for families in need, especially family therapy, psychology and child psychiatry. CPWs reported that child well-being and protection became a secondary consideration, and families' basic food needs and individual health protection from the virus became priorities. 27% of parents/caregivers indicated that they had resorted to physical punishment or emotional abuse in the last month (39% for urban parents) while 25% of the children confirmed that their parents or caregivers used physical punishment and/or psychological aggression in the past month. There was a significant reduction in the odds of sportingrelated mechanism of injuries (by 57%) in 2020 compared with 2019. There were only 97 referrals following the introduction of social distancing measures in 2020 compared with 302 in 2019. This represents a 68% reduction in paediatric injuries. The general demographic of those presenting with injuries changed between the 2 periods, with a significantly younger median age in 2020 and more girls. The pattern of injury also remained generally unchanged with upper limb injuries being the most common at 67% and 69% respectively in 2019 and 2020. In 2020 there were 3% more safeguarding referrals for non-accidental injuries (not a statistically significant difference compared to",Canada,first author,2021-02-16,02
4112fdf0e105c02321fc0555cd36fe7fa64ed34e,Journal Pre-proof COVID-19 Recommendations for Assisted Living: Implications for the Future COVID-19 Recommendations for Assisted Living: Implications for the Future,"Recommendations related to health care (Supplemental Table 2 ) addressed personal 147 protective equipment, screening, testing, outside healthcare providers, advance care planning, 148 and transfers/admissions. 149 Clothing/Personal Protective Equipment. Recommendations for personal protective 150 equipment across the three target settings shared many similarities regarding PPE training for 151 staff, staff wearing facemasks, and residents wearing cloth face masks if tolerated and near 152 others. 23, 24, 27, 29, 36, 37 Furthermore, across the three target settings, recommendations were similar 153 regarding the use of PPE when COVID-19 is suspected or confirmed, concurring about staff 154 wearing eye protection, N95 respirators, gloves, and gowns when providing care to any 155 resident. 23,29,34,36,37 156 Screening. While the recommendations for screening among the three target settings were 157 largely similar regarding when and for what to screen, they differed in their specificity about 158 who should be conducting the screening. 23, 24, 27, 29, 30, 34, [36] [37] [38] The recommendations for LTCFs and 159 NHs did not specify designating anyone to be in charge of screening, 27, 29, 30, 34, [36] [37] [38] whereas the 160 AL recommendations suggested designating at least one employee to be in charge of ensuring 161 screening was uniform or considering seeking outside assistance to conduct screening. 23, 24 162 Furthermore, the recommendations for AL suggested setting up a central point of entry to 163 facilitate uniform screening for all who enter the AL, which was not included in the 164 recommendations for LTCFs and NHs. 23, 25 165 Testing. Recommendations for both AL and NHs suggested prioritizing staff and 166 residents who are suspected of having COVID-19 for testing. 23 However, rather than including 167 specific recommendations regarding universal testing, the recommendations for both AL and 168 LTCFs deferred to CDC guidance on testing in NHs and to local and state health departments for testing guidance. 23, 28, 37, 39, 40 The recommendations for NHs, which include CDC testing guidance 170 for NHs, contained detailed guidelines for who should be tested, when they should be tested, and 171 how often. 29, 35, 36, 41 172 Outside Healthcare Providers. Across all three target settings, recommendations for 173 outside healthcare providers suggested determining which ones were nonessential and restricting 174 those from entering. 23, 25, 29, 30, 34 In addition, all guidelines suggested monitoring personnel who 175 work at multiple care sites for potential exposure to COVID-19 cases 23, 29, 30, 33, 42 Historically, AL has been considered to provide a ""social"" model of care for its residents.While this framework is no longer sufficient or in favor to fully characterize AL, 11,20,21,45-47 it 197 provides important context to some AL core values, which include promoting resident autonomy 198 and privacy and providing a space for social engagement and aging-in-place. 10 unlike the recommendations targeted to LTCF and NH, those for visitation in AL suggest 213 encouraging residents to limit, rather than curtail, visitors, perhaps acknowledging the residential 214 nature of these settings and emphasis on autonomy and social engagement. However, despite the flexibility in recommendations, many AL communities and residents have not always been able 216 to exercise that choice fully, as the majority of states prohibited visitation at some point during 217 the pandemic. 9 When many states loosened those prohibitions during summer 2020, AL 218 communities found ways to enable residents to see relatives in person, such as offering outdoor 219 visits with strict masking and physical distancing requirements. [53] [54] [55] In other instances, spouses 220 of residents with dementia moved into or started working in the AL communities to be able to be 221 with their spouse, 56 but this may not be a realistic option for most spouses.Given that the average length of stay of AL residents is almost two years, and that they 223 typically spend time with family and in outside activities, 21 disruption in social engagement may 224 be especially consequential. To maintain opportunities for social engagement for residents, some 225 AL communities have relied on technology (e.g. iPads) to enable residents to video chat with 226 their relatives and to participate in virtual activities. However, these adaptations require 227 investments in technological devices as well as add responsibilities to an already stretched 228 workforce who need to facilitate these virtual conversations for those without personal devices 229 and for residents with dementia. 53, 55, 57 Adding concern to the impact of this disruption is that in 230 general, psychosocial support in AL is limited; only 10% of communities directly employ a 231 social worker, and the extent of social work services lags behind that available in NHs, hospice, 232 and adult day services. 5 Because social workers are trained to promote resident well-being, [58] [59] [60] [61] [62] 233 COVID-19 recommendations underscore the benefit of having psychosocially-trained personnel 234 such as social workers to support residents, their family members, and staff.Regarding health care in AL, COVID-19 and related recommendations for AL have 236 paved the way for states, such as Massachusetts, to relax state regulations and so enable AL staff 237 to provide more health care services --such as administering injections and managing oxygen --which many AL operators want to be made permanent. 63 Other states already offer licensure 239 categories that enable AL staff to provide these additional health care services, sometimes 240 referred to as enhanced AL. 63 This modification of regulations offers an early indication of how 241 COVID-19 may lead to greater integration of health care into AL and reinforces the need to 242 evaluate what changes will provide the greatest benefit to residents.The recommendations for screening in AL 23, 24 indicate that there may not have 244 traditionally been an employee on staff who was recognized as capable to oversee the screening 245 of all residents, staff, and visitors for possible infectious illness, perhaps due to the variation in 246 licensed nurse staffing 14 and state requirements regarding infection prevention and control. 16, 17 247 While processes to screen staff and visitors may be standard, monitoring AL residents for signs 248 of COVID-19 may require more training because COVID-19 can present abnormally or 249 asymptomatically in older adults. 64 The recommendations for testing in AL explicitly defer to recommendations for testing in 251 NH, even though testing capacity is an area where AL and NH differ more so than most. Other 252 types of testing are more typical in communities that have licensed nurses, 13 yet testing is a key 253 part of reopening plans for all long-term care settings, indicating that some AL communities 254 must adapt to conduct testing. Such adaptation may involve partnerships with local health 255 departments and other third party care providers to access testing, perform the tests, and process 256 their results, 39, 65 particularly for the half of AL communities that do not have a licensed nurse on 257 staff to conduct or delegate testing. 12, 15 Nonetheless, it is worth noting that the issues related to 258 testing in AL extend beyond staffing, as many AL communities have faced barriers in enacting 259 universal testing programs, including long laboratory processing time, cost, and lack of 260 government support. 66 As with testing, vaccine distribution in AL communities rely on partnerships, such as with pharmacies in the federal Pharmacy Partnership for Long-Term Care 262 Program for COVID-19 Vaccination. 67 However, many states have prioritized NH residents for 263 vaccination before AL residents, resulting in delays in the vaccination of AL residents. 68,69 264 As with the recommendations for testing and screening, those for advance care planning 265 and transfers in AL highlight the need to actively involve licensed clinicians, particularly the 266 physicians, nurse practitioners, physician assistants and social workers in improving medical 267 care and decision making in AL. 39, 50 Some regulations go so far as to note the need for AL-268 affiliated clinicians to work with residents' primary care providers, giving a nod to evolution of 269 the role of medical director that has been advocated by some. 19 Both domains underscore the Furthermore, these adaptations and quality improvement must be based upon reliable data, which 302 has historically been a challenge for AL. 8, 9 As was recently noted, COVID-19 has brought long-303 term care out from ""under the radar"" 70 meaning the time is ripe for change. COVID-19 304 recommendations for AL indicate the change that is needed when push comes to shove.The authors have no conflicts of interest. • Cancel group activities 9,10 or modify group activities to follow infection control guidelines. 4 • Cancel communal dining 9,10 and have residents eat in their rooms alone if they can do so safely. 10 Consider other modifications for residents who need help when eating. 10 • Cancel group activities initially. 7 • If tolerated, residents should wear cloth face coverings when in communal areas or when in close proximity to other people. [1] [2] [3] [4] [5] • Staff should wear a facemask at all times in the AL, if available. [1] [2] [3] [4] 6 • Staff should be trained on selection, donning, and doffing of PPE. 1, 4, [6] [7] [8] Similar Intent• If gown supply is limited, prioritize them for highcontact care activities, such as helping with ADLs. Consider extended use or reuse of PPE if there are shortages. 1 • If COVID-19 is suspected or confirmed in a resident, staff should wear eye protection and an N95 respirator (or facemasks if respirators are not available) when in close contact with any resident. 1 • If COVID-19 is suspected of confirmed in a resident, staff should also wear gloves and a gown when in direct contact with any resident. 1• Prioritize N95 masks for staff caring for residents with COVID-19 and for procedures that may cause aerosolization of particles. 7 Consider extended use of PPE if there are shortages. 3 • If COVID-19 is suspected or confirmed in a resident, staff should wear an N95 respirator (or facemasks if respirators are not available), eye protection, gloves, and gown when providing care to any resident. 5, 7 If there is community-wide COVID-19 activity, staff should use gloves and facemasks when caring for any resident. 7• If gown supply is limited, prioritize them for highcontact care activities, such as helping with ADLs. Consider extended use and limited reuse of PPE if there are shortages. 4, 6 • If COVID-19 is suspected or confirmed in a resident, staff should wear an N95 respirator (or facemasks if respirators are not available), eye protection, gloves, and a gown when providing care to any resident. 4 • Designate at least one facility employee to be in charge of screening other employees, third party personnel, and visitors upon entry for fever and symptoms of COVID-19. 1,2 Consider if outside assistance is needed for this duty. 2 • Designate at least one facility employee to be in charge of screening • Screen employees, third party personnel, and visitors upon entry for fever and symptoms of COVID-19. 5, 7, 9 • Screen residents daily for fever and symptoms of COVID-19. 5, 7 Consider increasing this screening to 2-3 times daily when COVID-19 is in the LTCF. 3 • Screen employees, third party personnel, and visitors upon entry for fever, symptoms of COVID-19, and any known exposures to someone with COVID-19. 4 Substantially Different Intent• A resident with COVID-19 can stay in the AL if they can perform their own ADLs, request assistance, isolate in rooms, be checked on by AL staff or home health agency staff regularly, receive meals in their room. 1 If the resident needs more help, on-site or consultant personnel may provide supplemental care to allow them to stay in the AL. 1, 8 • A LTCF resident with COVID-19 does not have to be hospitalized but should be put in contact precautions and follow CDC guidance for COVID-19 cases in LTCF. 19 • Assume that new admissions without a negative COVID-19 test have COVID- 19. 19 • A resident with COVID-19 can stay in the NH if the resident does not need more care than the NH can provide and can follow proper infection control protocols for caring for residents with COVID-19. 10 • For new admissions without a positive COVID-19 test, place the resident in single-person room or separate observation area. Staff should wear an N95 respirator, eye protection, gown, and gloves when caring for these residents.These residents should stay in this observation area until they have been afebrile and asymptomatic for 14 days. 4, 6 Not Included Elsewhere• AL-affiliated clinicians should work with the resident's primary care provider and consider the resident's goals of care when making transfer decisions. 8• If a resident has a newonset suspected or confirmed COVID-19, the NH should consider halting admissions until they can assess the extent of transmission. 6 * This table includes paraphrased COVID-19 recommendations for AL, LTCF, and NH from 6 sources (Centers for Disease Control and Prevention, the Centers for Medicare & Medicaid Services, the American Geriatrics Society, the Society for Post-Acute and Long-Term Care Medicine, the American Health Care Association/National Center for Assisted Living, and the Alzheimer's Association). Where boxes are empty, no recommended policies or procedures existed.",United States,abstract,2021-02-25,02
1528b1d67f27183ce225533fde319556f1156043,Exosomes from COVID-19 patients carry tenascin-C and fibrinogen-β in Running title: Inflammatory signal by exosomes from COVID-19 patients,"was verified from the exosome preparations by Western blot analysis as described previously (10, 11) and 103 the results from a representative blot is shown (Figure 1, panel B) . Exosome depleted serum (Invitrogen) 104 was used a negative control and as expected, did not exhibit the presence or cross-reactivity for CD63 or 105 TSG101 proteins. N1 and N2 of SARS-CoV-2 RNAs were undetected in exosome preparation from 106 patients or healthy subject controls using a CDC recommended PCR kit. 107 108 Exosomes from plasma of COVID-19 patients harbor tenascin-C and fibrinogen-β. Little is 109 known about the proteome profile of the exosomes from COVID-19 patients. Using unbiased 110 proteomic approach, the mass spectrometry analysis identified 1,637 proteins. We shortlisted 163 111 proteins having more than five spectra counts and at least twofold changes as compared to 112 plasma exosomes from healthy volunteers (Figure 2, panels A and B) . Tenascin-C (TNC) and hepatocytes in vitro were used as a model cell line and exposed to exosomes from COVID-19 135 patients or from healthy controls. A significant upregulation of tumor necrosis factor-α (TNF-α), 136 interleukin-6 (IL-6) and C-C motif chemokine ligand 5 (CCL5) were observed from exposure of 137 immortalized human hepatocytes (IHH) to exosomes isolated from COVID19 patient plasma, as 138 compared to exosomes from healthy normal plasma (Figure 4, panel A) . Similar results were 139 7 noted from COVID-19 plasma exosomes when exposed to a different cell line with hepatocyte 140 origin (Huh7). Pearson correlation analysis among expressions of the TNF-α, IL-6 and CCL5 in 141 the hepatocytes exposed with patient exosomes. A significant positive correlation (P= 0.001, r= 142 0.66) was seen between TNF-α and CCL5 expression from hepatocytes (Figure 4, panel B) . 143 These results demonstrated that COVID-19 plasma exosomes trigger strong pro-inflammatory 144 cytokine production in hepatocytes. (FBS) and 1% penicillin/streptomycin at 37°C in a 5% CO 2 atmosphere. IHH and Huh7 cells 229 were seeded into 6-well plate at a density of 3x10 5 cells/well and exposed to equal concentration 230 of exosomes for 48h. Cells were harvested for RNA analyses. ",USA,first author,2021-02-09,02
f410d45beba063a71e3e2e4d41cd7760c7dfaedb,Journal Pre-proof Impact of COVID-19 on Future Ischemic Stroke Incidence Impact of COVID-19 on Future Ischemic Stroke Incidence,"Several reports have now confirmed that the severe acute respiratory syndrome coronavirus -2 (SARS-CoV-2) infection, coronavirus disease 2019 (COVID-19) is associated with thrombotic events, including ischemic stroke. 1-7 A possible association between COVID-19 and stroke was first noted early in the pandemic in a retrospective case study published from China. 4 Since this initial publication, several larger retrospective cohorts have reported stroke incidences of ranging from 0.9% to 3.3%. 3, 5-8 In fact in comparison to influenza A-B, the odds of developing a stroke have been reported to be seven fold higher with COVID-19. 3 Patients with COVID-19 that have stroke tend to be more severely affected and have higher mortality rate than case matched J o u r n a l P r e -p r o o f Journal Pre-proof control IS patients. 9 IS tends to occur in those with more medical comorbidities, 10 but can also occur in patients without preconditions and/or under the age of 55, [11] [12] [13] suggesting even healthy people are at risk. COVID-19 is thought to lead to increased thrombotic events such as IS secondary to hypercoagulability caused by systemic inflammation, viral-induced endothelial damage and cardiac dysfunction. 8, [14] [15] [16] [17] Multiple studies report that most COVID-19 related IS are cryptogenic or embolic stroke of undetermined significance (ESUS), which is a stroke subtype thought to be caused mostly by an undiagnosed cardioembolic source. 14, 18 Cardiac disease is one of the most frequent complications occurring in COVID-19 patients, 19, 20 and the damage can be long-standing even after recovery. 21 Given the increasing prevalence of COVID-19 and it's predilection for causing cardiac damage and known propensity for cryptogenic/ESUS IS, it is important to consider the future impact of COVID-19 on future stroke incidence.As mentioned previously, there is a higher proportion of COVID-19 related IS that have been reported to be cryptogenic or embolic stroke of undetermined significance (ESUS). 14, 18 Cryptogenic or ESUS are thought to occur in the setting of thromboembolic predisposition and involve an unknown embolic source. In the landmark trial NAVIGATE-ESUS, 73% of ESUS were eventually attributed to a cardiac source, with 37% associated with atrial cardiopathy and 36% associated with underlying ventricular disease. 18 COVID-19 patients may suffer several cardiac complications including ventricular and atrial arrhythmias (AA), myocardial injury, acute coronary syndrome, and cardiomyopathy. 19, 20 These can also result in embolic sources for thrombi and lead to ESUS. 3, 4 Based on these findings, COVID-19 patients may represent a perfect set-up for ESUS due to the increased risk of AA and cardiomyopathy development in addition to COVID-19 associated coagulopathy.Recent evidence suggests that COVID-19 cardiac complications are due to an orchestrated inflammatory response leading to cardiac dysfunction 19 and sympathetic surge. 22 The massive systemic inflammatory response or ""cytokine storm"" seen in sepsis caused by COVID-19 could also be a significant contributor. 19, 20 Cardiac complications associated with COVID-19 were reported in Chinese cohorts in early 2020 and were found to be most notable in the subset of patients who were most critically ill 19, 20, 23 and with pre-existing risk factors for cardiac disease such as hypertension and obesity. 19, 20 A global survey of medical providers reported that 21% of medical providers found atrial fibrillation within their patient population hospitalized with COVID-19, while 5.4% reported atrial flutter . 24 AA have also been reported to be a frequent reason for electrophysiology consultation in a hospital heavily impacted by COVID-19. 25 Cardiac arrhythmias were detected in up to 17% of patients with incidence increasing to greater than 40% among critically ill patients. 19, 20 Colon et al analyzed the electrocardiograms (ECGs) of COVID-19 ICU patients (n = 69) and non-ICU patients (n=46) and also found that around 17% of their cohort developed AA. 5 Furthermore, patients who developed AA including atrial fibrillation (AF) and atrial flutter often had a history of hypertension and/or obesity and were the most critically ill, requiring mechanical ventilation and vasopressor support. 26 These findings were further corroborated by a study in Pennsylvania, which reported that patients that developed atrial fibrillation while hospitalized had a higher mortality rate, were more likely to be in an intensive care setting, and more likely to have heart failure. 27 These studies suggest that the development of AA is associated with greater morbidity and mortality within the COVID-19 population. The etiology of COVID-19 related AA is currently unclear and requires further research.Even with current data, there are still several knowledge gaps. Most reported studies have included data from hospitalized patients early during the pandemic. During this time, secondary to stay at home orders and possibly patients wanting to avoid healthcare facilities, stroke volumes decreased significantly. 28 Thus, a sub-group of patients with asymptomatic or mild COVID-19 symptoms or mild or transient neurologic deficits may not have been captured in current data sets. Also, we are still learning about the long-term implications of COVID-19 related cardiac disease and hypercoagulability. Without both of these questions addressed, it is more difficult to formulate comprehensive stroke prevention strategy for COVID-19 patients, as we will not be able to determine which COVID-19 patients are at increased risk of having an IS, or be able to predict the mechanism behind it (i.e. hypercoagulability, cardioembolic/ESUS, or traditional stroke risk factors such as hyperlipidemia, hypertension, and atherosclerosis).This information is needed to provide evidence-based guidance on most effective forms of stroke prevention in this higher risk population. Several randomized trials further investigating the role of anticoagulation in COVID-19 for prevention of thrombotic events are currently pending (NCT04345848, NCT04362085, NCT04406389). With millions of patients contracting COVID-19 and the estimated risk of IS and persistent cardiac dysfunction in this COVID-19 patients reported, there could be a significant number of new IS cases related to COVID-19, particularly those with pre-existing conditions. 1, 26Assessment of the long-term risk of IS and cardiac disease that increases risk of ESUS and cryptogenic IS will provide vital information for future risk stratification of COVID-19 patients. Patients who develop severe cardiac complications such as myocardial injury, ACS, or cardiomyopathy may experience further compromise of cardiac function and later development of AA as natural progression of these processes. 19 These findings suggest that COVID-19 survivors, both those with and without acute onset of cardiac complications, may be at higher risk of developing AA in the future, further increasing their risk for ESUS and cryptogenic IS. Addressing this need could be accomplished with COVID-19 database registries, long-term observational studies of COVID-19 survivors, and studies comparing cardiac and stroke outcomes in COVID-19 patients. At this time in the developing COVID-19 pandemic, long-term follow-up on large cohorts of COVID-19 patients has not yet been reported. However, we do know that patients have been reported to have persistent symptoms even after SARS-CoV2 RNA is undetectable after recovery. 21, 29 In addition to capturing data on traditional stroke risk factors and assessment for coagulopathies, COVID-19 registries and observational studies should include clinical outcome variables that can be used to detect patients at highest risk of having an ESUS/cryptogenic IS as well as provide methods for tracking long-term outcomes. Previously established clinical markers associated with left atrial abnormalities, such as the P-wave terminal force in lead V1 (PTFV1), may be of use in COVID-19 patients, as they serve as indicators of long-term IS risk independent of clinically diagnosed AF. 30 Development of reliable methods to monitor these patients in the immediate setting and long-term will be instrumental in the understanding of how COVID-19 may increase the risk of ESUS/cryptogenic IS. This will require novel approaches for data collection and patient participation to compensate for the decreases in healthcare utilization during the pandemic. 28 For example, stay at home orders in Denmark not only reduced diagnosis of new onset AF, but were also associated with increase stroke incidence and mortality related to AF. 31 This demonstrates that adaptions for patient monitoring and systems of care are essential. Other forms of healthcare access such as telemedicine have proven to be successful as demonstrated by the TeleCheck-AF program. 32 In addition, the J o u r n a l P r e -p r o o f Journal Pre-proof COVID-19 Symptom study is another example of using remote technology to capture outcomes data in large population of COVID-19 patients (https://covid.joinzoe.com/us/data).The COVID-19 pandemic has ushered in a new era of healthcare. It is important to prepare for continued evolution of acute management practices and the discovery of potential long-term disease manifestations that can evolve in COVID-19 survivors, including IS.",USA,first author,2021-02-01,02
385cc54573b4bb2633f363052280b9ff4bd88bdc,Journal Pre-proof Assessing and Managing SARS-CoV-2 Occupational Health Risk to Workers Handling Residuals and Biosolids Assessing and Managing SARS-CoV-2 Occupational Health Risk to Workers Handling Residuals and Biosolids Retired -former USEPA,"that application of sludge and biosolids during the COVID-19 pandemic carries significant risk (Langone et al., 2021; Patel et al., 2020) . Reviews have recommended that sludge produced in cities with high numbers of cases should be incinerated or sent to the landfill (Liu et al., 2020b) .Some health authorities, such as the Italian National Institute of Health, have issued precautionary sludge handling guidelines, which detail minimum retention times requires for sludge in relation to ambient temperatures (Collivignarelli et al., 2020) . A recent quantitative microbial risk assessment by Dada and Gyawali (2020) suggested that risk of wastewater workers is only negligible when less than 0.3% of the population served by the plant is actively infected. Utilities, especially in smaller communities, neither have the resources nor the time to evaluate this emerging data.Given these contradictions in risk evaluations related to solids handling, the highly variable and inconsistent concentrations of SARS-CoV-2 genetic material (RNA) recovered from feces and sewage, the paucity of reports of viable SARS-CoV-2 in feces and the heightened risk perception amongst workers in the water sector, a critical and peer-reviewed synthesis of current data available would support risk mitigation and communication for utilities and their workers. The present work highlights the most recent relevant publications, pre-prints and reviews that help determine whether additional risk mitigation measures are needed when workers handle wastewater treatment residuals. We will specifically focus on risk resulting from fecal-oral, bioaerosols and fomite exposures.Residuals are categorized into: (1) human feces, (2) Code of Federal Regulations Part 503 to protect public and environmental health from any potential negative effects that might be related to the application of sludge and biosolids to land (Reimers et al., 2004; USEPA, 1992; USEPA, 2018) . The Regulation covered chemical pollutant limits, operational standards designed to reduce pathogens and attraction of disease vectors, as well as management practices.US EPA defines Class A disinfected biosolids as those where pathogenic organism densities are reduced to below detectable limits which include Salmonella sp. to less than 3 Most Probable Number (MPN) per 4 grams total solids, Enteric viruses to less than 1 Plaque Forming Unit (PFU) per 4 grams total solids and viable helminth ova to less than 1 viable helminth ova/4 grams total solids. Class A biosolids are achieved through a Process to Further Reduce Pathogens (PFRP). Class B biosolids can be achieved by showing that the sludge was treated by a Process to Significantly Reduce Pathogens (PSRP) or that the treated biosolids contain less than 2 million Colony Forming Units (CFU) or MPN of fecal (thermotolerant) coliform bacteria per gram of biosolids (dry weight basis). While pathogens are greatly reduced in Class B biosolids, they are not completely eliminated, therefore there are public access, agricultural and grazing restrictions placed on their use in land application (USEPA, 1992) .In some circumstances, WRRF seek to incorporate a novel process for biosolids treatment that was not previously included in the original legislation. For a process to achieve an equivalency status, it must be approved by the USEPA's Pathogen Equivalency Committee (PEC) (Fitzmorris et al., 2020) , as well increased partitioning into solids due to surface charge and relative hydrophobicity (Kumar et al., 2020) . Thus, we would expect that no additional protective equipment or other prevention and control measures in response to SARS-CoV-2 are required for managing properly treated biosolids than those previously described and encouraged.Overall, the risk of exposure to SARS-CoV-2, or any pathogen, decreases with increasing fecal waste and biosolids treatment with the highest risk being associated with spreading untreated feces (stool) or other fecal wastes, followed by untreated municipal sludge, the class B biosolids, while lowest risk is associated with spreading Class A biosolids.To assess potential risks resulting from SARS-CoV-2 exposure, reviews have relied primarily on data from viral indicator organisms (e.g., bacteriophages in Martin- Diaz et al., 2020 and Pillai et al., 2011) , for coronaviruses other than SARS-CoV-2 and more recently SARS-CoV-2 RNA.Martin- Diaz et al. (2020) concluded somatic bacteriophages have potential as surrogates for pathogenic viruses in solid and semisolid fecal waste matrices due to their higher natural persistence and resistance to typical treatment mechanisms (Martin-Diaz et al., 2020) . As viruses are typically adsorbed to solid particles both under natural and anthropogenic conditions, certain solids (Fongaro et al., 2017; Hurst et al., 1980; Sobsey et al., 1980; Feachem et al., 1980; Pederson 1981 ) and water quality characteristics can affect the adsorption efficiencies of viruses to various matrices. These characteristics include pH, virus ionic characteristics (surface charge), virus surface hydrophobicity, dissolved salts, and organic matter among others (Hurst et al., 1980; Zhao et al., 2008; Bitton and Mitchell, 1974; Bixby and O'Brien, 1979) . It has also been noted that other enveloped viruses used as SARS-CoV-2 surrogates (e.g. murine hepatitis virus (MHV) and Pseudomonas phage ϕ6) exhibit higher J o u r n a l P r e -p r o o f partitioning to solids compared to non-enveloped viruses (Ye et al., 2016) . Similarly, SARS-CoV-2 RNA has been documented in wastewater, primary sludge and waste activated sludge and is now being used as part of epidemiological and public health response efforts to track disease spread and prevalence in communities (Ahmed et al., 2020; Kocamemi et al. 2020; Peccia et al. 2020; Balboa et al., 2020; D'Aoust et al. 2021) ; however, infectious virus has not yet been identified in wastewater or biosolids. Additional review of the current state of knowledge related to coronavirus detection, presence and persistence in the water and wastewater environment may be found in the available literature (Carducci et al., 2020; Jones et al., 2020; Patel et al., 2020; Collivignarelli et al., 2020; Elsamadony et al., 2021; Maal-Bared et al., 2020; Foladori et al., 2020; Kataki et al., 2021) .Coronaviruses die off rapidly in wastewater compared with waterborne enteroviruses, with the time required for the virus amounts to decrease 99.9% between 2 and 4 days before any treatment at 23°C (Gundy et al., 2009; Bivins et al. 2020) . Even in the examination of nonenveloped, enteric viruses, the typical multi-barrier wastewater treatment approach, which may include primary sedimentation and coagulation, trickling filters or activated sludge, disinfection and membrane filtration, have been shown to achieve a greater than 99.9% reduction in viral load (Pepper et al., 2006) . Heat treatment of wastewater amended with SARS-more susceptible to disinfectants (free chlorine more effective than chlorine dioxide) than E. coli and f2 phage. Table 3 highlights the ranges in log reductions by sludge treatment type (Godfree, 2003; Ward, 1984) .Recently, Chin et al. (2020) confirmed SARS-CoV-2 sensitivity to heat and disinfectants. While coronaviruses have been shown to survive up to 9 days on surfaces, inactivation can be achieved with 62% to 71% ethanol, 0.5% hydrogen peroxide, or 0.1% sodium hypochlorite within 1 minute with higher temperatures also reducing survival (40 o C as compared to 20 o C) (Kampf et al., 2020; Fathizadeh et al., 2020) . The results from this meta-analysis correspond with recent SARS-CoV-2 research by Chin et al. (2020) that reported the inability to recover any infectious virus (>7.8 log 10 reduction) from viral transport medium after 5-min incubation at 22°C with various disinfectants with the exception of soap and water(~4.2 log 10 reduction). The latter study also reported that SARS-CoV-2 is extremely stable in a pH range of 3 -10 at room temperature (Chin et al., 2020) . Thus, disinfection of contaminated surfaces and personal hygiene measures (e.g., hand hygiene) are documented to be effective and therefore critical to mitigate risk of infection by SARS-CoV-2 and other pathogens (Heneghan et al., 2020) .Most virus-related research in the biosolids field has been on enteroviruses. Work by Gundy et al. (2009) showed that SARS-CoV-1, a relative of the SARS-CoV-2, displays less environmental persistence in primary and secondary effluent compared to poliovirus (an enterovirus), which is used as an indicator for biosolids PFRP equivalency. Wang et al. (2005) noted SARS CoV-1 virus was more susceptible to disinfectants than E. coli and f2 phage, with free chlorine more effective than chlorine dioxide. Recent work has observed that reoviruses and bacteriophages could be suitable surrogate indicators for viruses due to the similarity of their resistance to treatment (Diaz et al., 2020; Viau and Peccia, 2009; Gerba et al., 2018; Casanova and Weaver, 2015) . It should be emphasized that existing and proposed non-enveloped virus surrogate viruses are expected to display higher levels of resistance to environmental stressors and disinfection compared to enveloped viruses in general and SARS-CoV-2 specifically, thereby making them conservative indicators (CDC, 2020).Determining the risks for pathogens such as SARS-CoV-2 must consider their occurrence, persistence, routes of transmission and dose-related probabilities of infection and illness, among other properties. This is best done using quantitative microbial risk assessment (QMRA), which typically includes five stages: a) hazard identification; b) exposure assessment; c) dose-response assessment, d) risk characterization and e) risk management. As quantitative infectivity dose-response parameters of SARS-CoV-2 remain unknown at the time of this publication, performing a formal quantitative microbial risk assessment is not possible.However, a qualitative risk assessment can be performed based on an analysis of the hazards identified. This approach includes consideration of the presence and potential infectivity of SARS-CoV-2 in the four categories of residuals along with their likelihood of transmission to workers through various exposure routes. The most relevant transmission routes that should be considered to mitigate risk of occupational infection with SARS-CoV-2 for workers handling residuals and biosolids are the fecal oral route, bioaerosols, fomite transmission and direct personal contact. Overall, magnitude of risk resulting from exposure to a fecal solids residual category is higher the less treatment the residual receives prior to handling and spreading or J o u r n a l P r e -p r o o f other final disposition (e.g., landfill or incineration). The highest risk would be related to spreading or otherwise having intimate contact with feces or stool, followed by untreated municipal sludge, the class B biosolids, while lowest risk would be related to spreading or otherwise handling Class A biosolids.Prior to the emergence of SARS-CoV-2, a focus of concern about feces-associated coronaviruses was with SARS-CoV-1 and some of the respiratory coronaviruses causing the common cold. The presence of SARS CoV-1 RNA in stool samples was reported initially by He et al. (2004) in 57.4% of SARS patients; this study utilized fluorescence-based quantitative polymerase chain reaction or FQ-PCR method which does not determine infectivity.Additional quantification of the median duration of SARS CoV-1 virus RNA excretion from stools was 27 days (16 to 126 day range), but no infectivity was reported (Liu et al., 2004; Hung et al., 2004) .experiments in feces only 3 days at 20 o C, but at 4°C persisted for 17 days (Wang et al., 2005) .Detection frequencies of the genetic material (RNA) of other coronaviruses in feces of infected individuals ranged from 16% to 97% with a peak for SARS-CoV-1 RNA at 9 to 14 days after illness onset (Cheng et al., 2004; Wigginton et al., 2015; Wigginton and Boehm, 2020) .Three other human coronaviruses -HCoVNL63, HCoV-OC43, and HCoV-229E -that infect the upper respiratory tract have been detected in stool samples (Esper et al., 2010; Risku et al., 2010) .In the case of SARS-CoV-2, a meta-analysis conducted by Jones et al. (2020) concluded that 11% of COVID-19 patients experience diarrhea. Studies specifically examining the presence of SARS-CoV-2 RNA in stool samples from laboratory-confirmed positive patients report detection in 29 -64% of patients Chen et al., 2020; Holshue et al., 2020; Xiao et al., 2020; Ong et al., 2020; Tang et al., 2020; Wölfel et al., 2020) . Similarly, the prolonged shedding of SARS-CoV-2 RNA in feces by COVID-19 patients has been reviewed in the literature (Jefferson et al., 2020; Foladori et al., 2020) . Wölfel et al. (2020) reported that stool samples remained RNA-positive over three weeks in six of the nine examined patients, in spite of full resolution of symptoms.Recent work has shown that SARS-CoV-2 binds to the angiotensin-converting enzyme 2 (ACE2) receptors on Type II alveolar cells and intestinal epithelia (Hoffman et al., 2020; Wan et al., 2020; Wrapp et al., 2020) . Its ability to attach to these cell receptors in the intestinal tract supports the potential for fecal-oral transmission if the virus survives in the gut to then be fecally excreted. Details regarding infectivity of the SARS-CoV-2 may be found in the following references and also detailed in the WIDOC recommendations (Dhama et al., 2020; Maal-Bared et al., 2020; Prussin et al., 2020; Rodriguez-Lazaro et al., 2012; Lamers et al., 2020) . It is noteworthy that since the onset of the outbreak in December 2019, only seven studies have reported the presence of infective (replication-capable) SARS-CoV-2 in feces at the time of submission of this article Wang et al., 2020; Xiao et al., 2020a; Xiao et al., 2020b; Jeong et al., 2020; Kim et al., 2020; Yao et al., 2020) . Xiao et al. Other studies detected virus infectivity by experimental infection of ferrets with stool supernatant (Jeong et al., 2020; Kim et al., 2020) , and visual observation of virus replication and growth in tissue by electron microscopy. Jeong et al. (2020) was unable to detect SARS-CoV-2 in VERO cells but the culture negative fecal samples were used to successfully infect ferrets with SARS-CoV-2, bringing into question the efficacy of some of the current cell culturing methods.There is evidence that antiviral agents in the lower intestine rapidly inactivate most of the infectious virus that may be present from replication in the small intestine (Zang et al., 2020) .Recent laboratory and clinical study documents that new viruses released into the intestinal lumen are rapidly inactivated by human colonic (gut) fluids, resulting in no infectious virus recoverable from the stool specimens of COVID-19 patients (Zang et al., 2020) . Further consideration of these studies along with an overview of the impact of SARS-CoV-2 on WRRF and the water industry in general is summarized by various authors (Carducci et al., 2020; Jones et al., 2020; Patel et al., 2020; Collivignarelli et al., 2020; Elsamadony et al., 2021; Maal-Bared et al., 2020; Foladori et al., 2020; Kataki et al., 2021) .It is noteworthy that there is currently little epidemiological or virological evidence that SARS-CoV-2 is transmitted by the fecal-oral route. A documented incident occurred for the SARS-1 coronavirus in Hong Kong in the Amoy Gardens complex, where possible evidence of airborne exposure to the virus in entrained fecal particles was suggested as the source of transmission due to faulty wastewater piping in a building (Brown, 2020) . Both the World Health Organization (WHO) and further studies have indicated airborne transmission of viruses was J o u r n a l P r e -p r o o f likely but did not present conclusive evidence linking the airborne transmission to feces (WHO, 2003; Yu et al., 2014; Yu et al., 2004) . A recent report suggests that SARS-CoV-2 in airborne human wastewater may have caused 9 COVID-19 in cases among 3 families in a highrise apartment building in a Chinese city (Kang et al., 2020) . populations and has been used to support rapid public health response to prevent outbreaks (Polo et al., 2020; Betancourt et al., 2020) . Previous studies also have also reported SARS-CoV-1 (Bibby and Peccia, 2013) and now SARS-CoV-2 RNA in untreated wastewater sludge and Class B biosolids as recent efforts to also monitor SARS-CoV-2 RNA in WRRF sludge (Balboa et al., 2020; D'Aoust et al., 2020) . Again, these assessments were performed by nucleic acid (genetic) analysis and do not indicate infectivity of the virus genetic material detected.While enveloped viruses, such as coronaviruses are expected to be susceptible to disinfection and environmental stressors, the shedding of SARS-CoV-2 in various bodily secretions that are commonly released into the collection system in domestic wastewater have been reported, based on detecting virus RNA Peng et al., 2020; Zhang, Du et al., 2020) .These reports, along with the detection of high concentrations of SARS-CoV-2 RNA in wastewater, imply the potential presence of infective virus in untreated wastewater. So far, such presence of infectious in wastewater or biosolids has not been documented. Studies have reported that SARS-CoV-2 RNA has not been detected by molecular methods when analyzed in treated effluent (Rimoldi et al., 2020) . Thus, based on previous research on SARS-CoV-2 and other coronaviruses, the likelihood that Class B biosolids will contain infective J o u r n a l P r e -p r o o f SARS-CoV-2 seems low (Wolff et al., 2005) Microbial Risk Assessments can be conducted. However, concentrations in Class B biosolids of enteric viruses, which are more resistant to treatment than SARS-CoV-2, after mesophilic anaerobic digestion have been reported to range between 10 1 and 10 4 MPN/gram (Wong et al., 2010) , which emphasizes the need for worker infection prevention and control, including PPE.Potential risk from pathogenic microorganisms associated with land application of biosolids varies based on the biosolids application method, the microbiological quality of the biosolids at the time of application, environmental factors, and the management of the application site (Yates et al., 2007) . While the quantitative dose-response relationship for SARS-CoV-2 is currently unknown, prior risk assessment models of bioaerosol transport indicate little risk to surrounding communities and workers at application sites. In fact, negligible risk was determined from aerosolized Coxsackievirus (an enterovirus) at estimated distances of 10,000 m from the site and a 3% risk was estimated to workers on site (2 m/s wind, 1 hour of exposure) (Dowd et al., 2000) . It is also of note that these models tend to overestimate actual risk to populations by the nature of their design. From the limited evidence of viruses found in aerosols, even with variations in application methods, there is no indication of enteric viruses found further than 5 m from biosolids application areas (Brooks et al., 2004) . Westrell et al. (2004) reported the application of hazard analysis and critical control points along with quantitative microbial risk assessment tools to quantify risk to workers and communities surrounding land application sites (Class B, mesophilic anaerobically digested J o u r n a l P r e -p r o o f biosolids). They found the highest individual risk from a single exposure occurred via aerosols for workers at the belt press for dewatering (prior to Class B treatment) and overall risk was highest in the early processes, prior to exposures to stressors and use of disinfection as opposed to during land application (Westrell et al., 2004) .Class B biosolids are not likely a significant source of transmission for SARS-CoV-2 based on current evidence. Over the last 40 years, there have not been recorded infections due to viruses in Class B biosolids applications as noted by the National Research Council reports (NRC, 1996 and 2002) . Therefore, no supplementary measures are needed for protecting workers against SARS-CoV-2 beyond what is typically used when handling Class B biosolids. See CDC (2002) recommendations for additional details on these measures.It is of note that the vast majority of research related to virus presence and survival in biosolids, including research on the effectiveness of treatment, has been focused on nonenveloped viruses. As previously stated, non-enveloped viruses, such as polioviruses, other enteroviruses, adenoviruses and reoviruses are much more robust than enveloped viruses, such as the SARS-CoV-2. One study on these non-enveloped, primarily enteric viruses showed thermophilic digestion to be more effective than mesophilic anaerobic digestion (Wong et al., 2010) . Mesophilic anaerobically digested Class B biosolids further treated to Class A with heat pelletization (35° to 37°C for 10 to 20 days, dewatering, followed by a low-pressure oxidation drying system) and composting (agitated windrow method) resulted in even lower virus levels (Viau and Peccia, 2009) . Therefore, evidence documents that the risks of contracting COVID-19 from Class A biosolids are negligible. The virus itself is less stable than the enteric virus J o u r n a l P r e -p r o o f Journal Pre-proof surrogate utilized to get approval as disinfected Class A biosolids by the USEPA PEC (Wang et al., 2005) .Current prevention and control practices regarding the appropriate use of PPE when in potential contact with untreated wastewater and municipal sludge are considered to be effective, even in the vicinity of processes that create airborne droplets and aerosols. In In alignment with CDC (2002) , WHO (2020) , EU (2020) and OSHA (2020) recommendations, we recommend that workers and employers manage untreated residuals and sludge with potential or known SARS-CoV-2 contamination like any other untreated material. As noted by LeChevallier et al. (2019) there is a hierarchy of PPE and other prevention and control measures that follows the treatment through the WRRF. As material progresses through treatment, risk decreases. Contact transfer prevention PPE including gloves, boots, and uniform/coveralls should be utilized throughout WRRF operations, with the addition of safety glasses/goggles or face shields in areas with splash hazards. Overall, the use of typical engineering and administrative controls, safe work practices, and PPE when handling untreated wastewater, J o u r n a l P r e -p r o o f feces, and untreated municipal sludge to prevent worker exposure is important and considered necessary.In general, agencies should follow recommendations from OSHA (2020) and the state agency responsible for occupational health and safety in the USA and those of other worker health protection authorities in other countries. More specifically, the following recommendations should be highlighted during this time (Burton and Trout, 2009):1.As is current practice, remain mindful of the operation; take precautions to minimize the production of droplets and aerosols from feces and municipal sludge in the collections system and in the headworks of the WRRF. Wash hands often, carry disinfecting wipes and disinfecting gel to use anytime the operator touches surfaces that may have been exposed to liquids, droplets or aerosols. Switches, valves, and other surfaces exposed to aerosol from processes prior to complete biosolids treatment should be sanitized. Operators also should sanitize exposed surfaces prior to leaving an area to assure surfaces are as sanitary as possible and do not pose a hazard to other personnel.J o u r n a l P r e -p r o o f In summary, be aware of hazards. Wash hands frequently and especially before smoking, before drinking water or other beverages, before eating and applying cosmetics. Avoid hand contact with face and do not touch face with glove covered hands. Face coverings can help with protecting face from contact with gloves.Based on the evidence presented, there is no currently available epidemiological data that establishes a direct link between wastewater sludge or biosolids and risk of infection from the Attempts to quantify the risks from this virus in wastewater and biosolids are hampered by the lack of evidence for infectious virus in wastewater or biosolids and also the lack of any quantitative data on infectivity dose-response for this virus. So, any formal risk assessment would be based on huge assumptions for these variables that are probably not scientifically justifiable. Therefore, we are left with the need to estimate risk based on other sources of data, such as epidemiological data which indicates to date that this is not a virus for which fecal Final product contains < 2,000,000 fecal coliforms/g Final product contains < 1000 fecal coliforms or < 3 Salmonella sp./4 g; < 1 pfu/4g of enteroviruses and < 1 helminth ova/ 4g *Detailed information on demonstrating equivalency can be found at https://www.epa.gov/biosolids/pathogen-equivalency-committee.J o u r n a l P r e -p r o o f (Feachem et al., 1980; Shuval and Fattal, 2003; Metcalf and Eddy, 2014) It can be called Night Soil, Septage or Human Feces; without treatment, the infectivity of most viruses present in feces decreases by half within the range of 7 days to 6 months (Reimers et al. 2001; Madeley, 1979) Enteroviruses: 10 4 -10 7Hep A virus: 10 6 SARS: 10 6.1 (Shuval and Fattal, 2003 ) (Shuval and Fattal, 2003) ( J o u r n a l P r e -p r o o f Journal Pre-proof J o u r n a l P r e -p r o o f Figure 1 ",United States,abstract,2021-02-08,02
17c0f868d769557b3c7576325347153bc5fe7b56,,"Implementation of community mitigation measures such as stay-athome orders to slow the spread of SARS-CoV-2, the virus that causes the 2019 novel coronavirus disease , has been widespread in the United States (Gostin and Wiley, 2020) . Collateral consequences of these mitigation measures (e.g., economic stress, social isolation), coupled with fear of virus transmission, have raised concerns about worsening mental health and substance use-related harms such as opioid use disorder and overdose (Henry et al., 2020; Volkow, 2020) . A recent survey found that 1-in-7 U.S. adults reported serious psychological distress in April 2020, during peak use of community mitigation measures (McGinty et al., 2020) . A subsequent survey of adults in the U.S. reported that 13.3 % of adults had started or increased substance use to cope with pandemic-related stress or emotions, 30.9 % had symptoms of anxiety or depressive disorders, 26.3 % had symptoms of a trauma and stress-related disorder, and 10.7 % had seriously considered suicide in the past 30 days (Czeisler et al., 2020) . In addition, emerging data indicate that drug overdoses have increased during the same time period as peak community mitigation measures (Alter and Yeager, 2020) .Further, as a result of community mitigation measures, access to medical treatment, including medications used to treat opioid use disorder, opioid overdose, and mental health conditions, may have been limited due to clinician office closures, discontinuation of in-person treatment and recovery support services, and delays in seeking care due to concerns about exposure to COVID-19 during medical visits (Henry et al., 2020; Volkow, 2020) . Analysis of pharmacy dispensing data is one approach to examine if access to medications changed during community mitigation measures; yet, to date, such analyses are lacking. To address this research gap, this study used nationally representative data to assess dispensing patterns of selected substance use and mental health medications from January 2019 through May 2020 in the United States.In this time series analysis, data from the IQVIA Total Patient Tracker database, which captures 92 % of prescriptions dispensed from U.S. retail pharmacies, were used to calculate the number of unique patients (all ages) dispensed the following medications by month from January 2019 to May 2020: medications for opioid use disorder treatment, buprenorphine (single entity and buprenorphine-naloxone combinations), extended-release (ER) intramuscular naltrexone; the overdosereversal medication naloxone, including those issued under a standing order in retail pharmacies; selective serotonin reuptake inhibitor or serotonin-norepinephrine reuptake inhibitor antidepressants; benzodiazepines; and for comparison purposes, two chronic disease medications, HMG-CoA reductase inhibitors (statins) used in the treatment of hyperlipidemia and angiotensin receptor blockers (ARBs) used in the treatment of hypertension and other cardiovascular conditions. Buprenorphine formulations approved for the treatment of pain (i.e., Butrans, Belbuca, Buprenex) were excluded from the analysis. In addition, oral naltrexone formulations were not included as they are not generally recommended in the treatment of opioid use disorder (American Society of Addiction Medicine, 2020; Substance Use and Mental Health Services Administration, 2020a).To assess changes in the number of unique patients dispensed medications during the time of COVID-19 mitigation measures, March 2020 to May 2020, we used the exponential triple smoothing statistical forecasting function in Microsoft Excel (Seattle, Washington) to generate monthly forecasted estimates and 95 % confidence intervals (CIs) for each drug or drug class examined. This statistical forecasting method predicts future values based on historical data by utilizing the additive error, additive trend, and additive seasonality (AAA) exponential triple smoothing algorithm; a method well suited for data with seasonality or other cyclical patterns over time (Microsoft, 2015; Makridakis et al., 1998) . Once forecasted estimates and 95 % CIs were estimated, we then compared the forecasted estimates with the actual number of unique patients dispensed each medication by month for March 2020 to May 2020. The actual number of unique patients dispensed the medication were considered statistically significantly different than forecasted estimates if the actual number of unique patients in a particular month fell outside the forecasted estimates and associated 95 % CIs. When this occurred, the actual number of unique patients dispensed the medication was considered to be higher or lower than what would have been expected based on prior trends in the data for that medication. All analyses were conducted with Microsoft Excel (Seattle, Washington) and Stata V15.1 (College Station, Texas). This study was a secondary analysis of de-identified data and was therefore exempt from institutional review board approval.From January 2019 to February 2020, the monthly number of unique patients dispensed antidepressants (mean = 13,888,901 [SD = 337,357]; range = 12,696,855 to 13,844,201) as well as benzodiazepines (mean = 4,781,043 [SD = 166,850]; range = 4,478,448 to 5,011,279) was relatively stable; however in March 2020, the number of unique patients dispensed antidepressants (14,330,662) and benzodiazepines (5,128,721) was statistically significantly higher than forecasted estimates (Fig. 1) . In March 2020, an estimated additional 977,063 (95 % CI: 351,384 to 1,602,743) unique patients and 450,074 (95 % CI:189,999 to 710,149) unique patients were dispensed antidepressants and benzodiazepines, respectively, compared to forecasted estimates. The numbers of unique patients dispensed antidepressants and benzodiazepines in April 2020 and May 2020 were within forecasted estimates. The patterns of dispensing in March 2020 to May 2020 for the two comparison chronic disease medications, statins and ARBs, were similar to those for antidepressants and benzodiazepines during this time.The number of unique patients dispensed buprenorphine products approved to treat opioid use disorder increased from 713,778 in January 2019 to 814,019 in May 2020 ( Fig. 2A) . Between March 2020 to May 2020, the number of unique patients dispensed buprenorphine products was within forecasted estimates. The number of unique patients dispensed ER intramuscular naltrexone fell statistically significantly below forecasted estimates in each month, March 2020 to May 2020. In March 2020, an estimated -1039 (95 % CI: -1528 to -550) fewer patients were dispensed ER intramuscular naltrexone compared to forecasted estimates, followed by -2139 (95 %CI: -2629 to -1650) fewer patients in April 2020, and -2498 (95 % CI: -2987 to -2009) fewer patients in May 2020 (Fig. 2B ). The numbers of unique patients dispensed naloxone fluctuated during the study period (mean = 73,573 [SD = 3768]; range 67,294 to 81,323) but were within forecasted estimates for March 2020 to May 2020.Emerging research suggests indicators of mental health, substance use, and overdose have worsened during the peak of COVID-19 community mitigation measures in the U.S. (McGinty et al., 2020; Alter and Yeager, 2020) . Our findings show the number of unique patients dispensed medications used to treat anxiety, depression, and other chronic diseases increased above forecasted levels in March 2020, potentially reflecting public health recommendations to increase medication supplies on hand (Centers for Disease Control and Prevention, 2020), and were within forecasted levels in April 2020 and May 2020.The number of unique patients dispensed buprenorphine products indicated for opioid use disorder treatment and naloxone for overdose reversal did not experience a similar increase in March 2020 and were within forecasted estimates for March 2020 to May 2020. In contrast, during March 2020 to May 2020, the number of unique patients dispensed ER intramuscular naltrexone was significantly lower than forecasted estimates each month, suggesting patients may have experienced difficulties obtaining this medication, possibly due to healthcare provider office closures and the need for a healthcare provider to administer the medication.During the COVID-19 pandemic, a number of steps have been taken at the federal, state, and local levels to facilitate continued access to medications for substance use and mental health treatment, including deeming pharmacies essential services during stay-at-home orders (Cybersecurity and Infrastructure Security Agency, 2020), expanding the use of and increasing reimbursement for telemedicine (Centers for Medicare and Medicaid Services, 2020), allowing the remote prescribing of buprenorphine for new patients without first conducting an in-person physical examination (Drug Enforcement Administration, 2020), and relaxing policies related to take-home medications for opioid use disorder treatment from opioid treatment programs (Substance Abuse and Mental Health Services Administration, 2020b). Although our analysis did not specifically examine the impacts of these policies, our findings suggest that, with the exception of ER intramuscular naltrexone, there was not a significant drop in dispensing of several critical substance use and mental health medications, suggesting that steps taken to date may have facilitated continued access to medications. However, given data suggesting worsening mental health (McGinty et al., 2020) and increases in overdoses (Alter and Yeager, 2020) during the study timeframe, it is also possible that our lack of finding a significant increase in dispensing of buprenorphine for OUD treatment and naloxone for overdose reversal reflects challenges in accessing care and treatment for OUD and harm reduction interventions during the time of community mitigation measures. Future research should assess specific policy changes related to mental health and substance use treatment implemented during COVID-19, including differential impacts on continuity of care for people already receiving treatment prior to COVID-19 and access and ability to receive care among those that sought incident treatment during COVID-19 community mitigation measures, in order to better characterize their intended and potential unintended consequences.This study is subject to limitations. First, our data do not include information on whether prescriptions were used by patients, the patient- Source: IQVIA Total Patient Tracker *Prescription dispensing amounts that fell above or below the 95 % CI are considered statistically significant specific clinical indication for the medication, or whether these were new prescriptions or refills. Second, sociodemographic characteristics that could affect treatment access were not included in the data. Third, although our data reflect unique patients receiving medications at given points in time, we were not able to examine individual patients over time. Fourth, naloxone administered by emergency medical services personnel or first responders and naloxone distributed by communitybased organizations outside of retail pharmacies are not included in the IQVIA data used in this study. Fifth, our data did not include geographic identifiers; thus we were not able to assess differential impacts on unique patients dispensed medications across geographic areas. Finally, we were not able to assess use of non-medication-based treatments for mental health or substance use conditions or receipt of medications outside of U.S. retail pharmacies, including methadone for opioid use disorder treatment provided through opioid treatment programs as well as extended-release naltrexone provided through clinician offices.This study is the first to provide national estimates of access to select addiction, overdose reversal, and mental health medications during the COVID-19 pandemic and time of peak community mitigation measures. Importantly, we found that prescription dispensing for most medications examined fell above or within forecasted levels. However, ongoing concerns about the prolonged effects of the COVID-19 pandemic and related stressors on mental health and substance use (Henry et al., 2020; McGinty et al., 2020; Alter and Yeager, 2020; Volkow, 2020) underscore the importance of implementing innovative strategies to facilitate continued access to treatment, recovery, and harm reduction services.The findings and conclusions in this report are those of the authors and do not necessarily represent the official position of the Centers for Disease Control and Prevention/the Agency for Toxic Substances and Disease Registry.Drs. Jones and Guy conceived of the study. Drs. Jones and Guy conducted the data analysis and Dr. Jones drafted the manuscript. Drs. Guy and Board provided critical review and revisions to the manuscript.(caption on next column) Fig. 2 . A/B/C. Number of Unique Patients Dispensed Buprenorphine, Extended-Release Naltrexone, and Naloxone, United States, January 2019 -May 2020*. A. Number of Unique Patients Dispensed Buprenorphine Source: IQVIA Total Patient Tracker CI = Confidence Interval *Prescription dispensing amounts that fell above or below the 95 % CI are considered statistically significant B. Number of Unique Patients Dispensed Extended-release (ER) Intramuscular Naltrexone* Source: IQVIA Total Patient Tracker ER = Extended-Release CI = Confidence Interval *Prescription dispensing amounts that fell above or below the 95 % CI are considered statistically significant C. Number of Unique Patients Dispensed Naloxone* Source: IQVIA Total Patient Tracker CI = Confidence Interval *Prescription dispensing amounts that fell above or below the 95 % CI are considered statistically significant",United States,first author,2021-02-01,02
caa0b32c442706f3c33056d8dbfa245bb181ece1,The spread of COVID-19 increases with individual mobility and depends on political leaning,"In lieu of innovation and pharmaceutical solutions to limit the spread of COVID-19, human behavior-based interventions have been deemed critical to curtailing the spread of the pandemic. Such interventions rely on promoting physical distance between individuals and reducing group gatherings 1,2 . However, adherence to distancing behavior has varied significantly across individuals in the United States. Because of the major divide in the public rhetoric in describing the pandemic, individuals in different states, or with different political beliefs, may experience the risks of the pandemic in strikingly different ways. Here, we tested whether county-level political leaning is associated with social-distancing behavior and the growth rate of COVID-19 cases.In the U.S., local, state, and federal agencies have imposed orders mandating varying degrees of social distancing 3 . For example, these policies have included restrictions in workplace practices, public gatherings, and travel. Recent research has shown that differences in the speed and magnitude at which policies are imposed or relaxed by governments can influence the spread of COVID-19 and impact the economy [4] [5] [6] In some states, however, these orders and policies have also been complemented with efforts to communicate the severity of the pandemic and persuade citizens to adapt their behavior. For instance, NY state officials have used televised briefings, which have been watched by millions, to inform citizens on the dangers of COVID-19 7 , whereas other state officials, such as in FL, have consistently downplayed the severity of the pandemic 8 . A more in-depth evaluation of the epidemic process requires a deeper understanding of how government policies, as well as efforts to engage with citizens, may ultimately influence human behavior 9, 10 . Indeed these strategies (i.e., mandates, direct communications from officials) are deeply interrelated because the success of the policies in reducing the spread of COVID-19 is likely to depend on the degree to which individuals comply with the mandates and social norms. After all, in the view of many U.S. public officials, it would not be possible to enforce compliance with all social distancing orders.We investigated whether variables related to the political leaning of individuals influenced the growth rate of the COVID-19 cases. We used open data from several sources, such as the University of Maryland's COVID-19 Impact Analysis Platform 11 and Massachusetts Institute of Technology's Election Data and Science Lab 12 ) to investigate how individuals' mobility behavior changed in response to the pandemic and distancing orders implemented by the U.S. government. The UMD data contains a number of county-level metrics. We utilize the cumulative total number of COVID-19 cases to calculate the COVID-19 case growth rate and the social distancing index to construct a measure of individual mobility. The data is at the county-day level, and we utilize data from January 1, 2020, to June 20, 2020. The MIT data contains county-level voting results from the 2016 presidential election. Combining these two datasets allows us to investigate three relationships. First, increased levels of individual mobility are associated with high levels of COVID-19 case growth rates. Second, in early 2020, there was generally no relationship between political leaning and individual mobility, but a strong positive relationship developed in mid-March. Finally, there is an association between political leaning and the differentiation in the COVID-19 growth rates before and after Trump's March 11, 2020 announcement of travel restrictions to the U.S., which we refer to as the national travel ban. The results can inform researchers about currently underutilized variables that may improve models of spreading of the pandemic 9 .A substantial amount of scientific evidence has used spreading models 9 to predict the impact of government policies to reduce mobility on the extent and effects of the COVID-19 pandemic 13, 14 . For example, using these models, it has been shown that the effective implementation of social distancing policies is associated with reductions in the growth rate of COVID-19 cases, with an average reduction ranging from 3.0% during the early onset days of social distancing measures to 8.6% in the later days 15 . The variability in compliance with social distancing policies across the U.S. has not been reported yet.Reduction in individual mobility contributes to controlling the spread of the pandemic The U.S. county-level data from the UMC19 dataset was used for all analyses 11 . We used linear regression to estimate the COVID-19 case growth rate in each county across the U.S. as a function of individual mobility. In particular, we estimated the following specification: cumulative number of COVID-19 cases to account for issues when is zero, which would make the log cc it undefined. To compute individual mobility, we reversed the social distancing index in the UMC19 data: individual mobility = 100 -social distancing index. An individual mobility score of zero essentially means that all the residents in a county are staying home, and no non-residents are entering the county, while an individual mobility score of 100 means that there is no social distancing in the county.is a set of county-level fixed α i effects that control for any time-invariant characteristics of a county, and is a set of date-level fixed effects δ t that control for any characteristics that impact all counties on a given day. The coefficient is of particular b interest as it quantifies the relationship between COVID-19 growth rates on a given day and the 14-day lagged individual mobility across all counties and days, controlling for county and time effects. The term represents e it residual error. The errors were clustered at the state level to allow for arbitrary correlation across counties and days within a state and heteroscedastic error variances across states.The results show an aggregate association between the COVID-19 case growth rate and 14-day lagged individual mobility of 0.0015 (p-value < 0.001). In other words, for the United States as a whole, a one-point increase in individual mobility (out of 100) is associated with an increased COVID-19 cases growth rate of 0.15%. This result is consistent with findings of a relation between individual mobility and COVID-19 cases growth rate reported by Courtemanche et al. (2020) 15 .Whereas the results based on Eq. [1] demonstrate that, on average, there is a positive association between COVID-19 case growth rates and individual mobility, we also explored whether there are different associations for each county with the following specification:Eqwhere all variables are as described in Eq. [1] . The coefficient was of particular interest as it showed the b i relationship between COVID-19 growth rates and individual mobility for each county individually. The results from Eq. [2] show substantial variability in the association between individual mobility and COVID-19 cases growth rate across the U.S. counties ( Figure 1 ). For 66.6% of counties, the association was positive, indicating that increased individual mobility was associated with an increase in the COVID-19 growth rate. We restricted this to only coefficients, which had a p-value below 0.05 and found that 68.8% of those counties had a positive association. The associations varied greatly, with the range from -0.004 to 0.003. Put another way, while in New York County, New York a one-point increase in individual mobility (out of 100) is associated with an increased COVID-19 cases growth rate of 0.3%, in Dawson County, Nebraska that same one-point increase is associated with a decreased COVID-19 cases growth rate of 0.4%.After observing the profound variation in the association between individual mobility and COVID-19 cases growth rate, we were interested in understanding possible underlying causes for such variation. We set out to understand whether variations in political leaning across counties could account for part of the variance in the data. This was a plausible and particularly interesting question given the polarized state of American politics and to zero (white) using error clustering at the state level to allow for arbitrary correlations across counties (and days) within each state and heteroscedastic error variances across states 16 . The inset map shows in blue the counties with a positive association between individual mobility and COVID-19 cases growth rate, and in red the counties with a negative association. Counties lacking statistical significance are shown in white.correspondingly divided media reporting on the COVID-19 pandemic. Such a divide may have had an influence on individuals' responses to the national travel ban. In particular, we were interested in measuring whether individual mobility was associated with political leaning. Did individuals with different political leaning in the 2016 elections respond differently to the national travel ban?We estimated the association between individual mobility and the 2016 Trump margin (from the MITED dataset) across counties for each day from January 1, 2020 to June 20, 2020 ( Figure 2 ). The data shows that before the national travel ban of March 14, 2020, no association was measured between individuals' mobility and the 2016 Trump margin. Critically, after the national travel ban, the association quickly grew positive and remained strong through the end of June 2020. The results show that individuals with different political orientations behaved differently in response to the national travel ban. The association is well behaved, and it was found to be largely unrelated (0.057) with Trump's 2016 margin before the national travel ban ( left-hand panel ). In contrast, the association is strong (0.216) after the national travel ban ( right-hand panel ). We further looked at how these associations varied across the United States. Figure 3b reports the slope of the regression line measured across each state's counties. Consistent with the previous plot, no clear relationship between individual mobility was found before the national travel ban. In contrast, the state-wide association was strong after the travel ban. Critically, this association varied largely across states with a minimum of -0.029 in New Hampshire and a maximum of 0.345 in Nevada.Having shown a relationship between COVID-19 case growth rates and individual mobility and a relationship between individual mobility and Candidate Trump's 2016 margin, we then explored the association between COVID-19 case growth rates and Candidate Trump's 2016 margin. To do so, we predicted the difference in COVID-19 cases growth rate before and after the national travel ban:Eqwhere i indexes a county, B ( A ) indexes the period before (after) the travel ban, and is the COVID-19 case R G growth rate as detailed in Eq. [1] , and the bar indicates an average over the days in the before or after period.is the Trump margin in the 2016 election from the MITED dataset. Results show a positive association T i between Candidate Trump's 2016 margin and the difference in COVID-19 case growth rates before and after the national travel ban ( Figure 4 ).To further test the robustness of this finding, we performed a variation of the last regression (Eq. [4] ) by adding additional control variables (see Methods , Eq. [5] ). These variables included measures of population size, population density, education, urbanization level, poverty, employment, and income, as well as variables accounting for the five-year range for each county median age. Results show that the association between the change in COVID-19 case growth rate and Candidate Trump's margin was significant even after controlling for all these variables (t-test with 3,830 degrees of freedom; p-value < 0.001).is darker blue after the travel ban. The unprecedented gravity of the COVID-19 pandemic has mobilized governments for designing a series of ad-hoc policies that can limit citizens' individual mobility and freedom at multiple levels. Many of these policies involve limiting access to basic infrastructure, public offices, schools, and restrict access to travel 3 . In the U.S., over 90% of the adult population has had to change their lifestyle as a result of this pandemic 17 . Until scientists can produce a vaccine, we are left with behavioral remedies, such as limiting individual mobility, to reduce the impact of COVID-19.To truly understand how to limit the spread of the disease, it is vital to go beyond government mandates and policies 18 and capture the multifaceted factors that may influence human behavior and the response to policies. One factor of interest is the relationship between political leanings and social distancing behavior. Much like the severity and policies to the pandemic have varied across the U.S., individual compliance with social distancing policies also has also been observed to vary within the population across states and often along political lines. This geographical variation begs the question: are conservatives and liberals in the U.S. complying with the social distancing efforts to the same degree? These efforts include reductions in individual mobility and social activities perceived by many as a reduction to individual freedom. This line of reasoning was perhaps best expressed by the U.S. Surgeon General, the leading spokesperson on matters of public health of the U.S. federal government, ""Some feel face coverings infringe on their freedom of choice-but if more wear them, we will have more freedom to go out"" 19 . Indeed, a recent national poll reported that the percentage of Democrats who wore a mask all the time when leaving home was approximately 65% between May 8, 2020 and June 22, 2020 whereas the percentage of Republicans who wore masks was just 35% 20 .The divide in the current political environment in the United States may suggest that political leaning may play a role in shaping the response to social distancing prescriptions and indirectly affect the spread of COVID-19. First, the U.S. federal government has sent mixed signals throughout the pandemic 21 . The administration guidelines have asked Americans to reduce mobility and comply with local laws and wear masks in public spaces to slow the spread of the pandemic and yet, in most cases, President Trump does not wear masks in public 22 . Similar mixed signals have been reported by state and local officials 23 . Moreover, media coverage on the severity of the COVID-19 pandemic and addressing the need for social distancing has also varied widely along partisan lines. Indeed, U.S. citizens have been starkly divided on the perception of the severity of the pandemic since the beginning of the outbreak. Public discourse from top political leaders, as well as the diversity of opinions expressed by the media, might have played a role in this divide. For example, according to the Pew Research Center, in February 2020, 66% of Democratic-leaning citizens believed the news media coverage of COVID-19 was ""largely accurate,"" while only 31% of Republican-leaning citizens did 24 . This, along with comments in social media from prominent figures (i.e., President Trump), may explain why in early March, approximately 40% of Republicans were ""not at all concerned"" about an outbreak in their communities, whereas less than 5% of Democrats were in that category 25 . To make matters worse, U.S. citizens have also been prey to disinformation campaigns regarding COVID-19 from foreign actors, according to the U.S. Department of Defense 26 . All these elements taken together make the inclusion of political beliefs in disease growth models relevant, if not necessary.While limiting individual mobility is associated with reductions in the COVID-19 growth rate, we confirm that people are heterogeneous in the extent to which they adhere to the government policies and social norms, this is associated with varying levels of case growth rates. Furthermore, we demonstrate with county-level data that this association between growth rates and individual mobility is itself correlated with Candidate Trump's 2016 margin of victory. The result: a stronger Trump political leaning in your county is associated with higher COVID-19 growth rates. It is worth stating that due to the nature of the data (secondary), this does not imply a causal relationship.Understanding how political beliefs may be associated with particular behaviors is crucial for developing and evaluating policies to reduce mobility but also to reopen the economy as it is being attempted in most states. Our findings may be particularly relevant in certain rural regions that supported the President in 2016 and where the first wave of COVID-19 may have been delayed 27 . Carefully tracking case growth rates in these areas and pro-actively developing messaging that can influence and motivate human behavior in rural regions may be crucial to reducing the spread of COVID-19 in the coming months.University of Maryland COVID-19 data (UMC19). 11 URL to database: https://data.covid.umd.edu/ The data is updated daily and contains data from January 1, 2020, until a few days before the data was downloaded. The data we use for analysis was downloaded on June 24, 2020, and contains data from January 1, 2020, until June 20, 2020. We primarily use the county-level data restricted to only the continental United States (Alaska and Hawaii were excluded from all of the analyses because we encountered problems matching counties to the other datasets). More specifically, the columns used from the UMC19 dataset were: the county name, county-and state-level Federal Information Processing System (FIPS) codes, number of new COVID-19 cases, population, and population density. We adjust the population to be measured as a population in thousands by dividing the population by 1000. We create the individual mobility metric as 100 minus the social distancing index and the lag individual mobility metric as the individual mobility metric in a county but from two weeks (fourteen days) prior. In order to create the growth rate variable, we calculate the cumulative number of cases up to a given day. The case growth rate is then ln (cumulative cases today + 1)ln (cumulative cases yesterday + 1). We only use the state-level data to bring in the state name, which is not included in the county-level data. We merge the stateand county-level datasets based on the state FIPS code, which is present in both files.. 12 This data was downloaded on April 22, 2020. We use the candidate, candidate votes, total votes, year, and FIPS columns in this dataset. We exclude counties that do not have a FIPS code since they could not be merged with the UMD dataset. Examples include Uniformed and Overseas Citizens Absentee Voting Act (UOCAVA) in Maine, Rhode Island Federal Precinct, and Connecticut Statewide write-in. The data is limited to only 2016. The percent of votes for each candidate is calculated as 100 times the number of votes for that candidate divided by the total votes for all candidates. The Trump 2016 Margin is then the percent of votes for Trump in a county minus the percent of votes for Clinton in a county. The data is then merged with the UMD data based on the county FIPS code. Oglala Lakota County in South Dakota does not properly merge and is dropped from the analysis.Education Data (EdD). This data comes from the United States Department of Agriculture Economic Research Service Educational attainment for the U.S., States, and counties, 1970-2018 dataset available at https://www.ers.usda.gov/data-products/county-level-data-sets/download-data/ and was downloaded on April 22, 2020. The three measures of education are 1) percent of adults with only a high school diploma from 2014 to 2018, 2) percent of adults completing some college or associate degree from 2014 to 2018, and 3) percent of adults with a bachelor's degree or higher from 2014 to 2018. Excluded is the percent of adults with less than a high school diploma from 2014 to 2018, which serves as the baseline. We also use the county FIPS code for merging this dataset with others.Research Service Poverty estimates for the U.S., States, and counties, 2018 dataset available at https://www.ers.usda.gov/data-products/county-level-data-sets/download-data/ and was downloaded on April 22, 2020. The two measures of whether a county is urban or rural are 1) the rural-urban continuum code from 2013, and 2) the urban influence code from 2013. The three measures of poverty are 1) percent of people of all ages living in poverty in 2018, 2) percent of people ages zero to seventeen years living in poverty in 2018, and 3) percent of people ages five to seventeen years living in poverty in 2018. We also use the county FIPS code for merging this dataset with others.This data was collected from the United States Census Bureau Population Division Annual County Resident Population Estimates by Age, Sex, Race, and Hispanic Origin: April 1, 2010 to July 1, 2019 dataset available at https://www2.census.gov/programs-surveys/popest/datasets/2010-2019/counties/asrh/cc-est2019-alldata.csv and was downloaded on July 13, 2020. This dataset includes the number of people in each of eighteen different age groups. The first seventeen age groups are five years wide (zero to four years, five to nine years, etc.) and the final age group is 85 years or older. We use the data to calculate median age dummy variables. For each county, calculate the five-year range in which the median person's age falls. There are ten ranges that have at least one county's median age. We create a set of nine dummy variables that take the value of one if the county's median age is within that five-year range and zero otherwise. The first five-year range is used as the baseline. We also use the county FIPS code for merging this dataset with others.Employment Data (EmD) . This data comes from the United States Department of Agriculture Economic Research Service Unemployment and median household income for the U.S., States, and counties, 2000-18 dataset available at https://www.ers.usda.gov/data-products/county-level-data-sets/download-data/ and was downloaded on April 22, 2020. The measure of employment is the unemployment rate from 2018. The two measures of income are 1) the median household income from 2018, and 2) the median household income as a percent of the state total in 2018. We also use the county FIPS code for merging this dataset with others.Plot.ly county geojson (PCG). The PCG is a set of JSON files openly provided by Plot.ly©. The data allows the mapping of numerical values onto the U.S. map by county or state. This data was used only for visualization purposes ( Figures 1 and 3 ). The data is available at https://raw.githubusercontent.com/plotly/datasets/master/geojson-counties-fips.json .We used regression to map the COVID-19 cases growth rate of disease spread in each county across the U.S. In particular, we estimated the following specification: is the cumulative number of cc it COVID-19 cases on a given day, and is the cumulative number of COVID-19 cases on the day before the cc it−1 focal day.is the individual mobility metric from the UMC19 dataset described above from fourteen days M I (i,t−14) before the focal day.is a set of county-level fixed effects that control for any time-invariant characteristics of α i a county, is a set of date-level fixed effects that control for any characteristics that impact all counties on a δ t given day. The coefficient shows the relationship between the COVID-19 case growth rate and 14-day lagged b individual mobility on average across all counties and days. The errors are clustered at the state level to allow for arbitrary correlation across counties and days within a state and heteroscedastic error variances across states.We then modified Eq. [1] to allow for different coefficients for every county:Our primary interest lies in the coefficients that show the association between the 14-day lagged individual b i mobility and COVID-19 growth rates for each county . iWe performed a second linear regression to estimate the association between individual mobility, using U.S. county as fixed effects ( ), the date was also used as fixed effects ( ), and date fixed effects interacted with α i δ t the Trump 2016 margin:Eqwhere indexes a county and references a day, is the Trump margin in the 2016 election from the MITED i t T i dataset, and all over variables are the same as in Eq. [1] . Errors are clustered at the state level to allow for arbitrary state-level heteroskedasticity and correlated errors within states across all counties and all dates. The coefficients of the date fixed effect interacted with the Trump 2016 margin are then plotted along with their 95% confidence intervals. Figure 3a uses all county-days for Eq. [3] . Figure 3b runs Eq. [3] forty-eight times, one time per state (excluding D.C. because it only has one county as well as Alaska and Hawaii because of lack of data). In each of these runs, the data is limited to only the county-days in that state. where all variables are as previously defined. The regression was run once for the before period ( B ) and once for the after period ( A ). The bar indicates an average over the days in the before or after period. The scatter points are sized by the population and the line is the weighted least squares regression line.Finally, we repeated the above process individually for each state, i.e., using only the county-days for each state. The slope of the line in the weighted least squares regression was then used to color the state in the filled maps in Figure 3b .The line in Figure 4 was created from a weighted least squares regression:Eq.[4] e GR (i,A) − GR (i,B) = α + T i + i where the dependent variable was the change in COVID-19 case growth rate, the bar indicates an average over the days in the before or after period, the independent variable is the county-level Trump 2016 margin, and weights are based on the population in the county.We then modified Eq. [4] to include multiple control variables from four complementary datasets:Eq. ",United States,abstract,2021-02-04,02
32a2091a7522799eb738d249365999defd0d2299,Home Food Procurement Impacts Food Security and Diet Quality during COVID-19,"The COVID-19 pandemic has highlighted the uncertainty and fragility of food security and food access globally. In the United States, unemployment rates reached unprecedented levels at their height in April 2020, causing concerns among many Americans about how to access affordable and high-quality food [1] . Existing evidence suggests that home food procurement (i.e. backyard livestock, fishing, foraging, gardening, hunting, and canning, hereafter referred to as HFP) may offer opportunities to improve food security and diet quality (e.g. [2, 3] ). HFP activities have varying levels of participation in recent decades. While homesteading [4] and backyard livestock, especially chickens, have become more fashionable in recent years [5] , hunting has been declining for decades [6, 7] . However, since the COVID-19 pandemic began, there have been a number of stories from popular media outlets in the United States discussing a comeback of ""victory gardens"" in response to the pandemic [8, 9] , increased interest and demand for hunting and fishing [10] , and a shortage of canning supplies [11] . As well, previous research has found that depictions of wild food foraging in the media change in times of economic hardship from being discussed as more of a luxury to being conceptualized as a way to provide for basic needs [12] . Public discussion and interest around HFP practices seem to be shifting with COVID-19, but who is participating and what relationship do these activities have to food security and dietary outcomes? This study explores changes in HFP since the onset of the COVID-19 pandemic, and its relationship to food security and diet quality outcomes during the pandemic in a high-income country context.The potential for HFP to improve food security and dietary outcomes has links to other challenging times, including in historical moments such as World War 2. At that time, planting ""victory gardens"" were patriotic acts to grow local food amidst disrupted supply chains [13] . It is estimated that 40% of the nation's fruits and vegetables were produced via victory gardens during the war, demonstrating the potential for HFP to address food security challenges. But the current COVID-19 context has created new difficulties and significant increases in food insecurity in many countries, including the United States (e.g. [14, 15] ). Nevertheless, existing evidence suggests that HFP may positively affect both food security and dietary quality outcomes in high-income countries through multiple pathways.First, evidence suggests that growing your own food contributes directly toward food availability and access. Taylor & Lovell (2015) found that, while gardeners did not grow enough to sustain their families, ⅓ grew a substantial quantity and were self-sufficient in providing some items for a certain period of time during the growing season and almost all of these households said they always had enough to eat. Corrigan's (2011) [16] interviews of five gardeners in Baltimore found that most perceived that they saved money from their gardens and that it allowed them to grow quality, fresh produce that otherwise may not have been accessible. They also found that many gardeners canned or froze their excess produce, allowing them access to these foods into the winter. These results may also translate beyond gardening to other food procurement practices, although research is even more limited in these areas. Smith et al. (2019) [17] found that participants from one reservation who participated in the Food Distribution Program on Indian Reservations who also so hunted, fishes, or foraged were more food secure than those who did not. Additionally, those who engaged in more than one practice were more secure than those who did only one. A survey of Canadian Inuit also found that households with an active hunter were more food secure than those without an active hunter [18] . Cooke et al. (2018) [19] found that many anglers in the United States often consume what they catch, with an average of 4,700 grams of edible fish provided through fishing annually, even if their original motivation for fishing is recreation. As well, African American anglers are more likely to consider fishing important for providing food [20] and more likely to keep fish that they have caught [21] , though these studies did not examine food security outcomes. This direct food procurement may also lead to cost savings realized by not purchasing food, which enable money to be available for the purchase of other foods, or for other financial priorities.Realized cost savings from HFP may be another factor linking HFP to better food security outcomes. Perceived cost savings does appear to be a common motivation for those producing their own food [17, 22] and there have been a number of studies suggesting that this may in fact be the case [2, 3, 23, 24] . Home gardeners in San Jose reported that cost savings of gardening allowed them to eat produce they otherwise would not have had access to [25] . However, many studies looking at cost savings were analyzing the results of nonprofit programs in which gardeners were supported with resources to help set up their gardens, and therefore had a smaller up-front investment, which could have impacts on food security outcomes. Csortan et al. (2020) [26] found that 65% of gardeners would break even on garden investments in five years or less and then start saving money. In such a case, gardening would not be a sufficient means for achieving food security in the shortterm in response to an economic crisis. They also found that the number of years of gardening experience appeared to have a positive impact on productivity and resource efficiency, leading to additional concerns for new gardeners [26] .In addition to the potential for cost savings and increased food security, HFP may lead to a higher quality, more diverse diet, including one that may be more culturally appropriate [27, 28] . Growing one's own produce is linked to increased fruit and vegetable intake [3, 25, [29] [30] [31] . Hunting, fishing, and foraging may also lead to a more nutritious and diverse diet; for example, 80% of people surveyed on a native reservation said that hunting, fishing, and foraging made their diets more diverse and 72% said these practices improved the quality of their diet [17] . Stark et al. (2019) [32] found that wild edible greens were abundant in three low-income neighborhoods in California, and offered potential nutrient density comparable to some common nutritious vegetables, such as kale. Some research suggests that growing one's own food may also lead to improved nutritional knowledge [33, 34] and changes in eating habits for the long-term [24, 34, 35] . This may also be true of children, who are more likely to try vegetables when they garden [36] .The data were collected using a survey instrument developed initially in March 2020 [44] , in collaboration with other researchers as part of the National Food Access and COVID research Team (NFACT) [45] . The survey was further refined [46] , with the later forming the basis for this data collection. The survey measures multiple components of food access, food security, dietary quality, home food procurement, COVID-19 experiences and food assistance program participation as well as individual and household sociodemographics. Institutional Review Board approval was obtained from The University of Vermont (IRB protocol 00000873) prior to any data collection. The survey utilizes validated measurements when possible (Table 1) , and was also validated prior to release of Version 1 in Vermont with 25 eligible (18 and over) respondents using Cronbach alpha and factor analysis [14] . All question sets obtained an internal validity of alpha > 0.70 [47, 48] .Participants were recruited through an online survey administered by Qualitrics (Provo, UT), using a general population sample representative to the state of Vermont with respect to income, race and ethnicity. This sample was achieved by matching sample recruitment quotas to the income, race (White, Black or African American, American Indian and Alaska Native, Asian, Native Hawaiian or Other Pacific Islander, and Two or more races), and ethnicity (Hispanic, non-Hispanic) population profile of Vermont in the American Community Survey [49] . A total of 600 people ages 18 and over responded to the survey, representing a margin of error (95% confidence level) for this segment of the Vermont population of +/-4% [50] . The survey was administered in August and September 2020.We explore three self-reported dependent variables in this analysis (Table 1) . First, food security status, as measured through the US Department of Agriculture 6-item short-form food security module [51] where food insecurity is classified as answering affirmatively to two or more out of six questions. This was modified to ask respondents about food security since COVID-19 (approximately five months at the time of the survey) rather than the traditional 12-month period. Second, current fruit and vegetable intake was measured through the National Cancer Institute's 2item screener [52] , which was modified to apply to the last month and some example foods were removed to shorten it. Current red and processed meat intake was measured using two questions from the Dietary Screener Questionnaire in the National Health and Nutrition Examination Survey (NHANES) 2009-10. Finally, we developed new questions to measure perceived change in fruit/vegetable, red meat, and processed meat consumption since the onset of the COVID-19 pandemic. Independent variables included multiple questions related to previous and current HFP, specific HFP activities, and changes in HFP activities during the COVID-19 pandemic, as well as several household and individual-level demographics (Table 1) .Binary variable (1=more intense HFP, 0=no change in activity, or pursued less this year)Any respondent that indicated they pursued gardening ""for the first time this year"", or ""I have previously done this, but did it more this year"" 1=More intense or new, 0=same or less than before Fishing More Any respondent that indicated they pursued fishing ""for the first time this year"", or ""I have previously done this, but did it more this year"" Foraging More Any respondent that indicated they pursued foraging ""for the first time this year"", or ""I have previously done this, but did it more this year""Hunting More Any respondent that indicated they pursued hunting ""for the first time this year"", or ""I have previously done this, but did it more this year""Livestock MoreAny respondent that indicated they pursued backyard livestock ""for the first time this year"", or ""I have previously done this, but did it more this year""Canning MoreAny respondent that indicated they pursued canning ""for the first time this year"", or ""I have previously done this, but did it more this year"" * We would like to acknowledge we aggregate this data because of the low number of respondents identifying as BIPOC and/or Hispanic. While this survey is representative of Vermont state characteristics on race and ethnicity, the sample size is too low to analyze racial and ethnic groups in a disaggregated format in models.We have disaggregated race and ethnicity in reporting food security statistics in the results, but aggregate race and ethnicity together for modeling and matching.Matching techniques are useful with observational data to estimate causal effects of treated and control groups, aiming to balance the distribution of covariates across treated and control groups [53] . Here we explore how AHFP, intensity of HFP, or specific HFP activities are ""treatments"" on food security and diet quality, using demographic factors as matching covariates across groups. We use six demographic covariates in our matching analysis: female, children in household (HH), race/ethnicity (Black, Indigenous, People of Color (BIPOC)/and or Hispanic), negative job change, household income less than $50,000 (less $50k), and HH size (Table 1) , which are likely to be associated with the treatment and outcome [54, 55] . Matching techniques also require defining a distance (measure of similarity between the individuals). We use a nearest neighbor matching approach with a Mahalanobis distance, which accounts for covariance among variables, and is documented to work well with fewer than eight covariates [56, 57] . For each treated individual, nearest neighbor matching selects a control individual with the smallest distance from that individual. For example, if we are exploring AHFP, the technique would have people who did and did not engage in AHFP as ""treatment"" and control groups, and then match a treatment and control respondent together based on similar demographic covariates included in the analysis (e.g. household size and job change status). In all our models we use nearest neighbor matching with five matches per observation, meaning each observation was matched with five closest other observations within the control and treatment groups. Table 2 details the specific respondent characteristics, which reflect the demographic composition of the Vermont population for the gender, race, and income distribution. Overall, 67.3% of the respondents were female (std. dev= 0.47), and 30.2% of respondents had children in the household (std. dev= 0.46). Forty-four percent of respondents were age 55 years or older. Reflecting the racial/ethnic profile of Vermont, 8.3% of respondents identified as BIPOC and/or Hispanic ethnicity (std. dev= 0.28). More than 46% of respondents lived in a household that had experienced a negative job change during the first five months of the COVID-19 pandemic (job loss, loss of income or hours from job, or furlough) (std. dev=0.50). Household size was on average 2.57 (std. dev= 1.34), with 60.2% of households 2 or fewer people.Among all respondents, 42.1% (n=250) engaged in AHFP activity during the first six months of the COVID-19 pandemic, with the greatest number of respondents gardening (34.7%), followed by canning (23.5%) and fishing (10.2%) (Figure 1 ). Among only respondents who engaged in AHFP, 51.8% (n=128) did at least one HFP activity more intensely since the COVID-19 pandemic began or for the first time this year, with the greatest increase in intensity of activity among backyard livestock (52%, n=26), gardening (45.3%, n=106), and foraging (44.9%, n=31). On average, respondents self-reported they ate between 1-2 cups cumulatively of fruit (mean=2.20) and vegetables (mean=2.74) per day, though 11% and 5% of respondents ate no fruit or vegetables respectively daily. Respondents self-reported they ate red meat (mean=3.34) and processed meat (mean=3.15) about one time per week, with 10% each indicating they never eat red or processed meat. Nearly one in four (23.3%) respondents indicated eating less fruits and vegetables during the pandemic as compared to before, 65.5% reported eating the same as before COVID-19, and 11.2% reported eating more. Changes in red and/or processed meat consumption were also indicated by about one-third of respondents, with 25.9% eating less red and/or processed meat since the start of the COVID-19 pandemic, and 7.9% eating more.Using a matching approach, to examine the effect of AHFP on household food security we find a weak negative association between AHFP and food security (b=-0.070, p=0.059), while controlling for gender, children in the household, negative job change, income, race/ethnicity, and household size. Exploring the effect of specific HFP activities during the pandemic on food security outcomes, we find that fishing (b=-0.133, p=0.038), foraging (b=-0.173, p=0.025), hunting (b=-0.264, p=0.021), and canning (b=-0.100, p=0.017) are all negatively associated with food security (Table  5 ). We also find through chi-square analysis, significant associations between food security and intensity of HFP since the COVID-19 pandemic began, with 66.2% of food insecure households increasing intensity of HFP since the COVID-19 pandemic began, compared to 44.4% of food secure households (p=0.002). Food insecure households were also more likely to be gardening (p=0.005), fishing (p=0.025), foraging (p=0.040), and hunting (p=0.003) more intensely than before the COVID-19 pandemic as compared to food secure households ( Figure 2 ). These results are confirmed by matching analysis, controlling for demographics (p<0.05, Table 5 ).(mean=3.06 compared to 3.21, p=0.309). Using matching techniques, with demographic controls, we examine current fruit, vegetable, red meat and processed meat intake as it relates to AHFP, increased HFP, and relevant specific HFP activities (i.e. gardening, foraging and canning for fruit and vegetable intake and fishing, hunting and backyard livestock for red and processed meat intake). We find the ""treatment"" of AHFP to have a significant and positive relationship to higher fruit (b=0.386, p=0.001) and vegetable intake (b=0.526, p<0.001). Furthermore, we find that gardening and canning since the COVID-19 pandemic began have significant effects on higher current intake of fruits (gardening b= 0.329, p=0.006; canning b=0.240, p=0.071) and vegetables (gardening b=0.541,p <0.001; canning b= 0.511, p<0.001) ( Supplementary Tables 10 and 11 ). We find no significant effect of AHFP or increased intensity of HFP on current red meat or processed meat intake; however, we do find a significant effect of hunting (b=0.527, p=0.032) and backyard livestock (b=0.794, p=0.001) since the start of the COVID-19 pandemic on current red meat intake, with higher red meat intake among those engaged with hunting and/or backyard livestock production ( Supplementary Tables 14 and 15 ). We use chi-square tests to examine the change in dietary quality outcomes since the COVID-19 pandemic began as it relates to AHFP, specific HFP activities and intensity of HFP. We find households engaging in AHFP have a higher proportion of respondents with increased fruit and vegetable intake (14.8% compared to 8.4%, p=0.051), while those engaging in AHFP have both a higher proportion of respondents eating less red meat (29.2% compared to 23.3%) and a slightly higher proportion of respondents eating more red meat (9.6% compared to 6.7%, p=0.079). Using matching techniques, with demographic controls, we examine change in fruit/vegetable and red/processed meat intake as it relates to AHFP, increased HFP, and relevant specific HFP activities (i.e. gardening, foraging and canning for fruit and vegetable intake and fishing, hunting and backyard livestock for red meat intake). We find no significant effects of AHFP, increased intensity, or specific HFP activities on change in fruit and vegetable intake since the start of the COVID-19 pandemic. We do find that increased intensity of hunting is negatively associated with meat intake since the COVID-19 pandemic began, suggesting that those hunting more, or for the first time during the pandemic are eating less red meat.Overall, we find a significant increase in HFP since the beginning of the COVID-19 pandemic, evidence that has been documented in the popular media, but not yet widely shown through peerreviewed literature. Those engaging in AHFP were more likely to be in low-income households and those with negative job changes, and increased intensity was more likely among those with negative job changes, BIPOC/Hispanic respondents, and larger households. Importantly, food insecure households were more likely to be using AHFP, and especially more likely to have increased intensity of HFP during the pandemic. While we find that nearly 25% are eating less fruits and vegetables since before the onset of the COVID-19 pandemic, we also find that AHFP is positively associated with higher fruit and vegetable intake. These results were especially prevalent among gardening and canning households, while red meat intake was higher among households hunting and having backyard livestock.These results have several important implications. First, it suggests that food insecure households engage in HFP as a potential coping mechanism for food insecurity, and this appears to have been especially true during the first US growing season during the COVID-19 pandemic. This is further corroborated by the results that low-income households and those with negative job changes were also more likely to be engaging in HFP and increasing the intensity of their engagement. While food insecure households are overall more likely to engage in AHFP (both before and since the start of the COVID-19 pandemic), more than 2/3 of food insecure households engaged more intensely in HFP or for the first time during the first five months of the pandemic. It is also important to note that a higher percentage of food insecure households are engaging more in non-gardening HFP activities (e.g. hunting, fishing, foraging) during the pandemic. One recent change in Vermont law provides free hunting and fishing licenses to certified members of state-recognized Native American tribes, which may have influenced some Native Americans to pursue these activities for the first time, or more intensely since COVID-19. Coupled together, these results provide important evidence about the reliance on HFP during a pandemic, and as a ""safety net"" for many potential households engaging in these activities for the first time or more intensely than before.Second, our results demonstrate clear links between HFP and diet quality outcomes, especially for current fruit and vegetable intake among respondents using AHFP, gardening and canning, and for current red meat intake among hunters and those with backyard livestock. These results confirm previous research findings that gardening is correlated with increased fruit and vegetable intake (e.g. [25, 29, 31] . While other research on hunting and fishing has not linked these behaviors to higher intake of red meat, prior research among a Native American population found that hunting, fishing and foraging increased the diversity and quality of diets [17] . While red meat intake is linked to various adverse health outcomes (e.g. [58] [59] [60] [61] ), not all red meats have the same nutritional profile. Wild meat and game that could be acquired through hunting may provide important micronutrients and protein [62, 63] , providing important dietary quality benefits.These findings may have important long-term health implications, especially the finding that nearly one in four respondents was eating less fruits and vegetables during the COVID-19 pandemic than before. Increased fruit and vegetable intake is associated with reduced risk of cardiovascular disease, certain cancers, and all-cause mortality [64] , yet even pre-pandemic, most Americans did not meet the national recommendations for fruit and vegetable intake [65] . Our finding of reduced intake are similar to those from studies conducted recently in France (Constant et al. 2020 ) and the United Arab Emirates [37] finding lower fruit and vegetable intake during COVID-19 associated lockdowns. Respondents using AHFP were on average eating ½ cup more each of fruits and vegetables daily; higher fruit and vegetable intake is associated with reduced risk of cardiovascular disease, cancer and mortality [64] . Furthermore, since previous research suggests that gardening is also associated with improved nutritional knowledge [33, 34] , and long-term beneficial changes in eating habits [24, 35] , the significant uptick in gardening and other HFP strategies during the pandemic may have future impacts on diet quality and health not yet realized. Future research should continue to monitor these potential changes, including their link to health outcomes more specifically.This study documented the extent of a range of HFP activities among a statewide sample in the US and assessed associations between HFP and food security and dietary outcomes. The results demonstrate that HFP activities significantly increased during the first five months of the COVID-19 pandemic, and were especially prominent among food insecure households. The results also document clear relationships between HFP activities and dietary outcomes, including higher fruit and vegetable intake, and possibly increased diet diversity, which may have important health benefits long-term. Taken together, the results suggest that HFP activities are an important, and potentially increasingly important, way in which many people engage in the food system and the natural environment, with potential implications for both conservation and nutrition and health outcomes. As such, additional research should more fully aim to understand these relationships over time, and in greater depth, especially in the continuation and aftermath of the COVID-19 pandemic. As well, additional collaborations within the conservation sector may be important to assess the long-term impact of increased levels of HFP that may affect forests, waterways, and species. Heightened engagement in HFP may necessitate expanded education and outreach efforts to provide resources for HFP that is productive and sustainable.Ethics approval and consent to participate: Institutional Review Board approval was obtained from the University of Vermont under protocol 00000873. Consent was obtained from all participants prior to data collection.Availability of data and materials: The survey instrument materials used for this current study are available at Harvard Dataverse at: https://dataverse.harvard.edu/dataverse/foodaccessandcoronavirus . The datasets used and/or analysed during the current study are available from the corresponding author on reasonable request.Competing interests: The authors declare that they have no competing interests.Funding: This research was made possible through grants provided by The University of Vermont College of Agriculture and Life Sciences and the Office of the Vice President of Research, as well as a COVID-19 Rapid Research Fund grant from the Gund Institute for Environment. The funders had no role in the design of the study and collection, analysis, and interpretation of data.Authors' contributions: MTN conceived and designed the work, analyzed the data, and wrote and revised the manuscript. KBW conceived and designed the work, wrote and revised the manuscript. EHB and FB conceived and designed the work, and revised the manuscript.",United States,abstract,2021-02-03,02
6e6279ed0ef4e3384515f1202827ec6b91c977b4,"Risk Perceptions, Knowledge and Behaviors of General and High-Risk Adult Populations towards COVID-19: A Systematic Scoping Review","Organization on March 11, 2020 . Since then, COVID-19 continues to represent a major concern for populations and governments. As of mid-January, 2021, more than 92 million cases have been confirmed and 2 million confirmed COVID-19-related deaths have been reported globally (1) . Among the adult populations, older people and individuals with underlying health conditions are at the greatest risk for developing severe complications (2) . An increasing number of authors suggest that individuals of disadvantaged socioeconomic groups, because of their greater exposure to the virus, have an increased risk of infection with COVID-19 (3, 4) . Similarly, evidence suggests that some ethnic minority groups are at increased risk of getting sick and dying from COVID-19 (4) (5) (6) .To the best of our knowledge, no overviews have been published of primary studies assessing RPKB of general and high-risk adult populations with regards to COVID-19. The objectives of our scoping review were therefore to 1) conduct a systematic search of the recently published primary studies assessing RPKB of general and high-risk adult populations with regards to COVID-19; 2) map the characteristics of the identified studies; and 3) identify the level of RPKB towards COVID-19 in these populations and the factors associated with RPKB.Given the high number of studies conducted with only short delays, we decided to conduct a scoping review to map the early evidence regarding our research questions (15) . To ensure a systematic approach in conducting our scoping review and for reporting the findings, we followed the PRISMA extension for scoping reviews (PRISMA-ScR) (16) .Before conducting the review, we published a research protocol on the protocols IO research platform (17) . We conducted a comprehensive search of the following electronic databases: MEDLINE-Ovid, EMBASE-Ovid, PsycINFO-Ovid, Web of Science, and CINAHL (EBSCO). The searches were performed in English, with the search terms in Table 1 .The search term strategies were developed with support from a librarian at X University.We included peer-reviewed and preprint articles that assessed RPKB of general adult populations or high-risk adults with regards to COVID-19. High-risk groups were defined based on the Centers for Disease Control and Prevention's definition (18) as individuals who are at greater risk of getting infected with COVID-19 or developing severe illness from SARS-CoV-2 because of their age, underlying health conditions, or socio-economic conditions. We decided to exclude studies that did not simultaneously assess RPKB related to COVID-19, because all of the factors in combination play a role in the transmission of the virus. The inclusion and exclusion criteria are shown in Table 2 .Two authors (NC and JB) independently reviewed the titles and abstracts of the articles against our inclusion and exclusion criteria. A pilot round with a randomly generated sample of nearly 10% of the articles was done to evaluate inter-reviewer agreement on the exclusion and inclusion criteria before a full screening was done for all articles (19, 20) .After the initial review of full-text articles, four authors (NC, JB, LG, MLT) completed the data extraction. The data extraction consisted of collecting variables on the 1) general characteristics of the articles (i.e., authors, title, month of publication, country, and publication journal); 2) characteristics of the participants (i.e., data collection period and method, targeted population, sample size and characteristics, sampling scheme, response rate, and statistical analysis); and 3) research question outcomes (i.e., RPKB in general and high-risk adult populations and their associated factors).2) medium quality (60-80%), and 3) high quality (≥80%). Low quality studies were not excluded from the scoping review.Our initial search yielded 4,878 articles and 60 additional records were identified through the preprint servers. After removing duplicates and reviewing the titles and abstracts, 20 articles met our inclusion criteria (see the PRISMA flow diagram in Figure 1 and Table 3 ).All of the studies were cross-sectional, using surveys conducted between February and April 2020. Most of the studies (75%) were based on non-probability sampling methods while only 20% used random sampling methods. A total of 55% of the studies had samples that were smaller than 1000 participants. Finally, 80% of the articles used both descriptive and advanced statistics to present the survey data and analyze factors that were significantly associated with RPKB towards COVID-19. The main characteristics of the included studies are shown in Table 4 .The survey participants were from 14 countries across four continents (Africa, Asia, Europe, and North America). Most of the studies assessed RPKB towards COVID-19 among general adult populations (n=12), while eight studies focused on high-risk adults.All studies collected demographic statistics on age and gender and most of them collected data on the level of education and income. Other data were related to living areas, occupation, health status, and ethnicity. More detailed information is provided in Table 5 .In 85% of the studies (n=17), RPs towards COVID-19 were assessed through perceived susceptibility for self and/or others to be infected. Only one study also measured risk perception by considering the concept of the perceived risk of infecting others (22) .Perceived severity of COVID-19 in the community or for high-risk groups was assessed in 65% of the studies (n=13). RPs were reported by the percentage of participants who reported being worried about getting infected or by calculating the mean score of the perceived likelihood of becoming infected (low or high scores).General adult populations. Overall, the studies found that perceived susceptibility for self was moderate to high in the population. Three studies conducted in the United States (23), Hong Kong (24) and India (25) reported a moderate proportion of adults being worried about getting infected (ranging from 40% to 67%). Two studies in Egypt (26) and India (27) showed a higher proportion of participants (87% and 82 % respectively) being worried about getting infected. Among studies that measured the perceived likelihood of getting sick from COVID-19 among adults in the United States (28), South Korea (29) and Serbia (30) , the perceived risk was moderate (mean scores ranged from 3.9/10 to 3/5) (28-30).These studies were conducted among adults living with a chronic disease in the United States (31), poor households in the Philippines (32), sexual minorities in Taiwan (33) or liver transplantation recipients and candidates for transplants in Germany (34) . In addition, two studies reported a low percentage of perceived susceptibility among the participants (35%); one was conducted among pregnant women in Turkey (35) and the other was in poor households in Kenya (36) .General adult populations. The perceived severity of COVID-19 among the participants was high in most studies that measured this variable (n=5). The proportion of participants who perceived COVID-19 as a serious threat to their health ranged from 97% to 80%, in studies in Hong Kong (24) , Sudan (37) , and Uganda (38) . We noted the exception of one study that was conducted in Bangladesh where 55% of the participants considered COVID-19 as a deadly disease (39) . In studies that measured perceived severity, the mean scores among participants in South Korea (29) and Serbia (30) ranged from 3.66/5 to 4.7/5 (29, 30) .High-risk adults. As in the general adult populations, the perceived severity of the disease among high-risk adults was significant. Four studies reported a high proportion of participants who perceived COVID-19 (68% to 95%) as a serious threat for themselves.The studies were conducted among liver recipients and candidates for transplants (34) , adults with Parkinson's Disease (40) , sexual minorities (33) , and poor households (36) . In the study conducted among pregnant women, only 51% of the women felt more vulnerable to developing complications from COVID-19 (35) .General adult populations. Adult participants had an overall good knowledge of COVID- 19 . In most studies, the overall knowledge rates and the proportions of knowledgeable respondents were relatively high (from 72% to 98% of respondents) (22, 26, 29, 37, 38) .In two studies, however, the survey results showed that respondents were not very knowledgeable: a mean score of 8.56/13 among Bangladeshi respondents (39) and 41% of the respondents having poor knowledge among the adults in the United States (23). In addition, three studies in Hong Kong (24), India (27) , and Sudan (37) found that a significant proportion of individuals (ranging from 24% to 38%) were not aware that asymptomatic persons can infect others/or know the period of asymptomatic incubation.Similarly, a very high proportion of respondents (>90%) identified that the disease could be transmitted through droplets, and direct or indirect contact (between 99% and 83%) (24, 26, 28) , except in one study where only 29% of the Indian respondents knew that COVID-19 spreads through multiple modes like touching, kissing, and sneezing (25) . Adult respondents were also very knowledgeable about the common symptoms of COVID-19. In several studies, a minimum of 80% of the respondents (up to 98%) knew all of the common symptoms of COVID-19 (26, 28, 30, 37) , except in one study conducted among Indian adults where only 18% of the respondents considered fever to be a symptom of the disease (25) . Finally, adult participants were very knowledgeable about preventive practices to avoid COVID-19 transmission, with more than 90% of the respondents acknowledging the preventive behaviors like social distancing, hand washing/sanitizing, wearing a mask, and avoiding public gatherings (25) (26) (27) .Several preventive behaviors were assessed in the 20 included studies, including handwashing (n=15), wearing a mask (n=15), staying at home/reducing social contacts (n=13), avoidance behaviors (e.g., avoiding crowded places, social gatherings or public transports, cancelling travel) (n=11), and practicing social distancing (n=8).In studies on general populations, many authors reported appropriate behaviors for preventing COVID-19. The most observed preventive behavior was washing hands frequently, with reported rates from 68% to 99% among respondents (24-30, 37, 38) . According to several studies, avoiding crowded places or social gatherings were also practices generally adopted by most respondents (from 65% to 99%) (25, 27, (37) (38) (39) , except in one study where a minority of South Korean participants (41%) reported avoiding crowded places (29) . In any case, adults were reportedly more or less compliant when it comes to staying at home, reducing social contacts, or avoiding public transport.In three studies, more than 80% of respondents followed these practices (22, 25, 28, 38) whereas studies conducted among Hong Kong and South Korean adults showed lower rates in adopting preventive behaviors; 53% and 39% of the respondents, respectively, reported avoiding public transport (24, 29) . Mask wearing was also variably followed in the studies.High-risk adults. Overall, studies on the high-risk adults have reported appropriate preventive behaviors during the early period of the pandemic. Two studies reported that a large majority of respondents (>90%) among poor households, liver recipients, and candidates for transplants washed their hands more frequently (34, 36) . Nevertheless, only 40% of the adults with Parkinson's disease reported washing their hands more frequently (40) . Staying at home or leaving home less frequently were also reported by a majority of respondents (60-79%) from poor households (36) , liver transplant recipients, candidates for transplants (34, 41) , and people with Parkinson's disease (40) . Most of the respondents (63%-94%) from poor households (32, 36) and sexual minorities (33) avoided crowded places or stopped attending social gatherings. In three studies involving liver transplantation recipients and candidates for transplants in India (41), poor households (32) and adults with Parkinson's disease (40) few participants reported wearing a mask (6%-40%). Nevertheless, in Germany, 78% of the liver transplantation recipients and candidates reported wearing a mask when leaving home (34) . Finally, the two studies conducted among poor households in Kenya (36) and the Philippines (32) reported a high proportion of respondents (81% and 66%, respectively) keeping distance from other people to avoid getting infected from COVID-19.The most studied factors that were significantly associated with RPKB towards COVID-19 were socio-demographic factors such as age, gender, education, and ethnicity.Studies in Hong Kong (24) and South Korea (29) found that older adults were significantly less worried about getting infected compared to the young adults. We found one exception to this in a study among poor households in Kenya where the perception of risk increased by age group (36) . Age was positively associated with perceived severity in two studies: one in Serbia among the public (30) and the other in the United States among persons with chronic conditions (31). In four studies, older adults were also found to be more knowledgeable about COVID-19 compared to younger adults (28, 30, 34, 39) . In addition, three studies found that age was positively associated with hand-washing (28, 29, 37) .In two studies, women were significantly more worried about being infected with SARS-CoV-2 or to consider COVID-19 as a threat to health (31, 34, 40) . Men were found to be less knowledgeable than women about COVID-19 in three studies (28, 30, 37) . Finally, a high number of studies reported that the adoption of preventive behaviors such as handwashing, wearing a mask, reducing contacts, avoiding social gatherings, or practicing social distancing was positively associated with the female gender (22-24, 28, 29, 31, 37, 39) .A higher level of education was positively associated with knowledge of COVID-19 in five studies, especially with regards to modes of transmission and common symptoms (24, 30, 32, 36, 37) . Adults who were educated were also more likely to adopt preventive behaviors like wearing a mask or maintaining social distance (29, 30, 32) .To the best of our knowledge, this is the first scoping review that offers a mapping of studies conducted among general and high-risk adult populations on RPKB towards COVID-19 and factors associated with RPKB.Our scoping review has several limitations. We decided to cover a short period (January-June 2020). In the context of the pandemic, a large number of studies were conducted and published very early. Consequently, a first step in mapping the emerging evidence has been to gain an understanding of RPKB towards COVID-19 in the early stage of the pandemic.We did not provide a cross-comparison between countries, mainly because of the significant heterogeneity of studies regarding survey and sampling methods and the absence of cross-country studies in the scoping review. Finally, because the overall quality of the included articles was quite low, the research findings presented here should be interpreted carefully. Most studies used non-probability sampling and online surveys that raises doubts about the capacity for authors to generalize the research findings. While online surveys allow a rapid and user-friendly data collection from large samples of the population, they can also increase the likelihood of sampling and non-response bias (42) .The scoping review showed that general and high-risk adults were knowledgeable about COVID-19. Our findings are consistent with those of Majid et al.'s recent scoping review on knowledge, RPs, and behavior change during pandemics, where the authors stated that knowledge generally spreads rapidly during pandemics in most regions (48) . Nevertheless, we found exceptions in several studies that reported a relatively low level of overall knowledge among the general public in Bangladesh (39) , and the United States (23) .Our review identified hand-washing and avoiding crowded places as dominant preventive behaviors among both general and high-risk adults at the early stage of the pandemic.Nevertheless, staying at home, reducing social contacts, and avoiding public transport were less widespread in general populations. Alternatively, the high-risk adults reported being much more compliant with staying at home or leaving home less frequently (34, 36, 41) .Wearing a mask was the least respected practice in the early stage of the pandemic for both general and high-risk adults, except in one study conducted in Hong Kong where 97% of the participants reported wearing a mask when leaving home (24) . In Majid et al.'s scoping review, the authors reported varying degrees of adopting mask wearing, ranging from 4% in the United States to 96% in China (48) . In East Asia, mask wearing is socially embedded as a general preventive practice (50) . Surprisingly, a large majority of the participants from poor households (32, 36) , including those living in slums in Kenya (36) reported using social distancing to avoid getting infected. This finding is in contradiction with a recent observational study conducted in an urban slum in India. In any case, the authors concluded that social distancing measures were more of an aspiration than reality (51).Nevertheless, mixed evidence has been given for the link between ethnicity and adoption of preventive behaviors, a finding that is consistent with the review of Bish and Michie (8) .Our findings have several implications for public health authorities aiming to be responsive in adopting appropriate and effective risk communication strategies at the very early stages of a pandemic. Our review showed that during the first wave of COVID-19, the perceived severity of COVID-19 was higher than the perceived susceptibility among general and high-risk adult populations. This finding suggests that people, especially those in lessaffected areas, might have underestimated the infectivity of the virus. Perceived susceptibility combined with perceived severity plays a vital role in motivating health protection behaviors (53) and may facilitate or reduce the transmission of a virus during pandemics (11, 14) . While countries are facing a second or third wave of COVID-19, RPs should be continuously monitored to adjust the risk communication strategies over time.Effective risk communication relies on generating a sense of worry among the public while avoiding the fear that could lead to denial and inappropriate behaviors (54).Online survey (self-administered) 12 (60) Phone or face-to-face (administered by an interviewer) 8 (40) Paper survey (self-administered) 2 (10)Descriptive statistics (only) 4 (20) Descriptive and advanced statistics (analysis of variance/regression analysis) 16 (80) * The total sometimes exceeds 100%, because two studies used two survey administration methods for the participants.",Canada,first author,2021-02-15,02
961d00fb50ef4714f90d0a5d156d00c56b04ec3a,"In-hospital mortality from severe COVID-19 in a tertiary care center in Mexico City; causes of death, risk factors and the impact of hospital saturation","In this prospective cohort study, we enrolled consecutive adult patients hospitalized with severe confirmed COVID-19 pneumonia at a SARS-CoV-2 referral center in Mexico City from February 26th, 2020, to June 5th, 2020. A total of 800 patients were admitted with confirmed diagnosis, mean age was 51.9 ± 13.9 years, 61% were males, 85% were either obese or overweight, 30% had hypertension and 26% type 2 diabetes. From those 800, 559 recovered (69.9%) and 241 died (30.1%). Among survivors, 101 (18%) received invasive mechanical ventilation (IMV) and 458 (82%) were managed outside the intensive care unit (ICU); mortality in the ICU was 49%. From the non-survivors, 45 .6% (n = 110) did not receive full support due to lack of ICU bed availability. Within this subgroup the main cause of death was acute respiratory distress syndrome (ARDS) in 95% of the cases, whereas among the non-survivors who received full (n = 105) support the main cause of death wasAs the severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) pandemic has spread throughout the globe, it has currently remained in Latin America. As on September 3rd, 2020, Mexico has become the seventh nation with confirmed cases and the third regarding SARS--CoV-2 related deaths worldwide, lagging only Brazil as the second country with the highest death toll worldwide [1] . Current reports have shown a mortality rate ranging from 8 to 21% in patients hospitalized for SARS-CoV-2 pneumonia, and up to 16 to 78% in those requiring ICU admission [2] [3] [4] [5] . In the case of Latin America, a recent report from Honduras showed a crude in-hospital mortality of 39% and as high as 72% in mechanically ventilated patients [6] .It has been reported that socioeconomic factors such as higher poverty rates, high public transportation use, lack of health insurance, poor level of formal education as well as overcrowding housing (and other factors that preclude social distancing and precautionary measures) are associated with an increased rate of in-hospital mortality [7] [8] [9] [10] . Besides the unfavorable socioeconomic landscape of Mexico, the high rates of hypertension, type 2 diabetes and obesity pose an imminent threat for in-hospital survival [11] . In addition, health care system associated factors, particularly the high requirements for intensive care unit (ICU) beds reported during this pandemic [12] might have an essential role regarding in-hospital mortality. To face this onslaught, Mexico's ICU bed availability per 100,000 habitants approaches 1.5 [13] , which represents half of those initially contemplated in China, around 10% of those in Italy and between 0.04-0.05% of Germany and USA's total capacity, respectively [14] [15] [16] . This high demand for ICU beds might lead to a delay in ICU admission, which is a well-known, time-dependent factor associated with increased mortality [17] . Besides ICU saturation, the effect of both in-hospital and emergency department overcrowding are associated with unfavorable outcomes and might have an impact in major outcomes (mortality) in the circumstances the country faces [18] . In this study, we aimed to describe the in-hospital mortality in adult patients with confirmed SARS-CoV-2 pneumonia as well as risk factors associated with mortality in those who received the standard of care in a tertiary care center in Mexico City. The impact of hospital overcrowding was explored as well.In this prospective cohort study, we enrolled all consecutive adult patients hospitalized with severe confirmed COVID-19 pneumonia at a tertiary care center in Mexico City from February 26th, 2020, to June 5th, 2020 . The hospital was reconverted to a COVID-19 reference  center on March 16th 2020, 96 beds were used for hospital wards, the ICU bed capacity was  expanded from 14 to 42 beds (all of them for invasive mechanical ventilation, IMV) and 20  beds were used for intermediate care of critically ill non-intubated patients in the emergency  department. The process of patient selection for ICU care was based on bed availability. All patients included in this cohort had a positive real-time reverse transcription-polymerase chain reaction (PCR) either from a naso/oropharyngeal swab or from a tracheal aspirate by a procedure previously described [17] , chest computed tomography scan compatible with diagnosis of COVID-19 pneumonia, routine blood workup (including complete blood count, inflammatory markers, metabolic panel and arterial blood gas analysis) and required hospital admission due to hypoxemia. Clinical outcomes were monitored until August 1st, 2020 (the final date of follow-up) through the institutional electronic medical records. This study was approved by the Institutional Review Board (Comité de Investigación and Comité de Ética en Investigación, reference number 3333) and informed consent was waived due to the minimal risk characteristics of an observational study. A detailed description of the setting, molecular diagnostic procedures and data collection has been previously described [18] .Data regarding clinical, demographic, radiologic and laboratory findings were extracted from the institutional electronic medical records by two physicians and reviewed by a third one for data accuracy. Clinical outcomes were followed and registered until August 1st, 2020.Definitions and outcomes. The primary outcome was in-hospital mortality although no time frame was set for this outcome to occur; all the patients analyzed either died in hospital or were discharged home (with or without home oxygen supply). The cause of death was assigned in consensus by three different clinicians (JVJC, JLCF & CMB) under the following definitions: acute respiratory distress syndrome (ARDS) defined according to the 2012 Berlin criteria [19] in intubated patients; patients who died from hypoxemic respiratory failure but were not intubated were assumed to have ARDS even though a peak end expiratory pressure (PEEP) of 5 cm H20 was not administered (non-invasive mechanical ventilation and high flow nasal cannula were not approved by the epidemiology department in the initial months of the pandemic). The diagnosis of acute kidney injury (AKI) was made either with a 0.3 mg/dl elevation of serum creatinine levels or a decrease in urine output under 0.5 ml/kg/hr for > 6 hrs, staging followed the standard KDIGO guidelines criteria for AKI [20] . Multiorgan dysfunction syndrome (MODS) was defined by clinical or laboratory failure of two or more systems as stated by the SOFA score [21] . In addition to the medical cause of death, one of the following classifications was given in a case by case basis: 1 = directly attributed to SARS-CoV-2 infection (ARDS, septic shock or MODS without an additional nosocomial or opportunistic infection and acute pulmonary embolism); 2 = indirectly attributed to SARS-CoV-2 infection (septic shock or MODS because of nosocomial or opportunistic infections -microbiological evidence was required in this category-), arrhythmias either triggered or directly caused as a result of the critical state or life support (for instance vasopressor use, hemodialysis), precipitated acute coronary syndromes or complications directly attributed to standard management of SARS--CoV-2 pneumonia (e.g. barotrauma secondary to IMV or central line placement, or upper/ lower gastrointestinal bleeding secondary to anticoagulation/thrombolysis); 3 = not attributable to SARS-CoV-2 infection. Immunosuppression was considered if the patient was neutropenic (less than 500 neutrophils), asplenic, with an active malignant disease or under immunosuppressive treatment (prednisone >20mg/day or any other immunosuppressive drugs for at least 30 days). Smoking was considered as current tobacco use.Numerical variables are summarized in mean and standard deviation or median and interquartile range (IQR) according to the shape of the distribution (symmetric or non-symmetric), categorical variables are presented in frequencies and percentages. The characteristics at admission are described overall and by the following mutually exclusive groups: 1) survivor at discharge, 2) non-survivor with full support, 3) non-survivor without full support (because of lack of bed at the ICU and ventilator), and 4) non-survivor with do not intubate (DNI) or do not resuscitate (DNR) orders elected by the patient. The characteristics at admission were also compared between the first two groups (survivor at discharge versus non-survivor with full support) using a t-student test or a U Mann-Whitney test if numeric or a chi-squared test if categorical.In relation to mortality, causes of death, its association with COVID-19 and the number of deaths per week are described overall and by the groups defined by the support received. The number of deaths per week are also displayed according to the place of death. In order to illustrate the impact of hospital saturation on mortality over time, the following data are graphically displayed per day: the number of patients attended at triage, the number of admitted patients (both confirmed and non-confirmed SARS-CoV-2 cases), the number of confirmed and non-confirmed SARS-CoV-2 deaths, and the confirmed and non-confirmed SARS-CoV-2 mortality rates. The first order trends for the number of admitted patients and for the number of in-hospital patients over time were estimated using linear splines with one knot on the dates of a clear change of behavior. The confirmed and non-confirmed SARS-CoV-2 mortality rate tendencies over time were assessed with locally weighted scatterplot smoothing (LOWESS) curves superimposed to their corresponding mortality rates values per day. Non-confirmed SARS-CoV-2 patients had pneumonia compatible with COVID-19 but with a negative PCR test.The analysis of risk factors was performed using the data from patients in the first two groups: alive at discharge and died with full support. The following variables were evaluated as risk factors for mortality: sex, age, body mass index (BMI), obesity, diabetes, hypertension, smoking status, NEWS score and O2 saturation breathing air at admission. In order to report risk ratios for all these variables, numeric variables were categorized into binary variables using the closest integer to its overall mean or standardized cutpoints. For each variable, the unadjusted risk ratio for mortality was estimated using the normal approximation to the logarithm of the risk ratio, meanwhile the adjusted risk ratio was estimated using the Targeted Maximum Likelihood Estimation method with a super learning algorithm to estimate both the exposure and outcome mechanisms [22] . The confounders for adjusting the risk ratio estimate were different for each covariate and were selected according to scientific knowledge. No confounders were considered for age and gender. Statistical analysis was performed using R software version 4.0.2. A two-tailed confidence level of 0.05 was established.During the study period, 3924 consecutive patients were evaluated in the emergency department for suspected SARS-CoV-2 infection, of whom 1018 patients (26%) were admitted under the diagnosis of suspected SARS-CoV-2 pneumonia pending on the result of SARS-CoV-2 PCR. Of them, 143 patients (14%) did not meet inclusion criteria due to negative or indeterminate SARS-CoV-2 PCR results and 875 patients (86%) were confirmed SARS-CoV-2 pneumonia cases. Finally, we excluded 62 patients due to inter-hospital transfer and unknown clinical outcome (transfer to another hospital with available ICU beds owing to clinical deterioration) and 13 patients that were discharged against medical advice (Fig 1) . To complete the description of the flowchart (Fig 1) in S1 Fig, we described the total number of visits to the emergency department, as well as the number of patients who were not admitted and the total number of hospital admissions. In addition, we included the crude in-hospital mortality of patients with positive SARS-CoV-2 and the in-hospital mortality of patients with negative or indeterminate SARS-CoV-2 results.The final study population consisted of 800 hospitalized patients with confirmed SARS--CoV-2 pneumonia of whom 559 recovered (69.9%) and 241 died (30.1%) during hospitalization. Among the survivors, 101 (18%) received IMV and 458 were managed either in general hospital wards or intermediate medical care units/emergency department (IMCU/ED) beds. From non-survivor patients, 43.6% (n = 105) received full support (98 received full standard care of treatment including IMV and 7 died during CPR outside ICU areas); 45.6% (n = 110) did not receive full support (they had refractory hypoxemia but were not intubated due to ICU bed availability) and 10.8% (n = 26) were under DNI/DNR orders.Baseline characteristics are summarized in Table 1 . Overall, mean age was 51.9 ± 13.9 years, 61% (n = 488) were males, 46.3% (n = 350) were obese, 38.4% (n = 290) were overweight, mean BMI was 30.3 ± 5.8 kg/m2, 30% (n = 240) had hypertension and 26% (n = 209) lived with type 2 diabetes. Among the 664 patients who received full support, age was similar in survivors and non-survivors (mean of 48.8 years ± 12.9 years versus 51.9 ± 13.9 years, p = 0.054), but mean BMI (mean of 30.2 ± 5.4 kg/m2 in survivors and 32.3 ± 7.5 kg/m2 in non-survivors, p = 0.007) and diabetes prevalence (22% in survivors vs 33% in non-survivors, p = 0.015) were higher in non-survivors. There was no difference among survivors and non-survivors regarding other comorbidities. In-hospital mortality from severe COVID-19 in Mexico City Clinical evaluation at admission is described in Table 2 . The median time from symptoms onset to hospital admission was 8 days (IQR: 6-10). The most common symptoms were cough in 90% (n = 716), fever in 87% (n = 693), dyspnea in 80% (n = 633), malaise in 79% (n = 622) and headache in 74% (n = 583). Regarding the physical examination, average mean arterial pressure was 91.4 ± 12.3 mm Hg, mean heart rate was 103 ± 18 bpm, median respiratory rate was 28 bpm (IQR: [22] [23] [24] [25] [26] [27] [28] [29] [30] [31] [32] [33] [34] and median O2 saturation breathing air was 84% (IQR: 71-88). When comparing the patients who received full support, dyspnea (75% in survivors versus Table 3 . Overall, inflammatory measures were elevated: median leucocyte count of 8,100 cells/uL (IQR: 5,800-11,300), median neutrophil count of 6. In-hospital mortality from severe COVID-19 in Mexico City in non-survivors, p = <0.001), as well as, increased inflammatory markers such as ferritin (median of 564 ng/ml versus 850 ng/ml, p = <0.001), C-reactive protein (median of 12.9 g/dl versus 21.4 g/dl, p = <0.001) and LDH (median of 354 U/L versus 518 U/L, p = <0.001) levels in addition to increased prothrombotic markers (median D-dimer of 677 ng/ml versus 919 ng/ ml, p = < 0.001; median fibrinogen of 678 mg/dl versus 751 mg/dl, p = 0.005) were found among non-survivors. Patients who died during hospitalization showed more severity on markers of end-organ dysfunction than those who recovered, manifested as higher creatinine (median of 0.9 mg/dl versus 1.0 mg/dl, p = 0.002) and blood urea nitrogen levels (median of 13.9 mg/dl versus 17.9 mg/dl, p = < 0.001), lower PaO2/FiO2 ratio (median of 230 versus 118, p = < 0.001) and increased troponin levels (median of 4.6 pg/ml versus 12.4 pg/ml, p = <0.001). In relation to patients who died without receiving full support because of unavailability of critical care beds or DNR/DNI order, they appeared to be older, with lower BMI and lower PaO2/FiO2 ratios than those who received full support. However, the observed markers of inflammation and end-organ dysfunction appeared to be similar (Table 1) . The mortality rate in confirmed cases had an important increase until April 27th, stabilized during the first half of May and began to decrease afterwards. The behavior of mortality rate in non-confirmed cases was similar but with a mortality rate of 2.7% on March 30th, which corresponds to one death in a day with only 37 in-hospital patients, and stabilization after May 5th.The distribution of deaths stratified by the support received is shown in Fig 2A. The first death occurred on April 5th and the last one on July 3rd. Deaths in patients without full support began during the third week of April (April 22th), with a substantial increase in the last week of April, which was preserved until the first days of June. Previous information is further stratified by the place of death in Fig 2B. Of the total of 241 deaths, 39.4% (n = 95) occurred in the ICU, 39.0% (n = 94) in the IMCR/ED and the remaining 21.6% (n = 52) in the hospital ward. All deaths that occurred in the ICU received full support and decreased in number over time, whereas most of the patients who died outside the ICU did not receive full support (76 in the IMCU/ED and 34 in the hospital ward). Ten patients who received full support died outside the ICU, 6 in the IMCU/ED (4 during CRP and 2 after UCI discharge from a non-respiratory cause) and 4 in the hospital ward (2 during CRP and 2 after UCI discharge from a non-respiratory cause).Overall, the main cause of death was known in 239 of the 241 non-survivors and was ARDS in 67%, (n = 159) followed by septic-shock in 19% (n = 45) and MODS in 9.2% (n = 22). Arrhythmias, pulmonary embolism and acute coronary syndromes were rare causes of death in this cohort. We further analyzed the cause of death among patients who were not admitted to the ICU despite invasive mechanical ventilation requirements (due to lack of ICU beds) the vast majority of them died of hypoxic respiratory failure/ARDS (105/110, 95%). In contrast, among non-survivors who were admitted to the ICU the main cause of death was septic shock in 42% (43/105) followed by ARDS in 29% (30/105) and MODS in 18% (19/105). All of the patients who were admitted to the ICU and died (105/105) had respiratory failure, 85% (88/ 105) hemodynamic failure and 49% (50/105) renal failure; and 85% (88/105) had more than one organ failure. Information regarding causes of death in the group of non-survivors, those patients admitted to ICU and those not admitted into the ICU are described in Table 4 , 88% (210/239) of the total deaths were directly attributed to SARS-CoV-2 infection and 12% (29/ 239) were indirectly associated.The analysis of the studied risk factors for mortality is summarized in Table 5 . We estimated that the risk of in-hospital death was significantly higher in males than in females (RR of 2.05, 95% CI 1.34-3.12, p < 0.001), in obese than in non-obese patients (RR of 1.62, 95% CI 1.14-2.32, p = 0.008), in morbid obese subjects than in those with normal BMI (RR of 3.38, 95% CI1.63-7.00, p = 0.001), in diabetic than non-diabetic ones (RR of 1.47, 95% CI 1.01-2.15, p = 0.046), in patients with a NEWS score 7 as compared to those with less than 7 points at admission (RR of 2.44, 95% CI 1.18-5.03, p = 0.016) and in subjects with 80% oxygen saturation than in those with less than 80% oxygen saturation breathing air at admission (RR of 4.88, 95% CI 3.26-7.31, p < 0.001).In this prospective cohort study among patients with confirmed COVID-19 pneumonia, attended in a tertiary care center located in Mexico City, in-hospital mortality was 30.1%, and 49.2% in the ICU beds (which were composed of more than 50% enabled ICU beds), both falling within the range described in previous reports (20-40% and 50-70%, respectively) [2] [3] [4] [5] [6] [23] [24] [25] . It is worth noting that all (199/199) the patients admitted to the ICU required mechanical ventilation, in contrast to other cohorts in which 69-88% of the ICU admission required this modality of ventilatory support [23] [24] [25] . It is important to emphasize that until the final date of inclusion for this study, the use of high-flow nasal cannula or non-invasive mechanical ventilation was not approved by the infection control committee (due to the potential risk of aerosolization) and therefore they were not used in ICU nor in general hospital wards.Although the crude mortality seems to be similar to other cohorts, 45% of the non-survivor patients and 14% of the hospitalized patients who developed critical illness and warranted ICU admission did not received IMV/ICU care due to the lack of ICU bed availability (not only in this hospital but in the whole Metropolitan area of Mexico City). These numbers shed light about the unfortunate but urgent problem of health system saturation and ICU resource rationing during the pandemic. This behavior was similarly observed during the initial surge of the pandemic in both Wuhan [26] and New York City [2] where over 50% of the critically ill patients who required ICU care died in general hospital wards and did not receive IMV due to resource constraints [5] . We speculate that overcrowding of the ICU in this tertiary care center was a main determinant for this phenomenon. The rise in deaths between May and June was mainly driven by patients who did not receive IMV/ICU admission. This indirectly reveals a shortage in ICU beds (as well as hospital overcrowding) therefore a delay in ICU admission [27] which is an independent (as well as proportional for the time of delay) risk factor for ICU mortality [28] and, in the particular case of ARDS, a major factor perpetuating lung injury whenever IMV is imminently indicated (due to patient self-inflicted lung injury) [29] . The decrease in mortality throughout time is mostly impelled by the decrease in deaths among patients who did not receive IMV/ICU admission, although the ICU mortality also decreased over time which we believe might be explained by ICU care improvement and acquisition of expertise in the management of these patients in the enabled ICU areas. We included dexamethasone in the standard of care on June 30, 2020, once a preprint of the RECOVERY study [30] was available and NIH released a formal recommendation [31] .In regard to patient related factors associated with mortality, the findings of this study are similar to previous reports in which increased number of comorbidities, especially diabetes and obesity (the grade of the latter being directly proportional with mortality), male gender as well as increased inflammatory markers and laboratory findings related with organic failure were associated with an increased risk of in-hospital death. In a recent analysis of more than 17 million people and over 10,000 related to COVID-19 deaths in the United Kingdom in which multiple ethnicities were included [32] , the risk factors associated with mortality are consistent with ours. Interestingly, in that same study [32] , race other than caucasian was associated with an increased risk of death (whether Asian, black or mixed). The findings of this study suggest that previously known risk factors might not differ significantly among the Mexican population except for age. In patients who received full support, age was not associated with mortality. However, in this cohort the mean age was a decade lower compared to previous reports from Europe and North America [2, 12, [32] [33] [34] [35] . The same pattern was observed in a recent report from Honduras in which a younger age among hospitalized patients was noted and attributed both to a younger population distribution and a higher prevalence of comorbidities at younger ages. Under these speculations the authors of this study rightfully predicted a similar behavior in other Latin American countries as observed in this cohort [6] .In this study, prevalence of diabetes was nearly twice the known national prevalence (13.7% according to the 2016 National Health and Nutrition Survey [41] ), but prevalence of hypertension, overweight and obesity were similar (31.5%, 39.1% and 36.1%, respectively [36] [37] [38] [39] ). Living with diabetes increased 1.5-fold the risk of dying whereas hypertension was not associated with increased mortality. In relation to the weight, the mortality was 11% in patients with normal weight, 15% in those with overweight, 18% in grade 1 obesity, 16% in grade 2 and 34% in patients with morbid obesity. Moreover, in the analysis of risk factors, we found a 3.4-fold increase in mortality risk in patients with morbid obesity as compared to those with normal BMI after adjusting by age and gender. Hence, we believe that the main burden of weight in in-hospital mortality was due to morbid obesity which might be related to mechanical conditions but also to a higher load of metabolic comorbidities (potential mediators between obesity and mortality).Overcrowding of the ICU facilities and resource rationing revealed the course of the disease and provided valuable information regarding the natural history of this condition. The main cause of death in patients who were not admitted to the ICU was hypoxemic respiratory failure or probable ARDS (although the Berlin definition of ARDS was not strictly fulfilled because they did not received a PEEP > 5 mmHg, the implications of this concept has been recently discussed by Tobin et al. [40] and might be irrelevant to the purpose of this study) unlike those patients who were admitted and died in the ICU in whom the cause of dead was primarily due to septic shock, followed by ARDS and multiorgan failure. Although the initial failure conditioning survival is the respiratory failure, in advanced stages (after providing initial ventilatory support) viral septic shock seems to prevail as the major event leading to death, this chronological distinction has not been dissected in previous reports in which all the patients who died received IMV and ICU admission [41] [42] [43] . As it has been previously suggested [43] [44] [45] , the pathways leading to SARS-CoV-2 related death should be distinguished between those directly attributed the viral infection, those in which the infection partially contributed to the cause of death (i.e. nosocomial infections) and those unrelated to it, in this cohort the vast majority of deaths were directly related to SARS-CoV-2.Besides the intrinsic limitations of a cohort study [46] , ours has several additional ones. First, the population studied was limited to the metropolitan area of Mexico City, therefore extrapolation to areas with less population density (and less resource availability) might be inaccurate. Second, a considerable percentage of this cohort was transferred either to a convalescent center (due to clinical improvement) or to other hospitals with ICU bed availability (due to clinical deterioration and saturation of critical care areas of this tertiary care center) therefore the clinical endpoint of this subgroup is unknown and might have affected the analyzed data.In conclusion this study represents a large prospective cohort exploring in-hospital mortality in COVID-19 pneumonia in Mexico.Although unfortunate, this analysis reveals an unspoken problem in limited resource countries regarding supplies availability to handle health care challenges such as the SARS-CoV-2 pandemic. It has been stated through statistical modelling that high poverty indexes, lack of access to appropriate medical care and geographical location are major determinants for mortality among Mexican patients with SARS-CoV-2 infection [11] . To this data we may add the alarming situation of emergency department/critical care areas overcrowding and its impact in patient outcomes. Understanding and acknowledging this drawback might help forecast and prepare for future needs (particularly by reason of the prolonged plateau that is foreseen in this country). More data regarding outcomes in underdeveloped areas is needed to understand the scope and different scenarios of this pandemic in order to create strategies tailored for middle and low-income countries. ",Mexico,abstract,2021-02-03,02
e75ad5e006cccb191bb5705fe0f3144a300008e0,A novel box for aerosol and droplet guarding and evacuation in respiratory infection (BADGER) for COVID-19 and future outbreaks,"www.nature.com/scientificreports/ similar to SARS-CoV-1 and other coronaviruses. Most particles generated during coughing and sneezing are between 0.35 and 10 µm 13 . Direct droplet spread occurs when droplets from a patient's respiratory tract land on a recipient's mucosal surface. Indirect droplet spread happens via direct physical interaction with an infected person or on the surfaces and fomites with which infected persons or their droplets have had contact 14 . On the other hand, airborne transmission occurs when aerosolized particles are inhaled into the lower airway. Although it is often stated that droplets with a diameter (d p ) > 5 μm can deposit directly on nearby surfaces while smaller aerosol particles (d p < 5 μm) remain in the air for significantly longer periods of time, the distance a particle travels is complex and dependent on many dynamic variables, such as particle size, shape, charge, flow velocities, composition, density, air turbulence, temperature, and humidity [15] [16] [17] . Patients with respiratory infections often generate large amounts of aerosols from coughing, sneezing, or heavy breathing 18, 19 . Some studies have also shown an association between aerosol-generating procedures and healthcare provider infection during the SARS-CoV-1 epidemic 20, 21 . Faced with the likely risk of airborne transmission and lack of proper protection, many health care professionals have developed their own equipment and guidelines to protect themselves from infection when working with patients 22, 23 . Existing devices such as the ""intubations shield"" (Fig. 1b) are limited to a physical barrier of protection, as there are currently no strategies www.nature.com/scientificreports/ that provide protection from aerosol particles generated by a patient's coughs and sneezes and by high-risk procedures performed by healthcare providers 22 . In the face of great urgency and severe risk, we have designed, constructed and tested the effectiveness of an affordable, scalable Box for Aerosol and Droplet Guarding and Evacuation in Respiratory infection (BADGER) to contain both droplets and aerosol particles (Fig. 1c ).Construction of the BADGER. To decrease risk of airborne transmission of SARS-CoV-2 to health care professionals and workers, we sought to build a device that could decrease exposure of providers to the patient's droplets and aerosols. We defined the following criteria for our device to meet the function, urgency and demand during the pandemic: (1) ability to stop direct droplet contact, especially from a patient's coughs and sneezes, or during high risk procedures such as intubation of an airway and extubation; (2) ability to contain aerosol particles; (3) ease of manufacturing; and 4) affordability. We studied the ""aerosol box"" developed by Dr. Hsien-yung Lai from Taiwan and its ability to shield providers from large flashing droplets 22, 24 . Although innovative and simple, this device lacks the ability to adequately contain an aerosolized virus that could be present within smaller diameter aerosol particles due to its open air design (Fig. 1b) . In order to contain smaller diameter airborne particles, a negative pressure and/or rapid air exchange rate is needed, similar to the function of a negative-pressure room. To achieve our goal of keeping the device affordable and easy to manufacture, we used commonly available materials, clinical equipment and supplies. After three prototypes, we reached a production version. The BADGER is constructed of a clear reusable shell and disposable accessories and, when assembled, creates a closed chamber. The shell of the BADGER is a tapered pentagonal box that has a height of 50 cm, a torso-opening of 60 cm, and overall volume of 95.8 L (Fig. 2 ). There are 4 hand-ports for health care providers and assistants, and two 22 mm diameter openings for two viral high efficiency particulate air (HEPA) filters placement. The side panels are constructed by bending, or by cutting into separate panels (Fig. 2b) . The top panel is glued to the side panels using a hot melt adhesive (Fig. 2c) . To create a semi-sealed chamber, all the openings need to be closed off. For the hand-ports, we used the sleevering method by assembling large disposable surgical gloves on 3D custom-made printed grommets (Fig. 2d) .The glove fingers can be trimmed off at the palm to create a sleeve. While this compromises the seal at the hand-ports, it allows greater mobility, reach, and reduces wrong-handedness. The sleeve-rings are then inserted into the hand-ports of the BADGER (Fig. 3) . The large interior opening for the torso is sealed off from the outside environment using two overlapping plastic drapes. Large diameter tubing such as ventilator tubing is used to evacuate air from the box after passing through the HEPA filters.Outflow using wall suction. To model the BADGER after a negative pressure room, we designed the device to have a minimum of twelve air changes of exhaust per hour 25 . To achieve this goal, we connected the BADGER to a standard hospital room's in-wall vacuum suction source. In most modern hospitals, vacuum pressure is set to be at least 277 mmHg (36,930 Pa), which is 483 mmHg below atmospheric pressure at sea level 26 . The latter number (atmospheric pressure -vacuum pressure) is a commonly used vacuum suction strength in www.nature.com/scientificreports/ a hospital or a clinical setting to quantify suction strength. We refer to this as suction pressure throughout the manuscript. However, we will use the former number (vacuum pressure) in calculation of flow rate. To maintain at least twelve air changes per hour (the BADGER's volume = 95.8 L), the outflow rate must be at least 19.2 L per minute (L/min) or 9.6 L/min per filter outlet. Air flow rates from a standard hospital room's in-wall vacuum suction source was then measured using an in-line flow meter (TSI model 4043). The tests were carried out at room temperature (21 °C) and atmospheric pressure (760 mmHg or 101.3 kPa). The flow meter was fitted to different types of commonly available suction tubing used in hospitals and clinics and a mixed setup: (1) non-sterile, non-conductive 7 mm inner diameter (D) tubing (Universal Argyle Bubble Tubing, Covidien, Dublin, Ireland); (2) sterile, non-conductive 6 mm D tubing (Cardinal Health, Dublin, OH); (3) ""Mixed setup"" of a single 7 mm D tubing connected to a dual-limb breathing circuit tubing (Adult UltraFlex Dual-Limb breathing circuit, King Systems, Noblesville, IN). We used 2 different lengths (5 and 10 m) as these would provide adequate length to connect the BADGER to an in-wall vacuum suction source. Flow rates were assessed with and without a viral HEPA filter: Ultipor 25 (Pall, Port Washington, NY) or AG7178 Bacterial/Viral Filter (AG Industries, St. Louis, MO) attached to its upstream. We chose the ""Mixed setup"" to represent the current setup of the BADGER for our clinical use: 2 HEPA filters from the filter outlets connected to a dual-limb breathing circuit (1.8 m when stretch), which is in turn connected to a single 3.2 m × 7 mm D tubing. Measured volumetric air flow rates were plotted against the suction pressure settings that are commonly used in a clinical setting: low = 50 mmHg, medium = 100 mmHg, high = 150 mmHg, very high = 200 mmHg, and max suction = 700 mmHg. The BADGER uses commonly available hospital supplies to create isolation and semi-sealed chamber. Accessories for each BADGER are: two viral HEPA filters, two 60 cm × 60 cm clear drapes, 5-10 m of 6 mm or 7 mm inner diameter tubing, one dual-limb breathing circuit tubing, 2 pairs of size 8.5 or 9 surgical gloves. Grommets and surgical gloves are assembled into sleeve-rings to seal the hand-ports. Drapes are taped to create overlapping opening for the torso/neck. Direction of airflow into and out of the BADGER are depicted as green arrows (c). (d,e) Clinical application of an earlier version of the BADGER on a patient for intubation (d) and intraoperative use (e). 27 . Denatonium benzoate (Bitrex) is a non-toxic bitter chemical that can be detected by inhaling aerosolized droplets when breathing by mouth at concentration as low as 0.05 ppm 28 . Bitrex or saline control was nebulized inside of the BADGER in the standard operating configuration (Fig. 4a) . The test was carried out in a 5 m × 5 m well-ventilated non-negative pressure room. Volunteers, who have previously completed a respirator fit test and were able to detect the bitter taste, were asked by a blinded test administrator to detect any bitterness while breathing by mouth for 7 min while the sample was nebulized continuously into the BADGER.To compare the efficacy of the BADGER without seal, nebulized Bitrex or saline was introduced while the drapes were lifted up both with and without suction. The time to bitter taste detection was recorded.Negative pressure with smoke tests. To visually assess the BADGER's ability to generate negative pressure, we conducted a series of smoke tests using ventilation smoke tubes (Grainger, Lake Forrest, IL) in a simulated hospital room at the University of Wisconsin-Madison Simulation Center (Fig. 4c,d) . The smoke test is a www.nature.com/scientificreports/ standardized test used to verify negative pressure in an enclosure (e.g., negative pressure room). White smoke generated by the smoke tube is easily visualized under standard room conditions. Smoke was introduced into the BADGER in the standard operating configuration. To simulate a non-invasive respiratory therapy, we placed a 10 L/min oxygen facemask on a high-fidelity mannequin, which was positioned in the BADGER with a semisealed enclosure. We simulated coughs by quickly compressing the mannequin's lungs (Fig. 4d) . The exterior of the BADGER was monitored by two observers to determine if there was smoke leakage. Sub-micrometer aerosol particle containment test. The ability of the BADGER to contain submicrometer aerosol particles was assessed by placing the BADGER into a secondary sealed enclosure. A controlled aerosol source atomizer (TSI model 3076) was placed inside the BAGER to simulate aerosol production. Aerosol particle concentrations are measured inside both the BADGER and the exterior enclosure (Fig. 5 ). Aerosol particles from the output of the atomizer were dried to a relative humidity (RH) < 10%. The total output aerosol concentration added to the BADGER was ca 1 × 10 6 particles/cm 3 at a flow rate of 2.6 L/min. Aerosols generated from the atomizer had a narrow size distribution from 10 to 300 nm, with a mean diameter of 65 nm. The secondary sealed enclosure (0.45 m 3 ) was purged continuously with particle free air at 16 L/min. Measurements of aerosol particles were made with a condensation particle counter (CPC, TSI model 3787) and a scanning electrical mobility spectrometer (SEMS, Brechtel model 2100). The CPC measures total aerosol particle concentration (particles/cm 3 ) for particles from 5 nm to > 3 µm. The CPC sample flow rate was 1.5 L/min. The SEMS measures aerosol concentration and size distribution for particles from 10 nm to 1.4 µm. The SEMS sample flow rate was 0.31 L/min and supplemented with an additional pump pull of 1.2 L/min to create a total flow of 1.5 L/min matching the CPC. All aerosol sampling lines were composed of stainless steel and black conductive tubing. Sampling lines to both the SEMS and CPC were approximately 2.5 m long. Sampling lines for the CPC and SEMS were plumbed with valves to enable each instrument to alternate sampling from either the BADGER or the outer enclosure. An aerosol source line from the atomizer was run into the center of the BADGER to enable introduction of a stable aerosol particle source. The default configuration of the BADGER in these tests included two AG7178 Bacterial/Viral filters connected in parallel to the vacuum source with a controllable flow rate. All hand-ports were sealed. The plastic drapes were installed in standard operation configuration.The standard experimental procedure followed these steps: (1) Purge the outer enclosure until a particle concentration of < 50 particles/cm 3 was measured in both the BADGER and the outer enclosure. (2) Start the 2.6 L/ min aerosol particle source flow into the BADGER and sample aerosols in both BADGER and outer enclosure until a stable signal is reached. (3) Shut off the aerosol source flow and record the particle decay in the BADGER and outer enclosure. (4) Repeat at different filter pump rates or box configurations. This procedure enables determination of the aerosol concentration ratio in the BADGER (N inner ) and the outer enclosure (N outer ), which was used to calculate the fraction of particles that were contained in the BADGER.Filter efficiency testing. The filter efficiency of aerosol particles was determined for several standard HEPA filter types as a function of flow rate through the filter. Aerosol particle concentrations and size distributions were measured with the SEMS. The inlet of the SEMS was connected to a dry scroll pump to vary sample flow rates through the filter from 1.5 to 25 L/min. The flow rate was measured with an in-line flow meter (TSI model 4143) downstream of the SEMS sampling point. Aerosol concentration and size distribution were first determined on laboratory room air prior to testing of each filter. Laboratory air particle concentrations were typically from 1000 to 2000 particles/cm 3 , with a mean diameter of 220 nm. Filters were connected to the SEMS inlet with black conductive tubing. Room air was sampled through the filter at multiple flow rates in order to determine the flow rate when particle breakthrough occurred for the filter. Filter efficiencies were determined Figure 5 . Diagram of the sub-micrometer aerosol particle containment test experimental setup. The BADGER device was fully enclosed in a sealed outer enclosure which was continually purged with particle-free air at 16 standard liter per minute (slpm) and had an open vent port to the room to maintain pressure in the outer enclosure near room pressure. The SEMS and CPC aerosol sampling instruments were valved so that they could independently switch between sampling either the outer enclosure or the BADGER. The AG7178 filter was also tested as a function of filter number (1 or 2) and filter arrangement (in series or in parallel). The need for approval and consent from the Institutional Research Board of the University of Wisconsin-Madison were waived because the study was considered a quality improvement project. Written permission to publish patient images in an open-access journal was obtained. Methods were performed in accordance with relevant guidelines and policies.Construction of the BADGER. A production version of the BADGER can be constructed from a variety of transparent or semi-transparent materials. Clear materials that are appropriate are acrylic (PMMA), polycarbonate (Lexan), PETG, or vinyl. Each material has advantages and disadvantages, as summarized in Table 1 .Although the shell of the BADGER should be built by facilities with appropriate tools such as a computer numerical control (CNC) router, laser cutter, or die/blade cut, it can also be built using a box cutter and a metal straightedge. Our systems were constructed from CNC routed polycarbonate. Polycarbonate is an extremely durable material. Although it is slightly softer and more prone to scratches than acrylic, it is more chemically stable and easier to clean. Generally, polycarbonate is slightly more costly than acrylic. However, the cost of raw materials for this shell is still very affordable (< $100 material cost/unit). The tapered shape of the BADGER also allows it to be stacked, making the units easier to store and ship. Manufacturers can easily scale up the production if demand is high. Technical support for manufacturing, open-source design drawings, and lists of materials are available at the University of Wisconsin-Madison's MakerSpace 29 .Our production version of the BADGER was constructed from polycarbonate material, which can be cleaned by completely wiping down with isopropyl alcohol or bleach-based cleaners. Proper cleaning solution for other materials are provided in Table 1 . The grommets can either be made of 3D printed plastic, which are regarded as single use, or an injectable molding process, which can be cleaned as the polycarbonate shell.tubing connected to a standard hospital room's in-wall vacuum suction source, we obtained a minimum outflow rate of 16.5 L/min when using 10 m length × 6 mm D tube connected to low suction (50 mmHg) without filter and 14.5 L/min with an AG7178 Bacterial/Viral filter. Both AG7178 and Ultipor 25 performed similarly in impeding air flow. The outflow rate increased to 32 L/min at high suction pressure (200 mmHg) with filter and topped out at 41 L/min at maximum suction pressure (700 mmHg). As expected, outflow rate increased as tube length decreased or increased tubing D. However, the relationship between tube length and suction pressure to outflow rate are not linear (Fig. 6a) . In the mixed setup, we obtained a total outflow rate of 28 L/min at 50 mmHg suction pressure and maximum outflow rate of 59.7 L/min at 700 mmHg.The BADGER contains Bitrex. When sealed off and suction applied at medium strength (100 mmHg) using the mixed setup to achieve approximately 39 L/min of outflow, the BADGER prevents nebulized Bitrex from leaking into the room, thus preventing 100% of blinded volunteers (n = 5) from detecting its bitter taste. When the drapes were lifted off and suction was turned off, all blinded volunteers were able to detect the taste in the Bitrex group (n = 3) in an average of 39 s, while none of the volunteers in the saline group detected bitter taste (n = 3). When the suction was turned on with the drapes lifted up, all blinded volunteers were able to detect the taste in the Bixtrex group (n = 3) in an average of 1 min 53 s (p = 0.0179 compared to sealed + suction, Fishers exact test). (Fig. 4b) . www.nature.com/scientificreports/ Negative pressure with smoke tests. A series of smoke tests were conducted to visually assess the BADGER's effectiveness in containing airborne particles by its negative pressure. In the first scenario, the mannequin was receiving 10 L/min of oxygen via a facemask. As smoke was introduced into the BADGER in the standard operating configuration without suction applied to the BADGER, there was visual leakage of smoke from under the drapes and from the hand-ports (Fig. 4c) . When suction was applied at medium strength (100 mmHg) to create an outflow rate of approximately 39 L/min, smoke was well contained inside the BADGER. When simulated coughs were performed by suddenly compressing the mannequin's lungs, the BADGER was able to contain smoke inside its chamber (Fig. 4d) . Five minutes after cessation of smoke generation, the BADGER was able to clear the visible smoke inside. For the well-sealed BADGER, greater than 90% of sub-micrometer particles generated in the BADGER were contained. (c) Measured aerosol particle filtration efficiency for the selection of filter substrates and combination of filters used in this study. The filtration efficiency test was conducted using aerosol particles present in the room, where the mean particle diameter was 220 nm. www.nature.com/scientificreports/ Sub-micrometer aerosol particle containment test. Results from a typical particle containment test (outflow rate of 13 L/min with filters) are shown in Fig. 6b , where sub-micrometer particle concentrations were measured in both the BADGER (red circles) and the exterior enclosure (black circles). In our experiment, particle concentrations in the BADGER approach steady-state following approximately 15 min, peaking at 1 × 10 4 particles/cm 3 , while particle concentrations in the outer enclosure peak at < 500 particles/cm 3 . To determine the fraction of particles contained by the BADGER, we model the time dependent particle concentrations in each box, constrained by the measured flow rates into and out of each enclosure and the time dependent change in particle concentrations during a typical experiment. We utilize both the steady-state concentrations and the rise and fall times in both enclosures to determine the leak rate of particles from the BADGER to the outer enclosure and the particle wall loss rate in the BADGER. Model results are shown with solid lines in Fig. 6b . Modelmeasurement agreement is achieved with a particle wall loss rate in the BADGER (k wall ) of 1 × 10 -4 s −1 and a leak rate of 1.5 L/min from the BADGER to the outer enclosure. Conservatively, we estimate the uncertainty in the leak rate to be between 500-2500 slpm, based on the regression of modeled and measured aerosol concentrations in the outer enclosure. This results in containment of 90 ± 6% of sub-micrometer particles generated in the BADGER for the select operating conditions tested here. Particle containment was equally effective over the range of particle sizes generated by the particle source (10-300 nm). The approach to steady-state is specific to the operation of the BADGER in our experiment, we expect that in a clinical setting, procedures could commence as soon as the patient is placed in the BADGER. Alternatively, based on the data collected, we expect the sub-micrometer aerosol particle concentration inside the BADGER to be equal to the external environment within fifteen minutes after particles are initially introduced. This suggests it is permissible to remove the containment device at least 15 min after the aerosol-introducing-procedure takes place.Filter efficiency testing. The filter efficiency of aerosol particles was determined for several standard particle filter types as a function of air flow rate through the filter. The three standard filter types were tested: (1) Ultipor 25, (2) Pall BB22-15, and (3) AG7178 Bacterial/Viral filters. AG7178 filter was also tested as a function of filter number (1 or 2) and filter arrangement (in-series or in-parallel). Full results of the filter efficiency testing are shown in Fig. 6c . Filter efficiency was greater than 90% at flow rates less than 18 L/min for all filter types except for the single AG7178 filter.In response to the pandemic, unanticipated PPE shortages and lack of understanding about the transmission and infectivity of the SARS-CoV-2 virus have created the need for new tools to reduce risk of healthcare provider exposure based on best available information. Moreover, there is evidence that current PPE might not provide adequate protection against infectious airborne particles 30 . Given the rapidly evolving situation, proof-of-principle devices have emerged to provide organizations with possible designs for combating the imminent challenges they are facing. Several physical barrier designs to protect healthcare providers during aerosol-generating activities have been developed. However, these devices largely limit protection to direct contact with larger droplets and lack proven efficacy 22 . The use of negative-pressure isolation rooms is important to ensure infectious agents do not spread through the surrounding environment. However, many hospitals are not adequately equipped to handle the surge in patients during a pandemic 31 . We designed, constructed, and tested a portable, affordable and easy to manufacture device (BADGER) which can contain aerosol particles produced by patients with respiratory infection, such as COVID-19. The BADGER utilizes negative pressure to prevent dispersion of aerosolized virus throughout the room, which could expose healthcare providers several hours later 32 . We have performed both qualitative and quantitative tests; all demonstrated its effectiveness in containing aerosol particles. In this study, the aerosol dispersion test was conducted at lower outflow rate (13 L/min) compared with the recommended minimum outflow rate of 19.2 L/min. Therefore, we expect that at higher outflow rates and for larger aerosol particles, which are more representative of patient-generated aerosol particle diameters, the containment ability will improve even more significantly.The results on the filter efficiency test indicated that filters, especially the AG7178 Bacterial/Viral filters, have reduced efficiency at a flow rate more than 18 L/min. Multiple filters should be used in parallel to achieve high flow rate while minimizing aerosol particle breakthrough on the filters. Although viral HEPA filters reduce flow rate by approximately 15% in our testing, they are essential components if the exhausted air is to be reintroduced into the surrounding environment. Moreover, exhausted air from hospital in-wall vacuum is released without being filtered for virus or bacteria (personal communication). Therefore, we recommend always using viral HEPA filters for exhaust air from the BADGER.The BADGER is designed to contain and evacuate aerosol particles at minimal outflow rate of twelve air changes of exhaust per hour. This will be particularly useful during aerosol-generating activities and procedures in compliant patients who can lie in the BADGER to reduce the risk of aerosol dispersion and transmission of respiratory infective particles to healthcare professionals and workers. As a result, institutional approval for clinical use has been granted by the University of Wisconsin Health System during this pandemic. We have used the BADGER in the perioperative period with the consent of patients and their families (Fig. 3D,E) . The box was appropriately positioned prior to induction of anesthesia, and direct laryngoscopy was performed on all cases. There were no complications and endotracheal positioning and intubation were confirmed by capnography. The BADGER remained in place for the duration of all the cases. At the end of the operations, the patients were extubated inside the BADGER and had uneventful post-operative courses. As there is more evidence of aerosolized SARS-CoV-2 from innocuous activities such as sneezing and coughing, and current standard PPE might not fully prevent exposure for healthcare providers, the BADGER might be an additional layer of protection to mitigate airborne transmission of COVID-19 11 www.nature.com/scientificreports/ There are several limitations of this study and of the BADGER. It is foreseeable that in situations involving a difficult or obstructed airway, the device could limit access to the patient. In this scenario, the device could be easily lifted up and removed to restore complete exposure. The clear polycarbonate material allows for easy visualization of the patient's airway by the anesthesia provider, and intubation could be performed by either direct laryngoscopy or videolaryngoscopy. However, the BADGER can still make procedures more difficult in critical situations. We recommend standardized, simulated training for those who will use this device before implementation in a clinical setting. We found that most users became very comfortable after 2-3 hand-on practices.The optimal effectiveness of the box to limit aerosol dispersion is dependent on operating conditions including the flow rate of the vacuum suction and negative pressure generated. We have not tested the BADGER using portable vacuum pumps. Since portable vacuum pumps might not have a pressure regulator, thus limiting our ability to control outflow rate and prevent filter damage, this might limit the use of the BADGER to the settings where an in-wall facility-generated vacuum suction course is available. We have not extensively tested the BADGER using all tubing sizes and filter configurations at different vacuum levels. Although ideal outflow rate Q for laminar, isothermal, non-compressible gas can be estimated based on the Hagen-Poiseuille equation : Q = πD 4 (P 1 −P 2 ) 128µL 33 , where D is the inner diameter of the tube, P 1 is atmospheric pressure, P 2 is vacuum pressure, L is total length of tubing and µ is dynamic viscosity of air at room temperature and atmospheric pressure (1.81 × 10 -5 Pa . s), we expected and confirmed that actual outflow rates are much lower. This is due to very high Reynolds number for high air flow rate indicating non-laminar flow and increases in Mach number at higher pressures due to compressible air [33] [34] [35] . Flow rate saturates for each tubing configuration at approximately 200 mmHg vacuum (Fig. 6a) indicating higher order compressibility and turbulent flow effects, which are not modeled by Hagen-Poiseuille, influence the response. In our experience, the mixed setup (2 HEPA filters, 1.8 m of ventilator tubing and 3.2 m of 7 mm diameter suction tubing) would provide good balance between outflow rate, filter efficiency and easy of setup.While the BADGER provides a relative negative pressure analogous to a negative pressure room, the negative pressure is minimal, and these results are preliminary and purely in simulated environments. It is possible that the fraction of sub-micrometer particles contained during aerosol-generating activities and procedures (e.g., sneezing, intubation) may decrease as there is a sudden pressure increase inside the BADGER or as it becomes less well-sealed. Further testing must be performed to determine aerosol containment and clearance in more clinically relevant scenarios, both simulated and real clinical settings. In the meantime, healthcare providers should maintain appropriate respiratory PPE usage according to their institutional protocols. Furthermore, it is possible that CO 2 levels in the BADGER could rise when a patient is inside. Since data on CO 2 emission rate from a person inside the BADGER is not available, we recommend maintaining adequate outflow rate and frequent monitoring of the patient's condition to avoid possible negative outcomes.In conclusion, we describe here an affordable and scalable device to contain and evacuate aerosols that has been shown to be effective in laboratory aerosol testing and screening Bitrex/smoke tests. The BADGER has also been shown to be safe in our limited clinical applications. With more improvement, the BADGER could become an important tool in our armamentarium in the fight against COVID-19 and future respiratory outbreaks.The datasets generated during and/or analyzed during the current study are available from the corresponding author on reasonable request. www.nature.com/scientificreports/ Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creat iveco mmons .org/licen ses/by/4.0/.",USA,first author,2021-02-04,02
8b1b20809e7800c5eab08975b4e939b1a3c1d298,Modeling the potential impact of indirect transmission on COVID-19 epidemic,"other existing model since we incorporated testing of both asymptomatic and 56 symptomatic individuals. In addition, our model is the first to use multiple transmission 57 routes to estimate the impact of indirect transmission on the peak, peak time, the 58 effective reproduction number and the epidemic final size. We focus our analysis on [24] . Similarly, on January 18, 2021, the city of 71 Toronto reported 583 newly confirmed cases, with 5 new deaths, resulting into 75,273 72 cumulative confirmed cases with 2,211 total COVID-19-related deaths, and 67,219 73 recovered cases [25] . In addition to cases transmitted through close contacts, several 74 evidences point to indirect transmission of COVID-19 in loblaw stores [20] and 75 Sobeys [21] , we present a SEIRVD model to study the effect of indirect transmission, number of the combined model is calculated using the next generational matrix 85 approach [26, 27] , and expressed as the sum of the effective reproduction numbers of 86 the direct transmission and that of indirect transmission pathways. Similarly, the final 87 size relation is estimated following the approaches in [28] [29] [30] . In addition, the The model diagram presented in Figure 1 is described by the system of non-linear which is the probability of the disease transmission from a contact between individuals 116 in S and the virus in the environment or contaminated surfaces V , and the number of 117 contacts per day per length.The parameter p 1 represents the proportion of susceptible individuals protected from 119 direct transmission as a result of effective mask usage, while p 2 is the proportion of 120 susceptible individuals protected from indirect transmission (i.e. through environmental 121 protection, such as sanitation, cleaning of surfaces and door handles, environmental 122 disinfection, fumigation and so on). Exposed individuals become infectious at a rate δ, 123 where a proportion r of these individuals are symptomatic, and the remaining (1 − r) 124 are asymptomatic. Asymptomatic individuals are tested at the rate γ A , where a 125 fraction α A become hospitalized, and the remaining 1 − α A are isolated. We believe 126 that asymptomatic individuals show mild or no symptoms, but a small proportion of 127 those tested who are more vulnerable could be hospitalized as a precautionary measure. 128 Hence our justification for assuming that a fraction α A of this population could be 129 hospitalized. Similarly, symptomatic individuals are tested at the rate γ S , where a 130 fraction α S become hospitalized, and the remaining 1 − α S are isolated. Asymptomatic, 131 symptomatic, hospitalized and isolated individuals recover from the disease at rates ρ A , 132 ρ S , ρ H and ρ W , respectively. In addition, symptomatic, hospitalized and isolated 133 individuals die at rates µ S , µ H , and µ W , respectively, ignoring deaths of asymptomatic 134 individuals since there are no available data. Table ( 1) is given as susceptible individuals that will be infected is reduced by p 1 (proportion protected from 157 direct transmission) and p 2 (proportion protected from indirect transmission), and the 158 reproduction number computed is called the effective reproduction number R e . Using 159 the next generation matrix approach [26, 27] as in [28] [29] [30] , we have the effective 160 reproduction number given asNote that N (0) = N since the total population is constant at all time. R e can also 162 be written asandThe expression for R e in equation (2) denotes the secondary infections contributed by 165 direct transmission R D and indirect transmission R I .The final size relation 167 The final epidemic size can be derived from the solution of the final size relation. This 168 relation gives an estimate of the total number of infections and the epidemic size for the 169 period of the epidemic using the parameters in the model [28, 31, 32] . Therefore, in order 170 to estimate the total number of cases and deaths, we use the approach in [28] [29] [30] to 171 derive the final size relation asEquation (5) implies S ∞ > 0. 2. If the outbreak begins through direct contact and no infected individuals 3. If the outbreak begins through direct and indirect contact and no infected 210 individuals (I A = I S = I H = I W = 0), the final size relation takes the formThe results of the parameter estimation as in Table 2 indicate that most reported 260 cases in Toronto from March to August are reportedly through direct transmission since 261 the estimated shedding rate for symptomatic individuals is very low with ω 2 = 0.025193 262 (see Table 2 ). This shows that based on our model outcome from March 1 to August 31, 263 January 26, 2021 10/26The reproduction number for stages I, II and III using Toronto 269 related scenario 270 In this section, we show the impact of the parameters estimated at different stages of 271 the epidemic on the reproduction number for Toronto scenario. Table 4 and 5 show 272 estimates of the reproduction number using three different stages for Toronto scenario. 273 In Table 4 the estimated parameter for the symptomatic shedding rate (ω 2 = 0.025193) 274 is used, while ω 2 = 0.5 is used in Table 5 for illustrative purpose. Other parameters 275 used are as given in Tables 2 and 3 . Here, we compare Tables 4 and 5 for when ω 2 = 0.025193 and ω 2 = 0.5, respectively. 277 We see from these tables that the impact of indirect transmission is lower in Toronto 278 due to lower amount of viruses being shed by symptomatic individuals (ω 2 = 0.025193). 279 Using Table 5 for illustration, we have that the reproduction number changing and 280 increasing when more viruses are being shed. For both tables, even though the 281 contribution of R D to the total R e seems higher than R I , the value of R e is still able 282 to increase with increase in ω 2 . The full description of how changes in ω 2 affects the 283 reproduction number R e is shown in Figure 5 . For both direct and indirect transmission, the reproduction numbers are highest in 285 stage I and lowest in stage III, which means that infection is highest in stage I. We can 286 interpret biologically that if interventions and control measures in stage I are kept the 287 same throughout the outbreak, the epidemic peak will be quickly reached within a 288 shorter peak time and with a higher reproduction number compared to other stages. Table 6 shows three different scenarios with initial conditions, and different estimates of 292 the number of symptomatic individuals. Table 6 are presented in Fig 3 and Table 6 and 305 Fig 4a) . The final size for this scenario is given as 207250. Table 6 . The parameters used are given in Tables 2 and 3 except for ω 2 = 0.5.For the scenario with V 0 = 5 and no infected individuals at the beginning (Scenario 307 2 in Table 6 respectively. In addition, the final size for this scenario is estimated as 15143, which is 313 lower than the final size in scenario 1. Table 6 . The parameters used are given in Tables 2 and 3 except for ω 2 = 0.5.The cumulative number of cases and prevalence of symptomatic individuals for the 315 scenario with a few infected individuals at the beginning of the epidemic and V 0 = 5 316 (Scenario 3 in Table 6 ) are shown in Figs 3c and 4c, respectively. This scenario is used 317 to model an instance where the epidemic starts with both transmission routes. Here, 318 there are about 60685 symptomatic individuals at the epidemic peak, which occurs at 319 day 83. For the case with only direct transmission, the epidemic peaked at day 84 with 320 38807 symptomatic individuals. The final size for this scenario is estimated as 219850, 321 which is the highest of all scenarios. 322 We observe from the results presented in this section that no matter where and how 323 the outbreak is starting, the case of direct and indirect transmission lead to more 324 infections (almost doubling) than that of only direct transmission. This is due to the 325 impact of indirect transmission which are not accounted for in the case with only direct 326 transmission. In addition, we notice that scenario 2 has the lowest peak size and the 327 same peak time. This is because there are no infected individuals in the population to 328 shed viruses at the beginning of the epidemic. Note that no matter where the epidemic 329 is starting (direct or indirect route for different scenarios), the disease is still able to 330 spread but with different peak. But all scenarios in Table 6 show that the epidemic is 331 much worse for scenario 3, i.e. the situation where the outbreak begins through direct 332 and indirect transmission routes. In addition, we observe from our model outcome that 333 the epidemic will reach its peak a day earlier (day 83) for direct and indirect 334 transmission if we have some infected individuals at the beginning of the outbreak as in 335 Scenarios 1 and 3. There seems to be no significant difference in the peak times of Here, we present contour plots of the final epidemic size and the effective reproduction 340 number with respect to ω 1 and ω 2 . The left panel of Fig 5 shows the final epidemic size 341 of our model plotted with respect to the shedding rates ω 1 and ω 2 (Figs 5a, 5c and 5e in 342 column 1). These figures are for parameters, interventions and control measures in 343 stages I, II, and III, respectively as given in Table 2 . We observe from these plots that 344 the shedding rate of asymptomatic individuals (ω 1 ) has no obvious effect on the final 345 epidemic size for the three stages. On the other hand, as one may expect, an increase in 346 the shedding rate of symptomatic individuals (ω 2 ) increases the final epidemic size for 347 all stages, especially for stage II since the data accounts for symptomatic individuals.The epidemic size is largest in stage I, reduced in stage II, and smallest in stage III.These results are shown in the first column of Figure 5 . 15  15  15  15  15  15   16  16  16  16  16  16   17  17  17  17  17  17   18  18  18  18  18  18   19  19  19  19  19  19   20  20  20  20  20  20   21  21  21  21  21  21   22  22  22  22  22  22   23  23  23  23  23 I, II, and III from  Table 2 , for the Toronto related scenario. Column 1 which consists of Figs 5a, 5c, and 5e are showing the effect of varying the shedding rates ω 1 and ω 2 on the final epidemic sizes for stages I, II, and III respectively, while column 2 which consist of Figs 5b, 5d, and 5f are showing the effect of varying the shedding rates ω 1 and ω 2 on the reproduction number R e stages I, II, and III respectively. Other parameters are as given in Tables 2 and 3 . Rows 1, 2 and 3 are for stages I, II and III, respectively.The right panel of Fig 5 shows the contour plots of the reproduction number R e 351 with respect to the shedding rates ω 1 and ω 2 (Figs 5b, 5d , and 5f in column 2) for 352 stages I, II, and III described in Table 2 . For all stages, we observe from these plots that 353 the reproduction number increases as ω 2 increases, and an increase in ω 1 has no obvious 354 effect, which is similar to the trend shown from the contour plots of the final epidemic 355 sizes (column 1). This shows the impact of shedding of viruses in increasing cases since 356 an increase in the value of ω 2 means that more viruses are shed by symptomatic including lockdown, social distancing, mask usage were kept as in stage III, in addition 369 to the effort to decrease indirect transmission by reducing the shedding rates, the 370 disease will quickly die out (as seen from the reproduction number in stage III with low 371 ω 1 and ω 2 ) and an increase in the final epidemic size will not be significant. In this section, we explore the effect of varying the indirect transmission rate β I and the 377 proportion of individuals protected from indirect transmission p 2 , on the final epidemic 378 size for stages I, II and III. In Fig 6, we present contour plots of the final epidemic size 379 with respect to the parameters β I and p 2 . Figs 6a, 6b, and 6c are for stages I, II and III, 380 respectively as given in Table 2 . Table 2 . Figs 6a, 6b, and 6c are for varying the indirect transmission rate β I and the proportion of individuals protected from indirect transmission p 2 , with ω 2 = 0.5 in stages I, II, and III, respectively. Other parameters are as given in Tables 2  and 3 .For all stages, we observe from these plots that the final epidemic size decreases as 382 p 2 increases, and increases as β 1 increases. This shows the role of environmental 383 protection in averting cases since an increase in the values of p 2 means that more people 384 are protected from contracting infections through indirect transmission, thereby 385 lowering the epidemic size as observed from the contour plots. On the other hand, an 386 increase in the values of β I implies that infections are transmitted through indirect 387 route at a higher rate, leading to a larger outbreak. In addition, we observe that stage 388 III (Fig 6c) has lowest final epidemic sizes, followed by stage II, while stage I has 389 highest final sizes. This means that if parameters and measures in stage III are 390 implemented during an outbreak, the disease is still able to spread but with a lower 391 final size when compared to other stages. We can biologically interpret that different 392 control measures, especially measures related to indirect transmission (like β I and p 2 ) 393 need to be implemented in order to curtail or eliminate the epidemic. Tables 2  and 3 . Figs 7a, 7b and 7c are for stages I, II, and III respectively.From these simulations, it is obvious that difference and changes in control measures 491 related to indirect transmission could cause changes in the peak size of the epidemic. In 492 fact, they also have significant effect on the time of the peak and the end of the epidemic. 493 This concludes the importance and effort needed to lower transmission occurring epidemic size. Our study shows that the shedding of viruses, especially by symptomatic 503 individuals has a huge effect on COVID-19 transmission, and efforts towards reducing 504 virus shedding will significantly reduce the epidemic. We show that the epidemic of 505 COVID-19 could be better curtailed when additional interventions relating to indirect 506 transmission are combined with the current control measures. We see that reducing the 507 shedding of SAR-CoV-2 to the minimum possible will reduce the peak, peak time, 508 effective reproduction number and the final epidemic size.",Canada,abstract,2021-02-01,02
957b4d2cc98bf6ada387dcaa953b0f4e097bbeb3,,". People above 65 years old were 5 to 13 times more likely to be hospitalized and 90 to 630 times more likely to die from the disease than individuals between the age of 18 and 29 years old(3). The oldest and most frail seniors require hours of daily assistance and many reside in long-term care facilities (LTCFs) where outbreaks of viral respiratory (influenza) and gastrointestinal tract infections (norovirus) are common (4) .SARS-CoV-2 transmission in LTCFs has also been reported worldwide, including in the United States (5), the Netherlands (6) and Canada (7) . SARS-CoV-2 outbreaks are more likely to happen in confined/crowded congregate living spaces like LTCFs, nursing homes and prisons than traditional living spaces (8, 9) . People living in LCTFs generally have limited mobility, live in close proximity to each other, and require close contact with care personnel, leading to increased number of potential transmission events.Knowledge of SARS-CoV-2 spread is incomplete and it is still not clear how the virus is transmitted in LTCFs, particularly when recommended infection prevention strategies appear to be properly applied. Public health organizations recognized respiratory droplets and aerosols as major transmission routes for the virus (10, 11) . Although SARS-CoV-2 virus preserves infectivity for days on various surfaces (12, 13) and in the air (14) , no specific report clearly supports that COVID-19 can be transmitted via fomites, and it is not considered to be the main route of transmission (15, 16) . On the other hand, it was suggested that aerosols (short or long distance transmission) could be involved in the transmission of COVID-19 (17) (18) (19) (20) (21) . Indeed, it was reported that coughing, sneezing, talking or even breathing can lead to emission of SARS virus aerosols in both respirable and inhalable sizes (22) (23) (24) . Aerosols from various sizes (inhalable, thoracic and respirable) can be produced and enter the respiratory tract (25) (26) (27) (28) (29) . Since both SARS-CoV-1 and SARS-CoV-2 are phylogenetically highly similar, it seems possible that COVID-19 may also be spread by small particle aerosols (30) . Nonetheless, it is not clear how the emission of SARS-CoV-2 aerosols is modulated in both symptomatic and asymptomatic infected people. It seems that the earlier stages of COVID-19 is associated with emission rates as high as 10 5 viral RNA copies per min (31) .Accurate information about airborne concentrations of SARS-CoV-2 is still sparse and no standardized or reference sampling and detection methods have been validated for this purpose (32) . Published reports have used various approaches of air and no-touch surface sampling but experimental parameters are sometimes ill-defined, such as particle sizes and concentrations, air sampling and downstream processing (type of sampler, sampled volume, nucleic acid purification, real-time reverse transcription polymerase chain reaction (RT-qPCR)), environmental parameters (high/low risk areas, air exchange rates, sampler position/location), and presence and type of aerosols generating procedures (AGP). In addition, the contribution to viral aerosolization of common interventions in LCTF such as the use of continuous positive airway pressure (CPAP) machines or toilet flushing were not described in the COVID literature, nor was the impact of poor ventilation. All these limitations and differences in experimental approaches complexify interpretation and makes it difficult to generalize published knowledge to long-term-care facilities (32) . Nonetheless, these studies report positive air 5 samples and no-touch surfaces in healthcare settings (≈8% to 100% positive) (31, (33) (34) (35) (36) (37) (38) , suggesting SARS-CoV-2 may be aerosolized in COVID-19 LCTFs.Other than control and prevention measures such as personal protective equipment (PPE) and personal hygiene, appropriate ventilation should limit the spread of COVID-19 (39) . de Man et al. reported that inadequate ventilation in a nursing home building led to an outbreak that stemmed from aerosol transmission of SARS-CoV-2 (40) . It was also stated in the press that broken ventilation (100% recirculation) could have allowed the aerosols to concentrate and spread in the building causing at least 200 cases and 64 deaths among the 236 residents (41) .This prospective study was conducted to determine air and no-touch surface contamination by SARS-CoV-2 in LCTFs with COVID-19 outbreaks during spring 2020. Air and no-touch surface samples were simultaneously taken in COVID-19 positive patients' rooms.Contributing factors to the presence of SARS-CoV-2 aerosols in these healthcare settings were investigated and the outbreak calendar was obtained after the sampling visits. This paper adds knowledge that could help to limit propagation of COVID-19 among resident and healthcare workers in LTCFs.Seven LTCFs in major cities of the province of Quebec were visited during spring 2020 on a convenience basis. The willingness of the establishments to allow sampling guided these choices. Rooms of patients diagnosed with COVID-19, placed under droplet/contact isolation precaution, and cohorted in a dedicated -red‖ zone, were sampled. These red zones were floors or wards hosting only positive residents. The LTCFs observed no visitors allowance policy as well as standard infection control practices. No Table 1 ). Since these are living environments, as opposed to hospitals and critical care settings, symptoms monitoring was not rigorous, and these data could not be reliably included in this article. Only the LTCFs II, III, and V had a central ventilation system with intake and extraction vents in the corridor, but not inside the rooms (Supplementary Table 1 A total of 93 samples from 31 rooms hosting a patient were included in this study. Three samples were collected simultaneously for each room, one air sample and two surface samples. Table 1 illustrates the number of rooms sampled for each LTCFs, as well as additional information regarding the number of days since diagnosis of the patient and the number of days since the first case was confirmed in the LTCF in comparison to the sampling date.Air sampling was performed using an IOM Multidust sampler (SKC, Eighty Four, PA, USA) loaded with a 3 m gelatin filter (Sartorius Stedim Biotech, Gottingen, Germany). The samplers were attached to a portable pump Gillian Air 5 (Gillian, Sensidyne, USA) and calibrated at 3 L/min. Sampling was performed for 4 hours (total volume of air=720 L). They were put on furniture, at least 1.5m above the ground and placed approximately 2m from the resident to limit the capture of droplets.Filters were eluted on the day of sampling and stored at -80 ˚C until RNA extraction. Gelatin filters were dropped in 900 µL of viral transport media (VTM) (Redoxica, Little Rock, USA) at 37 ˚C until complete dissolution (less than 5 minutes). The solution was also divided in 400 µL aliquots and frozen immediately at -80˚C.Two surfaces of approximately 10 cm 2 were sampled for each room using flocked swabs (Puritan, USA). Swabs were humected in 1mL of VTM (Redoxica, Little Rock, USA) prior to sampling. They were eluted in the remaining liquid after surface sampling. The swabbed surfaces were unfrequently cleaned. Most swabs took a very dark color from the dust they collected. The elution liquid was divided in 400 µL aliquots and froze at -80 ˚C until RNA extraction. The top of the door frame inside the room of the resident and the top of a shelving unit were sampled. These areas are located between 2 and 4 meters from resident if bedridden and are considered not touched or cleaned on a frequent basis, which would limit the inference of surface contamination by residents or workers and act as a proxy for viral propagation in the environment through air.The sample treatment and quantification were described in Dumont-Leblond et al (42) . Briefly, the 400 µL aliquots of each type of sample was directly extracted using the MagMAX Viral RNA Isolation Kit (Applied Biosystems, Vilnius, Lithuania), following the manufacturer's instructions. The final elution volume was of 50 µL. Purified RNA was immediately quantified by RT-qPCR.Extraction controls (no template controls) were performed for each extraction batch. Nominal variables were expressed with frequencies and percentage (%) and were analyzed using Fisher's exact test. Continuous variables were reported as mean ±SD and analyzed using Student's t-test. The normality assumption was verified with the Shapiro-Wilk tests on residuals from the statistical model. The Brown and Forsythe's variation of Levene's test statistic was used to verify the homogeneity of variances. A mixed model, looking into the number of genomic copies, was performed to compare the viral yield of sample swabs between shelving units and door frames. A first factor was linked to the comparison between doors and shelves and was analyzed as a repeated-measure factor with the use of a generalized covariance structure. The rooms were analyzed as a random factor.We used residual maximum likelihood as the method of estimation and the Kenward-Roger method to estimate denominator degrees of freedom for the tests of the fixed effect. The normality assumption was verified with the Shapiro-Wilk tests after a Cholesky factorization on residuals from the statistical model. The Brown and Forsythe's variation of Levene's test statistic was used to verify the homogeneity of variances. Statistical analyses were adjusted for the number of days since the diagnosis or the beginning of the outbreak. Data were log-transformed to respect these assumptions. The results were considered significant with p-values < 0.05. All analyses were conducted using the statistical package SAS v9.4 (SAS Institute Inc., Cary, NC, U.S.A.). The source of aerosolized particles that led to no-touch surfaces contamination could be the patients themselves through respiratory droplets generation. However, other mechanism may be involved such as aerosolization through fecal matter manipulation during diaper changes/flushing toilets (43) . In addition, virus found in settled dust on no-touch surfaces can be re-aerosolized in the environment and deposited elsewhere from a surface to another. Patient-emitted aerosols and re-aerosolized particles cannot be differentiated in this study.When they are present, airborne particles can be inhaled and the virus can reach the respiratory tract (44) . SARS-CoV-2 could not be detected in any of the air samples. The residents' room were sampled from 8 to 30 days after they were first diagnosed with COVID- 19 . Evidence suggests that replication-competent virus in mild disease decreases after the symptom onset and that transmission happens more frequently within 5 days since the first symptoms (45) (46) (47) (48) (49) (50) . Concentration of the virus RNA in the upper respiratory tract is also known to decline after symptoms onset (49) (50) (51) (52) (53) . The air sampling campaign might have missed the window of time in which aerosols were more highly present in the rooms due to stronger resident shedding. Since aerosolization from patients may mostly rely 13 on sporadic events such as cough, the relatively short sampling time (4 hours) might have missed these events. Also, the possibility of underestimation caused by viral degradation during the sampling process cannot be completely discarded. However, a similar methodology was deployed in actively ventilated hospital rooms where airborne particles were detected (42) . A combination of poor timing and viral degradation may explain the lack of detection of aerosols in the presence of the patients, even in poorly ventilated rooms.Currently no standardized protocols for the study of airborne SARS-CoV-2 have been proposed or validated, leading to limited ability to compare studies. The sample collection protocol in this work was guided by previous literature and expertise on the study of viral bioaerosols and on the very few published articles at the beginning of the pandemic (38, 42) . To date, a consensus regarding a reproducible air sampling approach has not been reached even considering the various studies published to date (32) . However, these slight variations may obscure our ability to compare results. The difficulty to rapidly deploy sampling teams in this context of outbreaks constitutes a major limitation to this study, since they might have missed the pic level of viral aerosol production and exposition risks.Epidemiological data reporting long-distance transmissions of COVID-19 have yet to be published. The level of contribution of the airborne route of transmission of SARS-CoV-2 is still to be defined and new models of a broader airborne model involving inhalable aerosols for SARS-CoV-2 transmission in low-risk health care settings is to be considered (32) . Cumulative data and positive air and no-touch surface samples found in healthcare facilities suggest that airborne transmission does not occur only for smaller aerosols, but that some larger particles normally classified as droplets can remain airborne and be transported inside building such as LTCFs (32) . In addition, contamination of no-touch surfaces likely involve larger particles or droplets given their ability to settle. In that context, improper ventilation could contribute to viral accumulation in these environments (32) . SARS-CoV-2 could not be detected in air samples from residents' room in 7 different LTCFs from 8 to 30 days after symptoms onset.However, viral genomes were recovered from settled dust on no-touch surfaces, suggesting viral dissemination in the environment through air had happened previous to sampling. This could be an indication of the importance of timing between the patients' stage of infection and air sampling deployment. The collaboration of LTCFs is deemed crucial in future work in order to access these establishments in a timely manner and to allow the collection of environmental data in the potential peak of exposition risks. The authors have no conflict of interest to disclose.",Canada,first author,2021-02-12,02
5f25531b94449fd04f025cc136b3ecbe6319a42a,Emotional responses to prosocial messages increase willingness to self- isolate during the COVID-19 pandemic,"In the span of just a few months, COVID-19 has ripped through almost every country, infecting 30 million people, killing close to a million individuals as of September 17th, 2020 (John Hopkins University, 2020), and severely crippling dozens of economies. Without a vaccine in hand, it seems that the virus can only be slowed by extreme behavioral change and societal coordination (Arenas et al., 2020) . Some countries, like South Korea, were quick to respond by instituting enforced quarantines and entreating citizens to practice social distancing (Beech, 2020; Fisher & Sang-Hun, 2020) . Other countries, like the United States and the United Kingdom, were reluctant to impose widespread shelter-in-place measures (The Associated Press, 2020). In the United States, for example, individual states began gradually issuing social isolation practices to combat the spread of the virus through the months of March and April of 2020 (Mervosh, Lu, & Swales, 2020) . In both cases, the countries hoped their citizens would readily comply with public health messages. Preliminary reports, however, show vast differences in people's willingness to practice measures that can reduce pathogen transmission (Lunn et al., 2020) .At present, public health advisors, such as the World Health Organization, argue that mitigating the spread of COVID-19 necessitates people swiftly adapt and change their usual habits to obey new social distancing measures (World Health Organization, 2020). Problematically, social distancing measures increase unemployment rates (Coibion, Gorodnichenko, & Weber, 2020) , influence work productivity, and acutely affect mental wellbeing (Kawohl & Nordt, 2020) . Thus, the actions needed to reduce the spread of COVID-19 are in direct opposition to functioning daily life. This poses a critical challenge for accomplishing extreme behavior change compliance, especially in such large populations.Decades of research show that emotional engagement is a critical component of behavior change (Bagozzi & Pieters, 1998; Cooper & Nisbet, 2016; Hartley & Phelps, 2010; Nabi, 2007; Perugini & Bagozzi, 2001) , which is why it is often employed in public health campaigns (Dillard and Nabi, 2006; Lang & Yegiyan, 2008; Nabi, 1999 Nabi, , 2002 Zeelenberg & Pieters, 2006) . However, the relationship between emotion and behavior change is not straightforward (O'Keefe, 2012) . For instance, tailoring messages to evoke a specific emotional response can backfire: When public service announcements about binge drinking evoke shame-rather than the intended guilt-vulnerable populations can increase their alcohol consumption (Duhachek, Agrawal, & Han, 2012) . Fear is also notoriously fickle in creating successful behavior change (Hastings, Stead, & Webb, 2004; Leventhal, 1970; Petty & Cacioppo, 1996) . Some research shows that only those most at risk for certain behaviors, such as drunk driving, are least responsive to messages with fearful language (Tay & Ozanne, 2002) . While widespread and rapid adoption of preventative measures is unlikely to occur without messages that include emotional appeals (Myers, Nisbet, Maibach, & Leiserowitz, 2012) , it is crucial that current public health officials and researchers understand the relationship between emotional engagement and different persuasive messages related to Despite the complexity of the relationship between emotion and behavior, some media outlets have been leveraging fear language in order to motivate people to stay home and socially distance. A recent article, for example, highlighted grim outcomes, staggering death tolls, and an inability for an overwhelmed health system to treat citizens (Pueyo, 2020) . There is good reason to specifically focus on fear related to COVID-19 (Feldman & Hart, 2015; Moser, 2010; Nisbet, 2009 ): Evoking fear can potently effect attitudes and behaviors (Tannenbaum et al., 2015) , likely because fear can enhance attention towards the message (Baron, 1994) and increase perceptions of threat (Leiserowitz, 2006) . However, the relationship between fear and disease prevention behaviors is not straightforward (Hastings et al., 2004) . A message that is perceived as too threating can cause people to engage in defensive avoidance, which leads them to disregard the message altogether (Janis & Feshbach, 1953) . Indeed, across a host of behaviors, a message that evokes too much (Janis & Feshbach, 1953; Krisher, Darley, & Darley, 1973) , too little (Boster & Mongeau, 1984; Witte & Allen, 2000) , or in some cases, any amount of fear at all (O'Neill & Nicholson-Cole, 2009 ), can fail to produce any noticeable behavioral change. Thus, while the use of fearful language is widely adopted as a means for behavior change, the evidence to date illustrates that its efficacy is variable (O'Keefe, 2012) .On the other hand, appeals that use prosocial rather than threatening language can play a potent role in the efficacy of public health campaigns (Lewis, Watson, White, & Tay, 2007) , serving as a distinct contrast to fear-based appeals. For example, describing prosocial actions that can lead to positive outcomes in the face of public health problems can produce positive emotions, such as hope or joy (Nabi et al., 2018; Ojala, 2012) , which can increase reception to the message by reframing the issue as being more personally relevant (Monahan, 1995) . Indeed, some recent research illustrates that prosocial public health messages that underscore behaviors linked to societal and communal benefits (e.g., help protect your fellow citizens)-rather than focusing on behaviors that only benefit the self (e.g., protect yourself)-may be an especially effective method (Kelly & Hornik, 2016; Li, Taylor, Atkins, Chapman, & Galvani, 2016) for communicating public health recommendations related to COVID-19 (Jordan, Yoeli, & Rand, 2020) .One additional difficulty in designing public health messages is the heterogeneity of emotional responses to interventions (Carey & Sarma, 2016) . Although typically outside the scope of public health research, characterizing how stable personality traits interact with emotional experiences can provide inroads for understanding the link between emotions and a message's efficacy. For example, the biological theory of personality explores how extraversion and neuroticism are linked with the body's physiological response (Eysenck & Eysenck, 1991) , and these traits generally correlate with positive and negative mood, respectively (Costa & McCrae, 1980; Rusting & Larsen, 1997) . Whereas neurotic tendencies are linked to increased emotional arousal (Haas, Constable, & Canli, 2008; Kehoe, Toomey, Balsters, & Bokde, 2012) , extraverts are less likely to be as reactive to arousing stimuli. When considered within the framework of public health messaging, this suggests that neuroticism, and not extroversion, may predict stronger arousal responses to emotionally evoking messages.Presently, it is unknown whether messages using threating or prosocial language are equally effective in promoting changes in willingness to self-isolate regarding COVID-19. Research on public health campaigns typically examine specific emotions (Nabi et al., 2018; Ojala, 2012; Tannenbaum et al., 2015; Witte & Allen, 2000) , but these approaches constrain a person's emotional experiences by limiting them to identifying with a set of discrete emotions pre-selected by the researcher. For example, asking how afraid one feels after reading a message imposes an emotional structure that the participant ""ought"" to feel afraid. Scaffolding the question in such a manner assumes that these emotional words are interpreted in similar ways across individuals, and may even influence how the very emotion is experienced (Kassam & Mendes, 2013) . Here, we circumvent these issues by using a model of emotion that avoids specific emotion states and partitions emotional experiences into a two dimensional space: the affective dimensions of valence (pleasurableness) and arousal (alertness/activation; Russell & Barrett, 1999) . Using this approach, we can characterize the heterogeneity in emotional responses to both threat and prosocial appeals related to COVID-19, and directly relate emotional engagement on the independent dimensions of valence and arousal to message efficacy. Given that past research suggests that the intensity of emotional engagement (i.e., arousal) increases learning, memory, and attention (Kensinger & Corkin, 2004; Reisberg & Heuer, 1992; Storbeck & Clore, 2008) , we posited that increases in emotional responses would result in greater compliance. However, because of the inconsistent relationship between evoked fear and behavioral change in prior research, we were agnostic as to whether stronger valence and arousal reactions to the threat intervention, compared to the prosocial intervention, would result in more willingness to self-isolate regarding COVID-19.On March 24th, 2020, we began recruitment through the online site Prolific to collect a representative United States sample (based on sex, age, and ethnicity; Prolific Team, 2019) of N = 1000. Because effect sizes of persuasion on behavior are highly variable, our study used a conservative estimate of the smallest effect size of interest (Lakens, 2017) . Using a lower equivalence bound of d = −0.10 and upper bound of d = 0.10, our study was well powered (87%) to detect effect sizes with a greater absolute magnitude than 0.1 with an alpha of 0.05. Participants received monetary compensation and provided informed consent in a manner approved by Brown University's Institutional Review Board. The experiment was conducted within a week of the COVID-19 infection reports in the United States reaching 10,000 (John Hopkins University, 2020). We only recruited U.S. participants to ensure that national messages and questionnaires specific to the United States would be relevant. For example, on March 13th, the White House released a proclamation declaring a national state of emergency related to the COVID-19 outbreak (The White House, 2020) and on March 16th, social distancing guidelines were issued in the United States (The White House & Centers for Disease Control and Prevention, 2020). Using the preregistered exclusion criterion that aimed to ensure high quality data, we excluded 45 individuals' data using a conservative measure of noncompliance based on instructions for an emotion classification task (see Measuring Emotional Experiences for a description of the task). This resulted in a final sample of 955 participants recruited between March 24th and March 26th, 2020 (506 females; age M = 44.8, SD = 15.9). Participants reported being 73.0% White, 13.4% Black, 4.4% East Asian, 3.9% Hispanic / Latinx, 2.1% South Asian, 1.6% Mixed Race, 0.4% Native American, 0.3% Middle Eastern, and 0.9% Other.Here we detail every measure that participants responded to, however, only the intervention measures, personality measures (BFI-2-S; Soto & John, 2017) and a questionnaire on COVID-19 preventative behaviors (e.g., ""I stayed at home"", which provided a baseline for COVID-19 self-isolation behavior), were analyzed for this experiment (all detailed below). All other measures were collected for another experiment, whose hypotheses and methods were preregistered on OSF (https://osf.io/y2uj6). All participants completed a series of tasks and questionnaires in the following order: an emotion classification task, a variety of self-report questionnaires with a randomly presented order including the emotion regulation questionnaire (Gross & John, 2003) , interpersonal regulation questionnaire (Williams, Morelli, Ong, & Zaki, 2018) , extraversion and neuroticism subscales of the Big Five Inventory-2-S (Soto & John, 2017) , intolerance of uncertainty (Carleton, Norton, & Asmundson, 2007) , and clinical measures of depression (Radloff, 1977) , anxiety (Spitzer, Kroenke, Williams, & Lowe, 2006) , and alexithymia (Bagby, Parker, & Taylor, 1994) , a questionnaire that assessed their knowledge of COVID-19, a fear intervention, questionnaires that assessed behavioral responses towards COVID-19, fear of COVID-19, media consumption of COVID-19, motives related to COVID-19 behaviors, social support related to COVID-19, information about work related to COVID-19, an altruism intervention, and demographics.In a within-subject design, participants were given two prompts we created in the following order: The threat intervention followed by the prosocial intervention. The threat intervention was inspired by a recent Medium article (Pueyo, 2020) that tapped into fear of COVID-19: ""The coronavirus is coming for you. When it does, your healthcare system will be overwhelmed. Your fellow citizens will be turned away at the hospital doors. Exhausted healthcare workers will break down. Millions will die. The only way to prevent this crisis is social distancing today."" This generated threat message contains two traditional components of threat appeals that emphasize: 1) the severity of the issue through negative consequences, and 2) the likelihood these consequences will occur to the reader (Dillard et al., 2016) .After reading this prompt, participants were asked three questions: (a) How does this statement make you feel? (responses recorded using a granular emotion measure, see details below); (b) On a scale from 0 (not at all) to 100 (completely), how willing are you to self-isolate?; (c) On a scale from 0 (no change) to 100 (a lot of change), how much does the previous statement change your willingness to self-isolate? In the second prompt (which was temporally spaced by multiple questionnaires in between), participants were given a prosocial intervention that was designed to be as similar as possible in structure to the threat prompt, but which emphasized prosocial actions: ""Help save our most vulnerable. Together, we can stop the coronavirus. Everyone's actions count, every single person can help to slow the crisis. We have the tools to solve this problem. Together, by self-isolating we can save millions of lives."" This prosocial message focused on internal efficacy (how the individual can take successful action to mitigate the spread of COVID-19) and response efficacy (emphasizing the effectiveness of the group working together; Hart & Feldman, 2014) . After this prompt, participants were again asked the three questions denoted above.After reading both the threat and prosocial appeals, participants reported their affective experiences using the dynamic Affective Representation Mapping (dARM) tool (a measure we have used in our work; (Heffner, Son, & FeldmanHall, under revision)), which was adapted from the affect grid used in past research (Russell, Weiss, & Mendelsohn, 1989) . This measure allows participants to rate their affective experiences on a subjective map where the horizontal axis characterizes an unpleasant-pleasant dimension (i.e., valence), and the vertical axis characterizes a low-high activation dimension (i.e., arousal). The dARM has a sampling resolution of 500 × 500 pixels, enabling us to measure fine-grained self-reports of both the valence and arousal dimensions without forcing discrete emotional labels on their experiences. To ensure participants were able to effectively use the dARM to rate their emotional experiences after appeals (""How does this statement make you feel?""), participants completed an emotion classification task at the beginning of the experiment. The emotional classification task asked participants to rate 20 canonical emotion words (e.g., angry, sad, happy) using the dARM measurement. Critically, participants were told where to rate a specific feeling, neutral, in the instructions as an attention check: ""The center of the square represents a neutral, average, everyday feeling. It is neither positive nor negative"". Our preregistered exclusion criterion was to remove participants who failed to rate neutral within a 100 × 100 pixel square around the center (N = 45/1000).We used linear mixed-effects regressions to predict participants' selfreported 1) willingness to self-isolate, and 2) change in willingness to self-isolate after reading the interventions. Predictor variables were participant's emotional ratings on the dARM, separated by the arousal and valence dimensions, as well as the type of intervention (threat/ prosocial). Separate regressions were run for predicting willingness to self-isolate (labeled ""willingness"") and change in willingness (labeled ""change""). For the personality analyses, we used separate linear mixedeffects regressions to predict participants' arousal and valence ratings as a function of the personality trait and intervention type. All regressions were run using the nlme package in R (Pinheiro et al., 2020) .To examine the effectiveness of the fear and prosocial interventions, we first examined current reported self-isolation behavior. We found that, on average, people reported staying at home 87.3% of the time because of COVID-19 (""I stayed home"" ranging from 0 -not at all to 100 -all the time). Although people's initial willingness was heavily skewed (skewness = −2.80) such that most people were already reporting engaging in self-isolationist measures, we can still examine whether the two interventions encouraged people to engage even more in self-isolation.To create a measure of each intervention's effectiveness, we subtracted reports of current self-isolation from reported willingness to self-isolate after reading the threat and prosocial interventions (both scales ranged from 0 to 100). Comparing intervention' scores to 0 (i.e., no effect of intervention) revealed that both the threat intervention (M = 6.44, SD = 15.41; t(954) = 12.92, p < .001; Cohen's d = 0.42) and prosocial intervention (M = 6.50, SD = 15.71; t(954) = 12.79, p < .001; Cohen's d = 0.41) increased willingness to self-isolate, confirming the efficacy of both interventions. Importantly, these results remain the same when we use an aggregate measure of all preventative COVID-19 behaviors, rather than a single item assessing willingness to stay home (threat Cohen's d = 0.31, prosocial Cohen's d = 0.30). We then examined whether the threat or prosocial intervention produced differences in people's reported willingness to self-isolate (termed ""willingness""; Fig. 1A ), as well as their reported change in self-isolation behavior after reading the intervention (termed ""change""). Although participants reported high levels of willingness to self-isolate after reading both the threat intervention (M = 93.75, SD = 12.96) and the prosocial intervention (M = 93.81, SD = 13.43), a paired sample t-test showed the two interventions did not produce significantly different reports of willingness (t(954) = 0.25, p = .81) or changes in self-isolation (t(954) = 0.17, p = .87). The correlation between willingness and change was significant for both the prosocial (r(953) = −0.07, p = .04) and threat interventions (r(953) = −0.07, p = .04). Together, these results illustrate that both prosocial and threat interventions nudged willingness to self-isolate in comparable ways to help mitigate the spread of the virus.While the interventions were similarly effective (Fig. 1A) , examining the emotional reactions to both interventions revealed they were associated with distinct emotional experiences. The average emotional response to the threat intervention was very unpleasant and highly arousing while the average emotional response to the prosocial intervention was fairly pleasant and moderately arousing (Fig. 1B) . The emotional responses to the threat intervention were heavily clustered in the upper-left corner of the dARM, indicating more homogeneity in emotional responses compared to the prosocial intervention responses. Formal tests comparing experienced arousal and valence between the two interventions revealed that the threat intervention was experienced as significantly more arousing (M = 115.46, SD = 126.60) than the prosocial intervention (M = 81.88, SD = 99.37; paired sample t (954) = 7.90, p < .001; Cohen's d = 0.26). Moreover, while the threat intervention was unsurprisingly significantly more negatively valenced (M = −158.67, SD = 94.28) than the prosocial intervention (M = 134.60, SD = 90.95; t(954) = −68.50, p < .001; Cohen's d = 2.22), it was critically experienced as more unpleasant than the prosocial intervention was experienced as pleasant (absolute value of valence, t(954) = 7.56, p < .001; Cohen's d = 0.24). This suggests that participants had a stronger emotional reaction on both dimensions to the threat intervention than the prosocial intervention.Given the heterogeneity of emotional responses to the two interventions (Fig. 1B) , we next examined whether personality traits known to predict positive and negative moods-extraversion and neuroticism, respectively (Costa & McCrae, 1980; Rusting & Larsen, 1997 )-explain the observed emotional variance. We found that neuroticism interacted with intervention type to predict increasing arousal (interaction β = −0.10 ± 0.03, p < .001) but not valence (interaction β = −0.02 ± 0.02, p = .52), and this was uniquely carried by the threat intervention (β = 0.07 ± 0.02, p = .004; prosocial intervention: β = −0.03 ± 0.02, p = .19). There was also an observed main effect of neuroticism predicting negative valence for both intervention types (threat β = −0.05 ± 0.02, p = .006; prosocial β = −0.06 ± 0.02, p < .001), suggesting that individuals higher in neuroticism generally experienced more negative emotions to the interventions. Although less predictive, extraversion also interacted with intervention type to predict increasing arousal in the opposite direction as neuroticism (interaction β = 0.06 ± 0.03, p = .02), and this was uniquely driven by the prosocial intervention (β = 0.05 ± 0.02, p = .04) and not the threat intervention (β = −0.01 ± 0.02, p = .56). Finally, we observed that greater extraversion predicted increasingly positive valence for the prosocial intervention (β = 0.06 ± 0.02, p = .001) but not the threat intervention (β = 0.02 ± 0.02, p = .31). However, because of a nonsignificant interaction between extraversion and intervention type predicting valence (interaction β = 0.04 ± 0.02, p = .10), these simple effects should be interpreted with caution.Examining how these emotional responses influenced willingness to self-isolate revealed that the strength of experienced arousal and valence was more associated with willingness to self-isolate for the prosocial intervention compared to the threat intervention (arousal: interaction β = 0.07 ± 0.03, p = .023; valence: interaction β = 0.16 ± 0.05, p < .001; Fig. 2) . Indeed, the fact that the simple effects of the threat intervention (dark red and dark purple lines in Fig. 2) were not significant suggests that the efficacy of the threat intervention does not rely on the strength of the emotional response, whereas the prosocial intervention does. A similar behavioral pattern was found for changes in self-isolation (Fig. 3) , where the effect of valence on behavior change was significantly higher for the prosocial intervention than the threat intervention (interaction β = 0.24 ± 0.06, p < .001). However, unlike before, the relationship between arousal and change was similar across both interventions (interaction β = 0.02 ± 0.04, p = .644), suggesting that increases in Intervention results. A) Self-isolation behavior after reading each intervention. Participants reported how willing they were to self-isolate from 0 (not at all) to 100 (completely) and how the intervention changed their willingness to self-isolate from 0 (no change) to 100 (a lot of change). Participants report similar levels of willingness and change in self-isolation to the prosocial and threat interventions. B). Emotional experiences after interventions. Participants reported how each intervention made them feel on the dynamic Affective Representation Mapping (dARM) measure, which simultaneously captures experienced valence and arousal at a granular level. Raw data has been plotted as transparent dots and the group averages are plotted below the intervention labels. All error bars are 95% confidence intervals (CIs).arousal for both interventions lead to more intention to change behavior.The effectiveness of public health messages is crucial for successfully combating large public health crises such as the COVID-19 pandemic. Problematically, the behaviors associated with preventing the spread of the virus are difficult to adhere to, as they include vigilant hand washing, donning facial masks, and most disruptively, practicing extreme social distancing measures. This makes it challenging for public health officials to create messages that are effective in motivating behavior change. Here, we explore how emotion shapes the efficacy of two different persuasive appeals, one that highlights threat and one that emphasizes prosociality. Unlike previous research that has found prosocial frames to be more effective than threat frames (Shen, 2011) , we find that both threat and prosocial messages were equally effective in stimulating willingness to engage in disease prevention health behaviors. However, while threat messages created a stronger emotional reaction (which were more negative and arousing) than the prosocial message, the efficacy of the threat intervention depended less on the strength of the emotional response compared to the prosocial intervention. In contrast, the prosocial message was more effective at boosting willingness to self-isolate if it produced a strong, positive, and arousing emotional response.These findings reveal that although threat and prosocial interventions were similarly successful in changing people's self-isolation intentions, they do not operate from the same emotional mechanisms. While successful prosocial messages depend on strong, positive emotional engagement, effective threat messages leveraging fear-mongering language are less reliant on the strength of emotional reactions. Given the lack of observable relationship between emotion and reported willingness to self-isolate in response to fear-mongering language, other mechanisms such as a negativity bias (Rozin & Royzman, 2001) , or selective attention to negative information (Carretié, Mercado, Tapia, & Hinojosa, 2001) , may subserve the efficacy of fear messaging. Moreover, because stronger negative emotional responses did not yield influence on willingness to self-isolate, designing a message with more Emotional experience predicts reported changes in self-isolation after prosocial intervention. Change in reported self-isolation is plotted for arousal and valence after reading the prosocial and threat interventions. Change has been normalized (standardized and mean-centered) while arousal and valence have been standardized without being mean-centered (as the 0 point on the scale reflects a neutral feeling). Lines represent regression fits and shaded areas reflect ± 1 standard errors (SEs).graphic and emotionally evocative language would likely not improve the success of a fear-mongering appeal, but it may increase the efficacy of prosocial messages. Since self-isolation and monetary hardship related to economic downturns can result in increases in depression and anxiety (Brooks et al., 2020) , changing behavior without resorting to fear-mongering tactics would be important for public health officials to consider when designing public service announcements. Indeed, it is possible that messages associated with positive emotions may help buffer against any unnecessary increases in clinical mood disorders. Simply put, in a situation which may already exacerbate anxiety and depression, messages that promote behavioral change while simultaneously appealing to positive emotions are needed now more than ever. However, the observed heterogeneity of emotional responses to these messages suggests a lingering challenge in fine-tuning the emotional language of either a threatening or prosocial message. Although exploratory in nature, we found evidence that two commonly measured personality traits, extraversion and neuroticism (Hamann & Canli, 2004 ) explain some of the emotional variance. Dovetailing with past research illustrating a link between positive and negative affect and extraversion and neuroticism, respectively (Canli, Sivers, Whitfield, Gotlib, & Gabrieli, 2002) , our results reveal that neuroticism uniquely mapped onto arousal for the threatening intervention while extraversion uniquely mapped onto arousal for the prosocial intervention. Furthermore, neuroticism and extraversion generally predicted negative and positive valence across the intervention types. Overall, this suggests that individuals high on neuroticism will respond more strongly to threat-based messages while extraverts will engage more with the prosocial ones. Although a clear limitation is that we did not examine the full spectrum of personality traits, these findings may help policy makers consider the type of public health message given the demographics of a specific population.It is worth noting, however, that participants in our studies were simply asked to report their willingness to change their behaviors. Research on message interventions illustrates that reported behavior change does not always coincide with actual behavior changes in the real world (Gibbons, Gerrard, Ouellette, & Burzette, 1998) . Although previous work has demonstrated that perceived message efficacy is a relatively good measure of actual effectiveness (Dillard, Shen, & Vail, 2007; Dillard, Weber, & Vail, 2007) , it will be important to confirm that these results generalize to actual COVID-19 related behaviors, where readers are being bombarded with many different messages and likely exhibit divided attention when consuming news or reading public health messages. Furthermore, it is also critical to highlight that, while the rapid transmission of COVID-19 is unfolding on a global scale, our sample was limited, by design, to the United States. As there are known cultural differences in how emotion is conceptually represented (Jackson et al., 2019) and expressed (Gendron, Roberson, van der Vyver, & Barrett, 2014) , caution should be taken when interpreting the widespread applicability of these results since findings may not translate cross-culturally. One additional limitation of the current design is that participants were given the threat message first, followed by the prosocial appeal. While future work should consider counterbalancing the messages, in general, fixed-order effects typically present minimal to no changes in results (Sauer, Auspurg, & Hinz, 2020) .As of the beginning of September 2020, the United States had still not achieved widespread compliance with social isolationist measures (Canipe, 2020; Fitzpatrick & DeSalvo, 2020) , despite repeated calls for citizens to shelter in place from specific States. To help speed the global goal of ""flattening the curve"" (Qualls et al., 2017) , governments and public health officials need to find the most effective messaging for stimulating behavioral compliance. While threat appeals to mobilize society during this time might be tempting to motivate behavioral compliance, we found that prosocial calls to action not only created more positive emotions, but they also elicited just as much willingness to self-isolate compared to deploying threatening language. Although these are preliminary results, it suggests that when collaborative efforts are needed to fight a global pandemic, interventions that appeal to prosocial sentiments might have more to gain than those that appeal to threats.Behavioral data and analysis script of the reported experiment are available at: https://github.com/jpheffne/covid_intervention. The authors declare no competing or conflict of interests.",United States of America,first author,2021-02-15,02
522c5a1b100e9f3d2b4b136919d615e6a11083a4,Journal Pre-proof Common hematological values predict unfavorable outcomes in hospitalized COVID-19 patients,"In December of 2019 in Wuhan, China, a respiratory illness caused by a new coronavirus (SARS-CoV-2) was described, giving place to a new syndrome known as COVID-19 (COronaVIrus Disease 2019) [1] , spreading rapidly and reaching pandemic dimensions by March, 2020 [2] . As of 1 January 2021, at least 81.9 million cases of (and 1.9 million deaths attributed to) COVID-19 had been reported globally [2] . In Mexico, 1.4 million confirmed cases and 126,851 deaths attributed to COVID-19 have occurred [3] . Most cases of COVID-19 are mild and self-limited, but progression to respiratory failure and death occur in up to a third of hospitalized patients [4, 5] .COVID-19 has strained healthcare availability, particularly in the developing world and underserved areas, pushing resources to the brink of saturation. A number of tests and stratifying scores have been proposed; however, most rely on laboratory tests that are not readily available in non-academic settings. Moreover, there is no consensus on which can predict unfavorable outcomes early after hospital admission [6] . In that context, inexpensive and readily available tools to predict progression are crucial for clinical decision-making and allocation of limited resources. We aimed to evaluate the usefulness of blood biomarkers taken at the time of hospital admission as early predictors of eventual need of ICU, mechanical 2. METHODS 2.1 Study design. An ambispective cohort study evaluating the strength of prediction by laboratory variables of unfavorable outcomes among hospitaladmitted COVID-19 patients.Patients from a single COVID-19-designated reference center in Mexico City admitted with a confirmatory real time polymerase chain reaction (RT-PCR) nasopharyngeal test for SARS-CoV-2 and a non-contrast chest CT scan compatible with COVID-19 pneumonia. All patients were tested on admission for circulating levels of C-reactive protein (CRP), ferritin, D-dimer, lactate dehydrogenase (LDH), creatinine kinase (CK), troponin I, complete blood counts (CBC), arterial blood gases, as well as liver and kidney function tests. All patients had a new electronic health record created upon arrival (unless one already existed for other medical reasons) which was updated on a daily basis until discharge, transfer to a different facility, or death, and was the source of information shown hereby.Review Board (NER-3632-21-21-1). All data was de-identified, such that data analyses used only individual identifier codes for each patient. All authors had access to the complete dataset.We included every admitted patient between 21 March and 30 April, 2020 that had a positive SARS-CoV-2 RT-PCR J o u r n a l P r e -p r o o f test. Thereafter, outcomes were updated up to 15 May. The primary outcome was a composite of the following: 1) mechanical ventilation; 2) admission to a critical care area; or, 3) death (whichever occurred first). Clinical and demographic variables registered on admission included: age; sex; dates of symptom onset and hospital arrival; vital signs (heart rate, temperature, respiratory rate, blood pressure, and oxygen saturation); presence of dyspnea, chest pain, and cough; body mass index (BMI); past medical history of diabetes and hypertension;percentage of lung parenchyma affected by CT scan as reported by the Department of Radiology [7, 8] . For analysis, inflammatory hematological indexes were calculated with values obtained from CBCs, including: absolute neutrophil count (cells/mm 3 ); absolute lymphocyte count (cells/mm 3 ); neutrophil:lymphocyte ratio (NLR: absolute neutrophil count/absolute lymphocyte count); derivedneutrophil index (absolute neutrophil count/[total white blood cell countabsolute neutrophil count]); and platelet:lymphocyte ratio (absolute platelet count/absolute lymphocyte count). We also included D-dimer, ferritin, LDH, CRP, CK, and troponin I. All were treated as continuous variables.We calculated crude incidence of the primary outcome, as well as of its composite parts. Standardized differences were calculated for clinical and laboratory variables between patients that had a primary outcome and those who did not.We used a multivariate Cox proportional hazard's model with each of the laboratory variables to estimate the hazard ratio of the primary outcome. All Cox models were adjusted for age, sex, BMI, presence of diabetes, presence of J o u r n a l P r e -p r o o f hypertension, and oxygen saturation at hospital arrival, as we hypothesized these were the variables that could have a causal effect or be surrogates of causal variables on the measured laboratory values. Pneumonia severity scores were not included in the risk models as most include variables that we are already controlled for. Laboratory variables were not adjusted for each other. Cubic splines with three nodes were used to transform laboratory continuous variables and include them in each model. We did not input missing data and thus each model had a slightly different number of patients included. A P value ≤ 0.05 was considered significant.Data analysis was performed with R software version 4.0.0. The script used for the analysis is available at https://github.com/isaac-nunez/hematol_val_covid19.Two hundred and eighty-two patients were hospitalized with a diagnosis of COVID-19 during the study period. Clinical, demographic and laboratory characteristics are described in Table 1 . All patients had symptoms on arrival to the Emergency Room. Patients who developed the primary outcome were significantly older and had a higher BMI, but had no differences in prevalence of diabetes or hypertension. Dyspnea, cough, and chest pain were also more common among patients who developed an outcome. Respiratory rate and other vital signs were also modestly higher in the outcome group. Oxygen saturation was lower among those that developed an outcome ( Table 1) .Among blood count values, total platelets, total leucocytes, total neutrophils, neutrophil-to-lymphocyte ratio, derived neutrophil index, and platelet-to-lymphocyte ratio were higher in the outcome group, while hemoglobin, total lymphocytes, total monocytes, and lymphocyte to monocyte ratio were lower in the outcome group.Inflammatory markers also were higher among those that developed an outcome.Of note, pneumonia score indexes were higher among patients who reached a primary outcome ( Table 1) .All patients completed follow up by 15 May, with 80 (28.3%) developing a primary outcome, of which 66 were admitted to the ICU and 14 died without having been admitted to an ICU. Median time to primary outcome was five days (IQR 3-7). Two hundred (71%) patients were discharged from our center during the study period after a median of 9 days of hospitalization (IQR 7-12).Univariate and multivariate Cox proportional hazard models are shown in Table 2 .The adjusted models are also presented graphically in Figure 1 . Lower NLR, derived neutrophil index, LDH, and CRP, as well as higher total lymphocyte counts showed a protective hazard ratio of achieving the primary outcome.Several inflammatory markers have been evaluated as predictors of mortality among hospitalized patients with severe [9] [10] [11] [12] , as well as non-severe COVID-19 [13] [14] [15] . Circulating levels of cytokines and inflammatory biomarkers have been J o u r n a l P r e -p r o o f shown to successfully predict severity [16] , but unfortunately these are not readily available outside of tertiary-care medical centers.Here, we observed that NLR, the derived neutrophil ratio, lymphocyte-monocyte ratio, total neutrophil count, as well as total lymphocyte count successfully predict outcomes at the moment of hospital admission for COVID-19.The NLR, lymphocyte-monocyte ratio, and platelet-lymphocyte ratio are thought to reflect physiologic stress. Stress leads to increased circulating cortisol, in turn triggering an increase in circulating neutrophils and a reduction in lymphocytes.Higher values of NLR, lymphocyte-monocyte ratio, and platelet-lymphocyte ratio are commonly seen in critically ill patients. As they are not specific to a particular disease, those indexes are not useful for diagnosing, but can guide in weighting the severity of a known an inflammatory illness [17] [18] [19] .NLR has been previously shown to predict in-hospital critical illness and mortality among COVID-19 patients [20] [21] [22] ; NLR has also been incorporated into prediction scores of critical illness or mortality [12, 23] . Lymphopenia has been described as a predictor of mortality in some models [24] [25] [26] ; accordingly, we observed that lymphopenia is a good predictor of the primary outcome even in the absence of other laboratory biomarkers. To our knowledge, the utility of the derived neutrophil index, as well as the lymphocyte-monocyte ratio -two easily computed indexes obtainable from a simple and widely available CBC-have not been previously shown to predict unfavorable outcomes.We observed that troponin I predicts worse outcome, probably reflecting myocardial injury. Myocardial injury has been linked to worse outcomes in other studies [26, 27] . Nonetheless, troponin I measurement should be judicious and limited to patients that have clinical characteristics compatible with myocarditis.Interestingly, D-dimer showed a U-shaped curve with lower risk of outcome in the range of 1000-2000 μg/mL compared with lower and higher values. CRP and LDH were not associated with the development of primary outcomes, with the exception of the extremely high (but rarely observed) values.We found a discrepancy between PaO 2 and SaO 2, with PaO 2 being paradoxically higher in the primary outcome group, while SaO 2 was higher in the group that did not develop an outcome. That may be explained by the moment in which those values were measured. Patients were frequently given supplementary O 2 prior to the arterial blood gas analysis. A PaO 2 /FiO 2 ratio analysis would be useful to confirm this, but unfortunately we lack accurate information on FiO 2 values on admission. In our context, ambient air SaO 2 is a more accurate value and thus is the one we included in the risk model.Our study has limitations. First, it is partly retrospective. Also, we aimed to evaluate the usefulness of markers individually, and we did not incorporate them into a score with other laboratory values. Additionally, we lack information on treatment prior to hospital admission, which could have modified certain laboratory values.We are underpowered to determine if individual markers convey the same information. This would require an additional analysis, such as principal component analysis, which is beyond the scope of the present work.This study also has strengths. Our sample is representative of Hispanic patients; also, ours is a public hospital; all patients had access to the best medical care regardless of their financial or insurance status. We had a very low rate of missing individual data; between-hospital transfers were exceedingly rare during the study period, such that if patients were discharged it is highly unlikely that they were sent to another hospital for critical care or further treatment. Also, discharges in general occurred after 72 hours of in-hospital clinical stability, and while clinical worsening after discharge could be possible, it is unlikely. This kind of analysis allows for easier comparisons between patients that present different values of a certain variable.In conclusion, here, we show that simple hematological markers measured on admission to the Emergency Room can accurately predict progression to critical illness and mortality in hospitalized patients with COVID-19.We would like to thank Dr. Reynerio Fagundo-Sierra for facilitating access to laboratory information. This work was supported by grants from CONACyT (Consejo Nacional de Ciencia y Tecnología) to SIVF (289788 and 311783). NEWS (n=276) 7 (5-8) 6.5 (5-8) 8 (6-9) <0.001 Hemoglobin (g/dL,n=265))",Mexico,first author,2021-02-04,02
c2de0f520cbf0173fcc65f932e460341c69bd56d,Sex differences in the mortality rate for coronavirus disease 2019 compared to other causes of death,"All rights reserved. No reuse allowed without permission.Next, we investigated whether the degree of the male disadvantage in the COVID-19 compared to the all-cause mortality varied by age group. To do so, we divided -separately by ten-year age group -the age-standardized male-to-female rate ratio for the COVID-19 mortality by the age-standardized male-tofemale rate ratio for all-cause mortality. Point estimates greater than one in Figure 2 , thus, indicate that the sex differences in the mortality rate for COVID-19 were greater than expected based on the sex differences in the all-cause mortality rate. We found that among the older age groups, especially the group aged 80 years and older, the higher rate of death for men than woman exceeded (in relative terms) that for all-cause mortality for most countries. Among younger age groups, especially those aged less than 50 years, the direction and magnitude of these differences varied greatly by country. These patterns are similar when adjusting these estimates for remaining life expectancy ( Figure S2 ).All rights reserved. No reuse allowed without permission.All rights reserved. No reuse allowed without permission.All rights reserved. No reuse allowed without permission.The degree to which men are more likely to die from COVID-19 than women is substantially larger than would be expected merely based on the fact that men are generally more likely to die at any given age than women. Thus, the probability of succumbing to a SARS-CoV-2 infection does not appear to be fully explained by the remaining life expectancy of the person who was infected. This observation suggests that the causal pathways that link male sex to a shorter life expectancy may not fully explain the unusually high male disadvantage in COVID-19 mortality. Our findings, therefore, lend support to hypotheses that posit that the causal pathways that link male sex to a higher mortality from a SARS-CoV-2 infection are specific to SARS-CoV-2 rather than shared with the pathways responsible for the shorter life expectancy among men than women or the causal pathways for sex differences for other common causes of death.This study has several limitations. First and foremost, this study can only provide suggestive (as opposed to conclusive) evidence as to whether or not the causal pathways underlying the male disadvantage for COVID-19 mortality are shared with those underlying the all-cause mortality disadvantage for men. Second, our mortality rate calculations for COVID-19 use the total population (by sex) as the denominator. Thus, the assumption underlying the validity of our calculation is that there are no substantial differences in the probability of being infected with SARS-CoV-2 between males and females. To date, evidence from seroprevalence studies suggests that this assumption is reasonable 17, 18 . An alternative approach is to use the number of identified cases of SARS-CoV-2 infections as the denominator (i.e., calculating the case fatality rate). This approach, however, assumes that the degree of underdetection of SARS-CoV-2 infections is the same among men as among women. This assumption would, for example, be violated if males are more likely to develop symptoms from a SARS-CoV-2 infection than females and are, therefore, more likely to seek out a COVID-19 test, or if men have better access to testing than women. Although both choices for the denominator (total population or number of cases) rely on untestable assumptions, our analyses in which we use the number of cases instead of the total population as denominator found that the choice of denominator does not substantially change our conclusions.Studies have hypothesized that the sex differences in COVID-19 mortality exist due to behavioral and social risk factors (e.g., higher incidence of smoking and drinking among men than women) that place men at a greater risk of mortality from health complications associated with COVID-19 [19] [20] [21] [22] [23] [24] . Other studies have cited a higher rate of comorbidities, such as diabetes and heart disease, as the reason for the higher COVID-19 fatality rate among men 4,25-28 . Finally, some studies suggest biological factors that may explain these disparities. One potential factor is a higher expression among men than women of the angiotensin-converting enzyme 2 receptor, which is used by SARS-CoV-2 to enter the host cell 3, 29, 30 . Other possible biological factors relate to immunological differences between males and females [31] [32] [33] . Ultimately a combination of biological, behavioral, and social pathways may be responsible for the high male disadvantage in COVID-19 mortality. Elucidating these causal chains is an important research area given that it may assist in the development of therapeutics and preventive measures for COVID-19 and future outbreaks of coronavirus diseases. All rights reserved. No reuse allowed without permission.",USA,first author,2021-02-26,02
5bbffc48dec3d268d655cebc17199d3abd7179e2,To appear in: Public Health,"The Severe Acute Respiratory Syndrome Coronavirus 2 (SARS-CoV-2) pandemic has more serious repercussions in vulnerable groups: older people with comorbidities, homeless people, pregnant women and ethnic minority groups [1] [2] [3] . There are more than 476 million indigenous people in the world, which represent around 6% of the worldwide population 4,5 , in Mexico it is 10% of the total population 6, 7 .Indigenous populations are frequently affected by various crises due to the economic and social conditions they live in. Their communities are usually isolated or poorly communicated, with poor access to health services. In many cases, such health services have little capacity and limited coverage, which may delays seeking medical attention, complicating early management, and therefore, leading to greater risks of complications and mortality. Health disparities have been documented among ethnic minority groups who have a higher prevalence of metabolic disorders, such as diabetes 8 .The living conditions of indigenous populations in Mexico could place them into a higher impact of SARS-CoV-2 epidemic. The number of deaths can be used as a key indicator of the trajectory of COVID-19 in our country [9] [10] [11] . Various studies have identified factors associated with lowerWe performed a longitudinal analysis using the public data of the COVID-19 information derived from the Epidemiological Surveillance System of Viral Respiratory Diseases of suspected cases identified by the Healthcare System in Mexico 16 . The study population included those cases with a positive diagnosis for SARS-CoV-2 certified by the Institute for Diagnosis and Epidemiological Reference (InDRE); from February 27, 2020, where the first case in the country was officially reported, until July 30, 2020 (n= 424,637).A suspected case was defined as a ""person of any age who had at least two of the following signs and symptoms in the last 7 days: cough, fever or headache accompanied by either dyspnea, arthralgias, myalgias, sore throat, rhinorrhea, conjunctivitis or chest pain"", and the confirmed case, was the suspected case with a diagnosis confirmed by the InDRE 17 .Fatality rate was defined as the ratio of the number of deaths, occurred within the cohort study of confirmed COVID-19 cases, divided by the person-time at risk. of the patient's condition at the time of seeking care. This variable was defined according to the type of management at diagnosis: a) outpatient management (OM); b) hospital management (HM); c) management in intensive care unit (ICU) and/or with intubation and assisted ventilation.Indigenous population was defined as all individual who declared to speak an indigenous language.We conducted a descriptive analysis of the indigenous and non-indigenous population according to their survival condition. The person-time of the fatality rate was expressed in person-weeks according to the date from the symptom onset until death. Statistical differences between the nonsurvivor indigenous people vs. non-survivor non-indigenous people were tested using the immediate two-sample proportion test for categorical variables and the non-parametric Mann Whitney U test for numerical variables.In order to investigate risk factors of COVID-19 fatality, the Hazard Ratio (HR) and 95%Confidence Interval (CI) were calculated using the multivariable Cox proportional hazards regression models stratified by management at diagnosis. For variables that did not meet the proportional risk assumption, an interaction with time was performed 18, 19 . From this multivariable model, we explored the statistical significance of three-way interaction terms (indigenous*sex*time, indigenous*age groups*time and indigenous*comorbid conditions*time).In order to improve comparability among the populations groups, associations of interest were people is concentrated (34% -Oaxaca, Chiapas, and Guerrero). We excluded 12,610 cases without indigenous language information. There were no statistically significant differences in age (60.6 vs. 61.7, respectively), sex (men 66.1% vs. 64.9%) and comorbidities conditions such as diabetes (37.7% and 38%, respectively), hypertension (42.5% vs. 43.8%), or chronic obstructive pulmonary disease (4.6% vs. 4.8%) between excluded vs. included individuals. All analyses were performed using Stata 14.1 and Graphpad Prism 8.2. All p-values were two-tailed, and a p-value <0.05 was considered statistically significant.The average age of non-survivors of the non-indigenous population with COVID-19 was 61.7 years old (SD 14.2) and more than half were in the 35-64 age range, compared to 63.3 years of age (SD 13.4), and almost half of them were 65 years or older, in the indigenous population. In both groups, the majority were men. Most comorbidities were more frequent in the non-survivors in both non-indigenous and indigenous population: hypertension (43.9% vs. 39.1%, respectively), diabetes (38.1% vs. 36.5%), obesity (24.7% vs. 25.6%, respectively), COPD (4.8% vs. 7.6%), immunosuppression (2.7% vs. 2.6%), cardiovascular disease (5.3% vs. 4.6%), chronic kidney disease (6.9% vs. 5.5%), and smoking (8.3% vs. 7.1%), except for obesity (24.7% vs. 25.6%, respectively), and asthma (with higher prevalence in indigenous non-survivors) ( Table 1) .Considering all comorbidities, 64.4% of the indigenous people who died had one metabolic comorbidity at least, compared to 66.6% of the non-indigenous people who died, the most prevalent ones in both groups were: diabetes + hypertension, hypertension and diabetes. (Table   J o u r n a l P r e -p r o o f 1). Regarding the initial medical management, the majority of survivors received OM, 80.5% of non-indigenous vs. 69.5% of indigenous people. A lower percentage of non-indigenous patients required hospitalization compared to indigenous (17.9% and 27.7%, respectively), as well as intensive care unit (ICU) and/or intubation (1.6% vs. 2.8%, respectively).Among non-survivors, the majority were hospitalized 69.2% of non-indigenous vs. 63.7% of indigenous people, followed by the ICU and/or intubation (19.6% of vs. 23%, respectively), and a lower percentage received OM (11.2% vs. 13.3%, respectively).The time from the symptom onset to seeking medical attention, as well as death was similar in indigenous and non-indigenous people. Finally, non-survivor indigenous people had an average time of 6.5 days (SD 7.2) from the beginning of hospitalization to death, compared to 7.7 days (SD 7.5) in non-indigenous people (Table 1) . When stratifying the analysis by type of management at diagnosis, we observed that the indigenous population had a higher crude fatality rate in both outpatients and hospitalized patients, compared to non-indigenous people. Furthermore, we observed a significant difference in outpatients, where the indigenous population had a crude fatality rate more than twice the rate among non-indigenous patients (6.0 vs. 2.6, respectively). These results were similar in the subgroup of the 13 states containing 89% of the total indigenous population (2.4 vs. 6.1, J o u r n a l P r e -p r o o f respectively) and in the South Pacific region (2.6 vs. 7.6, respectively). In addition, we observed differences in the time from symptom onset to seeking care (days) among non-indigenous outpatients and indigenous outpatients for the different regions, at the national level and in the 13 states we observed an average time of 4.2 days in non-indigenous vs. 3.9 in indigenous (p <0.01); however, in the South Pacific region, we observed that indigenous have a longer time seeking care compared to non-indigenous (4.5 vs. 4.2, p <0.001, respectively). Within the outpatient group, the men were the most affected ones, where indigenous people had a crude fatality rate of 132% more than non-indigenous people; when assessing age, indigenous people in the 35-64 age range had a crude fatality rate 119% higher than non-indigenous people of the same age group (Table 2) .Results from the Cox proportional hazards analysis showed that sex, age, and the presence of comorbidities (COPD, hypertension, obesity, diabetes, and chronic kidney disease) are associated with a higher COVID-19 fatality rate, both in outpatients and in hospitalized patients.Ethnicity was associated with a higher COVID-19 fatality rate in individuals with outpatient management, but not in individuals with hospital management, regardless of age, sex, and comorbidities. In outpatients, we found that being indigenous increases COVID- 19 In our data, after adjusting by sex, age and metabolic comorbidities, the fatality rate is particularly higher among indigenous outpatients than in non-indigenous outpatients, while the fatality rates in hospitalized patients (indigenous and non-indigenous) are the same, at the three regions in Mexico (national, 13 states and South Pacific region). Similar results were found in Georgia, USA, where fatality rate during hospitalization was similar between African-Americans and other ethnic groups 23 .When analyzing the differences in the prevalence of various comorbidities, it was found that nonsurvivor indigenous people had a higher frequency of comorbidities, being most affected by chronic and metabolic diseases, corresponding to the elevated prevalence of metabolic syndrome, central obesity, and hypertension in indigenous communities in Mexico 24 .Historically, the indigenous population has shown poor health indicators in high rates of morbidity, disability, and early mortality, which are related to their own social, environmental, geographic, and cultural conditions. Access barriers are well-known factors that affects health results of these communities 9, 10, 25 . Unfortunately, the dataset we used for this analysis is only a J o u r n a l P r e -p r o o f public administrative information, we acknowledge the dataset lacks variables that measure access to care precisely, so we used as proxy variable the time from the beginning of symptoms and seeking medical attention. Nonetheless, in our study, we did not observe differences between We were unable to evaluate these factors in our analysis, but we consider this should be evaluated in further studies.Despite the large volume of research on the pandemic, studies aimed at analyzing the association between ethnicity and COVID-19 are limited 30 . According to our knowledge, this is the first study in Mexico that analyzes COVID-19 fatality risk in the indigenous population. Although the number of national indigenous population screened for SARS-CoV-2 is small (n = 8,835), it was possible to establish that they have higher COVID-19 fatality rates. These results, however, should be interpreted with caution as the nature of the data does not allow to fully understand the phenomenon occurred in the indigenous population with COVID-19, and because of the observed underrepresentation as well.Overall, our findings suggest that COVID-19 fatality is adversely affecting the indigenous population, particularly patients who received initial outpatient care. In addition, comorbidity ",Mexico,abstract,2021-02-11,02
23bc8ed1ea98e0ac75712cae766a9fae03884001,Insights from Patterns of SARS-CoV-2 Immunoglobulin G Serology Test Results from a National,"T he severe acute respiratory syndrome coronavirus-2 (SARS-CoV-2) illness has spread rapidly as a global pandemic. Widespread, preexisting immunity was presumably lacking in the population upon initial virus infection. The first known case of coronavirus disease 2019 (COVID-19) caused by SARS-CoV-2 was identified in the United States in January 2020, 1 and a national public health emergency was declared on March 13, 2020. As of late July 2020, the pandemic has resulted in 4.3 million confirmed positive cases and likely more than 150,000 deaths in the United States. 2 Specific treatments for COVID-19 are being investigated and public health countermeasures, including social distancing, quarantine, and contact tracing, are being implemented. However, controlling the pandemic in the long term likely will depend on sufficient proportions of the population acquiring immunity to the virus, either through natural infection or immunization with an effective vaccine. Studies on identifying appropriate vaccine candidates and vaccine immunogenicity are progressing, 3, 4 but conclusive evidence of acquired immunity and corresponding serological correlates of protection from SARS-CoV-2 reinfection is currently limited. Such correlates require measurement of neutralizing antibodies and virus antigen-specific quantitative immunoglobulin G (IgG) levels. In the interim, the widely available qualitative detection of SARS-CoV-2specific IgG serves as the primary biomarker of the longer term adaptive immune response.Evidence from studies with small sample sizes from Asia, Europe, and the United States suggests that most immunocompetent individuals produce serum antibody responses to Quest Diagnostics, Secaucus, New Jersey, USA. SARS-CoV-2 infection. 5 Large-scale clinical and epidemiologic studies, along with studies on convalescent plasma and administration of monoclonal antibodies, are currently underway to assess serological responses following SARS-CoV-2 infection. 6 In the meantime, useful correlative insights can be gathered from available clinical testing data.In this study, the research team retrospectively analyzed results from SARS-CoV-2 IgG antibody testing and nucleic acid amplification testing (NAAT) performed at a large national clinical laboratory. The objectives were to (1) estimate the proportion of individuals with positive or negative NAAT results who had evidence of SARS-CoV-2 IgG and identify predictors of SARS-CoV-2 IgG positivity, among the individuals with paired specimens for NAAT and IgG testing; (2) evaluate the probability of persistent IgG seropositivity among those who had an initial positive IgG result, followed by subsequent IgG testing; (3) evaluate IgG antibody concordance of dual household members; and (4) identify the IgG serologic index case (adult or child) among household members.Results from SARS-CoV-2 NAAT and qualitative IgG tests performed at Quest Diagnostics through July 10, 2020, were included in the analysis. The NAAT testing was initiated on March 9 and qualitative IgG antibody testing was initiated on April 21. Results were excluded for patients who were <2 years of age at the time of testing. For the evaluation of within-household adult and child IgG results, the data inclusion period was extended to August 11, 2020. The SARS-CoV-2 NAAT and IgG antibody methods in use at Quest Diagnostics are designated by the US Food and Drug Administration (FDA) for Emergency Use Authorization (EUA). The ribonucleic acid (RNA) testing platforms include (1) Quest Diagnostics laboratory developed test; (2) cobas (Roche Molecular Systems, Inc., Pleasanton, CA); (3) Panther Fusion, (Hologic, Inc., Marlborough, MA); and (4) Aptima (Hologic, Inc.). The IgG antibody testing platforms include (1) Architect (Abbott Laboratories, Inc., Chicago, IL); (2) VITROS (Ortho-Clinical Diagnostics, Inc., Raritan, NJ); and to a limited extent, (3) the EUROIMMUN Anti-SARS-CoV-2 ELISA (IgG) (EUROIMMUN US Inc.). According to the manufacturer's instructions-for-use documents, each of these serology assays have specificities ‡99%. A comparative study of these methods demonstrated >97.5% qualitative concordance across assay platforms. 7 For paired specimens of NAAT and IgG with IgG collected after NAAT from individuals with multiple testing results over time, the date of the first positive result for each analyte was included in the analysis. When all serial NAAT results were negative, the earliest NAAT date was used for analysis; when all serial IgG tests were negative, the latest IgG test date was used.To assess persistence of IgG seropositivity, or loss of IgG (ie, ''seroreversion''), the research team evaluated results from individuals who had an initial positive IgG result followed by subsequent IgG testing. The first negative IgG result after an initial IgG positive result was defined as an event (seroreversion), and the last positive result (persistent seropositivity) was considered to be a censored observation in Kaplan-Meier product limit estimate. 8 For IgG serology analyses, household members were identified as being in the same household by having identical residential addresses. For concordance within a pair of individuals in the same household, 2 household members had to be tested within 2 days of each other; for identifying a serologic index case, the household adult (ages 18-64 years) and child (ages 2-17 years) had to have positive results within 30 days of each other, and the positive adult had to be at least 15 years older than the positive child.The Chronic Condition Indicator (CCI) was used to categorize chronic conditions for individuals with International Classification of Diseases, Tenth Revision codes assigned by the health care provider at the time of a SARS-CoV-2 laboratory order or in the prior 12 months for any test orders. CCI is a tool developed for clinical research as part of the Healthcare Cost and Utilization Project, a Federal-State-Industry partnership sponsored by the Agency for Healthcare Research and Quality. 9 The 5-state northeast (NE) area (New York, New Jersey, Rhode Island, Connecticut, and Massachusetts) was selected as a unit to represent a geographic area where community transmission of SARS-CoV-2 and confirmed COVID-19 illness was particularly prevalent during the March through May 2020 period.Chi-square tests were used to assess difference in proportions. Multivariate logistic regression modeling was built via stepwise selection procedure to predict IgG positivity as a function of NAAT status, sex, age, CCI, geographic area of collected specimens, and interval between NAAT and IgG serology testing. Data analyses were performed using SAS Studio 3.6 on SAS 9.4 (SAS Institute Inc., Cary, NC). Kaplan-Meier product limit estimate and survival plot were conducted in R Statistical Software (R Foundation for Statistical Computing, Vienna, Austria). 10 This Quest Diagnostics Health Trends report was deemed exempt by the Western Institutional Review Board.Results from 6,643,505 SARS-CoV-2 NAATs, performed on 6,006,609 individuals from March 9 to July 10, 2020, were included in the analysis. SARS-CoV-2 NAAT results were derived from individuals who resided in 96.9% ( IgG result, followed by subsequent IgG testing. The interval from the first positive result to the first subsequent negative IgG (event) or the last positive result (censored) was 1 to 77 days. Overall, of all individuals with subsequent IgG testing following an initial positive result, 4305 (90.2%) were persistently seropositive and 467 (9.8%) became seronegative over 77 days. The probability of persistent seropositivity declined over time, from 98.6% by the end of the first week to 74.3% by 2 months. Rates of persistent seropositivity did not differ by sex: 75.6% for females versus 72.7% for males by 2 months (P = .07). To assess associations of age with persistent seropositivity, individuals were categorized into 3 age groups: 3-34, 35-54, or ‡55 years. Beyond the first month, the probability of persistent seropositivity was significantly higher in patients ages ‡55 years than in younger groups (P < .0001) (Figure 1 ).Among 102,420 individuals with paired NAAT/IgG serology specimens with IgG collected after NAAT, 21,452 (20.9%) were positive and 80,968 (79.1%) were negative for SARS-CoV-2 by NAAT. CCIs were available for 14,770 (68.9%) of SARS-CoV-2 NAAT positive and 54,520 (67.3%) of NAAT negative individuals.Of individuals with positive NAAT results, 19,434 (90.6%) subsequently had positive IgG results; the mean time to serology testing after NAAT testing was 37.7 days (median 35, range 1-121). As shown in Figure 2 , IgG positivity increased from a low of 66.2% 1-7 days after a positive NAAT result and peaked at 22-28 days (94.2% positivity). Although positivity declined gradually over the following weeks, it remained above 86% through 99-121 days. Among the 5577 individuals with an IgG test 15-28 days after their initial positive NAAT result (the period during which humoral immune responses are expected to peak), a total of 5186 (93.0%) demonstrated IgG positivity.The rate of IgG positivity among NAAT-positive individuals was high overall but differed significantly with respect to age (greater in persons ‡35 years of age) and geographic area (higher in the 5-state NE area) ( Figure 3A ). There were no statistically significant differences by sex or by CCI.Among all NAAT-negative individuals, the overall rate of subsequent IgG positivity was 9.7% ( Figure 3B ). In this group, males had a higher IgG positivity rate, as did the younger age group, those from the 5-state NE area, and those without a CCI.Multivariate logistic regression (Table 1 ) demonstrated that among SARS-CoV-2 NAAT-positive individuals, IgG positivity was more likely among samples originating from the 5-state NE area and among those from individuals ‡35 years of age. Serology tests performed 22 to 121 days after NAAT positivity had a higher positivity rate than those performed within the first 21 days. In specimens from individuals who were NAAT negative, subsequent IgG positivity was more common in those originating from the 5-state NE area and males (Table 1) . A serology test performed ‡22 days after NAAT negativity was less likely to be positive than was a test performed within the first 3 weeks after NAAT negativity. There were marginal differences in IgG positivity by age group but no significant differences between those with or without a CCI, after controlling for other predictors. Separately, of a total of 349,528 individuals who had NAAT and IgG specimens collected on the same day, 8434 (2.4%) had positive NAAT results. Of these, 5619 (66.6%) were simultaneously positive for IgG. Of the 341,094 NAAT-negative individuals, 55,170 (16.2%) were simultaneously positive for IgG. In a multivariate logistic model (Table 2) , among SARS-CoV-2 NAAT-positive individuals, a simultaneous positive IgG result was more likely in individuals who were ‡35 years of age, were from the 5 NE states, or had ‡1 CCI. Among SARS-CoV-2 NAATnegative individuals, a simultaneously positive IgG result was more likely in those who were ‡35 years of age, were from the 5 NE states, had ‡1 CCI, or were male.Among the 134,791 pairs of individuals with the same address who were tested for SARS-CoV-2 IgG within 2 days of each other, 113,718 (84.4%) pairs were both negative, 10,314 (7.7%) were both positive, and 10,759 (8.0%) were discordant.Among the 4021 households with ‡1 IgG-positive child and ‡1 IgG-positive adult tested within 30 days of each other, the first adult and child tested positive at the same time in 2249 (55.9%) households; the adult had the first positive result in 1435 (35.7%); and the child had the first positive result in 337 (8.4%).The results of this study demonstrate a high rate of IgG seropositivity in individuals with previously detected SARS-CoV-2 RNA. However, a sizable portion of IgG positive patients can lose detectable IgG seropositivity over a period of weeks or months. In households with both an adult and child testing positive for IgG at different times, the adult tested positive first more often than the child.Based on analysis of testing volume distribution by counties, the geographic reach of Quest Diagnostics NAAT testing covers virtually the entire US population. The gap in counties not represented by testing (3%) with 0.1% of the United States population may represent those that had a lower test ordering frequency or had testing performed by other clinical laboratories. Alternatively, a low number of test requests also could represent infrequently suspected COVID-19 cases.SARS-CoV-2 NAAT testing is effective in identifying SARS-CoV-2 RNA from intact virus particles or, in many cases, nucleic acid remnant materials. 11 Typically, SARS-CoV-2 NAAT is positive a few days after infection initiation and persists for up to 2 weeks or sometimes longer. 11-13 A negative NAAT result from individuals who are actually infected could be caused by inadequate or improper specimen collection, specimen instability prior to testing, or presence of viral RNA below the level of detection by an assay platform.IgG antibody is usually detectable starting 1 to 3 weeks after symptom onset. 11 The presence of IgG positivity may suggest decreased viral infectiousness 14 and may provide immune protection for an undetermined period of time. 15 Depending on the timing of SARS-CoV-2 NAAT and IgG serology specimen collection, results can be simultaneously positive. This study shows that the number of simultaneous positive paired NAAT/IgG (349,528) is more than 3 times that of the paired NAAT/IgG with IgG collected after NAAT (102,420). Given that many COVID-19 patients are asymptomatic or mildly symptomatic and the precise time of exposure to an infectious individual is unknown, the dual ordering of NAAT and IgG serology suggests that many health care providers are simultaneously investigating the possibility of both past and present infection.When the timing of a serum specimen collection is appropriate, a negative SARS-CoV-2 IgG serology result is consistent with absence of prior infection or seroreversion and positive IgG serology is consistent with past infection or recent exposure when the NAAT result is also positive. This role expands the guidelines of the Infectious Disease Society of America, which support ''evaluation of patients with a high clinical suspicion for COVID-19 when molecular diagnostic testing is negative and at least two weeks have passed since symptom onset,'' because, often, the time of exposure or symptoms is unknown. 16 Factors associated with seropositivity consistently include age and residency in the NE area versus elsewhere in the United States. Sex and interval between NAAT and IgG serology are observed to be predictors when data are available and sample size is large. These observations regarding age and sex are consistent with those from other studies. 11 CCI may relate to severity of disease among those infected. However, in this study, CCI was not associated with the likelihood of seropositivity in sequentially collected NAAT and IgG specimens, after adjusting for the interval between NAAT and IgG serology and other potential predictors. First row is number of IgG positives and second row is the total number tested. ** P < .0001 from chi-square test for age and state. (B) First row is number of IgG positives and second row is the total number tested. ** P < .0001 from chi-square test for sex, state, and CCI. * P < .02 for age. CCI, chronic condition indicator; IgG, immunoglobin G; NAAT, nucleic acid amplification testing; SARS-CoV-2, severe acute respiratory syndrome coronavirus-2.Present study observations may corroborate the findings of Ibarrondo and colleagues, 17 who reported rapid decay of SARS-CoV-2 antibodies in patients with mostly mild illness. However, loss of detectable IgG seropositivity does not always mean loss of seroprotection to reinfection. For example, IgG antibodies near the assay detection level could represent false-negative results and/or biological variations in antibody levels. Further, patients who have lost detectable IgG may have a robust secondary immune response when reexposed because of immune system memory and cellular responses, which requires further evaluation. 18, 19 Nevertheless, antibody persistence often serves as an indication of protection. 20 Present study observations suggest that younger people, who are more likely to have mild disease, are losing detectable IgG antibody faster than older individuals. A possible explanation is that older people are more likely to have been exposed to other coronaviruses and SARS-CoV-2 triggers a strong amnestic immune response 19 or to have more severe COVID-19 disease. Long-term clinical and laboratory evaluations are needed to better define the immune response necessary for COVID-19 immune protection for patients of all ages.To the research team's knowledge, this is the first largescale report on SARS-CoV-2 IgG serology testing within households. A priori, the likelihood of demonstrating seropositivity for each household member should be the same 90.6% that was observed overall, if the risk of seropositivity was independent for each household member. This suggests that the statistical probability of IgG antibody positive concordance (positive/positive) is 82.1% (90.6% x 90.6%), the probability of discordance (positive/negative or negative/ positive) is 17.0% (2 x 90.6% x 9.4%), and the probability of negative concordance (after both with presumed infection) is 0.9% (9.4% x 9.4%). Thus, the observed household discordance rate of 8.0% is only half of what one would have expected on a statistical basis (8.0% versus 17.0%). This observation may have a similar underlying cause as was noted for the 5 NE states with higher rates of SARS-CoV-2 IgG seropositivity compared to the other states. High viral load and duration of exposure may account for this difference in the NE area and also may apply to the higher-than-expectation discordance rate within households.Finally, the research team evaluated both adult and child household members with IgG positivity within each age cohort. In most cases, both members of the pair tested positive at the same time. However, among pairs in which one member tested positive before the other, the adult was much more likely to test positive first. This suggests that adults are more likely to be infected prior to children in the same household, which is not surprising, as adults are more likely to work outside the home. However, it may be that children with milder disease than adults are less likely to demonstrate detectable seropositivity, or that children are more likely to display seroreversion if tested earlier. [20] [21] [22] Alternatively, adults may be more likely to be a person of concern based on an exposure or new symptoms. The role of contact tracing to identify secondary household members also must be considered. Of note, the findings of this study reflect a time frame when children were home from school because of school closures or summer recess; the analysis did not include the start of the academic year, when some school systems reopened with full-time classrooms or in a hybrid model.As an observational study of laboratory test orders and results, the main limitation is that the clinical course of illness and epidemiological history of exposure in the individuals tested were not available. Also, there is no knowledge of whether the testing (NAAT and serology) was performed for clinical care, screening, or public health surveillance activities. The primary strength of this investigation is the enormous scale of data from across the United States and the ability to link results longitudinally for individuals and within households.In the largest study to date of paired molecular diagnostic and subsequent serology tests for SARS-CoV-2, the research team found that 90.6% of individuals with NAAT-positivity subsequently had evidence of IgG antibody by qualitative testing using a laboratory-based FDA EUA platform. Of interest, 9.7% of those who tested negative for SARS-CoV-2 RNA NAAT subsequently tested positive for IgG. The results of simultaneous NAAT and IgG serology testing revealed IgG positivity in 66.6% of patients with positive NAAT results and in 16.2% of those with negative NAAT results. This observed IgG positivity is hopefully of clinical value, in that these patients likely represent diagnostic challenges to their physicians.The combined results of both tests can reveal if there is current infection or past exposure with an immune response. People are exposed at different viral loads and durations, and the immune response varies. Further, specimen collection events occur at different times relative to exposure and development of symptoms. The relatively high frequency of infection based only on a positive SARS-CoV-2 IgG antibody result creates challenges to understanding the dynamics affecting NAAT and IgG serology result interpretation. This uncertainty reinforces the position that maximal diagnostic utility is achieved when both a NAAT and a simultaneous or subsequent IgG serology test are performed on at-risk patients when exposure history is unknown. Notwithstanding the value of dual testing, caution is warranted in test interpretation given the variability in the human immune response, the limitations of testing highlighted in this study, and our collective expanding understanding of SARS-CoV-2.Prevalence of SARS-CoV-2 in the community in the NE states likely contributed to the higher seropositivity rate among NAAT-negative individuals in this region. Negative NAAT results in association with a positive IgG result may be related to timing and other factors. While interpretation of SARS-CoV-2 seropositivity is being addressed, this study provides support for SARS-CoV-2 antibody testing as a marker of subclinical or medically-attended infection, in both high-and low-prevalence areas of reported COVID-19 illness. Public health surveillance must incorporate the underlying expected seropositivity and seroreversion rates while evaluating community rates of infection.The presence of SARS-CoV-2 IgG in serum has not yet been confirmed to be immunologically protective against reinfection in humans. Studies are needed to address critical questions regarding the correlates of immunity to SARS-CoV-2 in those who are asymptomatically infected as well as those who have experienced symptomatic infection, individuals of all ages, vulnerable populations, and in special populations such as first responders, health care workers, pregnant women, and the Black non-Hispanic and Latinx populations.Drs. Kaufman, Meyer, and Wohlgemuth, and Ms. Chen had access to relevant aggregated study data and other information (such as study protocol, analytic plan and report, and validated data table) required to understand and report research findings. They take responsibility for the presentation and publication of the research findings, have been fully involved at all stages of publication and presentation development, and are willing to take public responsibility for all aspects of the work.",United States,abstract,2021-02-01,02
10721ea88cef747607d71fe3f8df2c456b82b19b,How effective was Newfoundland & Labrador's travel ban to prevent the spread of COVID-19? An agent-based analysis,"On March 11, 2020, WHO declared SARS-CoV-2 (COVID) a pandemic with 118,000 cases largely from four countries [1]; four months later, there were 28 million cases globally and 1.8 million new cases per week. [2] . Empirical evidence indicates that travel restrictions reduce the spread of diseases in general [3, 4] , and successful current real-life strategies for COVID include travel restriction as a crucial component. In China, travel restrictions imposed on January 23, 2020 resulted in a decrease of 515 to 39 travel-related cases in Wuhan just one week later [5] , and an estimated three-day delay of COVID arrival [6] . Continued travel restrictions in New Zealand, part of a broad intervention package, led to one of the lowest case numbers and mortalities worldwide [7] and effective community elimination of COVID by June 2020 [8] . Similarly, Australia utilized both international and internal travel restrictions, controlling both initial and subsequent waves [9] .Though seemingly effective at slowing COVID spread, the economic impact of travel restrictions is inconclusive, and mobility restrictions disproportionately impact poorer people [10] and workers in certain industries [11] . Further, travel restrictions may be legally controversial [12] and are only moderately effective unless implemented with other policies [13, 14] . Thus, it is important to understand the potential benefit of travel restrictions for individual regions.For the province of Newfoundland & Labrador (NL) in Canada, strict restrictions on travel from out-of-province, implemented May 2020, have contributed to low case counts. NL has a large tourism economy, with annual non-resident travellers (≈533,000 [15] ) exceeding the province's population (≈520,000 [16] ), as well as a large presence of rotational workers. Thus, there is considerable pressure to relax travel restrictions. While studies show that travel increases COVID spread, there is a reliance on models with ""potentially inappropriate assumptions"" [17] . We therefore use a granular agent-based simulation (ABS) of COVID spread in NL to estimate the effectiveness and appropriateness of NL's travel ban, finding that a small number of infected travellers can introduce new chains of transmission even with contact tracing, similar to documented case studies [18, 19] . This finding is particularly important in the presence of new COVID variants of concern (VOCs)-particularly the UK variant, estimated to be 56% more transmissible than pre-existing variants [20] -as demonstrated by a recent outbreak at a long-term care home in Barrie, Ontario, where contact with an international traveller by a staff member quickly led to the infection of 127 residents and at least 32 deaths [21] . morPOP models each individual in the population as a unique entity, allowing for individual behavioral, demographic, and health characteristics to be represented. Unique environments where people interact are represented: households, hospitals, schools, businesses, etc. Individuals have random community contacts in the CSDs where they live and work. Each individual has an infection status following the typical SIRD (susceptible, infectious, recovered, dead) model, with a latent asymptomatic infectious period after initial infection. During the simulation, individuals follow behavior patterns like being at home for a certain number of hours per day, going to work or school, observing physical distancing guidelines or not, and seeking medical care when infected. Visits to primary care physicians (assumed to be all in-person) and hospitals are captured, but use of advanced medical care (e.g., ventilators) is not.At each location visited by an individual, there is interaction with other individuals at the same location (household members, fellow students, fellow employees, etc.), and an individual's chance of becoming infected is determined by contact with infected individuals in each location and the nature of that contact. For example, contact in a household may be much more likely to result in infection than contact with a customer at a business. Individuals' health statuses are updated each simulated day, and the probability that a susceptible person j becomes infected on day n is calculated bywhere α ij is the Vancouver School of Economics (VSE) risk factor for the environment in which person i and person j have contact [23] ; t n ij is the time (in minutes) of contact between i and j on day n; b n ij is the rate of disease transmission between i and j per minute of contact; c n ij is indirect transmission between i and j; and I is the set of currently infected individuals.Travellers arrive to CSDs either singly or in travel parties at a rate determined by monthly travel volumes, and each travel party (including a travel party of size one) forms its own household. The entire travel party is assigned to a workplace in the CSD if the visit purpose is business, or is ""bubbled"" with another household in the CSD if the visit purpose is to visit friends/family. For other visit reasons, the traveller (or travel party) only has random community contacts with residents. After a pre-determined length of stay, travellers leave the simulation. Infected travellers count towards the province's infections while they are in the province, but not after they leave.Specific limitations of the current implementation of morPOP for NL-COVID, and whether they are likely to result in an under-or overestimation of infections, are in Table 1 .To assess the impact of the travel ban, we compare a baseline scenario of the travel ban in place with low, medium, and high values of travel volumes, traveller infection rates (θ), and traveller quarantine compliance rates ( Table 4 ). The impact of contact tracing on each scenario is examined by running each scenario with and without contact tracing, for a total of 56 scenarios.Daily contact tracing call capability 1932 calls/day Days after being infected that contact tracing begins (includes latent period, days with symptoms before getting tested, and turnaround time for test result) 9 days Number of days before symptom onset to contact trace 2 days Percent of non-medical-care seeking individuals that are contact-traced 50% Percent of known contacts that are successfully found and contacted 95% Percent of contacts outside home/work/school that an individual remembers 90% Number of employees for workplace to be small enough to be closed due to a single infection 10Per-minute disease transmission rates between age groups Reasonable low (0.03%), medium (0.1%), and high (1%) values for θ were chosen in consultation with NL Public Health, noting that a 1% infection rate was calculated at Toronto Pearson International Airport from September to November 2020 [32] . The medium (50%) and high (100%) travel volumes were similarly estimated at the time the travel ban was implemented. After the summer, St. John's International Airport in NL reported that travel volumes were in fact 10% of typical volumes. As the available travel volume data [29] is for non-resident travel only, 10% of total travel volumes is approximately 24% non-resident travel volumes, and thus, 24% travel volume is examined as the low travel volume scenario.The scenarios start on May 1 and simulate 100 days. An initial undetected five cases are present at the start of the simulation. Although NL had no detected cases on May 1, without full-scale population testing, it is reasonable to assume that there are a small number of existing infections that are asymptomatic or have sufficiently mild symptoms so as not to require hospitalization. Households are engaged a ""double bubble"", meaning that households have close contact with one other household, in accordance with NL's de-escalation protocol during the time period.Unlike most ABSs that struggle to capture large populations or that require lengthy computation times and memory, morPOP is written in C++ for computational speed and parallelization. Using a number of computational techniques specifically designed to speed up run times, morPOP simulated a single 100-day outbreak on the NL population of ≈ 520, 000 agents in on average 1.8min without travellers or contact tracing; 5min with travellers; and 8.3min with travellers and contact tracing. The difference in time is primarily due to dynamic memory allocation required by travellers and contact tracing. The model was parallelized with one simulation per processor and implemented on high-performance computing infrastructure provided by the Center for Health Informatics and Analytics (CHIA) at Memorial University. The specific infrastructure used was three Linux nodes, each with 32 cores (64 threads) and 256 GB RAM, allowing for 192 simulations to be run simultaneously. Thus, a run of 500 simulations requires ≈5-25 min, depending on the presence of travellers and contact tracing.Mean peak hospitalizations Travel volume θ = 0.03% θ = 0.1% θ = 1% θ = 0.03% θ = 0.1% θ = 1%Five hundred simulations were performed for each scenario. To assess the impact of contact tracing, we first analyze scenarios without contact tracing, followed by the same scenarios with contact tracing.In the baseline (travel ban) scenario, the number of infections reaches 0 in late June, while all other scenarios show exponential increase (Figure 2, top) . Travellers' quarantine compliance does not have a large impact on community disease spread; once infected travellers initiate community disease spread, exponential growth of infections begins. Travel volumes, however, significantly impact disease spread, with 1% infected travellers yielding such high numbers of cases that the figure had to be plotted on a different scale. Table 5 indicates the magnitude increase in mean total cases and hospitalizations over baseline for each scenario, again illustrating that quarantine compliance impacts total cases far less than travel volume and infection rate. Because mean and confidence interval plots like those in active case plots of Figure 2 (top) obscure simulation outcomes that are much larger than the mean (e.g., super-spreader events), simulation outcomes are better illustrated by examining the probability that metrics exceed thresholds. The other rows in Figure 2 illustrate the probability that the peak number of cases, total cases, deaths, and hospitalizations exceeds the threshold in the x-axis. In all metrics, for a fixed rate of infection, the probability of increasingly worse outcomes increases as the travel volume increases and rate of compliance declines. As the rate of infection increases, the outcomes all worsen dramatically, particularly as the rate of infection grows to 1%.Contact tracing is highly effective at reducing disease spread (Figure 3 ), but the predictions of daily active COVID cases still exhibit exponential growth even in the best-case scenario of 24% travel volume, θ = 0.03%, and high quarantine compliance. The number of cases is still determined much more by travel volume and traveller infection rate rather than compliance, and contact tracing is insufficient to stop community spread from travellers (Table 6) , which also results in significantly more hospitalizations than with the travel ban in place.Travel restrictions may be lessened with screening, however, allowing more travel means an increase in imported cases given the potential for false negatives [33] [34] [35] , especially for asymptomatic and pre-symptomatic cases that may comprise close to half of infected travellers [36] . As demonstrated, the potential for a failure to contain COVID is high even with few infected travellers in the community, so any policy to reduce quarantine requirements must be carefully investigated with detailed knowledge of travellers' points of origin and likely infection rates; however, such information is difficult to ascertain given potentially convoluted travel paths.Thus, the morPOP simulation model indicates that the travel ban provided significant protection to the NL population. With more transmissible VOCs recently discovered, the importance of preventing imported cases from travellers is even more critical than the model results suggest.",Canada,first author,2021-02-08,02
d2d5ae88dd03827740d1db3f3c109704f313520d,Rapid vaccination and early reactive partial lockdown will minimize deaths from emerging 4 highly contagious SARS-CoV-2 variants 5 6,"The COVID-19 pandemic is a profound tragedy that has resulted in widespread death and 44 high morbidity. 1 Its social impact has also been devastating with recurrent lockdown resulting in 45 economic loss and psychological damage, particularly among children who are being deprived of 46 in-person schooling. 2-4 47 Accordingly, recently initiated COVID-19 vaccination programs have public health and 48 societal goals. Vaccine allocation strategies are intended to prevent the largest numbers of 49 cumulative deaths, as well as high peaks in hospitalizations to avoid collapse of healthcare 50 systems. 5 Because a moderate proportion of infected people develops debilitating long-term 51 symptoms, limiting cumulative case numbers is also a priority. 6 52Similarly, "" ""'( is the case threshold (two-week number of diagnosed cases per 100,000 123 people) which triggers reopening during which ! ! gradually decreases (at 10% every two weeks) 124 from ! %& to ! ""'( in the 3 younger cohorts (! ""'( +0.2 in seniors). We test 20, 60 and 100 as 125 possible values for "" ""'( . Unless otherwise noted, the level of social distancing after a period of 126 societal reopening (! ""'( ) is maintained at 0.2 to capture persistent behaviors such as masking, 127 working from home and avoidance of large social gatherings, which inherently limit the number 128 of interpersonal contacts relative to pre-pandemic levels. considerably if VE )*)+ is low, but its values has also not been measured. 31 Moreover, the 138 efficacy of the Pfizer and Moderna vaccines against new variants remain unknown. The efficacy 139 of the Novavax and Johnson and Johnson products were 90% and 69% against the consensus 140 variant but were less effective against the South Africa B.1351 lineage. 37, 38 We therefore 141 consider low (0.1), medium (0.5) and high (0.9) values for each of the vaccine efficacies. 142 A final variable is the vaccination rate, +. We use a range of possible rates intended to 143 capture national goals (~3400 people vaccinated per day 7 ) and more aggressive state level goals 144 (~8000 people vaccinated per day 39 ) extrapolated to King County. Under all scenarios, we 145 assume current local policy prioritizing seniors by allocating 80% of initial vaccines doses to the 146 elderly cohort until the maximum coverage of 80% among this cohort is reached (Supp Fig 1c) . 147 148 Sensitivity analysis. We performed a global sensitivity analysis under a full factorial design of 149 six input variables (Table 1) , including two of the described parameters governing social 150 distancing ("" ""#$ , "" ""'( ), the three parameters describing vaccine efficacy (,-3435 , ,-367% , and 151 ,-89: ), and vaccination rollout rate r, resulting in 3888 vaccination implementation scenarios. 152We sought to determine which variables carried the most significant impact on COVID-19 153 related outcomes during 2021 including peak and cumulative infections, diagnosed cases, 154 hospitalization and deaths, as well as total days under partial lockdown (defined by ! ! =0.6 in 3 155 younger cohorts and ! ! =0.8 in the elderly) and average value for ! ! during 2021. We calculated 156Spearman's rank-order correlation, a nonparametric measure assuming monotonicity but not 157 linearity, among outcomes as well as between outcomes and variables. 158 190 Reduction in COVID-19 infections and deaths due to a low case threshold for triggering 191 partial lockdown. The case threshold for triggering partial lockdown ("" ""#$ ) correlated with all 192 outcomes related to infections, hospitalizations and deaths (Fig 1a) : assuming a vaccine with 193 high efficacy against infection (VESUSC=90%, VESYMP=10%, VEINF=10%) and with national 194 target vaccination rates (3500 per day), a low case threshold for triggering partial lockdown 195 ("" ""#$ =200) would substantially limit number of diagnosed cases, infections, hospitalizations 196 and deaths associated with the current third wave (Fig 1b, blue line) . 197("" ""'( ) partial lockdown. Lowering "" ""#$ reduces infections, hospitalizations and deaths, but 210The scenario associated with "" ""#$ =350 (Fig 1b, vaccination occurs in the context of fewer susceptible people, partial herd immunity is projected 228 and a delayed and blunted fourth wave is predicted, despite the predominance of the B.1.1.7 229 variant (Fig 1b) . 230Key findings are that 1) decreasing "" ""#$ by several hundred cases may lower total 349 infections during 2021 by several hundred thousand and total deaths by several hundred, 2) 350 decreasing "" ""#$ by several hundred cases may increase total days under lockdown during 2021 351 by over a month (though approximately 100 of the total reported days under partial lockdown 352 have already been accrued during the third ongoing wave), 3) increasing the vaccination rate by 353 several thousand people per day may lower total infections by more than one hundred thousand, 354 total deaths by more than one hundred, and days under lockdown by two months, 4) increasing 355 the vaccination rate lowers cases and deaths under all scenarios, 5) increasing the vaccination 356 rate lowers total days under partial lockdown most significantly when "" ""#$ is low, 6) while 357 equivalent trends are noted across all four vaccine efficacies, high VESUSC rather than VESYMP 358 results in fewer infections but only slightly fewer deaths at equivalent "" ""#$ and vaccination rate, 359 and 7) higher vaccine efficacy (either against infection or symptoms) also results in fewer 360 infections and deaths at equivalent "" ""#$ and vaccination rates. 361 362Increasing variant infectivity to 75% resulted in a more severe fourth wave which could be 367 dampened but not prevented with more rapid vaccination (Fig 4b) Higher vaccination rate delays the fourth wave and lowers cumulative infection and peak death. 378All simulations assume VESUSC=90% / VESYMP=10% / VEINF=10%, "" ""#$ =350. and "" ""'( =25 379We again noted that increased vaccination decreased cases and deaths under both scenarios. 395Rapid vaccination will have the greatest absolute benefit in states such as Hawaii, 410Vermont, Washington and Oregon that have maintained lower overall seroprevalence to date. 411These states often employed more rapid triggering of partial lockdown during recent waves of 412 SARS-CoV-2 infection. Because a higher proportion of people are still susceptible in these 413 states, they are particularly vulnerable to contagious variant strains. A larger percentage of 414 people will in turn need to be vaccinated to reach herd immunity. Aside from lowering 415 infections, hospitalizations and deaths, more rapid vaccination will also decrease the total 416 number of days under partial lockdown. 417Our simulations suggest that lowering the case threshold for partial lockdown will most 428 significantly decrease the number of total infections in 2021 if coupled with a high vaccination 429 rate. This is because the high infectivity of B.1.1.7 and other emerging variants will make fourth 430 waves severe, even if partial lockdown is initiated relatively early. The current harrowing 431 experiences in London and Manaus are consistent this projection. Lowering the case threshold 432 for partial lockdown will decrease total deaths under all scenarios assuming high efficacy 433 vaccines because this strategy will allow more time to vaccinate the elderly. 434Finally, we project a 2 to 3-month delay until new variant cases surge. This is based on 493 the fact that among sequenced viruses in the United States, new variants appear relatively 494 uncommon at this stage representing fewer than 0.5% of sequenced viruses. 18 However, if 495 current estimates are misleadingly low, then a wave of infections can be expected sooner when a 496 lower proportion of the population has been vaccinated and/or infected. 497In conclusion, we project that despite considerable uncertainty about the timing and 498 severity of variant waves in the United States, rapid vaccine distribution and low case threshold 499 for triggering partial lockdown are the two critical components to save the most lives. 500Our mathematical model is an extension of an SIR model in which each state variable (or 510 compartment) can be stratified by age (4 compartments, children <20, young adults 20-40, adults 511 40-70, and seniors >70), vaccine status (yes or no), and infecting strain (current or B117 strain). 512Thus, state variables are tensors 4(5, ,, 7) with dimensions for age group, vaccine status, and 513 infecting strain. We include compartments for susceptible, exposed, pre-symptomatic, 514 asymptomatic, symptomatic, hospitalized, and deceased. We also include separate compartments 515 for diagnosed cases of each infected type both for the original model fitting to cases but also 516 because diagnosed cases may behave differently from individuals who do not know their To attempt to accurately model societal or governmental responses to pandemic surges, 531 we include a time-dependent term that reduces contacts when cases reach a certain point. This 532 term !(5, 8) varies from 0, indicating pre-pandemic levels of societal interactivity and no 533 masking, to 1, indicating complete lockdown with no interactions (Supp Fig 1b) . When two-534week number of diagnosed cases per 100,000 people rises above "" ""#$ , a ""partial-lockdown"" 535 (!(5, 8) → ! %& ) is mandated (Supp Fig 1b) . Partial lockdown is defined by an enforced social 536 distancing of ! %& =0.6 in the 3 younger age cohorts and ! %& =0.8 in seniors (≥70 years). When 537 cases drop below a relaxation threshold "" ""'( , !(5, 8) is lowered gradually from ! %& to ! ""'( (5) 538 at a rate of 10% reduction in !(5, 8) every two weeks that cases stay below the threshold. 539in Ref. 31 . This involved fitting the model to Diagnosed Cases, Hospitalizations, and Deaths from 548 Department of Health data in King County Washington. Age proportions and age structured 549 contact matrices were inferred from local demographic and contact data. All initial conditions 550 and parameters for the model can be found in Sup Table 2 . 551 Global sensitivity analysis. We performed a comprehensive exploration of vaccination rate, 552 mechanisms, and case levels for triggering and releasing lockdown: all combinations of all 553 parameters in Table 1 . 12 outcomes quantifying societal and public health were recorded (see 554 Sup Fig 2) for each simulation. Then, correlation and clustering analyses were performed by 555 calculating Spearman correlations among outcomes and between variables and outcomes using 556 the Seaborn package in Python. 557social distancing is maintained between partial lockdown periods. Impact of varying 609 vaccination rate on relevant outcomes. a. A minimum 30% social distancing value is assumed. 610To model SARS-CoV-2 epidemiological dynamics we have applied a dynamical systems approach which uses an SIR model extended in several key ways. In general each state variable is now a tensor whose dynamics are given by its properties, distinguished as age group a, vaccination status V , and depending on the infecting strain q. The model extensions are detailed in Table S1 and a schematic cartoon is provided in Fig S1. variable values definition The force of infection depends on the state of the infected individual (X) and the strainspecific infectivity X (q). It also depends on a time-dependent reduction in contacts mediated by social/physical distancing t . Finally, we use the empirically derived contact matrix to adjust the force of infection on a certain age group from transmitters in each other age groups (denoted by a T , and calculated using the adjacency matrix A(a, a T )). Finally, we have the force of infection for an individual in age group a, exposed to strain q, with vaccination status V , and with ongoing social distancing level t :where X = {A, P, I, C A , C I } is the set of all potentially infectious states. Note it is assumed that hospitalized individuals do not contribute to transmission ( H = 0). Naturally, susceptible, exposed, recovered, and deceased individuals also do not contribute to ongoing infection.The total number of individuals (across age, vaccination, and strain) in each compartment can then be calculated as a sum over the variables asAssumptions on asymptomatic infection. We assume that 20% of infections are asymptomatic and that asymptomatic people are as infectious as symptomatic individuals but missing the highly infectious pre-symptomatic phase. As a result, the relative infectiousness of individuals who never develop symptoms is 56% of the overall infectiousness of individuals who develop symptomatic COVID-19. This conservative estimate falls between the 35% relative infectiousness estimated in recent review based on 79 studies 1 and the current best estimate of 75% suggested by the CDC in their COVID-19 pandemic planning scenarios.Dynamic social distancing. An attribute that sets our model apart from most others is a notion of dynamical social distancing related to the current diagnosed cases. We include a time-varying, agestratified vector (a, t) that governs social distancing (non-pharmaceutical interventions) including reduced contacts through personal choices and/or mandated partial lockdowns, as well as reductions in exposure contacts due to mask wearing or physical distancing. (a, t) varies from 0, indicating pre-pandemic levels of societal interactivity and no masking, to 1, indicating complete lockdown with no interactions. This function is parameterized by 4 values: the maximum C max and minimum C min number of cases and the partial-lockdown and reopened social distancing values P L (a) and min (a) (see Supp Fig 1B) . Thus we have (a, t) = 8 > < > :We use the state of the pandemic in October 2020 as derived in our prior publication 2 to initialize and parameterize the simulations in this manuscript.",USA,first author,2021-02-03,02
12880441bf3eb08ee9a547f3d9911d79fff64197,"""An epoch-making and blessed moment in the history of medicine"" -thoughts on international health equity and the Nobel prize in medicine","In October, beginning with the category of Physiology or Medicine, the 2020 Nobel Prizes were announced. Rules for the Prize in Medicine permit it to be given to no more than three individuals (not an organization), all of whom must be living. This year awarded Alter, Houghton, and Rice for the discovery of the Hepatitis C virus [1] . Alfred Nobel's last will and testament directs the Prize in Medicine to esteem ""the most important discovery within the domain of physiology or medicine."" [2] .The late benefactor's description presents as objective, but the Prizes in Medicine are miscible with history and politics. The second-ever Prize was awarded to Ross in 1902 for illuminating the malaria life cycle during a decade when malaria was commonly fatal on five continents, including to the British Army occupying India. In the lecture before the award to Erlich and Mechnikov in 1908 ""for their work on immunity,"" [3] Count K.A.H. Mörner invoked an earlier achievement in immunology 100 years before the Prize began, when Edward Jenner introduced cowpox vaccination for smallpox immunity. Mörner described that achievement as ""an epochmaking and blessed moment in the history of medicine."" However, he followed his accolade by claiming that Jenner ""did not advance the development of the study of immunity... the first and most important condition for making the problem of immunity the subject of real scientific research was namely to establish the cause of disease."" [4] In doing so, as Rector of the Royal Karolinska Institute (the awarding committee), he created an archetype for the Prize in Medicine that promotes the discovery of abstract knowledge -to the point of ideologically disqualifying the first-ever vaccine.Following this pattern, Prizes in Medicine have typically gone to honor foundational knowledge (e.g. structure of the DNA molecule in 1962), innate bodily substance (insulin in 1923), or illumination of a diseasecausing agent (HIV in 2008) [1] . Only one vaccine has ever been awarded [5] . The Prize consistently distinguishes moments in the history of medicine when knowledge first suggests the possibility of a cure or prevention of a disease, not the final realization of protection or cure in human bodies.Alfred Nobel also offered general advice that all five original Prizes should be given ""to those who, during the preceding year, have conferred the greatest benefit to humankind."" He would have stood in awe of crowning achievements of medicine and humanity after his lifetime: the discovery of sodium-glucose co-transport around 1960 leading to oral rehydration solution for cholera [6] , the total eradication of smallpox in 1977 [7] , and the 2006 development of a universal set of growth charts to assess malnutrition in children [8] . But the Nobel Prize in Physiology or Medicine did not award these undertakings.These three accomplishments do not fit nicely in the established precedent or scope of the other Nobel Prizes. They are not directly related to war relief like the 1999 Nobel Peace Prize to Medicins San Frontieres (MSF), an organization which was founded in the aftermath of the Nigerian-Biafran War [9] . The three accomplishments are not innovations that directly impact the income potential of the poor, like Amartya Sen's Economics award in 1998 ""for his contributions to welfare economics"" 1 [11] . The closest precedent is this year's Nobel Peace Prize to The World Food Programme (WFP) ""for its efforts to combat hunger, for its contribution to bettering conditions for peace in conflict-affected areas … "" All of the non-medicine Nobel Prizes to health-related organizations are to non-governmental organizations (MSF and the Red Cross) or multilaterals (United Nations Children's Fund, UNICEF, and WFP) and specifically laud accomplishments that are politically stabilizing in a period of war or potential conflict [1] . But where the three crowning achievements that we invoke diverge categorically (from non-Medicine Nobel Prizes) is that they are based on life-threatening diseasescholera, smallpox, and severe acute malnutrition in children under five all of which required medical intervention based on a new scientific discovery.There is a crossing between discovery and impact forded by a tremendous amount of work. Ross described malaria in 1902 but treatment still failed to reach about 384,000 lives in 2019, two-thirds of whom are children [12] . Our historical high points begin in the mind, but do not self-assemble in the world. This is the work we will always have with us. One hundred and twenty years after a Nobel Prize for illuminating malaria's life cycle, the pernicious agent of perennial health risk is confined to a subset of the world's people. Many children in just a few parts of the world will typically suffer the course of this disease two or three times before developing natural immunity -if they survive.Could we consider successful implementation of medical knowledge as its own discovery? Mörner's discrimination towards Eureka! moments of abstract discovery in physiology is appealing precisely because it is akin to our conception of new love: immediately recognizable and often sentimentalized. But broad impact in medicine is more like the hard-earned intimacy of lifelong friendship, with origins often lost in private stories but fundamentally transformative over time, as described in the following two examples. Dr. Bhan's primary research achievement is discrete, easy to explain, and traceable to a lightbulb moment, sitting in a hospital reviewing analysis of viral strains in diarrhea from infants. But the 30+ year development of the vaccine was a labor of love for many brilliant doctors, scientists, government officials, nurses, and field workers. Even more impactful is this vaccine's implementation, whose rollout continues today with delivery and monitoring of Rotavac® in the Indian Public Health system [14] . Through medicine, children are spared a dangerous illness in large numbers.'WHO says our kids are just as good'In 2004, Kofi Annan as Secretary-General of the United Nations wrote a preface to the World Health Organization (WHO) Multicentre Growth Reference Study (MGRS), noting ""the United Nations undertook in 1993 a comprehensive review of anthropometric references"" to ""strengthen the hand of those working to extend the right to health to all children."" At least seven major research entities on five continents came together for a broad survey of those children having completely unrestricted physical growth (i.e. full food security, no major illness, optimal breastfeeding, non-smoking parents, etc) [8] .At the Asia site for this collaborative research project, Dr. Nita Bhandari led a team at what would become her remarkable female-led research organization called the Centre for Health Research and Development, Society for Applied Studies. They screened 117,000 pregnant women and followed up 425 of them at 73 different hospitals within 24 h of their child's birth, diligently taking height and weight measurements of the children for years [15] .When results were combined from a representation of all geographic areas, a discovery of physiology was clear. Children have the same growth potential regardless of geography or the non-medical category of race. A newspaper headline in India summed up what applied to all areas where previous growth standards set the bar too low: ""WHO says our kids are just as good."" [16] This discovery was implemented as the 2006 WHO Child Growth Standards, constituting an historic moment in medicine impossible to ascribe to three or fewer living people. The impact of the 2006 WHO Child Growth Standards was to substantially increase in the number of children accurately diagnosed with severe acute malnutrition (SAM). This in turn fostered a renewal in efforts to treat child malnutrition, including innovations in formulations for treatment and a new program funded by UNICEF called community-based therapeutic feeding for SAM [17, 18] . Through medicine, children are treated for a life-threatening illness in large numbers.Since the Nobel Prizes began, medicine has evolved with a concept of health defined by the WHO 's founding documents in 1946 as ""a state of complete physical, mental and social well-being and not merely the absence of disease or infirmity."" [19] Like a new growth standard that captures more cases of malnutrition, this definition of health comes with more work. But, global health inequities are more visible and collaborations to address them are more developed than when the Nobel Prizes began.Can the Prize expand? The Nobel Prize in Medicine is without clear equal in the health sciencesit is a worthy aspiration for physicians and physiologists alike.And, like the highest award in any field, it helps define the culture and scope of the discipline. The Prize in Medicine also constitutes a record of historical achievements, and discoveries are usually awarded more than two decades after they are made (with a notable exception of insulin). [20] This is the long view of the Prize in Physiology or Medicine as an exercise in writing the history of medicine.Successful physician-scientists plan their life work first by understanding history and hearing stories of achievements that came before them. Let them hear the long versionthe version where impact is defined in counting the number of lives touched by a discovery implemented through collaboration and by prioritizing the disproportionately affected. It is the version in which doctors are driven to discover after being exposed to great need. Let them aspire to be humanitarians as well as discoverers. Through medicine, children in need can be spared or treated for serious illness on their way to a state of complete well-beinga broader definition of medicine that could be used by the Nobel Committee to expand the Prize's territory, along with our maturing concepts of health and equity.The reality of an uncontrolled pandemic due to a novel but well-characterized virus invites us to consider that discovering the cause of a disease may no longer be the most important concern for medical research. New patterns that redefine achievement in Physiology or Medicine could emerge. We write during a phase of the pandemic in which COVID-19 vaccines were rapidly developed and administered to a set of prioritized front-line healthcare workers in a limited number of wealthy nations. Yet the pandemic carries a lesson in health equity. ""In an interconnected world, none of us is safe until all of us are safe,"" UN Secretary-General António Guterres proclaimed in a speech early in the pandemic era [21] . The collaborations that produce and broadly administer an effective vaccine for COVID-19 would arguably meet both the original Nobel Prize criteria of ""the most important discovery in the field"" and having ""conferred the greatest benefit to humankind. ""And when the most severe restrictions of COVID-19 are lifted, our universal experience of uncertainty can unite us across physical distance and bring global health equity into public focus. Similarly, a Nobel Prize in Physiology or Medicine that honors a global health achievement from an area of greatest need could shift our values away from the ivory towers of research science towards impact.Either that, or we can wait (like a quarter-million children), for a ""blessed moment"" when the eradication of malaria is achieved by combined efforts of novel vaccine development and a long vaccination campaign for an undeniably worthy new Nobel Prize Category. This prize could be endowed, perhaps, by a large and well-funded American pioneering organization in health science research with a fortune derived of a computer company -to honor ""Global Medical Collaboration, Implementation, and Impact,"" or simply, medical humanity. ",USA,first author,2021-02-10,02
8a51ec502164f0608c8afcd164288f5f84478503,Journal Pre-proofs Autism spectrum disorder patients may be susceptible to COVID-19 disease due to deficiency in melatonin Autism spectrum disorder patients may be susceptible to COVID-19 disease due to deficiency in melatonin,"COViD-19 disease is a multiorgan disease due to SARS-CoV-2 viral infection, that become pandemic in early 2020 (4) . It has been hypothesized that those with ASD may be predisposed to COVID-19 disease because of modifications at the immune and genetic levels (5, 6) . Recently, a case series of 16 ASD patients admitted to a neurodevelopmental unit with COVID-19 like symptoms was reported (7) . Eleven of these patients were shown to have COVID-19 disease by reverse transcriptase polymerase chain reaction (RT-PCR) or by serology at follow-up, of these patients only one required oxygen therapy. A recent case report describes a nine-year-old Italian child in a nursing home with exceptionally high viral load and an extended duration of viral shedding(8). Initial symptoms of cough and nasal discharge disappeared within two days and no clinical signs of lung involvement could be detected. However, quantitative RT-PCR indicated an extremely high viral load. A gradually decreasing load was seen over the following twelve weeks until negative tests were found, but only after 82 days. ASD patients with COVID-19 disease may be a major problem to the health care system; those who are severely intellectually disabled may be unable to communicate symptoms effectively thus monitoring, prevention and testing are doubly important (9) .A potentially significant factor in ASD is the finding of low urinary levels of the melatonin metabolite 6-sulphatoxymelatonin (aMT6s). In 23 ASD patients aged 4-10 years overall nocturnal aMT6s levels were reduced (10) together with increased N3 sleep, decreased N2 sleep and increased daytime sleepiness (10) . In another study 43 patients with ASD showed lower urinary aMT6s levels (8.26 µg per 24 h vs 18.00 µg per 24 h) both during nighttime and daytime in comparison to 26 controls matched for age, sex and pubertal status (11) . In that study the amount of aMT6s decrease correlated with the severity of illness. Most ASD studies looking for melatonin excretion, except for one (12) , reported decreased melatonin output. Another controlled study of 77 children with ASD and 84 controls aged 2.5 to 15.5 years reported that those with ASD had lower nighttime aMT6s than the controls with no difference in the daytime levels (13) . aMT6s levels in the ASD group were associated with sleep disturbance but not with ASD severity. In a study of 83 children with ASD aged 5 to 10, it was reported that aMT6s levels were increased in families with higher income but decreased with increased neurological problems(14). Manuani and coworkers examined the relationship between the pineal gland volume (PGV) estimated by MRI and early morning melatonin levels in 215 participants, 78 with ASD, 90 unaffected relatives and 47 controls. Although both melatonin and PGV were lower in patients than controls, the melatonin deficit appeared to be more related to group than to PCV. The authors stated that the findings support a deficit in the melatonin synthetic pathway as a possible main cause (15) .Genetic variation in synthesis of melatonin has been reported in ASD. In a unique subgroup of ASD children selected for having sleep onset delay, higher frequencies were reported of variants that decrease acetylserotonin O-methyltransferase (ASMT, the enzyme that determines the quantity of melatonin synthesized), as well as of those that decrease cytochrome p450 1A2 (CYP1A2, the enzyme that metabolizes melatonin) (16) .Two different polymorphisms in the promoter have been reported for ASMT, moreover a splicing mutation was reported in two families (17) (18) (19) In 2065 children, ages 4-18, from the Simons Simplex Collection (SSC) no relationship was found between any gene variants and sleep problems(20). The authors suggest that sleep problems may be related to translational or posttranslational effects of these genes or to additional ones modifying the sleep system.Melatonin is a multipotential body substance: it is not just a pineal hormone but is synthesized widely in the body and acts as a potent antioxidant, scavenger, modulates the immune system and modulates macrophage function (21) . It is synthesized in cerebral mitochondria, where it can counteract overproduction of radical oxygen species at the site of their generation during electron transport (22) . In the immune system it supresses innate immunity while facilitating antibody production. Melatonin suppresses NLRP3 inflammasomes, proinflammatory cytokine activation and facilitates switching of highly inflammatory M1 macrophages to antiinflammatory M2 macrophages (23) (24) (25) In numerous animal viral diseases it has been shown to greatly enhance survival. Moreover, in several instances of human sepsis adjunctive treatment with melatonin has improved patient outcome (26) . The structure and physico-chemical properties of melatonin have been examined using electronic structure methods and molecular-mechanics tools as a predictor of melatonin's bioactivity against the coronavirus 2 proteins. Based on the docking scores obtained, the authors proposed that melatonin could be effective to defend against the viral load in vulnerable populations (27) . Recently a case series has reported that melatonin is a helpful adjuvant in patients with severe pneumonic COVID-19 disease (28) .. The analysis of 26,779 records of patients in a COVID-19 database revealed melatonin was associated with an improved outcome (29) . A prospective study of 791 intubated COVID-19 patients showed that melatonin was associated with survival (30) . In the first reported randomly controlled trial of melatonin in COVID-19 patients, 3 mg was administered three times daily to hospitalized patients (24 given melatonin vs 20 none), the melatonin treatment group had significantly less symptoms and were discharged earlier from hospital (31)Based on the hypothesis that low melatonin can be a reason for susceptibility to the SARS-CoV-2 virus we postulate that adequate melatonin levels will be preventative. It is known that there is genetic variation in the melatonin synthesis pathway in some ASD patients. In others the sleep irregularity that frequently is seen in ASD may result in a decrease in circulating melatonin because of waking during the night and exposure to light. Light and especially blue light will supress melatonin production by the pineal gland, so it is important to regulate sleeping if it is possible(32). Two treatments described recently can be of assistance (3) . A comprehensive program of sleep hygiene that improves sleep can be effective in reducing exposure to light at times that would impair melatonin secretion. Another possible treatment is the administration of melatonin. It has often been used to help with sleep disorder (3) . In treatment with melatonin, it should be noted that a minority of individuals develop resistance to its sleep inducing effects after a few days. These people have been shown to be slow metabolizers due to a genetic variation in CYP1A2, the gene that metabolizes melatonin(33).We hypothesize that a low melatonin output, found in those with ASD due either to genetic variation in the synthetic enzyme pathway or to frequent nighttime with exposure to light that suppresses melatonin synthesis by the pineal gland, may lead to susceptibility to COVID-19 disease. Further we propose that treatment with sleep hygiene to correct nighttime waking and treatment with melatonin are both treatments that may prevent COVID-19 disease or reduce its severity in ASD patients.All authors declare that they have no financial or personal interests that may influence this work.No funding is declared. Legend to Figure 1 It is hypothesized that melatonin, well documented for its protective effects in various human and animal studies will protect ASD patients who have are known to have low melatonin levels and may be susceptible to COVID-19 disease. Furthermore, restoration of melatonin levels will be protective against the SARS-CoV-2 viral infection. Melatonin's protective actions in the left box are conducive to health. SARS-CoV-2 virus with low melatonin levels result in a cytokine storm that causes COVID-19 disease. Raising melatonin levels may help prevent illness due to SARS-CoV-2. SARS-CoV-2 figure is from Pixaby",Canada,first author,2021-02-18,02
a38e70207fb6687f9ab337c1758ccfcc237038eb,Post-infection treatment with a protease inhibitor increases survival of mice with a fatal SARS-CoV-2 infection,"Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) infection continues to be a serious global public health threat. The 3C-like protease (3CLpro) is a virus protease encoded by SARS-CoV-2, which is essential for virus replication. We have previously reported a series of small molecule 3CLpro inhibitors effective for inhibiting replication of human coronaviruses including SARS-CoV-2 in cell culture and in animal models. Here we generated a series of deuterated variants of a 3CLpro inhibitor, GC376, and evaluated the antiviral effect against SARS-CoV-2. The deuterated GC376 displayed potent inhibitory activity against SARS-CoV-2 in the enzyme and the cell-based assays. The K18-hACE2 mice develop mild to lethal infection commensurate with SARS-CoV-2 challenge doses and was proposed as a model for efficacy testing of antiviral agents. We treated lethally infected mice with a deuterated derivative of GC376.Treatment of K18-hACE2 mice at 24 hr post infection with a derivative (compound 2) resulted in increased survival of mice compared to vehicle-treated mice. Lung virus titers were decreased, and histopathological changes were ameliorated in compound 2-treated mice compared to vehicle-treated mice.Structural investigation using high-resolution crystallography illuminated binding interactions of 3CLpro of SARS-CoV-2 and SARS-CoV with deuterated variants of GC376. Taken together, deuterated GC376 variants have excellent potential as antiviral agents against SARS-CoV-2.Coronaviruses are a large group of viruses that can cause a wide variety of diseases in humans and animals (1) . They are single-stranded, positive-sense RNA viruses that belong to four genera, designated (4) and, most recently, SARS-CoV-2, the causative agent of COVID-19 (5, 6) . SARS-CoV-2 emerged in China in December 2019 and subsequently spread throughout the world. Ominously, the diversity of coronavirus strains in potential animal reservoirs suggests that emerging and reemerging pathogenic coronaviruses will continue to pose a significant threat to public health (7, 8) . Currently, vaccines using different platforms have been developed or under development, and two vaccines just became available in the US for COVID-19 licensed for emergency use with more others expected to be available soon. The specific therapeutic interventions that are currently licensed include a nucleoside analogue remdesivir (Veklury®), a combination of remdesivir and a JAK inhibitor baricitinib, and a cocktail of anti-SARS-CoV-2 monoclonal antibodies. These treatments may diminish disease progression, but such effects are not found in most studies, indicating the urgent necessity to develop additional antiviral therapies (9) (10) (11) (12) .The SARS-CoV-2 genome encodes two polyproteins which are processed by a 3C-like protease (3CLpro) and a papain-like protease. These viral proteases are essential for viral replication, making them attractive targets for drug development (13) (14) (15) (16) (17) (18) . It is furthermore acknowledged that, in addition to the development of effective vaccines, the concurrent identification of FDA-approved drugs that can be repurposed for use against SARS-CoV-2 may accelerate the development and implementation of effective countermeasures against the virus (19, 20) . We previously described a series of 3CLpro inhibitors (including GC376) with activities against multiple coronaviruses, including SARS-CoV(21), MERS-CoV (13, 22) and SARS-CoV-2 (13) . GC376 was recently demonstrated in clinical trials to have efficacy against a fatal feline coronavirus infection, feline infectious peritonitis (FIP) (23, 24) , and is currently in clinical development for treating FIP in cats. Mice expressing human angiotensin I-converting enzyme 2 (ACE2) receptor under the cytokeratin-18 (K18) promoter, designated as K18-hACE2 mice, were previously proposed as a model for efficacy testing of antiviral agents (25, 26) . We report herein the results of our studies related to the synthesis and evaluation of deuterated GC376 variants which have enhanced antiviral activity and display efficacy in a fatal mouse model (K18-hACE2 mice) of SARS-CoV-2.SARS-CoV-2 in the enzyme and the cell-based assays. We synthesized deuterated variants based on GC376 ( Figure S1 , and Supporting information) and compared their inhibitory activities against SARS-CoV-2 to non-deuterated GC376 in the enzyme and the cell-based assays (Table 1) . Three different variants of deuterated aldehyde compounds (compounds 1, 6 and 9 with R 1 , R 2 and R 3 , respectively) as well as their bisulfite adducts (compounds 2, 7 and 10)were prepared for the testing. In addition, an α -ketoamide (compound 5) based on compound 1 and prodrug variations (compounds 3, 4, 8 and 11) of the bisulfite adducts of aldehydes (compounds 1, 6 and 9) were synthesized for the testing. In the enzyme assay, the bisulfite adducts showed similar 50% inhibitory concentration (IC 50 ) values as their aldehyde counterparts (Table 1C) . The (Table 1C ). The deuterated compounds that were more effective than GC376 in the enzyme assay were tested in the cell-based assay.The 50% effective concentration (EC 50 ) values of the tested deuterated compounds (compounds 1, 2, 6 and 7) (0.068 to 0.086 µM) were lower than GC376 by 2.67~3.38-fold in Vero E6 cells. All compounds, including GC376, did not show any cytotoxicity up to 100 µM (Table 1C) .variants of GC376. Compound 2 with a bisulfite adduct warhead and compound 5 with α -ketoamide were co-crystallized with the 3CLpro of SARS-CoV-2 and SARS-CoV and examined by X-ray crystallography. Examination of the active site of SARS-CoV-2 3CLpro revealed the presence of prominent difference electron density consistent with compound 2 covalently bound to the Sγ atom of Cys 145 in each subunit ( Figure 1A and B) . Interestingly, the electron density was most consistent with the S-enantiomer at the newly formed stereocenter.Although the electron density in subunit B did contain a small ""bulge"" that may be due to the R-enantiomer, only one configuration was modeled. Compound 2 adopts the same binding mode in each subunit and forms identical hydrogen bond interactions with residues Phe 140 , His 163 , His 164 , Glu 166 and Gln 189 ( Figure   1D and E). As we generally observed in studies of SARS-CoV 3CLpro, the electron density map was consistent with both the R and S-enantiomers of compound 2 at the new stereocenter formed by covalent attachment of the Sγ atom of Cys 145 in the cocrystal structure of SARS-CoV 3CLpro ( Figure 1C ).Overall, the hydrogen bond interactions are nearly identical relative to SARS-CoV-2 3CLpro. The main difference is that a hydrogen bond is formed between His 41 and the hydroxyl of compound 2 in the R-enantiomer and a long contact (3.29 Å) to the backbone N-atom of Ser 144 with the hydroxyl of the S-enantiomer ( Figure 1F) . Notably, the hydroxyl in compound 2 bound to SARS-CoV-2 3CLpro is 3.38 Å and 3.39 Å from the N-atom of Ser 144 , which would be a weak hydrogen bond contact. The benzyl ring in both structures is positioned outward from the hydrophobic S 4 subsite and are directed towards the surface as shown in Figure   1G , H and I. Notably, the structures of SARS-CoV-2 3CLpro in complex with nondeuterated G376 and its precursor aldehyde GC373 (PDB 6WTJ and 6WTK, respectively) adopts the same binding mode as that observed for compound 2 ( Figure S2 ). Superposition yielded root-mean-square deviation (RMSD) deviations of 0.59 Å (GC376) and 0.55 Å (GC373) between Cα atoms for 299 residues aligned (27) .The structures of SARS-CoV and SARS-CoV-2 3CLpro in complex with compound 5 also contained prominent difference in electron density consistent with the inhibitor covalently bound to the Sγ atom of Cys 145 ( Figure S3A and D).The entire inhibitor could be modeled in subunit A but was partially disordered in subunit B and the benzyl group in the S 4 subsite could not be modeled for SARS-CoV. The inhibitor forms direct hydrogen bond interactions similar to compound 2 as shown in Figure S3B Interestingly, the compound bound to subunit B of SARS-CoV-2 3CLpro adopts a conformation similar to that observed for compound 2 in which the benzyl group is directed away from the S 4 subsite and towards the surface (FigureS4).Therefore, it appears the structure of SARS-CoV-2 3CLpro in complex with compound 5 serendipitously contains two binding modes of the inhibitor.mice. Compound 2 was tested in SARS-CoV-2-infected K18-hACE2 mice for protective efficacy, because it potently inhibited SARS-CoV-2 in the cell-based assay described above. The dose curve of compound 2 against SARS-CoV-2 in cell culture is shown in Figure 2A . In the first experiment, infection with 2x10 3 pfu per mouse led to body weight loss in all vehicle-treated mice resulting in 50% survival by 9 dpi ( Figure 2B ). Mice treated with compound 2 (100 mg/kg/day, once a day) starting from 24 hr post infection (1 dpi) lost body weight, but loss was less severe compared to vehicle-treated mice with statistically significant differences (0.002<p<0.049) on most days between 5-10 dpi (Figure1C). All The advent of SARS-CoV-2, the causative agent of COVID-19, has provided the impetus behind worldwide efforts to develop effective countermeasures against the virus for the treatment of COVID-19, including the use of repurposed drugs [reviews (19, 20) ]. Indeed, remdesivir, a nucleoside analogue, which was originally developed and FDA-approved for treating Ebola virus infection has been shown to be a potent inhibitor of SARS-CoV-2(28-30) and recently approved for COVID-19. However, effects in patients have been modest, with some studies showing no efficacy (9) (10) (11) (12) . Multiple FDA-approved drugs which exert their antiviral effects by impeding key steps in the viral lifecycle, including virus entry and fusion, and viral replication, among others, are currently under intense investigation for use against SARS-CoV-2 (19, 20, (31) (32) (33) . Efforts in developing small molecule inhibitors targeting the virus proteases of SARS-CoV- 1 1 protease inhibitor under commercial development for FIP, was reported to have anti-SARS-CoV-2 activity by us (13) and other groups (27, 36, 37) , which suggests this compound is a lead compound for COVID-19 amenable to further optimization. Based on the multiple potential advantages frequently accrued from the introduction of deuterium in a drug, such as improved pharmacokinetics, reduction in toxicity, and enhanced potency (38) (39) (40) , it was envisaged that deuterated variants of GC376 could function as therapeutics with superior characteristics compared to the corresponding non-deuterated GC376 drug. Therefore, we generated three deuterated variants of GC376 by replacing hydrogen with deuterium at the metabolic soft spots encompassed in the R site (aromatic ring and benzylic carbon) and evaluated their activity in the enzyme and the cell-based assays. All three R site-deuterated variants (aldehydes and their bisulfite adducts) showed modestly increased potency compared to GC376, which was more apparent in the cell-based assays than in the enzyme assay (Table 1C) .Crystal structures of deuterated GC376 (compound 2) and the 3CLpro of SARS-CoV-2 revealed that deuteration did not alter the interactions between GC376 and 3CLpro which are reported by other groups (27, 37, 41) . It may be speculated that the enhanced activity of the deuterated compounds can be attributed to tighter binding to the target, which was observed with other deuterated compounds (38) or improved physicochemical properties of the compound. However, further study is needed to understand the mechanism.Substitution of the aldehyde warhead in compound 1 with an α -ketoamide (compound 5) significantly decreased potency, which confirms earlier findings by us (21, 42) that ketoamide is less suitable for coronavirus 3CLpro inhibition.Employing an OCOmethyl or n-pentyl ester derivative of bisulfite adducts to produce prodrug variants (compounds 3, 4, 8 and 11 ) led to reduced potency in the enzyme assay, which may be due to inefficient conversion to the active compound in the enzyme assay.Most animals (hamsters, ferrets, and non-human primates) experimentally infected with SARS-CoV-2 serve as good models for asymptomatic, mild, and Synthesis of deuterated variants of GC376 3CLpro inhibitors. Compounds 1-11 were readily synthesized using a reaction sequence similar to the one previously reported by us ( Figure S1 ) (45) (46) (47) , and are listed in Table 1B . Briefly, the deuterated alcohol inputs (Table 1A) Table 1C . (Table 1C) . Structure refinement and manual model building were conducted with Phenix (54) and Coot(55), respectively. Disordered side chains were truncated to the point for which electron density could be observed. Structure validation was conducted with Molprobity(56), and figures were prepared using the CCP4MG package(57).Superpositions were performed using GESAMT (58) . Crystallographic data are provided in Table S1 . Compound 2 was examined for efficacy using 7-8 week-old female K18-hACE2 mice infected with SARS-CoV-2(26) . In the first experiment, animals were Table S1 SI ReferencesGeneral. Reagents and dry solvents were purchased from various chemical suppliers 3) Rfactor = Σhkl ||Fobs (hkl) | -|Fcalc (hkl) || / Σhkl |Fobs (hkl)|; Rfree is calculated in an identical manner using 5% of randomly selected reflections that were not included in the refinement. 4) Rmeas = redundancy-independent (multiplicity-weighted) Rmerge (1, 2) . Rpim = precision-indicating (multiplicity-weighted) Rmerge (3, 4) . 5) CC1/2 is the correlation coefficient of the mean intensities between two random halfsets of data (5, 6) .",USA,first author,2021-02-05,02
0d420b523030bb16dd2db912982b88eb5bb83547,Risk compensation and face mask mandates during the COVID-19 pandemic,"www.nature.com/scientificreports/ spreading the pathogen to others 10 . The theory of social distancing suggests that if people can mitigate disease risks by lower private cost means, then they will distance less 11 . The concern of inducing risky behaviors by providing some protection is well established in the broad literature on behavior, risk, and externalities 12 . The public health literature uses the term ""risk compensation"" to describe the case when someone increases certain risky behavior when using protective equipment 13 . A close analog is condom use and HIV transmission. In the case of risk compensation, people using condoms engage in more sexual activity and increase the risk to susceptible individuals in the population 9, 14 . Public health researchers and economists have long been concerned about the behavioral impacts of introducing partially effective prophylaxis or vaccine for viruses such as HIV 15, 16 .The study's objective is to contribute to the public health literature addressing COVID-19 by using the variation in face mask mandates along with mobile device data to measure the change in the amount of time Americans stayed at home, and the number of visits Americans made to public places, following face mask mandates. This study investigates the substitution effect between two COVID-19 behavioral interventions, staying home (or visiting certain types of businesses) and public face mask mandates. We find evidence of risk compensation behavior as people spend less time at home and make more trips to public places. Though the ultimate impact for face mask orders on transmission depends on the unknown relative effectiveness in breaking transmission of face masks and staying home. These policies are hard to separate empirically because they are often implemented together.As of August 22, 2020, 42 US states mandated face mask use by employees in public-facing businesses, and 48 states ordered all individuals in public spaces to wear face masks 17, 18 ) (see Fig. 1 ). We examine the two policies separately when possible. We use SafeGraph home dwell time and public location visitation data to evaluate the effect that face mask orders had on representative behaviors that could expose individuals to COVID-19 transmission. SafeGraph is a data company that aggregates anonymized location data from numerous smart device applications in order to provide insights about physical places, via the Placekey Community. To enhance privacy, SafeGraph excludes census block group information if fewer than five devices visited an establishment in a month from a given census block group. (https ://docs.safeg raph.com/docs/socia l-dista ncing -metri cs). Saf-eGraph reports the median home dwell time by Census Block Group, and we produce a device weighted average for each county. We also calculate device-weighted averages of trip visits to points of interest by four-digit NAICS (North American Industry Classification System) code.Time at home. We examine behavior aligned to 2 weeks before and after each of the counties or states implemented face mask mandates. For a county i on day t , we regress time spent at home measured as the device-weighted county mean of the median Census Block Group home dwell time in minutes, Y it , on the first mask mandate for the public, M1 it , and on the first mask mandate for use in businesses, M2 it . We condition the regression on reported cases and newly increased cases in one's own county, state, and nationwide, C it 19 , on other county-level controls, X it (including weather, the device count by Safegraph for each county, and holiday dummies), a county-specific fixed effect, a i , and a weekday specific fixed effect, w t . We consider the possibility that individuals have become exhausted with stay-at-home orders, distancing fatigue 20 , by including the log of days since a stay at home order was implemented, S it . The two face mask mandates are generally after the stayat-home policy is issued but can be before or after the end of the stay-at-home policy (see Figures S1-3). We include an additional group of policy variables to examine the possible effects of various business reopening in some states. The vector, R it , includes policy dummies of businesses, daycares, bars, restaurants, movie theaters, hair salons, religious opening, non-essential retailers, and gyms being allowed to reopen, as well as a dummy for the end of stay-at-home policy.Weather variables are constructed by aggregating 4 km gridded estimates of maximum and minimum daily temperature, maximum and minimum relative humidity, precipitation amount, surface solar radiation, and wind speed 21 . We cluster standard errors at the state level to account for state-level serial correlation and heteroscedasticity caused by the phase-in of orders and because for most states there is very little variation at the county level. The model is specified as If people attempt to manage infection risk by substituting the use of masks for time at home, we hypothesize that people spend less time at home once they receive a directive to wear masks, γ 1 < 0 and γ 2 < 0 . Thus, γ 1 and γ 2 are the parameters of interest, and the remaining terms help eliminate confounding by other variables and if these other terms were not included the regression could violate the standard regression assumption that the expectation of ǫ it is zero.We then examine the pre-trend of the policy given the specification. We adopt the dynamic event study model by using a list of policy indicator variables for 2 weeks before and after the face mask mandates in public,The equation for the face mask use mandates in businesses is similar and constructed by replacing M1 Dit with M2 Dit : (2) is similar to Eq. (1), but rather than providing a single slope estimate associated with the mandate, the structure of Eq. (2) allows for a non-parametric day specific impact of the mask mandate, with the other terms playing a similar role as in Eq. (1).We remove the first and the last treatment indicators before the policy to avoid under-specification 22 . We report results for regressions on the Y it and on ln(Y it ) for the above equations. In the Supplemental material, we examine pairs of states with and without orders and analyze these pairs with a difference-in-difference design. These analyses support the overall conclusion, but also suggest the risk compensation result is complex because not all pairs support the risk compensation hypothesis.Points of interest visitation. If people decrease their time at home, they must go somewhere. It is important to know if they allocate time to relatively high risk or low-risk locations. Benzell et al. 23 argue that gyms and grocery stores are relatively high risk and hardware stores, sporting goods stores, and general merchandise stores are moderate-risk locations. Conversely, parks may be relatively low-risk locations. To explore the impact of the mandate of face mask use to site visits, we use point-of-interest (POI) data from January to August 18, 2020 that are within 2 weeks before and after the mask mandates, from SafeGraph to examine the change in visits after the face mask mandate. www.nature.com/scientificreports/ We aggregate each day t 's visits to a site in industry I located in county i , V Iit . Each industry type is analyzed independently. I is defined by the first four digits of a location's NAICS code. We regress the county-aggregated visits, V Iit , on the mask mandates, M1 it and M2 it . Similar to Eq. (1), we condition the regression on county-level controls, X it , on re-opening dummies R it , on reported cases and newly increased cases in the POI's own county, state, and nationwide, C it , on time since the stay-at-home order, S it , a county fixed effect a i , and a weekday fixed effect w t .We focus on the sites in the selected industries in wholesale trade (NAICS sectors #41 and 42), retail trade (NAICS sectors #44 and 45), entertainment and recreation (NAICS sector #71), and accommodation and food services (NAICS sector #72). Consistent with the analysis of time at home, we examine the impact of M1 it and M2 it before and after 14 days of the mask mandate. Like in Eq. (1) the focus is on γ 1 and γ 2 , with the other terms playing a similar role to the extra terms in Eq. (1).We find evidence that masks are associated with risk compensation behavior and that Americans spend less time at home when living with a face mask mandate. Furthermore, we find weak evidence that Americans spend more time in moderate to high-risk locations following orders to wear masks. We also find evidence of distancing fatigue, but risk compensation results persist after accounting for distancing fatigue.Time at home. By the time face mask orders were issued, Americans were already experiencing distancing fatigue measured as the log of days since stay-at-home orders were issued, and time at home was already declining (Table 1) . We find evidence of distancing fatigue in all states, but if anything, distancing fatigue is greatest in states that ultimately received face mask orders. Understanding distancing fatigue provides a baseline for behavioral shifts associated with mask mandates.Americans appear to have reduced time at home following state mandates to wear face masks (Fig. 2) . Estimates are stable across all specifications and range from a reduction in time at home from 10 to 12 min for mandates in public or 2-3.6%, and 16-24 min for mandates in business or 2-4% ( Table 2 ). The estimate of distancing fatigue (day since stay-at-home orders) is robust to the inclusion of mask orders providing evidence that the face mask order effect is not confounded with distancing fatigue. Including no-policy counties with a study period constructed based on state-level average or earliest dates of mandates provides robust estimates (Table S1 and S2).We use the same constructed study periods for no-policy or late-policy states to examine face mask mandates for business for pairs of bordering states ( Fig. 3 and Table S3 ). In the majority of states, we observe a reduction in time at home following business face mask mandates.The effect of face masks is robust to including business reopening policies in the model. This is likely because few states closed or opened businesses within the window of analysis.We investigate possible spillover effects of mask orders across the state border. We find that Americans in counties without mandates do not respond significantly to the bordering counties' mask mandate ( Table 3) .Americans increased trips to a variety of places in the weeks following the mask mandate (Fig. 4) . The greatest effects were for restaurants and other eating places, which could be dominated by take-out pick-ups because we look at the count of visits and not time on site. Fisher (2020) reports that adults testing positive for COVID-19 were twice as likely to have dined at a restaurant relative to adults with negative tests. The next most affected locations were recreation locations, which includes parks, health and personal care, and florist, which may include gardening stores. Grocery stores and various merchant wholesalers did not appear to receive increased trips following the mask orders.Overall, the increase in out-of-the-house activity appears to expose people to a mix of sites with different risk characteristics. Variation in site risk characteristics implies that it is difficult to know if the net effect of mask orders and risk compensation increased or decreased transmission risk relative to staying home. The mechanism by which mask orders could reduce transmission is that they could reduce contacts among maskless individuals similar to the way that adding immune individuals can reduce transmission in an otherwise identical population 11 . Furthermore, the net effect may vary by geography.Addressing potential concerns. One possibility is that governors and local leaders simply run to the front of the crowd. The assumption would be that leaders know people will start going out. Therefore, they implement face mask orders to signal it is ok to start going out. If this were the case, it is unlikely that there would be a systematic break, and a substantial number of governors relaxed stay-at-home orders directly. Furthermore, such a concern simultaneously gives the governors a large amount of credit for political astuteness and treats their actions with a high degree of cynicism. Both assumptions seem unmerited in the fog of the COVID-19 crisis.We analyze the effect of the mask orders defined by the implementation date and not the announcement. It is possible that policy announcements or earlier CDC and WHO announcements signaled to the public that it is safe to resume public interaction with a mask. Such anticipatory behavior would attenuate our estimates because the pre-policy period would be contaminated by the behavioral response that we associate with the face mask orders. Still, we find a robust decrease in time spent at home and a robust increase in trips to public places following the implementation of face mask requirements. Furthermore, we find no effect in states without mask orders to the orders of neighboring states. Americans increased visitation to public locations and reduced their time spent at home even as COVID-19 cases rose in much of the United States. Some of this was distancing fatigue. However, our results suggest that mask orders provide a sense of protection. When everyone was expected to wear a mask, people perceived a lower risk associated with leaving home and visiting public locations. This led people to substitute away from other non-pharmaceutical interventions like avoiding time in public. The net effect of these behaviors on public health outcomes depends on the relative effectiveness of masks and other behaviors in reducing transmission. Recent evidence suggests that the net effect of masks has been to reduce transmission of SARS-CoV-2 24 , but other explanations remain possible. Evidence suggests that staying home effectively reduced transmission. One concern with that conclusion is that it is easier to observe staying home behavior than handwashing, physical spacing, and face mask-wearing. For face masks to be effective, they must be used consistently ( Figure S4 ) and correctly. This includes having a tight seal, which requires things like a clean shave, having one's nose in the mask, and leaving the mask on while talking to someone. One need only look at images of mask-wearing in public to conclude that a non-trivial share of mask wearers are not wearing them correctly or that the masks themselves are of questionable quality (i.e., bandannas). It is certainly possible that misused masks do not increase transmission, and may reduce it, holding Table 1 . Impacts of days since stay-at-home order issued on dwelling time at home (in min) during the mask mandate study periods for (a) with with-policy counties, and (b) all counties, with no-policy counties using the average date of mandates in state for study period construction. Standard errors are shown in parentheses, one, two, and three asterisk refer to 95%, 99%, 99.9% confidence level. Our results suggest that wearing a mask, given real compliance levels, needs to be as effective as individuals, reducing their average time out of the house by approximately 1.6-3.% or 11-24 min. Bayham et al. 25 found that voluntary behavioral change of a similar magnitude reduced 2009 H1N1 swine flu cases on the order of 10%. The swine flu estimate is likely a lower bound for the value of additional time at home for reducing COVID-19 cases, as COVID-19 appears more transmissible. Are face masks in the general public equivalent to the average individual staying home an additional 11-24 min a day-likely one less trip somewhere? This is a challenging empirical question that still needs answering. However, systematic data on individual behaviors similar to the smart device data do not exist for mask wearing and other protective measures, making it difficult to rule out other explanations of declining cases in some areas. Cases increased in some states and decreased in other states Our results should not be used as a justification for discouraging face mask use. Rather, extreme care must be taken when suggesting new behaviors that may be helpful, in order to avoid replacing behaviors that are known to be helpful. The message to wear a face mask in public is at least suggestive that it is safe to resume public interactions with a mask. However, time in public is still riskier than time at home and can still enable transmission from asymptomatic individuals.An alternative interpretation of our results is that mask orders can help inspire confidence to encourage people to return to commerce if people overestimate the local risk of infection. If policy makers believe that COVID-19 is under control, and want to encourage a return to commerce, then mask orders might help stimulate the local economy. This would be especially true if people continue to feel unsafe in public spaces because they overestimate infection risk.Overall, the results suggest some risk compensation, with trips directed to one of the highest risk locations. However, our state comparisons do raise identification questions beyond the net effect. Evaluating COVID-19 policies is challenging because many policies were initiated in short-order and policies likely interact 19 . This feature of evaluating non-pharmaceutical interventions means that each study can add a weight of evidence, but that no study will provide a definitive answer to the relative effectiveness of any one policy intervention.There can be risk compensation and the net effect can be beneficial 26 . Requiring seat belts likely outweighs the damage from riskier driving and energy efficiency reduces carbon emissions even if it leads to more device use 27 . Even encouraging condom use has likely prevented more cases of HIV, then the risk compensation generated. At present it is unclear whether the risk compensation associated with masks results in a net benefit or net cost. However, the difference between a few trips with a mask and staying home, spread across the entire population could be the difference between the reproductive rate of the pathogen (R(t)) exceeding one, and renewed exponential growth, and a reproductive rate less than one and containing the epidemic. If people must go out, then it is advisable to wear a mask. The fact that people now own masks is likely making them more likely to even consider a trip out. On one hand, these marginal trips could make the epidemic more difficult to bring under control, on the other they may alleviate the economic stress creating space to control the pandemic. Either way, it is important to understand the substitution effects among non-pharmaceutical responses. Code available at https ://githu b.com/youpe iyan/face_mask_manda te with instructions for acquiring data.Received: 17 September 2020; Accepted: 20 January 2021",United States,abstract,2021-02-04,02
3f04d3458e3bb89d14941f2766ced1fa5dcba6da,Teaching Tips -Special Issue (COVID) Structuring Formative Feedback in an Online Graphics Design Course in BME,"The COVID-19 pandemic-based shift of decision to launch our new course on Graphics Design in BME in an online mode instead of face-to-face, raised a big challenge in terms of providing meaningful feedback to a large, online class of students for improving their problem solving, graphics communication, and design skills. Feedback was needed for reducing discrepancies between students' understandings and the goals of the assignment. 15 However, the conditions that make feedback possible in face-to-face instruction, such as observation of students' work over time and multiple opportunities to provide useful comments, are diminished in an online course. Compounding the problem further are factors such as larger class size and a lack of students' training in how to interpret and utilize feedback for improving performance on task. 3, 23 Many theoretical models describe the mechanism of feedback production, how it is received, and what effect it has on students. 3, 4, 8, 18 These models have been used to formulate principles to provide feedback, 6, 20 including that of sustainable feedback practice. 5 Despite the volume and rigor of studies investigating feedback, we found that the concept is still fragile 9 and inherently problematic. 16 Literature indicated that the feedback process needs to be made more dialogical and ongoing through discussions, clarifications, and negotiations between student and tutor. 5 However, this dialogical nature of feedback requires a fair deal of interactivity between student and teacher, which is inherently difficult to achieve in an online environment. Opportunities for informal engagement outside the classroom, such as discussions with other classmates, tutors, etc. are also reduced in an online environment, which would otherwise help and equip students with a better appreciation of what is expected of them, and develop their understandings of academic terms and appropriate practices as they begin to write project reports. This situation is especially delicate in the context of contemporary higher education imparting engineering skills, where students attend large classes with fewer opportunities for an individual student to interact with teaching staff.Most works in the past have treated feedback as a singular concept. Here we treated feedback as more than one notion and focused primarily on the needs of learning rather than the capacities of the teacher as suggested by Boud and Molly. 3 We focused on the feedback process, format, personalization, content, function, and presentation as described in Sect. 2.1, and implemented it online. The salient features of our feedback were: its written and dialogic format, personalization for each team, and facilitation of twostage assignment submission. Assessment of impact caused by our formative feedback as presented in this paper showed there was an effect in the desired direction.The aim of this paper is to: (1) report how we structured formative feedback in an online transitioned course on Graphics Design in BME, in response to the COVID-19 pandemic, and (2) report the assessed effects of the formative feedback provided online, to enhance students' performance in a computer-aided bioreactor-design project.The Learning Objectives (LOs) of this course were set such that at the end of the course, students would be able to:1. Apply spatial visualization and create orthographic and isometric views of objects.2. Construct 2D and 3D drawings, and assembly and sub-assembly structures. 3. Follow engineering design procedures including problem identification, problem formulation, approaches, methodology, and solution. 4. Use industry-standard software packages for the design of a 3D Computer-Aided Design prototype of a bioreactor. 5. Work in a team to document and present the process of Computer-Aided Design of their product. 6. Develop an ability to utilize online learning tools and collaborate online.Specifically, an end-of-the-quarter bioreactor project was designed to teach students to (i) identify a biomedical graphics design challenge for creating a bioreactor that satisfies a given need, (ii) evaluate various parameters for the optimal design of the bioreactor based on literature search, (iii) Select specific parameters for bioreactor design using a weighted decision matrix, (iv) synthesize a preliminary concept of the prototype on paper and in CAD, and (v) communicate the model formation process and drawing in CAD accurately in the form a written report.All students had a common challenge for their project-to create a bioreactor using CAD for enhancing the viability and proliferation of mesenchymal stem cells on porous silk-fibrin 3D scaffolds (project details are in Supplementary Information). The course had 98 students split into 24 teams. Each team designed a bioreactor using CAD. The project constituted 15% of the final grade, including a written project report (10%) and a CAD portfolio (5%).The project was divided into several assignments due week 2 to 9. Final projects were due in week 10 of instruction. Rubrics and additional resources were provided to students for each assignment. Written formative feedback was given using Canvas LMS through weeks 2-6. We analyzed the pre and post-feedback performance of students after coding the data upon approval of the Institutional Review Board (IRB). The timeline of project deliverables is indicated in Table S1 . The Project Need Statement, Goals & Objective, Decision Metrics, and Preliminary Concept were assessed by the instructor. Handdrawn Sketches were assessed via a peer review process, where at least three different students graded a submission anonymously, and scores were averaged by a TA.Research shows that viewing feedback more as dialogue than the transmission of information, 20 and providing high-quality formative feedback in iterative cycles 1 while assuring that students engage with it, facilitates and promotes learning. 2 However, complex feedback could have negative effects on student motivation, 18 so we carefully designed our feedback to be a continuous intervention, as described below.Dialogic feedback suggests an interactive exchange in which interpretations are shared, meanings are negotiated and expectations are clarified. 5 Dialogic feedback is impacted by iterative cycles such as twostage assignments or multi-stage assignments that can involve feedback on the first stage, intended to enable the student to improve the quality of work for a second (or later) stage submission. 12 To facilitate iteration, we divided the students' Computer-Aided Design (CAD) project into several project elements (table S.1 in Supplementary Information), each tasked into a twostage assignment, initial and final, both graded by the same grader. Such iterative two-stage or multi-stage assignments are shown to be more promising than the end of the quarter assignments or examinations and have been reported to facilitate sustainable and dialogic feedback. 5 Personalization of the feedback allowed tailoring comments to students' learning needs. 7 Personalization was operationalized at two levels: (1) mistakes in assignments were identified and communicated to teams, (2) information tailored to each student's needs was reported to that individual student in the team using the Canvas Learning Management system (LMS) as shown in Figs. 1 and 2. It is known that the more personalized feedback is, the more dialogue it will support. 7 Another element that influences the potential for dialogic feedback is peer feedback. Peer feedback involves students engaging in reflective criticism of other students' products. 7 We designed one of the feedbacks in our course assessment as peer feedback (element 2 c-hand-drawn sketch of the bioreactor). Since student expectations and objectives can differ from the instructor's objectives, a peer evaluation rubric was given to all classmates, as shown in Supplementary Table S4 for Week 6 assignment. We facilitated the provision of anonymous peer feedback using Canvas LMS.Feedback content is also important, where 'content' involves both the verification and elaboration aspects. The verification is a simple judgment of whether an answer is correct, and elaboration provides hints, cues, analogies, explanations, etc. 24 (e.g., see comments in Fig. 2) . We also used a scaffolded, directive feedback approach where students were encouraged to reach the next goal of the assignment by addressing the points mentioned in the first feedback. Our feedback function was therefore directive in nature.Finally, the presentation of our feedback components was immediate; provided within 1-2 weeks of students' assignment submissions (see Supplementary Table 1 ). This decision was based on Mason and Bruning's framework for computer-based feedback. 19 We provided feedback mainly in written format than oral format, because Chickering and Ehrmann's 6 essay suggests that it is often easier to discuss values and personal concerns in writing than orally since inadvertent or ambiguous nonverbal signals are not so dominant in written format. Thus we had an opportunity to converse and exchange work through Canvas LMS more thoughtfully and ''safely''.We used the Comment feature and the Highlight and Free Draw annotation types in the point annotations as shown in Canvas DocView in Figs. 1 and 2 to give feedback. Other annotation features such as the Free Text, Strikeout annotation types were also found useful. Students could view our DocView comments from the assignment Submission Details page. The Assignment Comments section (Fig. 1) allowed for written dialogue. We could also send a comment to an individual student in the team if required, or to the whole group by selecting 'Send comment to this student only', or 'Send comment to the whole group' option respectively (Fig. 1) .Sadler 23 emphasizes feedback may simply be viewed as 'dangling data' if strategies are not provided for improving learning and monitoring how performance information subsequently influences the learner. We avoided making feedback such a 'dangling data' for students, by structuring project assignments as a twostage submission and provided rubrics, resources to students to improve their work before resubmission. Moreover, breaking the final project into various tasks to be completed weekly agreed with the important principle that assessment should inspire an even distribution of study time throughout a module, rather than being concentrated at its end. 11 The structuring of all student project deliverables into two-stages also allowed us to detect feedback effect on online learning. 22 Assessing the performance of students on elements 1a, and 1b, and 2 a, 2b, 2c (Fig. 3) , we found that there was an increase in students' final scores compared to their initial scores on each assessed project element. We believe this increase in student performance can be attributed to the personalized nature of feedback, that emphasized the connection with learning and promoted higher student engagement, in agreement with the results from liter- ature suggesting the use of such strategies in face-toface instruction. 3, 21 The median student grade on final CAD projects was 96%, the lowest was 89.33%, and the highest was 98.33%.We analyzed pre and post-feedback assignments for all project elements except the last two project elements-3 (CAD Method) and 4 (Drawings using Solidworks) because some teams were still working upon their CAD parts at the time of feedback (week 9). To facilitate feedback provision on these deliverables in the future, we will shift the last two deliverables by a week earlier.One project element-the Hand-Drawn Sketch warrants special discussion. The hand drawn-sketch assignment required anonymous peer feedback which was enabled via Canvas LMS. Detailed rubrics were provided to every student and each submission was analyzed per rubric by three students anonymously. We observed that the peer feedback process enhanced student engagement with the course content. Several students provided elaborate feedback with specific comments about positive and negative issues in a submission. Our experiences about peer feedback processes are in agreement with previous findings showing that the opportunities for dialogic peer formative feedback promote learning support and selfregulation. 13 While the feedback process significantly enhanced the students' final scores in all project deliverables, not all student teams reached an 'Accomplished' and above (Exemplary) level in the rubric, which essentially meant scoring more than 80% on a project deliverable. This is illustrated through data in Table 1 . Performance of teams on the assignments-Need Statement, Goals and Objectives, and Decision Matrix-indicated the weakness in applying the engineering design principles, which the students had studied in their first year.In contrast to these engineering design based assignments, the Preliminary Concept and Hand Drawn Sketch assignments showed higher class performance level. To address this discrepancy, we will place greater emphasis on engineering design principles in teaching the course in the future. However the increased achievement in graphics design assignments could be attributed to some other factors such as the related class content being fresh in students' minds; assignment being closer to the submission of the final report, better global picture of the project and role of this assignment in the project; a visual learning process happening via graphics/drawings; better interpretation of feedback by students than on the earlier assignments. We did not do any follow-up interviews or student surveys on this issue, but this will be worth doing in the future to know the underlying causes.Reflecting deeper on the student performances in the first three assignments of the project, namely the Need Statement, the Goals and Objectives, and the Decision Metrics assignments, we realized a need to introduce another competency in this course and train students to interpret the given feedback. Studies such as that by Winstone 25 have revealed that many barriers can inhibit the use of feedback, ranging from students' difficulties with decoding terminology, to their unwillingness to expend effort. Whereas the barriers identified could all in principle be removed, doing so would typically require a sharing of responsibility between teacher and student. This highlights the importance of training students to be proactive receivers of feedback, especially in an online environment. By structuring learning environments supportive of students' metacognitive training, 20 we can train our students to self-monitor their project progress and interpret and apply available feedback efficiently for improving the quality of their final product.The assessment of student project deliverables while constructing feedback also helped us spot the common issues that students were faltering upon in each project deliverable. These 'common issues' were mistakes found in submissions of about 5-6 teams (about 1/4th of a class) in their first iteration of the project deliverables. The early review of student-work helped us find these shortfalls, as listed in Fig. 4 . Spotting these mistakes was particularly helpful in the online environment because informal discussions and places for ongoing monitoring of evidence of learning are difficult to attain online. 14 Identification of any common mistakes we came across in the assessment of the first iteration of project deliverables, helped us to provide concrete, directive, and personalized feedback to teams for improvement while alerting the class to avoid such issues in the final submission. More importantly, identifying common errors helped us to adjust FIGURE 3 . Impact of feedback on students' scores of project elements before and after receiving the feedback: Each element was assessed twice, before feedback and after feedback. The total number of student teams was 24. Asterisk marks (*) indicate statistically different experimental groups as determined by a paired two-sample test performed on each element's pre-feedback and post-feedback scores for 24 teams. (N 5 24, p < 0.05).instruction to clear misconceptions about specific content/topics before students submitted their next iteration of the assignment.Student's progress in submissions showed progressive evolution of drawings from simplified preliminary concept drawings to more concrete, practical bioreactor CAD designs. For example, images in Figs. 5a, 5c, and 5e, indicate the different teams' preliminary concept sketches on paper that were later utilized to build their final bioreactor models (Figs. 5b, 5d, and 5f) using Solidworks. About 16% of teams (4 out of 24) even went beyond making the first iteration of their bioreactor in CAD, and after seeking feedback from teaching staff about it in week 9, drew an entirely new preliminary sketch on paper before re-building their new bioreactor model in CAD. Other teams focused on improving the quality of their CAD model sticking to their idea of a preliminary sketch. For e.g., connecting lines that are seen in the exploded view of CAD in Figs. 5b, 5d, and 5f, were initially missing in some teams' submissions, that were improved upon after feedback.The written mode gave us an excellent means to provide more intimate and protected feedback to stu- dent teams. The written form of feedback was perhaps less intimidating than the demands of face-to-face communication. This was illustrated by the fact that we received requests from 6 student teams (out of 24) for additional feedback on their iterations of the project, beyond the feedback cycle implemented that quarter. Furthermore, typed annotations of the student submissions eliminated any possible barrier of the illegibility of any written feedback. In Ferguson's study, 9 a large number of students reported difficulty reading written responses from teaching staff. This issue was eliminated by typed, easily accessible, and downloadable feedback in Canvas LMS. One observation this quarter was that students, in general, lacked coordination efforts for the final assembly of their project and were not comfortable approaching teammates in difficulties since the pandemic began. In that vein, a teammate rating assignment and continuous feedback for improvement can be helpful, as shown in Supplementary Materials FIGURE 5. Representative images from student submissions for project deliverables showing the evolution of drawings from simplified preliminary concept drawings (a, c, and e) to the final bioreactor CAD designs (b, d, and f). Drawings shown on the lefthand side of the arrows were created by student teams on paper, and drawings shown on the right-hand side of the arrow were created by the same teams in Solidworks. The final bioreactor models in CAD represent the multilayer series assembled reactor with easy to add/remove components, suitable for continuous flow of culture solution (part b); a cylindrical bioreactor with quick installation of scaffolds in hinge type chamber suitable for a heavy-duty operation involving high fluid flow volumes (d); and a lightweight, hollow bioreactor with reduced material use for stencil design (f), which also increases the volume of culture solution flowing through the reactor.(S2). Another idea is to go over the team-work logistics with each team, such as how are they going to make decisions about process, leadership, deputization, and coordination.We identified feedback characterized by multiple notions, such as dialogic iterative cycles, personalized, goal-directed, immediate, in written format, and having a peer assessment component. The process of providing formative feedback online through the structure mentioned in this paper helped us identify the common issues students are faltering at in a graphics design class and gave us opportunities to provide customized feedback, and ideal examples of expected work. The process of giving feedback inspired us with ideas and resources to teach innovatively and help students to achieve mastery of content in this course. It also possibly provided opportunities for metacognition to students by having them reflect on their previous assignment iteration.The formative feedback type we gave in the online environment resulted in students' improved scores on the final project elements. These results agree with many benefits of providing formative feedback reported in the literature 10, 17, 24 Continuing to offer high-quality formative feedback and improve upon such formative, dialogic, personalized, and written feedback will be important for us in the current COVID-19 pandemic, as well as future online instruction. Efforts will be made to make sure that students engage with the feedback given, and that the given feedback facilitates and promotes learning.The online version contains supplementary material available at https://doi.org/10.1007/s43683-021-00046z.",USA,first author,2021-02-12,02
d92118353c7b4635dcf94843e8236bd3e6d7abb5,Contribution of pulmonary diseases to COVID-19 mortality in a diverse urban community of New York,"As the World Health Organization declared Coronavirus disease (COVID-19) a pandemic, attention quickly shifted to New York City as it became the epicenter of COVID-19. 1,2 Consternation arose rapidly, as the world watched a parade of patients seeking help to alleviate their severe breathing discomfort, some lying in the hallway of overcrowded hospitals, witnessing healthcare providers frantically attending to those needing urgent care. It became very clear then that the principal reason that the majority of patients sought urgent care was related to shortness of breath, some reporting a history of pulmonary conditions (e.g., chronic obstructive pulmonary disease [COPD] , asthma and sleep apnea). In light of such evidence, public health officials began a media campaign advising that individuals should consider seeking care only if they had severe difficulty breathing, particularly if they had pre-existing metabolic conditions (e.g., obesity, hypertension, and/or diabetes). 3 Early evidence from Wuhan (China) showed that individuals with cardio-metabolic conditions 3 had an elevated risk of severe COVID-19 diagnosis. 1 Moreover, such individuals also had a greater likelihood of death due to associated medical complications. [4] [5] [6] Published reports to date have focused on cardio-metabolic burden as the principal driver of COVID-19 morbidity and mortality, lessening the emphasis on potential effects of pre-existing pulmonary diseases. A focus on the effects of pulmonary diseases is warranted as patients with such conditions may be at greater risk for COVID-19 morbidity, over and above risks conferred by metabolic conditions alone. This is consistent with the evidence that patients with such conditions sustain remarkable damage to their lung tissue and/or over-reactive airways, impairing the natural immunity of the airways. 7 In the first wave, New York City has been one of the largest epicenters of the COVID-19 pandemic. Therefore studying the characteristics of COVID-19 patients in a multi-ethnic city such as New York would yield a wealth of data to examine the contributions of cardio-metabolic burden and pulmonary conditions as potential ""at-risk"" conditions for COVID-19. In this report, we analyzed data derived from one of the largest existing US-based case series of patients with COVID-19, captured from a large quaternary academic health network covering a large catchment area from New York City and Long Island. Specifically, we assessed the relative contribution of common upper and lower airway pulmonary diseases (COPD, asthma and sleep apnea) in assessing likelihood of COVID-19 -related mortality independent of other medical conditions, health risks, and sociodemographic factors.Data were retrieved from a validated electronic health record (EHR; Epic Systems, Verona, WI), which included all inpatient and outpatient visits, beginning on March 2, 2020 and ending on May 24, 2020. COVID-19 testing was performed using the SARS-CoV2 Xpert Xpress assay in the Cepheid GeneXpert instruments. The targets amplified by these assays are the ORF1/a and E in the Roche Cobas assay and N2 and E genes in the Cepheid XpertXpress. Patients were tested if they presented to the emergency department with COVID-19 complaints or as clinically indicated. In the event testing was repeated and was found discordant (i.e. negative test followed by a positive test), we used the positive result. Details regarding procedures for defining positive COVID-19 cases have been published elsewhere. 2 EHR queries yielded age at time of testing, sex, selfreported ethnic minority aggregated as non-Hispanic black, Asian and Hispanic referenced to non-Hispanic white; cardio-metabolic conditions (e.g., hypertension, hyperlipidemia, diabetes, obesity, peripheral artery disease, and coronary artery disease); history of pulmonary disease (e.g., COPD, sleep apnea, or asthma); autoimmune disease; and cancer. This study was approved by the NYU Grossman School of Medicine Institutional Review Board.Determinants. Factors in our analyses were selected on the basis of prior work on COVID-19 patients. Age at time of testing, sex, race and ethnicity as reported by the patients were included. Median household income quartiles based on patient's 5-digit ZIP code were included as a proxy of socioeconomic status (25th percentile $34,361; 50th percentile $37,580; 75th percentile $41,328). 8 History of preexisting chronic health conditions such as hypertension, diabetes, obesity, hyperlipidemia, coronary artery disease, peripheral artery disease, autoimmune disease and cancer were included. Since the focus of the present analysis was to explore the relative risk of preexisting pulmonary conditions (as captured in EHR), we included upper and lower airway respiratory conditions (i.e., COPD, asthma, and sleep apnea). We defined COPD as the presence of chronic bronchitis or emphysema. 9 For patients with COPD or asthma, an effort was made to cross-validate the history of these medical conditions with reported COPD or asthma treatment.Demographic characteristics of the sample were contrasted using t-tests for continuous variables and w 2 tests for nominal variables. When non-normal distributions were detected, Kruskal-Wallis test was used. Spearman correlations were used to test the association between continuous variables. Statistical significance was defined by p < 0.05. We used Cox proportional hazard modeling to explore the relative importance of each of the predictors in assessing mortality risk. Before constructing the models, we used Random-Forest modeling to select factors that should be entered in the Cox model based on their clinical importance and feature importance in building parsimonious prediction model ( Figure 1 ). 4 In the model, we included all patients testing positive for COVID-19. A random forest classifier algorithm with 3-fold cross-validation was used on Python 3.7 for group prediction. Results of hyperparameter optimization showed that the optimal number of estimators (number of trees in the forest) was 10 and the maximum depth of the tree was 2. For Cox regression analysis, time-to-discharge was calculated using initial time stamp of the admission date and the time stamp on the discharge date. Event was defined based on the patient state (alive or deceased) at the moment of discharge. We included only patients who had been discharged alive or had died, omitting hospitalized patients with unknown state information. No information regarding post-discharge events was available during EHR queries. Anaconda Python 3.7 was used to perform all analysis and plots. Scikit-learn library was used for machine-learning and Lifelines for survival analysis.As of May 24 2020, a total of 11,512 patients admitted to the hospital were tested for COVID-19, with 4,446 (38.62%) receiving a positive diagnosis. Among those who tested positive, 959 (21.57%) died of COVID-19related complications at the hospital. Demographics and clinical characteristics of the sample contrasting patients who were alive or deceased upon discharge are provided in Table 1 . Differences in mortality rates were observed across age, ethnic minority status, sex, COPD, hypertension, diabetes, hyperlipidemia, coronary artery disease, peripheral artery disease, cancer, and time-to-discharge. Results of our survival analysis are shown in Figure 1 factor, followed by low income, ethnic minority status, diabetes, obesity, hyperlipidemia, male sex, hypertension, cancer, asthma, coronary artery disease, sleep apnea, COPD, peripheral artery disease, smoking status, and autoimmune disease (all sequentially presented from most to least important) [Panel B].In Table 2 , we show the results of the multivariateadjusted Cox proportional model. Of the demographic factors, age was strongly associated with higher mortality rates (HR ¼ 1.05; 95% CI, 1.04-1.05). Mortality rate was greater for ethnic minority (Asian, Non-Hispanic black, and Hispanic populations combined) (HR ¼ 1.26; 95% CI: 1.10-1.44) and for patients with low median household income (HR ¼ 1.29; 95% CI: 1.11, 1.49), but was higher for those of the male sex (HR ¼ 1.18; 95% CI: 1.03, 1.36). Of the clinical factors, higher mortality rate was associated with obesity (HR ¼ 1.19; 95% CI, 1.04-1.37) and peripheral artery disease (HR ¼ 1.33; 95% CI: 1.05-1.69). Of all the pulmonary conditions, COPD was independently associated with a higher mortality rate (HR ¼ 1.27; 95% CI: 1.02-1.58). Multivariateadjusted curves from the multivariate models are shown in Figure 2 . Our observational study identifies determinants of COVID-19-associated mortality among patients residing in New York City. In univariate analyses, we found that advanced age, male sex, patients who were Asian, non-Hispanic black, or Hispanics, and history/diagnosis of COPD, hypertension, diabetes, hyperlipidemia, coronary artery disease, peripheral artery disease, or cancer were more likely to die of COVID-related complications. However, with appropriate adjustment for known confounders, mortality rate was independently associated with advancing age, individuals from ethnic minority groups (Asian, non-Hispanic black, and Hispanic populations), low median household income, male sex, obesity, peripheral artery disease, and COPD. The area under the curve of our machine-learned model was robust and could potentially serve as the basis for developing a risk-score for future mitigation strategies or for prioritization of limited primary and secondary prophylaxis measures including vaccines.Clinical factors. Our finding that COPD is an independent factor associated with mortality among patients with COVID-19 is novel. Patients with COPD may suffer from greater risk for contracting more severe COVID due to their tenuous respiratory status, the de-implementation of noninvasive ventilation in many intensive care units due to concerns regarding aerosolization risk and greater risk for nosocomial spread to other patients and healthcare workers. 10 Noninvasive ventilation has been shown to reduce mortality in patients with COPD with acute respiratory failure 10 as well as likely over-expression of ACE2 receptors in epithelial cells which serve as targets for the SARS-CoV-2 virus. 11 Moreover, the antiviral immunity is impaired in patients with COPD and likely worsened by inhaled corticosteroids that are often prescribed to such patients. 12,13 A limitation of our study is that we do not have GOLD classification of the severity of COPD, although our findings of increased mortality risk among patients with COPD was independent of corticosteroid administration. The COVID-19 mortality risks associated with obesity and heart disease are consistent with published findings. In two parallel studies in New York City, investigators observed that both obesity and heart failure were predictive of mortality (HR ¼ 1.5; 95% CI: 1.0 to 2.2; HR ¼ 1.9; 95% CI: 1.4 to 2.5). 2 Likewise, results of a multivariate Cox model revealed that in addition to increased age (aHR ¼ 1Á31; 95% CI: 1Á09-1Á57 per 10-year increase) and chronic pulmonary disease (aHR ¼ 2Á94; 95% CI: 1Á48-5Á84), chronic cardiac disease was strongly associated with mortality (aHR ¼ 1Á76; 95% CI: 1Á08-2Á86). 14 Several other investigations conducted in varying US cities and across the globe have documented these associations, rendering them ubiquitous features of COVID-19 manifesfation. [15] [16] [17] [18] Our study makes a unique contribution to the literature in that it demonstrates that above and beyond the effects of other medical comorbidities, COPD seems the most important driver of mortality risks among the three pulmonary conditions we investigated.Sociodemographic factors. Both older age and male sex were positively and independently associated with COVID-19 deaths in our sample. Older age was associated with a greater likelihood of COVID-19 mortality relative to younger individuals. The observed age-related mortality has been reported previously and may be attributable to the presence of various medical comorbidities (including hypertension, diabetes mellitus, and coronary artery disease) among older individuals or may be related to immune senescence. 13, [15] [16] [17] [18] Compared to females, males had a greater likelihood of COVID-19 deaths. Males infected with SARS-CoV-2 virus seem more likely to develop severe disease and die. 19 This is line with global data, showing that the case fatality ratio is greater among males, relative to females. 19 Such sex differences in mortality may be attributable to underlying biological (such as greater burden of cardiovascular disease) or high-risk behaviors (delayed medical attention, alcohol consumption or smoking). Genetic factors that relate to X-chromosome containing greater density of immune genes and females having more Angiotensin Converting Enzyme 2 (ACE2) genes by virtue of ACE-2 being on the X-chromosome may confer stronger innate immune response as protection against acute lung injury, respectively. 20 Lastly, greater estrogen receptor stimulation among females may reduce levels of systemic inflammation. 19 We also observed a significant increase in mortality risk among ethnic minorities. While many other U.S. reports did not examine ethnic minority and socioeconomic status as determinants of COVID-19-related mortality in a comprehensive manner, 21-25 a few studies have examined effects of ethnicity, adjusting for variation in income, finding an increased risk for hospitalization among patients of black ethnicity. 26 Data from an integrated healthcare system in California revealed no mortality differences based on ethnic minority status, but that study might have been underpowered. 26 To our knowledge, ours is the largest study of COVID-19 that involved a machine-learning approach that revealed potential ethnic minority health disparities in COVID-19 related mortality. Such disparities in health and healthcare are not new; they are well documented and continue to persist especially in critical illnesses. 27 Indeed, in a large study of claims-based data from the Healthcare Cost and Utilization Project spanning from 2008 to 2012, blacks, Hispanics, and other ethnic minorities exhibited higher in-hospital mortality from sepsis-related respiratory failure compared with non-Hispanic whites. 27 Explanations for the observed ethnic minority differences in mortality rates could be that ethnic minorities typically exhibit greater comorbidities, may experience delayed or inadequate medical treatment due to limited health coverage, limited health literacy, and lack of access to quality medical care. Regarding access to care, it's notable that our finding of ethnic minority differences was independent of income although we did not determine other access to care issues such as insurance type or provider-availability. 15 Independent of healthcare system factors, there are genetic factors that confer race-based susceptibility to acute lung injury that have been well described. [16] [17] [18] Notwithstanding these observations, caution needs to be exercised as to how our findings are contextualized, which otherwise could create or potentiate harmful myths and perceptions that may unintentionally undermine the very same goal of dispelling health disparities. 14 Our findings provide a robust machine-learned model that can serve as the basis for developing a COVID-19 risk-stratification score, especially for patients who have a history of respiratory illness. The development and validation of a COVID-19 risk-stratification score that can predict mortality would be valuable for directing limited resources that include medications and vaccines aimed at improving outcomes in patients with COVID. Although such a score has been developed to predict ICU utilization 9 a population-based score that can predict mortality would be valuable for public and population health interventions aimed at limiting COVID-19 infections, transmissions and mortality rates.Despite the significance of our findings, results should be interpreted cautiously given a few methodological limitations. First, our data were collected with the primary intent of clinical care. Therefore, a few critical variables were missing from our dataset that might be informative for future analyses. For example, mortality might be somewhat suppressed because it is likely that some patients who were discharged may have subsequently died; this was not available in EHR queries. Likewise, data regarding other respiratory conditions likely to play a role in Covid-19 morbidity were not available. We were also unable to ascertain whether mortality risks associated with COPD might have been partially influenced by clinicians' decision not to use ventilation in certain cases. Future studies should have a more robust follow-up and longitudinal data collection framework. Second, income was based on the median income of the patient's ZIP code data, which is a crude representation of patients' socioeconomic status. In the same vein, we were unable to investigate the association between other proxies of socioeconomic status and COVID-19 mortality, such as social vulnerability and social determinants of health, which have been linked to poor, differential health outcomes among racial/ethnic minorities.Our findings indicate that patients with COPD had the highest odds of COVID-19 mortality compared with patients who had pre-existing metabolic conditions. Indeed, even among all the pulmonary conditions, COPD was the strongest independent predictor of mortality, which represents a meaningful contribution to the extant literature. In a way, this seems to have overwhelmed the evidence of deleterious effects of obesity on COVID-19 mortality. Based on our findings, it appears that only COPD as a lower airway respiratory condition is significantly associated with COVID-19 mortality, as smoking or asthma history were not significantly associated with mortality. Indeed, our survival analysis demonstrated that the peak of cumulative COVID-19 mortality rates among patients with COPD occurs much sooner (within the first 20 days of receiving a positive diagnosis) compared with those without a COPD history (within the first 50 days of receiving a positive diagnosis), suggesting patients with COPD are more likely to die sooner. In addition to the clinical conditions, several sociodemographic factors-increasing age, low income, ethnic minority status (non-Hispanic Black, Asian and Hispanic populations), and being malewere independently associated with COVID-19 mortality. These findings add to our current understanding of factors that should be considered in developing COVID-19 risk-stratification strategies.",USA,first author,2021-02-08,02
06f5f4d006ffe9ef11d40643b50239770a1cd9a4,Rapid processing of SARS-CoV-2 containing specimens for direct RT-PCR,"The COVID-19 pandemic has created a great demand for molecular tests that detect viral infection caused by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), the RNA virus responsible for coronavirus disease 2019 . Currently, the most accurate diagnostic tests for COVID-19 are based on detection of SARS-CoV-2 RNA. However, virus-containing biological specimens collected from patients contain components that negatively affect detection of viral RNA by degrading RNA and inhibiting RT-PCR. Several strategies have been developed to mitigate the negative actions of these components. Commonly used tests to detect viral RNA involve removal of extraneous components from a biological specimen by RNA purification. These tests include two steps: 1) a purification step to extract viral RNA from a patient sample (nasopharyngeal swab, sputum, or other); followed by 2) a quantitative reverse transcription PCR (RT-qPCR) assay to detect SARS-CoV-2 RNA. Effective target sequences for detecting SARS-CoV-2 RNA by RT-qPCR are located in the nucleocapsid (N) gene or the spike (S) protein gene of SARS-CoV-2, and the most effective target is the N1 sequence of the N gene [1] . The lower limit of detection (LOD) of RT-qPCR performed on samples of purified SARS-CoV-2 RNA using N1 primers is approximately 10 copies of viral RNA per reaction, with a cycle threshold (C T ) of 36 [2] . For automated detection of SARS-CoV-2 using cartridges for viral RNA isolation followed by RT-PCR, the LOD for detecting viral RNA was 14.8 copies per reaction and 365 copies per ml of a viral specimen, using primers for the S gene [3] . Alternatively, RT and a Loop-Mediated Isothermal Amplification (LAMP) method can be used to detect SARS-CoV-2 RNA. The detection sensitivity of an RT-LAMP test for SARS-CoV-2 was 100 copies of purified viral RNA per reaction [4] .Other RT-qPCR tests have been developed that eliminate the viral RNA purification step, in which a minimally processed virus-containing specimen is added directly to the RT-qPCR assay (direct RT-qPCR). Direct RT-qPCR offers advantages for streamlining testing because it is faster and simpler to implement than tests which require an initial RNA purification step. Most direct RT-PCR tests use saliva because it is more sensitive than nasopharyngeal swabs for detection of SARS-CoV-2 and it is simpler and safer to collect [5] .Several direct RT-qPCR diagnostic tests have been developed in which heat-processed saliva samples or viral suspensions in Universal Transport Medium (UTM) are diluted in a buffer, and an aliquot of the treated sample is added directly to a reagent mix to perform RT-PCR, without RNA purification. In one test, a viral suspension is heated at 95C for 10 min, then used for direct RT-qPCR [6] . For a low viral load (C T > 30); this method was not satisfactory and test results required further confirmation. In other direct RT-PCR tests, saliva was diluted with a buffer and heated at 95 C for 30 min and then supplemented with Tween-20 [7] or heated at 65 C for 10 min [8] ; an aliquot of the heat-treated, diluted sample was used for direct RT-PCR. The LOD for these tests, evaluated using saliva spiked with γ-irradiated SARS-CoV-2, was 1,000 copies of SARS-CoV-2 virus per ml of saliva [7] , or 6,600 per ml of a viral suspension spiked with synthetic SARS-CoV-2 RNA [8] . Another direct RT-PCR test for detecting SARS-CoV-2 RNA used saliva treated with dithiothreitol (Sputasol) and a ribonuclease inhibitor [9] . For this method, the LOD of the final RT-PCR mix, evaluated using saliva spiked with a viral RNA template of 99 bp, was 12 copies of RNA template per reaction (equivalent to 14,000 copies of viral RNA template per ml of saliva). Another publication described a method in which saliva samples were treated with proteinase K and then heated before being used in a direct RT-PCR assay [10] . The reported LOD for detecting SARS-CoV-2, evaluated using SARS-CoV-2 positive saliva, was 6,000 virus copies per ml of saliva. In direct RT-PCR tests, addition of non-ionic detergents, such as Tween-20 and Triton X-100, to saliva or swabderived samples was shown to increase the sensitivity of SARS-CoV-2 RNA detection [7, 11] .Our goal was to further simplify detection of SARS-CoV-2 RNA by direct RT-PCR and to enhance its sensitivity. We focused on the initial processing of clinical specimens because this step is time-consuming and critically affects the sensitivity of subsequent RNA detection assays.We developed a method, termed Alkaline-Glycol Processing (AG processing), patent pending [12] , in which a virus-containing specimen is briefly incubated in an alkaline-glycol solution and the AG-processed specimen is assayed for the presence of a viral RNA by direct RT-qPCR. The method builds on a previously described direct PCR assay for detecting DNA in biological samples [13, 14] . It was found that concentrated polyglycols in alkaline aqueous solution act as chaotropes, which increase the alkalinity of a lysis solution and promote alkaline lysis of biological samples.We tested detection of viral RNA using AG processing with human saliva specimens from multiple donors and virus-containing specimens suspended in Universal Transport Media (UTM) or Hanks' medium. Direct RT-qPCR assays were performed with a range of RT-qPCR products and kits, using γ-irradiated or heat-inactivated virus particles as template. We determined the LOD for detecting viral RNA using saliva spiked with a defined quantity of γ-irradiated or heat-inactivated SARS-CoV-2 virus particles or a defined quantity of synthetic SARS-CoV-2 viral RNA. We report that AG processing used with direct RT-qPCR provides a highly accurate and sensitive diagnostic test for COVID-19. The method is economical, scalable, and can be integrated into a range of diagnostic workflows and automated settings.RT-qPCR tests were performed using commercially-available one-step RT-qPCR kits. The following kits were used: TaqPath™ The following materials were used as substitutes for SARS-CoV-2 live virus: NIAID, NIH: SARS-Related Coronavirus 2, Isolate USA-WA1/2020, Heat inactivated (NR-52286; 1.16 x 10 9 genome equivalents per ml, BEI Resources, Manassas, VA, USA); γ-irradiated SARS-CoV-2 (NR-52287, 1.7 x 10 9 genome equivalents per ml, BEI Resources, Manassas, VA, USA); synthetic SARS-CoV-2 RNA, 99.9% genome coverage, Control 1 (MT007544.1) and Control 2 (MN 908947.3) (Twist Bioscience, San Francisco, CA, USA). Positive control plasmid contained SARS-CoV-2 nucleocapsid gene cDNA at 2 x 10 5 copies/μl (2019-nCoV_N Positive Control Plasmid, Integrated DNA Technologies, Coralville, IA, USA. Cat no. 10006625). Primers and detection probes for N1 and N2 regions of the nucleocapsid gene were sourced from Integrated DNA Technologies (cat. no. 10006770) that were manufactured using the U.S. CDC sequences and QC qualified under a U.S. CDC Emergency Use Authorization. The human RPP30 gene was used to confirm amplification of a gene known to be expressed in saliva (RPP30 primer set, exon 1-2, Integrated DNA Technologies, Coralville, IA, USA, Cat. no. Hs.PT.58.19785851).Human saliva samples (sputum) from individual donors were collected by Molecular Research Center, Inc, in accordance with an approved IRB protocol (MRC C19 protocol, ""Collection of saliva for detection of viral ribonucleic acid (RNA)"", IntegReview IRB, Austin, TX.). All participants were adults and gave written informed consent prior to study inclusion.Saliva was spiked with known quantities of a SARS-CoV-2 reference material. AG processing was performed by mixing one volume of an aqueous solution containing 65% (v/v) polyethylene glycol 200 (PEG200, CAS 25322-68-3) and 45 mM KOH, with two volumes of saliva or with two volumes of universal transport medium or Hanks' medium containing saliva. The resulting AG processing composition contained: 21.7% (v/v) PEG200, 67% (v/v) saliva, and 15 mM KOH, with pH ranging from 12.2 to 12.8 (depending pH of saliva specimens). AG processing was performed by incubating samples at room temperature for 5 to 30 min.An aliquot of 5 μl of the AG processed composition was added to 15 μl of RT-qPCR reaction mix; thus, each RT-qPCR reaction contained 3.33 μl of processed saliva. RT-qPCR was performed for 45 cycles (fast cycling) following the protocol specified for each manufacturer's kit. Reaction mixes were prepared using master mix, qPCR primer-probe mix, and Tris-HCl at pH 8 or 8.5, in accordance with the optimal conditions specified by each manufacturer. Where specified, the reaction mix included 0.2% Tween-20. Where indicated, some saliva samples were heated at 65 or 95 C prior to AG processing. Unless stated otherwise, each reaction was performed in triplicate and results are presented as the mean C T value. Each reaction plate included control reactions: positive control reactions consisting of synthetic SARS-CoV-2 RNA or SARS-CoV-2 cDNA, processing composition reactions with no reference material, and reactions with neither processing composition nor reference material. Results were considered valid if all controls provided positive or negative results, respectively. A target was considered undetected for C T values � 40.The RNA genome of SARS-CoV-2, like other RNA viruses, is protected by a protein-lipid envelope [15, 16] . This envelope must be lysed to release RNA and make it available as template in molecular assays. A biological sample such as saliva contains carbohydrate and protein components, including ribonucleases, that degrade RNA and inhibit RT-PCR. The alkalineglycol processing method developed in this study lyses virus particles and suppresses RT-PCR inhibitors. These combined actions allow for sensitive detection of viral RNA in saliva by direct RT-qPCR, without RNA purification. The high alkaline pH in AG processing is maintained by both a strong mineral base and glycols. In this report, AG processing was performed using a solution containing (v/v): 67% of saliva, 21.6% of polyethylene glycol 200 and 15-mM KOH. Depending on the initial pH of a saliva specimen, the pH during AG processing ranged from 12.2 to 12.8. Table 1 compares C T values for detecting SARS-CoV-2 RNA in human saliva by direct RT-qPCR performed with or without AG processing. Saliva samples were spiked with 10,000 copies of γ-irradiated or heat inactivated SARS-CoV-2 virus, or synthetic SARS-CoV-2 RNA. The N1 and N2 primer and probe sets amplified and identified target sequences in the nucleocapsid region of SARS-CoV-2 RNA. Both N1 and N2 primers amplified target sequences to a comparable degree, with the N1 primers performing marginally better. In compositions containing γ-irradiated or heat-inactivated virus, AG processing decreased the C T for detecting SARS-CoV-2 RNA by about 5 amplification cycles, indicating a 32-fold increase in detection sensitivity. These results demonstrate detection of SARS-CoV-2 RNA in AG-processed human saliva and show that AG processing significantly increases the detection sensitivity for SARS-CoV-2 RNA.An even greater effect of AG processing was observed in tests using synthetic SARS-CoV-2 RNA as template. In AG-processed saliva, the synthetic viral RNA was detected at C T 27, whereas without AG processing, viral RNA was undetectable using N1 primers and barely detectable using N2 primers. This result indicated that SARS-CoV-2 RNA in untreated saliva was rapidly degraded by saliva ribonucleases, rendering it unavailable as template for RT-qPCR. Collectively, the results in Table 1 suggest that AG processing increases the detection sensitivity for viral RNA by dual actions: it promotes release of RNA from the virus capsid, providing more usable RNA template for RT-qPCR, and it protects the RT-qPCR assay from inhibitory components in saliva.It is notable that detection of viral RNA was not impaired by the high alkaline pH of AG processing (typically pH 12.2-12.8), which is known to fragment RNA. A likely explanation for this finding is that limited fragmentation of the large SARS-CoV-2 RNA genome during AG processing did not preclude effective detection of short RNA fragments. Most RT-qPCR products are less than 100 bp in length. Thus, limited fragmentation does not preclude detection of short amplicons such as the 71 bp N1 and 67 bp N2 sequences in the CDC SARS-CoV-2 test. 5 minutes of AG processing was sufficient for effective detection of SARS-CoV-2 RNA ( Table 2) . Extending AG processing time to 1 hour did not alter detection.In addition to the Sigma KiCqStart kit used in Tables 1 & 2 , AG processing can be used with other commercially available RT-qPCR kits ( Table 3 ). The increase in sensitivity, measured as the decrease in C T , ranged from 32-to 70-fold.AG processing can be combined with a heating step prior to RT-qPCR and/or the addition of a non-ionic detergent to the RT-qPCR assay (Table 4 ). In our study, saliva containing inactivated virus was heated prior to AG processing and Tween-20 was added into the RT-qPCR reaction mix. Heating saliva for 30 min at 65 C or at 95 C substantially improved detection of viral RNA, as evidenced by a 5 C T decrease in amplification cycles. Addition of Tween-20 to the RT-PCR reaction mix had a similar beneficial effect on detection of SARS-CoV-2 RNA. i.e. either heating or addition of Tween-20, when applied separately, had similar beneficial effects on detection of SARS-CoV-2 RNA; however, their combined effects were not additive. When Tween-20 was present in the reaction mix, heating was not necessary to achieve the optimal SARS-CoV-2 detection sensitivity reported in this study. Nonetheless, heating clinical samples at >56 C to inactivate virus prior to handling can provide an additional layer of safety [17] . In additional experiments, Tween-20 added directly to saliva samples instead of the RT-qPCR reaction mix caused a time-dependent degradation of SARS-CoV-2 RNA (results not shown). Saliva specimens spiked with γ-irradiated SARS-CoV-2 were incubated for 30 min at 65 C or 95 C. After incubation, saliva specimens were AG processed and assayed by RT-qPCR using the KiCqStart One-Step RT-qPCR kit with the N1 primer and probe set. Each RT-qPCR reaction contained 1.00 x 10 4 virus copies. Some RT-qPCR assays were supplemented with Tween 1 -20 (CAS 9005-64-5) to reach 0.2% concentration in the reaction mix. Each C T value reports the mean of 3 replicates.https://doi.org/10.1371/journal.pone.0246867.t004AG processing of saliva with direct RT-qPCR allows a wide detection range (Fig 1) . The detection range for γ-irradiated SARS-CoV-2 RNA in AG-processed saliva was from 400,000 copies to 4 copies per RT-qPCR reaction. C T values ranged from 16.8 for 400,000 copies to 33.7 for 5 copies per reaction. Thus 400,000 and 4 copies per reaction correspond to 1.2 x 10 8 copies and 1.5 x 10 3 copies of viral RNA per ml of saliva, respectively.Human saliva collected from infected subjects contains from 10 10 to 10 4 SARS-CoV-2 virus particles per ml of saliva [5] . Thus, the method reported here-AG processing with direct RT-qPCR-provides an effective, sensitive, and robust diagnostic tool for detecting SARS-CoV-2 RNA.It has been reported that saliva samples provide a more sensitive specimen for detecting SARS-CoV-2 in COVID-19 patients than nasopharyngeal swabs [5] . However, nasopharyngeal swabs are still a prevalent method of specimen collection for COVID-19 testing. Following collection, oropharyngeal or nasopharyngeal swab specimens are immersed in UTM or Hanks' medium and taken for COVID-19 testing. Specimen collection by swab does not provide a consistent amount of biological matter for diagnosis and significant variability in the number of cells and viral particles in nasopharyngeal specimens has been reported [18] . In our tests of buccal swabs, the amount of swab-collected material varied over 2-fold, from 60 mg to 170 mg of specimen per swab.To simulate swab-derived clinical samples and provide a defined sample content for determining detection range, we prepared compositions containing γ-irradiated SARS-CoV-2 in UTM or Hanks' medium and 20% (v/v) saliva. The virus detection range for SARS-CoV-2 RNA was similar to that in AG-processed saliva (Fig 2) . C T values were 18.2 and 16.2 for 400,000 copies of SARS-CoV-2, and 35.5 and 32.2 for 4 copies of SARS-CoV-2 in UTM and Hanks' medium, respectively.To determine the lower limit of detection (LOD) for SARS-CoV-2 RNA copy number in AG-processed saliva, we tested samples containing single-digit numbers of virus particles per reaction (Table 5) . Saliva was spiked with SARS-CoV-2 virus to reach a final concentration of 3, 2, and 1 copy per reaction. Each viral concentration was tested in 20 repetitions. In accord with U.S. FDA guidelines, determination of LOD requires 19 positive detections out of 20 repetitions, and the FDA LOD is taken as twice the lowest detectable number of copies per mL of specimen. Results in Table 5 show 20, 19, and 19 positive RT-qPCR results for 3, 2, and 1 copy per reaction, respectively. The method detects 1 viral copy per reaction, which corresponds to an LOD of 300 viral copies per ml of saliva (600 copies/mL using the FDA definition). The LOD for SARS-CoV-2 RNA copy number in simulated swab specimens (20% saliva in UTM or HSSB) is given in Table 6 .It should be noted that the detection sensitivity of AG processing with direct RT-qPCR can be increased an additional two-fold by increasing the RT-qPCR reaction volume from 20 μl to 50 μl (results not shown).Finally, additional validation of our method was provided by the diagnosis of COVID-19 in three sample donors. The donors provided a self-collected saliva specimen that was incubated at 95 C for 30 min, then AG processed and used for detection of SARS-CoV-2 RNA by direct RT-qPCR with primers for the N1 target. Results showed amplification of the target sequence in the control samples without added reference material. In accordance with IRB requirements, these donors were notified of the results and instructed to consult a physician. They were diagnosed with COVID-19 following a positive result from an FDA-approved nasopharyngeal swab-based RT-PCR test.AG processing combined with direct RT-qPCR is an effective and sensitive method for detecting SARS-CoV-2 without a requirement for viral RNA purification. The sensitivity of the method for detecting SARS RNA in AG-processed saliva is on par or greater than existing AG processing solutions were prepared by mixing two volumes of saliva spiked with γ-irradiated SARS-CoV-2 and one volume of alkaline glycol solution, to contain 3, 2, or 1 viral particle(s) per RT-qPCR reaction, performed using the KiCqStart One-Step RT-qPCR kit with the N1 primer and probe set. Each reaction contained 3.33 μL of the initial saliva specimen.https://doi.org/10.1371/journal.pone.0246867.t005 Specimens consisted of 20% saliva in UTM or HBSS, spiked with γ-irradiated SARS-CoV-2, and were heated at 65 C for 30 min prior to AG processing. AG processing solutions consisted of two volumes of specimen and one volume of alkaline glycol solution. Each RT-qPCR reaction contained 3, 2, or 1 viral copy and 3.33 μL of the initial specimen, and 0.2% Tween-20. RT-qPCR was performed using the N1 primer and probe set using either a KiCqStart One-Step RT-qPCR kit or TaqPath kit.https://doi.org/10.1371/journal.pone.0246867.t006methods that require an initial RNA extraction step (Table 7) . Currently, all FDA reviewed kits that use saliva specimens require RNA purification, and their LODs range from 600 to 180,000 virus copies per mL of saliva [19] . Various methods for detecting SARS-CoV-2 in saliva without RNA extraction report LOD values from 1000 to 14,000 copies/mL [7, 9, 10] . AG processing is effective over a wide range of viral concentrations in either saliva specimens or samples collected by swab into media. AG processing is robust across different RT-qPCR platforms and works with multiple FDA-approved RT-qPCR products. These advantages, plus its simplicity and cost-effectiveness, can increase laboratory throughput and streamline COVID-19 diagnosis. Although this report focused on the use of AG processing for detection of SARS-CoV-2 in saliva or swab-derived oral specimens, the method can also be used for processing SARS-CoV-2 containing specimens derived from a variety of biological fluids and tissues. It is also easily adapted for processing specimens containing other RNA viruses. ",United States of America,first author,2021-02-10,02
ec23c971dd6feec865d152e7d5e5da55e1efc099,,"COVID-19 was first identified as a public health hazard in late December 2019 1 and was accorded pandemic status on March 11, 2020. 2 The national task force recommended, as part of its response to mitigate spread, a temporary nationwide halt on non-urgent procedures in the United States. 2, 3 Consequently, an executive order by the Florida governor authorized only urgent encounters beginning on March 17, 2020 and ending on May 11, 2020. 4 The American Academy of Ophthalmology and the American Society of Retinal Specialists formulated guidelines defining urgent conditions to offer guidance. 5, 6 Vision-threatening conditions were authorized for visits including intravitreal injections (IVIs) for various prevalent retinal vascular conditions. 6 Despite administrative efforts to maintain urgent appointments, some patients thought the clinic was completely closed or elected to defer their appointments due to personal concerns.We studied the characteristics and results of patients undergoing IVIs who re-established care during a six-week interval shortly following the restricted period.All studies were conducted after approval of Human Subjects Committee of the University of Miami which granted a waiver of study consent due to the low risk to the patient and the retrospective nature of the study, and in accordance with the Declarations of Helsinki. We reviewed a six-week study interval (from 6/18/2020 to 8/7/2020), a month after rescission which was chosen to allow for a transition to ""new normal"" operations. Inclusion criteria included adults ages 18 and over who had been engaged in active IVI treatment (defined as having had at least 3 prior visits) for a diagnosis of macular edema or neovascular complications. Exclusions included repeated injections within the study interval and eyes that had not been seen 3 times or within the previous 12 months.One retina specialist saw all patients during the study interval across four practice sites using the same electronic record. Standard protocols were enacted to maximize patient safety, including universal masks, social distancing through restrictions of visitors, use of plastic barriers at desks, and compulsive hand-washing. The previous three visits were reviewed to identify a delayed encounter which was defined as when the delay exceeded 33% of the previously scheduled follow-up cycle (eg, returning at >8 weeks instead of 6 weeks). A pre-COVID-19 control group was assembled from encounters during the corresponding interval in 2019. The treating physician typically (but not using a standard protocol) asked the patient why their visit was delayed, taking care not to compound their anxieties of missing the appointment.Clinical information analyzed is listed in Supplemental Table 1 . Outcome measures included BCVA (logMAR) change, OCT status (better, stable, worse), switch of intravitreal agent, and change in previously established followup interval. The OCT was judged to be worse when there was an increase in subretinal or intraretinal fluid; all changes were not subtle.Statistical analyses were performed using the SPSS 26.0 (SPSS Inc, Chicago, IL) software package. Analyses were performed using Pearson χ 2 analysis, Fisher exact test, and t-test, when appropriate. A p-value of 0.05 or lower was considered statistically significant.The number of IVIs in the 2020 study interval was 9.9% (219 vs. 243) lower than for the corresponding 2019 pre-COVID-19 control group (Table 1) cohort (p=0.021). Delayed encounters in the study group were attributable to patient concern for COVID-19 in 20/ 46 (43.5%) patients, other personal reasons in 10 (6.6%) patients, unspecified in 15/46 (32.6%) patients, and illness during the closure period in 1/46 (2.2%). One patient each in the delayed and not delayed group indicated having had COVID-19 infection.The delayed subgroup had a larger proportion with at least a 0.05 logMAR (3 letters) loss in BCVA, poorer OCT results (50%), and more often was switched to different IVI agents compared to those not delayed (p<0.03) ( Table 2 ). There were no statistically significant factors across the subgroups associated with worsening at re-presentation. However, eyes with wAMD were less frequently delayed compared to pseudophakic cystoid macular edema (5/6, 83.3%) and diabetic macular edema (21/45, 46.7%) (p=0.009) (Supplemental Table 1 ).This retrospective study showed 32% of patients returning for established IVIs were delayed in their follow-up during a six-week study interval shortly following the restricted interval; half of the delays were attributable to COVID-19 concerns. The magnitude of the disruption might be even larger, since nearly 10% fewer incident IVI patients were seen compared to a corresponding control group. Moreover, the consequences of delay included worse BCVA loss and more frequent worsening in the OCT features. This is one of the first studies to show worse visual acuities and OCT findings in eyes whose IVIs were delayed due the COVID-19 pandemic and is unique in that it surveyed results of those re-presenting rather than just those not presenting.Delayed IVI care is not unique to the constraints of the pandemic closure and has been shown by others to be associated with inferior outcomes in retinal vascular diseases. [7] [8] [9] Relatedly, we acknowledge that alterations in the management plan (changing agents, shortening of subsequent follow-up intervals) were subjective, based on the recommendations and potential biases of the treating physician.Obeid et al studied 9007 wet AMD patients in which 22% were lost to follow up for over 12 months after IVI. Risk factors for failure to return included lack of VA improvement, female gender, non-Caucasian, distance residing from the office, and unilateral versus bilateral treatment. 10 Gao et al reported 25% of 3400 patients with retinal vein occlusion with macular edema were lost to follow-up over 12 months. Risk factors included non-Caucasian, <65 years, and poorer baseline vision. 11 The current study did not demonstrate these risk factors, but was substantially smaller and was conducted under a different setting.Lange et al estimated that by May 2020, nearly 41% of adults had delayed medical care due to fear of the pandemic, corresponding to marked reductions in both routine and emergency encounters for life-threatening conditions. 12 Recent studies show that the 2020 pandemic closure resulted in a 53-75% reduction in IVIs when compared to 2019. 4, 13, 14 Our study demonstrates a relatively lower, but significant, 10% overall decrease in IVI volume in 2020 after the severest of restrictions were rescinded compared to the same period in 2019, with over 2.5 times as many delayed intravitreal injection treatment encounters. At least 42% of these delayed IVIs were directly related to pandemic-related constraints.Reports from other countries have suggested a similar experience as is related in the current manuscript. Saleh et al reported that intravitreal injections were safely delivered, without any know Covid-19 case transmission in a tertiary care clinic in Jordan, but clinical volumes were diminished due to patient fears regarding contracting the virus. 15 Moreover, those who did seek care had poorer presenting visual acuity. Two studies from Milan, Italy also documented decreased clinical (up to 71%) and injection (54-58%) volumes. 13, 16 There was a higher rate of submacular hemorrhage among wAMD patient reported 16 and a higher rate of absence among elderly and wAMD compared to other diagnostic categories. 13 Diabetics and the elderly wARMD represent groups that are at higher risk of complications from COVID-19 infection. Understandably, those patients frequently chose not to risk coming to their appointments. A dependence on travel arrangements to appointments, the need to quarantine for those in assisted living facilities, inaccurate information regarding their healthcare appointments, and illness were also likely was also additional factors in reduced compliance with IVI-based follow up during the COVID-19 pandemic period.The current study captured cases that re-presented after a delay, rather than ascertaining the cohort that did not present as previously scheduled. The retrospective study design did not permit us to collect the reason for the delayed return in a standardized fashion.In conclusion, the potentially deleterious effects of the pandemic closure period require careful consideration if future healthcare constraints are imposed. Clear messaging to define and to distinguish urgent and non-urgent categories of medical disease is essential. The degree of recovery after reestablishing care merits further investigation.All authors made a significant contribution to the work reported, whether that is in the conception, study design, execution, acquisition of data, analysis and interpretation, or in all these areas; took part in drafting, revising or critically reviewing the article; gave final approval of the version to be published; have agreed on the journal to which the article has been submitted; and agree to be accountable for all aspects of the work.Supported by NIH Center Core Grant P30EY014801, Research to Prevent Blindness Unrestricted Grant.Dr Noy Ashkenazy served in the Advisory Board for Alimera Sciences in May 2020. The authors report no other potential conflicts of interest (financial and/or non-financial) for this work. ",USA,first author,2021-02-03,02
808285057cd4e6b43a1a7bbf156d8b2a026f50da,,"taxes, such as soda taxes, on consumption and health. Recent examples include studies showing that at-risk subpopulations such as obese children coming from low-income families are more sensitive to soda taxes [7, 8] .In contrast, the relationship between grocery taxes and health outcomes has received little attention. This is somewhat surprising given that relative to soda taxes, grocery taxes are far more common, a significantly larger percentage tax on average, and they apply to all grocery foods so represent a considerably larger share of household income. The current lack of research on the impacts of grocery taxes is unfortunate since it is during times of economic hardship, such as a COVID-19 induced recession, that policies such as grocery taxes receive greater consideration as a source of stable tax revenue for state and local governments.Grocery taxes can affect the odds of eating at home versus dining out through changing the relative effective prices (tax included price) of grocery and restaurant foods. Compared with states such as New York where restaurant foods are taxed while grocery foods are tax exempt, taxing both grocery and restaurant foods in states like Alabama creates more of a disincentive to eat at home [9] . For the poorest segment of the population, fast food restaurants become their primary option as a substitute for grocery foods because fast food restaurants are both more accessible [10, 11] and cheaper [12] . In particular, two recent empirical studies show that grocery taxes reduced U.S. consumers' grocery food expenditures and increased restaurant food expenditure, and restaurant food sales taxes increased U.S. consumers' grocery food expenditures [13, 14] . Therefore, the substitution from grocery food to fast food in response to taxing groceries may increase the odds of unhealthy outcomes since there is evidence that consumption of fast food affects a person's risk of becoming both obese [15] and diabetic [16] .Unlike soda or fat taxes, grocery taxes apply to thousands of grocery items and may effectively change consumers' grocery food choices. Though not all grocery foods are healthy, reduced consumption of fruits and vegetables may induce obesity [17] and diabetes [18] , and food-at-home is widely considered healthier than food-away-from-home. Therefore, we hypothesize that health outcomes are negatively correlated with grocery taxes. We choose two health outcome measures for this study: obesity and diabetes rates within a county, because food consumption is closely related to obesity and diabetes.It is well known that individuals gain weight whenever consumed calories exceeds expended calories [19] . Yet, rates of obesity vary significantly from person to person according to the individual's social economic status [20] like education [21] , income [22] , gender [23] , age, and race [24] . In addition, individual body mass index (BMI) is also highly related with individual risky behavior such as smoking [25] and alcohol consumption [26] . However, these individual-level reasons do not explain fully the increasing prevalence of obesity across the entire society over time.Researchers from multiple disciplines have identified various underlying causes of obesity epidemic from different perspectives, such as decreasing price per calorie [17] , high availability of fast food, high cost of healthy food [27] , difficulty to access healthy food especially for lower-income households [28] , and the high amount of marketing of unhealthy food and beverages especially among younger children [29] . While the evidence is mixed, some studies have identified physical inactivity as a cause for obesity, attributed to urban sprawl [30] , labor-saving devices such as dish washers [31] , and increasingly sedentary occupations [32] . Similar to findings in the obesity literature, the rising rates of diabetes has been attributed in part to environmental factors, such as the abundance of food supply and sedentary lifestyles [33] [34] [35] . In fact, 60% of diabetes cases can be attributed to being obese or overweight [36] .In terms of magnitude, the quantitative significance for obesity and diabetes risk factors also varies widely. For instance, quitting smoking has been found to reduce body mass index (BMI) by 1.8-1.9 units with a BMI above 30 defining obesity [25] . As a separate example, a one percent increase in soda taxes has been associated with at 0.013 decrease in average BMI [8] . Overall, there is not clear consensus on the aggregate effects of different risk factors on either obesity or diabetes rates, especially among individual studies that examine specific sub-populations.In summary, the public health literature has identified a multitude of causes for the rising obesity and diabetes epidemic in the United States, including prices, food availability and accessibility, and marketing. The aim of this study is to examine another potential factor which has not been investigated previously: the relationship between grocery food taxes and health outcomes. Despite the fact that groceries are taxed in one third of U.S. states as well as on-going debates on whether to impose significant grocery taxes (e.g., New Mexico and West Virginia), there is, to our knowledge, no comprehensive dataset on state and county-level grocery taxes exists. Therefore, one contribution of our work is the development of a comprehensive dataset on state and countylevel grocery taxes from 2009 through 2016, which we then link to county-level estimates of obesity and diabetes rates. The main empirical contribution of our work is to estimate the effect of grocery taxes on these two important health outcomes using our novel county-level panel data and a county fixed effects estimator that also includes time-varying variables to control for socioeconomic factors, risky behaviors, and food access and affordability environment. A third contribution is policyfocused, we calculate benefit-cost ratios of eliminating grocery taxes as a way to assess the quantitative significance of grocery taxes in determining obesity and diabetes rates.We organize county-level panel data consisting of six time periods on obesity and diabetes rates, food taxes, socioeconomic characteristics, and risky health behaviors. Each of the six periods is 3 years in length; thus, the unit of observation in the statistical analysis is the county-three-year period. Each of the six periods in the study has a 1 year overlap with the subsequent period or the preceding period or both- Fig. 1 depicts this somewhat unique structure of our county-level panel data and empirical design. We develop this data structure because the outcome variables of obesity and diabetes rates are only precisely estimated and reported based on the average of a 3 year-sample window. Concordance on the timing of measurements between the health outcome variables and the explanatory variables requires that the food tax, socioeconomic, and risky health behavior variables also be measured as three-year averages. A separate justification for measuring each variable as a three-year average is that the adjustment of diets due to a tax change, and any subsequent transition to or from obesity is not likely immediate.We assemble a large set of data on state-and countylevel grocery tax rates in the U.S. from 2009 to 2016.The key independent variable of interest in this study is the total grocery sales tax, measured as a percentage. The total tax is the sum of the state-level and countylevel grocery sales taxes. We also collect data on restaurant sales taxes, which we use to calculate the ratio of the grocery to restaurant sales tax as an alternative explanatory variable. The tax data are obtained from Bridging the Gap for state tax rates, Tax-Rates.org for 2016 county rates, and state Departments of Revenue for the rest (by online searching by two research assistants over an extended period of time).We assess two dependent variables in our analyses: 1) three-year county-level obesity prevalence; and 2) threeyear county-level diabetes prevalence. County-level rates of diagnosed obesity and diabetes are obtained from the Centers for Disease Control and Prevention (CDC) county data indicators [37] , which are three-year average rates calculated by CDC using annual surveys from the Behavioral Risk Factor Surveillance System (BRFSS) [38] and are based on a three-year average to improve precision. For both obesity and diabetes outcomes we use age-adjusted rates to measure the health outcomes.We collect data for control variables in the regression analysis from multiple sources on a wide range of socioeconomic data measured at the annual level. To conform the explanatory variables with the dependent variable, we use the annual socioeconomic data to construct three-year county level averages for use as control variables in the regression analysis. The first set includes food environment/access/affordability including the numbers of grocery stores, fast food restaurants, and full-service restaurants, and the average cost per meal. The former three variables are from the Census Bureau's County Business Patterns [39] and the latter is from Feeding America [40] . Socioeconomic measures on population, race, gender income, employment and [41] . The per capita income and employment rate are from the Regional Economic Information System (REIS) [42] .Additional control variables include data on risky health behaviors, which are also at the annual level and used for constructing three-year county-level averages. The county-level prevalence estimates of smoking and alcohol use are obtained from BRFSS. Smoking is measured as the percentage of adults in a county who both report that they currently smoke every day or most days and have smoked at least 100 cigarettes in their lifetime. Excessive alcohol use is the percentage of adults that report excessive alcohol consumption in the past 30 days in each county. Data on drug-possession and driving under the influence (DUI) arrests are obtained from the County Level Detailed Arrest and Offense Data supported by the Uniform Crime Reporting (UCR) Program [43] . We divide the arrests by county population from REIS to obtain per capita possessing-drug and DUI arrests.In total we have tax data for 3101 U.S. counties. We only keep 2446 counties in the dataset due to our study design. Moreover, 408 counties are lost when merging in socioeconomic variables. After eliminating the 180 singleton counties, we are left with 1858 counties in the dataset. Of these counties, 87 experienced a grocery tax change in the year 2012, 2013 or 2014. The other 1771 counties experienced no grocery tax change during the study window (2009-2016); 1250 of these counties never have a grocery tax, while 521 have a constant grocery tax during the study window. In terms of our entire panel of county-period observations, we only keep observations for which the grocery tax is constant within the three-year period. As a consequence, counties with grocery tax changes appear in exactly two periods each, which correspond to either 1) the 3 year periods before and after 2012, 2) the 3 year periods before and after 2013, or 3) the 3 year periods before and after 2014. Counties with no tax grocery tax changes during our study window will appear in each of the six periods unless there is missing data for covariates in a county for some years. If our panel of counties with no tax changes is balanced, then we would have 11,148 observations (1858 counties by 6). Of the 1771 counties without tax changes, 1319 of them appear in all six periods. In terms of total county-period observations, we have 9979 observations; observations 9805 observations from our panel of counties that never experience a tax change and 174 observations from counties that do experience a tax change.We estimate the effects of grocery taxes on obesity and diabetes rates resulting from changes in county-level grocery taxes in the years 2012, 2013 and 2014. Our estimating procedure uses a county fixed effects linear regression model for county-level, age-adjusted health outcomes. The main explanatory variables of interest are 1) grocery taxes and 2) restaurant taxes. Our main parameter of interest describes how changes in the countylevel total grocery sales tax relates to county-level health outcomes on average, after parsing out other observable variables and unobservable time-constant variables. Standard errors are clustered at the state level to account for arbitrary intra-cluster correlations between the error terms [44] . The regression model controls for county-level food access, demographics, socioeconomics, and risky health behaviors. The model also includes period fixed effects to control for period-specific time shocks common to all counties and county fixed effects to control for county-specific time-invariant factors.In addition to the main analysis described above, we assess the robustness of our results to an alternative measure of food taxes-the ratio of the grocery tax to the restaurant tax. Because some counties have no restaurant tax, we add 0.01 to both the numerator and denominator. This adjustment has only a small influence on the ratio when then the restaurant tax is non-zero, which is the vast majority of observations. In all instances when the restaurant tax is zero, the grocery tax is also zero, which makes the ratio equal to one in such cases. To us this transformation is reasonable since it keeps intact the ratio when the denominator is non-zero, and implies parity when the denominator is zero.A map of grocery taxes Figure 2 presents a map of the United States depicting county-level grocery taxes along with the top 12 most obese states identified in bold. This figure illustrates that grocery taxes are more prevalent in states with the highest obesity rates. Figure 3 plots the average rates of obesity and diabetes from 2009 through 2016 for both counties with and without a grocery tax (state, county, or both). Over this period, the national average obesity and diabetes rates increased significantly, especially after 2013. If we look at counties with and without grocery sales tax separately, the taxed counties are less healthy. Specifically, the average obesity and diabetes rates of counties with taxes are approximately 3 and 2.5 percentage points higher, respectively. Figure 3 clearly shows that counties with a grocery tax consistently were worse for both obesity and diabetes.In Table 1 we present the summary statistics of the variables used in our analysis. The first three columns in Table 2 report the regression results of obesity rates on grocery sales tax rates under a base specification with year fixed effects, the base specification augmented with county fixed effects, and a third specification that also adds time-varying control variables. The results in columns 1, 2 and 3 are all similar with point estimates of 0.707, 0.606 and 0.588, respectively. Under all specifications, the grocery tax is positive and statistically significant at the 1% level. Our preferred specification reported in column 3, which includes the most comprehensive controls (county fixed effects plus a number of factors identified in the literature), suggests that a onepercentage point increase in the grocery tax rate is associated with a 0.588 percentage point increase in the obesity rate. In contrast, the coefficient on the restaurant tax is negative in sign (− 0.158), though it is statistically indistinguishable from zero.The results in columns 4, 5 and 6 present the results for diabetes rates. The point estimates of 0.400, 0.252 and 0.215, respectively. Under all specifications, the grocery tax is positive and statistically significant at the 5% level. Our preferred specification reported in column 6 suggests that a one-percentage point increase in the grocery tax rate is associated with a 0.215 percentage point increase in the diabetes rate. Again, the coefficient on the restaurant tax is negative in sign (− 0.127), though it is statistically indistinguishable from zero.In Table 3 we assess the robustness of our results for both obesity and diabetes rates using an alternative food tax measure-the grocery tax to restaurant tax ratio is used as the main independent variable instead of the grocery tax. Results are consistent with those reported in Table 2 and are statistically significant at the 5% level for specifications including county fixed effects.We find evidence that grocery taxes have an adverse effect on both obesity and diabetes rates. Specifically, assuming our county fixed effects estimator is not biased by time-varying omitted variables, then a one percentage point increase in grocery taxes increases obesity and To put our results in context from a policy perspective, we calculate benefit-cost ratios (BCRs) to summarize whether the health benefits associated with reducing the grocery tax by one percentage point are likely to exceed the cost of foregone tax revenues from their reduction. Table 4 reports the ratios and Additional File 1 shows the full regression results as well as the detailed steps to obtain the ratios.Our preferred estimates of annual expenditures (direct costs only) for treating obesity and diabetes are $1901 [45] . We also considered variations among cost estimates; for example, a meta-analysis found that the annual medical expenditures attributable to treating obesity for a person with the condition varies from $1239 to $2582 [46] . Therefore, in a sensitivity analysis we consider low and high estimates for these figures, these results are also summarized in Table 4 .The top portion of Table 4 summarizes our estimates of health burdens associated with grocery taxes. The aggregate U.S. health burden of grocery taxes in the year 2016 due to medical expenditures on obesity and diabetes is calculated to be $5.86 billion (95% C.I. is $1.81 billion to $10.30 billion).The bottom portion of Table 4 summarizes the BCRs. The calculated BCRs for obesity, and diabetes using our preferred estimates of medical expenditures are 0.666 (95% C.I. is 0.324 to 1.008) and 1.23 (95% C.I. is 0.163 to 2.329), respectively. The BCR of these two factors combined is 1.896. Similar to health burden analysis, we also summarize the results of our sensitivity analysis for the BCR. Based on the sensitivity analysis and taking into account a range based on sampling variability of our regression output, our lowest estimate of the combined BCR is 1.289, and the highest is 2.601.Many states and local municipalities have recently considered changing their grocery tax, such as West Virginia in 2017 (proposing an 8% new tax) and Utah in 2018 (proposing removing grocery taxes). States and counties that tax food need to understand that this policy is associated with adverse health outcomes. Our preliminary results suggest that officials in states that tax groceries should take a closer look at ways to lessen the potential burden of such taxes as a way to improve health outcomes for the community. Decreasing the grocery tax, would reduce tax revenue, and government officials would need to look at alternative revenue generating options if it lowered grocery taxes. Another option to off-set the potential adverse effects of grocery taxes would be a tax credit, though it would have to be sufficiently large to off-set the tax. Further, it is not clear how a lump-sum tax credit would affect the marginal responses to taxes we estimate in our analysis.Furthermore, we find that the ratio of the grocery tax to the restaurant sales tax is also positively associated with adverse health outcomes. In particular, a doubling of this tax ratio is found to increase obesity and diabetes rates by an average of 0.773 and 0.21 percentage point, respectively. This has policy implications that should be considered especially by states and counties that are either considering levying a grocery tax or eliminating it. It is possible the adverse health outcomes could be lessened if this relative tax ratio were lowered in states with grocery taxes. For example, one option would be to consider a revenue neutral simultaneous decrease in the grocery tax and increase in the restaurant (particularly fast-food establishments) tax as a way to lessen adverse health outcomes.Our county-level depiction of grocery taxes in the United States reflects the first comprehensive dataset on state and county-level grocery taxes and shows a clear spatial correlation between grocery taxes and nutritionrelated health outcomes. The regression results, which are based on data county fixed effects estimator, shows a strong statistical relationship between grocery taxes and both obesity and diabetes. Several states and counties Note: Standard errors are in parentheses. *, **, and *** denote statistically significance at the 10, 5, and 1% levels, respectively are actively considering the levying or removal of grocery taxes. Our study design is only one component of the costs (or benefits) of a grocery tax; nonetheless, the results are thought-provoking and suggest the possibility of a large health burden from grocery taxes and a benefit-cost ratio greater than one corresponding to reductions in the grocery tax. Based on our findings using a novel panel dataset combining comprehensive countylevel grocery tax data with county-level health outcome measures, we recommend both researchers and policy makers give further consideration to the removal of grocery taxes a possible mechanism to improve health outcomes. Meanwhile, more evidence would be required to pin down a mechanism through which grocery taxes may affect health outcomes; for example, more evidence on the potential link through fruit and vegetable consumption choices.The Authors' contributions YZ, DD, and HK formulated research questions, LW conducted the literature review, collected and processed data on obesity and diabetes rates and control variables, YZ, DD, HK, and SB designed the study, all contributed to the writing and YZ, SB, and LW carried out the statistical regression of this study and were major contributors in writing the manuscript. All authors read and approved the final manuscript.This work was funded by the U.S. Department of Agriculture (USDA) Economic Research Service through a cooperative agreement under federal grant number 58-4000-8-0020.The obesity and diabetes datasets generated during and/or analyzed during the current study are available in the CDC WONDER system. The scanner data that support the findings of this study are available from the Nielsen company but restrictions apply to the availability of these data, which were used under license for the current study, and so are not publicly available.The tax datasets used during the current study are available from the corresponding author on reasonable request.Ethics approval and consent to participate Not applicable.Not applicable. Note: In parentheses we report the 95% confidence interval derived from the sampling variability of the regression coefficients reported in columns (3) and (6) of Table 2 ",United States,abstract,2021-02-13,02
36d827f604a563caae4f68f1878cb20f18d78bc6,Low level of Vitamin C and dysregulation of Vitamin C transporter might be involved in the severity of COVID- 19 Infection,"of ascorbic acid could reduce SARS-CoV-2 infection via the supplements ability to boost immune response along with diminishing the severity of the viral-mediated inflammatory response. A number of studies support the finding that a high dose of the vitamin helps boost the immune system [5, 6] . Still, there are several important variables for which there is little information, including the impact of aging, vitamin C transporter system, gender, and race. Therefore, this paper aim is to summarize previously published data pertaining to the effects of vitamin C administration/supplementation on the immune response, disease prevention, and progression. We also discuss the role of age, vitamin C transporter systems, gender, and race, and their impact on the effectiveness of vitamin C in diseased conditions. COVID-19 infection disproportionally affects older individuals, males, and specific populations, including African American and Hispanic groups [7] . Therefore, it is important to consider and thoroughly investigate the factors mentioned above before arriving at any conclusion on the effectiveness of vitamin C treatment.Vitamin C, also known as ascorbic acid, is one of the essential vitamins needed for mammalian species to survive and thrive. Through evolution, the homo sapiens species has lost the ability to synthesize vitamin C due to the inactivation of the gluconolactone oxidase gene [8] . However, fruits and vegetables such as strawberries, oranges, and broccoli are rich in vitamin C and readily available for human consumption. Due to its watersoluble nature, most vitamin C is absorbed across the intestinal lumen and transported across cellular membranes via sodium-dependent vitamin c transporter 1 and 2 (SVCT 1 and 2) depending upon tissue type. There is an alternative way that the vitamin can gain access to the intracellular space, that being via the Glucose Transporters (GLUTs). However, the vitamin must be in the oxidized form (dehydroascorbic acid) for this to occur. Vitamin C's unique chemical properties, such as being an electron donor/reducing agent, allow it to have antioxidant properties and act as a coenzyme for more than fifteen mammalian enzymatic reactions [9] . These enzymes include monooxygenases (Dopamine β-Hydroxylase critical for norepinephrine synthesis), dioxygenases (Prolyl-Hydroxylase and Lysyl Hydroxylase), and amine oxidase [10] . Perhaps one of the most well-known actions that vitamin C participates in involves hydroxylation of proline and lysine residues during the synthesis of collagen [9] .Low levels of vitamin C can cause a myriad of problems, with prolonged deficiencies leading to scurvy, a disease often associated with sailors in the 1800s (due to lack of fresh fruits and vegetables) while at sea. Symptoms such as bleeding gums, abnormal wound healing, and fever are commonly associated with the disease and can be attributed to the inability of certain enzymes to function properly, especially those involved in collagen synthesis. Furthermore, it has been noted from previous studies that patients suffering from various pathophysiological conditions such as diabetes, COPD, chronic hypertension and viral induced sepsis, have decreased levels of serum and plasma vitamin C [11] [12] [13] [14] . This has led to studies on the use of intravenous administration of vitamin C for the treatment of patients suffering from severe and chronic diseases as well as viral infections such as COVID-19.It has been noted from previous studies that resting neutrophils contain high intracellular levels of vitamin C, around 1-2 mM, or about 10-100 fold higher than average plasma levels [15] . This intracellular concentration only increases when neutrophils are activated and begin to undergo oxidative burst, with levels reaching 10-20 mM following stimulation [15, 16] . Due to this phenomenon and vitamin C's antioxidant properties, it has been hypothesized that vitamin C plays a vital role in neutrophil function and thus essential for proper immune system response. In order to investigate this hypothesis, Bozonet et al. (2015) [6] conducted a cohort study including fourteen men (aged [18] [19] [20] [21] [22] [23] [24] [25] [26] [27] [28] [29] [30] for four weeks in which they maintained a regimen eliminating juice and high vitamin C foods, such as citrus and kiwifruit, from their diet to achieve suboptimal plasma vitamin C levels (<50 μmol/L). Following the initial four weeks ""lead-in"" period, baseline data was obtained via a blood sample. Plasma vitamin C and neutrophilic superoxide levels were measured, as well as neutrophil chemotaxis assay performed. The men were then given two gold kiwifruit (~256 mg Vit C) a day for four weeks. Blood samples were then drawn again following the four weeks [6] . They reported that the mean levels of serum vitamin C and neutrophilic vitamin C substantially increased from baseline to post-intervention (26±3→72±2, 21±1→26±2 mM; respectively). Mean neutrophil chemotaxis showed an increase of 20% (p = 0.041) as well as an increase in superoxide production of 23% (p = 0.031) postintervention. The end results showed that adequate vitamin C levels are imperative for proper neutrophil function and normal immune system function [6] . It is known that in patients with severe COVID-19 infection, hyperactivity within the immune system is rampant. However, there are indications that providing excessive vitamin C in those with deficient levels will allow for proper immune function, thus limiting and decreasing the severity of the infection.Vitamin C is highly water-soluble; it cannot directly diffuse across the hydrophobic lipid bilayer of the plasma membrane to gain access into cells. A specific transport system, sodium-dependent vitamin C transporters (SVCT), exists in the plasma membrane to mediate the entry process. There are two subtypes of sodiumdependent vitamin C transporter, SVCT1, and SVCT2 [17] [18] [19] [20] . The expression of vitamin C transporters is cell and tissue-specific. Sodium-dependent vitamin C transporter 1 is expressed in a number of different tissue and cell types, including liver, kidneys, and intestinal epithelial cells, whereas SVCT2 transporter is expressed in various tissues such as liver, brain, heart, chondrocytes, and osteoblast [17] [18] [19] . Several studies reported that aging, oxidative stress, and inflammatory factors cause changes in the expression of both SVCT 1 and 2 [17, 21] . Only a few human studies reported the regulation of vitamin C transporter in pathophysiological conditions. In 2014, our lab demonstrated that the SVCT2 transporter expression is significantly down-regulated in osteoarthritic tissue compared to healthy tissue [22] . However, expression of the vitamin C transporter is not altered in all pathological conditions. Larsson et al. (2015) reported no differences in SVCT 1 and 2 expressions in alveoli tissue, macrophages, lymphocytes, and neutrophils when comparing asthmatics to healthy subjects [23] . But, there are several in vitro and animal studies demonstrating drastically altered expression of vitamin C transporter (SVCT1 and SVCT2) in the presence of oxidative stress, inflammatory factors, and various disease conditions (See Table 1 ) [22, [24] [25] [26] [27] [28] [29] . Further research into the regulation of the SVCT expression under various pathophysiological conditions is warranted in order to better understand whether these alterations are normal fluctuations, or abnormal due to underlying pathology caused by the condition.With the advancement in genome sequencing technology, some studies reported polymorphisms in transporter regions that have shown correlations with significant declines in plasma vitamin C levels despite high dietary vitamin C intake [30] [31] [32] . Researchers found that the SNP (rs33972313) is associated with a 50% decline in the rate of ascorbate accumulation in cells. Interestingly, this polymorphism was found to be present at a higher frequency in African, African American, and Yoruba African populations [33] [34] [35] . We speculate that dysregulation of SVCT transport and genetic polymorphism might be important contributing factors in many age-related pathophysiological conditions and increase COVID-19 infection and severity in certain sections of the populations.In the past decade, several research groups conducted studies investigating whether serum and plasma vitamin C levels differed between gender and race. The data collected from those studies were surprising. In almost all studies, there was a statistically significant difference in average plasma vitamin C concentration between males and females, with male plasma vitamin C levels much lower than in females despite a diet consisting of higher levels of vitamin C [36] [37] [38] [39] . Data also showed disparities in vitamin C levels among different races/ethnicities. Non-Hispanic African Americans had a much larger chance of having vitamin C deficiency compared to Caucasian Americans; however unlike in the gender data, average dietary vitamin C intake was much lower in the non-Hispanic African American participant group [37, 38] . It should be noted that dietary recall, an oftenmisreported data collection method, was used to determine the dietary vitamin C levels of the respective groups and thus could have affected the final outcomes from these respective trials. It well know that COVID-19 infection rate and severity have been disproportionately higher in males, indicated by the drastic increase of mortality rates in males compared to females in hard hit countries such as Spain and Italy [7, 40] . Furthermore, non-Hispanic African Americans also exhibited a higher prevalence rate and severity compared to Caucasian Americans [7, 41] . Johns Hopkins reported that of the 131 predominately black counties in America, the infection rate of COVID-19 was 3-fold higher and the death rate was 6-fold higher than in predominately white communities [41] . There is a possibility that vitamin C levels might be one of the factors accounting for the higher prevalence and severity of COVID-19 infection in male and non-Hispanic African Americans. Table 2 shows the correlation between vitamin C levels and the risk of COVID-19 infection and mortality. However, ultimately determining whether this correlation is directly related warrants further research.Vitamin C levels have been shown to decrease in the elderly population as well as those exhibiting chronic underlying conditions (e.g. diabetes, hypertension) [42] . Fletcher et al. (2003) conducted an interesting study to correlate the association between vitamin C levels and mortality in older persons [14] . They reported a strong inverse correlation with blood ascorbic acid levels and allcause mortality, including cardiovascular disease. Those patients in the lowest quantile for blood ascorbic acid (<17 μmol/L) showed the highest mortality rate with a hazard ratio of 1. Those in the highest quantile (>66 μmol/L) showed the lowest mortality rate indicated by a hazard ratio of half that (.54). Fletcher et al. (2003) concluded that serum vitamin C levels are a strong predictor of mortality in the aged population [14] . From this study, it seems that vitamin C levels are positively correlated with longevity.Several studies demonstrated a decline in vitamin C levels in most of the underlying conditions [13] . Hypertension and diabetic conditions are the risk factors to increase COVID-19 infection and mortality [7] . Wilson et al. (2017) investigated vitamin C levels in healthy individuals and type-2 diabetic patients [13] . They reported significantly lower plasma vitamin C levels in T2D patients compared to healthy individuals (41.2 µmol/L vs. 57.4 µmol/L, p < 0.05) [13] . Low serum vitamin C levels lead to disruption in the normal distribution of ascorbic acid to a certain tissue in the body, thus leading to many of the frequently seen diabetic complications such as hyperlipidemia, neuropathy, and hyperglycemia [13, 43] .The prevalence and severity of COVID-19 infection are drastically higher within the elderly population group and the underlying condition, as mention above [7, 44] . However, no study has linked decreasing levels of vitamin C with increased susceptibility and severity of COVID-19 infection. A study looking at this associated would help us to better understand the increased virulence of COVID-19 in these populations and whether vitamin C therapy will have a substantial therapeutic benefit in treating the disease.Antioxidants supplementation is essential for reducing inflammation by decreasing proinflammatory cytokine production. In COPD patients, chronic elevated oxidative stress and inflammatory cytokines are major contributors to the pathogenesis and decreased respiratory function seen in these patients [45] . Previously, MacNee et al. (2000) [46] conducted a single-blinded randomized control trial aimed to evaluate the efficacy of vitamin C and/or N-acetylcysteine (NAC) supplementation in increasing antioxidant status in COPD patients [45] . A total of 79 patients who had previously been diagnosed with COPD were enrolled in this trial and divided into four groups. The first group received IV NAC (600 mg/day), the second group received IV vitamin C (500 mg/day), the third group received IV NAC (600 mg/day) + IV vitamin C (500 mg/day), and the fourth group received a placebo solution. The patient's glutathione levels, a reliable indicator of antioxidant status, was measured at baseline, 3 months, and 6 months posttreatment [45] . Results showed that group 2 had the greatest increase in glutathione levels compared to the control group, with an increase of 516% compared to 56% increase (P=0.005) following 6 months of treatment. They concluded that NAC supplementation alone showed a dramatic improvement in the nutritional status of COPD patients, while Vitamin C supplementation alone showed a remarkable increase in antioxidant status [45] .As mentioned above, hypertension is associated with decreased serum vitamin C levels, so it is logical to propose supplementation of vitamin C to treat hypertension. Several clinical studies have been published using vitamin C with mixed outcomes [47, 48] . A study published in 2012 performed a Meta-Analysis of Randomized Controlled Trials investigating the effects of vitamin C supplementation on blood pressure from 1966 to 2011 (included 29 clinical trials) and showed a positive outcome of vitamin C treatment in reducing SBP and DBP. However, after analyzing the data from the trials, it was noted that the average change in blood pressure was small (> 5 mm hg) [48] . Ghosh et al. (1994) performed aged and sex-match randomized double-blind study to treat hypertensive subjects with vitamin C supplementation in aged patients [47] . The participants received either oral Vitamin C 250 mg once or twice daily or a placebo for 6 weeks, followed by analysis on plasma vitamin C and lipid peroxidase. They reported a significant fall of systolic and diastolic blood pressure in the treatment group, but surprisingly, no statistical difference in blood pressure between treatment and placebo groups [47] . Ghosh et al. (1994) conclude that vitamin C treatment showed marked antioxidant action but need to investigate thoroughly for any hypotensive action [47] . Similarly, the mixed benefits of vitamin C supplementation have been reported in diabetic clinical trials [49] [50] [51] . Clinical studies looking at severe cases of COVID-19 infection that resulted in death have quickly realized that the virus induces a rapid increase in proinflammatory cytokines and chemokines [52] . Without proper intervention, this can quickly compound into viralinduced sepsis causing full-blown cytokine storm for the patient, and ultimately resulting in severe injury or death. Acute respiratory distress syndrome (ARDS) is one of the severe complications of sepsis [53] . Therefore, it has been proposed that therapeutic intervention available for sepsis might be repurposed for the treatment of COVID-19. It has previously been noted that low vitamin C serum levels correlate with worse outcomes in septic patients [54] , which gives a strong indication that vitamin C injection/supplementation might be beneficial. Several clinical studies used vitamin C to treat patients suffering from sepsis and acute respiratory distress syndrome ( Table 3 ). The first clinical study performed by Sawyer et al. (1986) in which 16 patients suffering from acute respiratory distress syndrome (ARDS) were treated with vitamin C (1000 mg IV every 6 h) plus antioxidants (Nacetylcysteine, selenium, and vitamin E) versus 16 ARDS patients who received the standard care at that time. They reported a dramatic reduction in end case mortality in the vitamin C group compared with the control group (37% vs. 71%) [55] . Syed et al. (2014) conducted a phase I clinical trial in which vitamin C injections were given to investigate the efficacy of preventing multiple organ failure in patients suffering from severe sepsis. They reported that the group receiving vitamin C infusions showed far less organ failure compared to the control group [56] . The benefits of vitamin C was also exhibited in a single case review of a patient presenting to the emergency department suffering from enterovirus/rhinovirus induced acute respiratory distress syndrome [57] . After mechanical ventilation failed to stabilize the patient, venovenous extracorporeal membrane oxygenation (ECMO) along with IV administration of vitamin C (200 mg/kg per day) was initiated. Lung gas exchange and lung opacities on x-ray significantly improved following the new course of treatment, with the extubation from ventilation occurring at day 7 post-intervention [57] .The recently published randomized, double-blind, placebo-controlled, multicenter (CITRIS-ALI ) trial that took place between September 2014 to November 2017 to study the effect of vitamin C (intravenous infusion) on organ failure score, inflammatory markers and all-cause mortality in patients with sepsis and ARDS [58] . A group of 167 patients met the diagnostic criteria and were enrolled in the trial with half receiving an intravenous infusion of vitamin C (50 mg/kg in dextrose 5% in water, n = 84) every 6 hours for 96 hours. The other half of the participants were given a placebo (dextrose 5% in water) for the same allotted period. The Sequential Organ Failure Assessment score (0-20 scale with a higher score indicative of more severe organ damage) was recorded, as well as measurements of inflammatory markers (creactive protein) and vascular injury (thrombomodulin levels) [58] . Surprisingly, the study concluded that there were no significant differences between the vitamin C and placebo groups in mean modified Sequential Organ Failure Assessment score from baseline to 96 hours (9.8 to 6.8 in the vitamin C group and 10.3 to 6.8 in the placebo group; P = .86) or in C-reactive protein levels (54.1 vs. 46.1 μg/mL; P = .33) and thrombomodulin levels (14.5 vs. 13.8 ng/mL; P = .70) at 168 hours [58] . There was however, a statistically significant difference in all-cause mortality in patients receiving IV vitamin C treatment (29.8% (25/84)) compared to the placebo group (46.3% (38/82)). Researchers proposed that this discrepancy could possibly be due to vitamin C ability to correct the underlying cause of sepsis within patients and therefore, are not reflected in the biomarker analysis; however, further research is warranted to investigate these findings.Most recently, Fujii et al. (2020) published a multicenter, open-labeled, randomized clinical trial to investigate the efficacy of the triple therapy of vitamin C, thiamine, and hydrocortisone in increasing the time alive free of vasopressor in the patient suffering from septic shock compared to hydrocortisone treatment alone [59] . A total of 216 patients were enrolled for the trial from Australia, New Zealand, and Brazil fulfilling the sepsis-3 definition of septic shock. The patients were randomized into two groups, the study group (n=109) receiving a triple therapy consisting of intravenous vitamin C (1.5 g every 6 hours), hydrocortisone (50 mg every 6 hours), and thiamine (200 mg/12 hours), and the control group (n=107) receiving intravenous hydrocortisone (50 mg/6 hours) until shock resolution or up to 10 days. As in the CITRIS-ALI study, this study also did not find any significant improvement. This study reported that the triple therapy treatment did not show a significant increase in time alive and free of vasopressor administration compared to the control group, with the meantime being 122.1 hours and 124.6 hours, respectively. Moreover, the secondary outcome of 90-day mortality did not show any remarkable improvement with the triple therapy vs. the hydrocortisone treatment alone (28.6% vs. 24.5%, respectively) [59] . The variable results stemming from the CITRIS-ALI and Fujii et al. (2020) clinical trials raised questions on the efficacy of IV vitamin C therapy in reducing organ failure and mortality in life-threatening conditions like sepsis and ARDS. Once again, further research is warranted in order to fully know the effectiveness of vitamin C therapy in limiting the severity and duration of symptoms seen with septic patients.The beneficial role of vitamin C as an antioxidant and anti-inflammatory is well known [56] . This leads the scientific community to conduct several clinical trials investigating whether high doses of vitamin C (>1000 mg/day) has efficacy in treating and reducing the severity of illness seen with a variety of viral infections (Table 3 ). In 2014, Mikirova and his group investigated the effect of early administrations of the high intravenous dose of vitamin C in patients diagnosed with Epstein-Barr virus (EBV) to reduce the duration and viral load of the disease [60] . They reported that a high dose of intravenous vitamin C administration had a positive effect on viral antibody levels and disease duration, with an inverse correlation seen with serum vitamin C levels and viral antibody levels [60] . This same positive effect was seen in another study monitoring patients with herpes zoster viral infections [61] . Once again, a high dose of Vitamin C demonstrated an ability to reduce the viral load in patients receiving the treatment, with mean declines of pain scores and fewer symptoms being reported [61] . A double-blinded randomized control trial was performed looking at whether oral ingesting of 1000 mg vitamin C supplements daily, in young adult men would reduce the severity and duration of symptoms after contracting the common cold virus [62] . Data illustrated that those participants within the study group (with 1000 mg vitamin C supplements daily) showed a reduction in incidence of contracting the common cold virus. Also, in participants who did contract the common cold virus, a significant reduction in duration and severity of symptoms (59%) was reported compared to the placebo group [62] . Several meta-analyses have been performed contradicting this result, with all concluding that vitamin C does not affect the incidence of developing a cold (For detail, see ref [11, 63, 64] ). However, the studies do agree with the conclusion reach in Johnston et al. 2014 , that vitamin C administration does reduce the symptoms and duration of the contracted cold but it should also be noted that in the Johnston et al. study, vitamin C was taken orally. This significantly reduces the effectiveness of high dose vitamin C therapy due to the slow absorption of ascorbic acid through the gut epithelial cells. Administration taken by this route tightly regulates the rise in serum vitamin C concentration, unlike during intravenous administration [65] .The underlying mechanism or cell signaling how Vitamin C combat the virus infection still remains unclear, but a number of theories have been proposed. Currently the rationale behind treatment with vitamin C is two-fold, with the substance having both an antioxidant and immunomodulatory affects [66] . Most viral infections are associated with decreasing levels of vitamin C well below the normal (5-15 mg/L) [67] because of the intracellular environment undergoing substantial oxidative stress. This was illustrated by researchers investigating vitamin C levels following herpes zoster infection. They found that patients who had been infected had an average serum vitamin C level of 4.6 mg/L vs. 13.5 mg/L seen in healthy individual cohort [68] .It is thought that high dose vitamin C therapy helps neutralize the proinflammatory response and combat the elevated levels of reactive oxygen species, thus limiting collateral tissue damage that is often seen in viral infections [69] . Also, as mentioned above, vitamin C is essential for a proper and effective innate and adaptive immune response due to high concentrations of the vitamin being seen within leukocytes, lymphocytes and neutrophils [15, 16, 66] . Furthermore, vitamin C has been noted to increase chemotaxis, enhance neutrophil phagocytic capacity and support lymphocyte proliferation. Lastly, it has been shown that vitamin C levels have immunomodulatory properties in patients with viral infections due to its ability to stimulate alpha/beta interferons while simultaneously downregulating production of pro inflammatory cytokines [66, 70] . It is clear from literature that vitamin C indirectly reduce the viral load and infection through its potent antioxidant properties and immunomodulatory affects. With an exponential increase in COVID-19 infection rate and mortality in an ongoing global pandemic, researchers, clinicians, and government agencies are focusing on repurposing drugs with known safety profiles [3] . Previously known beneficial outcomes following high doses of vitamin C therapy in clinical studies have made this vitamin a frontline candidate for possible COVID-19 treatment. Also, there are very limited side effects and patients have high tolerability to ascorbic acid high doses [65] . Currently, there are approximately 30 ongoing clinical trials registered using Vitamin C alone or in combination with other drugs looking at the efficacy behind treating COVID-19 infections on Clinicaltrial.gov and International Clinical Trials Registry Platform (World Health Organization) (See Table. 4). However, as of the date of writing, there are no published, peer-reviewed manuscripts or data sets looking at the effectiveness of either high dose IV or oral vitamin C in treating and limiting the symptoms of COVID-19 positive patients. ConclusionBased on the literature mentioned above, high dose intravenous vitamin C therapy has been shown to have a range of effectiveness from moderate to high in preventing and limiting the duration of viral infections, with the most beneficial effect coming in those with reduced ascorbic acids levels. The vitamin C treatment is known for its beneficial role in preventing/ neutralizing inflammatory response, reducing oxidative stress, and stimulating interferons and other antiviral cytokines. Vitamin C is drug of choice in this critical time because of its known high dose tolerability and little or no side effects. It is possible that Vitamin C might help in a certain population of COVID-19 infected patients. The previous moderate success of vitamin C supplementation in human clinical studies may be due to several factors depending on the subject's age, race, levels of vitamin C transporter expression, and polymorphism in the vitamin C transporter, etc. Future clinical studies should be designed and conducted with all these factors taken into consideration, specifically vitamin C transporter expression and polymorphism. We recommend that the factors mentioned above should be considered at the start of clinical trials and during the analysis of the outcome of clinical findings. It will be interesting to see if vitamin C can help specifically in treating COVID-19 infected patients who are older, have underlying conditions or belong to African American populations. Furthermore, there is an urgent need to investigate the direct relationship between serum/plasma vitamin C levels in COVID-19 infection rate and severity.",USA,first author,2021-02-01,02
cf798939fe291db482ccd128385a5879f7de0f86,The protective association between statins use and adverse outcomes among COVID-19 patients: a systematic review and meta-analysis,"In December 2019, the first outbreak of a novel human coronavirus infection named severe acute respiratory syndrome-related coronavirus 2 (SARS-CoV-2) was reported in Wuhan, China 1 . The SARS-CoV-2 then rapidly spread across the globe, manifesting a high incidence of COVID-19 disease; on March 12, 2020, the World Health Organization declared COVID-19 as a pandemic 2 .The pathophysiology that underlies the severe COVID-19 pneumonia is an overproduction of early response proinflammatory cytokines, namely tumour necrosis factor (TNF), IL-6 and IL-1β 3 . If left unattended, this cytokine storm could place COVID-19 patients at a higher risk of vascular hyperpermeability, multiorgan failure, and death 3 . Moreover, cholesterol has been implicated to have a possible role in an increased risk of infection in the elderly patients, wherein higher tissue cholesterol has been shown to increase the endocytic entry of SARS-CoV-2.Statins, with its mechanism of inhibiting 3-hydroxy-3-methyl-glutaryl-CoA (HMG-CoA) reductase inside cells, may reduce such a cytokine storm, as it stabilizes the protein myeloid differentiation primary response 88 (MYD88) at normal levels, and also up-regulates angiotensin-converting enzyme 2 (ACE2), which is reported to be downregulated by SARS-CoV-2 and decrease infiltration of SARS-CoV-2 into the cells [4] [5] [6] .Several studies have reported on the use of statins amongst COVID-19 patients with differing conclusions. Zhang et al 7 reported that the use of statin was associated with reduced mortality, while Cariou et al 8 reported an opposite association with an increased mortality. Other studies such as De Spiegeleer et al 9 and Song et al 10 reported no difference in mortality between statin All rights reserved. No reuse allowed without permission.Meta-analyses by Hariyanto et al 11 and Kow et al 12 have studied the association between statin use and mortality among COVID-19 patients. However, while they analyzed several studies on the association between statins and adverse outcomes on COVID-19 patients, neither metaanalyses comprehensively reported on all studies conducted to-date of their publication. Further, neither paper distinguished studies on the circumstances around statin use; specifically, whether included studies in their meta-analysis reported on patients who used statin prior to hospitalization and statins after hospitalization.The aim of this study was to conduct a systematic review and meta-analysis to report on adverse outcomes among COVID-19 patients by statin usage.Ovid MEDLINE, Embase and the Cochrane Central Register of Controlled Trials were searched from January 2019 to December 2020, for English-language publications. The search strategy is presented in Appendix 1.Studies underwent level 1 title and abstract screening to identify articles that reported on the use of statins among COVID-19 patients. Relevant articles from level 1 screening subsequently All rights reserved. No reuse allowed without permission.All screening was done independently by two reviewers (RC, JI). Where there were disagreements, a discussion occurred and consensus was achieved to determine whether to include or exclude an article. Where consensus could not be achieved, a third author (NC) was consulted for their input and final decision.Articles identified for inclusion after level 2 full-text screening were assessed for quantitative synthesis. Articles were included if they reported an adjusted relative risk measure on mortality, ICU admissions or mechanical ventilation of patients who were statin users compared to those who were not statin users (comparison group).For studies included at this stage, demographics such as sample size, study design, patient population, central measures of tendency for age, percentage male, and percentage of statin users were noted. We noted whether studies reported exclusively on ICU patients at the time of enrollment. Additionally, we assessed if statin use was defined as prior to or after hospitalization.In corollary to study screening, quantitative synthesis was conducted independently by two reviewers (RC, JI), and a third reviewer (NC) was consulted if consensus was not achieved. All rights reserved. No reuse allowed without permission.Meta-analysis was conducted for mortality by the subgroups of ICU status (ICU Patients, and Non-ICU Patients) and statin usage (Statin Use Before and After COVID-19 Hospitalization).Studies employing similar relative risk ratios were analyzed together to generate a summary risk estimate. That is, studies reporting an odds ratio (OR) were aggregated to produce a summary odds ratio and studies reporting a hazard ratio (HR) were analyzed together. Corresponding 95% confidence intervals (CI) for an OR or a HR are reported as well. When there was heterogeneity of I 2 of equal to or greater than 50%, a random-effects DerSimonian-Laird analysis model was applied; otherwise, a fixed-effects inverse-variance analysis model was used. A p-value of less than 0.05 was considered statistically significant.A funnel plot and Egger's test were used to assess the publication bias for the endpoint of mortality. A p-value of greater than 0.05 indicated a lack of asymmetry of the funnel plot, and thereby no significant concern for publication bias. All analyses were conducted using Stata 16.A total of 482 records underwent level 1 screening, of which 474 were identified through database search and 8 identified from backward reference searching. After removing duplicates, 346 records underwent level 1 screening; 49 articles subsequently underwent level 2 screening.Twenty-one studies were assessed for quantitative synthesis, of which 13 studies 7-10,13-22 , presenting on 14 cohorts, reported relative risk ratios adjusted for potential confounders and were included in this systematic review and meta-analysis (Appendix 2). All rights reserved. No reuse allowed without permission.Study demographics are presented in Table 1 . All studies were observational in design, with either a retrospective cohort study design or a case-control study design. Israel et al 16 Visual inspection of the funnel plot and Egger's test (p = 0.086) suggests no significant concern for publication bias (Appendix 3).Twelve studies compared mortality between statin users and non-users. Individuals who had used statins prior to COVID-19 hospitalization had a similar risk of mortality to those who did not use statins -HR of 0.80 (95% CI: 0.50, 1.28) and OR of 0.62 (95% CI: 0.38, 1.03). COVID-19 patients who had statins administered after their COVID-19 hospitalization had a lower risk of mortality compared to those who did not receive statins -HR of 0.53 (95% CI: 0.46, 0.61) and OR of 0.57 (95% CI: 0.43, 0.75) (Figure 1a) . COVID-19 patients who were using statins and admitted to the ICU did not show a lower risk of mortality, compared to non-statin users -OR of 0.65 (95% CI: 0.26, 1.64). Among non-ICU All rights reserved. No reuse allowed without permission.Two studies reported on ICU admissions by patients who did and did not use statins. The risk of All rights reserved. No reuse allowed without permission.As statins are not currently a recommended medication for COVID-19 treatment and there is no randomized controlled trial in this setting, one could assume that Scenario 3 is unlikely to happen given its intent to solely treat COVID-19 with statin.In the event that Scenario 3 did occur, patients in Scenario 3 who only used statins after COVID-19 hospitalization may have acute cardiovascular indications for statin use after hospitalization, such as those who may develop acute myocardial injury, acute coronary syndrome or stroke. Our analysis by statin use before COVID-19 hospitalization therefore compares patients who used statins prior to COVID-19 hospitalization who may or may not continue using statins (Scenarios 1 and 2) after hospitalization, to patients who did not use statins prior to COVID-19 hospitalization who may or may not start statins after hospitalization (Scenarios 3 and 4) . The data reporting on non-statin users prior to COVID-19 hospitalization would therefore include more patients with poorer outcomes (Scenario 3), and result in an overestimation of the possible protective association between statin use before hospitalization and adverse outcomes.Along a similar vein, the possible protective association of statins prior to COVID-19 hospitalization and adverse outcomes may also be underestimated. Masana et al 18 reported further on Scenario 2, in which 42.2% of enrolled patients who used statins before COVID-19 hospitalization but discontinued statins during hospitalization. While the pre-hospitalization analysis would not be affected, the hidden assumption of pre-hospitalization statin use reflecting, or being used as proxy for, post-hospitalization statin use would be violated; the association between statin use before COVID-19 hospitalization and adverse outcomes will underestimate the association between statin after COVID-19 hospitalization and adverse outcomes. Hence, by All rights reserved. No reuse allowed without permission.Masana et al also reported that patients who continued on statins had significantly better outcomes, compare to patients who were not on statins before COVID-19 (p=0.045). In fact, our results suggest that statin usage after COVID-19 hospitalization may have a protective association for mortality, and our analysis supports the recommendation by UpToDate® for ""continuing statins in hospitalized patients with COVID-19 who are already taking them"" 24 .However, prospective randomized controlled trials should further investigate whether statins may be an effective therapy for COVID-19 patients.Our analysis also suggests that the risk of mortality among statin users compared to non-statin users differs, when focusing on subsets of ICU and non-ICU patients. Non-ICU patients seemed All rights reserved. No reuse allowed without permission.However, there is a paucity of data with respect to ICU patients. Further investigation is required among ICU patients, given this limited statistical power to find association between statin and mortality, among ICU patients.This study was not without limitations. Intrinsic to meta-analysis study designs, the strength of meta-analysis conclusions is limited to the strength of the input studies and underlying data. As all included studies are observational studies, randomized controlled trials are needed to confirm whether statin can be beneficial in patients with COVID-19 as COVID-19-specific treatment agent. Additionally, there is a general paucity of literature. While there are thirteen studies reporting on mortality, only two studied ICU patients. Only two studies reported on ICU admissions; only one study reported on mechanical ventilation. We need further research to address whether statin is beneficial in terms of preventing ICU admission or mechanical ventilation, which are surrogate markers of severe COVID-19 infection.In conclusion, patients administered statins after COVID-19 diagnosis were at lower risk of mortality. Ultimately, all included studies in this analysis were observational and predominantly retrospective in nature. Further prospective investigation is needed to assess whether statins may be an effective therapy in COVID-19 patients. Continued investigation is required to assess statin use among COVID-19 patients with respect to other outcomes, such as ICU admissions and mechanical ventilation. All rights reserved. No reuse allowed without permission.-17 - All rights reserved. No reuse allowed without permission.All rights reserved. No reuse allowed without permission.",United States of America,first author,2021-02-09,02
45222a069e220d9e76daaebc1a06edfbecdcb0cf,High-Performance 0.55-T Lung MRI in a Patient with COVID-19 Infection Manuscript type: Images in Radiology,"are observed using both imaging modalities. In some regions, the severity of the abnormality appears worse on MRI, as shown in the red boxes.",USA,first author,2021-02-02,02
92f7fccbf3f6666527a8225bf4f91fbede6ffca0,"Seroprevalence of SARS-CoV-2 Antibodies in Children and Adults in St. Louis, Missouri, USA","United States around April and May 2020 have varied from 1 to 20% (5-10), emphasizing the need for regionally specific data. The first known COVID-19 case in Missouri was reported on 7 March 2020 and located in the St. Louis County region. By 1 May, a total of 6,332 positive cases had been reported in the St. Louis metropolitan area, equal to 0.226% of the population (https://slu-opengis.github.io/covid_daily_viz/).The role of children in the spread of SARS-CoV-2 is unclear. Lower prevalence is generally reported in younger children than in adults. This general trend is also observed in St. Louis, with reported pediatric rates in late May of only 0.03% for children aged 0 to 9 years and 0.1% for children aged 10 to 19 years (https://stlcorona .com/). There is evidence that children may be infected at lower rates than adults (11) (12) (13) and that they are less likely to experience severe symptoms (14) (15) (16) (17) , although the relative contribution of each to lower reported rates is unclear. Asymptomatic individuals seem to account for up to 50% of SARS-CoV-2 infections, and the rate may be even higher in children (18, 19) . Asymptomatic individuals, including children, show evidence of high viral shedding and likely contribute to the rapid spread of the disease (20) (21) (22) (23) (24) (25) (26) . The goal of our sero-prevalence study was to determine the extent of SARS-CoV-2 infection in adult and pediatric cohorts from the St. Louis metropolitan area early in the outbreak.Sensitivity and specificity of ELISA. We performed receiver operating characteristic (ROC) analysis for the spike and nucleoprotein (NP) antigens to determine diagnostic thresholds for IgG enzyme-linked immunosorbent assays (ELISAs) (Fig. 1) . Negative pre-COVID-19 samples had greater cross-reactivity to NP (mean, 0.516; standard deviation [SD], 0.557) than to spike (mean, 0.142; SD, 0.114) (Fig. 1B) . ELISA sensitivity and specificity were estimated with a Markov chain Monte Carlo (MCMC) scheme. Area under the curve (AUC) values were 0.999 and 0.961 for the spike and NP assays, respectively. The optimal cutoff point for each assay was selected as the number of SD above the pre-COVID-19 sample mean that maximized the Youden index (sensitivity plus specificity minus 1).Based on this criterion, the optimal cutoff for the spike IgG ELISA was equal to the average optical density (OD) value of prepandemic samples plus 4 SD, resulting in 98.2% sensitivity (95% CI, 97.4% to 99.9%) and 98.7% specificity (95% CI, 95.7% to 100%). The NP IgG ELISA was less accurate, with 86.5% (95% CI, 80.1% to 92.8%) sensitivity and 93.1% (95% CI, 90.3% to 95.8%) specificity for the assay's optimal cutoff of the average pre-COVID-19 OD plus 2 SD. Requiring a positive response to both antigens decreased assay performance (87.4% sensitivity and 99.7% specificity) compared to that of the spike ELISA alone, so samples with spike IgG ELISA responses greater than the spike cutoff are considered seropositive, regardless of reactivity to NP.Demographic and clinical characteristics. Deidentified adult samples included 503 individuals (296 females, 207 males) with a median age of 61 years (range, 18 years to 93 years) ( Table 1 ). The pediatric cohort included 555 different individuals (286 females, 269 males) with a median age of 9 years (range, 2 days to 17 years).SARS-CoV-2 seroprevalence in St. Louis. Spike and NP ELISA results for the 1,055 tested samples are shown in Fig. 2A . Thirty-six samples were found positive for antispike IgG antibodies with OD values above the cutoff value. Twenty-one of the positive samples were identified from the adult cohort (n = 503) and 15 from the pediatric cohort (n = 555). Accounting for test performance in a Bayesian regression model led to estimated seroprevalence rates of 3.11% (95% CI, 0.92% to 5.32%) and 1.71% (95% CI, 0.04% to 3.38%) for adults and children, respectively (Fig. 3) . A breakdown of positive samples by demographic information is provided in Table 1 and Fig. 2B . Of the 176 samples tested in children under 4 years of age, none were positive. The youngest seropositive subject was a 4-year-old female child and the oldest a 70-year-old male.As the St. Louis Department of Health reported an incidence rate of only 0.03% for children aged 0 to 9 years in late May, despite an overall St. Louis population incidence rate of 0.226%, we tested the hypothesis that our data provide evidence for higher seropositivity in adults than in young children. Our data suggest an estimated seroprevalence rate of 0.67% for children under 5 years, which is significantly lower than the estimated adult seropositive rate of 3.11% (P = 0.0032). However, the rate for children between 5 and 18 years is 3.37%, similar to the rate of adults (P = 0.473). Our results do not provide evidence for seroprevalence rate differences based on sex (P = 0.256).We used a serological assay to identify SARS-CoV-2 antibodies in children and adults early in the St. Louis outbreak. We observed seroprevalence rates of 1.71% among children and 3.11% among our adult cohort. A prior study estimated the seroprevalence of SARS-CoV-2 in Missouri at 2.7% using 1,882 serum samples, most from adults, collected broadly across the state in late April (27) . The adult incidence rate that we report in samples from the St. Louis metropolitan area was slightly higher, We observed lower estimated seropositivity in children under 5 years than in adults, and none of the samples from children under 4 years of age were identified as seropositive. These results are consistent with a growing body of evidence that young children may be infected by SARS-CoV-2 at a lower rate than adults (28) (29) (30) . One potential caveat is that due to differences in inclusion criteria of the pediatric and adult cohorts, there may be biases that limit comparative interpretation of the observed seropositivity rates. Additional studies performed with samples collected later in the pandemic are needed to better understand pediatric infection rates and inform public health protocols related to schooling.In this study, we established and validated a robust ELISA protocol for the detection of SARS-CoV-2 antibody responses in serum/plasma samples. We found that a seropositivity criterion based on the spike IgG ELISA alone is more accurate than one based on both the spike and NP antigens, possibly due to high NP cross-reactivity to seasonal coronaviruses (31) . A Bayesian model is then used to jointly estimate the specificity and sensitivity of the test along with the seroprevalence rate. In this way, our reported posterior distributions for seroprevalence account for test specificity and sensitivity while propagating uncertainty in these parameters into final seroprevalence estimates.Our study used sera from patients obtaining medical care early in the pandemic, so it is not necessarily generalizable to the general St. Louis population. Notably, the St. Louis stay-at-home order overlapped with our sample collection period, when routine medical visits and bloodwork for healthy patients may have been limited. Individuals with severe medical conditions therefore may be overrepresented in our cohort relative to the general population. An improved understanding of general seroprevalence in both adult and pediatric populations is critical to implementing public safety guidelines. Our results indicate that both children and adults are susceptible to SARS-CoV-2 infection and develop antibody responses. Serological studies such as this provide essential information on the risk for transmission and the immunological state of the population.Patient cohorts. We screened 503 adult and 555 pediatric serum/plasma samples. The adult samples were residual samples sent to Barnes-Jewish Hospital for physician-ordered vitamin D testing between 27 April 2020 and 12 May 2020. Residual pediatric specimens were collected from unique outpatients presenting to St. Louis Children's Hospital between 14 April 2020 and 8 May 2020. The most common indications for pediatric blood draw were an evaluation of allergies, a general health assessment in the emergency department (basic and comprehensive metabolic profiles), and screening/follow-up for a variety of conditions (includes orders for bilirubin, vitamin D, lipids, iron/ferritin, TSH/free T4, and HgbA1c). Specimens with orders for immunosuppressant therapeutic drug monitoring were excluded.Assay sensitivity was evaluated with two sets of sera (n = 110) collected from COVID-19 RT-PCR-positive individuals that exhibited neutralization titers of .1:40 in a focus reduction neutralization assay (I. Harvey and D. Fremont, unpublished data). The first set included 35 serum samples from 16 patients being treated at the Mayo Clinic, collected 6 to 20 days after symptom onset. The remaining 75 COVID-19-positive samples, from 75 individuals following convalescence ($2 weeks without symptoms and PCR negativity), were collected by Washington University researchers.Assay specificity was assessed using a subset of pre-COVID-19 serum samples collected between 2007 and 2008 for prior serological studies (32, 33) and stored at -80°C. Three hundred pre-COVID-19 samples were obtained from adult (n = 150) and pediatric (n = 150) patients presenting to Barnes-Jewish Hospital or St. Louis Children's Hospital.This study was approved by the Human Research Protection Office at Washington University in St. Louis (approval no. 202004199 and 202004153).Cell line, virus, and recombinant protein.Purified RNA from the 2019-novel CoV(nCoV)/USA-WA1/ 2020 SARS-CoV-2 strain was reverse transcribed into cDNA and used as the template for recombinant gene cloning. Full-length SARS-CoV-2 NP was cloned into pET21a with a hexahistidine tag and recombinantly expressed using Escherichia coli BL21(DE3)-RIL in terrific broth (bioWorld). Following overnight induction with isopropyl b-D-1-thiogalactopyranoside (GoldBio) at 25°C, cells were lysed in 20 mM Tris-HCl, pH 8.5, 1 M NaCl, 5 mM b-mercaptoethanol, and 5 mM imidazole for nickel affinity purification. Following elution in the prior buffer supplemented with 500 mM imidazole, the protein was purified to homogeneity using size exclusion chromatography, followed by cation exchange chromatography.The SARS-CoV-2 spike ectodomain (residues 14 to 1211; GenBank accession no. MN908947.3) and influenza hemagglutinin (HA) ectodomain (subtype B/Colorado/06/2017) were cloned into pFM1.2 with an N-terminal m-phosphatase signal peptide. The C terminus of SARS-CoV-2 spike was engineered with an HRV3C protease cleavage site (GSTLEVLFQGP) linked by a foldon trimerization motif (YIPEAPRDGQAYVRKDGEWVLLSTFL) and an 8ÂHis Tag. The S1/S2 furin cleavage site was mutated, and 2 stabilizing proline mutations were introduced. The influenza HA construct contained a T4 fibritin trimerization domain at the C terminus (34) . The plasmids were transiently transfected into Expi293F cells and purified by cobalt-charged resin chromatography (G-Biosciences) as previously described (35, 36) .ELISA. We developed two ELISAs based on trimeric spike and NP proteins. Our protocol was previously optimized based on serial dilution results of 16 negative controls and 122 positive controls as described in the work of Harvey et al. (unpublished data). Briefly, 96-well MaxiSorp plates were coated with 2 mg/ml of purified antigens in 50 mM Na 2 CO 3 (70 ml) overnight at 4°C. Plates were then washed with phosphate-buffered saline (PBS)-0.05% Tween 20 and blocked with 200 ml 1Â PBS-0.05% Tween 20-1% bovine serum albumin (BSA)-0.02% sodium azide for 2 h at room temperature. Serum/plasma samples were diluted 1/500 in blocking buffer. Diluted samples were then added to plates (50 ml/well) and incubated for 1 h at room temperature. Bound IgG was detected using horseradish peroxidase (HRP)-conjugated goat anti-human IgG (at 1/5,000). Following 1 h of incubation, washed plates were developed with 50 ml of a 1-Step Ultra TMB ELISA solution and quenched with 2 M sulfuric acid, and the absorbance was read at 450 nm. The results of independent technical replicates (n = 3) were averaged for each sample. The ELISA response of each sample to the influenza HA ectodomain was also evaluated as a control.Cutoff value and statistical analysis. Sensitivity and specificity values were calculated for spike and NP ELISAs from the positive-and negative-control sera. Cutoff values were determined by ROC analysis focused on maximizing both the sensitivity and the specificity of the assay. To assess plate-to-plate variation, the same 2 negative controls (pre-COVID-19 sera) and 2 positive controls (sera from SARS-CoV-2 PCR-positive individuals) were included on every ELISA plate. The coefficient of variation was less than 20% in all cases. All blank wells had absorbance values of ,0.15.Parameters were estimated with a Bayesian framework using a Markov chain Monte Carlo (MCMC) method implemented in python using the PyStan package (37) . Five independent chains of 10,000 iterations each were simulated, with the first 1,000 iterations corresponding to the burn-in. Noninformative beta(1) priors, along with a binomial likelihood function, were used for sensitivity, specificity, and prevalence. Convergence was assessed by visual inspection of time series plots and Gelman and RubinR statistics (38) . Posterior distributions for each parameter were described using means and 95% posterior credible intervals.Bayesian hypothesis testing was done to examine the effects of age and sex on SARS-CoV-2 seroprevalence. The P values that we report are Bayesian P values (39) . We calculate the x 2 discrepancy measure between generated data sets and the expected values drawn from the posterior distribution. The Bayesian P value is the probability that the x 2 discrepancy measure based on the replicated data were more extreme than the observed data. Differences were considered to be statistically significant at a P of ,0.05.",USA,first author,2021-02-03,02
10359ef07feb1ee883a86993f3ab9094722c3fda,Host-virus chimeric events in SARS-CoV2 infected cells are infrequent and artifactual,"Advances in, and availability of, high throughput sequencing technologies have enabled the accumulation of detailed molecular level information from cells, including genome variations, gene transcription, and gene regulation. These technologies are extremely sensitive at capturing nucleic acid sequences regardless of their origin. As such, the data from these techniques contain not only sequences encoded by the cell itself, but also sequences encoded by infecting pathogens, and/or common contaminating agents (e.g. vectors, plasmids, etc) 1,2 . In virus-infected cells, captured sequences derived from the host or virus represent a powerful tool to study the mechanisms underlying host-pathogen interactions. We have previously deployed these methods to gain mechanistic insights into the pathophysiology of oncogenic viruses, such as Epstein-Barr virus (EBV), hepatitis B virus (HBV) and human papilloma virus (HPV) 1,3-5 .RNA-sequencing data from virally infected cells contain reads that map perfectly to either the host genome or the viral genome. However, a significant portion of host sequencing reads can also be aligned to discontiguous sections of the genome and often represent canonical forward splicing or back splicing events generated from mRNAs and circular RNAs, respectively. In cells infected with DNA viruses that integrate into the host genome (e.g. HPV or HBV), a chimeric read that is partly mapped to the host genome and partly mapped to the virus genome, is a signature of transcribed segments of the host genome containing integrated viral DNA [6] [7] [8] . Similarly, in virusinduced cancer cells, chimeric reads that are partly mapped to one gene and partly mapped to another gene are the markers of genomic rearrangement and/or gene fusion 9, 10 . Thus, chimeric reads can represent real biological events.The pathogenic mechanisms underlying severe acute respiratory syndrome coronavirus 2 (SARS-CoV2), the virus responsible for pandemic coronavirus disease of 2019 (COVID- 19) , are under investigation 11-14 but still not fully understood. In particular, relatively little is known about the processes following viral infection and why some individuals develop little to no symptoms, while others develop life-threatening or persistent (""long"") COVID-19. Recent studies have identified host-virus chimeric (HVC) reads in RNA-sequencing data from SARS-CoV2 infected cells and samples from COVID-19 patients 15, 16 . Both studies have suggested that HVC events support potential ""human genome invasion"" and ""integration"" by SARS-CoV2. This suggestion has fueled concerns about the long-term effects of current vaccines that incorporate elements of the viral genome 17 . SARS-CoV2 is a positive-sense single-stranded RNA virus that does not encode a reverse transcriptase and does not include a nuclear phase in its life cycle, so some doubts have rightfully been expressed regarding the authenticity of HVCs and the role played by endogenous retrotransposons in this phenomenon. Thus, it is important to independently authenticate these HVC events.Here we investigated the presence of HVC events in a large number of currently available RNA-sequencing samples from SARS-CoV2 infected cells and patients with COVID-19.Consistent with previous studies, we found that 0.01-1% of viral mapped reads could be characterized as HVC reads. In contrast to reads originating from known or novel splicing junctions, HVC events were not reproduced between different libraries, suggesting that they are either stochastic or artifactual. By counting chimeric events observed in unrelated human RNAseq libraries prepared in the same manner but containing spike-in of fruit-fly RNA, we estimated that errors in reverse transcription result in ~1% of RNA-seq reads being artifactually chimeric, approximately the same frequency as observed HVCs from SARS-CoV2 infected cells. Finally, we developed a novel experimental approach to enrich for viral sequences from infected cells during RNA-seq library preparation. Despite achieving >30-fold enrichment of viral sequences using our method, HVC events were not enriched, indicating that the low frequency of HVCs observed are likely introduced during reverse transcription steps of RNA-seq library preparation.In summary, we conclude that current data do not support the authenticity of HVC events in SARS-CoV2 infected samples.RNA-sequencing reads that partly align to the host genome and partly align to the viral genome are the signature of HVC events in RNA-sequencing datasets. Recent reports 15, 16 suggesting the presence of HVC events in SARS-CoV2-infected cells have been interpreted as supporting viral integration into the human genome as a mechanism of viral persistence. To gain insights into the authenticity of these events, we re-analyzed the 3 available RNA-seq datasets from patients with COVID-19 (n=57 samples) and in vitro SARS-CoV2 infected cells (n=64 samples). We categorized sequencing reads to those that perfectly aligned to the human genome (build hg38) in a contiguous or discontiguous manner (i.e. reads originating from one exon or reads spanning exon-exon junctions), those that perfectly aligned to the SARS-CoV2 viral genome, and those that partly aligned to both host and viral genomes (potentially representing HVC events) (Fig. 1A) .Viral mapped reads were detected across several cell lines infected with SARS-CoV2 (Fig. 1B) .SARS-CoV2 infected Calu-3 and A549-ACE2 cells had the highest percentages (~20-70%) of viral reads, while other cells, including A549 cells and samples from lung autopsies of patients with COVID-19, had dramatically lower representation of viral reads (Fig. 1B) . The frequency of viral reads in cells infected in vitro with other viruses, including influenza A (IAV), middle east respiratory syndrome (MERS) and respiratory syncytial viruses (RSV), were similar (Fig. S1A) .We next quantified the reads that partly mapped to the human genome and partly mapped to the SARS-CoV2 genome (see methods). We found that nearly 0.05-1% of all viral reads are formed of hybrid sequences between host and virus RNAs, a frequency consistent with that recently reported by others 15, 16 (Fig. 1C) . Infected A549-ACE2 and Calu-3 cells had the highest percentages of chimeric reads, while others, including normal human bronchial epithelial cells (NHBE) and lung autopsies of patients with COVID-19, had ~1.5-2 orders of magnitude fewer chimeric reads (Fig. 1C) . Similar percentages of chimeric reads were observed in cells infected with other viruses (Fig. S1B) .To test whether there are regions of the viral genome that more frequently participate in chimeric events, we separately aligned the viral reads and the viral fragments of the chimeric reads to the SARS-CoV2 genome (Fig. 1D) . Consistent with previous studies, we found higher coverage of the 3' end of SARS-CoV2 genome in sequencing libraries across different cells (Fig. 1D 1D , lower panel). This is consistent with a stochastic model in which chimeric events are dependent on the availability of template RNA, i.e., the more viral RNA fragments present the higher the chance of participation in chimeric events. Based on this model, we hypothesized that host fragments participating in chimeric reads will also be over-represented in genes that are more highly expressed. Indeed, we observed that human genes with HVC events are more highly expressed than those without HVC events across all SARS-CoV2 infected cells (Fig. 1E ). This is exemplified by A549-ACE2 cells, which are transduced to express high levels of angiotensin converting enzyme (ACE) 2, a well-characterized entry receptor for SARS-CoV2. In these cells, ACE2 was one of the top loci participating in chimeric events (Fig. S1C) .Collectively, we identified HVC events in RNA-seq from SARS-CoV2 infected cells. We found that these events were very rare in samples from patients with COVID-19 and that there was a correlation between the expression of host and/or viral genes and the frequency of participation in chimera formation. These data indicate that HVC events are either stochastic and biased towards more highly expressed transcripts or authentic biological events involving 3' regions of the viral genome with specific human genomic elements.HVC events are not reproducible and have comparable frequency to artifactual chimeric events A precise and reproducible junction between host and viral fragments of a chimeric event would be evidence of authentic HVC events occurring as part of the natural life cycle of the virus. To determine whether the junctions of HVC events are precise and reproducible, we compared RNAseq data from independent studies (Table S1-2) and looked for reads that spanned known or novel exon-exon splicing junctions, as well as HVCs (Figs. 1A-B) . For each cell type, we specifically sourced two or more RNA-seq libraries from independent studies ( Table S1 ). As expected, ~90% of known splicing events sourced from RefSeq database were reproducible between independent studies ( Figs. 2A-B, S2A) . We also found that nearly one-third of novel (i.e., unannotated) splicing events could also be independently replicated between different studies ( Figs. 2A-B, Fig. S2A ).Conversely, almost none of the exact HVC events were reproducible in independent data sets ( Figs. 2A-B, Fig. S2A ).Another way to determine whether specific HVCs are reproducible is to identify the proportion of unique reads in a given RNA-seq dataset that span the HVC junction. The higher the number of reads the more likely it is that the HVC is not a stochastic event. We thus examined the number of unique reads spanning known splicing, novel splicing and HVC junctions in each RNAseq dataset (Fig. 2C) . We found that only 2-15% of HVC events had more than one read spanning their junctions. This is in clear contrast to 90-95% and 40-70% of known and novel splicing events, respectively, that have more than one supporting read (Fig. 2C, Fig. S2B ).Our data above indicated that observed HVCs likely represent non-biological artifacts.However, how these artifacts are generated remained unclear. Reverse transcriptase enzymes (RTs) are error-prone and susceptible to a process called random template switching 18 . In this process RTs synthesizing cDNA infrequently dissociate from their template RNA and associate with a secondary template RNA, resulting in creation of an artifactual fusion cDNA containing both the original template and the secondary RNA. Reverse transcription is one of the main steps in most commonly used RNA-sequencing methods, thus it is conceivable that some of the HVC events are artifacts of RT. To test this, we took advantage of spike-in control libraries that are typically utilized for internal calibration and normalization. In those libraries, a small quantity of RNA from an unrelated species is spiked-in to the RNA of interest, followed by RNA-sequencing library preparation. We sourced existing human RNA-sequencing libraries that harbored spikedin Drosophila melanogaster RNA and were prepared using a common library preparation kit from Illumina. We mapped these libraries to the human-Drosophila chimeric genome, using the exact same method that we employed when analyzing the host-virus chimeric genome (see Methods).Nearly 5% of all reads were mapped to the Drosophila genome. We then identified the fraction of Drosophila mapped RNAs that were human-Drosophila chimeric. Since there is no actual possibility of biological fusion events between host and spiked-in RNAs, we considered any chimeric reads identified as artifactual. This could therefore determine the expected background level (""noise"") of chimeric events created as artifacts of RT and/or alignment errors. We observed ~1% of all Drosophila-mapped reads to participate in chimeric events (Fig. 2D) . Interestingly, in all libraries analyzed from SARS-CoV2 infected cells, the observed fractions of HVC reads were lower than 1%, indicating that the frequency of HVC events in SARS-CoV2 infected libraries were comparable to the expected background ""noise"" of chimeric events created as artifacts of RT and/or alignment errors.We next examined the expression of human genes with and without Drosophila chimeras.Similar to what we had observed in SARS-CoV2 infected cells (Fig. 1E) , human genes with chimeric events were more highly expressed than those without such events (Fig. 2E) . This was consistent with a stochastic model in which chimeric events are dependent on the availability of template RNA and driven by random RT template switching. Repeat sequences of RNA are known substrates for RT template switching 18 . To test this, we examined the genomic distribution of the host segments of chimeric events between human and spiked-in Drosophila RNA and found that these artifactual chimeric events were, indeed, enriched in RNAs with highly repetitive structures, including rRNAs and tRNAs (Fig. 2F) . We next sought to determine whether the same observation holds true in virally-infected cells. In RNA-seq libraries of SARS-CoV2-infected cells we found that HVCs were similarly enriched in RNAs with repetitive motifs, including rRNAs and tRNAs, when compared to the total transcriptome (Fig 2G, see methods) .Collectively, these data indicated that the exact junctions of HVC events were not reproducible between different samples, that the frequency and the genomic distribution of HVC events were comparable to that from artifactual chimeric events generated by RT template switching and that host RNAs partaking in chimera formation were enriched in structures conducive to template switching.Although viral reads in most infected RNA-sequencing libraries were readily detectable, the fraction of viral reads to total mapped reads was low (Fig. 1B) , presumably due to heterogenous infectivity rates within cell cultures or patient samples. Thus, it is possible that detection of HVC events and junctional reads is too infrequent to allow robust detection of identical species across different samples. Thus, we developed a technique to experimentally enrich for viral RNAs during RNA-seq library preparation that would also enrich any bona fide HVC events as well. To this end, we designed a pool of 30 specific oligonucleotides that spanned the entire SARS-CoV2 genome ( Table S3) . Using these oligonucleotides, we developed a novel methodology to specifically amplify viral RNAs from SARS-CoV2-infected cells and constructed sequencing libraries (schematic in Fig. 3A , please also see methods). Two types of chimeric events are possible, 5'->3' host-virus chimeras and 5'->3' virus-host chimeras. To enrich for viral sequences and ensure ""capture"" of both types of chimeras, we used two approaches (enrichment methods 1 and 2, respectively, in Fig. 3A) . To enrich for viral sequences that also contain 5'->3' host-virus chimeras (enrichment method 1 in Fig. 3A) , we carried out virus-specific RT to construct cDNA incorporating an Illumina-P5 adaptor sequence and T7 RNA polymerase promoter, followed by second-strand DNA synthesis and in vitro RNA transcription using T7 RNA polymerase. RT primed with random hexamer was then carried out to incorporate an Illumina-P7 adaptor sequence, before library amplification by PCR and high throughput Illumina sequencing. To also enrich for viral sequences including 5'->3' virus-host chimeras (enrichment method 2 in Fig. 3A) , we performed oligo-dT-primed RT to construct cDNA incorporating an Illumina-P5 adaptor sequence and T7 RNA polymerase promoter, followed by second-strand DNA synthesis and in vitro RNA transcription using T7 RNA polymerase. RT primed with virus-specific primers was then carried out to incorporate an Illumina-P7 adaptor sequence, before library amplification by PCR and high throughput Illumina sequencing. Any RNA amplified using this technique would be enriched in viral sequences, including those mapping solely to the viral genome as well as those mapping partially to host as well as viral genomes (HVCs). For comparison, we also prepared cDNAs from RNAs of infected cells without any enrichment (unenriched control, see methods).To validate this approach, we performed qPCR on sequencing libraries for SARS-CoV2 N gene using CDC recommended primer sets. We specifically chose the N gene since it is the highest expressed gene and the site of most HVC events. We observed dramatic enrichment (> 30-fold) of viral N gene mRNA in enriched libraries compared to the control (Fig. S3A) . We next performed high throughput sequencing on all libraries and their corresponding controls and performed the same analysis as Fig. 1 . Consistent with our qPCR data, we found that the total number of reads mapped to the virus genome were much higher in enriched libraries compared to control (Fig. 3B) , indicating a mean enrichment for viral reads of 2-6-fold. We then compared the total number of HVC events before and after the enrichment. Despite the significant enrichment of viral reads, HVC events were not enriched at all and their frequency remained at <0.05% (Fig. 3D), comparable to the expected level from background ""noise"" denoted previously (Fig. 2D) .Moreover, the genomic distribution of the host portion of these HVC events (Fig. 3D ) was similar to those observed from artifactual chimeric events.Collectively, these data indicate that even after enrichment of transcripts containing viral sequences HVC events remained at the level of noise expected by random RT template switching, which we consider it to be evidence that the observed SARS-CoV2 HVCs are likely artifacts of in vitro RNA-seq library construction and unlikely to be bona fide events occurring in vivo.Sequencing reads from high throughput assays, if appropriately analyzed, are invaluable resources for identifying novel biological events and provide exceptionally detailed information about hostvirus interactions occurring in vivo. This is exemplified by the discovery of viral integration as a driver of oncogenesis in HPV-associated cancers 19 . We have previously used this approach to examine host-virus interactions during EBV infection and to determine how the EBV episome interacts with the human genome 4, 5 . Even in the absence of infection, detailed analyses of RNAseq data can deliver new insights into cell biology, including, for example, discovery of novel linear or circular genes and isoforms. On the other hand, the technology is extremely sensitive, relies on low fidelity RTs during library preparation and there are many computational challenges during chimeric sequence alignment. Collectively, these can result in the detection of low frequency sequencing reads originating from artifactual events or contaminants (including plasmid vectors). Thus, appropriate positive and negative controls during analysis are essential to distinguish real from artifactual events. SARS-CoV2 is a good example of a novel pandemic coronavirus of humans that is as yet relatively understudied. In particular, little is known about host-pathogen interactions that determine clinical outcomes, including why some people develop little to no symptoms, while others succumb to life-threatening disease and others progress to chronic disease (""persistent"" COVID-19). In this setting, sequencing assays are key methods for uncovering as yet undiscovered mechanisms of pathogenesis. Particular attention has focused recently on reports of HVCs forming between host and viral mRNAs, which have been interpreted as evidence of viral incorporation into the host genome and raised questions about long-term safety of vaccination strategies using viral RNA. Here we found several lines of evidence that indicate that the reported HVC events observed in sequencing libraries are most likely artifactual.We found that the precise location and the nucleic acid sequence of HVC events are not reproducible across different libraries prepared by different labs. Consistent with previous reports, we concur the viral part of HVC events to be enriched in sequences from the 3' end of SARS-CoV2 virus. This is the portion of the virus that contains the most highly expressed gene encoding N-protein 20 . Likewise, we also observed that chimeric events incorporated the more highly expressed host genes. A model consistent with these observations is that HVCs are likely the result of stochastic events occurring at the RNA level that incorporate components of more highly expressed transcripts (templates) from both the host and virus.One of the potential mechanisms that could generate artifactual HVC events is random template switching by RTs used during RNA-seq library preparation to convert RNA to cDNA. RTs are known to occasionally switch from one template to another, thus creating artifactual fusion cDNA.Here we found that ~1% of spike-in control RNAs exhibit chimeric events with host RNA that can only be explained by random template switching during library preparation. This provides an expected level of artifactual chimeric events for the RTs used in common RNA-sequencing library preparation kits (e.g., Superscript II). We found that the frequency of HVC events from all SARS-CoV2 infected samples was below 1%, indicating that these events are likely to be artifacts of RTs.Moreover, repeat sequences of RNA are known substrates for template switching 18 . Not surprisingly, we found that the host part of HVC events was enriched in RNAs with highly repetitive structures, including rRNAs and tRNAs (Fig. 1F) . This further supports undesired template switching by RTs as the origin of observed HVC events.Finally, we developed a novel method to enrich for viral RNA fragments from infected cells. Deploying this method, we found that, although we could enrich for viral transcripts by between >30-fold, the rate of HVCs remained unchanged and at, or below, the expected level of ""noise"" introduced by in vitro RTs. A benefit of our technique is that it is a general method that can easily be used for enrichment of any RNA and its chimeric partners, as long as sequences for oligonucleotide design are known (e.g., a genome build is available). This is particularly useful because cellular RNAs in infected cells typically dominate over RNA derived from infecting pathogens, especially when infection rates and/or viral titers are low. One example for the utility of this method is to help identify ""cap-snatching"" and ""start-snatching"" events. In IAV-infected cells, for example, viral transcripts form chimeras with the 5' portion of host transcripts containing 5' caps in order to stabilize viral transcripts and create bona fide fusion proteins 21, 22 . Although there are computational challenges in aligning sequencing reads if very short fragments (<18 bp) are ""snatched"" from the host, one would anticipate seeing enrichment of host 5' UTR elements in HVC events if similar cap-snatching mechanisms were utilized by SARS-CoV2. However, we observed quite the opposite, if any (Fig. 1F) . In fact, the overall conclusion on successfully enriching for viral RNA reads but observing no enrichment of HVC events above background is that the majority of HVCs are the result of artifacts generated by RT errors during library preparation.Collectively, our data analyses and experimental findings indicate that currently observed and widely reported HVC events are infrequent, not reproducible, and likely to be an artifact of reverse transcription during RNA-seq library preparation. As anticipated from the cytoplasmic replication stage of positive-strand RNA viruses, viral integration is not expected to be a major pathological factor for SARS-CoV2 and, by extension, not a cause for concern in the use of SARS-CoV2 RNA vaccines. Table S1 for the source of Data in this figure. *p<0.05; ****p<0.0001 by Kruskal-Wallis (E) and multiple Wilcoxon (F) tests and FDR correction. Table S1 for the list of independent studies used here). The representative studies in (A) are GSE147507 and PRJNA665581 for Calu-3 cells, and GSE147507 and GSE151803 for patient samples. Table legends  Table S1 . SARS-CoV2 infected samples from independent studies used here. See Table S2 for the complete list of individual samples. To experimentally enrich for viral RNAs from total RNA of SARS-CoV2 infected cells prior to RNA-seq library preparation, we developed a series of in vitro amplification steps using SARS-CoV2 virus specific primers (VSP) as following. The VSP pool contained ~30 oligonucleotides that span all SARS-CoV2 genes (at least one oligo per gene and nearly 1 oligo per 1kb of the genome). Given our goal to additionally enrich for potential HVC events, we used two approaches, enrichment methods 1 (5'->3' host-virus chimeras) and enrichment method 2 (5'->3' virus-host chimeras) (Fig. 3A) .First strand cDNA synthesis reaction: To capture and enrich for viral, virus-host or host-virus transcripts, we first set up a 20 µl reverse transcription (RT) reaction using 100 ng of mRNA isolated from SARS-CoV2 infected using Superscript III reverse transcriptase. We used 2 pmol T7-P5-VSP oligo pool (for enrichment 1) or 50 pmol of T7-P5-Oligo dT (for enrichment 2) as ""gene-specific primer"" for RT reaction (see Table S3 ). We also incorporated a T7 promoter and Illumina P5 sequence at the 5' end of every oligo as shown in the schematic Fig. 3A Second strand cDNA synthesis and In vitro Transcription: Following this, we performed second strand synthesis using the NEBNext Ultra II Non-Directional RNA second strand synthesis module as per the suggested protocol (NEB, Catalog# E6111L). The synthesized DNA was purified via 1X Mag-Bind TotalPure NGS beads and eluted in ~12 ul of sterile water. 10 ul of this was then used as an input for T7 polymerase mediated In vitro Transcription (IVT) using the NEB HiScribe T7 High Yield RNA Synthesis Kit (NEB, # E2040S). Briefly, all the components were mixed as mentioned in the kit protocol and incubated at 37°C (lid at 50°C) for 16 hours. The reaction was eluted in 20 µl of sterile water after a round of 1X Mag-Bind TotalPure NGS bead cleanup. This newly transcribed RNA was quantified using a Nanodrop and to improve the hybridization kinetics and enhance signal, 500ng of the amplified RNA was fragmented by RNA Fragmentation reagent in a total reaction volume of 10 µl as per specifications (Thermo Fisher, Catalog# AM8740).Final reverse transcription and PCR enrichment of the library: Next, to generate final enriched libraries, we performed reverse transcription of the fragmented RNA with 50 pmol of P7-N6 for enrichment (1) and 2 pmol of the P7-VSP primer pool for enrichment (2,) respectively (see Table  S3 ) using SSIII reverse transcriptase as per the steps mentioned above. After RT, the reaction mixture was purified using 1X Mag-Bind TotalPure NGS beads and eluted in 20 µl of sterile water. 5 µl of this RT reaction was saved for running on a Bioanalyzer and to perform a qRT-PCR validation assay. The remaining 15 µl was used to PCR amplify the library by using high-fidelity Q5 DNA Polymerase (NEB, Catalog# M0491L) for 16 cycles using Universal primer and unique indices (NEB Catalog# E7335L, E7500L) in a total of in a 50 µl reaction volume. Finally, the amplified and enriched library was purified using the 0.8X Mag-Bind TotalPure NGS beads, quantified by Bioanalyzer/Tape station and then sequenced using Illumina platform.The enrichment of viral genes was determined by performing a qRT-PCR assay on the libraries generated. Briefly, the cDNA generated by RT, prior to library amplification by Q5-PCR was diluted 10 -20 fold and used to amplify target gene 'N' of SARS-Cov2 using CDC recommended primers for 2019-nCoV_N1-F The raw sequencing files were download from the Sequence Read Archive (SRA) as shown in the  Table S1 . Fastqc (v0.11.7) was used for data quality control. Sequencing reads were aligned as single end to the chimeric genome of human (hg38) and SARS-CoV2 (NC_045512.2) using STAR aligner (v2.7.7a). For the analyses of the other viruses, the influenza A virus (IAV) genome (A/Puerto Rico/8/1934 (H1N1)， GCA_000865725.1), middle east respiratory syndrome (MERS) genome (NC_019843.3) and the Respiratory syncytial virus (RSV) genome (A2 strain, M11486) were all sourced from NCBI.To estimate the background level of chimeric reads in RNA-seq libraries, a fruit-fly RNA spikein control libraries (PRJNA311567) were used. Briefly, a chimeric genome between human (hg38) and fruit-fly chr4 (dm6) was constructed and the sequencing reads were aligned by the STAR aligner using the same parameters as --outFilterMultimapNmax 1 --outFilterMismatchNmax 3 --chimSegmentMin 30 --chimOutType Junctions SeparateSAMold WithinBAM SoftClip --chimJunctionOverhangMin 30 --chimScoreMin 1 --chimScoreDropMax 30 --chimScoreJunctionNonGTAG 0 --chimScoreSeparation 1 --alignSJstitchMismatchNmax -1 -1 -1 -1 --chimSegmentReadGapMax 3.The known annotated and novel unannotated splicing junctions were extracted from the STAR output as positive controls. The chimeric junctions for human-virus and human-fly were extracted from the STAR chimeric output. The unique chimeric junctions were considered as our chimeric events. To estimate the reproducibility, for each independent study and each cell type, the number of unique junctions were extracted. For every cell type, the mean value of overlapping junctions from two independent studies to the number of junctions in each study was recorded as the reproducibility.To examine the genomic features of the HVC reads, HOMER (v4.11) annotatePeaks.pl was used to annotate the HVC junctions and the corresponding RNA-seq library. In brief, reads in each RNA-seq library were converted to genomic regions by bamTobed (bedtools, v2.30.0) and the unique regions were kept using the following command""sort -k1,1 -k2,2n | uniq"". The reported ""Log2 Ratio (obs/exp)"" for each annotation (e.g tRNA, LTR) were compared between HVC junctions and the corresponding RNA-seq library. Mann-Whitney's U test was used for statistical analysis.",USA,first author,2021-02-17,02
224050e479bc579d63539a9dc2b3187b3a8a7c5f,Title: Genomic surveillance of SARS-CoV-2 in the Bronx enables clinical and epidemiological inference,"The Bronx was an early epicenter of the COVID-19 pandemic in the USA. We conducted temporal genomic surveillance of SARS-CoV-2 genomes across the Bronx from March-October 2020. Although the local structure of SARS-CoV-2 lineages mirrored those of New York City and New York State, temporal sampling revealed a dynamic and changing landscape of SARS-CoV-2 genomic diversity. Mapping the trajectories of variants, we found that while some have become 'endemic' to the Bronx, other, novel variants rose in prevalence in the late summer/early fall. Geographically resolved genomes enabled us to distinguish between a case of reinfection and a case of persistent infection. We propose that limited, targeted, temporal genomic surveillance has clinical and epidemiological utility in managing the ongoing COVID pandemic.The ongoing emergence of novel SARS-CoV-2 variants has highlighted the need for continual genomic surveillance in order to track their spread and limit introductions into new areas. An understanding of circulating viral strains also provides a powerful tool that can be used to make clinical inferences. Here, we employ temporally and geographically resolved sequencing of SARS-CoV-2 samples in order to describe the local landscape of viral variants in the Bronx and to differentiate between cases of re-infection and persistent infection. We propose that local and targeted sequencing of viral isolates is an underutilized approach for managing the COVID pandemic.COVID-19 has had a devastating effect on the health of communities across the globe, with over 79 million reported cases and greater than 1.7 million deaths since the start of the pandemic (1). Until vaccines become widely available, understanding and interrupting SARS-CoV-2 transmission to prevent infection is the mainstay of public health efforts. The Bronx, a borough of New York City (NYC) has sustained the second highest rate of COVID-19 in New York City with 6,035 cases per 100,000 people as of January 11, 2021 (2) . To track the local spread of SARS-CoV-2, we conducted a genomic epidemiologic study at Montefiore Health Systems (MHS), which offers healthcare services to two million residents throughout the Bronx, one of the most diverse and poorest urban communities in the United States.The number of COVID-19 cases peaked in the Bronx in March-April 2020 and subsided during the late spring into summer 2020. To characterize the genetic diversity of SARS-CoV-2, we randomly selected nasopharyngeal samples that were positive for SARS-CoV-2 by RT-PCR testing at the MHS clinical laboratory between March and October 2020. Genomic viral RNA was extracted from nasopharyngeal swabs, and sequencing libraries were prepared using the ARTIC Network protocol and analyzed on an Oxford Nanopore MinION (3, 4) . The ARTIC Network bioinformatics protocol was used to quality check and annotate SARS-CoV-2 genomes with default parameterization (5) . We called variants with the NextClade tool and annotated lineages using the constructed PANGOLIN guide tree from 05/29/2020 (6, 7) . Samples were derived from patients who required hospitalization (48%), mild disease managed as outpatients (26%) and asymptomatic carriers (8.9%) (Fig. 1A) .Analysis of the resulting 104 SARS-CoV-2 genome sequences revealed that B.1 and B.1.3 lineages were the most prevalent during the early months of the pandemic in the Bronx; however, several other lineages were also present at low frequencies ( Fig. 2A) . Although B.1.3 plateaued after the first wave, B.1 continued to be sampled, and a new lineage, B.1.1, arose in late August. We observed no major differences between Bronx SARS-CoV-2 lineages and other SARS-CoV-2 lineages in NYC and New York State (NYS) (Fig. 2B) (8, 9) . We note that ""A"" lineage SARS-CoV-2 viruses are less prevalent in the Bronx, NYC, and NYS compared to the rest of the USA and the world. To determine how the Bronx sequences compared with those sampled across the world, we created a downsampled SARS-CoV-2 tree from 613 high-quality SARS-CoV-2 genomes deposited in GISAID with available location and collection dates. We found that Bronx SARS-CoV-2 sequences represented subsets of different clades of the global tree (Fig. 2C) .We next examined patterns in variant nucleotide positions observed in our data. We found that variation is distributed across the SARS-CoV-2 genome and that some variants are present in almost all Bronx genomes sequenced-these can be described as 'core' to the Bronx at present (Fig. 3A) . Core variants include the spike protein variant A23403G (D614G), as well as variants C241T, C1059T (T265I), C3037T, C14408T (P314L) in Orf1ab, and G25563T (Q57H) in Orf3a. We next examined the dynamics of individual SARS-CoV-2 variants. Although the core variants continued to increase in prevalence as we sequenced new genomes, we also observed variants novel to the Bronx whose prevalence is beginning to increase, whereas others have plateaued or are in the process of plateauing (Fig. 3B) .This local phylogenetic framework of SARS-CoV-2 strains in the Bronx enabled us to distinguish between a case of reinfection and a case of persistent infection in two pediatric patients. The first case is a 10-15-y.o. female who was initially seen in April 2020 in the emergency department with 3 days of fever, sore throat, anosmia, and ageusia. SARS-CoV-2 infection in this patient was confirmed by RT-PCR. She had a total of 6 days of symptoms and was in general good health until the second presentation. In August 2020, she presented again to the emergency department with two days of fever, severe postprandial abdominal cramps, watery diarrhea and generalized body aches. All other reviews of symptoms were negative. The patient had no known COVID-19 exposures and limited outside exposure. A respiratory pathogen panel was negative but her SARS-CoV-2 RT-PCR was positive, as was her SARS-COV-2 IgM Immune Status Ratio (ISR) (2.1, with less than 1 considered negative). Her IgG ISR was negative, 8.7 (normal range ISR < 9). The patient had a total of three days of fever with complete resolution of all other symptoms by day four of illness.The second case involved a 15-20-y.o. female with an incompletely characterized immunodeficiency who presented in July 2020 with an oral lesion. She had no fever, or respiratory or gastrointestinal symptoms, and had neutropenia (absolute neutrophil count 700 cells/ul). After admission for further evaluation, she was found to be SARS-CoV-2 positive.Remnant nasopharyngeal swabs were collected and deidentified at Montefiore Medical Center. All sequences generated in this study have been made publicly available through the GISAID hCoV-19 sequence database. The source code used for sequencing, analysis, and figure generation, is hosted on Github at https://github.com/kellylab/genomic-surveillance-of-the-bronx.Viral RNA was isolated from nasopharyngeal swabs using the MagMAX Viral RNA isolation kit (Applied Biosystems, #AM1939) according to the manufacturer's specification. 400 μl of viral transport medium was used as input for each sample. Isolated RNA was then stored at -80C prior to sequencing library generation.The pipeline was run using the workflow tool Argo running on a Kubernetes cluster in the cloud. Data was stored on a cloud storage bucket between steps (see supplemental code).Low-coverage sequences were improved by combining passed reads from multiple sequencing runs before generating consensus sequences.We included in our analysis only sequences that had 95% or higher coverage, a criterion 104 out of 132 sequences satisfied (Fig S2) . We also looked for signs of biases in the base calling pipeline which would result in higher or lower likelihood of gaps in certain regions. We found that the probability of a gap being present in the consensus is strongly correlated with the coverage level in the BAM file generated by the pipeline. In particular, we found that a coverage of 20x was almost always sufficient to result in a basecall being made at a given position but that the majority of positions had coverage above 400x. Thus, any biases in the pipeline are more likely to arise from biases in the nanopore sequencer itself or its basecaller rather than the consensus generation software.Individual FASTA files ≥ 95% coverage were collected after output by the ARTIC pipeline. The multi-FASTA was aligned using MAFFT on the Nextstrain command line interface version 1.16.7 (6, 22) . The resulting alignment FASTA generated was constructed into a maximum likelihood tree with 1000 SH-aLRT bootstraps using a TIM + F + I substitution model via iqtree-2.1.1-Windows (14) . The tree was rooted on AECOM 90, the oldest outgroup sequence, and the entire tree was branch length corrected based on a fixed mutation rate of 0.0008 nucleotides/site/year with a standard deviation of 0.0004 using treetime 0.7.6 (13). The tree was visualized on iTOL and annotated with the iTOL annotation editor (21).The GISAID database: GISAID -Initiative limited to 95% coverage and higher was used as an input for this analysis. The multi-FASTA of 11/14/2020 was filtered using the Nextstrain command line interface version 1.16.7 filter command. The specifications entailed and inclusion criteria used to construct a globally and temporally representative multi-FASTA was adapted from the criteria used to construct the Nextstrain global tree. An inclusion and exclusion text file was used to remove and keep strains that Nextstrain deemed important and is located here:To identify pangolin lineages, the pangolin command line tool 2.0.8 was used in legacy mode, relying upon the 05/29/2020 update of the guide tree to assign lineages to local sequences via bootstrapping. The browse function of the GISAID database was used to count the lineages present in New York State. United States and global data were retrieved from SARS-CoV-2 lineages (cov-lineages.org) (7).Pangolin Command Line Tool:All figures were conjoined and post-processed to adjust colors and layout in Adobe Illustrator. Figure 1 a) The table was generated by manually pulling EMR records for the patients whose samples came from the hospital. Not all of the fields were available for every patient.Rare: Positions where a variant is found less than four times.ii) Uncommon: Positions where a variant is found at least four times but less than 26 times (25% of our samples that were used in the analysis). This was further broken down into wave 1 and wave 2 categories, where a variant was considered to be 'wave-1-associated' if it showed up at least four times in the first half of the samples and at most once in the latter half (and vice-versa for wave 2). Samples that showed up at least once in both halves were labelled as wave 1 + 2.iii) Common: Positions where a variant is found at least 26 times.c) This table simply shows the data in the previous figures in text format for the more frequent variants.This tree was visualized using iTOL. See above for how the local phylogenetic tree was constructed.In contrast to Fig. 3B , the x-axis is ordered by date in order to demonstrate the temporal dynamics of variants in the Bronx.",USA,first author,2021-02-10,02
a7efa394756a4b79d40225c7a36d2e2e23200045,Title: Preservation of neutralizing antibody function in COVID-19 convalescent plasma treated using a riboflavin and ultraviolet light-based pathogen reduction technology,"The coronavirus disease-2019 (COVID- 19) pandemic bears testimony to the risk presented by emerging infectious diseases (EID). Few treatment options are available when novel viruses first arise, but the use of convalescent plasma (CP) may be an expedient therapeutic approach until other medical countermeasures become widely available. CP is a treatment in which putatively antibody-rich plasma is taken from those recovered from the disease and transfused to provide passive immunity to infected patients or susceptible individuals. Case reports of effective use of CP date back to the 1918 influenza pandemic [1] and more recently to EID outbreaks including severe acute respiratory syndrome (SARS) [2, 3] , Middle East respiratory syndrome (MERS) [4] , H1N1 influenza [5] , and Ebola virus disease (EVD) [6] . In the current pandemic COVID-19 CP (CCP) has demonstrated safety with minimal side effects [7] , though controlled clinical efficacy data is only beginning to come in [8] [9] [10] .While the most effective protocols for treatment with CCP are yet to be defined, plasma transfusion is a routine medical procedure available globally. However, as with any blood product, there is a risk of transmitting bloodborne pathogens with CCP transfusion. The causative agent for COVID-19, severe acute respiratory syndrome coronavirus-2 (SARS-CoV-2), is itself not believed to be transfusion-transmissible [11] .Yet the possibility of co-infections is present, particularly in regions with a high endemic prevalence of other infectious diseases [12] . Pathogen reduction technology (PRT) treatment of CCP is a measure that can be taken to maintain the safety of the blood supply while providing potential benefits to COVID-19 patients.PRT systems have been developed over the past decades as a proactive means to reduce the residual risk of transfusion-transmitted infections that continues to exist despite the implementation of routine blood safety practices such as donor questionnaires, travel deferrals, and viral screening tests [13, 14] . Donor infections could escape these blood safety measures for a number of reasons, including a ""window period"" donation where the viral load has not yet reached the detection limit of screening tests, a lack of testing capability for particular infectious agents, or an unfavorable cost-benefit ratio for continuing to implement more and more tests. PRT All rights reserved. No reuse allowed without permission.CCP was provided by an accredited blood center specializing in biomaterial collections for research (Key Biologics, Memphis, TN, USA). CCP was collected by apheresis under an IRB-approved protocol from donors determined to have recovered from COVID-19 and was shipped to Colorado State University. All products were placed into frozen storage at ≤ -20 °C upon receipt until needed for further processing.CCP units were treated using a R+UV PRT system (Mirasol ® Pathogen Reduction Technology, Terumo Blood and Cell Technologies, Lakewood, CO, USA) as previously described [18] . Briefly, thawed CCP units were transferred to an illumination bag and mixed with 35 mL of riboflavin solution (500 µmol/L riboflavin in 0.9% sodium chloride, pH 4.0 to 5.0 [Terumo Blood and Cell Technologies, Larne, Ireland]). The prepared units were then placed into the UV illumination device (Terumo Blood and Cell Technologies, Lakewood, CO, USA) and exposed to 6.24 J/mL of energy. Samples for analysis were taken prior to the addition of riboflavin solution (Post-Collect), after addition of riboflavin (Pre-Treat), and after UV illumination (Post-Treat). Sample aliquots were stored frozen (≤ -20°C) in cryovials until testing. CCP units were analyzed for selected coagulation factors, immunoglobulins, and SARS-CoV-2 antibody binding and neutralizing activity.All rights reserved. No reuse allowed without permission.Plasma immunoglobulins and IgG subclasses were measured by standard quantitative nephelometry (IgG, IgA, IgM at UC Health Anschutz, Aurora, CO, USA; IgG subclasses at ARUP Laboratories, Salt Lake City, UT, USA). The reference laboratories performing immunoglobulin analysis are accredited by the College of American Pathologists (CAP) and maintain Clinical Laboratory Improvement Amendments (CLIA) certification.An enzyme-linked immunosorbent assay (ELISA) was performed at Colorado State University to test CCP samples and a negative control (normal plasma sample) for antibody binding to the SARS-CoV-2 spike protein receptor-binding domain (RBD) and epitopes associated with the spike protein subunits S1 and S2 (catalog numbers 40592-V08H, 40591-V08H, and 40590-V08B, Sino Biological US Inc., Wayne, PA, USA). The protocol for ELISA was adapted from Robbiani et al. [19] with a few modifications.Briefly, high binding 96-half-well microplates (Corning Life Sciences, Tewksbury, MA, USA) were coated with 50 ng S1, S2, or RBD protein prepared in PBS and incubated overnight at 4 °C. On the next day, the plates were washed 5 times with 180 µL wash solution (PBS + 0.05% Tween 20) and non-specific interactions were blocked using 180 µL blocking buffer (PBS + 0.05% Tween 20 + 2% BSA + 2% normal goat serum [Jackson ImmunoResearch Inc., West Grove, PA, USA]). After 2 hours the plates were washed and different CCP sample dilutions prepared in blocking buffer were added to All rights reserved. No reuse allowed without permission.Data sets exhibiting a non-normal distribution were evaluated non-parametrically using a Wilcoxon matched-pairs signed rank test. Statistical analysis was performed using Prism 8 for Windows (GraphPad Software, Inc., San Diego, CA, USA).CCP was collected from 6 donors with demographics as described in Table 1 . All 6 units met the incoming product specifications for the R+UV PRT process and were successfully treated. Protein retention analysis (Table 2) demonstrated that although there was a statistically significant treatment effect for the coagulation factors, retention was on the order of 70% or better. Of note is that the immunoglobulin concentrations, including those for IgG subclasses, were unaffected by R+UV treatment as demonstrated by retention remaining at 100%. All rights reserved. No reuse allowed without permission.This study evaluated the effect of R+UV PRT treatment on functional properties of CCP.A treatment effect upon coagulation factors was observed following R+UV treatment, but the reductions seen were consistent with previously published R+UV literature [18, [22] [23] [24] [25] . Moreover, all PRT methods are known to degrade plasma proteins to varying degrees [26] [27] [28] [29] . Minimal effects upon antibodies were demonstrated, from the very general immunoglobulin retention percentages to the more specific SARS-CoV-2 epitope binding measurements. Neutralizing antibody activity was similarly well- [30, 31] . These data suggest that PRT treatment does not impair the passive immunity provided by CCP. All rights reserved. No reuse allowed without permission.Importantly, the levels of IgG and IgM antibodies to specific viral proteins in the receptor binding domain (RBD) and spike proteins (S1 and S2) were maintained following treatment. These antibodies have been shown to have high virus neutralizing capacity.Robbiani et al. [19] demonstrated that despite variations in the levels of overall neutralizing antibodies in donors of convalescent plasma, the presence of these specific subsets of antibodies with potent antiviral activity correlated with improved clinical outcomes in patients receiving the convalescent plasma products. The data implies that maintenance of the level of these subsets of antibodies may correlate with clinical effectiveness more directly than measure of overall neutralizing antibody levels.CCP is the most readily available source of anti-SARS-CoV-2 antibodies, and its use has been widely embraced as a treatment for COVID-19 while other antiviral therapies and vaccines are in development and can be widely deployed. The ability to safely utilize convalescent plasma in these settings, however, depends on the safety of the product collected from donors who may have experienced a period of immune compromise during acute phases of the disease. Exposure to a variety of transfusiontransmitted diseases during this period or reactivation of latent disease could introduce additional risk into the use of such products for therapeutic applications. PRT treatment All rights reserved. No reuse allowed without permission.With the worldwide need for treatment options to address the COVID-19 pandemic, CCP is an expedient therapeutic option that can be implemented globally, whether in resource-rich or resource-limited environments. The addition of PRT may be warranted to address possible co-infections in regions experiencing a high prevalence of endemic transfusion-transmissible diseases, but conservation of the passive immunity conveyed through CCP must be ensured. Based upon this small study there is no indication that All rights reserved. No reuse allowed without permission.p=0.4722 Anti-S2 IgM (AUC)p=0.1208All rights reserved. No reuse allowed without permission.",USA,first author,2021-02-20,02
f8f4bc9cc53df03d603ab218076d750f9b810b92,The Impact of COVID-19 on Otolaryngology Community Practice in Massachusetts A,"high-risk field for exposure, given high COVID-19 viral titers in the nasopharynx and other nearby mucosal surfaces. This theoretical exposure risk was compounded by shortages of personal protective equipment (PPE) in the early phases of the pandemic, rendering many otolaryngologists potentially susceptible to COVID-19. 4 The explosive growth of new COVID-19 cases overwhelmed health care systems worldwide, accompanied by a disruption in the provision of elective and semielective health care services across many medical specialties. In particular, the state of Massachusetts was profoundly affected by the COVID-19 pandemic, with case totals in the tens of thousands in the first 2 months alone, 5, 6 along with concurrent shortages of ventilators, staff, and PPE. 7 Following national and local government recommendations, nonurgent clinical visits and elective surgical procedures were postponed or canceled across many institutional hospitals and private practices across Massachusetts. The impact of COVID-19 across medical and surgical specialties remains under investigation. Not only are data pertaining to changes in practice patterns due to COVID-19 lacking for otolaryngology, but the few available reports have all been generated by academic institutions. However, private practices comprise the majority of otolaryngology care delivery within the United States. In the present study, we use aggregated data from 10 otolaryngology private practices in Massachusetts to quantify the impact of COVID-19 on the provision of otolaryngology services and identify changes in practice patterns for private community practices.This is a retrospective review of private practice physician services provided at 10 private practices in Massachusetts. Institutional review board (IRB) approval was obtained for this study from the Partners Health Care IRB (IRB #2020P001248).All Massachusetts-based private practice physicians using the services of ENT Billing Associates (an independent national medical billing services organization) between January 1, 2019, and April 30, 2020, were eligible for inclusion in this study. Physicians were excluded if they had not remained at the same practice throughout the entire study period.The electronic billing records of ENT Billing Associates were reviewed and compiled by week. Service and encounter data were determined based on billed Evaluation and Management (E/M) codes and Current Procedural Terminology (CPT) codes. Data were collected based on fiscal weeks beginning with the first Monday to Sunday period of each year (2019 and 2020) and extending for 16 weeks in total for that year. Encounters were determined based on any visits that generate an E/M CPT code or chart flag for a visit not designated to generate a bill (eg, a visit within a global period). Procedures were identified based on the most common procedures performed in these general otolaryngology practices and grouped by CPT code type, including endoscopy (31231, 31237, 31238, 31575, 31579), cerumen removal (69210, G0268), septoplasty (30520) In addition, a questionnaire was distributed to each practice. This was completed by either the practice manager or a representative physician from the practices. The questionnaire detailed the financial and staffing impact of COVID-19.Comparisons were made between the early fiscal weeks (weeks 1-10) and late fiscal weeks (weeks 11-16) of the first third of 2019 and 2020. Specifically, t test comparisons were made between early and late 2019, early and late 2020, early 2019 and 2020, and late 2019 and 2020. This was performed using Stata software (StataCorp). GraphPad Prism version 8.0.2 (GraphPad Software) was used for visualization of data.Demographic information was captured from 20 general otolaryngology physicians across 10 private practices in Massachusetts and is shown in Table 1 . There was a mean (SD) of 2.1 (1.6) physicians per clinic, as well as a mean (SD) physician age of 51.4 years (7.8). Eight of 10 practices furloughed personnel, while 2 clinics experienced permanent layoffs. Cutbacks in working hours took place in 90% of practices. Among those that cut back hours, there was a mean (SD) reduction by 75.5% (12.1%). Seven clinics applied for the federal Paycheck Protection Program (PPP), all of whom reported reduced necessity for layoffs due to PPP utilization. Between weeks 11 and 16 of 2020, only 20% private practices provided audiology in person, and no practices were able to do so remotely. No practices provided any nonemergent audiology during this period. During these weeks, only 60% of practices continued performing endoscopy, with all of them implementing stricter selective criteria. Aggregate week-by-week visit and procedure data for 20 general otolaryngology physicians across 10 practices in Massachusetts are shown in Table 2 . Total visits in weeks 1 to 10 of 2019 and weeks 1 to 10 of 2020 were not statistically different, while a significant decrease of 62.5% of visits is observed when comparing weeks 11 to 16 of 2019 and weeks 11 to 16 of 2020 (P \ .0001; 1432.8 [95% CI, 1295.7-1570.0] vs 537.3 [95% CI, 408.9-655.8]). These numbers were reflected in a decrease in both consult visits and established visits. Week 10 in 2020 corresponds to the time that the Massachusetts governor declared a statewide State of Emergency (on March 10, 2020), while week 12 corresponds to the statewide emergency stay-at-home recommendation (on March 23, 2020). These events closely corresponded to a decrease in total visits ( Figure 1) . Notably, the first coronavirus case was diagnosed in Boston on February 1, 2020, 6 weeks prior to an observed decline in clinical volume. Figure 2 highlights that while total visits declined precipitously during weeks 11 to 16 of 2020, they were partially but incompletely replaced by virtual visits. After no virtual visits were performed in 2019, and fewer than 1 virtual visit was performed on average weekly in the first 10 weeks of 2020 (0.8; 95% CI, 0.06-1.5), weeks 11 to 16 of 2020 had an average of 293.8 (95% CI, 167.4-420.3) virtual visits per week. The difference in both cases relative to weeks 11 to 16 of 2020 was statistically significant (P \ .0001 for both). By week 12, virtual visits comprised a greater proportion of overall visits than in-person visits, which continued through week 16.Of additional interest is volume of clinic and operating room (OR) procedures performed by general otolaryngologists, listed in Table 3 . Significant decreases were observed for all evaluated OR procedures in weeks 11 to 16 of 2020 compared to 2019 data, including functional endoscopic sinus surgery (90% decrease), myringotomy with or without tube placement (90% decrease), tonsillectomy and/or adenoidectomy (89% decrease), and septoplasty (93% decrease) (P \ .001). Clinic procedures including cerumen removal (85% decrease), control of epistaxis (58% decrease), and flexible and rigid endoscopy (77% decrease) saw corresponding significant decreases in 2020 (P \ .001), while clinic myringotomy did not decrease to a significant degree (Figure 3 ).COVID-19 caused tremendous disruption in the provision of health care services in Massachusetts. Following international and federal recommendations, significant public policy changes were made to adapt to the new challenge.Shortly after the first positive COVID-19 case in Boston, the Massachusetts governor declared a state of emergency on March 10, 2020 (week 10), a day before the WHO declared COVID-19 a pandemic. 8, 9 Three days later, the American College of Surgeons urged physicians to postpone or cancel all nonurgent clinical visits and elective surgeries as well. 10 Then, on March 23, 2020 (week 12), the Massachusetts governor announced an emergency order, including closure of all ''nonessential'' physical workplaces and a stay-at-home order for at least 2 weeks. 8 These recommendations and government orders substantially altered many practices' operations.While this pandemic affects all medical fields, otolaryngologists are among the groups thought to have the highest risk of contracting COVID-19 11 due to proximity of clinical examination to the upper airway. 4 Beyond anatomical exposure, common otolaryngology procedures also can generate airborne particulate through powered instrumentation, potentially increasing exposure risk if COVID-19 can be transmitted in this fashion. [12] [13] [14] COVID-19 also is associated with high rates of respiratory failure in patients, often requiring urgent airway management by otolaryngologists, in which procedures like intubation and tracheostomy are particularly high risk. 15, 16 Finally, the disease has been shown to transmit via asymptomatic carriers, facilitating interpersonal spread in a busy clinical practice. 17 New guidelines, combined with public apprehension of in-person health care, resulted in significant changes in practice patterns, finances, and patient outcomes for private practices. Due to COVID-19, 9 of 10 clinics represented in this data set cut back working hours, with an average 75.5% decrease. The hour reduction placed substantial constraints on prompt patient care. It also led to financial constraints for practices for maintaining fixed and overhead expenses. As a result, 8 practices furloughed personnel, and 2 practices had permanent layoffs. In response to the decrease in revenue, 7 clinics applied for PPP assistance. Despite 2 applications being delayed, all PPP recipients reported benefits from the funding for obviating additional layoffs. These outcomes highlight the necessity and efficacy of federal assistance to sustain otolaryngology practices during this challenging time.Availability of otolaryngology services differed starkly before and after COVID-19. Following the Massachusetts declaration of a state of emergency, practices providing inperson audiology decreased by 80%, with none providing remote or nonemergent appointments. During this hiatus of audiology services, communities were at risk for missed sudden sensorineural hearing loss diagnoses and subsequent expedient treatment. In addition, patients with nonemergent problems were left without audiologic care at a time during a period of widespread mask use, which could further strain patients' ability to communicate. Only 6 of 10 practices continued performing rigid or flexible endoscopy. The inherent perceived danger of endoscopy prompted all practices included to implement stricter selective criteria. Reduction in the availability of endoscopy, combined with broader exclusion criteria, may have delayed or decreased the accuracy of diagnosis of a number of time-sensitive conditions, including head and neck malignancy, and this would be a worthwhile focus of further investigation.Our study found a precipitous decline in the utilization of private practice total visits, established visits, and new patient visits within otolaryngology, most notably in weeks 11 to 16 of 2020, relative to both early 2020 (weeks 1-10) and weeks 11-16 of 2019. The greater decline in total visits of weeks 11 to 16 in contrast to weeks 1 to 10 suggests the decrease is most aligned with the influence of governmental policies, as opposed to direct natural pandemic progression. Comparisons can be drawn to the severe acute respiratory syndrome outbreak in 2003, where the Prince of Wales Hospital in Hong Kong observed a 59% decrease in outpatient clinic attendance, a 79% decrease in number of operations performed, and an 84% decrease in daily hospital admission rates. 18 These decreased patient visits were attributed to cancellation of nonessential elective surgeries, public recommendations to stay-athome, and patients canceling appointments, similar to what was more recently observed in Massachusetts. 18 Based on our data, OR procedures had a higher percentage decline than office procedures, which is likely due to several factors. Canceling OR procedures preserves PPE, which was critically low in supply nationwide in early phases of the COVID-19 response. Furthermore, OR procedures necessitate higher potential inpatient admissions, which can further exhaust limited medical personnel and resources. Another factor in the decline in OR cases is that the hospital regulates availability of OR time, based on government and health care system recommendations. Findings may suggest response to COVID-19 had a greater impact on canceling OR procedures than clinic procedures, seen most prominently in our myringotomy/tympanostomy tube placement data. Office myringotomy remained stable from pre-COVID-19 levels during weeks 11 to 16 of 2020, while OR myringotomy rates dropped by almost 90%. This finding is likely most applicable to interventions without upper airway involvement to mitigate aerosol-generating procedures. The rise of telemedicine also provided another significant tool to prescreen patients and identify individuals who may be candidates for office-based procedures. 19 Although the United States has established telemedicine programs offered by more than 50 health systems, 19 pre-COVID-19 telemedicine users were limited to medical specialties with low barriers to entry and easily digitized encounters, such as psychiatry and dermatology. 20, 21 Prior to the COVID-19 pandemic, otolaryngology as a field rarely used telemedicine, with significant uptake noted alongside policy changes that were announced in March 2020 by both Medicare and private payors to implement less restrictive and more remunerative coverage policies for telemedicine. 22, 23 Our findings in this study corroborate this trend seen in the field of otolaryngology as a whole. Before 2020, virtual visits were not a part of any of the otolaryngology practices that we studied, and yet, the number of telemedicine visits surpassed in-person visits consistently after week 12 of 2020. This is not unique to the United States; Hong Kong hospitals used technology, specifically Zoom, a virtual meeting program, to continue regular checkup visits while triaging possible patients in need for operations. 24 Not only does telemedicine allow physicians to assess patients from a safe distance, but it also likely decreased the buildup of canceled or postponed patient flow post-COVID-19.Our study has several limitations, first and foremost its retrospective nature from a single source of data for multiple otolaryngology groups. Our inclusion group was from Massachusetts only, which restricts this study's implications for other geographic regions. In addition, 20 general otolaryngologists were represented in our data set from 10 practices, implying that one practice's decision may potentially affect outcomes for multiple physicians. Only the first 4 months of 2020 were selected for examination based on available data at the time of manuscript preparation. Lastly, this study specifically focuses on the field of otolaryngology and its unique relationship with COVID-19 during this unprecedented time; other specialties may have seen varying alterations in the provision of clinical and surgical care. A key strength of this study is that it focuses on the COVID-19 experience of general otolaryngologists rather than their academic counterparts, the former of which have been excluded from reporting to date.COVID-19 had a multifaceted impact on otolaryngology practices in Massachusetts. To our knowledge, this is the first article to quantify this impact within otolaryngology private practices. Significant declines in provision of otolaryngology services aligned with Massachusetts government's public health policy changes in response to COVID-19. The combination of limited personnel and PPE, as well as suspension of nonessential office visits and surgeries, led to a decrease in total office visits and even higher decrease in OR procedures. This reduction in otolaryngology services was only partially replaced by telemedicine visits, and therefore, overall delivery of otolaryngology care was substantially diminished due to COVID-19.Timothy Fan, made contributions to conception/design of study, analysis of results and drafting and revising final manuscript; Alan D. Workman, made contributions to conception/design of study, analysis of results and drafting and revising final manuscript; Lauren E. Miller, made contributions to conception/design of study, analysis of results and drafting and revising final manuscript; Mallory Mason Sakats, made contributions to conception/ design of study, analysis of results and drafting and revising final manuscript; Karthik Rajasekaran, made contributions to conception/design of study, analysis of results and drafting and revising final manuscript; Jason A. Brant, made contributions to conception/design of study, analysis of results and drafting and revising final manuscript; Arjun K. Parasher, made contributions to conception/design of study, analysis of results and drafting and revising final manuscript; David Huckins, made contributions to conception/design of study, analysis of results and drafting and revising final manuscript; Avner Aliphas, made contributions to conception/design of study, analysis of results and drafting and revising final manuscript; Robin Glicksman, made contributions to conception/design of study, analysis of results and drafting and revising final manuscript; Antoine Eskander, made contributions to conception/design of study, analysis of results and drafting and revising final manuscript; Jordan T. Glicksman, made contributions to conception/design of study, analysis of results and drafting and revising final manuscript.",USA,first author,2021-02-02,02
a3bd5c28130b5204ebc66ab369cb261b9c00cc2d,"Risk factors for SARS-CoV-2 infection among farmworkers in Monterey County, California","Essential workers in agriculture and food production have been severely affected by the ongoing COVID-19 pandemic. Widely-reported outbreaks associated with occupational exposure to SARS-CoV-2 have strained U.S. food supply chains 1 and drawn attention to circumstances potentially placing workers at risk, including poor hygienic conditions, lack of access to educational materials in languages other than English, medical leave policies, and residential crowding. 2 Agricultural work is one of the lowest-paid occupations of the U.S. economy, with 29% of full-time workers earning an annual income below $26,200 for a family of four. 3 More than half of U.S. farmworkers are Latino, 4 and many live in crowded housing of substandard quality. 5 In California, at least half of farmworkers are believed to be undocumented, which could further lead to labor exploitation and a less protected working environment. 6 In a study in Monterey County, California, we have reported 4-fold higher SARS-CoV-2 test positivity among farmworkers than the county population at large, and 24% higher test positivity among farmworkers than other individuals residing in the same communities. 7 Statewide, agricultural and food workers experienced a 39% higher risk of all-cause death from March-October 2020 than during the same period in 2019 -a greater increase than any other occupational group; 8 for workers of Latino backgrounds, the increase in all-cause mortality was 60%. Testing for SARS-CoV-2 infection at CSVS began 15 June 2020 and was offered to all individuals regardless of exposure, symptoms, documentation, or health insurance status. Medical personnel collected oropharyngeal specimens for detection of SARS-CoV-2 RNA via the qualitative Hologic (Marlborough, Massachusetts) Aptima nucleic acid transcription-mediated amplification (TMA) assay.Testing was conducted on clinic premises or at community sites, including low-income housing, agricultural fields, and CSVS-run community health fairs.Between 16 July and 30 November 2020, we invited farmworkers (i.e., anyone employed in the agricultural sector) receiving care or getting tested for SARS-CoV-2 infection at CSVS clinics and community sites to participate in our study. We posted flyers about the study at the clinics and around town and provided study information to community groups and growers. Farmworkers were eligible for participation if they were not pregnant, ≥ 18 years old, had conducted farm work within the two weeks preceding their testing date, and were sufficiently proficient in English or Spanish to give consent and complete study procedures. Beginning 5 October, we enrolled any individuals who had engaged in agricultural work at any time since March 2020 since the growing season was ending.We enrolled a total of 1,115 farmworkers. We excluded 8 farmworkers who did not provide blood samples or were not employed as farmworkers at time of enrollment from analyses, leaving a total of 1,107participants. Study protocols were approved by the Office for the Protection of Human Subjects at UC Berkeley. All participants provided informed written consent.After the participant completed the SARS-CoV-2 TMA test and consented to participate in the study, the study team obtained a blood sample by venipuncture for testing of anti-SARS-CoV-2 antibody status. We then measured (with shoes on) height and weight using a digital scale. The study team administered a 45-minute computer-guided questionnaire by telephone in Spanish or English within two days before (for pre-consented participants) or after the enrollment visit, but before SARS-CoV-2 testing results were available. The questionnaire gathered information on socio-demographic characteristics, risk factors for SARS-CoV-2 infection, and impacts of the pandemic on daily life and wellbeing. Participants received a $50 prepaid VISA gift card which was loaded upon completion of all data collection activities.All rights reserved. No reuse allowed without permission.We analyzed current (TMA-positivity) and historical (IgG antibody reactivity) SARS-CoV-2 infection separately. Analyses examining risk factors for TMA positivity included participants who worked in agriculture in the two weeks preceding enrollment (n=911); analyses for seropositivity included all farmworkers who provided a blood sample (n=1,058).We performed bivariate analyses for a wide range of socio-demographic, household, community, and work-related characteristics known or suspected to be associated with SARS-CoV-2 infection (Tables 1-4 and eTables 1-4) and assessed correlations between these characteristics (eFigure 1). We included covariates in multivariate models if there were >5 TMA positive or seropositive cases in each category, respectively, and a chi-square or t-test p-value<0.2 in bivariate analyses. Categorical risk factors were modeled as shown in Tables 1-4 , with the exception of language spoken at home (modeled as indigenous language spoken at home -yes/no) and working in the fields (yes/no). Age, years in the U.S., and household size were modeled as continuous variables. We did not consider specific agricultural crops in multivariate analyses because farmworkers reported working in a variety of them. We used backward stepwise elimination (with a threshold of p<0.1) to select covariates for inclusion in final models.We used multiple imputation with chained equations to account for missing values (<2.5% missing for all variables). To account for differences between those recruited at clinics vs. community events, as well as changes in the background positivity rate in Monterey County over the course of the study period, we grouped participants into strata by recruitment site and period (i.e., 16 July-31 August, 1-30 September, 1-31 October, or 1-30 November). We used conditional fixed-effects Poisson models 12 to estimate adjusted risk ratios (aRRs) while accounting for differences among strata, estimating robust standard errors using the Huber-White estimator.Most study participants were born in Mexico, had primary school or lower levels of educational attainment, were married or living as married, and were overweight or obese ( Table 1) . Participants All rights reserved. No reuse allowed without permission.About three-quarters of participants worked in the fields and farmed a variety of crops; the most common were berries (28.6%), leafy greens (26.4%), and broccoli (18.8%) ( Table 3) . Nearly all farmworkers reported using a face covering at work, and 34.3% commuted to work with members of other households.Almost 40% worked during the pandemic with someone who had symptoms of COVID-19 or were known to be infected with SARS-CoV-2 and 13.5% reported such workplace exposure during the two weeks preceding their testing date. Almost all farmworkers reported that their employers provided them with hand sanitizer, gloves, face coverings, and handwashing stations; disinfected surfaces and tools regularly; and provided them with information on how to prevent SARS-CoV-2 transmission at work and the importance of staying away from work if they were sick (Table 4) . However, 44.7% reported that their employer did not screen for fever and symptoms upon arrival at the workplace, which was recommended as part of a countywide agricultural advisory.Thirteen percent (n=118) of the 911 participants currently working in agriculture tested positive for current SARS-CoV-2 shedding by TMA, including 18.5% of those recruited at the clinics and 5.8% of those recruited via outreach ( Table 1) . Several socio-demographic, household, community, and work-related variables were associated with TMA positivity in bivariate analyses (Tables 1-4) . Notably, we found that participants who had a lower educational level, spoke indigenous languages at home, lived in the community of Greenfield, worked in the fields, did not work indoors, commuted to work with nonhousehold members, lived or worked with someone who had symptoms of COVID-19 or with known infection in the preceding two weeks, and were not screened for either fever or COVID-19 symptoms upon arrival at work had a higher prevalence of TMA positivity. We also observed correlations between some of these characteristics (eFigure 1). All rights reserved. No reuse allowed without permission.someone who had symptoms of COVID-19 or was known to be infected with SARS-CoV-2 in the previous two weeks. Additionally, working in the fields (compared to agricultural work in all other settings) was associated with higher risk of current SARS-CoV-2 infection (aRR=1.60; 1.03-2.50). In contrast, farmworkers screened by employers for symptoms of COVID-19 or elevated temperature had a reduced risk of current infection (aRR=0.79; 0.61-1.01; Figure 1A ).We found that 19% of the participants who provided a blood sample had antibody evidence of prior infection, with similar prevalence among those tested in the clinics (18.4%) and at community sites (19.4%; Table 1 ). Farmworkers with primary school or no education, who lived in Salinas or Greenfield (vs. other towns), were overweight or obese, lived in large households or with children ≤ 5 years, lived in crowded housing, had ever lived with someone who had symptoms of COVID-19 or were known to be infected with SARS-CoV-2, and worked in the fields had higher antibody prevalence than their counterparts (Tables 1-3). We also found that those who worked indoors and whose employer provided information on how to protect themselves at work had lower likelihood of seropositivity (Tables 3 and 4) .In multivariate analyses, we found that participants who were obese (aRR=1.65; 1.01-2.70) or overweight (aRR=1.42; 0.94-2.16) or reported being diabetic (aRR=1.31; 0.98-1.75) were more likely to be seropositive. Additionally, we identified higher risk of seropositive status among those living with children ≤ 5 years old (aRR=1.40; 1.1-1.76), with unrelated roommates (aRR=1.40; 1.19-1.64) or in crowded housing (aRR=1.23; 0.98-1.53), and those who had ever lived with someone who had symptoms of COVID-19 or were known to be infected with SARS-CoV-2 (aRR=1.59; 1.13-2.24; Figure 1B ).Farmworkers who lived outside the region's largest communities of Salinas and Greenfield (aRR=0.58; 0.47-0.71), worked indoors (aRR=0.68; 0.61-0.77), or whose employer provided them with information on how to protect themselves at work (aRR=0.59; 0.40-0.86) had a decreased risk of serpositivity.In this primarily Mexican-born and very low-income farmworker population in California, current SARS-CoV-2 infection was associated with having lower levels of education, speaking an indigenous language, working in the fields rather than elsewhere in agriculture, and exposure to known or suspected COVID-19 case at home or in the workplace. We also found higher prevalence of prior SARS-CoV-2 infection, All rights reserved. No reuse allowed without permission.Those living in the more urban areas of the county were particularly at risk, as were those who were obese or diabetic. As evidence of the importance of health education, farmworkers who reported that their employer provided them with information on COVID-19 protection were less likely to have been infected.Our study suggests several routes of SARS-CoV-2 exposure that may be of importance to the farmworker population. Unsurprisingly, living in crowded housing or with unrelated roommates was associated with higher risk of prior infection. Independent of these associations, we also saw higher seroprevalence among individuals living with children five years old or younger. While the role of children in SARS-CoV-2 transmission has been uncertain in many populations, in part due to lower risk of symptoms and lower frequency of testing at younger ages, [14] [15] [16] recent investigations have demonstrated equivalent viral load across ages 17 and higher risk of transmission from infected children than from adults, given similar household exposures. 18 While schools and formal daycare establishments were closed during our study, informal or home-based childcare arrangements with relatives or friends may have led to additional exposure to infection. Taken together, our findings suggest substantial risk of infection associated with residential exposures in this low-income essential workforce population.Several workplace factors were also associated with infection risk. Farmworkers whose employers provided informational resources on preventing COVID-19 at work had 41% lower risk of prior infection, whereas farmworkers whose employers screened them for symptoms or fever had 21% lower risk of current infection. This reduction could owe to benefits of health education, as well as more stringent efforts by employers to reduce risk by providing education and screenings. Individuals working outside and in the fields were more likely to be both currently infected and seropositive, respectively. Whereas indoor exposures are thought to be associated with the greatest risk of transmission, 19 a lower perceived sense of risk during outdoor work, difficulty using PPE while engaged in physically demanding tasks, or socioeconomic differences among outdoor and indoor workers may contribute to the observed association in our study. While the estimated risk ratio for infection associated with workplace exposure was lower than that for household exposure, this difference could in part reflect misclassification, if individuals are are more likely to know about the health of household members. Previously, we have reported higher SARS-CoV-2 test positivity among farmworkers than among age-and sex-matched adults from the same communities who also received testing at CSVS, 7 further supporting the hypothesis that workplace exposures specific to agriculture may be of importance to SARS-CoV-2 transmission.Last, we observed that farmworkers who spoke indigenous languages and those with lower education were more likely to currently have COVID-19 at the time of testing. Those who spoke indigenous languages also had a lower educational level and had more recently arrived in the U.S. They lived in All rights reserved. No reuse allowed without permission.We also saw associations of prior infection with comorbid conditions. While it is known that obesity increases the risk for severe COVID-19 illness, 20 we also observed an increased risk of prior infection among obese individuals. This finding is consistent with a recent meta-analysis of 20 studies which found 46% higher odds of SARS-CoV-2 infection among obese individuals, 20 possibly related to alterations in systemic metabolism, including altered adipokines [21] [22] [23] and chronic low-grade inflammation. 24, 25 Similarly, diabetes can attenuate the synthesis of proinflammatory cytokines (e.g., interferon gamma and interleukins) and their downstream acute phase reactants, 26 but also impair macrophage and lymphocyte functions. 27 As obesity and diabetes are prevalent among farmworkers as well as other low-income Latino populations, our findings that these conditions are associated with higher risk of infection add to previous concerns based on the knowledge that these conditions may also exacerbate risk of adverse clinical outcomes.Our work represents the first epidemiological study to address risk factors for SARS-CoV-2 infection among U.S. farmworkers, and substantiates earlier concerns 6,28-30 that living and working conditions in this population may contribute to risk of infection. Several limitations should be considered. We cannot determine how well our sample represents the farmworker population, many of whom are ""hidden"" due to their informal workforce participation and undocumented status. 31 As we excluded individuals who did not speak Spanish or English sufficiently well to participate, our study likely under-represents indigenous populations. We observed differences in prevalence of current, but not prior, SARS-CoV-2 infection between study participants recruited at clinics and those recruited via community outreach events, 7 as individuals seeking testing at clinics were more likely to be symptomatic or to report recent known exposure; to mitigate confounding, we defined strata by recruitment site. In addition, waning antibodies, particularly for individuals experiencing mild or asymptomatic infection, 32 may have contributed to misclassification for individuals infected early in the pandemic. Lastly, many identified risk factors were highly correlated, making it difficult to separate out their unique effects.California's Salinas Valley; findings reported here further underscore the urgent need to intervene on modifiable risk factors such as increasing availability of isolation facilities to reduce exposure to COVID-19 cases at home and access to paid medical leave to avoid transmission in the workplace. Farmworkers speaking indigenous languages, who have very low levels of formal education, and who live in rural communities were at especially high risk of infection in our study, demonstrate disparities even within this very low-income and high-risk population. Efficacious vaccines have now been authorized and should be All rights reserved. No reuse allowed without permission.All rights reserved. No reuse allowed without permission.",Mexico,abstract,2021-02-03,02
b264712b44928d0163ea98d5664cb05212e985e8,SARS-CoV-2 disinfection in aqueous solution by UV 222 from a krypton chlorine excilamp 2 3 4 AUTHORS 5,"(mercury from breaking fragile quartz lamp bulbs is toxic 23 ), (2) the UV dose response 87 kinetics needed to inactivate SARS-CoV-2 are unknown. Should these two challenges 88 be overcome, the use of UV to inactivate SARS-CoV-2 in environments with high 89 potential for transmission (e.g. congregate care facilities, convalescent patient homes, 90 hospital waiting rooms, airplane cabins) would be a practical and readily deployed 91 engineering solution to augment current prophylactic measures (social distancing, face 92 masks, vaccines). Due to a surge in interest and application of UV in various public 93 settings, there is an urgent need to understand the dose response kinetics of SARS-94CoV-2 to UV radiation to inform decisions which balance the risk to eyes and skin from 95 Krypton and chlorine in KrCl excilamps are much less toxic than mercury, and KrCl 106 excilamps have already been shown to be competitive in terms of electrical efficiency 107 with mercury lamps that have many more years of product development and 108 optimization 30 . Our results demonstrate that when an aqueous solution of pathogenic 109 SARS-CoV-2 is exposed to UV222 light emitted by a Kr-Cl excilamp, its infectivity and 110 integrity is attenuated in a UV dose-dependent manner, as measured by culture and 111 molecular assays. These first UV222 disinfection dose responses demonstrate the 112 METHODS diffusing cosine corrector detector. Raw spectral data from the OceanView software 142 was interpolated to integer wavelengths using the FORECAST function in Microsoft 143Excel and relativized to peak emission at 222 nm for use in dose calculations (Figures 1  144 and S1). Total incident UV-C irradiance was measured using an International Light 145 Technologies (ILT) 2400 radiometer with a SED 220/U solar blind detector, W Quartz 146 wide eye diffuser for cosine correction, and peak irradiance response NIST-traceable 147 calibration. For irradiance measurement, the peak wavelength calibration value was 148 input manually as the radiometer factor. The incident irradiance was measured with the 149 detection plane of the radiometer centered at the height and location of the sample 150 surface during UV exposures, and corrected for several factors to determine the 151 average irradiance through the sample depth. Spatial nonuniformity of emission was 152 accounted for each test by measuring irradiance at 0.5 cm increments from the center 153 to the edge of the petri dish and relativized to determine a petri factor, which was 154 always > 0.9. The typical detector spectral response was obtained from ILT and used to 155 calculate the radiometer factor integrated over the lamp emission, which was 0.9971. 156As previously 34 , the reflection factor for water at the 222 nm peak wavelength was 157 assumed to be 0.9726. The divergence factor was determined each experiment day by 158 accounting for the distance between the lamp and the sample surface, and the sample 159 depth and was always > 0.9. The water factor was determined each sample day by the 160 ratio between the incident irradiance and the average irradiance integrated through the 161 sample depth after wavelength-specific absorption. The UV-vis absorbance of virus 162 working stocks (prepared fresh for each test) was measured in the biosafety cabinet 163 using a Nanodrop TM One C spectrophotometer via the microvolume pedestal for 164 wavelengths 200 -295 nm and the 1 cm quartz cuvette for wavelengths above 195 nm. 165Working stock absorbance spectra for each test are shown in Figures 1 and S1 . After 166 these adjustments to incident irradiance in the center of the sample, the average 167 irradiance was used to calculate exposure times (max: 15 minutes; min: 15 seconds) for 168 pre-determined UV doses (0-40 mJ/cm 2 ) (summarized in Supplementary Table S1). 169 All rights reserved. No reuse allowed without permission.All UV measurements, sample preparation, UV treatments, and subsequent handling of 179 treated samples were performed in a biosafety cabinet. On the day of each three 180 biologically independent tests while the UV source warmed up and measurements were 181 taken for dose calculations, aliquots of SARS-CoV-2 (previously tittered at 10 7 PFU/mL) 182 were diluted in cDMEM to make a ""working stock solution"" with a target titer of 10 5 183 All rights reserved. No reuse allowed without permission.Working stocks for untreated samples were placed on the stir plate for a representative 193 amount of time with the lamp off before transfer to centrifuge tube (0 mJ/cm 2 ). 194Graphs were prepared using either GraphPad Prism or Microsoft Excel programs; 290 statistical analyses (including regression using the data analysis add-in to determine 291 standard error of regression coefficients) were performed using these programs' 292 bundled software. Log10 Reduction (LR) was calculated as log10(No/N), where N was 293 viral PFU/mL in the plaque assay, N gene copies/µL in qPCR assays for either the short 294 N1 amplicon or the long N1-2 amplicon, or N protein concentration in pg//mL in the 295 ELISA assay after exposure to a given UV222 dose, and No was the initial concentration. 296The level of replication in this study was three biologically independent tests, with at 297 least technical duplicates for each assay. 298 All rights reserved. No reuse allowed without permission.300 Viral infectivity UV222 dose response was characterized by exponential decay kinetics 301 (Figure 2) . At a mean initial viral titer of 6.51x10 4 PFU/mL, the pseudo first order rate 302 constant for viral disinfection was -1.48 cm 2 /mJ (R 2 = 0.89). When expressed as LR of 303 viral infectivity after exposure to a given UV dose, the linear rate constant was 0.64 304 cm 2 /mJ (R 2 = 0.95), which equates to a D90 (dose for 1 log10 or 90% inactivation) = 1.6 305 mJ/cm 2 . Doses ranges and initial Vero cell confluence were only sufficient in the Test 3 306 experimental replicate to quantify a dose response. However, in Test 2, the mean initial 307 viral titer of 3.54x10 4 PFU/mL in untreated samples was reduced to below detection by 308 the first dose tested of 10 mJ/cm 2 , equivalent to a LR of at least 4.25 logs. These 309 results were also consistent with qualitative results from Test 1, where Vero cells 310 appeared mostly dead in the untreated samples, appeared increasingly healthy through 311 doses 0.7 and 1.4 mJ/cm 2 , and appeared healthy at doses above 2 mJ/cm 2 . 312 313 All rights reserved. No reuse allowed without permission.",USA,first author,2021-02-23,02
795126d6ae7138baa992c6dd70462ff983b6c49e,0123456789) 1 3 Journal of Community Health,"The outbreak and community transmission of COVID-19 in the United States (U.S.) in March and April of 2020 impacted many, including U.S. institutions of higher education (IHEs). The New York City (NYC) metropolitan area, defined as a geographic area encompassing counties in close proximity to NYC [1] , was among the hardest hit areas in the country, forcing IHEs to close campuses, transition to online instruction and send residential students home for the remainder of the Spring 2020 semester [2] . In the late spring and early summer of 2020, as new infections were declining, attention shifted to how to safely re-open IHEs for the fall semester. Given the importance of higher education, ensuring the continuation of research, and the contribution of IHEs to local and state economies, reopening plans became a priority for school administrators. While the majority of IHE students are not at high risk of severe morbidity or mortality due to COVID-19, experts recognized that outbreaks among college students could put faculty and staff at risk, as well as vulnerable members of surrounding communities [3] . Recommendations for IHEs provided by the U.S. Centers for Disease Control and Prevention (CDC) suggest a tiered approach to risk reduction [4] . Among measures aimed at reducing the spread of COVID-19, the CDC recommended testing of ""students, faculty, and staff for purposes of surveillance, diagnosis, screening, or in the context of an outbreak,"" and discussed the likelihood of off-campus transmission. CDC recommendations were meant to supplement local, state or federal rules and regulations for IHEs, and implemented in collaboration between IHE administrators and state and local health officials [4] New York (NY), New Jersey (NJ), and Connecticut (CT), developed guidance for Fall 2020 IHE reopening, which varied in scope and stringency [5] . Of the three, CT's guidelines called for the most comprehensive COVID-19 testing strategies, recommending that residential campuses conduct arrival testing and symptomatic and ongoing surveillance testing. Non-residential campuses were only required to plan for symptomatic testing for students, faculty, and staff [3] . NJ's restart guidance mandated that IHEs establish COVID-19 testing plans, yet the specifics were left to individual institutions [6] . NY's IHEs reopening guidelines listed mandatory and recommended best practices (i.e., arrival and ongoing systems for testing on campus). However, no surveillance testing was required [7] . Yet, it was clear during the summer of 2020 that many IHEs would face barriers implementing comprehensive testing strategies. These included cost, logistics, limited testing supplies, and inadequate laboratory capacity [8, 9] These barriers could have been particularly significant for smaller colleges, and colleges under financial strain.Another aspect of an IHE's testing strategy is its health communication plan about testing (e.g., its importance, the logistics, and the results). Gaining compliance with public health measures like testing on campus is likely to be improved by well thought out health communications regarding transmission dynamics and the importance of testing. This issue is particularly important for college-aged students who, while at lower risk of adverse outcomes of COVID-19, may benefit from messaging about their important role in preventing transmission and protecting others [10] . The CDC recommendations emphasize the importance of ""providing information on the process of case investigation and contact tracing to students, faculty, and staff [4] ."" Although the NY and NJ guidance acknowledged the importance of an IHE's communication plan, none of the three state guidance documents make specific best-practice recommendations for IHEs to follow. In the absence of clear guidelines, it is unknown to what extent the IHEs developed and implemented communication plans to their students and staff regarding testing, including whether adequate and accurate information on COVID-19 surveillance and testing is present on their websites. There is a dearth of published literature related to COVID-19 communications by the IHEs. Therefore, the purpose of this study was to describe information on websites of IHEs in the NYC metropolitan area related to IHE COVID-19 testing plans and results.This cross-sectional study took place over the Fall 2020 semester and included IHEs in the New York City (NYC) metropolitan area. All IHEs in New York (NY), New Jersey (NJ), and Connecticut (CT) were identified using College Navigator, a search tool of The National Center for Education Statistics (NCES), part of the U.S. Department of Education [11] . The sample was further refined to include only IHEs in the counties defined by the NYC metropolitan area (NYC planning). Inclusion criteria hinged upon the colleges and universities having an operational website. Undergraduate and graduate student enrollment data for each school was identified using the data provided on the institution's website, and when this information was not available, it was garnered from the College Navigator tool. Based on enrollment information, institutions were categorized into small-(≤ 5000 students), medium-(5001-10,000) and large-(> 10,000) sized institutions. We also noted whether institutions were public or private.After determining if the Fall 2020 semester classes were held in person in some capacity (i.e., hybrid) or fully online, colleges' and universities' websites were coded for the presence of content related to COVID-19 testing. Content categories included the following: general information on COVID-19, information on reasons for testing, statements on urgency of testing if exposed or symptomatic, information on COVID-19 testing on and/or off campus, information on surveillance testing conducted by individual schools, information on how to make an appointment for COVID-19 testing, whether website included information on free testing, if social media was used to promote testing, and whether colleges reported their testing data to campus community. All content categories were coded dichotomously (0 = information absent, 1 = information present). We also collected information on whether institutions reported testing data to the campus community (0 = no, 1 = yes), whether they reported positive COVID-19 cases (0 = no, 1 = yes), the positive case count, and the frequency of the dashboard updates on COVID-19 cases as obtained (0 = weekly, 1 = biweekly). Finally, we noted the time (in minutes) spent to navigate college websites looking for COVID-19 information. All data analysis was completed using SPSS 26.0 [12] . The Institutional Review Board at William Paterson University does not review studies devoid of animals or human subjects.We identified 150 community colleges and universities in the NYC metropolitan area (Table 1) . Slightly over half (50.7%) of the sample were small colleges with an average enrollment of 1988 students (range 55-4875). Medium size colleges with an average enrollment of 7245 students (range 5027-9916) accounted for 24.6%, while large colleges with an average enrollment of 18,197 students (range 10,105-63,778) accounted for 24.7% of the sample. Overall, the majority of institutions were private (58%), with small colleges more likely to be private, while medium and large schools were more likely to be public institutions (χ 2 (2) = 31.3, P < 0.001). Only about 10% of colleges were fully online during the Fall 2020 semester. Almost two-thirds (64.7%) of the sampled colleges were located in NY state, while one quarter (24.7%) were in NJ, and 10.7% in CT. NY had a larger proportion of smalland large-sized colleges, while medium-sized colleges were more evenly distributed between three states. Table 1 also presents the analysis of the COVID-19 testing information provided by colleges on their websites. Chi-square analyses were conducted to explore differences between small, medium and large colleges for each of the content categories. Statistically significant differences were observed in regard to the provision of information on how to make an appointment for COVID-19 testing (χ 2 (2) = 8.1, P < 0.05), and information on free testing (χ 2 (2) = 7.0, P < 0.05) with larger institutions more likely to provide this information than smaller institutions. A total of 124 (82.7%) of institutions reported testing data to the campus community, with the majority of providing this data biweekly (62.9%). Interestingly, among three states, NY has a centralized IHE dashboard of COVID-19 cases. Schools in NY were more likely to to report testing data to their community than schools in CT and NJ (χ 2 (2) = 33.5, P < 0.001). Approximately half (48.5%) of NY schools provided information on the number of COVID-cases directly on their websites, while 47.4% reported this information primarily through the centralized IHE dashboard. Of 124 institutions reporting testing data to the campus community, 116 recorded at least one positive COVID-19 case among their students or staff. The Kruskal-Wallis test indicated significant differences in the number of reported COVID-19 cases (P < 0.001) as related to college size, with the smaller-sized institutions reporting a significantly lower number of cases than medium-(P < 0.001) and large-sized (P = 0.003) institutions, adjusted for multiple comparisons.Interestingly, all institutions that offered surveillance testing to their students and staff reported information on the number of positive cases to their community compared to 65% of those who did not offer surveillance testing (χ 2 (2) = 12.0, P = 0.001). Institutions offering surveillance testing reported a higher number of COVID-19 cases (N = 43, mean = 86) than those who did not (N = 79, mean = 48). A Mann-Whitney test indicated that this difference was statistically significant (U = 652.5, z = − 5.61, P < 0.001). Comparing three states, schools in CT (57.1%) were more likely to conduct surveillance testing than NY (25.8%) and NJ (28.6%) schools (χ 2 (2) = 5.8, P = 0.05). No statistically significant difference in the time taken to collect information between different college sizes was observed.With decisions to reopen campuses in the Fall semester of 2020 (90% of IHEs in our sample opted for some form of inperson learning), IHEs were additionally confronted with the task of controlling infections among students, faculty, and staff. While school administrators relied on rules and guidance from the Centers for Disease Control and Prevention (CDC), state governors and state and local health officials, the lack of consensus on the best practices for reopening campuses, including how to proceed with testing, or provide information on testing to students and staff, represented a significant obstacle to reopening efforts.The findings from this study reveal that in the absence of regulations and consistent guidance, IHEs information on COVID-19 testing procedures and reporting on COVID-19 cases varied despite the proximal geographic nature of the IHEs. The lack of an agreed upon approach to COVID-19 testing and communication at IHEs has been previously documented [13] . Because asymptomatic and pre-symptomatic carriers may be responsible for half or more of all COVID-19 transmission [14] , robust and frequent COVID-19 testing is critical for controlling outbreaks on campuses [15] [16] [17] . Ideally, campus testing plans would include entrance testing [18] , symptomatic testing, testing close contacts of symptomatic individuals, and surveillance testing to identify asymptomatic or pre-symptomatic cases [19] . In our sample, CT colleges were more likely to conduct surveillance testing, which was consistent with the state guidelines. However, given lack of logistical capacity for expanded testing and financial strain faced by many colleges this may have not been feasible for many IHEs, particularly for the smaller ones.In our sample, 116 institutions (77%) reported at least one positive COVID-19 case among their students or staff, with the smaller-sized institutions reporting a significantly lower number of cases than medium-, and large-sized institutions. While the typical population of college students is not considered to be in the highest risk category for developing severe illness, increases in COVID-19 cases occurred rapidly in the Fall. A New York Times report identified a dramatic increase in the number of COVID-189 cases. After fall reopening: ""more than 26, 000 COVID-19 cases at more than 750 colleges across the nation by August 26, and more than 130, 000 cases at 1,300 colleges by September 25"" [20] . The increase was particularly dramatic in counties where college students comprised at least 10% of the county population [21] IHEs do not function in isolation, they are an integral part of communities and the connection between outbreaks on campus and deaths in the community cannot be overlooked [21] [22] [23] Various planning strategies for IHEs also recommended developing information-sharing systems in relation to COVID-19. The CDC recommended that ""institutional information systems can be used for day-to-day reporting on number of cases and information, such as absenteeism or changes in student and staff health center traffic to detect and respond to an outbreak"" [4] . IHEs were encouraged to develop and maintain effective communication with diverse campus constituencies, including students with limited English proficiency and those with disabilities [4] In the NYC metropolitan area, larger institutions were more likely to provide students and staff information on how to make an appointment for COVID-19 testing, including information on free testing. Furthermore, NY schools were more likely to report testing data to their community than schools in CT and NJ. It is important to note that NY state recommendations for IHEs included reporting the cases to the state centralized IHE dashboard.The lack of consistency on COVID-19 information, including reporting of cases on college campuses, shows there is room for improvement. IHEs should develop comprehensive communication strategies related to COVID-19 testing accessible not only by students, but for community members as well. Specifically, IHEs should aim for transparency in COVID-19 communications as IHEs practices and procedures influence the immediate campus community as well as the community at large. Further, health education related to COVID-19 testing is an essential component in understanding asymptomatic spread and why reducing incidence among college students is important. A goal in providing information on IHEs websites should be to minimize search time. Although we did not measure the location of information within webpages, homepage information listings will minimize search time, average length of time searching for this information was substantial. IHEs should provide easily accessible and comprehensive dashboards. Services are available to aid IHEs in the type of information that should be made available to the public [24] . IHEs should go beyond administrator input in planning campus health communications. Students, faculty, staff as well as stakeholders in the geographic community should also be included [10] . Information must be communicated with attention to varying levels of health literacy among US college students [25] and with the knowledge that students may be exposed to significant misinformation on social media and elsewhere [26] .This study has limitations that warrant mention. As with all cross-sectional studies, the results are not generalizable. By virtue of collecting data at a single point of time, this data does not reflect changes in information over time. The focus of the study was to document what information was identified on IHEs websites, but it is possible that information was present in some capacity, was delivered in an alternative way, or was encrypted, but was not readily identified using the methods deployed. Further, the sample size was relatively small, representing a fixed geographic area. While this area is highly populated and was a pandemic epicenter at the beginning of the pandemic, further study with larger samples is justified.Despite these limitations, this research fills a gap in literature and can serve as a springboard for further inquiry. Inconsistent and inadequate delivery of information related to pandemic by IHEs, particularly when they are geographically close, may further contribute to the lack of awareness and confusion, as well as the inability to make informed health decisions, including decisions on when and where to get tested. IHEs websites are an obvious place to house and update information related to COVID-19. Doing so in a consistent, timely, transparent, and comprehensive way may significantly contribute in efforts to curb community transmission.Author Contributions CB and MS conceptualized the study. NQ collected the data. AK conducted the data analysis. All authors contributed to the manuscript production.Funding None.",United States,abstract,2021-02-10,02
dd430044cdce629978720ca73fa95b433cc6e400,Nasopharyngeal SARS-CoV-2 viral loads in young children do not differ significantly from those in older children and adults,"Children remain underrepresented in current studies aimed to analyze the spread of SARS-CoV-2 coronavirus, making their contribution to viral transmission elusive. It is well established that, in general, children experience less severe illness than do adults, though in rare cases children can be subject to a severe multisystem inflammatory syndrome 1 . And there is an emerging view that children may play a lesser role in the spread of SARS-CoV-2 than they do in other respiratory pathogens 2 , but much uncertainty about this remains 3 . Recently, it was reported that children less than five years old may carry higher viral loads in the nasopharynx than older children and adults 4 , raising concerns that exposure to this group may pose special epidemiologic risks. Here we report results bearing on this question from two coronavirus testing laboratories that serve large populations of patients in California.By providing widely available, free SARS-CoV-2 testing to the community, a total of 5,544 patients with laboratory-confirmed COVID-19 were identified. Laboratory A and B identified 4,619 and 925 patients. The population in Laboratory A was slightly younger than that of Laboratory B by mean and median ( Table 1) . Cases of COVID-19 were analyzed using three age categories, young children aged less than five years (n = 199), children aged five to 17 (n = 665), adults aged and older (n = 4680), were identified. Table 1 denotes baseline characteristics of laboratory-confirmed COVID-19 study participants by laboratory. Statistically significant differences between the population of Laboratory A and B include mean age, 36.5 and 42.4, respectively, as well as percentage of hospitalized cases, 4.4% and 24.4%, respectively.Symptom status on testing was available at Laboratory B. Patients meeting Laboratory B symptom definition were defined as symptomatic (Supplemental Table 1A ). Day of symptom onset for Laboratory B and symptom status for Laboratory A was unavailable. Age-specific stratification of hospitalization and symptom status by location can be found in Supplementary Table 1B. In order to ascertain potential differences in viral load, Ct values were assessed. As depicted in Fig. 1 , despite differences in the population represented by Laboratory A and B, no significant differences in Ct value were observed across the three age groups. In particular, the children less www.nature.com/scientificreports/ than age 5 did not display higher nasopharyngeal viral loads than older children or adults. No differences across age groups were found when comparing viral loads for Laboratory A cases (Supplemental Fig. 1A) , conversion of Ct values to viral loads were not available for Laboratory B cases. Furthermore, Ct values did not differ significantly between hospitalized and non-hospitalized cases across both laboratories (Supplemental Fig. 1B and C). Comparison of Ct values across symptom status for Laboratory B cases yielded a statistically significant difference between young children aged less than five and adults of 18 years of age and older (Supplemental Fig. 1D ). However, this difference is not considered clinically significant as the number of cases of asymptomatic young children was too low for appropriate comparison (age less than five n = 3, age 18 and older n = 193).In contrast to a prior smaller study of 145 individuals 4 , our study of 5,544 children and adults did not demonstrate higher nasopharyngeal viral loads in children under five years of age. Notably, a significant proportion of Laboratory B outpatient cases were asymptomatic, underscoring the importance of broad community testing strategies. No clinically significant differences in Ct value or viral load were noted across age groups upon comparison of hospitalization status or symptom status. Differences in Ct values among asymptomatic children and adult cases in Laboratory B are not deemed clinically significant as there were only three asymptomatic children in that cohort. One limitation of this study is the lack of symptom status for outpatient cases of Laboratory A. A recent outpatient study supported by Laboratory A with a comparable demographic identified that 52% of patients were www.nature.com/scientificreports/ asymptomatic at the time of testing, which may provide a reasonable estimate for the cases originating from Laboratory A 5 . Our work largely presents outpatient cases and is relevant to the majority of pediatric COVID-19 cases but possibly not to the subset of children hospitalized with severe disease. There are conflicting data on the association of viral load with disease severity, with some studies showing higher viral loads in severe cases 6 , while others indicate a lower viral load in hospitalized patients than those not hospitalized 7 . Since the viral load changes rapidly during early infection, the time between symptom onset and sampling is a significant variable. Some patients with severe disease may delay entry to care, missing the peak period of viral shedding. Notably, these earlier studies were done primarily in the hospital setting, so the findings do not necessarily translate to the outpatient population. While the presented work offers a large predominantly outpatient population, it is limited by an inability to compare time between sampling, symptom onset, and symptom severity, which remain significant variables. We believe this limitation does not take away from the overall conclusion due to the robust sample size of largely asymptomatic or mildly symptomatic individuals, making this work likely to be representative of the general population of infected subjects. Sampling bias can also compromise the generalizability of the obtained results, such as testing availability and cost to testing. However, testing was made widely available to the general population at no cost. Patients were allowed to self-present at will, or secondary to symptoms or due to contact tracing. Given the low barrier and wide availability to testing, we further regard these data to likely be applicable to the general population. An accurate understanding of the variables that affect viral transmission, including amount of virus carriage, will be essential to guide public policy efforts as re-opening strategies are devised.We caution, however, that viral load as determined by RT-PCR is only one of many potential influences on infectivity. PCR accurately enumerates viral genomes, but does not indicate whether they come from infectious virions, defective viral particles, or lysed infected cells. Infectivity in populations is affected by many other clinical, behavioral and environmental factors. Our findings argue against the idea that young children are more infectious due to higher viral loads, and suggest an alternative explanation for their contribution to SARS-CoV-2 transmission, such as representing a reservoir of asymptomatic infections. Ultimately, future epidemiological studies are needed to understand the role of children in the spread of SARS-CoV-2.Ethical considerations. All research was performed in accordance to UC San Francisco good clinical practice guidelines. The protocol was approved by UC San Francisco research committee. All data were anonymized and de-identified before analyses. The UC San Francisco Institutional Review Board provided an exemption and waiver of HIPAA authorization and informed consent.Sample collection and processing. Testing was carried out in two laboratories from March-August 2020. Laboratory A serves the University of California (UC) San Francisco health care system, local clinics and county health departments in 26 California counties. Laboratory B serves the UC Davis health care system and partner clinics/hospitals centered in Sacramento, CA. Testing was made available to the general population at no cost. Patients were encouraged to self-present for symptoms, as part of contact tracing, or at will. Nasopharyngeal swabs were collected at various outpatient, drive-through, inpatient, and emergency department testing sites. Laboratory A swabs were collected in DNA/RNA Shield (Zymo Research) to inactivate virus and preserve RNA stability. Laboratory B collected specimens into 3 mL Becton, Dickinson and Company (Franklin Laes, NJ)/Copan (Murrieta, CA) Universal Transport Medium (UTM) or Remel Viral Transport Medium (VTM) (San Diego, CA). Real RT-PCR used NEB Luna Universal RT-qPCR kit (New England Biolabs, Ipswitch MA) on Bio-Rad CFX384 instruments (Bio-Rad, Hercules, CA) in Laboratory A; and Roche cobas 6800 (Roche Diagnostics, Indianapolis, IN) using the EUA SARS-CoV-2 assay in Laboratory B. Each real-time RT-PCR assay provided a threshold cycle (Ct) value, indicating the number of cycles surpassing the threshold for a positive test. Samples were considered positive if the Ct value was ≤ 40, and otherwise it was negative. Viral loads for Laboratory A cases were converted using a viral load standard curve created on the establishment of CLIA-certified Laboratory A. Statistical significance was calculated using ANOVA, Student t-tests, or Fisher's exact test. P values less than 0.05 were considered significant. Statistical analysis used R ggpubr v.0.4.0. ",USA,first author,2021-02-04,02
e6002754c62f50bc9c9676d20f9b2d403ed97e3b,Glucocorticoid use in patients with adrenal insufficiency following administration of the COVID-19 vaccine: a pituitary society statement,"Availability of vaccines is a giant step in combating the coronavirus disease 2019 (COVID-19) pandemic. Side effects of the Pfizer-BioNTech and Moderna vaccines include up to several days of pain at the injection site, fatigue, headache, myalgias, arthralgias, chills, and fever [1, 2] . These signs and symptoms can be early indicators of an increased need for glucocorticoid replacement in patients with adrenal insufficiency [3, 4] . Other than a case report of adrenal crisis in a patient with Addison's disease following routine administration of influenza, Tdap, and pneumococcal vaccines [5] , there is no information on routine management of primary or secondary adrenal insufficiency following administration of these vaccines, and we do not yet know the potential impact of glucocorticoids on immune response to the vaccine.The Pituitary Society surveyed its membership to understand planned approaches to glucocorticoid management in patients with adrenal insufficiency who will receive a COVID-19 vaccine with a goal of using survey results to inform the larger community of suggested best practices.Surveys were developed using SurveyMonkey (San Mateo, CA) with branch logic. Members were asked to complete up to 3 questions regarding their planned approach for use of glucocorticoid replacement in patients with proven adrenal insufficiency ( Table 1 ). The survey was closed after 3 days and results were collected and analyzed.Surveys were sent to 273 members and 103 responded (38% response rate). As shown in Fig. 1 , 36% (37/103) plan to recommend that patients automatically increase their glucocorticoid dosage with administration of the first vaccine injection. Of these, 84% (31/37) plan to increase glucocorticoid dose on the day of vaccination, and 49% (18/37) plan to increase glucocorticoid dose prior to vaccination.By contrast, 64% (66/103) do not plan to recommend an automatic glucocorticoid dose increase with vaccine administration. Of these, 88% (58/66) plan to increase the dose if the patient develops a fever following administration, and 47% (31/66) plan to increase the dose if myalgias and arthralgias occur.Thus, most clinicians plan to maintain the current glucocorticoid dose with vaccine administration. The vast majority of these clinicians plan to increase glucocorticoid dose with fever, and just under half plan to increase the dose with associated arthralgias and myalgias, known vaccine side effects.These survey results offer a glimpse into the planned approach of our members for glucocorticoid management in patients with adrenal insufficiency. This survey does not reflect results of a trial on efficacy of glucocorticoid management in patients receiving the vaccine nor the impact of a particular glucocorticoid dose on the vaccine immune response. Importantly, these results do offer suggested management guidance based on responses from experienced clinicians treating pituitary diseases. If the answer to question 1 was YES, will you recommend raising the glucocorticoid dose prior to the vaccination? If yes, go to question 3 If no, go to question 3 Question 3If the answer to question 1 was YES, will you recommend raising the dose on the day of the vaccination? If yes, end questionnaire If no, end questionnaire Question 4If the answer to question 1 was NO, will you recommend that the patient increase the glucocorticoid dose for fever? If yes, go to question 5 If no, go to question 5 Question 5If the answer to question 1 was NO, will you recommend that the patient increase the glucocorticoid dose for muscle and joint pains? If yes, end questionnaire If no, end questionnaire Do you plan to recommend that your patient automatically increase the glucocorticoid dosage?When will you recommend raising the glucocorticoid dose prior to the vaccination?When will you recommend that the patient increase the glucocorticoid dose? ",USA,first author,2021-02-10,02
00b8446716d3959329dbe81227a4d7151ed43748,Using Spirituality to Cope with COVID-19: the Experiences of African American Breast Cancer Survivors,"Among women diagnosed with breast cancer, racial disparities persist and are especially evident among African American women [1] . African American women diagnosed with breast cancer continue to have the highest mortality rates as well as the second highest incidence rates [1] . In fact, the cancer death rate for non-Hispanic African American women is 41% higher than non-Hispanic white women. Although the mortality rates for breast cancer have been declining, a racial disparity persists for African American women [1] . Financial difficulties, lack of provider sensitivity, and an absence of family support are among those major patient concerns that contribute to this racial disparity in breast cancer. African American women with breast cancer are now faced with being in the category of individuals at a higher risk of contracting and dying from COVID-19 [2, 3] . In comparison to other racial/ethnic groups, African Americans are nearly four times as likely to die from COVID-19 [2] . In addition, comorbidities such as heart disease, asthma, obesity, and diabetes are prevalent among African American breast cancer patients so that if COVID-19 is contracted, the outcome is likely to result in death [4, 5] .African American women generally rely on their spirituality to cope with psychosocial issues encountered during cancer survivorship [6, 7] . However in order to mitigate the risk of contracting this potentially deadly disease, it is imperative that community-dwelling older adults physically distance themselves from family, friends, and even traditional faithbased activities [8] . For many African Americans, access to social support and religious services at faith-based institutions is a challenge; therefore, this population is likely to experience higher levels of social isolation, loneliness, and psychological distress [9] [10] [11] [12] . This pandemic in particular is associated with higher levels of hopelessness, loneliness, and depression that is highest among women, individuals with the lowest household incomes, individuals with existing chronic conditions, [13] and older women who live alone [14] . Loneliness in particular is likely to result in higher levels of psychological distress [15] [16] [17] which is especially evident in research among older African American adults where loneliness was associated with high levels of perceived stress and poor mental health [12] .African Americans have a long cultural history of using their spirituality for purposes of keeping the memories of ancestors alive and for the intergenerational transmission of important survival strategies [18] [19] [20] . Older African Americans in particular were more likely to transmit stories of ""making it through"" times of oppression and serious illness that incorporate their strong religious culture [18] [19] [20] . Historically, the use of religious songs and Bible verses as expressions of spirituality were memorized and transmitted orally as a strategy that has given African Americans meaning to their human existence [21] . Biblical text and lyrics of religious songs, for example, were used frequently among African slaves to provide insight into their belief systems as well as their connectedness to God and to other individuals who were suffering and powerless [18] [19] [20] . Moreover, among African Americans, Biblical text was a source for stories that allowed transcendence from a current situation of suffering to some other place or time. A reliance on spirituality further helped African Americans to view the relief of pain and sorrow of other faithful servants as evidence of God's ability to protect, strengthen, and heal [18, 22] .In this report, we draw from the narratives of older African American breast cancer survivors for an exploration of the ways in which spirituality is used to cope during this COVID-19 pandemic. The findings from these interviews will permit a glimpse into the use of spirituality to cope, whether participants have adapted this strategy to be relevant during this time, and benefits of this coping strategy during this pandemic.In this report, we used a qualitative descriptive design including purposive sampling, open-ended semi-structured interviews, qualitative content analysis, and quantitative descriptive analysis. Approval for this study was obtained from the Institutional Review Board of Emory University.The interviews included in this report are from 18 African American women and breast cancer survivors residing in the Southeastern United States, African American ethnicity by self-report, at least 18 years old but less than 89 years, and survivors of cancer. Participants for these interviews were generally recruited through an African American breast cancer support group with whom the fourth author of this report is founding member.The first author conducted semi-structured interviews lasting 15-45 min. Participants were interviewed via phone and video conferencing platform and asked to respond to questions of strategies used to manage stressors encountered during this COVID-19 pandemic. Participants were given a $30 gift card for each interview. All interviews were conducted in April and May of 2020.All interviews were conducted with only interviewee and first author present. Participants were encouraged to freely express issues and experiences related to spirituality. Interviews were audiotaped and later transcribed verbatim with a research assistant reviewing each transcript for accuracy. Member checking was conducted with members of the target population and clergy during the process of data collection and drafting of this report to validate the interpretation of findings, generation of themes, and accuracy of conclusions.In order to content analyze the data, a table was initially constructed to organize each participant's responses by category of text related to spirituality as expressed among these participants' narrative responses. These spiritually grounded responses included religious practices associated with faith-based institutions as well as meanings derived from beliefs associated with these practices.The interviews included in this report are from 18 older African American cancer survivors residing in the Southeastern United States (see Table 1 ). The participants were on average 58 years old with stage 0-2 breast cancer (88.9%); married (38.9%); college educated (44.4%); employed full time (55.6%); and resided in rural areas (67%).In the paragraphs to follow, we describe with participant quotes, the perspectives of the ways in which spirituality is used to cope with the COVID-19 pandemic among African American women breast cancer survivors. Specifically, the ways in which spirituality enables African American breast cancer survivors to better manage their psychological distress were through (1) increased engagement in religious activities; (2) reliance on God for protection when fearful, feeling isolated, and in need of assistance to pay household bills; (3) finding joy and courage from listening to gospel music and reading scripture; and (4) finding meaning through spirituality. To date only a few scholars have examined the ways in which spirituality is a coping resource among African American breast cancer survivors during the COVID-19 pandemic. Participants have been provided fictitious names to protect their identity.In this category, participants described ways in which they increased participation in religious activities to cope with the COVID-19 pandemic. Ms. Morrison is a 61-year-old, stage 2, four-year survivor of breast cancer. She described the changes made in her attendance at worship services during the COVID-19 pandemic:But we actually do a lot over the phone. But I've been watching other -I'm on Facebook so I have friends that are ministers so I've been watching their Facebook live. So like I told my friend yesterday I've been in church all day because everybody came on at different times. And even if they didn't come on at different times they're still on there so you can be able to go back and listen to them.She also described the increased religious service participation she has observed in others:But I think you know, more people are going, you know, to Christ now because everything is unpredictable or they don't know what's really going on so they have to go to God to understand.Another participant, Mrs. Sherill, a 59-year-old, stage 0 (DCIS), seven-year survivor of breast cancer had this to say about the change in the religious practice of prayer to cope during the COVID-19 pandemic:Prayer is more prevalent in my life now because of COVID than it had been before. I think I just find myself just thanking the Lord throughout the day just for being able to have a job. Reliance on God for Protection When Fearful, Feeling Isolated, and in Need of Money to Pay Bills In this category, participants described a reliance on God to cope with fear, social isolation, and to provide for food and shelter during the COVID-19 pandemic. A 72-year-old, stage 3, 19-year survivor of breast cancer described her religious belief in God's ability to protect:He is going to protect us through this. And not only that, I said, ""Okay, it could be His doing that's not to harm us, but we have gotten so, busy, busy, busy in this life, in this world,"" it's like, ""Okay, rest for a minute; just take a breath; just rest; rest in my Word; rest in me. I just had a moment to where it's almost like fear tried to grip my heart. But I had to go inside and rely on what I knew to be true concerning the word of God. And for a moment there you know that's what I had to do. Well when you are a believer you're just that. You come to believe that even though you are here in this world you believe that God is greater than what you see around you. He's able Mrs. Dillingham is a 62-year-old, stage 2, two-year survivor of breast cancer. In her narrative, she describes feeling down as a result of not being able to socialize and embrace family and friends. However, talking to God and family by phone and social media has helped to alleviate those depressed moods:My communication is not as prevalent as it was and that kind of gets me down sometimes because of this. Not able to go out and socialize. They do call and check on me and see how I'm doing. But I'm a hugger. I like to hug and I like to socialize. That has been taken. It's one thing if you don't go out because it's your choice. It's another thing when you don't have a choice or say in the matter. It kind of gets me down sometimes. And I've had some little emotional bouts in my home being by myself. I talk to God a lot. I have to, you know? That keeps me going. I talk to my family every day. We're on the phone every day. We can even do video chats and it's so nice. On Saturday Sisters Network got together and we did a Zoom.A reliance on God for money to pay household bills was a coping strategy for Mrs. Smith, a 48-year-old, stage 2, eightyear survivor of breast cancer. Her experience, like many other African Americans, included the loss of income and ability to buy food and pay household bills including those for utilities and car note. Mrs. Smith recalled her experience and a reliance on her faith in God:My faith is keeping me grounded. Because I know all of us that believe in the power of God we're grounded so my faith has kept me grounded and kept me sane while going through this. I'm actually one whose job had to shut down due to the virus and I am not receiving unemployment. I had actually put in my unemployment back in February before everything started shutting down and my stuff is still pending. So through the grace of God my mortgage is current. My car note is not due until May. They went ahead and set up a few of my payments at the end of the loan. And I thank God that the utility company, you know, putting a freeze on the disconnections. But I know as time goes on, you know, the bills are going to add up. And I'm just thankful that I have people that are in my corner that I can go to anytime that I'm in need. So there's food and everything -I'm good. My faith is carrying me through.Finding Joy and Courage from Listening to Gospel Music and Scripture In response to the stress of the COVID-19 pandemic, participants were able to find joy and peace in a favorite religious song or Biblical text. Mrs. Smith referred to Isaiah 4:10 as the scripture that gets her through stressful times:But I know that what I relied on as far as faith and prayer but I relied on Isaiah 4 verse 10 which was the one that got me through. And I was listening to this song that my sister sings. It's called Faith Is. Because the song says faith is my hope in you. Faith is my trust in you and it also says I'm an overcomer. And that's how I see myself. I'm more than a conqueror and I'm an overcomer. And so whenever I feel a little down I'll go to that song and then I'll go to that scripture.Ms. West is a 59-year-old, stage 2, two-year survivor of breast cancer who finds joy in singing to relieve stress during the COVID-19 pandemic. She especially finds joy in singing songs that are reassuring and positive. Ms. West describes the joy from hearing religious songs from an Easter Service:Like you said singing is a joy for me because I sing on the choir. Singing is a joy for me. That makes me feel good. When I sing positive songs and reassuring songs, that's a joy for me. Listening to gospel music. Like somebody sent a tape through an Email and they said we've been apart and we've had... because of this situation but they wanted to send a reminder of songs we sang last year. They sent a recording of the songs we sang last Easter and it was so uplifting just to hear it. You know what I'm saying? So things like that you know I have to focus on that.Ms. Russell is a 50-year-old, stage 1, eight-year survivor of breast cancer who described a specific Biblical text used to overcome her fears of being in the COVID-19 pandemic. This breast cancer survivor recalled previous environmental threats such as the Spanish Flu and Smallpox and other plagues referenced in the Holy Bible. According to Ms. Russell:It's happened many years whether it's the Spanish flu, whether it's smallpox. There's different things that come throughout the world that happens and it's just our time to go through it. My main and probably only Bible verse that I read constantly and still to this day is 2Timothy 1:7. That God hasn't given you the spirit of fear that's how I got through those fearful, fearful, times where I just knew over and over again that, you know. . . .For God has not given us the spirit of fear but of power and of love and of sound mind. That was and still is my go-to verse. Of course I read other verses too but that's the main one I hold close to my heart. When I'm fearful. When I'm scared. When I'm worried. When I'm a little anxious about anything. When I'm doubting something.Finding Meaning Through Spirituality The ability to find purpose and meaning through one's spirituality was expressed among these African American breast cancer survivors. Mrs. Dillingham, a 62-year-old, stage 2, two-year survivor of breast cancer, shared her perceptions of finding purpose and meaning via her spirituality. For Mrs. Dillingham, the COVID-19 pandemic was a time to refocus: God gave us this time off to do self-reflection. Look inside ourselves and see if we know where we're at, you know? And coming out of this how we're going to be better. What are you going to do differently?For other survivors, comfort was found in Biblical text with references to God's ability to bring His children through pandemics. Mrs. Winston, a 49-year-old, stage 2 two-year survivor of breast cancer described the Biblical story of Noah and the Ark. Adhering to the mandates for sheltering in place was similar to the Biblical story Noah staying in the Ark until it was safe to come out after the flood: I think biblical you know you're bringing up the plagues. Thinking back in that time, thinking about Noah and the ark. How when the flood came he and his family they had to go in and stay until it was time to come out so relating it to that.The goal of this report was to explore the ways in which African American cancer survivors use their spirituality to cope during the COVID-19 pandemic. We purposively used the narratives of African American women who are breast cancer survivors for this exploration as they are a high-risk group for poor outcomes should they contract this potentially deadly virus.The analysis of the narratives of these African American survivors of breast cancer illustrates that there are at least four responses to the stress encountered during the COVID-19 pandemic. For example, one response was through an increased engagement in religious activities. Although these women were restricted from attending church activities in person, they found on-line services that permitted them to actually engage in more worship services than previously when there were no COVID-19 restrictions. This finding is consistent with other reports of African Americans adapting to their needs for spiritual support via churches through on-line and social media formats during this pandemic [23] . However, since not all churches have resources for an on-line format, benefits such as fellowship with congregants and support and encouragement from this interaction are missing [24] . Although the response of increased religious activities during stressful life events is not novel, the benefit from the availability of worship services from local churches through social media during extended periods isolation even after the pandemic ends should be further explored.A second type of increased engagement in religious activities included prayer. A realization among these participants was that the threat and potential harm from this pandemic was larger and more powerful than any other and one only God could alleviate [25] . This response of relying on God to cope with fear, social isolation, and to provide for food and shelter during the COVID-19 pandemic brings to our attention to a function of spirituality not emphasized in literature during this pandemic. The closure of churches and requirements for physical distancing has led to feelings of social isolation and loneliness that has been stressful for many African Americans [23] . An increasing reliance on connectedness through phone and social media fills the void for social interactions for some but not all. The findings from previous research suggest that a lack of meaningful social interactions adversely affects one's mental and physical health; however, the short-and long-term effects from physical distancing imposed by the COVID-19 pandemic are unclear. Additionally, African Americans have been especially impacted by financial hardships such as the loss of income. This financial hardship is apparent in the long lines of cars showing up at food banks, the individuals in jeopardy of being evicted from their homes, and the increased loss of health insurance that accompanies unemployment.A third response was related to listening to gospel music and reading Biblical text during stressful life events. These religious practices are consistent with and further extend what is known about the functioning of these practices to calm, strengthen, and encourage [26, 27] . Not surprisingly, these breast cancer survivors also relied on a religious song or Biblical text previously used to cope during their diagnosis and treatment for cancer. Although religious songs have previously been referred to as sources of comfort and strength [27] , these breast cancer survivors also referred to religious songs as a source of joy and reminder that they were conquerors and overcomers. Reading Biblical text provided an additional resource for the relief of fears and anxieties through the belief that an all-powerful Deity is an important source of protection [26] .The fourth and final category was the use of spirituality to find meaning and purpose during the COVID-19 pandemic. For these breast cancer survivors, the mandate for physical distancing has resulted in time alone to reflect and think. This time of reflection resulted in a refocus on individual life goals, reconnection with old friends by phone or social media, or even engagement in life-long learning opportunities through attendance in available online courses. These participants recalled previous plagues from the Bible, God's purpose for calamities, ways in which individuals survived those times through being obedient. Similarly, survivorship of the COVID-19 pandemic is possible through adhering to the mandates for physical distancing.African American breast cancer survivors are a high-risk population during the COVID-19 pandemic and spirituality is an important coping mechanism for this population. Important questions for future inquiry would be whether the use of spiritualty as described in this report is sufficient to buffer the short-and long-term effects of social isolation, loneliness, and stress as a result of the COVID-19 pandemic.The strengths of this study lie in the ability to capture the spiritually influenced strategies used to manage encounters with stressors among an at-risk population during the COVID-19 pandemic. The interviews were conducted fairly early in the pandemic and therefore capture early adaptations to disruptions in traditional spiritually influenced strategies during this pandemic amidst mandates for physical distancing and closures of faith-based institutions.There are a few limitations. Due to physical distancing mandates, participants were interviewed via telephone or video conferencing and it is unclear whether this mode of collecting data provided the same level of ease as a personto-person format. Secondly, the small sample size and qualitative methodology format limits our ability to generalize to a larger population. However, the purpose is not to generalize to a larger population of breast cancer survivors but rather to generate knowledge that expands the current evidence related to the use of spirituality during this pandemic.The COVID-19 pandemic has been particularly threatening among African American populations. African American women who are survivors of breast cancer are especially at high risk for not only contracting but also dying from this virus. African American women generally rely on their spirituality to cope with psychosocial issues encountered during cancer survivorship; however, the findings from this study suggest that spirituality continues to be an important strategy in spite of physical distancing and church closures. These breast cancer survivors were more engaged in religious practices, relying on God for protection, finding joy and courage through religious songs and reading Biblical text, and finding purpose in their lives during this pandemic. Educational efforts should target health care providers to assist their cancer patients to think of alternative ways to meet their needs for spiritual support during this pandemic. For example, cancer patients might be encouraged to locate on-line worship services or to reflect on other historical and Biblical plagues that required physical distancing. Secondly, health care practitioners might encourage cancer patients to sing, hum, or recite the lyrics of a favorite song or Biblical text when anxious or worried. Finally, cancer survivors find meaning and purpose in ""giving back"" through supporting other cancer patients. Health care practitioners might encourage the cancer survivor to redirect goals to those that can be accomplished during this time of physical distancing and limited access to traditional faith-based activities. These efforts are likely to enable the cancer survivor to overcome social isolation and loneliness that frequently leads to high levels of stress and poor mental health outcomes.Code Availability Not applicable.Conflict of Interest The authors declare no competing interests.",USA,first author,2021-02-17,02
673db0a47fb9ac84d77f273f2be56db97657d9ad,One size does not fit all: Assuming the same normal body temperature for everyone is not justified,"a1111111111 a1111111111 a1111111111 a1111111111 a1111111111In these days of increasingly personalized medicine, a surprising relic is the continued assumption that 37.0˚C (98.6˚F) is a rough approximation of each person's normal temperature. What if the normal temperature of many is over a degree less than that and some people's normal temperature is as low as 35˚C (95˚F) or lower? That matters because serious fevers in such persons can go unidentified by medical professionals who see their elevated temperature as close to 37.0˚. It also matters because checking people's temperatures as a way to screen for COVID-19 will yield false negatives for people with low normal temperatures because their elevated temperatures are accepted as in the normal range by screeners.We investigated between-subject and within-subject thermal variability, whether a significant percentage have low mean oral temperatures, and whether these differ by sex, age, time of day, ethnicity, body mass index (BMI), or menstrual phase. As far as we know, this is the first study to investigate (1) thermal stability and variability across days and weeks, (2) overnight temperature changes (from bedtime to waking) in a sizeable sample over multiple nights, and to compare (3) temperatures not only of unrelated men and women but also within couples, where room temperature and warmth of clothing were equated. Our main hypotheses were:(I) (a) Sizeable inter-individual differences in body temperature exist and (b) the average temperature of many individuals is at least one degree fahrenheit (0.55˚C) below 37.0˚C (98.6˚F). Even Wunderlich in his 1868 magnum opus [1] reported finding that ""normal"" temperature fell along a range, though that point has been largely ignored in clinical medicine [2] . Most studies over the past 50 years, especially those assessing oral temperature, have found a lower mean temperature than did Wunderlich. Many studies [e.g., 3] have found the difference to be as large as 0.55˚C (1˚F), i.e. mean temperature of �36.5˚C (97.6˚F), though a number have not [4] (36.57˚), 5 (36.8˚).(II) A given individual's temperature is fairly stable. We were primarily interested in inter-day reliability rather than diurnal fluctuation. We could no other investigation of the stability of a person's temperature over days, weeks, or months.Our secondary hypotheses were:(III) Women have higher temperatures than men (as important studies have found, e.g. [5, 6] ).(IV) Evening temperatures are higher than morning temperatures (based on consistent reports of diurnal fluctuations in temperature with temperature being lowest in the morning [7, 8] ).(V) Women tend to be warmer in the evening and cool down by morning while men tend to be cooler in the evening and warm up by morning-predicted based on personal observations.(VI) Younger adults have higher temperatures than older adults (given the much-replicated finding that temperature decreases with aging, e.g. [2] [3] [4] [5] [6] 9] ).It was not our intent to estimate population values. A far larger sample would have been needed for that. The intent was to see if we would find enough variability among individuals and enough people with mean temperatures �36.5˚C (97.6˚F) to support the recommendation that we not assume everyone's normal temperature is~37.0˚C (~98.6˚F), but instead routinely take a person's temperature at each doctor visit, much as we do now with blood pressure. This would be simple to implement and could be life-saving for those whose normal body temperature is quite a bit lower than 37.0˚C (98.6˚F).Our sample consisted of 96 adults (42 men, 54 females; no one self-identified as neither or other), ranging in age from 18-67 years (mean = 30 years). Persons who were feeling unwell at the time or recently, were pregnant, had a chronic illness, or were taking any medication that could depress one's temperature were excluded. Ethnicities of participants were 55% European origin, 16% East Asian, 16% South Asian, 8% Middle Eastern, and 5% mixed. No participant smoked. Participants were recruited via posters and social media, gave their written informed consent, and were paid $10 to thank them for their participation. No participant refused to participate since potential participants contacted us to volunteer. The study received human subjects approval from the University of British Columbia and Vancouver Coastal Health.Life Brand 1 Fast Read Digital Oral Thermometers were used. They are accurate to 0.1˚iover the range of 34.0˚to 42.0˚. To take their temperature, participants turned on the thermometer, placed it under their tongue towards the back of their mouth, closed their lips, and waited until the thermometer beeped.Participants were to take seven pairs of temperature readings in the evening right before going to sleep and first thing the following morning over a two-week period (yielding a total of 1,333 temperature readings). Thus all temperature readings were taken in participants' own homes in the greater Vancouver, BC area. Participants were instructed not to eat, drink, or engage in strenuous physical exercise during the 30 minutes prior to taking their temperature and not to take their temperature for this study when feeling unwell. We also collected data on factors that might affect body temperature including weight, height, age, ethnicity, and menstrual phase (when a woman's last period began and ended and when she expected her next period). about the length of their menstrual cycle and dates of their last and next (estimated) periods.We calculated BMI from height and weight (weight divided by height squared [kilograms/ meters 2 ). We estimated midluteal phase menstrual phase by counting back 6-8 days from the anticipated onset of the next menstruation, and early follicular phase by counting forward 3-5 days after the onset of menstruation. We did not ask about use of oral contraceptives unfortunately. All data were collected between January and May in Vancouver, BC, where the mean outdoor temperature during this period was 7˚C (44˚F) and ranged from -8˚C (18˚F) to 16˚C (61˚F).Couples participating were asked to be in the same room and wear similarly heavy or light clothing at the time of the temperature readings and for �30 minutes beforehand to try expose their bodies to the same ambient environment with similar protection against heat or cold. Our sample included 27 couples and 42 singles. All couples were heterosexual.We provided each participant with a thermometer and a temperature collection form for recording temperature readings and their dates and times. Importantly, participants were unaware of our hypotheses. Participants gave a $10 deposit for the thermometer, which was returned when they handed in their collection form and thermometer.Repeated measures analysis of covariance (ANCOVA) was used for all analyses, except when comparing variances. To compare variances, Levene's statistic was used. Neither ethnicity, BMI, nor menstrual phase was significantly related to body temperature nor did they interact in any significant way with sex, age, or time of day to affect temperature, so they were dropped from analyses. Sex, age, and time of day were included in all ANCOVA analyses.It is likely that BMI was unrelated to any study outcomes because participants self-reported their height and weight, instead of our measuring that. For menstrual phase we could not analyze within-subject effects because temperatures were taken over only two-week periods. Between-subject analyses were hampered by failing to ask about the use of oral contraceptives, which presumably many women sampled were taking, and by less than half our female participants having �2 temperature readings during either their midluteal or early follicular menstrual phases.The first part of Hypothesis #1, that there are sizeable individual differences in temperature, was confirmed. Inter-individual differences in oral temperature were large (see Table 1 Between-individual differences in temperature did not vary by gender, nor did variability just in the morning or evening temperatures. See Table 1 .Individual differences in temperature were larger among younger than older participants. Among participants 18-42 years old (mean = 26 years), range of mean temperatures spanned 2.2˚C [3.9˚F]. Among participants 43-67 years old (mean = 47 years), range of mean temperatures spanned 0.8˚C [2.3˚F]). The variance among younger adults was significantly greater than among those older (i.e., middle-aged): Levene statistic (1, 94) = 4.56, p<0.04. Similar age differences in temperature variability were seen in the morning and evening (Levene statistic (1,94) = 6.22, p<0.01; Levene statistic (1,94) = 5.94, p<0.02; respectively).There was no difference in the size of individual differences in oral temperature by time of day. Variability among participants' mean waking temperatures was comparable to that among their mean bedtime temperatures. The average morning time when participants took their temperature was 7:30; average evening time was 22:30.The second half of Hypothesis #1, that for many individuals their normal temperature is at least 1˚F below 37.0˚C (97.0˚F), was also confirmed. Among our participants, 77% had a mean temperature �36.5˚C (�97.6˚F). Significantly more participants had mean temperatures �36.5˚Cithan above it: chi-square (1, N = 96) = 29.16, p<0.001. The mean temperature across all participants was 36.1˚C (97.0˚F), with a 95% confidence interval of 36.0˚C (96.8˚F) to 36.2˚C (97.1˚F). See Fig 1. Among women participants, 82% had mean temperatures �36.5˚C (97.6˚F); the corresponding percentage for men was 71%. The difference between the percentage of men and women with mean temperatures �36.5˚C (97.6˚F) was not significant. Among adults �43 years old, 89% had mean temperatures �36.5˚C (97.6˚F); among adults 18-42 years that percentage was 77%. No adult �43 years had a mean temperature >36.4˚C (97.5˚F). Significantly more of our participants who had a mean temperature �36.5˚C (97.6˚F) were older than 42 versus younger: chi square (1, N = 74) = 21.62, p<0.001.Hypothesis #2, that a given individual's temperature is fairly stable, was confirmed too. The mean standard deviation across an individual's 14 temperature readings was only 0.32˚C (0.58˚F). Across an individual's seven morning readings it was 0.31˚C (0.55˚F) and across the seven evening readings it was 0.25˚C (0.45˚F). It was rare for a given individual's temperature to vary by >0.55˚C (1˚F) over the 14 temperature readings at two timepoints per person; indeed only 7% of within-subject readings differed by that much. Variability among the 14 temperature readings per person did not vary by sex, age, or time of day.Thermal variability also refers to diurnal variations in temperature. To look at that we paired morning and evening temperature measurements made on the same day in the same person. No significant differences emerged between a.m. and p.m. temperatures overall, or among either gender or age group.Hypothesis #3, that women have higher body temperatures than women, was supported. Women participants tended to have higher body temperatures than the men (see Table 1 ). Indeed, among adults >42 years old, mean temperatures for men and women were identical. We also examined this in just the 54 individuals in couples, where we have temperature readings from the wife and husband in the same room temperature wearing clothing of similar warmth. The mean temperature of the wives was 36.3˚C (97.2˚F); mean temperature of the husbands was 36.0˚C (96.7˚F). Comparing the paired values controlling for age, this small difference (see Table 1 Hypothesis #4, that a person's temperature tends to be higher in the evening than the morning, was disconfirmed. Indeed, the mean waking and bedtime temperatures of our participants were the same: 36.1˚C (96.9˚F). First-morning and bedtime temperatures did not vary by sex or age. Note that morning temperature readings were generally not taken during the window when lowest temperature is usually recorded (3-6 am); the mean morning time when temperatures were taken in our study was 7:30 am. Evening temperatures were generally taken by our participants at 10:30 pm (22:30), outside the window when peak temperature is normally recorded (4-9 pm [16:00-21:00]). Importantly, many of the temperature readings for our study might have been taken when participants were lying down. We return to these points in the discussion.Hypothesis #5, that women are warmer in the evening and become cooler overnight but men's temperatures show the opposite trend, received no support. To analyze this we looked at the difference in each pair of temperature readings for each participant (e.g., temperature on the night of X minus temperature on the morning of X+1). There was no sex or age difference in these difference scores. More than half our participants (57%) experienced an increase in temperature overnight. Overall, though, there was no consistent tendency for temperature to increase or decrease overnight.Contrary to our prediction in Hypothesis #6, we found no age difference in average temperature overall, nor just in morning or evening. There was no indication whatever that younger adults tended to have higher or lower body temperatures than middle-aged adults.We did not have a prediction concerning seasonal variation, but we compared temperatures taken before March (during the winter) with temperatures taken after March (during the Spring). We found no difference by season overall, nor among either gender or age group. In general, slightly warmer body temperature has been found in the summer, as in Lu et al.'s review [7] and several individual studies [10, 11] , but at least one study found the opposite [12] .Are there marked differences in the mean or ""normal"" temperature? Yes. The range of mean temperatures in our study spanned 2.2˚C (4.0˚F). Across a representative sample of reviews and other studies, the range in normal oral temperature has varied from 0.5˚C (0.9˚F) to 2.6˚C (4.7˚F; see Table 2 ). Other researchers who found variation in the normal temperature of healthy adults to be �2˚include Geneva et al. [4] , Sund-Levander et al. [13] , Mackowiak et al. [5] , Gomolin et al. [14, 15] , and Keilson et al. [16] See Table 2 [17] . Individual temperature readings in our study ranged from 33.8˚C (92.8˚F) to 37.7˚C (99.9˚F); a difference of 3.9˚C (7.1˚F); see Fig 1b. Such large ranges mean that body temperature varies enough from person to person that using the same mean for everyone will cause marked errors.The stability of temperature readings taken at roughly the same times across several days had not previously been reported. We found it to be quite stable. Thermal stability was equally true for men and women, and older (i.e., middle-aged) and younger adults. This is consistent with a snapshot of someone's temperature taken at each yearly check-up being sufficient to establish the average temperature for that person, realizing that slight dips very early morning and slight increases just before and after dusk are typical [2, 5, [7] [8] [9] 14] .We did not find the diurnal changes that are so well established. That was probably because of the times of day when we assessed temperature (07:00, after the morning nadir; and 22:30, after the peak around dusk; [5, 8, 18] ). While studies find that temperatures tend to rise in late afternoon, they also find they dip just before sleep onset [19] [20] [21] . Also, many of the temperature measurements for our study may have been taken while participants were in bed (after having just awakened or before going to sleep). Prone or recumbent posture has associated with lower temperature [20, 22, 23] . This may also be why the temperatures we observed were toward the lower end of the range of temperatures found in other studies. Also our study is more recent and Protsiv et al. [24] report that temperatures have been declining.The mean oral temperature of our healthy volunteers was 36.1˚C (97.0˚F). The mean temperatures from reviews and studies listed in Table 2 vary from 36.0˚C (96.8˚F) to 36.8˚C (98.2˚F), except for Wunderlich. Wunderlich's estimate is especially too high when oral versus rectal thermometers are used because oral and axillary temperatures tend to be 0.3-0.6˚C (0.5- Table 2 . Results from a representative sample of studies and reviews of oral temperature in healthy adults.Reviewed that assessed oral temp. 1.0˚F) lower than rectal temperature, though the range is similar [7, 13, 25] . Experts have been arguing to abandon 37.0˚C (98.6˚F) as not having any ""special significance vis-à-vis the oral temperature of healthy adults"" since at least 1992 [5 p. 1580] . A just-published study based on massive datasets [24] reports that at least in the U.S., temperatures have been declining at the rate of 0.03˚C per decade of birth. The mean currently in use (~37.0˚C [~98.6˚F]) is too high, but this has persisted despite 35 years of research consistently showing that it's too high. Using this mean causes fevers in those with normally lower temperatures to be missed.Medical historians trace the wide acceptance that normal body temperature of healthy adults is~37.0˚C (98.6˚F) primarily to Wunderlich [1] . Wunderlich was the first to systematically use a thermometer to measure human body temperature. His data are based on~25,000 patients, whose care he supervised. There are a number of limitations with this classic work, however. a Whereas most researchers and clinicians before us have argued for a new, lower estimate of normal adult temperature, we are urging that normal temperature be personalized because what is normal for one person can be quite different from what is normal for another. As Edelsberg [27] wrote: ""[N]o single value of mean body temperature has much clinical importance because of individual and population variability.""We are particularly worried about fevers not being detected in persons with low normal temperatures (e.g., �36.5˚C [97.6˚F]), which in our study was 77% of participants, 82% of just the women, and 89% of adults �43 years age. Indeed, 30% of our sample had mean temperatures <35.9˚C (96.6˚F). Similarly, Waalen et al. [3 pp. 490-491] wrote: ""[I]n every age cohort up to age 50, there is a small discrete subset of individuals with body temperatures less than 96˚F. The representation of that population increases with increasing age."" Since studies consistently report lower mean temperatures in seniors than in younger adults, it is particularly likely that troubling temperature elevations in elderly adults might be missed if one ""normal"" temperature continues to be assumed for everyone at all ages.Thus, all of our principal hypotheses were confirmed. We turn now to our secondary hypotheses; only one of which were confirmed.More than half our participants (57%) experienced a temperature rise overnight, but overall there was no consistent trend in either direction. Others have shown that temperature is lower during sleep and its onset [22, 28, 29] . Two studies had previously examined overnight temperature fluctuations, though both looked at only one night per participant, did not align temperature changes to when a participant actually fell asleep or awoke, and had small samples (Baker et al. [21] ; Cagnacci et al. [30] ). a bWe found that women had slightly higher temperatures than men, consistent with Wunderlich et al. [6] , Mackowiak et al. [5] , and Sund-Levander et al. [13] , but the opposite of that reported in McGann et al.'s study [31] or Geneva et al.'s review [4] . As far as we know, no one had previously compared the temperatures of spouses. We asked couples to be in the same room before and during taking their temperatures and to wear clothing of similar warmth. Even within couples we found that women had slightly higher temperatures than men. However, if there is a reliable sex difference in adults' temperatures it seems tiny and unlikely to be of clinical significance.Women tend to have higher temperatures in the midluteal phase [2, 21, 30] . Our sex-difference results do not seem to be menstrual-phase driven, however, since only 12 women measured their temperature even once during their estimated midluteal phase. We found a trend for temperatures to be higher during the midluteal phase, but that was not significant. Another reason we might have found higher temperatures in women than men is that many of our female participants were probably taking oral contraceptives. Women's temperatures tend to be higher when they are on oral contraceptives [21, 32] .Although it has been consistently reported that older adults have lower temperatures than younger adults [2] [3] [4] [5] [6] 9] , we did not find that. Almost certainly that is because our older adults were middle-aged rather than elderly. The mean age of our older adults was 47 years and only two participants were �60 years. The participants in Mackowiak et al. [5] were 18-40 and no age-related difference in temperature was found. The participants in Adhi et al.[33] were 9-70 (mean age = 34 years) and they, too, found no age-related temperature difference.We did find a larger range of temperatures among younger adults, but no greater diurnal variability. Perhaps we found no age difference in diurnal temperature fluctuations because of when we assessed temperatures or because our participants were more similar than different in their degree of physical activity. Thermal variability is greater in those more physically active [34] .Limitations of our study include a small sample size and our not having asked about use of oral contraceptives or level of physical activity. We should have asked participants to note the room temperature when taking each temperature reading and note their posture. We had only two participants �60 years old, which limited our ability to look at age differences throughout the adult lifespan. We did not confirm menstrual phases with hormone assays. Not having assessed temperatures between 16:00-21:00, we didn't include the window of peak temperatures. We should have measured participants' height and weight ourselves rather than accepting participants' self-reports. It might have been more accurate, though less practical, if we had taken the temperature readings ourselves, but given the small variability between readings and our means and ranges being comparable to those found by others, participants seem to have accurately measured their temperatures.Our take-home message is that it is time to personalize body temperature. It is needed and easily doable. The range in normal temperature is sufficiently large that using a standard ""normal"" temperature value will lead to errors for many individuals. For the many people whose normal temperature is much lower than 37.0˚C (98.6˚F), healthcare professionals may fail to identify a pathologically high fever or may obtain false negatives when using oral temperature to screen for COVID-19, mistaking what is actually an elevated temperature for normal.We propose that a person's temperature be taken at each doctor visit, just as we do now with blood pressure. This would be simple to implement and would permit an accurate estimate of each person's normal temperature because, as we have shown, temperature varies little across days. Such records over time would also provide a more accurate understanding of how temperature changes over the lifespan.glass thermometers had to be read in situ. His thermometers were not as precise as today's and were probably calibrated differently, yielding readings~1.7˚C (3.1˚F) higher than those obtained with digital thermometers [2] . Medical historians question whether >1,000,000 temperature readings were really taken when the thermometers took 15-20 min to calibrate, and even if taken, whether with the technology available Wunderlich could have analyzed more than a fraction of those data [26] ",Canada,first author,2021-02-03,02
372ba172e653bf11c9b63e3a09e8620a5e5a8b78,Journal Pre-proof COVID-19-Related Stress Symptoms Among Emergency Department Personnel The Project COVERED Emergency Department Network includes the following,"The coronavirus disease 2019 (COVID-19) pandemic has challenged healthcare personnel (HCP) throughout the healthcare system, leading to unprecedented levels of stress and anxiety. [1] [2] [3] [4] [5] [6] [7] [8] [9] [10] [11] [12] [13] [14] Facing unique stressors during their frontline work, HCP in emergency departments (EDs) may be particularly vulnerable to poor mental health during the pandemic.We previously reported moderate to severe stress levels induced by work during the pandemic and identified several potential stress mitigation measures, including broadly available SARS-CoV-2 testing of HCP, even for those not experiencing symptoms. 7 That study, however, was limited to academic emergency medicine physicians in California, New Jersey, and Louisiana. Little is known about the effects on other ED personnel in a geographically diverse sample of EDs across the United States.The objectives of the current study, conducted during the acute phase of the COVID-19 pandemic, were: 1) to assess symptoms of anxiety and burnout, and risk for post-traumatic stress disorder (PTSD) in a national sample (20 geographically diverse U.S. hospitals) of ED personnel over a broad range of staff roles, including nurses and non-clinical personnel (e.g., clerks and others without routine patient contact); 2) to describe specific concerns of ED personnel arising from their work during the pandemic; and 3) to determine whether the previously-reported stress mitigation measure of SARS-CoV-2 serologic testing for ED personnel would decrease self-reported anxiety.J o u r n a l P r e -p r o o f 3 We conducted this prospective cohort study as part of the COVID-19 Evaluation of Risks in Emergency Departments Project (COVERED), a SARS-CoV-2 infection surveillance analysis of physicians, nurses, advanced practice providers (nurse practitioners and physician assistants;APPs), and non-clinical ED personnel in 20 U.S. academic EDs in 15 states; the protocol has been previously described. 15 Participants in the parent study were recruited from ED staff who had not previously been diagnosed with COVID-19. The sample size was determined by the parent study, which included 1,606 participants (approximately 40 doctors or APPs, 20 nurses and 20 non-clinical ED personnel at each of the 20 sites). This project was reviewed by a CDC Human Subjects Advisor (STARS Tracking Number: 0900f3eb81b18773, NCEZID Tracking Number: 040920PK) and classified on 9 April 2020 as public health surveillance deemed not to be research under the provision as defined in 45 CFR 46.102(l) (2) . It was reviewed by the institutional review boards at all sites, and informed consent was obtained from all participants. We followed the Strengthening the Reporting of Observational Studies in Epidemiology guidelines. 16 We administered baseline electronic surveys (as part of enrollment in the parent study) from 5/13/20-7/8/20 (during a one-week period at each site). Participants then underwent nasal swab reverse transcriptase polymerase chain reaction (RT-PCR; Architect i2000, Abbott Laboratories, Chicago, Illinois) and anti-SARS-CoV-2 IgG serologic testing (Cobas SARS-CoV-2, Roche, Basel, Switzerland). Approximately 2-3 weeks after receiving their test results, participants were asked to complete a follow-up survey.After consulting with survey content experts, we utilized an abbreviated version of our previouslypublished mental health survey 7 to assess the following domains: 1) effects of the COVID-19 pandemic on stress and anxiety symptoms (hereafter collectively referred to as ""COVID-19 stress and J o u r n a l P r e -p r o o f 4 anxiety""); 2) work-related stressors; 3) work-related symptoms of emotional exhaustion, cynicism, and burnout (hereafter collectively referred to as ""burnout""); and 4) PTSD risk (measured using the Primary Care-PTSD Screen for DSM-5 [PC-PTSD-5], a validated five-item screening instrument in which a score of ≥3 signifies high risk for PTSD). 17 COVID-19 stress, work-related stressors, and job stress over the prior week were rated on a 7-point Likert scale where 1 = not at all, 4 = somewhat, and 7 = extremely. Scores ≥4 were considered elevated stress responses. To assess the perceived stress mitigation effect of serologic testing, we asked participants to rate their agreement with the following statements: ""Knowing my prior exposure and immunity to COVID-19 by serologic (blood) testing would decrease my anxiety"" (prior to testing), and ""Knowing my prior exposure and immunity to COVID-19 by serologic (blood) testing has decreased my anxiety"" (after receiving their test result).Both questions were rated on a 7-point Likert scale where 1 = strongly disagree and 7 = strongly agree. See Supplement for survey questions.We report HCP characteristics and key responses as raw counts, frequencies, percentages, medians, and interquartile ranges (IQRs). Logistic regression was used to measure the difference in the percentage of the participants who screened positive for PTSD symptoms; the model included site and participant random effects. We performed explanatory multivariable logistic regression to identify factors associated with risk for PTSD and antibody positive-associated decrease in anxiety, in which a positive response was defined as any level of agreement that testing decreased anxiety. We performed multivariable logistic regression to identify factors associated with a score of 4 or greater on questions about stress/anxiety due to COVID-19 and job-related emotional exhaustion/burnout.Variables included in multivariable models were selected a priori based on existing literature and included the following participant characteristics: quartiles of age, gender, race/ethnicity, home living situation (living alone or with a spouse / significant other, children, roommates, or other family), type J o u r n a l P r e -p r o o f 5 of HCP (physician, APP, nurse, or non-clinical staff), and community COVID-19 prevalence at time of baseline survey (quartiles as determined by local public health reports). [1] [2] [3] [4] [5] [6] [7] [8] [9] [10] [11] [12] [13] [14] Baseline models also included a dichotomous variable for participant belief that they had previously been infected (but not diagnosed) with SARS-CoV-2, and follow-up models included SARS-CoV-2 RT-PCR test results and serology test results. Standard errors were clustered at the site level. All analyses were conducted using Stata v13.0 (StataCorp LLC, College Station, TX).Of 1606 participants in the parent study, 1606 (100%) completed the baseline survey (638 physicians, 156 APP, 410 nurses, and 402 non-clinical staff) and 1413 (88%) completed the follow-up survey ( Table 1) .Before serologic testing, 1030 (64%) respondents (64% of physicians/APPs, 68% of nurses and 61% of non-clinical staff) reported feeling stress and anxiety due to COVID-19 ""somewhat"" or more strongly. HCP characteristics associated with reporting higher stress and anxiety included female Table 2 ).Participants expressed concerns about specific worries described in Figure 1 . The highest-rated (greatest) concerns were secondarily exposing participants' family members (median score 5 on the J o u r n a l P r e -p r o o f Prior to testing, 741 (46%) respondents (40% of physicians/APPs, 55% of nurses, and 50% of nonclinical staff) reported feeling burnout symptoms in the prior week ""somewhat"" or more strongly. Prior to testing, 308 (19%) respondents (18% of physicians/APPs, 23% of nurses, and 18% of nonclinical staff) screened positive for PTSD risk (score ≥3). Female respondents were more likely to screen positive than males (OR 2.03, 95%CI 1.49-2.78). Among participants who responded to both surveys, fewer respondents (12.5%) screened positive for PTSD risk after testing (difference 6.5%, 95%CI 4.6-8.5%; Figure 2 ).Community COVID-19 prevalence was not associated with positive responses to the anxiety, burnout, or PTSD symptom questions in any of the multivariable logistic regression models ( Table 2) .J o u r n a l P r e -p r o o f 7 Prior to COVID-19 testing, 75.6% (95% CI 73.5-77.7%) of participants somewhat agreed, agreed, or strongly agreed that knowing their prior exposure and immunity to SARS-CoV-2 would decrease their anxiety. After receiving their test results, 54% (95% CI 51.8-56.7) somewhat agreed, agreed, or strongly agreed that knowledge of their immune status had decreased their anxiety. A positive serology result, i.e. evidence of past infection, was associated with a higher likelihood of reporting a decrease in anxiety (OR 2.83, 95%CI 1.28-6.25; Table 2 ).In this study conducted at 20 U.S. EDs, four central findings advance our understanding of the impact of the COVID-19 pandemic on the mental well-being of U.S. frontline ED personnel. First, we found that self-reported feelings of work-related anxiety, emotional exhaustion, and burnout are prevalent across the full spectrum of ED staff, including nurses and non-clinical personnel. Second, primary stressors include concerns about HCP and patients infecting others with COVID-19 and the health of coworkers diagnosed with COVID-19. Third, over half of ED personnel reported one or more mental health symptoms of PTSD (e.g., nightmares), and nearly one in five screened positive for elevated PTSD risk. Finally, most respondents (54%) reported that their anxiety was diminished by learning their test results, though this was a lower proportion of participants than those who predicted that serologic testing would decrease their anxiety (75%). This mitigating effect was especially pronounced among those who had positive serology for antibodies to COVID-19.Our findings are consistent with those of international investigators, who have documented increased symptoms of anxiety, depression, insomnia, and PTSD risk in HCP and have found slightly greater risk in women. [1] [2] [3] [4] [5] [6] [7] [8] [9] [10] [11] [12] [13] [14] In our previous research, conducted from February 23 to April 10, 2020, the limited availability of personal protective equipment (PPE) was academic emergency physicians' primary J o u r n a l P r e -p r o o f concern. 7 At the later time of this study, PPE was no longer among the top five listed worries, suggesting that PPE became more widely available.In terms of practical, actionable items from this research, the stress mitigation effect of serologic testing has substantial face validity. ED personnel serve as the initial hospital caregivers for the majority of critically ill patients with known or suspected COVID-19 infection. They also deal with many patients with undifferentiated symptoms consistent with COVID-19, whose SARS-CoV-2 test results are often unknown while in the ED. This can lead to uncertainty of ED personnel regarding exposure to COVID-19 and secondary risk to their families. By clarifying exposure and risks, testing of HCP may logically relieve anxiety, especially in those who test positive indicating some level of perceived immunity.Our findings were remarkably consistent across all demographic groups and ""hotspot"" sites. The Centers for Disease Control and Prevention (CDC) advocates for the early recognition of the signs of stress (irritation, anxiety, lack of motivation, feeling burned out, and difficulty sleeping) in ED personnel. 18 Along with following CDC recommendations, guidance to employers to develop and implement a COVID-19 response plan (including healthy work conditions, improved leave policies, and resilience building among workers), 19 it is important that ED leadership consider provision of serologic testing for ED personnel. Considering that over half of participants reported experiencing at least one symptom of PTSD and as many as 20% were at elevated risk, employers should also similarly consider assuring that HCPs are aware of available well-being programs and encourage workers to take time off, get adequate rest, and utilize resources available to them.Our study selected HCP from large academic centers and may not reflect the experience of HCPs in smaller community EDs. Because of the potentially taxing extent of survey items for the parent project, we used abbreviated scales instead of comprehensive instruments to measure anxiety, burnout, and risk for PTSD. Although our questions were reviewed by survey and content methodology experts and we used questions from some validated instruments, our final survey instrument and questions were not externally validated.We only surveyed two points in time (approximately three weeks apart) during one stage of a lengthy pandemic and were unable to observe or control for day-to-day variables that could impact participants' reports of anxiety levels, burnout, and PTSD symptoms, such as a very stressful workday prior to completing the survey. Similarly in terms of timing, we conducted this work from May to July 2020 -prior to COVID-19 vaccination of ED providers. Receipt of COVID-19 vaccines has likely had a substantial impact on HCP emotional well-being and anxiety levels. Finally, lack of a control group who did not receive serologic testing precludes causal inferences regarding relief in anxiety and PTSD symptom reduction after serologic testing.Symptoms of anxiety, emotional exhaustion, and burnout are prevalent across the full spectrum of ED staff during the COVID-19 pandemic, and as many as one-fifth are at risk for PTSD. Future work should focus on organizational efforts to prevent pandemic-associated stress to the extent possible through healthy work design and supportive workplace policies. As HCP continue to serve on the frontlines in this pandemic, it is critical to explore ways to mitigate the long-term effects of chronic stress. Increasing provision of SARS-CoV-2 testing shows promise for achieving this aim. 2 Home living categories not mutually exclusive, except for alone. 3 Community cumulative incidence defined as cumulative cases as of 6/29/20. ",United States,abstract,2021-02-05,02
2e391a524b8dbf826413402a92987ae67c47130a,"Journal Pre-proof Assessment of Commercial SARS-CoV-2 Antibody Assays, Jamaica Assessment of Commercial SARS-CoV-2 Antibody Assays, Jamaica","The SARS-CoV-2 pandemic has resulted in an unprecedented need for reliable commercial laboratory diagnostics. While SARS-CoV-2 antibody assays have recently become commercially available, performance data have mainly assessed high-income country populations (Van Walle et al., 2020) , with data from populations of mostly African descent lacking. To our knowledge, there has been no published performance assessment of SARS-CoV-2 antibody assays with a predominantly black population. In this study in Jamaica, serum samples were used to assess the diagnostic sensitivity and specificity of the Roche Elecsys ® Anti-SARS-CoV-2, Abbott Architect SARS-CoV-2 IgM and IgG, Euroimmun SARS-CoV-2 IgA and IgG, and Trillium IgG/IgM assays.For diagnostic sensitivity analysis, 42 blood samples collected in tubes without coagulant were obtained from 37 consenting persons (5 persons were sampled at two different time points) testing SARS-CoV-2 real-time PCR positive at the Jamaica National Influenza Centre using the Corman et al method (Corman et al., 2020) . Disease severity was classified according to WHO criteria. Samples were collected 6-103 days after disease onset for symptomatic persons and 20-69 days after a positive real-time PCR test for asymptomatic persons. An additional 17 consenting SARS-CoV-2 real-time PCR positive persons were recruited to compare whole blood and serum for Trillium IgG/IgM rapid test kits. Paired whole blood and serum samples were Table) . Not all residual sera used for specificity analysis was tested across all platforms as sufficient volume was not present for some tests and a limited number of Trillium IgG/IgM test kits were provided for validation.Detection of antibodies was conducted with an Architect i2000SR for the Architect SARS-CoV-2 IgM and IgG assay, a cobas ® 6000 analyzer for the Elecsys ® Anti-SARS-CoV-2 assay, a Thermo Scientific Multiskan FC Microplate Photometer for the Euroimmun SARS-CoV-2 IgA and IgG ELISAs and lateral flow assay rapid test for the Trillium IgG/IgM assay. Each manufacturer's instructions were used for cutoff index values and interpretation of rapid test results. For Euroimmun assays, borderline index values were considered negative to allow for equivocal results to be included for sensitivity and specificity analysis, and to be consistent with other assays that do not include a borderline (or equivocal) interpretation. Previous studies (Buss et al., 2020; Eyre et al., 2020; Péré et al., 2020) of the Architect SARS-CoV-2 IgG assay indicate that samples with a high negative index value result are likely true positive but in this study were considered negative in keeping with the manufacturer's instructions and consistent with Euroimmun borderline results being considered as negative.This study was approved by the UWI Mona Campus Research Ethics Committee (ECP 244 19/20). Table) . Diagnostic sensitivities for samples collected 6-9 days, 10-13 days and ≥14 days after symptom onset were 42.9-71.4%, 85.7-100.0% and 90.0-95.0%, respectively (Fig.   1 ). Samples from asymptomatic and mildly affected persons were only available ≥14 days after onset of symptoms or after an initial SARS-CoV-2 PCR test. Sensitivities ranged from 67.9-75.0% when all disease severities were included (Fig. 1) . Grouping moderate, severe and critical disease showed a significant association with testing antibody positive for all assays: Elecsys ® Anti-SARS-CoV-2 (χ 2 =13.14, p<0.001), Architect SARS-CoV-2 IgM (χ 2 =13.81, p=0.003), Architect SARS-CoV-2 IgG (χ 2 =11.00, p=0.001), Euroimmun SARS-CoV-2 IgA (χ 2 =16.92, p<0.001) and IgG (χ 2 =14.30, p=0.001), and Trillium IgM (χ 2 =6.61, p=0.010) and IgG (χ 2 =11.70, p=0.001). Detection of antibodies was highly congruent between assays (Fig. 2) . Additional participants were recruited to compare whole blood (point of care) and serum (laboratory) for the Trillium IgG/IgM rapid lateral flow assay. Results for Trillium IgG were identical for whole blood and serum; however, Trillium IgM results showed discrepancies when comparing whole blood and serum (Supplemental Figure) .SARS-CoV-2 real-time PCR cycle threshold (Ct) values were compared with the presence of antibodies from persons with samples collected ≥14 days after onset of symptoms or an initial SARS-CoV-2 PCR positive test. For the Elecsys ® Anti-SARS-CoV-2, Architect SARS-CoV-2 IgG, Euroimmun SARS-CoV-2 IgG, and Trillium IgG assays, the Ct value was 23.5 ± 5.7 (mean J o u r n a l P r e -p r o o f ± SD) and 34.6 ± 1.0 for samples testing antibody positive and negative, respectively (p<0.0001). Ct values for SARS-CoV-2 IgM were 23.0 ± 6.2 for samples testing antibody positive and 33.5 ± 2.8 for samples testing antibody negative (p=0.0008), for Euroimmun IgA were 24.0 ± 5.7 for samples testing antibody positive and 31.8 ± 6.8 for samples testing antibody negative (p<0.0001), and for Trillium IgM, 23.0 ± 5.8 for samples testing antibody positive and 33.5 ± 2.8 for samples testing antibody negative (p=0.0003).Our data examining three chemiluminescent assays, two ELISA assays and one rapid test show that the diagnostic sensitivity of these assays for SARS-CoV-2 antibodies is comparable. The similar diagnostic sensitivity and specificity of the Trillium IgM/IgG rapid diagnostic test with chemiluminescent and ELISA assays makes this test suitable for resource-limited laboratories lacking high cost instruments. However, discrepant IgM results between whole blood and serum for the Trillium IgM/IgG rapid diagnostic test warrant additional investigation should results of the IgM component of the test be considered.An accumulating body of evidence indicates that after a SAR-CoV-2 infection antibodies become detectable approximately one week after disease onset (Deeks et al., 2020) . In agreement with these studies, approximately half of the SARS-CoV-2 infected persons in our study had detectable antibodies 6-9 days after onset of symptoms, with most having antibodies ≥10 days after symptom onset. When asymptomatic and mild groups were included in our analysis, sensitivities decreased for all assays, consistent with previous studies [3, 4] .Comparing SARS-CoV-2 antibody results revealed a striking difference in Ct values between persons testing antibody negative or positive. These data are consistent with a recently published study examining SARS-CoV-2-infected asymptomatic contacts and outpatients showing that SARS-CoV-2 PCR Ct values are inversely related to SARS-CoV-2 IgG index values (Wellinghausen et al., 2020) . High SARS-CoV-2 viral loads may cause a more robust production of SARS-CoV-2 antibodies (Zhang et al., 2020) .Our data assessing a Caribbean population of predominantly African descent highlights the limited diagnostic sensitivity of the assays examined for persons with asymptomatic and mild SARS-CoV-2 infections and has important implications for future seroprevalence studies in which a sizable proportion of the SARS-CoV-2-infected population may have experienced no symptoms or mild disease. Disease severity is color coded as follows: green = asymptomatic, blue = mild, orange = moderate, yellow = severe, and red = critical. ",Jamaica,abstract,2021-02-18,02
e0396d97906a2ae3c9d7aceab6a5d4017d2bfd25,Associations of Race/Ethnicity and Other Demographic and Socioeconomic Factors with Vaccination During the COVID-19 Pandemic in the United States,"both education and pre-pandemic income levels exhibited evidence of positive doseresponse relationships with vaccine initiation (P for linear trend = .01 and <.001, respectively). Substantial (vs. no) financial hardship was linked to 44% lower odds of vaccination (P<.001). The most common reasons for vaccine hesitancy were concerns about side effects and safety.In this large, nationally-representative study with relatively complete race/ethnicity and socioeconomic data, we find that being Black non-Hispanic and having the least education and income were each independently associated with a markedly lower likelihood of definitely planning to get vaccinated or having been vaccinated. In the ensuing months of the pandemic, addressing racial/ethnic and socioeconomic inequities in vaccination due to differential access and vaccine hesitancy will be critical to mitigate the pandemic's disproportionately higher risks of infection and adverse outcomes in Black non-Hispanics and socioeconomically disadvantaged groups and to help maximize vaccination coverage nationwide.The main predictors were race/ethnicity, education, and pre-pandemic (2019) household income. Outcomes consisted of the self-reported: 1) receipt of ≥1 dose of a COVID-19 vaccine; and 2) either receipt of ≥1 dose of a COVID-19 vaccine or the plan to definitely receive a vaccine once available to the respondent. 1.9% of the sample did not respond to either of the survey items corresponding to these outcomes.Multivariable logistic regression models were fit to estimate adjusted odds ratios with generalized estimating equations for each outcome to account for survey weights and obtain robust standard errors. Log-Poisson regression was not employed due to bias when estimating relative risks for binary outcomes. 7 All models included all of the above main predictors, and were also adjusted for age, gender, marital status, household size, children in household, financial hardship, and state of residence. Multiple imputation analysis (using 20 multiply imputed datasets) was employed to handle missing data. All analyses were conducted using SAS (version 9.4; SAS Institute).The final sample was comprised of 66,994 adults, representative of 243 million Americans. Of individuals who reported their COVID-19 vaccination status, race or ethnicity information was missing in 3.92% of the sample, and was previously handled using hot deck imputation. 5 Figure 1 illustrates the racial/ethnic group variations in receiving ≥1 vaccine dose. In Hispanics and Black non-Hispanics, the estimated prevalences of vaccine initiation were 6.1% and 6.2%, respectively, compared to 8.7%in White non-Hispanics and 15.1% in Asian non-Hispanics. Across all races and ethnicities, the estimated prevalence of vaccine initiation was 7.6%. Controlling for other demographic and socioeconomic factors, Hispanics and Black non-Hispanics were no more or less likely than White non-Hispanics to have received ≥1 vaccine dose ( Table   1 ). Asian non-Hispanics were 79% more likely than White non-Hispanics to have received ≥1 vaccine dose (P <.001). Meanwhile, both education and pre-pandemic income levels exhibited evidence of positive dose-response relationships (P for linear trend = .01 and <.001, respectively). Compared to those with at least a college education, those with less than a high school education were 59% less likely to have been vaccinated (P <.001). Compared to those with 2019 income levels ≥$200,000, those with income levels <$25,000 were 47% less likely to have been vaccinated (P = .001). Substantial (vs no) financial hardship was linked to 44% lower odds of vaccination (P <.001).In a large, nationally-representative study with relatively complete race/ethnicity and socioeconomic data, being Black non-Hispanic and having the least education and income were each independently associated with markedly lower odds of definitely planning to get vaccinated or having been vaccinated. Study limitations include its cross-sectional and observational design, which cannot rule out bias due to confounding. While sampling weights and raking accounted for non-response and undercoverage, the low survey response rate could have led to selection bias. Last, all measures were based on self-report, and could be subject to biases such as related to social desirability of reporting vaccination. Although the levels of vaccine initiation appeared to be higher based on this survey compared to the levels in the CDC analysis, this might be attributed in part to selection bias or social desirability bias and/or the 4 additional days covered in the HPS administration period.",United States,abstract,2021-02-19,02
a7f1017f32eb08ac2d3b1e2b0db9751264a62f42,Returning to a normal life via COVID-19 vaccines in the USA: a large-scale agent-based simulation study,"The Centers for Disease Control and Prevention (CDC) forecasted that 300,000 deaths would be attributable to COVID-19 by the end of the year. Reality defied expectations, as COVID-19 was directly responsible for approximately 350,000 deaths in the USA out of 20 million reported cases (for forecasts and total case numbers, see [1] ), which may only represent one out of seven actual cases based on CDC estimates for September [2] . Despite popular comparison with the flu, the ongoing COVID-19 epidemic has thus already claimed five times as many lives than the worst year for the flu, whose recent yearly death tolls range from a low of 16,000 to a high of 68,000 [3] . To contextualize the impact of COVID-19, we note that the U.S. life expectancy decreased by more than a year, which is ten times worst than the decline from the opioid epidemic [4] . In another comparison, 2020 is the largest single-year increase in mortality in the USA since 1918, which had both a flu pandemic and a war. This reflects both direct and indirect consequences on COVID-19, such as disrupting in-person treatments [5] and supply networks, with effects as far ranging as a jump in drug overdose [6] . To complement measures of short-term effects such as deaths or number of cases, we also note the longterm impacts captured by the outpatient journey. Common symptoms often persist over month (e.g. fatigue, cough, headache, sore throat, loss of smell) [7] [8] [9] and less frequent ones can be severe since COVID-19 involves many organs. Effects can involve the cardiovascular system in up to 20-30% of hospitalized patients [10] [11] (e.g., cardiac injury, vascular dysfunction, thrombosis), result in kidney injury [10] or pulmonary abnormalities [13] , or lead to a deterioration in cognition due to cerebral micro-structural changes [14] . Based on similar infections, such effects can be long: for instance, inflammation of the heart caused by viral infections (i.e., myocarditis) can have a recovery period spanning months to years.Interventions in 2020 were strictly non-pharmaceutical, as vaccines were being developed and tested. Such intervention strategies have included preventative care (e.g., social distancing, hand washing, face masks), lockdowns (e.g., trasvel restrictions, school closures, remote work), and logistics associated with testing (e.g., contact tracing, quarantine) [15] [16] . The range of non-pharmaceutical interventions adopted at various times across countries can be seen in further details through the CoronaNet project [17] or the collection of essays ""mobilizing policy (in)capacity to fight COVID-19"" published in mid-2020 [18] . In early 2021, two vaccines were deployed (Pfizer-BioNTech and Moderna) with plans for up to three additional vaccines (AstraZeneca, Janssen, Novavax) [19] . With the availability of vaccines comes the key question: when will life return to normal in the USA? The implicit expectation is to see a return to normalcy thanks to the vaccine, rather than due to a high number of cases with its accompanying death toll.In a highly publicized interview, Dr. Anthony Fauci, director of the National Institute of Allergy and Infectious Diseases, estimated a return to normal by fall, if the vaccination campaign is successful [20] . Getting a precise estimate of when life will return to normal is a challenge as it depends on numerous interrelated factors: potential behavioral changes affecting non-pharmaceutical approaches (e.g., lesser compliance to mask wearing and social distancing), participation in the vaccination campaign, logistics associated with vaccination (i.e., who can get vaccinated and when), and mutations leading to new strains with different biological properties (e.g., higher infectivity) or unknown vaccine responses. In this paper, we use large-scale simulations to identify when there will be an inflection point in the dynamics of the disease, and the level of cases that will be obtained.Simulations have been used since the early days of the COVID-19 pandemic. Classic compartmental epidemiological models were first produced (e.g., many SEIR models [21] [22] [23] [24] ), with a focus on estimating broad trends and key epidemiological quantities such as the expected number of new cases generated by each infected individual (i.e., the basic reproduction number R 0 ). Such compartmental models provide limited support to study the effect of interventions, for instance by lowering the contact rate to represent the impact of social distancing. A research shift in the second part of 2020 resulted in the growing use of Agent-Based Models (ABM) to support the analysis of interventions by explicitly modeling each individual as well as their interactions among each other or with the environment. This shift to individual-level models was underpinned by the evidence of heterogeneity in risk factors (e.g., older age, hypertension, respiratory disease, cardiovascular disease [25] [26] ) as well as behaviors (e.g., non-compliance with social distancing orders) based on personal beliefs and values [27] [28] . There is also spatial variation in socio-ecological vulnerability to COVID-19 [29] , with rural counties being at higher risk (due to e.g., older population with more underlying conditions, lower access to resources) [30] [31] and hence experiencing higher mortality rates [32] . Finally, there is a documented heterogeneity in transmission based on contact tracing data [33] , which stresses the need to use realistic networks when modeling the spread of COVID-19 [34] . Considering this growing evidence-base, our work relies on an ABM which accounts for individual heterogeneity (e.g., in age), explicitly embeds them in a network to model their contacts, and simultaneously considers different network types (e.g., community, work) to account for various settings.By adding vaccines to a previously validated ABM of COVID-19, we are able to assess how the number and timing of cases depends on key factors such as the population's interest in vaccines and the efficacy of vaccines. Our specific contributions are twofold:-We extend the validated COVASIM model with a detailed process of vaccination, accounting for vaccine efficacy, interest in vaccination, and fluctuations in vaccination capacity. Our process models the need for two doses and the possibility of being infected until the second dose is administered. -We examine vaccination interventions under two hypotheses for the number of doses available and considering concurrent non-pharmaceutical interventions.The remainder of this paper is structured as follows. In our methods, we briefly cover the rationale for choosing COVASIM and how we adapted the model to account for the latest epidemiological evidence. We then explain which non-pharmaceutical interventions are simulated, in line with our previous work [35] . Most importantly, we detail the novel extension of vaccines into COVASIM and our examination of the trends in cumulative infections using a logistic growth model. The following section presents and analyzes our results. Our final section discusses our main findings and provides an exhaustive list of limitations due to the ongoing nature of the pandemic and challenges in vaccination.COVASIM was developed under leadership of the Institute for Disease Modeling and released in May 2020 by Kerr and colleagues [36] . It is one of several open-source Agent-Based Models, together with OpenABM-Covid19 [37] or COMOKIT [38] . The model captures the transition from susceptible to infected followed by a split between asymptomatic individuals and various degrees of symptoms, resulting either in recovery or death ( Figure 1 ). The model was created to support interventions offered at the time, which did not include vaccination. We thus modified the model to account for our current understanding of viral dynamics as well as the use of vaccines over two doses ( Figure 1 ). When instantiating the model to the U.S. population, we use a resolution of 1:500 (i.e., each simulated agent accounts for 500 U.S. inhabitants). Given our resolution and target population size, our application exceeds half a million agents and can thus be described as a ""large-scale COVID-19 simulation"" [39] . Our simulations start on January 1 st using CDC data for the number of infected, recovered, and immunized individuals to date (see subsection ""Initializing the model""). We then simulate for 6 months, that is, 180 time ticks based on a temporal resolution of one day per simulation step (i.e., 'tick'). To cope with the computational challenges created by a large-scale stochastic model, a philanthropic grant supports us in performing cloud-based simulations via the Microsoft Azure platform.Apart from being open source, there are two reasons for which we selected COVASIM. First, it captures heterogeneity within individuals (e.g., assigns an age and uses agespecific disease outcomes) as well as transmission patterns, by placing agents within synthetic networks corresponding to a multiplicity of contexts: work (based on employment rates), school (based on enrollment), home (based on household size), and the general community. However, these high-resolution age-specific contact patterns are not unique to COVASIM. For example, the OpenABM-Covid19 [37] also embeds agents in age-stratified occupation networks (encompassing work and school), household networks, and a 'general' random network. COMOKIT [38] similarly uses the Gen* toolkit from the same team to redistribute populations from census units down to exact buildings such as the nearest school. Thus, the second rationale for choosing this platform is that it has been used in the most peer-reviewed modeling studies to date [40] [41] , hence providing an additional layer of scrutiny and confidence in the correctness of the model (i.e. validation) as well as its implementation (i.e. verification). As detailed in our recent work [35] , changes in the evidence-base have required alteration in the model to keep it valid. Consequently, we modified three COVASIM parameters to account for the current biological and epidemiological evidence on COVID-19 (Table 1 ). In addition to support for heterogeneity, COVASIM implements several nonpharmaceutical interventions. Although our focus is on vaccines, such interventions may be continuing in parallel with the vaccination campaign hence we have to take them into account when forecasting case counts. Interventions can be organized into three broad categories: preventative care (e.g., social distancing and face masks), lockdown (e.g., stay-at-home orders such as remote work and/or school closures), or testing-related (e.g., testing itself, then quarantining and contact tracing) [42] [43] 15] . In line with our previous work on non-pharmaceutical interventions, we considered all six specific interventions. Although all six are natively supported by the COVASIM platform, we changed testing delays from their default value (constant) to a distribution (based on a survey across all 50 U.S. states) [44] , thus accounting for the variability observed in practice.As detailed in our discussion, there is significant uncertainty and frequent changes regarding the number of vaccines that may be administered monthly. We thus consider two vaccine availability scenarios, both proposed by federal governments. The first scenario from the former Trump administration, named Operation Warp Speed, stated that vaccines will be available in tiered amounts (20 million in December, 30 million in January, and 50 million every month thereafter). The second scenario from the Biden administration, known as the '100-day goal', proposes that there will be 1 million vaccines every day [ 4 5 ] , thus covering 50 million Americans. Although there are other scenarios, they vary from state to state (e.g., the governor of New Jersey aspires to vaccinate 70% of the adult population within 6 months [46] ) and are also subject to frequent revisions. Given the country-wide nature of our simulation, we rely on federal plans while detailing challenges (c.f. discussion).At the same time as either vaccination schedule is active, we also have the six scenarios listed in the previous sections. As these scenarios include a no-intervention case, we are able to study the interaction between non-pharmaceutical interventions and vaccines. In total, this gives 12 distinct situations. In addition, we also vary two essential parameters regarding vaccines: the percentage of the population that seeks vaccination (which we refer to as 'vaccine compliance' from hereon) and the efficacy of the vaccine. Varying these two parameters across 12 situations in a large-scale ABM results in significant computing needs. These are challenging to parallelize as the runtime of each experiment is not the same. Therefore, we took advantage of the massive parallelism enabled by the cloud computing platform Azure to accelerate computation. Using this platform, we varied vaccine compliance and vaccine efficacy between the bounds listed in Table 3 . Regarding our approach to vaccine efficacy, we note that individuals can be infected after their first dose, as has been documented on thousands of cases [48] . We thus only apply the probability of vaccine efficacy only after the 2nd dose. Although we do not track which of the two approved mRNA COVID-19 vaccine (Pfizer-BioNTech or Moderna) is administered, we vary vaccine efficacy to account for a margin of uncertainty regarding their respective performances. Since the vaccine capacity is either planned to increase (Operation Warp Speed) or at a high constant rate, a simulated agent given one dose will always be able to come back to get the second dose on time. Should an agent be contaminated or die before the second dose, it is then released for administration to another agent.A simulation model is composed of an initialization (setting characteristics of agents for t=0) and rules governing its update, thereby producing data for analysis. The previous subsections covered the rationale for inclusion of agents' characteristics and the design of the rules, while the next subsection focuses on the analysis. The present subsection thus briefly covers our approach to initialization such that our results can be independently replicated by other modeling teams.To quantify the spread of the disease, we fitted the progression of cumulative infection to a logistic growth model, which is a simple yet effective model describing resourcelimited growths in natural processes and has been used on several occasions for COVID-19 [52] [53] [54] . Let the cumulative infection be, then the logistic model stipulates that ܲ is the solution of the differential equation (1) suggests. In the regression, the independent and dependent variables are ܲ and ܲ ሶ / ܲ , respectively. In addition, we measure the goodness of fit as that of the linear regression. Since the simulation is stochastic, multiple replications are needed for each configuration to obtain an average behavior. We used the confidence interval method [55, pp. 184-196] Although we report ‫ݎ‬ and ‫ܭ‬ in our supplementary material, the interpretation of these variables can be difficult for a broader audience. The growth rate ‫ݎ‬ is proportional to the maximum fraction of the carrying capacity ‫ܭ‬ that is infected on the worst day. In other words, it is an indication of how fast the disease spreads as its peak, based on another variable. For ease of interpretation, we focus on the adjusted growth rate whose unit is directly in number of individuals. This adjusted growth rate is obtained asFor instance, an adjusted value of 200,000 means that at most 200,000 individuals will be infected on the worst day.As the early steps of the simulation witness a shift from a vaccine-naïve population to one that gradually builds vaccine-based immunity, early trends differ from the longer ones that are the focus of this study. This is a typical situation in modeling, whereby estimating the long run performance measures requires to first run the model for a certain amount of time (known as 'warm-up period') [56] . We empirically determined that a warm-up period of 20 days was sufficient to start the curve fitting, that is, we create the time series for ܲ starting from ‫ݐ‬ 2 0The carrying capacities and growth rates as functions of vaccine compliance and efficacies for each vaccination plan are provided as supplementary online material S1 -S4. In this paper, we focus on the adjusted growth rate in Figures 5-6 for the two federal plans, six scenarios (including 5 non-pharmaceutical interventions), and by varying vaccine efficacy as well as compliance. This allows to examine the synergistic effects of non-pharmaceutical interventions with vaccines while comprehensively accounting for key unknowns.In comparing the two federal plans, the Biden plan showed more potency at controlling the infection across all intervention scenarios than the plan created under the previous administration. We note that even if a small fraction of the population seeks vaccines, and even if vaccines are less effective than announced, the vaccination campaign can reduce the total number of infections. Note that increasing the efficacies of vaccines results in lower infections for all scenarios and vaccine plans. This agrees with expectation since in our simulations, agents are not re-vaccinated upon having no immune response. Therefore, while holding all else equal, increasing the vaccine efficacy accelerates the growth of the immune population, thereby reaching herd immunity more quickly. In contrast, the dependence on compliance is much less intuitive and even leads to unintended consequences.Typically, we assume that higher vaccine compliance will lead to lower overall infections, since the proportion of the immune population is upper bounded by the compliance. However, in both vaccination plans, only scenarios 1 and 2 yielded such results. For the rest of the scenarios (3 to 6), the dependence on vaccine compliance is apparently reversed, with some hinting towards a non-monotonic relationship (scenario 4 of the Biden plan and scenario 5 of the federal plan, for example). The reason behind this puzzling behavior is a combination of three factors: (i) vaccines are strictly administered in decreasing order of age, (ii) the elderly are going neither to work nor to school, hence they have fewer social ties than other age groups, which reduces their impact on preventing the spread of infections once immunized, and (iii) relative to the growth of infections in the scenarios in which the anomaly happen, the vaccine availabilities are too low.As the vaccine compliance increases uniformly in the population, it means that a larger number of elderly in particular will seek vaccines. Given the vaccination strategy that focuses on older individuals, it will therefore take more time before anyone from the more connected/younger age groups can be vaccinated. During this time, the virus can continue to spread among the younger population, particularly because (i) the scenarios with counter-intuitive results (3 to 6) are among the least restrictive in terms of nonpharmaceutical interventions and (ii) elderly have a lower contribution to the spread of infections due to their more limited social ties. Therefore, while the elderly population will be better protected, the longer delay for the rest of the population means that by the times they are eligible for vaccinations, the infection has already spread, leading to overall higher infections.The incoming CDC director predicted half a million death by mid-February [57] , thus stressing the urgency of vaccination. However, vaccination is an unprecedented and complex endeavor whose success depends on many other variables such as vaccine compliance, vaccine efficacy, and the ongoing presence of non-pharmaceutical interventions. In line with expectations, our large-scale agent-based simulations show that vaccination can reduce the total number of infections across all possible scenarios. The capacity pledged under the new Biden plan (one million doses a day) would have a greater impact than the plan of the previous administration (""Operation Warp Speed"") when accounting for its initial delays.Two key findings of our study are as follows. First, we demonstrate the necessity to maintain non-pharmaceutical interventions over the next six months. As interventions are relaxed (from scenario 1 offering the most control to scenario 6 offering no control), there is an increase in case count such that a return to normalcy is not achieved through vaccination but rather through a very high number of infected individuals. Second, there is an unexpected interplay between vaccination strategies, non-pharmaceutical interventions, and vaccination availabilities. As non-pharmaceutical interventions lose momentum (scenarios 3 and above), an increase in vaccine compliance leads to an unexpected increase in infections due in part on the low availability of vaccines and the priority on vaccinating elderly. More so than the observation that tighter nonpharmaceutical interventions result in the slower spread of infections, this result further delineates the necessity of preparing the population to continuing non-pharmaceutical interventions even as the vaccination progresses.There are two main limitations to our current understanding of the COVID-19 pandemic and the vaccination campaign, which affect how our simulations account for (i) the number of vaccines that can be administered each month, and (ii) biological aspects.We have thus followed the federal plan for the number of individuals who can get vaccinated each month. Out of all the doses that are planned, fewer may be distributed and an even lower number may ultimately be administered. Our simulations are thus likely representing an upper bound on the number of vaccines administered, leading to more optimistic results than in reality. The gap is particularly pronounced in December and may remain significant in January, but early logistical issues and delays should be gradually addressed, such that the gap between federal expectations and actual implementation narrows over time.Second, all biological aspects of the virus are based on the strains that dominated throughout 2020. Epidemiological studies from these strains have informed parameters such as transmissibility, incubation period, the proportion of asymptomatic carriers, the severity of symptoms and hence the course of the disease, as well as the efficacy of treatments or vaccines. The existence of different strains is well-established, as phylogenies have shown seven distinct lineages [refs 65, 66] , but here has not yet been a documented need to ascribe different parameter values (i.e., different viral 'behaviors') to each strain. There are two possible reasons. First, there are relatively few mutations and thus a limited 'chance' of a drastically different outcome naturally occurring: the virus is ""considered a slowly-evolving virus as it possesses an inherent proofreading mechanism to repair the mismatches during its replication"" [ref 66 ]. Second, there has been little selective pressure on the virus, as it was spreading through a population that had never been exposed to an antigen (i.e., immunologically naïve). Both arguments are now changing.(including mutations and deletions) [ref 67 ]. Some of the biological changes make it easier for the virus to attach to its targets and enter cells, which is captured through epidemiological indicators as increased transmissibility [68 -69] . This is relevant for our study, as this more contagious COVID-19 strain has been spreading in the USA and may dominate by March [70] . To date, there is no peer-reviewed evidence of an impact on disease severity or vaccine efficacy over a large population sample, but the function for some of the mutated parts remains unknown (hence the possibility of an impact on severity) and early studies over 20 volunteers suggests that antibodies from vaccines are only one-third as effective on some variants [71] . In addition, vaccination means that the virus is no longer spreading through an immunologically naïve population, thus creating selective pressure for functional mutations which can help the virus adapt. Our simulation results are thus optimistic as they use a lower transmissibility than provided by the new strain and as we did not worsen any of the other parameters to account for possible selective pressure.Finally, we note that our model is built very specifically for the USA. It would not be accurate when transposed to another country with minimal changes (e.g., only reducing the population size). For example, stark differences in vaccine rollout strategies exist between the UK and the USA, which would affect our simulations. In the USA, two doses of the same vaccine are normally administered, as the CDC stated that ""mRNA COVID-19 vaccines are not interchangeable with each other or with other COVID-19 vaccine products"" [72] . However, new guidance from the UK allows a mix-and-match vaccine regimen in which the second dose may be from a different vaccine in exceptional circumstances (e.g., if the vaccine from the first dose is not available upon the patient's return), even though clinical trials for mixed regimens are only due to be conducted at a later, unspecified time [73] . Another difference is that the UK frontloads the vaccine by delivering as many first doses as possible, which thus (i) no longer guarantees that a patient can receive the corresponding second dose upon return (hence raising the need for a mix-and-match) and (ii) potentially delays the delay before a second dose up to 12 weeks [73] . In contrast, the USA is against delaying the second dose [74] , thus our model operates on the assumption that a patient can complete treatment on time.COVID-19: Disease caused in humans by a new strain of the severe acute respiratory syndrome coronavirus 2, SARS-CoV-2 (initially named 2019-nCoV). VOC-202012/01: Variant of Concern 2020/12/01 is a new strain, first identified in the UK and currently spreading in the USA, whose unusually large number of changes in genomes result in higher transmissibility.",USA,first author,2021-02-03,02
6a12fde9c55d73ef1213a9b6a0f939dbae7dc09d,Title: Household secondary attack rate of COVID-19 by household size and index case characteristics,"Household secondary attack rate (SAR) is an important indicator of the transmission of COVID-19.Previous studies have reported household SARs of COVID-19 ranging from 4% to 55% 1 . A majority of these studies were based on small cohort sizes, with few stratifying by number of household contacts 2 . In this population-wide study in Ontario, Canada, we investigated the household SAR to understand its relationship to household size and index case characteristics.We identified all patients with confirmed COVID-19 in Ontario's provincial reportable disease surveillance system between July 1 and November 30, 2020. Cases within households were matched based on reported residential address 3 and the number of household contacts were determined using reported household size. Cases living alone were excluded, as were those living in congregate settings such as retirement homes and shelters. Households were grouped based on household size.We defined index cases based on the symptom onset date in the household; specimen collection date was used when symptom onset date was missing. In households with 1 contact, secondary cases were defined as those with symptom onset dates 1-14 days after the index case; in households with 2 or more contacts, this interval was increased to 1-28 days to allow for chains of transmission. Households containing multiple cases with the same earliest symptom onset date were excluded. In sensitivity analyses, secondary cases were those with onset 2-14 days after the index case. We obtained ethics approval from Public Health Ontario's Research Ethics Board.Larger households in the most ethnically diverse neighborhoods had greater SAR than those in the least ethnically diverse neighborhoods (15.0% vs 20.3%); this was not evident in smaller households. Index cases with longer delays between symptom onset and test seeking were associated with greater household SAR; each one-day increase in testing delay was associated with a 1.8% increase in SAR. When secondary case onset was 2-14 days after the index case, household SAR was 15.5%.Household SARs differed by index case characteristics. Our estimated household SAR (19.5%) aligns with a pooled estimate compiled by Koh et al. (18.1%, 95% CI: 15.7-20.6). Unlike our findings, studies have reported greater SARs in households with more contacts, though these studies utilized cohorts with fewer than 1000 participants and conducted enhanced contact follow-up 2,4 . Asymptomatic index cases associated with lower SAR is consistent with previous findings 1,2 .The increased SAR within larger households in more ethnically diverse neighborhoods reflects findings that visible minorities are less likely to work from home during the pandemic 5 and that greater household crowding in these communities contribute to their increased risk of COVID-19 6 . Our findings propose the importance of immediate test seeking, as a confirmed case may motivate behavior to prevent household transmission. This analysis is limited by the absence of household contact information (including COVID-19 testing status), and by the potential misclassification of index cases, especially in households with asymptomatic cases. Our findings present characteristics associated with greater household SARs and proposes immediate testing as a method to reduce household transmission and incidence of COVID-19.",Canada,abstract,2021-02-25,02
2a5eac7754adc7ce2b142342151e0e81c1974b32,Complexity and unanswered questions in the pathophysiology of COVID-19 ARDS,"We welcome the correspondence by Jha [1] who invites further elaboration on the findings reported in our manuscript [2] . In responding, it is well to keep in mind that the simplifications of classical physiology which often are helpful in other settings may give rise to misconceptions regarding the pathophysiology and observed behaviours of acute distress respiratory syndrome (ARDS) related to coronavirus disease 2019 (COVID-19).Recent radiological studies using dual energy computed tomography (CT) scan and iodine maps have shown extensive heterogeneity in ventilation/perfusion mismatching, ranging from dead space, due to poor perfusion of ventilated lung parenchyma (as Dr Jha alludes to in the letter), to shunt due to increased perfusion in poorly or non-aerated lung regions [3] .Similarly, the dead space of COVID-19 pneumonia is not just due to microthromoboses-although these are much more prevalent than ARDS from other etiologiesbut also to dysregulation of pulmonary perfusion, without overt thrombosis [4] . Therefore, shunt fraction and venous admixture is a composite element which derives from variable non-aerated lung tissue mass and neovascularisation in these regions, which further increases the perfusion in non-aerated lung [5] . The combination of these phenomena is reflected in the weak relationship between the quantity of non-aerated lung and observed venous admixture, and consequently hypoxaemia.With these considerations in view, we are compelled to take serious issue with the flawed arguments posited by Jha regarding gas exchange in COVID-19. While we agree that the net effect on hypoxemia depends on a multitude of factors, large shunts are-by definitionrefractory to inspired oxygen and to increases in minute ventilation. What is more, the alterations of respiratory drive in COVID-19 are complex and not necessarily due to absolute levels of hypoxaemia; many patients experience high levels of respiratory drive even when hypoxaemia is mild or corrected. It stands to reason, therefore, that the hypoxaemic stimulus is physiologically unlikely to cause high drive per se, nor is increased ventilation able to compensate for hypoxaemia (or improve the dead space fraction). This would seem self-evident, given the rather high number of patients requiring respiratory support. In addition, however desirable they might be, accurate and reproduceable measurements of lung mechanics and CT characteristics under standardised conditions are difficult to obtain in spontaneously breathing patients.However, Jha is correct in saying that ventilation settings may influence ventilatory ratio [6] , dead space and PaO 2 /FiO 2 ratio. We note that this concern is an issue with all ARDS studies. The many interesting questions Jha raises, however, cannot be easily answered by any single study. Patient populations are inherently heterogeneous, both in terms of pathophysiology and timing of presentation; moreover, matching patients using certain variables of interest may pose insurmountable methodological challenges and limitations. We do hope, however, that our results have generated enough interest to stimulate further research into the complex pathophysiology of COVID-ARDS (CARDS).",USA,first author,2021-02-01,02
a3b09113dd6da3da937488487bea92c717ee6566,Journal Pre-proof USING MACHINE LEARNING TO DEVELOP A NOVEL COVID-19 VULNERABILITY INDEX (C19VI) USING MACHINE LEARNING TO DEVELOP A NOVEL COVID-19 VULNERABILITY INDEX (C19VI),"the current study, we developed a more reliable assessment: the COVID-19 Vulnerability Index (C19VI) which quantifies the pandemic vulnerability of each United States county. This relative index processed the same six input variables as CCVI, however, instead of using a statistical linear algorithm, we utilized machine learning technique. We implemented Random Forest (RF) machine learning technique to calculate C19VI. An innovative ‗COVID-19 Impact Assessment' algorithm was also developed using homogeneity analysis and temporal trend assessment techniques for training the RF model. Our ‗COVID-19 Impact Assessment' algorithm, for the first time, introduce the concept of analyzing temporal dynamics of confirmed cases, deaths and IFR in addition to analyzing the CDC's six themes in a non-parametric, non-linear machine learning-integrated method. Thus, our vulnerability modeling approach has a two-fold added advantage than the conventional methods. First, we assessed the additional variables that introduce variability in vulnerability modeling, i.e., temporal analysis of daily confirmed cases, deaths, and IFR data. Secondly, all of the variables were processed in a non-linear, nonparametric fashion by using RF machine learning techniques. Next, our C19VI index was compared with CDC's CCVI using advanced statistical measures and a machine learning model.We then tested the accuracy and checked the internal consistency of the C19VI.Our vulnerability assessment methodology has allowed us to analyze the impact of COVID-19 that has been unequal and widespread across the nation [12] [13] [14] [15] . Besides, there are current techniques in vulnerability modeling, leveraging the preparedness of vulnerable counties to reduce the COVID-19 burden within the United States.We used publicly available datasets from Johns Hopkins University 2 , Centers for Disease Control and Prevention (CDC) 10 In order to understand the impact of COVID-19 pandemic in all 3142 counties in the   United States, we have proposed a ‗COVID-19 Impact Assessment' algorithm. This algorithm   ‗Scores' and ‗Ranks' the impact of COVID-19 pandemic by evaluating the temporal changes in confirmed cases, deaths, and infection fatality rate (IFR) 20 datasets using trend analysis (Mann Kendall 21, 22 & Theil and Sen Slope 23, 24 ) and homogeneity assessment (Pettitt's test 25 ) . Trend analysis characterizes the overall pattern in daily-time series dataset and homogeneity assessment identifies abrupt changes in temporal trends [21] [22] [23] [24] [25] . Together, trend and homogeneity analyses make the algorithm more sensitive to daily changes in the epidemiological curve and recognize the subtle impacts of the health policies. Thus, the algorithm classifies each county in one of the six impact groups, ‗very high' (Rank = 1), 'high' (Rank = 2), ‗moderate' (Rank = 3), ‗low' (Rank = 4), ‗very low' (Rank = 5) and 'non-significant' (Rank = -999). See supplementary material for the ‗COVID-19 Impact Assessment' algorithm pseudocode. The algorithm functions in four steps:1. Data import and pre-processing: County-wise, daily time-series data of the confirmed cases and deaths were obtained from the John Hopkins University as mentioned above 2 .Then, daily time-series data for IFR is calculated using the imported datasets.2. Homogeneity analysis: Pettitt's test 25 was applied county-wise to check for the homogeneity in the time-series dataset of all three epidemiological parameters obtained after step 1. If the data was found to be non-homogeneous, pre and post-changepoint time series were computed and kept alongside the ‗overall' dataset, which was the only populated data column in the cases of homogenous datasets. This expanded the timeseries dataset into three aspects, i.e., pre-changepoint, post-changepoint, and overall, for J o u r n a l P r e -p r o o f Journal Pre-proof each of the three epidemiological parameters, i.e., confirmed cases, deaths, and IFR for each county.3. Trend analysis: We applied Mann Kendall's test 21, 22 to assess the trend and its nature, i.e. increasing, decreasing, or no trend, in a given time-series. Next, the trend magnitude was quantified using the Theil and Sen slope estimator test 23, 24 . Mann Kendall's, and Theil and Sen slope estimator test was performed on all three time-series computed at the end of step 2 for all three epidemiological parameters in each county.4. COVID-19 Impact ‗Score' and ‗Rank' determination: Impact Score was determined using the trend magnitude data obtained from the previous step. We used IFR as the most important parameter for assessing the impact of the COVID-19 pandemic in our algorithm 20, 26 . In the instances where IFR did not show a significant trend in a given county, we first used the deaths 26 . If the deaths did not show a significant trend either, confirmed cases were used to evaluate the impact of the pandemic 26 . Thus, rank classification occurred in three stages, each further divided according to the homogeneity results:a. On the basis of the IFR:i. In a homogeneous IFR time-series with an increasing ‗overall' trend, the county was assigned Rank 1 and its impact Score was equal to the ‗overall' trend magnitude.ii. In a non-homogeneous IFR time-series with an increasing pre-changepoint trend, the scoring and ranking were specified based on the post- i. In a homogeneous death time-series with an increasing ‗overall' trend, the county was assigned Rank 2 and its impact Score was equal to the ‗overall' trend magnitude.ii. In a non-homogeneous death time-series with an increasing pre- Every other county was classified as Rank -999 and Score -999. Finally, out of the three ranks, assigned to each county, based on the three epidemiological variables, the highest impact group (lowest rank) and its corresponding trend magnitude were decided as the final COVID-19 Impact Score and Rank for a given county.Our study methodology was built and tested in six steps ( Figure 3) . First, the trainingtesting data was prepared using the -most affected‖ and the -non-significantly‖ affected counties using the proposed ‗COVID-19 Impact Assessment' algorithm. Second, COVID-19 vulnerability map was generated using the RF machine learning technique 27, 28 . Third, vulnerability modeling was validated using Receiver Operating Characteristic (ROC)-Area Under the ROC Curve J o u r n a l P r e -p r o o f Journal Pre-proof (AUC) technique 29-31 and Cronbach's α 32 . Fourth, our C19VI modeling was comparatively assessed against the CDC's CCVI using Friedman 33 and two-tailed Wilcoxon signed rank 34 test and later, the input themes contribution to the respective vulnerability index, the output, were ranked using, and Boruta technique 35 . Fifth, C19VI was analyzed with racial minority population and poverty dataset to determine the disproportionate county-level impact of COVID-19 pandemic. Lastly, an interactive version of the C19VI map with other results was released to the public using the ESRI Web GIS customization toolkit 36 . Each step is further detailed below:1. Preparation of the training-testing dataset: Proposed ‗COVID-19 Impact Assessment' algorithm was used to map the impact of COVID-19 pandemic on all 3142 counties in the US using confirmed cases and deaths. Out of total 3142 counties, 200 very highly affected and 200 non-significantly affected counties were selected to prepare the COVID-19 vulnerability modeling training and testing dataset. 70% of the total counties (280) were randomly selected and implemented as a training dataset while rest 30% (120) were used for testing. 4. Comparison of the CCVI and C19VI: As both the CCVI and the C19VI models were developed using the same six thematic indicators, Friedman 33 and two-tailed Wilcoxon signed rank 34 statistical tests were implemented to comparatively assess model vulnerability prediction ability. Next, Boruta feature importance assessment technique 35 was used to evaluate the relative importance of input indicators in CCVI and C19VI.5. Community specific vulnerability analysis: Long-standing systemic, social and economic inequities across the counties have put many people from racial minority groups and living below the poverty line at increased risk of getting sick and dying from COVID-19 15, 16, 37 . By overlaying the C19VI map on racial minority population percentage data, COVID-19 vulnerability specific to racial minority groups were identified. As recommended by CDC, a 13% of the racial minority threshold, i.e. a given county with J o u r n a l P r e -p r o o f more than 13% racial minorities residents, was used for computing the COVID-19 vulnerability for racial minority groups 38 . Similarly, by overlaying the C19VI map on poverty percentage data, COVID-19 vulnerability specific to economically poor communities were identified. As defined by the Economic Research Service (ERS), United States Department of Agriculture (USDA) a 20% of the poverty threshold, i.e. a given county with more than 20% economically poor residents, was used to estimate the vulnerability for economically poor communities 39, 40 . ESRI ArcGIS overlay analysis tool 41 was used to conduct the community-specific vulnerability analysis. Our ‗COVID-19 Impact Assessment' algorithm performed a county-wise assessment of the pandemic using the confirmed cases, deaths and IFRs data from 22nd January 2020 to 31st J o u r n a l P r e -p r o o f July 2020. We generated a map of our assessment that groups the impact of the pandemic on all United States counties in one of the six categories (Figure 4(A) ). We found 88 counties with ‗very high', 30 with ‗high', 73 with ‗moderate', 344 with ‗low', 214 with ‗very low,' and 2393 with ‗non-significant' impact due to the COVID-19 pandemic (Figure 4(B) ). Top 200 counties with the most impact and the bottom 200 with non-significant impact were used as training and testing datasets for our COVID-19 vulnerability model.Using the impact assessment data of the selected United States counties, input themes and the RF technique, we developed COVID-19 Vulnerability Index (C19VI). Figure 5 (A) shows the C19VI map at the scale of 0 to 1. As presented in Figure 5 We used the AUC-ROC technique to validate the prediction accuracy of our C19VI model. As shown in Figure 7 The racial minority populations of the United States reside more densely in the southern states and in urban areas 17, 44, 45 . Our community-specific analysis reveals that the racial minorities disproportionately reside in counties that are more vulnerable to COVID-19 (Figure 9(A) ). We found that 77.62% counties with racial minority populations > 13%, have very high or high (CCVI > 0.60) COVID19 vulnerability. Similar to racial minorities, economically poor communities are more likely to be affected by the virus and have higher mortality rates 45 . The C19VI derived COVID-19 vulnerability with reference to poverty is presented in Figure 9 (B).We find that 82.84% of economically poor counties, where poverty > 20%, have very high or high (CCVI > 0.60) COVID-19 vulnerability. iii) heuristic modeling 52 . In addition, a few studies were conducted by performing numerical simulations of the total confirmed cases, deaths, and IFRs using statistical 47, 53 and machine learning 54 techniques to compute COVID-19 specific vulnerability. While these approaches have enhanced the domain of pandemic vulnerability modeling, they show at least one of the three underlying limitations recognized by the public health planners and policy makers that impair an optimal modeling process. Either they implement an equal weight assignment approach in vulnerability assessment, assume steady transmission rates in mathematical modeling, or treat J o u r n a l P r e -p r o o f Journal Pre-proof confirmed cases, deaths, and IFR as constants for vulnerability assessment. However, it is known that 1) not all input themes variables are equally important in determining vulnerability 49 , 2) confirmed cases, deaths, and IFR are not biological constants in a pandemic and thus, they do reflect the severity of the pandemic in a particular context, at a particular time 55 Furthermore, we optimized the dynamic characteristics of the pandemic by developing novel ‗COVID-19 Impact Assessment' algorithm, which assesses the regional pandemic impact by performing trend and homogeneity analysis on daily datasets rather than static values for a defined period. Trend and homogeneity assessments help characterize the course of the pandemic and point out the COVID-19 response through changes in healthcare infrastructure or policies in a given region by identifying subtle changes in daily datasets [21] [22] [23] [24] [25] . Moreover, besides optimization, our impact assessment algorithm also serves to enhance vulnerability modeling to be driven by the chronic disease burden, healthcare infrastructure, and policy impact such as lockdown phases.In conjunction with the optimized impact assessment algorithm, high training (90%) and testing (84%) accuracy with favorable internal reliability score (Cronbach's α = 0.709) of the RF J o u r n a l P r e -p r o o f machine learning-derived predictive modeling technique makes C19VI an accurate and reliable index. Besides, despite using the same input, our machine-learning derived C19VI produced significantly different and consistent results in contrast to the CDC's CCVI as elucidated through the Friedman and Wilcoxon signed-rank tests. Moreover, Boruta algorithm-based importance assessment of the variables for both methods show that both methods handled the variables with major notable differences. The divergence between the two methods indicates that the C19VI was able to capture non-linear relationships in the variables which were not captured with the linear ‗equal weight assignment approach' used in the CDC's CCVI model 10 .The ability of capturing non-linearity in the input variables alongside the unique characteristics of the C19VI methodology, makes the C19VI an optimal index to be considered for vulnerability assessment.Our nationwide vulnerability analysis reveals interesting patterns of vulnerability distributions around the country. We found that most of the vulnerable counties are concentrated in the southern states. As shown in the Figure 5 This index can also be used alongside other epidemiological data, such as disease transmission, infection fatality rate, the proportion of cases needing hospitalization, intensive care unit admissions, or ventilator support to heighten the preparedness of a district or state, as well as planning and executing the response. We also recommend the use of our C19VI index alongside the CDC's Social Vulnerability Index (SVI) for developing disaster risk assessment and preparedness plans in COVID-19 affected regions. For example, in the times of COVID-19 pandemic, the C19VI should be used alongside the SVI for the disaster management in counties with frequent forest fires, tornadoes or hurricanes.COVID-19 has brought previously unaddressed health disparities of racially marginalized and economically poor communities to the forefront of both disaster management officials and government concern. By overlaying the C19VI with the race and poverty data, we found that racial minorities and economically poor Americans disproportionately reside in communities that are more vulnerable to COVID-19. This finding is consistent with other evidences highlighting the disproportionate incidence of COVID-19 among minority groups and poor communities 13, 15, 37, [57] [58] [59] . The currently available county-level cases and deaths dataset, that is J o u r n a l P r e -p r o o f Journal Pre-proof segregated by minority population and economic status, is not sufficient to generate reliable COVID-19 risk estimates. The analysis proposed here provides an excellent way to help the communities that disproportionately bear the burden of this crisis, by precisely identifying these areas.Thus, the C19VI is intended to help policy makers, non-profit entities, private companies, local organizations, and the general public to improve the COVID-19 contingency planning. This index may also be useful for: i) a better management of distribution of resources; ii) addressing pandemic-associated healthcare disparities; iii) providing businesses with opportunities to grow where support is needed the most; and iv) raising public awareness of the COVID-19 pandemic.Besides, we hope that this methodology will also prove to be useful in driving more advanced predictive modeling techniques by professionals in academia.Ideally, it would be possible to calculate the index at a census-tract level. However, several important variables used to define vulnerability were not available at this level. Hence, this analysis is restricted to the county-level. Secondly, being based on the ranking of counties for CDC six themes, our C19VI is a relative index of each county rather than being an absolute score. Thirdly, we were unable to test the external validity of C19VI since no accurate and stable measure of vulnerability was available. Fourthly, the ‗COVID-19 Impact Assessment' algorithm requires to be evaluated for space and time complexity, and internal errors. We declare no competing interests. vulnerability of the racial minorities. The map shows counties with high vulnerability (C19VI > 0.6) and higher than 13% racial minorities in cobalt, low vulnerability (C19VI < 0.6) and higher than 13% racial minorities in tropical blue, high vulnerability (C19VI > 0.6) and lower than 13% racial minorities in red, and low vulnerability (C19VI < 0.6) and lower than 13% racial and higher than 20% poverty in red, low vulnerability (C19VI < 0.6) and higher than 20% poverty in pink, high vulnerability (C19VI > 0.6) and lower than 20% racial minorities in orange, and low vulnerability (C19VI < 0.6) and lower than 20% poverty in chardonnay.J o u r n a l P r e -p r o o f ",United States,abstract,2021-02-05,02
dc6f571eae7e510502523ea2f223dd74fc40d95f,Development of a new Aerosol Barrier Mask for mitigation of spread of SARS-CoV-2 and other infectious pathogens,"The three subjects involved in the test study participated voluntarily and signed informed consents.The tests were carried out by Arizona State University (ASU) researchers at Mayo Simulation Centers at Phoenix, Arizona in April 2021. The study was approved by the Institutional Review Board of Arizona State University (IRB reference protocols # STUDY00006547).The mask was redesigned and retrofit using an existing single-use mask from the Breezing Pro TM metabolic tracker. 9 The mask is equipped with two connectors as observed in Fig. 1A and B. The central coupler is an outlet port that connects to the main flow Anti-Bacterial/Viral Filter, which further connects to an appropriately designed fan to suction out the aerosols generated from the wearer (flow rate: 3.6-4.3 CFM at zero static pressure). The second connector is an oxygen port, sealed with a medical-grade adhesive, allowing the administration of medical oxygen. The mask has a comfortable and adjustable strap to hold it in position on the patient's head. The fan is powered by a 5V portable and a rechargeable battery pack, and it can be reused for multiple times.To quantify the number of aerosols, a commercial laser particle counter, Dylos DC1100 (Dylos Corporation, CA) was used. This air quality monitor detects particles between 0.5 and 2.5 microns. The monitors were installed at three distinct locations away from the subject -1.3 ft towards the left, 2 ft towards the right, and 13 ft longitudinally away (data not shown). The aerosols generated by coughing and sneezing simulations were accomplished by ten puffs with a sprayer at the subject's mouth level. The resulting concentration of aerosol particulates were studied with and without the ABM system.An infrared CO2 VacuMed analyzer, silver edition Model 17630, was used to measure the concentration of the corresponding gas accumulated by breath using the ABM. The assessments of CO2 levels were conducted in 5 different conditions:i. ABM with filter, 15 LPM of oxygen, and fan turned OFF ii.ABM with filter, 15 LPM of oxygen, and fan turned ON iii.ABM with filter, fan turned ON, with no oxygen tank iv.ABM with filter, fan turned OFF, with no oxygen tank v.It is important to note, with the absence of oxygen supply, ambient air was available to the user through the one-way inhalation valve on the mask. The data was collected using a Bluetooth Data Acquisition Module -BTH-1208LS manufactured by Measurement Computing. Measurements were taken every 5 minutes with a 1-minute interval for a total time of 30 minutes. The CO2 inhalation average and standard deviation were calculated using the acquired data set.An Aerosol Barrier Mask has been developed to prevent the spread of SARS-CoV-2 while transporting infected in-patients through hallways, elevators, and other places within hospital facilities. It has been shown that the ABM can mitigate close to a 100% of the aerosols and droplets generated by the wearer, which helps protect the individuals in proximal contact with the infected patients. Moreover, there is no carbon-dioxide accumulation inside the mask, outside the normal breathing range when the patient is administrated with oxygen. The ABM is a new alternative to help the mitigation of COVID-19.",USA,first author,2021-02-15,02
d730b5cf0ac1b4d2275e3a345413bdb958dc6de7,,"Coronavirus disease 2019 (COVID- 19) is an infectious disease which results in substantial morbidity and mortality in some population groups. By September 2020, over 32.7 million cases of COVID-19 had been confirmed worldwide, of which 90 966 were in China. 1 Prevention and treatment of COVID-19 can be expensive. According to Chinese clinical guidelines, 2,3 all confirmed cases of COVID-19 should receive inpatient care. Moreover, patients with critical COVID-19 often require costly treatment such as mechanical ventilation and extracorporeal membrane oxygenation, potentially substantially increasing health-care costs. The societal cost of COVID-19 could be even greater. To prevent disease transmission, a series of emergency measures were implemented by the Chinese government, 4 including isolation of COVID-19 cases, 14-day quarantine for close contacts of COVID-19 cases, lockdown of Wuhan city and adjacent areas, travel restrictions and extension of the Chinese New Year holiday period. While these containment strategies successfully reduced the transmission of COVID-19, 5 they inevitably caused a considerable loss in productivity.This study assessed the health and societal costs of the COVID-19 outbreak in 31 provincial-level administrative regions in mainland China.We conducted and reported our study according to the costof-illness checklist. 6 The population of interest was all residents in mainland China, which has 31 provincial-level administrative regions -22 provinces, five autonomous regions (Guangxi Zhuang, Inner Mongolia, Ningxia Hui, Tibet and Xinjiang Uyghur) and four municipalities (Beijing, Chongqing, Shanghai and Tianjin). We divided the population into four mutually exclusive patient subgroups, based on their experience of COVID-19: (i) asymptomatic close contacts of suspected or confirmed cases of COVID-19, who were eventually diagnosed as COVID-19 negative; (ii) symptomatic suspected cases with or without close contact history with existing suspected or confirmed cases, who were eventually diagnosed as COVID-19 negative; (iii) confirmed cases of COVID-19, including those previously assessed as close contacts or suspected cases; and (iv) people not considered to have been exposed to COVID-19. We further divided confirmed cases into non-severe, severe and critical COVID-19, according to the disease severity (Box 1). Fig. 1 shows the diagnostic and treatment pathway for each patient subgroup; also described in the data repository. 8We estimated direct health-care costs, direct non-health-care cost and productivity losses for each region and for mainland China as a whole (Box 2). We calculated all costs in Chinese yuan (¥) at the 2019 value and converted to United States dollars (US$) using the annual exchange rate for 2019: US$ 1.00 = ¥ 6.91. 9Although COVID-19 was first identified in China in December 2019, 99.96% (74 648/74 675) of confirmed cases were identified in January and February 2020. 10 From 6 March 2020, the number of new cases a day fell below 100, and no new cases were identified in 29 regions. Therefore, we calculated costs for the period from 1 January to 31 March 2020.There are two approaches to estimate the cost of illness: the bottom-up approach and the top-down approach. 6 The bottom-up approach multiplies the average cost of the illness per patient by the prevalence of the illness. The topdown approach uses aggregated data and a population-attributable fraction to assign a percentage of total expenditure to the disease of interest. Because published total expenditure on COVID-19 was lacking (details in the data repository), 8 we used the bottom-up approach. We estimated unit costs, p x , at the patient or individual level for each component, x, of the overall burden of disease. We calculated the overall cost, C, as:where i x is the number of individuals affected.Over the period of interest, the National Health Commission of the People's Republic of China published national data on COVID-19 daily. 11 However, detailed regional information was only published for Hubei province. Therefore, we manually extracted the number of newly identified close contacts, suspected cases and confirmed cases in each region from the daily updates reported by the local health commission of each region (details in the data repository). 8 While all regions reported complete data for the number of confirmed cases and the numbers of deaths of confirmed cases, data were incomplete for the number of close contacts and/or suspected cases. We estimated these missing data either from published reports, or from the reported regional number of confirmed cases, 11 assuming the same ratio between the number of close contacts or suspected cases and confirmed cases across regions.We used information in the published literature 12, 13 and clinical guidelines, 2,3 supplemented with expert opinion where necessary, to estimate the healthcare resources used for close contacts, suspected cases and confirmed cases. Shanghai is one of the few regions in China which reports full unit cost data. 14 To calculate the unit costs for other regions, we calculated a health-care industry salary index (details in the data repository). 8 We calculated a weight (w r ) for each region as:where s r is the ratio of the average health-care industry salary in the region and s s is the average health-care industry salary in Shanghai. 15 We then estimated regional unit costs (p r ) as:where p s is the unit costs derived from Shanghai. 14 According to the State Council, 42 600 front-line health professionals worked with suspected and/or con-Box 1. Definition of close contacts, suspected cases and confirmed cases of COVID-19, China, 2020An asymptomatic person who has had close (less than 1 m), unprotected (without personal protective equipment) contact with suspected cases or confirmed cases (see definitions below), 2 or fewer days before the onset of their symptoms.A person who has one epidemiological history criteria and meets two clinical symptoms criteria, or has no epidemiological history but meets all three clinical symptoms criteria.• Epidemiological history. Fourteen days before the onset of the disease, the person has: (i) travelled to or lived in a high-risk region or country; or (ii) had direct contact with confirmed cases (definition below); or (iii) had direct contact with someone with a fever or respiratory symptoms in a high-risk region or country; or (iv) been to a place with disease clustering -defined as two or more cases with fever and/or respiratory symptoms occurring at places such as homes, offices and school classrooms.• Clinical symptoms. The person has: (i) a fever and/or respiratory symptoms; (ii) the following imaging features of COVID-19 after computerized tomography of their chest -multiple patchy shadows and interstitial changes, particularly at the periphery of the lungs, multiple groundglass opacities and infiltrates in both lungs, or in severe cases, lung consolidation and pleural effusion; (iii) normal or decreased white blood cell count in the early stage of the disease, or normal or decreased lymphocyte count over time.A suspected case that meets one of the following criteria: (i) positive result of the nucleic acid test for SARS-CoV-2; (ii) DNA sequencing results indicating high sequence similarity to known SARS-CoV-2 sequences; (iii) positive result for the serum-specific antibodies (IgM and IgG) of COVID-19. Severity of disease in confirmed cases is categorized as follows.• Non-severe cases: mild cases (mild clinical symptoms with no signs of pneumonia on imaging) and moderate cases (symptoms such as fever and respiratory tract symptoms, and signs of pneumonia on imaging 16 The daily risk subsidy for front-line health professionals was estimated to be ¥ 300.00 per person. 17 We estimated the emergency funds (for construction of temporary emergency buildings and non-routine procurement of additional medical supplies and equipment) based on the budget plans of the Ministry of Finance and the National Development and Reform Commission (data repository). 8 For reusable equipment, we only included the cost attributable to the 3-month period of the study in our analysis. Calculations and results for emergency funds are in the data repository. 8We estimated a daily cost of quarantine in Shanghai to be ¥ 75.00 (US$ 10.85), assuming that 50.0% of people quarantined at home at zero cost and 50.0% quarantined at a designated centre at the cost of ¥ 150.00 (US$ 21.71) a day. We calculated the regional quarantine costs per person (QC re ) per person by category of exposure (e), as:where w r is the regional weight described earlier and d e is the estimated duration of quarantine.The average cost of quarantine for close contacts and suspected cases was ¥ 1246.00 (US$ 180.32) and ¥ 735.00 (US$ 106.37) per person, respectively. We calculated the overall cost of quarantine (TQC) as:TQC n r e re = × ∑ ∑ (5) where n re is the number of people quarantined by region (r) and exposure (e) category. Details on methods and results are in the data repository. 8We used the human capital approach to estimate productivity losses. For people not considered to have been exposed to COVID-19, we calculated costs by region (CP r ) as:where i r is the mean daily wage rate by region, f is the proportion of the population in employment, h r is the mean number of days lost by region, and q r is the regional population. We obtained regional employment statistics from the China Statistical Yearbook 2019. 15 The national average daily wage was ¥ 271.94 (US$ 39.35), ranging from ¥ 204.67 (US$ 29.62) in Heilongjiang province to ¥ 486.43 (US$ 70.40) in Beijing. The national unemployment rate was 3.0%, ranging from 1.4% in Beijing to 4.0% in Heilongjiang province. Data were not available on the employment status for close contacts, suspected cases and confirmed cases. Therefore, we estimated the employment rate, f, for each patient subgroup at 54.0% based on the age and sex distribution of confirmed cases, the legal working age (16 years) and official retirement age (60 years for men and 50 years for women), and the national unemployment rate (3.0%). Employment rate calculations are in the data repository. 8 We estimated the average number of working days lost due to restrictions on movement for people not considered to have contracted COVID-19 as 23.26 days, based on the Baidu migration index, 18, 19 which tracks the proportion of workers returning from their hometowns to work after the Chinese New Year holiday. Close contacts, suspected cases and confirmed cases may have experienced more working days lost due to their quarantine and/or hospitalization. 12, 13, 20 Working days lost for these people depended on the start and end date of their quarantine and/or hospitalization, and whether these dates overlapped with the extended Chinese New Year holiday and the study period. We limited productivity losses from COVID-19 deaths to the study period in the base case analysis. Calculations of the working days lost for each patient subgroup are in the data repository. 8To determine which parameters were key cost drivers we conducted a sensitivity analysis. We identified costs that contributed to 10.0% or more of the total health-care costs and societal costs and varied the parameters for use of resources and unit cost. We used available data or our judgement to inform the ranges for the selected parameters.During the study period, there were 707 913 close contacts, 126 032 suspected cases and 81 879 confirmed cases in mainland China (Table 1) Table 2 shows the health-care cost per person for each patient subgroup, based on the estimated use of resources and the unit costs from Shanghai. 15 The health-care cost of managing close contacts and suspected cases diagnosedRoutine health care: identification, diagnosis, treatment and follow-up of people with suspected or confirmed COVID-19. Non-routine health care: (i) risk subsidy for front-line health professionals who work with suspected and/or confirmed cases; and (ii) emergency funds for construction of temporary emergency buildings (i.e. Huoshenshan and Leishenshan hospitals, and Wuhan mobile cabin hospital), and non-routine procurement of additional medical supplies and equipment (e.g. personal protective equipment).Compulsory quarantine for close contacts and suspected cases. The quarantine cost can be covered by the local government, or by the quarantined individual, or jointly, depending on local policies.These losses include: (i) employed close contacts, suspected cases or confirmed cases who lost work time due to their quarantine and/or inpatient care; and (ii) any employed individuals who lost work time due to government policies controlling population movement (these individuals include people not considered to have had COVID-19). 8 We calculated costs of routine health-care services, quarantine and productivity losses, and total healthcare and societal costs ( 8 For the confirmed cases, we assumed that 45% of them were identified from close contacts, whilst 55% were identified from suspected cases. Therefore, the cost of identification and diagnosis for all confirmed cases was calculated as the multiplication of the cost per case and 0.45 for close contacts and 0.55 for suspected cases. Fig. 2 and Fig. 3 show the health-care cost and societal cost for each region, respectively. The health-care cost for Hubei province alone accounted for 66.7% (¥ 2.84 billion/¥ 4.26 billion) of the national health-care cost (Fig. 2) . Guangdong province incurred the highest societal cost, followed by Jiangsu province and Beijing (Fig. 3) .The results of the sensitivity analyses are reported in the data repository. 8 The direct health-care cost was most sensitive to the proportion of confirmed cases with severe or critical disease, and the health-care cost per person for treating severe and critical cases. The cost of the loss in productivity was most sensitive to the number of working days lost for people not considered to have had COVID-19, the national average daily salary, and assumptions on the effect of movement restriction policies on worker productivity.We estimated the health-care and societal costs associated with the COVID-19 outbreak in China for the first 3 months of 2020 to be ¥ 4.26 billion (US$ 0.62 billion) and ¥ 2646.70 billion (US$ 383.03 billion), respectively. Although the health-care cost per person for con- Includes risk subsidy for health-care staff and emergency funds for construction of temporary emergency buildings and non-routine procurement of additional medical supplies and equipment. c Column total. We could not assign the cost of non-routine health care to any specific individual patient group so we only report the total cost of non-routine health care in the last column; therefore, the cost of non-routine health care is not reflected in the total societal cost for each patient subgroup (last row).Cost of COVID-19, China Huajie Jin et al.firmed cases was high, 99.9% of the societal cost was attributable to productivity losses in people not considered to have had COVID-19. These findings reflect the overall number of employed people in China (416.5 million), which is much larger than the number of confirmed cases (81 879 cases). Our estimated cost of productivity losses -¥ 2641.61 billion (US$ 382.29 billion) -is comparable to the decrease in the Chinese GDP for the first quarter of 2020 compared with the same period in 2019: ¥ 1506.68 billion (US$ 218.04 billion). 22 Hubei province, where most confirmed cases were identified, accounted for two thirds of the national health-care cost. The productivity loss was greatest for those regions with the highest number of employed people and/or the highest daily salary, such as Guangdong province (57.7 million employed people, ¥ 296.37, US$ 42.89, daily salary), Jiangsu province (42. We did not identify any cost-ofillness studies for COVID-19 in our rapid review of the literature. Evidence on cost of illness is available for severe acute respiratory syndrome (SARS). [23] [24] [25] [26] [27] To facilitate comparison of results, we inflated costs from the literature to 2019 values using a local consumer price index and converted to US$ using the annual exchange rate. 28 Three studies [23] [24] [25] reported the cost of managing patients with SARS; the health-care cost per case ranged from US$ 4151.00 in mainland China 24 to US$ 362 700.00 in Canada. 23 29 Another study used a simulation model to estimate the societal cost of SARS in 30 countries. 30 The cost in mainland China was 1.03% (¥ 0.12 trillion/¥ 11.69 trillion) of GDP, 30 which is comparable to our estimate of the societal cost of COVID-19 (2.7% of China's GDP in 2019). 22 The societal cost of COVID-19 is substantial and greatly outweighs the health-care cost. Our analysis, which demonstrates the effect of COVID-19 beyond the health-care system, justifies the redirection of resources from other sectors of the economy to strengthen health systems, as the potential productivity losses caused by a pandemic may far exceed the health-care cost. Despite a lack of evidence on their cost-effectiveness, unprecedented controls on people's movements and ability to work have been imposed in several countries in an attempt to reduce the spread of COVID-19. Future work will examine the cost-effectiveness of these policies. Our data can help inform these analyses by providing the cost of identifying, diagnosing and treating patients with suspected or confirmed COVID-19. Our analysis underlines the importance of action to strengthen health systems, particularly the capacity to test for infection and trace contacts, which has been identified as one of the most cost-effective policy responses. 31 Effective disease mitigation action will require international cooperation and considerable investment. Underinvestment in strengthening the capacity of health systems to tackle future pandemics could prove to be far costlier than the additional investment required.Our study has several strengths. This study fills an important evidence gap by presenting the first cost-of-illness study of COVID-19. The study identified the cost of the COVID-19 pandemic in different sectors of the economy; such data are necessary to inform planning of services and the prioritization of research. Our data also provide important information for future economic evaluations of interventions for CO-VID-19. We accessed detailed data on use of resources in the 31 regions of mainland China, including incidence of close contacts, suspected cases and confirmed cases, from the local health commission of each region. We applied unit cost data adjusted to reflect relative price differences across provinces, and used clinician input from Shanghai and Hubei province to check the use of resources for each subgroup (close contacts, suspected and confirmed cases). We estimated productivity costs for close contacts, suspected cases and confirmed cases based on the duration of quarantine and/or treatment, and regional migration patterns after the end of the extended Chinese New Year holiday period.Our analysis also has some limitations. First, we only covered the first 3 months of the epidemic and there-fore could not capture the long-term economic effects of COVID-19. Future research is needed to assess the longterm economic impact of COVID-19 on the health-care system (e.g. for management of chronic diseases) and on society (e.g. reduced international trade and increased unemployment rates). Second, due to a lack of data, we could not include some cost components, such as productivity losses for carers of suspected and confirmed cases and out-of-pocket payments for travel to hospitals and over-the-counter medicines. Third, because of a shortage of nucleic acid tests in China in January 2020, not all patients suspected of having COVID-19 were tested. 3 Therefore, the reported number of confirmed cases is likely to be an underestimate, especially in Hubei province. Fourth, our estimate of the number of working days lost, which we based on migration data, may have overestimated losses for people who worked from home. Fifth, we lacked some data on the incidence, demographic information and prognosis for close contacts and suspected cases, and had to estimate these data based on published literature and/or expert opinion. Finally, some positive effects of the restrictive measurements have been reported, such as reductions in crime rates, 32 environmental improvements 33 and a rapid increase in e-commerce. 34 Analysis of the effects of these factors was beyond the scope of our study.The results of our study highlight the substantial economic burden of the COVID-19 outbreak. Research is needed on the cost-effectiveness of different policies to control infectious diseases and developing capacity to limit the spread of disease while minimizing the impact on everyday life. ■ Carga económica de la COVID-19 en China entre los meses de enero-marzo de 2020: estudio del coste de la enfermedad Objetivo Estimar el coste económico de la enfermedad coronavirus-19 (COVID-19) en 31 regiones administrativas a nivel provincial y en su totalidad en China. Métodos Utilizamos los datos de los informes del gobierno, las guías clínicas y otras publicaciones para estimar los principales componentes del coste de la COVID-19 desde el 1 de enero al 31 de marzo de 2020. Estos componentes fueron: identificación y diagnóstico de contactos cercanos; casos sospechosos y casos confirmados de COVID-19; tratamiento de los casos de COVID-19; cuarentena obligatoria de contactos cercanos y casos sospechosos; y pérdidas de productividad para todos los residentes afectados. El principal resultado fue los costes totales de la atención sanitaria y de la sociedad. Resultados El total estimado de los costes de atención sanitaria y de la sociedad asociados con la COVID-19 fue de 4.260 millones de yuanes chinos (¥; 0,62 mil millones de dólares estadounidenses) y 2.646,70 mil millones de yuanes (383,02 mil millones de dólares estadounidenses), respectivamente. La atención hospitalaria representó el 44,2% (0,95 mil millones/2,15 mil millones de yenes) de los costes de la atención sanitaria rutinaria, seguida de los medicamentos, que representaron el 32,5% (0,70 mil millones/2,15 mil millones de yenes). Las pérdidas de productividad representaron el 99,8% (2.641,61 mil millones/2.646,70 mil millones de yenes) de los costes de la sociedad, que se atribuyeron principalmente al efecto de las políticas de restricción de movimientos en las personas que no tenían COVID-19. Los costes sociales fueron más sensibles a los costes salariales y al número de días de trabajo perdidos debido a las políticas de restricción de movimiento. La provincia de Hubei tenía el mayor coste de atención sanitaria, mientras que la provincia de Guangdong tenía el mayor coste social. Conclusión Nuestros resultados destacan la alta carga económica del brote de COVID-19 en China. Las medidas de control para evitar la propagación de la enfermedad dieron lugar a costes sustanciales por pérdidas de productividad que ascendieron al 2,7% (382,29 mil millones de dólares estadounidenses/14,14 millones de millones de dólares estadounidenses) del producto interno bruto anual de China.",United States,abstract,2021-02-01,02
4956e2891b7d307f74ae14a7f80a18dbe48e4271,,"The COVID-19 pandemic has swept the globe, but its differential impacts among racialized and marginalized immigrant populations have brought deeply rooted inequities to the forefront. Racialization continues to ensure that the identities of immigrants within social structures and institutions are defined by their race, leading to severe inequities among immigrants of colour [1] . Increasing evidence has shown that outbreaks in settings such as farms, meat processing plants and residential and long-term care centres, where racialized im/migrants are overrepresented, has perpetuated a disproportionate burden of COVID-19 transmission for these groups [2, 3] . We use the term ""im/migrant"" to include all immigrants and migrants, including refugees, asylum seekers, and undocumented persons. Lower income im/migrant communities may also be worst affected by lockdowns and restrictive measures, face less opportunity to physically distance or stay home sick within 'essential' jobs, and are known to face severe barriers to healthcare [3] . The insufficient attention to experiences of racialized im/migrants in policy responses during COVID-19, including government benefits, occupational environments, and public health, highlights an urgent need to more fulsomely address these unmet needs. Given the current need for rapid data in order to inform pandemic responses and growing evidence of inequities in COVID-19 transmission and impacts among racialized im/migrant communities, this commentary highlights the need for public health training, research, and policy to better prioritize and address inequities among racialized im/migrants.COVID-19 has further exposed inequitable health outcomes faced by racialized im/migrants globally Global pandemic responses have neglected im/migrants by continuing to ignore or at best, insufficiently address inequities, exacerbating COVID transmission, xenophobia, racism, and occupational injustice [4] . Xenophobic immigration policies demonstrate the ways in which communities without or who are seeking immigration status find themselves deemed 'unworthy' of protection and basic human rights. Deaths, illness, stress, and other negative consequences of overlapping issues of COVID-19 and precarious im/migration status highlight the tangible, life-threatening manifestation of these inequities, perpetuating structural racism. Worse yet, dominant public health interventions (e.g., sweeping 'lockdowns') may reinforce inequities by privileging more advantaged groupsfor example, those who are able to work remotely, access private childcare during school closures, and engage in virtual services [5] while failing to sufficiently adopt strategies that support more marginalized populations.These inequities manifest across diverse settings. Despite portrayals of Canada as a setting of universal healthcare and inclusion, racialized immigrants with and without status face stark health and social inequities prior to and during COVID-19, including racial profiling by police, inabilities to meet basic needs, and barriers to healthcare [3] . Im/migrants working in care centres, healthcare settings, and farms are heavily overrepresented among COVID-19 cases. Migrant farmworkers in particular have reported coercion into unsafe work environments and threats of deportation, alongside other rights violations (e.g., termination based on country of origin) [2] . Lockdowns in India have forced 100 million migrant workers into unemployment, where many have fled to home communities by foot and died from hunger and exhaustion [6] . Despite being called upon by the United Nations to protect migrants' rights, the government's inaction continues to exacerbate poverty, police brutality and COVID-19 stigma among workers [6] . Germany's recent global health strategy effectively excluded refugees and asylum seekers from their pandemic response, contributing to several outbreaks among im/ migrant populations [7] . Meanwhile, in the United States, Customs and Border Patrol continues to discriminately deport asylum seekers and incarcerate im/migrant children and families in crowded and unsafe detention centres, in direct violation of national and global policies and human rights standards [8] . These examples highlight the urgent need to shift the gaze of public health to prioritize and address the deep-rooted and alarming crisis currently being faced by im/migrant communities across diverse high, middle, and lowincome contexts during COVID-19.As evidence mounts about how racialized immigrants have been left behind in times of crises, there is a need to sharpen public health decision-making and evidence with intentional considerations of equity and social justice. Alongside crucially needed biomedical work including COVID-19 testing and vaccine development, there is a need to address deep inequities being produced and exacerbated by the COVID-19 pandemic by examining and pursuing structural interventions that are necessary to mitigate these impacts [5] . In the context of im/migrant health equity, research identifying patterns and harms of xenophobic policy, structural racism, and white supremacy [9] in shaping im/migrant health outcomes during and beyond COVID-19 is needed. Research and structural interventions must address equity and structural racism, and be sufficiently tailored to pandemic phases and community contexts. Areas of urgently needed focus may include occupational protections (e.g., sick pay, ability to physically distance), healthcare and social protection schemes available to all residents regardless of im/migration status, training for public health practitioners and clinicians focused on anti-racist, culturally tailored approaches, and decarceration in jails, prisons, and immigration detention.Finally, there is a need to strengthen anti-racist and equity-oriented curriculum within health education, and ensure sufficient attention to the needs of im/migrant communities within public health, clinical, and research training. This includes addressing the severe structural challenges faced by international students across settings during the pandemic; [9] during COVID-19, this has involved learning across time zones, experiencing family separation, navigating financial difficulties, and facing racism, xenophobia, and fear associated with im/migration status, [10] as demonstrated by the recent U.S. policy proposal to force international students to return to their countries of origin for programmes shifted solely online.The COVID-19 pandemic has exacerbated and rendered more visible the deeply rooted health and social inequities faced by racialized im/migrants across diverse settings. In this commentary, we argue for a greater emphasis on equity-focused and anti-racist im/migrant health research, interventions, and training. Policymakers and practitioners have a responsibility to ensure that healthcare policies and practices do not exacerbate inequities, and instead meaningfully address unmet needs of communities, including racialized im/migrants. Ethical and respectful community engagement is critical for achieving this. To fulsomely advance equity-focused research and interventions, deep commitment and collaboration with global, national, and local communities, policymakers, academics, and educators, as well as accountability across sectors, is needed.",Canada,first author,2021-02-08,02
b8ea1c9aa83b2919ce15cdb2b5e92c0edba383c4,0123456789) 1 3 Health and Technology,"COVID-19 is an acute respiratory disease considered the third documented propagation of an animal coronavirus in humans [1, 2] . This virus has become a pandemic with severe clinical manifestations. In the current situation, 98 794 942 people are infected, and it has responsible for 2 124 193 deaths around the world as reported by World Health Organization on 25 January 2021 [3] . This largescale pandemic imposes extraordinary demands on the world's health systems, attacks vulnerable populations, and threatens global communities in an unprecedented way [4] . Researchers are working hard to detect the virus, provide treatments, and develop vaccines [5] .However, the technologies and systems to address disease emergence, stop its propagation and prevent disease are vitally important [6, 7] .Telemedicine and eHealth represent the contribution of a new technology that combines the exchange of knowledge between health professionals and gives patients access to quality services [8] . Its applications improve the availability of various medical services and health care despite geographic and economic barriers such as home health control, ensuring that elderly patients can lead independent lives and reducing direct and indirect costs. They also help patients with minor diseases to get the supportive care they need while minimizing their exposure to other patients with acute conditions [9, 10] .Telemedicine has become a critical technology for providing medical care to patients by trying to reduce transmission of the virus among patients, families, and doctors. In the case of hospitals, strict limitations on visitors have meant that some consultation programs of palliative care for inpatient are doing family meetings and consultations virtually [11] . Using eHealth apps helps to mitigate the propagation of COVID-19 and preserve the lives of medical personnel. The use of virtual platforms for medical care reduces the saturation of emergency patients during the pandemic [12, 13] . These virtual platforms can be used by smartphones or webcam computers and allow clinicians to effectively detect patients with early signs of COVID-19 before they arrive at the hospital [14, 15] .The economic consequences of coronavirus have affected the entire world and disrupted daily life in many countries. The development of telemedicine applications and eHealth services can significantly help to manage pandemic worldwide better [16] . Hence, in this study, we present a systematic review of the literature regarding the current situation on telemedicine and mobile health applications to face the current pandemic scenario. Therefore, the main objective of this paper is to present a systematic review of the application of telemedicine and e-health systems to combat COVID-19. Furthermore, the main contribution of this paper is to present a comprehensive description of the state of the art in this field considering the domain areas, organizations, funding agencies, researcher units and authors involved.The paper has the following structure: Section 2 describes the methods applied in the review. Section 3 states the results of the relevant articles found. Finally, in Sect. 4, the results achieved are discussed, and in Sect. 5, the conclusions of this paper are presented.The proposed literature review aims to present a systematic information extraction from the application of mobile health applications regarding the current pandemic public challenge of COVID-19. This systematic review has been conducted on 15/5/2020, and the papers have been selected by common agreement of all authors. Taking into account the proliferation of a high number of publications regarding this topic as preprints or in non-indexed journals and conferences, this paper reviews the documents published in peer-reviewed journals indexed in the journal citation reports (JCR). This indexation is considered as the most relevant index available. Moreover, the Web of Science database includes the most relevant journals of the most reputable publishers.Furthermore, the authors aim to find the common objectives, outcomes and limitations of the applications of mobile health to face the current pandemic scenario. A biometric analysis is conducted to make a summary about the countries, regions, domains and authors who are employing mobile health solutions to promote health and well-being and combat the critical new virus.The methods used in this literature review includes multiple steps that start with the definition of the keywords used to search the relevant papers. Second, the research objectives have been formulated. Consequently, the extracted documents from the Web of Science selection have been selected based on the title and abstract. The relevant studies have been selected for full review, and several have been excluded since do not meet the inclusion criteria. The final selection of papers that met the selection criteria have been analysed for data extraction.This review aims to serve as a first situation report about the most recent mobile health applications to face the current pandemic scenario. Therefore, the authors want to answer the following research questions that will support the ongoing research activities in the mobile health domain:• RQ1: What are the different areas of research that are proposing the use of telemedicine systems regarding the current pandemic scenario? • RQ2: Which are the organizations and institutions that are working in this field? • RQ3: Which are the funding agencies that are supporting the current research in this field? • RQ4: Who are the top authors involved in the development of telemedicine in the current pandemic scenario?• RQ5: Where is the location of the studies about the application of telemedicine concerning the current pandemic scenario?The current pandemic scenario has shown the crucial importance of cross-domain research and the application of mobile health. Furthermore, the present situation brings together researchers from multiple fields that joint efforts to combat COVID-19. Mobile health includes two major domain fields, such as computer science and medical field. The high proliferation of non-peer-reviewed papers concerning the current pandemic scenario is evident. However, there is a critical problem emergence from the spread of non-validated results that can also provide fake and limited outcomes for further research activities. Therefore, this systematic literature review only considers the most reputable journals included in JCR. Moreover, the authors only consider the articles and do not have regarded as other document types such as editorial material and letters. Since the objective is to analyse the mobile health initiatives, the review papers have also been removed from our analysis. These search queries have been selected by the authors and applied in the web of science database from Clarivate Analytics. The defined keywords are ""coronavirus"", COVID-19"", ""SARS-CoV-2″, ""telemedicine"", ""eHealth"", ""telehealth"", ""mobile health"", and ""mHeatlh"". Consequently, the search string used is: ((coronavirus or COVID-19 or SARS-CoV-2) and (telemedicine or eHealth or Telehealth or mHeatlh or mobile health)). This research has been applied, considering all the document fields. The search query has been applied in on 15th May 2020.The inclusion criteria defined by the authors were divided into five requirements such as 1) the paper has been published after 2020; 2) the included documents are articles; 3) the selected papers propose the application of mobile health regarding the current pandemic scenario, 4) the paper is indexed in a peer-reviewed journal included in the JCR, and 5) the study does not include only a recommendation of mobile health technologies.The search query has initially returned 85 publications. After applying the inclusion criteria, 1) the results have been reduced to 74. The inclusion criteria two have limited the considered papers to 48 since 15 are editorial material, 8 letters and 3 reviews. Furthermore, 5 documents have been removed since they do not meet the inclusion criteria 4, resulting in 43 papers. Following the abstract and title analysis, 20 papers have been removed. Finally, after full review, 4 articles have been excluded since they according to the inclusion criteria 5. The PRISMA diagram is presented in Fig. 1 .Nowadays, many countries have successfully integrated telemedicine and advanced technologies into a wide range of healthcare processes including diagnosis, disease prevention, treatment and health research. The benefits of using these telemedicine and eHealth technologies in epidemics such as the current COVID-19, allow helping patients with chronic diseases who need follow-up and medical attention, reducing their exposure in hospital centres.In this systematic review, we found a total of 19 relevant studies that base their research on the analysis of the current situation on mobile health applications to face the present pandemic scenario.Due to the social isolation that the COVID-19 pandemic has generated, different studies focus on using telemedicine to support patients who need medical and psychological help. In [17] , the authors implement a process of multidisciplinary telemedicine clinics to preserve the care model for patients with cystic fibrosis. The study was performed at the University of Virginia, with a total of 63 patients. The results achieved show that the multidisciplinary team attended 60% of patients through telemedicine. This systematic process of design and testing demonstrates that through telemedicine, viable and sustainable programs can be created and adapted to the context.In [18] , the authors show the importance of eHealth to avoid depression in patients who feel alone and maintain their life quality during serious diseases. They describe patient participation in healthcare at the individual and organizational level when it comes to eHealth urgent solutions for COVID-19. Based on case histories in public media in which patients and families share their experiences during isolation and quarantine with the virus. They analysed a list of 8 functionalities of eHealth tools in an eHealth centre in Denmark during COVID-19, demonstrating that for 7 features, patient participation can be an essential element that improves the meaning of the tool, to ensure compliance and adherence, and integrating needs.In [19] , the authors analyse the importance of telehealth applied to Mental Health. They highlight the use of telemedicine as a valuable way of meeting the physical and psychosocial needs of patients, independently of their geographical location. The main challenge that the authors describe is to provide mental health services in the context of patient isolation, highlighting the telehealth role through videoconference, email and smartphone applications. They show how the use of telehealth systems allows sharing information on symptoms of exhaustion, depression and anxiety during the COVID-19, offer the cognitive ability, treat minor symptoms, and encourage access to online self-help programs.A complementary and effective strategy to slow the virus propagation and reduce the impact is to track the primary and secondary contacts of COVID-19 confirmed cases using tracking technology. For this reason, in [20] , the authors present an exploratory review of the current measures implemented in the world to trace contacts of cases confirmed by COVID-19 and propose recommendations on how Nigeria can adopt this approach while adhering to the guidelines provided by the National Data Protection Regulations (NDPR). The study shows that mobile phone location data can be used effectively in Nigeria in response to COVID-19. Furthermore, the authors suggest that the government can take advantage of existing mobile technologies and infrastructure available to optimize the monitoring and surveillance of ongoing contacts of more than 9000 known contacts of confirmed cases. Moreover, taking into account the NDPR for protecting people's data and avoid a violation of privacy right.On the other hand, the use of videoconferencing platforms has been of great help in providing training to health personnel facing the COVID-19. The authors of [21] propose the application of the Kirkpatrick model in a training program for nurses. This application has been conducted at the department of emergency surgery during COVID-19 pandemic in China. The study includes 35 nurses who were trained according to the clinical program during the epidemic. The application of the Kirkpatrick model based on the clinical market during COVID-19 confirms that it is useful for the nurse training program of the emergency surgery department. Improving nurse knowledge and skills during the pandemic is also beneficial, serving as a positive influence on the clinical reference. In [22] , the authors analyse the effect of applying the combined mode of the micro-video of Massive Open Online Course (MOOC) during the epidemic period COVID-19 in the practice of distance teaching of interns in the emergency department. The study involved 60 interns in nursing practices at Tongji Hospital, China. The results show that compared to traditional teaching methods, the effect of the combined mode of micro-video MOOC in nursing practice is the same as that of conventional teaching methods. Still, satisfaction is more significant, so it is best suited to be used in nursing practice during the epidemic period of COVID-19, to reduce cross-infection among doctors effectively, nurses and teaching personnel.In [23] , the authors provide orientation for researchers transitioning from in-person evaluations and interventions to a synchronous videoconferencing platform. They show the challenges to consider for the implementation of videoconferencing, such as the development of protocols. These protocols will simplify the process and help reduce unexpected problems. Protocols for facilitators and personnel should include standards to promote data privacy and confidentiality. In this way, the transition to videoconferencing can help ensure continuity of research and to benefit from potentially meaningful social interaction during isolation time.Part of the relevant studies found in the review focus on analyzing the use of telemedicine and eHealth to face pandemics such as COVID-19. In the study [24] , the authors propose hospitalization services for patients with neurological diseases through teleconferencing platforms at the Medical University of South Carolina. Medical records are completed remotely by all team members as well as virtual ""table rounds,"" and academic discussions are concluded via the teleconferencing platform each morning before clinical rounds. In this way, they can optimize the use of telehealth services in neurology and significantly help reduce virus propagation.In [25] , the authors analyse the benefits of using telehealth technology in previous epidemics and how they can influence the management of COVID-19. The authors show that to control the rapid propagation of coronavirus better and manage the COVID-19 crisis, both developed and developing countries can improve the efficiency of their health system by replacing a proportion of clinical patient encounters with a telehealth system. Hence, providing therapeutic diagnostic and follow-up services for patients with COVID-19 through telemedicine may be the right solution.In [26] , the authors show telemedicine in Italy under the management of COVID-19. The authors state a limited availability of telemedicine systems to manage locked-up patients with chronic diseases. In recent years, health authorities have ignored requests from various experts and professionals in the sector for the efficient implementation and integration of telemedicine services in the national health system. The authors show that telemedicine should not be considered as a possible option or complement to react to an emergency, but as a proactive approach to guarantee continuity of care for patients suffering from chronic diseases.The authors of [27] present a mobile telehealth system (MTS) applied to facilitate the presentation of patient information and the discussion of cases among professionals. The MTS provides epidemiological medical personnel members with a concise interface and tracks patient information, which is stored on the hospital intranet and uses five modules to display patient information. The system uses mobile collaboration technology to present patient information and support case discussion, thus providing benefits for professionals and reducing physical contact. In [28] , the authors explore the role of Internet hospitals in the prevention and control of the COVID-19 epidemic in China. A total of 4913 online queries related to the pandemic were collected. The results show that 94.20% (n = 4628) of the consulted patients had symptoms related to the epidemic with a distribution similar to COVID-19. These hospitals have enabled essential medical support to the public during the pandemic, reduce social panic, promote social distancing and enhance the public's self-protection capacity.In the study [29] , the authors implement an online/offline multidisciplinary quarantine observation model for epidemic prevention and control, analyzing the successful recovery of a mild and severe patient. The model allowed medical experts to monitor disease progression in both and the treatment of patients that ultimately resulted in a successful recovery. This model applies to the current COVID-19 epidemic and can actively promote the management of mild suspected or confirmed cases, the monitoring of critical incidents and self-management of discharged patients.The essential requirements to ensure the use of telemedicine systems in COVID-19 pandemic are discussed in [30] . The authors show the benefits of telemedicine by highlighting its ability to quickly deploy a large number of providers, deliver medical services when local clinics or hospitals are damaged or cannot meet demand; and decrease the risk of contagious diseases by contact.In [31] , the authors describe the implementation of capabilities by UW Medicine Information Technology Services (ITS) to support the clinical response to the COVID-19 pandemic and provide recommendations for consideration by the Health systems. They analyze the management of control processes to quickly update Electronic Health Records (EHR) with new clinical and laboratory workflows. Therefore, the authors' recommendations include establishing a hospital incident command structure that provides for close integration with IT, optimize emergency communication for personnel and patients, preparing human resources, security and equipment to support the transition of all staff not essential for teleworking.In the study [32] , the authors review the transition from a new LGBTQ clinic to telemedicine and the implications for providing HIV prevention and care services during COVID-19. Open Door Health (ODH) is the first clinic dedicated to providing primary and sexual healthcare to the LGBTQ community in Rhode Island. It offers phone calls when patients have technological challenges with videoconferencing and completes pre-appointment documentation on the patient portal with electronic medical records. Moreover, this provider includes consent forms, demographic information, and social and medical histories. Both patients and providers report high levels of satisfaction with telemedicine, and providers can overcome most obstacles in providing clinical services.In countries such as Afghanistan where war and social conflict have been going on for many years, the use of telemedicine platforms would allow better management of the COVID-19 pandemic [33] . Healthcare workers need consultation and support on a global scale, creating small consultation networks using mobile apps could deliver better health outcomes. Telemedicine in countries like this could help provide clinical services, drug testing and vaccines that are currently being developed worldwide. Based on the situation we are going through with COVID-19, integrated healthcare providers such as HealthPartners with based in Minnesota have reinforced their telemedicine infrastructure to deal with the pandemic [34] . This organization is currently providing hospital medications coverage outside the hours of patient care in five rural hospitals and critical access; for this, they use commercial telemedicine carts in hospitals and home laptop computers provided by the company. They have also increased capacity at two large tertiary care hospitals by adding webcams to existing mobile workstations and purchasing new laptops for new telemedicine providers. The main barriers found in this process include cost and equipment testing.In the study [35] , the authors show the use of telehealth in postoperative visits to minimize patient exposure during the pandemic. The study presents a medical case in which they use a passive and self-extracting drainage dressing after a neck dissection to facilitate the discharge process during the day and the postoperative follow-up through telehealth. The results were favourable since the patient removed the bandage and drainage at home during a telehealth visit on postoperative day 4, healing without any sign of infection. Table 1 shows the research domain area of the analysed proposals on the application of telemedicine systems. Moreover, Fig. 2 presents the percentage of the papers for each research domain area.In total, 58% of the analysed literature have been published in health care sciences services journals (N = 12). Moreover, 16% (3) of the selected papers have been published in medical informatics journals and 11% (2) in the public and occupational health domain. Finally, biotechnology applied microbiology, general medicine and surgery count with one published paper each.The results of our review show us the leading research organizations found in the literature that are involved in the fight against COVID-19, as well as the funding agencies that support the research (See Table 2 and Table 3 ).According to Table 2 The funding agencies that are supporting the study of telemedicine applied to COVID-19 pandemic are presented in Table 3 .In total, ten different agencies are supporting the research on telemedicine solutions applied to the COVID-19 pandemic. The National Health and Medical Research Council of Australia is involved in two research works. Moreover, the research work presented by the authors of [23] is supported by four agencies, and the study proposed by [17] involves three different agencies.Furthermore, Table 4 highlight the authors with more than two research papers in the telemedicine, considering the analysed literature. According to Table 4 , Huang SF is involved in three different studies. Moreover, Cheng J, Smith AC, Snoswell CL, Xiao YR and Zhou T collaborate in more than one research study. Figure 3 presents graphical information about the countries of the authors involved in the analysed studies. Table 5 presents the countries of the authors involved in the analysed studies. The United States and China have the most significant number of studies found in the literature and that have been relevant to our review; with 42.11% and 31.58%, respectively. In total, 12 different countries have work on the application of telemedicine systems on this pandemic scenario. However, countries such as Brazil, United Kingdom, Spain, France, Germany and India that are in the top of the most affected locations considering the number of total deaths originated by the COVID-19 are not presented in any of the analysed research studies.It has been proven the interest of the international community on COVID-19 topic. Also, the applicability of telemedicine and e-health systems on COVID-19 issue or similar pandemic situations is very promising. However, there are some limitations related for instance the quality of the open data available for research. An important challenge concerning cleaning and reliable data is denoted. Finally, a recent study related to risks of emergency use authorizations for medical products during outbreak situations states the limitation regarding the need for an evidence-based regulatory framework [36] .This paper presents a state-of-the-art analysis of telemedicine and e-health systems that have emerged in the current pandemic scenario. Furthermore, the Nevertheless, this systematic review has limitations. This literature review only considers the most reputable journals included in JCR since there is a significant spread of non-peer-reviewed papers that can also provide fake and limited outcomes for further research activities.In summary, the application of telemedicine and e-health systems involves a cross-domain research approach and is used by numerous authors from distinct locations. Furthermore, telemedicine plays a critical role to ensure continuous access to healthcare in lockdown scenarios. Consequently, it is necessary to ensure the quality and privacy of these architectures to offer efficient methods and approaches for enhanced public health and well-being.",United States,abstract,2021-02-03,02
03ed5aaa8147311fecd315285b2da0969bc8fcae,An integrated framework for building trustworthy data-driven epidemiological models: Application to the COVID-19 outbreak in New York City,"This study aims to answer a fundamental question: given epidemiological data, how to 2 develop an appropriate model and identify which parameters we can accurately infer 3 that would, in turn, allow us to correctly predict the states of interest such as daily 4 cases, hospitalizations, and deaths. The objective of this work is to provide a systematic 5 way to model a pandemic accurately through carefully formulating a suitable model, 6 uniquely identifying the model parameters, and predicting outbreaks under 7 uncertainties based on the different epidemiological data available. To address the above 8 fundamental question, we propose a general integrated framework to approach the 9 problem systematically through identifiability analysis, sensitivity analysis, model 10 robustness analysis, and forecasting under uncertainties.Numerous modeling approaches have been used to gain insight into epidemic 12 disease's ever-evolving dynamics and the effects the interventions have had on 13 containing the spread. Mathematical modeling is an efficient way to test and evaluate 14 the effectiveness of hypothetical interventions that cannot be tested out due to practical 15 or ethical limitations. Describing the disease's development involves representing a interventions. Compartmental models are commonly applied in epidemiology for the 26 reason that they are simple and easily tractable. However, these models are local and 27 have limited capabilities to describe spatial dynamics. Partial differential equation 28 (PDE) models, such as diffusion-reaction models, describe dynamics in time and space 29 more naturally [12, 13] . ODE models are the most commonly used models due to the 30 increased mathematical complexity and computational cost of PDE models. However, 31 their accuracy is constrained by parameter uncertainties and gaps in information about 32 the disease dynamics. Likewise, assumptions to maintain model simplicity may affect 33 the estimated values. For a long-lasting pandemic, the model parameters change with 34 time; hence the parameter identification problem becomes nontrivial given the fact that 35 typically a limited amount of relevant data is available. 36 In an ODE-based epidemiological model, the system parameters usually contain 37 critical information that often cannot be measured directly such as the transmission rate 38 which needs to be inferred from data. A necessary condition for the well-posedness of a 39 parameter estimation problem in ODE theory is the model's structural identifiability if 40 we assume noise-free data. The structural identifiability analysis can be performed 41 without any experimental data; it addresses whether the parameter estimation problem 42 is well-posed under ideal conditions. Should the postulated model not be structurally 43 identifiable, the parameters obtained will be unreliable. However, a model can be 44 structurally identifiable (a necessary condition) but may not be practically identifiable. 45 Thus, the structural identifiability analysis may conclude that a model's parameters are 46 uniquely determined, yet when real-life, noisy data are used, the estimated parameter 47 values could still be unreliable. To conduct the practical identifiability analysis, we 48 compute the correlation matrices of model parameters in different settings using Fisher 49 Information Matrices (FIMs) following lines of approach in [14, 15] . 50 Non-identifiability is a problem frequently encountered in pandemics modeling since, 51 typically, not every state variable is available. In recent literature, model identifiability 52 issues have been studied due to the wide variation in model predictions in the context of 53 the COVID-19 pandemic [2, [16] [17] [18] . Tuncer et al. analyzed the structural and practical 54 identifiability of some of the most widely-used pandemic models, including SIR, SIR 55 with treatment, and SEIR, assuming only one observable is available using simulated 56 data [19] . Roda et al. extended these ideas by studying SIR and SEIR models' practical 57 identifiability using data from the COVID-19 outbreak in Wuhan, using only the counts 58 of infected individuals as the available data [2] . They found that complex mechanistic 59 models are more likely to have identifiability issues compared to simpler models. A general framework for building a trustworthy data-driven epidemiological model -an overview of the main contribution. In this work, we propose a general framework for building a trustworthy data-driven epidemiological model, which constructs a workflow to integrate data acquisition and event timeline, model development, identifiability analysis, sensitivity analysis, model calibration, model robustness analysis, and forecasting with uncertainties and scenarios. We first introduce a modified SEIR model that accommodates the pandemic data in New York City. Secondly, we study the structural identifiability, practical identifiability, and sensitivity to examine the relationship between the model's data and parameters. We then calibrate the identifiable model parameters using simulated annealing and MCMC simulation. Model robustness is then checked to study how the model behaves under random perturbations. In addition, we demonstrate the model's predictive capabilities with uncertainties. Finally, reopening scenarios are investigated as a reference for policymakers.parameters;• We treat the transmission rate, hospitalization ratio, and death from hospital • We specifically investigate the effects of indoor dining reopening and vaccination 128 scenarios as a reference for policymakers. 129 General Framework and Workflow 130 Holmdahl and Buckee, in [26] , discussed different types of models for the COVID-19 131 epidemic as well as the distinct challenges in these approaches. The authors highlighted 132 that ""models are a way to formalize what we know about the viral transmission and 133 explore possible futures of a system that involves nonlinear interactions, something that 134 is almost impossible to do using intuition alone."" They further elaborate that ""models 135 will be useful for exploring possibilities rather than making strong predictions about 136 longer-term disease dynamics."" Thus, a systematic way of designing an effective 137 data-driven model is essential for assessing ongoing control strategies endowed with 138 uncertainty quantification.To systematically design an effective data-driven model, we propose a general 140 framework for building a trustworthy data-driven epidemiological model, which 168 We evaluate the effectiveness of the proposed framework by applying all the outlined 169 steps to the outbreak dataset in NYC. One of the advantages of the framework's 170 generality is that it is not limited to a single dataset or model. In general, it provides a 171 guideline on how to build an effective and trustworthy epidemiological model with the 172 available data. For illustration purposes, we show how our framework can handle 173 different data types by assuming scenarios when some observables in the NYC dataset 174 are missing. However, for practical use, one should determine the data that are fed to 175 the model at the very beginning.(I) Data acquisition and event timeline 177 We use the data consisting of daily cases, hospitalizations, and deaths between February 178 29, 2020, and February 4, 2021, to fit the model's parameters. All the data used in this 179 paper were extracted from the NYC's government's website and collected by the NYC 180 Health Department [25] . Hospitalization data were collected from several sources, such 181 as NYC public hospitals, non-public hospitals, and the Health Department's syndromic 182 surveillance database, which track hospital admissions across NYC. The data on the The stay-at-home order was effective in bringing down the disease's incidence. As 214 a result, a four-phase reopening plan was developed, taking into account seven 215 health metrics the city needed to meet before reopening [30] . NYC entered Phase 216 1 of reopening on June 8, Phase 2 on June 22, Phase 3 on July 6, and Phase 4 on 217 July 20. Each phase had specific policies that determined what businesses could 218 reopen and in what capacity. Industries that posed the lowest risk of infection for 219 employees and customers were allowed to reopen in Phase 1. These included but 220 were not limited to construction, manufacturing, and wholesale supply-chain 221 businesses and retailers for curbside pickup, in-store pickup, or drop-off [31] . were eased, and meetings of up to 50 people were allowed. Indoor religious 229 meetings were allowed to resume at 33% capacity. Malls, zoos, and botanical 230 gardens were also permitted to reopen in this phase. NYC stayed at Phase 4 until 231 September 30, 2020, when indoor dining at 25% capacity was allowed. The careful reopening process, which followed the strict stay-at-home order, In December 2020, the increasing rate of virus transmission in NYC threatened to 243 overwhelm hospital capacity. Although contact tracing data from NYC placed 244 indoor dining as the fifth source of new infections in the state, the CDC 245 designated indoor dining as a ""high risk"" activity [34] . The governor's decision to 246 ban indoor dining was an attempt to halt the steep increase in cases and avoid a 247 broader shutdown. In the same week when the governor's office closed indoor 248 dining again, the first coronavirus vaccine was administered in Queens on 249 December 14, 2020 [35] . These modifications allow a more accurate description of the biology of the disease. 284 Since this study focuses on a single outbreak, births and other deaths are not 285 considered. When the epidemic begins, all individuals are susceptible and transit to the 286 exposed class via contact with presymptomatic, symptomatic, or asymptomatic 287 individuals. Moreover, we assume that there is no reinfection. In other words, once an 288 individual recovers, they do not become susceptible again. We divide the total 289 population into nine different compartments: susceptible (S), exposed (E), individual. Similar to [39], we assume that presymptomatic individuals (P ) are just as 296 infectious as asymptomatic individuals (A). The transmission rate of the disease is 297 denoted by β. After a latent period (1/d E ), an exposed individual becomes 298 presymptomatic infectious. A presymptomatic infectious individual develops symptoms 299 with probability δ or is asymptomatic with probability (1 − δ) after (1/d P ) days.Asymptomatic individuals recover after an infective period of (1/d A ). A proportion p of 301 symptomatic individuals is hospitalized after an infective period of (1/d I ), while the 302 rest of them are isolated (for example, isolated at home) but do not go to the hospital. 303 The isolation period is (1/d Q ). The hospitalization period is (1/d H ), at the end of 304 which, a proportion q of the hospitalized individuals die while the rest of them recover. 305 Asymptomatic cases pose a challenge to identify since there is no widespread systematic 306 February 10, 2021 8/39Note that the compartments (I, H, D) represent the current symptomatic 319 individuals, hospitalizations, and deaths. In order to represent the daily cases I new , 320 hospitalizations H new , and deaths D new , we add the following ODEs that take into 321 account the inflow of the these compartments to record the cumulative cases I sum ,hospitalizations H sum , and deaths D sum :Now, the daily numbers are just the increments of the cumulative numbers:for t = 1, 2, 3, · · · .We fit the parameters in each stage defined by policy changes, such as the stay-at-home 342 order and the subsequent reopening processes; see reproduction number of the model is:In this particular study, given that the model parameters are defined in a piecewise 349 fashion and there was no control in Stage 1, the basic reproduction number, R 0 , is 350 computed by using β = β 1 .The transmission of the disease slows down when there are more immune individuals. 352 Since R c is the number in an entirely susceptible population, we can calculate the 353 effective reproduction number:By setting R e = 1, we obtain the immunity threshold of the ODE system, which is the 355 critical portion of the population needed to be immune to stop the transmission of the 356 disease:The herd immunity threshold (HIT) is calculated by substituting R c with R 0 . A higher 358 R 0 results in a higher HIT.Formally speaking, a parameter in a dynamical system is considered to be In our framework, we analyze both structural and practical identifiability, and use There are 11 undetermined parameters in the proposed model, and it is impossible to fit 391 every parameter without fixing some of the values. For example, it is unnecessary to fit 392 biologically determined parameters such as the time an individual spends in the exposed 393 or infected classes. Since d E , d P , d I , d A , d H , and d Q are determined by the biology of 394 the disease, we fix these values according to [39] . 395 We analyze the structural identifiability of the rest of the parameters when different 396 types of data are given. Note that for general use of our modeling framework, one 397 should fix the dataset at step (I). Here we consider all the scenarios just for illustration 398 purpose. Specifically, we assume that the data are given as the cumulative cases I sum , 399 cumulative hospitalizations H sum , and cumulative deaths D sum , or a subset of the three 400 aforementioned observables, because these quantities can be calculated directly from 401 daily quantities I new , H new , and D new . In other words, it is equivalent to assume X new 402 or X sum to be given as one of the observables, where X can be I, H, and D. The 403 effectively vaccinated population v is treated as the input variable to the system.According to Table 3 , when only two out of three observables are available, the model is 405 not identifiable and the fitting result will not be unique. The results are to be 406 interpreted in the following way. In the case of lacking deceased individual counts, the 407 death rate q cannot be inferred accurately. If the hospitalization data are not available, 408 both the hospitalization ratio p and death from hospital ratio q cannot be inferred proportion of disease-related deaths when one of the observables considered in this 417 paper is missing. One of the main differences between the proposed model and most 418 other existing SEIR-based models is that our model integrates information of infectious, 419 hospitalized, and deceased populations simultaneously, therefore producing more 420 reliable results on these estimated parameter values. Since we have data for all three 421 observables in NYC, we should utilize all of them.In practice, hospitalization data could be reported in different ways; some databases 423 provide daily reports of the number of hospitalized individuals, whereas others register 424 the number of currently hospitalized individuals. Regardless of the data type available, 425 structurally identifiability of the model remains the same according to S2 Table. 426 Practical identifiability 427 We then proceed with fitting 5 undetermined parameters using all the available data, Table 4 . We see that the values of and δ vary a lot among different 431 stages, which is inconsistent with reality. This poses a question on the practical 432 identifiability of the model.The correlation matrices are then computed based on parameters obtained in Stage 1 434 to help determine the practical identifiability. In practice, one can obtain the correlation 435 matrix from the FIM of model parameters, with details given in S4 Text. As shown in 436 Fig 4(b) , there is a strong correlation between , δ, and β, while either p or q is need to be fixed, while the rest and p, q can be fitted. In this paper, we fix , δ and fit 441 β, p, q for the following reason: β, which represents the transmission rate, is highly 442 affected by local government policy and does not have a stable and universal value 443 compared to and δ. This means that the value of β could be very different across 444 different datasets and is hard to determine a priori. Therefore, we fix and δ according 445 to [38] . After that, the model becomes practically identifiable as shown in S3 Fig. A 446 summary of the reasoning is shown in Fig 4(a) . Variance-based sensitivity analysis, also called Sobol sensitivity analysis, is a global method that measures sensitivity across the whole input space. It decomposes the model's output variance into fractions that can be attributed to individual inputs or groups of inputs [20] . Suppose we are given a black box model:where y ∈ R is the output and Θ = [θ 1 , θ 2 , · · · , θ k ] ∈ [0, 1] k are independent and 449 uniformly distributed uncertain inputs. If some components of Θ are not within [0, 1], 450 we may transform Θ into the unit hypercube. The parameter β is the most important parameter for all three quantities of interest in every stage of the pandemic. The parameter p has no influence on I sum . The parameter q has no influence on I sum or H sum .First-order sensitivity index measures the contribution to the output variance by a single input θ i alone:where Θ ∼i = [θ 1 , · · · , θ i−1 , θ i+1 , · · · , θ k ]. Total-order sensitivity index measures the 452 contribution to the output variance by an input, including its first-order effect and all 453 higher-order interactions with other inputs:Note thatby definition, and k i=1 S T i (y) ≥ 1 since the interaction between θ i and θ j is counted in both S T i (y) and S T j (y). The vaccination data of COVID-19 in NYC are given in the form of the number of first 477 and second doses administered from December 14, 2020 to February 4, 2021 (see Fig 2) . 478 The vaccine efficacy is 52% for only one dose and 95% for both doses. As the vaccines 479 are not 100% effective, in order to calculate the number of effectively vaccinated in the region β, p, q ∈ [0, 1], where ""MSE"" stands for mean squared error. The estimated 503 final value in the previous stage is the initial value for the next stage. The results of all 504 compartments are plotted in Fig 6 and Fig 7. The time-dependent parameters (β, p, q) 505 and the control reproduction number R c are shown in Fig 8, Table 5, and Table 6 .The control reproduction number R c , whose expression is in Eq. (5), depends on six 507 parameters: β, , δ, d P , d I , and d A . Since , δ, d P , d I , and d A are fixed as in Table 2 , 508 R c is proportional to the transmission rate β; see Using the fitted parameter values in Table 5 , we perform the Monte Carlo simulation to 535 check the robustness of our model to perturbations, adapting ideas from [19, 57] . The 536 major difference between their approach and ours is that we incorporate sensitivity 537 analysis results in our method. 538 We first multiply the daily increase in the calibrated data (a subset of 539 {I sum , H sum , D sum }) by independent and identically distributed Gaussian random noise 540 of mean 1 and standard deviation σ to generate a new dataset, which looks like our 541 original dataset with measurement error. Then, we estimate the parameters by fitting 542 the model to the artificially generated dataset and compare the result with the 543 parameter values obtained in Table 5 . The same procedure is repeated for M = 1000 544 times, and we compute the average error between the parameter values estimated from 545 the original and the generated datasets. We then rescale this error by a sensitivity Sensitivity-based Average Relative Error (SARE) of (β, p, q) in different observable settings. Each row corresponds to a standard deviation level of random noise multiplied to the observables. Each column represents an observable setting. Note that when SARE of a parameter is 0, it means the provided data are not sensitive to that parameter. When (I sum , H sum , D sum ) are given, SARE is lower than the threshold 1. Therefore, our model is robust to noise in the NYC dataset. In some of the missing observable cases, our model is also robust to perturbations at different noise levels.(SARE):where θ i is the fitted value of the ith parameter (i.e., β, p, q) on the original dataset, where k is the total number of parameters to be estimated. If MSARE < 1, we say the 561 model is robust to perturbation. The algorithm is detailed in S5 Text. This method is a 562 complement to the identifiability analysis in the sense that the identifiability analysis 563 only takes care of the uniqueness of model parameters but not their significance to the 564 data. An insensitive non-identifiable parameter would not influence the predictability of 565 the model too much. On the other hand, robustness does not guarantee the correctness 566The first column in Fig 9 shows that when (I sum , H sum , D sum ) are given, our model 569 is robust to noise, which justifies the correctness of the fitting result (since β, p, q are 570 also identifiable) and provides a theoretical backup for the forecasting in the next 571 section. The other columns in Fig 9 show that even when some observables are missing, 572 the model could still be robust to perturbation at different noise levels, so that one can 573 use our model to make predictions in some missing observable cases. For example, only 574 infectious and hospitalized data (I sum , H sum ), only hospitalized and deceased data The situation in NYC evolves day by day. The city reinstated indoor dining restrictions 582 in mid-December due to the steady increase in the virus incidence. The ever-changing 583 policies add a high level of uncertainty to any long term forecast we can make. Here, we 584 explore our model's ability to predict the number of daily cases, hospitalizations, and 585 deaths in the city with uncertainty.The MCMC simulation provides us with a way to quantify uncertainty. We may 587 sample from the posterior distribution of the parameters in the last stage (see S11 Fig) 588 and run the model after that to obtain a distribution of the predicted daily cases, 589 hospitalizations, and deaths. However, this approach assumes that the situation remains 590 the same after the last stage, which may not be the case. There might be policy changes 591 or other events. As a result, we perturb the transmission rate β by a percentage to 592 reflect future policy changes or other events. We sample from the posterior distribution 593 of the parameters (β, p, q) in the last stage. Then, we multiply β by a random number 594 drawn from a uniform distribution (U(0.95, 1.05) or U(0.85, 1.15)). In other words, we 595 perturb β by 5% or 15%. As a reference, see Table 6 for the historical changes of β 596 between contiguous stages. We run the model with the initial value as the ending value 597 of the last stage to predict daily cases, hospitalizations, and deaths. After repeating 598 4000 times, we obtain a distribution of the daily cases, hospitalizations, and deaths at 599 every timestamp after the last stage. Then, the 95% confidence interval at every 600 timestamp is plotted. The COVID-19 epidemic is an unprecedented worldwide public health challenge, 614 especially in densely populated areas such as New York City (NYC). Epidemiological 615 models can provide the dynamic evolution of a pandemic but they are based on many 616 assumptions and parameters that have to be adjusted over the time when the pandemic 617 lasts. However, the available data might not be sufficient to identify the model 618 parameters and hence infer the unobserved dynamics. This is typical of any past 619 epidemics or pandemics, and hence a systematic integrated framework is required to 620 make existing or modified models useful for designing health policies.To this end and after studying the current pandemic for almost a year, we have 2. Identify the flow between the components and link them with directed arrows.Assign the rate of the flow with one parameter per arrow except for S → E, which 886 is defined by the transmission of the disease. See S1 Fig.   887 3. Change parameters such that every parameter has physical meaning. We use nine 888 parameters (p, q, δ, d E , d P , d I , d A , d H , d Q ) to replace (w 1 , · · · , w 9 ). See Eq. (13) 889 for the formulas. Note that there is a one-to-one correspondence between the nine 890 parameters we use and (w 1 , · · · , w 9 ). S2 Text. Parameter settings. Parameter values for the fixed parameters are summarized in Table 2 . The percentage of infected people who never show the disease's symptoms is extracted from the CDC's current best estimate for this value [38] . The parameter δ is obtained by averaging the lower and upper bounds of the estimates for this value from different sources:We use data from the hospitalization surveillance network used by the CDC to estimate the median number of days an individual spends hospitalized due to the disease [58]. The numbers provided are specific to individuals admitted to the ICU and not admitted to the ICU divided into age groups; therefore, we perform a weighted average of those values considering the demographic composition of NYC. According to S1 Table, is the disease-free equilibrium state of the system. We haveThen,Let ρ(F V −1 ) denote the dominant eigenvalue of F V −1 . The control reproduction 893 number is given by R c = ρ(F V −1 ).S4 Text. Definition and algorithm for identifiability analysis.Structural identifiability 896 Suppose we are give a dynamical system of the following abstract formwhere X = (X 1 , · · · , X n ) represents the state variables, y = (y 1 , · · · , y m ) represents the 898 observables, Θ = (θ 1 , · · · , θ k ) contains the parameters to identify, and u(t) represents 899 the input variable to the system. A parameter set Θ is called structurally identifiable if 900 g(X(t), Θ, u(t)) = g(X(t), Φ, u(t)) =⇒ Θ = ΦThe structural identifiability, defined above, is referred to as global identifiability 903 in [51] [52] [53] [54] . Global identifiability is stronger than the so-called local identifiability, which 904 only requires Eq. (15) or Eq. (16) to hold in a neighbourhood N (Θ) of Θ. Structural 905 identifiability analysis is usually conducted before the fitting of the model and it does 906 not rely on any data. 907 We perform the structural identifiability analysis using the software SIAN [56] , 908 which is based on differential algebra and Taylor series expansion. Detailed 909 documentations on the theory behind the software can be found in [60] , and information 910 regarding the algorithm can be obtained from [56] .SIAN is a randomized algorithm that requires users to choose a hyperparameter that 912 defines the probability of correctness. In this paper we choose 0.999. The algorithm first 913 replaces the observables with their truncated Taylor series and reduces the identifiability 914 problem to the problem of studying the generic fiber of the map between the parameter 915 space and the space of truncated observables, which is a map between finite-dimensional 916 varieties. Due to the hardness of analyzing the generic fiber, a step to simplify 917 computation is applied in the algorithm by studying fiber at a specific point instead of 918 generic ones. The correctness of this step is controlled by the hyperparameter 919 aforementioned. The problem is then turned into checking the consistency of a system of 920 algebraic equations. The Buchberger algorithm allows the computation of the Grobner 921 basis of the system. This basis shows whether the algebraic relations' parameters have a 922 single solution/finitely many solutions/infinitely many solutions, which implies the 923 model would be structurally globally identifiable/locally identifiable/not identifiable. [19, 57] .Statistical correlation can be used to describe some of the practical non-identifiability phenomena. Specifically, one can use the Fisher Information Matrix (FIM) to calculate the correlation matrix of Θ in Eq. (14) . FIM is defined as:where V is covariance matrix of the measurements error. S i = ∂ỹ(ti) ∂Θ is the sensitivity matrix at time t i , which can be calculated by solving the adjoint equation:using automatic differentiation libraries. It is proved that the correlation matrix is equal 933 to F −1 by the Cramér-Rao theorem [61] . Once the correlation matrix is obtained, one 934 can determine whether a parameter is identifiable by checking whether it is correlated 935 with the other parameters. If θ i is strongly correlated with θ j , then neither of these 936 parameters is practically identifiable because they cannot be uniquely determined from 937 the data.",USA,first author,2021-02-24,02
ef4a94443921cc60bb3c9d8380913b5d45a69369,Clinical characteristics and outcomes in women and men hospitalized for coronavirus disease 2019 in New Orleans,"Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), which causes coronavirus disease 2019 , is disproportionately impacting older subjects with chronic medical comorbidities, and men, reportedly, exhibit a uniformly more severe outcomes than women [1, 2] . In case series from China, Europe, and the USA, COVID-19 hospitalizations, admission to intensive care unit (ICU), and in-hospital death have consistently been higher in men than in women [1] [2] [3] [4] [5] [6] . The reasons for this sex disparity in COVID-19 outcomes are not entirely understood. Most diseases are characterized by sex differences in clinical presentation, evolution, and response to treatment [5] . Characterizing differences between men and women in COVID-19 presentation and outcomes is a central consideration in clinical research, as it may open therapeutic avenues to promote health equity in COVID-19 severity. To date, the sex-stratified analysis of clinical and biological characteristics of COVID-19 patients in relation to outcomes is still not available from most studies. New Orleans, LA, was an early epicenter, with the highest death rate per-capita in the USA noted during the April 2020 peak of the outbreak [7] . In this population, we reported that the high prevalence of metabolic disease including hypertension, obesity, and diabetes, dramatically increased the odds of mortality [7] . Further, in contrast to prior studies, our hospitalized population exhibited a predominance of women. These early observations led to the hypothesis that sex disparities may, in part, account for the greater severity of illness seen among this disadvantaged population suffering worse outcomes from COVID-19. This case series describes the association of sex with clinical characteristics and outcomes in 776 consecutive women and men hospitalized with COVID-19 in two tertiary care academic hospitals in urban New Orleans from 27 February to 15 July 2020.This is a retrospective case series using data from 776 adult patients consecutively admitted for COVID-19 at two tertiary care academic hospitals, Tulane Medical Center and University of Medical Center in New Orleans, LA, from 27 February to 15 July 2020. These hospitals serve racially diverse, low-income populations across metropolitan New Orleans. All adults (> 18 years) hospitalized with confirmed SARS-CoV-2 (COVID-19) infection on admission were included [COVID-19 infection assessed by polymerase chain reaction of a nasopharyngeal sample] and were subsequently hospitalized. Inhospital death or discharge status was assessed through 23 July 2020. This study was reviewed and approved with waiver of consent by the Tulane University Biomedical Institutional Review Board (IRB) and the University Medical Center New Orleans Research Review Council.Demographic and clinical data were extracted from two hospitals' medical records. Six clinicians then performed manual medical record review to organize and verify the data, with discrepancies resolved following discussion with two senior investigators and attending physicians. This dataset included the following domains: demographic characteristics (age at admission, sex, patientreported race, and hospital site), clinical symptoms at admission, comorbidities, laboratory values at or right after admission, and COVID-19 outcomes including ICU admission, invasive mechanical ventilation (IMV), and in-hospital mortality. Comorbid conditions, including chronic obstructive pulmonary disease (COPD), asthma, cardiovascular disease (CVD), cerebrovascular disease, chronic kidney disease (CKD), chronic liver disease (CLD), and dementia were ascertained by codes in the International Classification of Diseases, 10th Revision [ICD-10] and physician notes 6 months prior to the admission. Diabetes and pre-diabetes were defined by documented diagnosis, elevated hemoglobin A1c value, or the use of anti-diabetic medications. Hypertension and hyperlipidemia were defined by documented diagnoses or use of antihypertensive or lipid-lowering medications.To compare patients' characteristics at admission by sex, we used chi-square test (Fisher's exact test when appropriate) for categorical variables and two tailed t test for continuous variables. To describe the relationship between comorbidities, biomarkers, and outcomes in the overall sample, we performed univariate and then multivariable logistic regressions adjusting for age, sex, hospital site, and the Charlson Comorbidity Index [8] . Sex (women vs men) and race (non-Hispanic Black vs non-Black) stratified analyses were also performed separately. All model-based results are presented with 95% confidence intervals. All analyses were conducted with the use of the SAS System for Windows, version 9.4 (SAS Institute).The overall baseline characteristics (overall and by sex) of our cohort are presented in Table 1 and race-specific baseline characteristics in eTable 1. Mean age of the cohort was 60.5 years, 61.4% were women, and the majority of participants (583; 75%) self-identified as Black.Black patients were slightly younger than non-Black patients. While Black women and men exhibited no age difference, non-Black women were older than non-Black men (eTable 1). White women were significantly older than White men (71.7 vs 63.7-year-old, P = 0.03) and Black women (71.7 vs 60.2-year-old, P < 0.0001, results not shown in tables). The most common comorbid conditions were hypertension (74%), obesity (53%), and diabetes (35%), followed by CVD (21%), COPD (19%), CKD (17%), and asthma (11%). A non-obese (< 30 kg/m 2 ) or normal BMI (< 24.9 kg/m 2 ) was more common in men than women, whereas obesity (BMI ≥ 30 kg/m 2 ) was more common in women than in men, with morbid obesity (BMI > 40 kg/m 2 ) being over twice as prevalent among women as men (Table 1) . Similarly, hypertension, COPD, asthma, and to a lesser extent, diabetes were more common at baseline among women than men, while CLD was more common among men (Table 1) . When data were analyzed by race, the prevalence of all comorbidities was higher in Black compared to non-Black patients (eTable 1). A similar sex difference was observed for obesity, asthma and CLD in the Black, as in the overall sample (eTable 1). In the Black sample, women were more likely to have obesity and asthma at baseline, while men were more likely to have CKD and CLD. In non-Black patients, women had higher prevalence of hypertension, obesity, and dementia compared to men (eTable 1). No sex difference was observed in the prevalence of other comorbidities in either Black or non-Black samples. Non-Black, and especially White women, had significantly higher Charlson Comorbidity Index score than Black women (mean index, 4.8 vs 3.7, P = 0.01, results not shown in tables).At admission, women were more likely than men to present with digestive symptoms, dyspnea, and fatigue (Table 2) , and this phenotype was driven by Black women (eTable 1). In Black patients, more women reported non-productive cough than men. In non-Black patients, more men had fever at admission than women (eTable 1). A greater proportion of men than women had ALT, AST, procalcitonin, ferritin, and neutrophil-tolymphocyte ratio (NLR) above the normal range ( Table  2) ; results were qualitatively similar in the Black sample who additionally showed a greater percentage of monocytes (eTable 2). In non-Black patients, more men than women had elevated AST and ferritin (eTable 2).During hospitalization, 271 patients (34.9%) were admitted to ICU, among which 144 were women and 125 men were (35.5 vs 34.3%, P = 0.7), 187 patients (24.1%) received IMV, among which 100 were women and 85 were men (24.6 vs 23.3%, P = 0.7). In-hospital death occurred in 140 patients (18.1%), among which 71 were women and 66 were men (17.5 vs 18.1%, P = 0.8). Black versus non-Black patients had higher incidence of ICU admission (37.7 vs. 26.3%, P = 0.004) and IMV (26.5 vs. 17%, P = 0.007); in-hospital death rate for Black (106 patients, 18.3%) vs White patients (17 patients, 17.1%) was not statistically significant (P = 0.9). Results were similar for each comparison in women vs men within each racial group (P > 0.05-data not shown in tables).In adjusted multivariable analyses, obesity was independently associated with increased odds of IMV and ICU admission in the overall sample (Fig. 1) . When data were stratified by sex, only morbid obesity (BMI ≥ 40 kg/m 2 ) was independently associated with increased odds of ICU admission in both women and men (Fig. 1) . Obesity was independently associated with increased odds of IMV at a lower BMI (> 35 kg/m 2 ) in women than men, but the magnitude of the effect of morbid obesity (BMI ≥ 40 kg/m 2 ) was similar in both sexes (Fig. 1) . When multivariable analyses were performed by race, obesity was associated with increased odds of ICU, IMV, and death in the overall Black patients, which remained significant for IMV in Black women and men (eFigure 1). However, obesity was not associated with death in the non-Black women and men (eFigure 1). In adjusted analyses, diabetes was independently associated with increased odds of ICU admission and IMV in the overall sample, and in women and men (Fig. 1) . Similar results were observed for ICU and IMV in race-specific analyses (eFigure 1). Notably, diabetes was independently associated with increased odds of in-hospital death in the overall sample. When data were stratified by sex, diabetes was associated with increased odds of death in women, but not in men (Fig. 1) . When stratifying by race, diabetes remained positively associated with increased odds of death in Black and non-Black women, not in Black and non-Black men (eFigure 1). The existence of COPD was independently associated with increased odds of ICU admission and IMV in women but not in men (Fig. 1) , which remained significant for ICU in the Black sample, especially for Black women (eFigure 1). Notably, CKD was positively associated with the odds of ICU admission and death in the overall and women only sample. When data was disaggregated by race, CKD was associated with increased odds of ICU, IMV, and death in the overall Black patients (eFigure 1). However, CKD was associated with increased odds of in-hospital death in Black women only (eFigure 1).Several biomarkers of inflammation and hypercoagulability, including C-reactive protein (CRP) [9] , N-terminal pro-type natriuretic peptide (NT-proBNP) [10] , Lactate dehydrogenase (LDH) [11, 12] , procalcitonin [13, 14] , NLR [12, 15] , ferritin [11] , troponin [16, 17] , and Ddimer [18] have been associated with COVID-19 severity.CRP is an acute-phase protein produced by the liver during inflammation following interleukin-6 secretion by macrophages, T cells, and adipocytes. CRP was similarly elevated in men and women in the overall and racespecific samples ( Table 2 and eTable 1). In multivariable analyses, CRP was associated with increased odds of IMV, ICU, and death in the overall sample as well as in sex-specific samples ( Fig. 2 and eFigure 2) . When analyzed by race, similar results were observed in Black patients overall and by sex. The association between CRP, IMV, and ICU were found in the overall non-Black patients and non-Black women; whereas the association between CRP and death was found in the overall non-Black patients and non-Black men (eFigure 2).NT-proBNP is a BNP prohormone released from the heart during heart failure. NT-proBNP was shown to be an independent risk factor for in-hospital death in patients with severe COVID-19 [19] . NT-proBNP was similarly elevated in men and women in the overall sample and in race-specific samples ( Table 2 and eTable 1). NT-proBNP was independently associated with increased odds of ICU, IMV, and death in both sexes (Fig.  2) . When stratifying race, the association of NT-proBNP with the ICU and IMV remained significant in Black patients overall. NT-proBNP was positively associated with the odds in-hospital death in Black men and women, and non-Black women (eFigure 2). LDH rises following multiple organ injury and failure with decreased oxygenation. The elevation of LDH was similar in women and men in the overall sample, and in Black and non-Black sample, separately (Table 2 and eTable 1). Elevated LDH was independently associated with increased odds of IMV, ICU, and death in the overall sample (Fig. 2) . When analyzed by sex, the magnitude of the effect of LDH on ICU and death was greater in women than in men (Fig. 2) . Similar results were observed in Black and non-Black patients, separately (eFigure 2). Procalcitonin increases during infection and inflammation and is a marker of COVID-19 severity [13] . An elevated procalcitonin was more prevalent in men than in women in the overall and Black samples ( Table 2 and eTable 1). Procalcitonin was independently associated with the increased odds of ICU admission, IMV, and death in patients overall (Fig. 2) . When analyzed by sex, the magnitude of the association between procalcitonin and IMV and death was greater in women than in men (Fig. 2 ). This sex difference was also observed in Black patients (eFigure 2). Procalcitonin was also independently associated with increased odds of ICU admission, IMV, and death in the overall and sexspecific samples. The same association was also found in the overall non-Black sample (eFigure 2).Lymphopenia with increased neutrophils is a criteria for severe COVID-19 and predicts the severity clinical outcomes [20] . A greater proportion of men exhibited an increased NLR > 6 than women with a trend toward increased prevalence of lymphocytopenia and increased monocytes compared to women (Table 2) . When data was stratified by race, the male bias in lymphopenia and increased monocytes became significant in Black patients (eTable 1). The increased NLR was independently associated with increased odds of ICU, IMV, and death in patients overall (Fig. 2) . When data were stratified by sex, the magnitude of the association between NLR and ICU admission and IMV was greater in women than in men (Fig. 2) . Notably, the increased NLR was independently associated with death in women only, but not in men. When analyzed by race, of the association between NLR and ICU admission, IMV, and death remained significant in both Black and non-Black patients, and mainly driven by women (eFigure 2).Ferritin is a key mediator of immune dysregulation via direct immune-suppressive and pro-inflammatory effects, contributing to the cytokine storm [21] . An elevated ferritin was more prevalent in men than in women in the overall and Black samples ( Table 2 and eTable 1) . Ferritin was independently associated with increased odds of ICU admission, IMV, and death in patients overall and by sex (Fig. 2) . Similar results were observed in the Black patients (eFigure 2). However, ferritin was independently associated with death in women only in the overall and Black sample ( Fig. 2 and eFigure 2) .Elevated cardiac troponin levels, a marker of myocardial injury, are associated with increased mortality in patients with COVID-19 [19, 22] . Troponin was similarly elevated in men and women in the overall sample ( Table  2 ) but was more elevated in Black men than Black women (eTable 1). Troponin was independently associated with ICU admission and death in the overall sample (Fig. 2) . When analyzed by sex, troponin was associated with increased odds of ICU admission only in men, and the magnitude of the effect of troponin on the odds of death was greater in men than in women (Fig. 2) . When analyzed by race, troponin was independently associated with death in Black and non-Black men, but not in women (eFigure 2).D-dimer is a marker of activated coagulation commonly elevated in patients with COVID-19, which correlates with disease severity [18] . D-dimer was similarly elevated in men and women in the overall and Black samples ( Table 2 and eTable 1) . Notably, D-dimer elevation was independently associated with increased odds of ICU admission, IMV, and death in men only, but not in women (Fig. 2) . When disaggregating race, D-dimer elevation was positively associated with ICU admission and IMV in Black men, and ICU admission and death in non-Black men (eFigure 2).This study highlights sex disparities in demographic characteristics, as well as clinical and biological presentation of the initial 776 sequential hospitalized adult patients with confirmed COVID-19 at two large urban medical centers in New Orleans.The first finding of this study is that COVID-19 outcomes (hospitalization, admission to ICU, IMV, and inhospital death) were similar in women and men. This contracts with most published case series from Asia, Europe, and the USA where men with COVID-19 had higher proportion of hospitalization and more severe outcomes compared to women [1] [2] [3] [4] [5] [6] [7] 23] . These findings may be unique to the predominantly Black patient population cared for at these urban centers, as other studies have found similar results in predominantly Black patients of New Orleans and Detroit [7, 23] . Supporting this hypothesis, our Black cohort contained a higher percentage of women than men. However, consistent with other case series, our non-Black cohort contained a greater proportion of men than women. Additionally, Black women exhibited a similar age and Charlson Comorbidity Index as Black men. In contrast, White women were older and exhibited a higher Charlson Comorbidity Index than White men and Black women. Women, and especially Black women, also exhibited greater proportion of comorbidities including obesity, hypertension, diabetes, COPD, and asthma than men. Therefore, and consistent with other studies, non-Black women seem to exhibit a biological or sociodemographic advantage compared to non-Black men regarding COVID-19 hospitalization in New Orleans, as they need to be older and accumulate a higher index of comorbidities to be hospitalized. In contrast, in this cohort, Black women seem to have lost their female biological advantage regarding COVID-19 severity compared to Black men. They are hospitalized at a similar age and index of comorbidities than Black men, and at a younger age with a higher index of comorbidities than non-Black women. These finding highlights the health disparity that seem to affect Black women in New Orleans. Note that our hospitals serve a population with low socio-economic background, with high rate of Medicaid and uninsured patients, and an average Charlson Comorbidity Index of 3.9. We also observed that more women presented with digestive symptoms and this was significant in Black women only.The second finding is that some comorbidities at baseline are determinants of more severe outcomes in women than men. Obesity was a predictor of respiratory failure requiring IMV at a lower level of obesity (BMI 35-40 kg/m 2 ) in women than men (BMI > 40 kg/m 2 ). The presence of COPD was a determinant of ICU admission and respiratory failure requiring IMV in women, but not in men. Notably, diabetes was a major independent determinant of death in Black and non-Black women, but not in men. Accumulating evidence suggest that women who develop type 2 diabetes experience an earlier, greater, and more prolonged deterioration in metabolic homeostasis than men, including central obesity, insulin resistance, inflammation, hypercoagulability, dyslipidemia, and hypertension [24] [25] [26] [27] [28] . All these factors increase the risk of COVID-19 mortality. Similarly reported in other COVID-19 case series [29] [30] [31] , in our overall cohort, CKD was an independent determinant of death. Notably, after stratifying by sex, CKD was an independent determinant of death in all and in Black women, but not in men. This contrasts with other investigations of sex differences in CKD mortality. For example, in the Chronic Renal Insufficiency Cohort Study, a large CKD cohort of around 4000 racially diverse men and women, after adjusting for demographic and clinical factors, women had lower risk of death than men [32] . Therefore, the biological and social factors explaining why CKD is an independent predictor of death from COVID-19 in women, and especially Black women, deserve investigation.As observed in Wuhan [33] , men were more likely to exhibit systemic inflammation compared to women, with increased procalcitonin, ferritin, a NLR > 6, and a greater percentage of monocytes. However, the increased NLR and ferritin were independent predictors of death in women, independent of race, but not in men. The increased NLR in severe COVID-19 reflects a depletion in lymphocytes, particularly cytotoxic T lymphocytes, coupled with an increase in neutrophils that produce proinflammatory cytokines [34] . Consistent with our findings, a study of patients hospitalized for COVID-19 in New Heaven, reported that higher levels of innate immune proinflammatory cytokines, like those produced by neutrophil, were associated with worse disease progression in women, but not in men [35] . Ferritin is also a marker of innate immune (macrophage) activation [36] . Together, these data suggest that the exaggerated innate immune response could be a greater predictor of COVID-19 severity in women than in men.In contrast, D-dimer, a marker of hypercoagulability was an independent predictor of severe outcomes or death in men, independent of race, but not in women. Men are at higher risk of venous thromboembolism (VTE) than women [37, 38] , including during COVID-19 [39] . Coagulopathies resulting in VTE and disseminated intravascular coagulation have been reported to be the primary cause of death in critical COVID-19 patients [10] . Therefore, D-dimers could be a greater predictor of lethal COVID-19 coagulopathy in men than in women.The biological factors underlying these sex disparities in immune, inflammatory, and hypercoagulability markers deserve further investigation, as they may have implications for sex-based treatment and vaccination.This study has several limitations. First, the study population only included patients within the New Orleans area, and the findings may not be generalizable to other populations. Second, the limited number of patients from some ethnic groups, such as Asian and Native Americans precluded a finer racial/ethnic stratification in the analysis. We split patients into two general racial groups-Black and non-Black. However, our sample reflects the racial distribution of COVID-19 in New Orleans, where Blacks have been disproportionately affected by the pandemic. Lastly, this is a case series study of hospitalized patients with confirmed COVID-19. It does not include a comparison of outcomes in patients not exposed to COVID-19. The observational nature of the study does not permit us to draw conclusions on causal relationships between comorbidities, biomarkers, and the COVID-19 outcomes.",USA,first author,2021-02-05,02
ac6b20e61ccb9322711e9225ee1558e0cb2fef52,Quantification of the tradeoff between test sensitivity and test frequency in COVID-19 epidemic -a multi-scale mod- eling approach,"Following the emergence of the novel coronavirus-2 severe acute respiratory syndrome (SARS-CoV-2) late in 2019 in Wuhan, China, the World Health Organization declared the COVID-19 pandemic on March 11, 2020. As of February 12, 2021 , this pandemic has resulted in over 107.4 million confirmed infections and 2.3 million deaths worldwide [3] .Epidemiological data from nations such as South Korea, Iceland and Taiwan demonstrates that widespread surveillance using real time polymerase chain reaction (RT-PCR) testing, combined with contact tracing and quarantine measures, can be effective at limiting the spread of SARS-CoV-2 [23] . However, in many other nations, notably the United States, the testing infrastructure was insufficient to prevent viral spread.1 of infectiousness onset and the time interval when a test detects an infection by looking at the virus dynamics inside an infected individual. The between-host model connects these events with transmission at the population level. We investigate testing strategies with assays of different sensitivities, frequencies, and delays in test returns. We will deem optimal a testing strategy that flattens the infection curve best, under either the same testing frequency or the same monetary cost.To generate within-host virus profiles, we use the target cell limitation model of SARS-CoV-2 kinetics developed by Ke et al. [20] , which was fitted to virus levels measured in pharyngeal swabs and sputum samples of patients infected through contact with the same index case [10, 39] . Briefly, the model considers the interaction between uninfected epithelial cells, T j ; exposed epithelial cells, E j ; infected epithelial cells, I j ; and virus, V j in upper (URT) and lower (LRT) respiratory tracts j ∈ {1, 2}, as in other acute infections [4-7, 9, 28, 29, 36] . Target cells in each tract are infected at rates β j , exposed cells become infectious at rates k j , and infected cells produce new virions at rates p j . Infected cells die at rates δ j and virus particles are cleared at rate c, independent of the tract. The two tracts are linked via the virus populations, with a proportion g 12 of V 1 migrating from URT to LRT and a proportion g 21 of V 2 migrating from LRT to URT. The model describing these interactions is given bywhere j = l ∈ {1, 2}. Ke et al. [20] assumed that the pharyngeal swabs data V T and sputum data V S in [10, 39] are proportional to the predicted URT and LRT virus loads given by model (1), V T = f 1 V 1 and V S = f 2 V 2 . They assumed that parameters {k j , c, g 21 } are known and fitted the remaining parameters {β jT , δ j , π j , Γ} to the data, where β jT = β j /f j , π j = f j p j and Γ = f 2 g 12 /f 2 .We model the interaction between a susceptible class S(t), infected class of asymptomatic individuals, i a (τ, t), and infected class of symptomatic individuals, i s (τ, t). The independent variables are τ , the age of infection in an individual, and t, the time-since-outbreak in the population. We assume the individual infection status is given by its virus profile at time τ , V (τ ), with V (τ ) = V T (τ ) = f 1 V 1 (τ ) being the solution of system eq. (1). We assume that β is the transmission rate, λ j the force of infection, b the birth rate, µ the death rate, m j the disease induced mortality rates, and j ∈ {a, s}. In the absence of testing, the model is given bywhere f is the fraction of infections that are symptomatic. Parameters {β, µ, m a , m s , f } are taken from literature, and δ(τ ) is the Dirac delta function. A summary of the parameters we used in eqs. (2) and (3) is given in Table 2 .We determine a per capita random testing rate, ρ rand , corresponding to an overall testing capacity of C tests per day, as follows. If subjects are removed from a population P by testing at per capital rate ρ rand , then the remaining untested population is given byThe total number of tests administered in a given day is P (0) − P (1) = P 0 − P 0 e −ρ rand . Setting this equal to the testing capacity C, we find that the daily random testing rate corresponding to the administration of C test is given byso long as C < P 0 . Thus, if N (t) is the population subject to random testing at time t, the time-dependent continuous testing rate isfor N (t) < C.Given virus profiles for infected individuals, we link test sensitivity to the ages of infection during which virus load is above the sensitivity threshold. Similarly, we determine the ages of infection during which the virus load is high enough to allow transmission. We define τ j 1 = age for onset of virus detectability by given test, τ j 2 = age for onset of infectiousness, τ j 3 = age for end of infectiousness, τ j 4 = age for end of virus detectability by given test,where parameter 0 < γ < 1 represents the relative infectiousness of asymptomatic carriers, in comparison with symptomatic carriers. The case detection rate functions r j (τ, t) becomewhere j ∈ {a, s}. We assume a test return delay of days, and that individuals who receive a positive test result are isolated, and can no longer transmit the virus. Lastly, we ignore the possibility of reinfection. The between-host model equations under testing becomewhere τ = τ − and t = t − . The cumulative number of cases at time t, Σ(t), is given by the equationand the cumulative number of detections at time t, P (t), is given by the equationThe boundary and initial conditions (see eq. (3)) and parameters {b, β, µ, m a , m s , f } (see Table  2 ) are as before. The return delay and ages τ k j for j ∈ {a, s} and k ∈ {1, .., 4} vary among tests. A summary of parameters and initial conditions are given in Table 2 and the integration method is described in the Appendix.We develop a between-host SI model for a well-mixed population, given by a system of ordinary and partial differential equations. It considers the interactions between susceptible individuals, S(t), and two types of infected individuals: asymptomatic, i a (τ, t), and symptomatic, i s (τ, t). The independent variables are the age of infection in an individual, τ , and the time-since-outbreak in the population, t (see model eqs. (2) and (3) in Methods). We set an individual's incubation period to the previously estimated value of 4 days (patient E in [39] ); and assume that infectiousness occurs 1.5 days before the symptoms onset, τ 2 = 2.5 days [18] , and ends eight days later, τ 3 = 10.5 days.To determine the effect on the total population, N (t) = S(t) + ∞ 0 [i a (τ, t) + i s (τ, t)]dτ , of tests with different sensitivities, frequencies, and return delays, we expand the SI model to include the age of infection at which a test first gives a positive result, τ 1 ; the age of infection past which a test can no longer detect the virus, τ 4 ; the return delay, ; and the daily testing capacity, C. Assuming that surveillance testing occurs in a randomized manner, we calculate a continuous testing rate ρ rand (t), which is equal to − ln(1 − C/N (t)). This connects the daily testing capacity C with the population that is subject to random testing on a particular day, N (t) (see eq. (4) in Methods, for a derivation). The resulting system of differential equations (see model eqs. (5) and (3) in Methods) was used to predict epidemic outcomes under three testing regimes: an RT-PCR test, a rapid antigen test, and a paper-strip test. We assume a fixed daily testing capacity of 10% of the initial population, C = 0.1, which is administrated randomly among the groups, and an initial 1% of the population being infected. A portion f = 0.7 of the initial infected population is in the symptomatic class, and the remaining 1 − f = 0.3 is in the asymptomatic class.Under a rapid antigen test with fixed C = 0.1 daily testing capacity rate, detection interval (τ 1 , τ 4 ) = (2.77, 7.37) days, and delay in test results of = 0.5 days, model (5) predicts a peak infection at 45 days after the start of the outbreak, three days later than in the RT-PCR case. At that time, 5.5% and 2.4% of the population have symptomatic and asymptomatic infections, respectively, lower than in the RT-PCR testing scenario (see Figure 2 , panel B, red and blue curves). While the infection does not decay to less than 0.1% daily case until day 90 after the start of the outbreak, the total population infected half a year after the start of the outbreak is 47%, lower than in the RT-PCR case where 57% individuals had the infection. This occurs in spite of only 42.6% of infections being detected (see Figure 2 , panel B, magenta versus green curves). The highest daily incidence of 0.78% occurs 40 days after the start of the outbreak (see Figure 2 , panel B, yellow bars) and daily detection rates peak 8 days later, at day 48 (see Figure 2 , panel B, blue bars).Lastly, under an even faster yet lower sensitivity paper-strip (or antigen) test with fixed C = 0.1 daily testing capacity rate, detection interval (τ 1 , τ 4 ) = (3.48, 6.14) days, and delay in test results of = 0.1 days, model eq. (5) predicts a peak infection 47 days after the start of the outbreak, when 9% and 3.8% of the population have symptomatic and asymptomatic infections, respectively (see Figure 2 , panel C, red and blue curves). While the peak of infection is delayed, the daily infections are higher than both those in the RT-PCR and antigen testing approaches. At half a year after the start of the outbreak 59% of population has been infected. Of those, 27.1% have been detected (see Figure 2 , panel C, magenta versus green curves). The highest daily incidence of 1.15% occurs 41 days after the start of the outbreak (see Figure 2 , panel C, yellow bars), lower than in the RT-PCR but higher than in the antigen testing approach. The daily detection rates peak 46 days after the start of the outbreak (see Figure 2 , panel C, blue bars).These results show that, with fixed testing capacity, tests that return results quickly, slightly flatten the daily incidence curve. The sensitivity is important, however, with low-sensitivity (corresponding to rapid antigen tests) resulting in a slight reduction in the total infections half a year into the outbreak, and super-low-sensitivity (corresponding to paper-strip tests) resulting in increased total infections. To more closely determine the relationship between the total cases half a year after the start of the outbreak, the return delays, and the test sensitivities, we derive a heat map for smaller sensitivity and delay increments (see Figure 3 , panel A). We find that the RT-PCR holds better results than a test that detects 10 3 , 10 4 and 10 5 RNA per swab in half a day, only when the return is shorter than 2, 2.8 and 4.2 days, respectively. This means that, under the same daily test capacity, low-sensitivity tests can be a preferable surveillance resource in areas where there are long delays in RT-PCR returns.We next investigate the effect that increased testing frequency has on the outcomes. While, under the Families First Coronavirus Response Act, testing in the United States is free of cost for an individual, the overall public health (or institutional) budget associated with test administration and processing may limit the overall number of tests available for administration each day. Conversely, reduction in test cost allows for increased testing capacity and frequency. We use model eq. (5) to quantify the overall infection, half a year after the start of the outbreak, when we provide as many tests as possible under a fixed daily budget.Early and current studies show varied cost ranges for molecular and/or antigenic tests [26] . We assume the following costs for a single RT-PCR [26] , Yale saliva [40] , and Abott BinaxNow [1] tests: 50 USD, 10 USD and 5 USD, respectively. When we administer RT-PCR tests costing 50 USD, the daily testing capacity is equal to 10% of the population, C = 0.1, as in the previous sections. When we administer a saliva test costing 10 USD, the daily testing capacity is equal to 50% of the population, C = 0.5. Lastly, when we administer an Abott BinaxNow test costing 5 USD, the daily testing capacity is equal to 100% of the population, C = 1. Under these assumptions, the daily budget is the same regardless of the testing strategy. Moreover, we extrapolate these values to obtain intermediary cost functions (see Figure 3 , panel B). We next derive a heatmap for the total cases, half a year after the start of the outbreak, for equal budget, varied testing sensitivities, and varied test return delays (see Figure 3 , panel C).We determine that tests of low-sensitivity (10 5 virus load per swab detection and half a day return delay) that are administrated daily vastly outperform high-sensitivity tests. In particular, half a year after the start of the outbreak, the total number of cases is reduced from 19.4% for a RT-PCR that is returned in 24 hours (25.9% for a 48 hours return) to less than 1.2% when the low-sensitivity rapid test is given to everyone every day (see Figure 3 , panel C). This is not a transient result, with overall infection reaching a maximum of 3.2% three years after the start of the outbreak. If the same low-sensitivity test is administered every other day, the overall infection is reduced to 3.8% half a year after the start of the outbreak; and if everyone is tested once every three days, the overall infection is reduced to 5.4% (not shown). If, however, everyone is tested with low-sensitivity tests once a week, than the overall infection is 30% half a year after the start of the outbreak (not shown), as high or higher than for the RT-PCR tests that are returned in less than 2.5 days. There is, therefore, a clear tradeoff between frequency, test sensitivity, and test return delays, which should be optimized to the needs of each community.We investigate how testing regimes differentially affect the proportion of transmission associated with each disease status (symptomatic, presymptomatic and asymptomatic). We define presymptomatic, as infections that occur before day τ presym = 4 days [18] . As seen in the previous sections, under fixed C = 0.1 daily testing, the peak daily incidence is reduced by 38.2% and 9.0%, respectively, when the antigen or paper-strip testing regimes replaced the standard RT-PCR tests. We further split the peak daily incidence into infections that occur due to symptomatic, presymptomatic and asymptomatic transmission (see Figure 4 , orange vs red vs blue bars). Using the antigen test, peak daily incidence due to symptomatic transmission is reduced by 39.9% compared with RT-PCR, presymptomatic transmission is reduced by 33.2% and asymptomatic transmission is reduced by 38.2%. Using the paper-strip test, peak daily incidence due to symptomatic transmission is reduced by 8.9% compared with RT-PCR, presymptomatic transmission is reduced by 9.2% and asymptomatic transmission is reduced by 9.0% (see Figure 4 , orange vs red vs blue bars).To account for the lower costs associated with antigen and paper-strip tests, we also calculate the reduction in peak daily incidence when these tests are administered at higher frequency than RT-PCR. As before, we assume that RT-PCR is administered at a fixed daily capacity of C = 0.1. When antigen tests are administered at daily capacity C = 0.3, C = 0.6 and C = 1 the total peak daily incidence is reduced by 70.4%, 76.2% and 79.0%, respectively. When paper-strip tests are administered at these capacities, the total peak daily incidence is reduced by 68.3%, 73.1% and 77.4%, respectively. We see limited variability in the reduction of infection due to symptomatic, presymptomatic and asymptomatic transmission (see Table 3 ).When antigen and paper-strip tests are administered with the same capacity as RT-PCR, C = 0.1, the antigen test significantly outperforms the paper-strip test in reducing peak daily incidence (38.2% vs. 9.0% reduction). However, as the capacity is increased, this difference in performance vanishes, and both tests approach a limiting peak incidence reduction of approximately 80% (see Table 3 ). This indicates that there is a critical capacity required to achieve significant incidence reductions with less sensitive tests.While RT-PCR is the gold-standard for diagnosis of SARS-CoV-2 cases, there are significant challenges in implementing effective epidemic surveillance and mitigation regimes on the basis of these tests, due to the need for specially trained lab personnel, limited lab capacity, high costs per test and delays in returning test results. Alternative tests such Abbott BinaxNOW TM can produce results rapidly, at lower cost and without the need for specialized lab personnel, but are less sensitive to lower virus concentrations. We investigated the tradeoffs between test sensitivity, return delay and test frequency using a deterministic mathematical model of virus transmission.Our model shows that for fixed testing capacity, lower sensitivity tests with shorter return delays slightly flatten the daily incidence curve and delay the time to the peak daily incidence. The cumulative number of infections, however, shows a more complicated interaction between the loss of sensitivity and the benefits of faster test returns. We find that low-sensitivity tests with a return delay of one half day, such as antigen tests, reduce the cumulative case count at half a year into the outbreak. Despite the higher sensitivity of RT-PCR, in order to outperform the antigen test, its return delay would need to be reduced below 3 days. On the other hand, super-low-sensitivity tests with a return delay of 2 − 3 hours, such as paper-strip tests, result in a cumulative case count slightly higher than RT-PCR.We also studied whether there is a differential impact of alternative testing strategies on the proportion of viral transmission from sources at different stages of infection. When compared with RT-PCR, antigen and paper-strip tests reduce the number of new infections due to symptomatic, presymptomatic and asymptomatic sources by roughly equal amounts. This reduction is greater for increased testing frequency, however, the improvement is capped at approximately 80%.Our modeling approach includes several simplifying assumptions, some of which can be relaxed to generalize our results in a variety of ways. First, we assume a well-mixed population and the model is therefore most suitable to a tightly interconnected community such as a college campus. Our findings support the conclusions of Paltiel, et al. [32] , who found that frequent (every 2 days), low-sensitivity testing might be necessary in order to allow for college reopening. Moreover, several modeling studies have found that diagnostic testing of symptomatic patients alone is insufficient for outbreak control, and must be supplemented by randomized surveillance testing of the asymptomatic population [8, 11, 22, 32] . Indeed, under randomized and uniformly distributed surveillance testing of the entire non-isolated population, we find that frequent testing of the entire population can flatten the daily incidence curve and significantly decrease the cumulative size of the outbreak. Further work is needed to compare randomized testing to alternate strategies such as prioritizing the testing of high-risk or symptomatic individuals or preemptively quarantining those with symptoms and testing only asymptomatic individuals.We have assumed a 100% detection rate when tests are administered to patients whose viral load is above the sensitivity threshold. As mentioned before, the BinaxNOW TM antigen rapid test has sensitivity levels of 85.7% for Ct< 25 (when the virus still infects), and 36.4% for Ct> 30 (when the virus may no longer be infectious) [22, 33] . We assume a step-function dependence of detection on viral load, with 0% detection below the threshold and 100% detection above. Moreover, we assume that all infected individuals have identical viral dynamics over the course of infection. Once available, more complete information about patient viral profiles and the dependence of test sensitivity on viral load can be incorporated to increase the accuracy of the model and to quantify the incidence of false negatives.In summary, our study shows that surveillance testing that employs low-sensitivity tests at high frequency is an effective tool for epidemic control. Reduced cost per test is essential for the success of this approach, as it allows for the increased testing frequency, which overcomes sensitivity concerns. This more effective testing strategy would enhance the effectiveness of control measures that are testing-dependent, such as contact tracing, isolation and quarantining, further increasing our ability to overcome the COVID-19 epidemic.as follows. We discretize by taking equally spaced steps along the individual age of infection and the population time-since-outbreak, ∆τ = ∆t. Let K = G/∆τ and Q = T /∆t . Then, the age and time steps become τ k = k∆t and t q = q∆t, for 1 ≤ k ≤ K and 1 ≤ q ≤ Q. The delay will comprise L = /∆τ time steps.We initialize the system with S 1 = S(0) andi k,1 s = f i 0 ∆τ , for k = 1 0, otherwise .The initial infected population is assumed to have infection age τ = 0 at time t = 0, split between symptomatic and asymptomatic classes according to the ratio f . The total initial infected population is Discretized versions of the functions λ a , λ s , r a and r s are needed. The force of infection terms λ a (τ ) and λ s (τ ) are independent of t and discretized versions are defined byλ k s = 1, for τ s 2 ≤ k∆τ ≤ τ s 3 0, otherwise .The testing rate ρ rand (t) depends on t, so at each time step q we calculate ρ q rand = − ln(1−C/N q ), where N q is the total current testable population N q = S q + K k=1 i k,q a + i k,q s .Given values for all state variables and all age classes at time step q, we update all state variables to time step q + 1. First, we calculate i a and i s at time step q + 1 for each age class except the first. For k ≤ L or q + 1 ≤ L, no positive test can have been returned, so i j is governed byUsing the method of characteristics, this equation can be solved precisely over the square [k∆t, (k + 1)∆t] × [q∆t, (q + 1)∆t] to give i k+1,q+1 j = i k,q j e −(µ+m j )∆t . For k > L and q + 1 > L, testing and removal affects the dynamics of the infected classes, so i j are governed by ∂i j ∂τ + ∂i j ∂t = −(µ + m j )i j (τ, t) − r j (τ , t )i j (τ , t )e −(µ+m j ) .If we assume that the second term on the right hand side is a constant over the domain [k∆t, (k + 1)∆t]×[q∆t, (q +1)∆t], we can again use the method of characteristics to integrate over this square. This results in Next, we calculate the integral representing the force of infection. [λ a (τ )i a (τ, t) + λ s (τ )i s (τ, t)] dτ.Third, we calculate the updated value of S using the standard implicit method S q+1 = S q + µ∆t 1 + ∆t(µ + βInfInt) .Finally, we fill in the age 0 infection level i 1,q+1 = βS q+1 InfInt.This completes the update of the scheme from time step q to time step q +1 for all state variables and all age classes.",USA,first author,2021-02-18,02
52ce24a09a57de7dd2d851dabba795ae01f12043,The proximal proteome of 17 SARS-CoV-2 proteins,"is either unknown or highly variable across differing coronaviruses, underscoring the need to 65 begin mapping their putative localizations and functions. 66 Proximity proteomics (BioID) uses enzymes, such as the modified bacterial biotin ligase, BirA, to 67 biotinylate nearby proteins on lysine residue-containing proteins within a radius of 10-20nm (4). 68 When fused to a protein of interest it labels not only proteins that directly bind the fused protein 69 but also those adjacent to it, enabling rapid isolation of biotinylated proteins whose identity can 70 provide clues about the localization and function of the protein studied. When coupled to mass 71 spectrometry it provides an alternative to traditional tandem affinity purification and mass 72 spectrometry (TAP-MS) (5). Whereas, TAP-MS can isolate protein complexes that stably bind 73 the protein of interest in a manner robust enough to survive protein extraction, BioID-MS labels 74 both transient and stable interactors in living cells, particularly those stabilized by cellular 75 Meyers et al. 5 membranes that can be destroyed in traditional TAP-MS experiments. In this way, BioID may 76 localize the cellular ""neighborhoods"" of a given fusion protein. We recently generated a biotin 77 ligase derived from Bacillus subtilis, which has 50 times greater activity than the original E. coli 78 BirA (4, 6), allowing decreased labeling times and increased signal-to-noise ratios. Applying 79 proximity proteomics to SARS-CoV-2 viral proteins in human cells may facilitate insight into their 80 localization and putative functions. 81 The actions of specific SARS-CoV-2-encoded proteins are only partially understood at present. 82 The replication transcription complex, which includes the RNA-dependent RNA polymerase and 83 other factors, and the structural proteins, which are necessary for protecting the newly 84 synthesized genomes and assembling the viral particles, comprise the core viral replication 85 machinery. Other viral gene products, generally termed accessory factors, are believed to be 86 dedicated to manipulating the host environment to foster viral replication (7). One of the main 87 functions of accessory factors is to block host antiviral response (8). Non-SARS-CoV-2 88 coronaviruses have also been shown to block host translation (9, 10), inhibit interferon signaling 89 (11, 12), antagonize viral RNA sensing (13, 14), and degrade host mRNAs (15). The degree of 90 homology between SARS-CoV-2 and other coronaviruses, suggests the existence of both shared 91 and divergent host protein interactions between its viral proteins and those of the other members 92 of the coronavirus family. 93 Here we used proximity proteomics to identify the human proteins vicinal to 17 major SARS-CoV-94 2 proteins and, from that data and validation studies, to predict their likely location and function. 95 We examined the intersection of the resulting atlas of human factors adjacent to SARS-CoV-2 96 viral proteins with risk loci associated with severe COVID-19 by genome wide association studies 97 (GWAS). This nominated specific, viral protein-adjacent host candidates whose natural variation 98 in expression may contribute to differences in COVID-19 susceptibility in the population. We also 99 demonstrated that multiple SARS-CoV-2 products can affect host translation and host innate 100 Meyers et al. 6 immune signaling and define a list of potential host targets and pathways for the NPS5 protease. 101 Taken together, these resource data plot the location of the 17 major SARS-CoV-2 within the cell, 102 define an atlas of human host proteins adjacent to them, and offer insight into potential pathogenic 103 mechanisms engaged by SARS-CoV-2.Host proteins proximal to viral proteins and their subcellular localization 106 To identify the human host proteins vicinal to the 17 major SARS-CoV-2 encoded viral proteins, 107 HA epitope tagged fusions of BASU-BirA (6) were generated with each of these 17 viral ORFs 108 (Fig. 1A) . BASU was introduced at the N and C terminus to minimize disruption as previously 109 described (16) . Samples were prepared from plasmid-transfected 293T cells after 2 hours of 110 biotin labeling and the biotinylated proteins were then isolated using streptavidin. Samples were 111 divided for LC-MS/MS and immunoblotting (Fig. S1) . MS data search was performed and protein 112 lists were analyzed and scored using the Significance Analysis of Interactome (SAINT) method 113 (17). Using a cutoff of a SAINT score of 0.9 generated a list of 2422 host proteins (Fig. 1B, Fig.   114 Table S1 ) across the 17 viral proteins studied, 514 of which were unique to a specific viral 115 protein. These data (Table S2 ) comprise a compendium of candidate human proteins adjacent to 116 SARS-CoV-2-encoded proteins. 117 The identity of these 2422 human proteins provided clues to SARS-CoV-2 biology. Molecular 118 function analysis (Fig. 1B-D) identified processes associated with SARS-CoV-2 viral protein 119 impacts. This included translation initiation, RNA binding, the 26S proteasome, signaling, and 120 SNARE-associated intracellular transport. It also identified adjacencies to major histocompatibility 121 (MHC) proteins and components of the nuclear pore complex (NPC). A number of these 122 processes, such as protein translation, are known processes affected by coronaviruses, while 123 others, such as RNA-binding, are less well characterized. To begin to map putative localizations for the 17 studied SARS-CoV-2 proteins within the cell, 125 cellular component GO-term enrichment analysis was performed ( Fig. 2A) , which pointed to 126 possible intracellular localizations for each viral protein based on curated knowledge of the host 127 proteins identified adjacent to each viral protein. To validate and extend this, protein fractions 128 were prepared from cells expressing each SARS-CoV-2 protein studied. These included four 129 overlapping fractions: a) cytoplasm b) cytoplasm/membrane c) nucleus/membrane, and d) 130 nucleus (Fig. 2B) . Integrating GO-term analysis with immunoblotting of these fractions enabled 131 predictions of the likely intracellular localization of each viral protein (Fig. 2C) . We further 132 confirmed NSP5 diffuse expression and ORF3a membrane localization through immunostaining. 133 Many SARS-CoV-2 accessory proteins concentrate in the ER or in ER-proximal membranes (M, 134 ORF3a, ORF3b, ORF6, ORF7a, ORF7b, ORF8, and ORF10). A number, however, appear to be 135 predominantly cytoplasmic (NSP1, NSP2, NSP5, NSP9, NSP15, ORF9b) and, interestingly, 136 several appear to localize in part to the nucleus (NSP14, ORF6, ORF9c). The localization 137 predicted from these data is consistent with observations from other recent work (16, 18) . Of the 138 membrane localized proteins, subtle differences in location could be inferred. In the case of M 139 protein, association with membranes in the endocytic pathway as well as lysosomal membranes 140 was predicted. ORF8 and ORF10 clustered similarly with enrichment for ER interactions in the 141 lumen. These data indicate that specific SARS-CoV-2 may display increased localization to a 142 variety of intracellular sites, including the cytoplasm, nucleus and distinct endomembranes. 143 Viral proximal interactors include drug targetable host genes. 144 There is a lack of SARS-CoV-2 specific antiviral therapies or against coronaviruses generally. 145 Many current and experimental therapeutics were developed for activity against other viruses and 146 are being tested for cross efficacy against SARS-CoV-2. Others are therapies known to have 147 broad antiviral effects. There is significant interest in developing drugs that directly target SARS- 148 CoV-2 viral proteins, but research and development may take years before use in patients. 149 Another approach is using drugs against host genes critical to virus infection and replication. For 150 Meyers et al. 8 example, drugs targeting ACE-2, the main receptor for SARS-CoV-2, or ACE-2 expression and 151 function have been pursued. To expand the list of possible drugs beyond entry inhibitors, we 152 compared the viral proximal proteome generated in this study against the ""druggable"" genome, 153 which include databases of the gene targets of available drugs. This generated a list of 47 host 154 genes (Fig. S3, Table S3 ) and highlights, as previously reported (16) The resulting disease risk-linked variants were further distilled to those identified as expression 174 quantitative trail loci (eQTLs) for specific putative eGene targets (Fig. 3A) . These eGenes, which 9 represent a set of genes whose expression may be controlled by natural variants in the human 176 population linked to COVID-19 risk, were then intersected with the atlas of host factors identified 177 as adjacent to SARS-CoV-2 viral proteins by proximity proteomics. Publicly available protein 178 interaction data was then integrated to project the connectedness of resulting gene set (Fig. 3B) . 179 The resulting network was notable for host proteins implicated in cytokine signaling, cell cycle 180 control, transcription, and translation, suggesting that genetic susceptibility to COVID-19 may link 181 to variations in the expression of proteins that mediate these processes. 182 Among proteins identified by this analysis was TRIM4, a RING E3 ligase, that activates type I 183 interferon signaling through activation of the cytosolic RNA sensor RIG-I. TRIM4 was significantly 184 associated with SARS-CoV-2 M protein in proximity proteomics data (Table S1 ) and, using proximal proteome (Fig S2C) . To nominate possible host targets of NSP5 whose levels are 258 decreased upon protease expression, we performed SILAC mass spectrometry comparing wild 259 type SARS-CoV-2 NSP5 to the catalytically-inactive NSP5 C145A mutant (16, 46) . Residue 145 is 260 the critical catalytic cysteine and mutation to alanine prevents protease activity (47). A number 261 of host proteins showed significant depletion in cells expressing wild type NSP5, but not protease-262 inactive NSP5 C145A (Fig. 5A) . Combining both data generated identified an additional 26 263 candidates resulting in a pool of 60 potential host protein targets for NSP5 (Fig 5B) . 264 To begin to examine potential cleavage of these candidate proteins by NSP5, we searched their 265 peptide sequences for potential cleavage sites using a published a cleavage prediction algorithm 266 (48). We then took these peptide sequences and tested them for cleavage by NSP5 using a loss Innate immune signaling is a central mechanism of host cell response to viral infection. ORF6 of 365 SARS-CoV-1 (11) and SARS-CoV-2 (38) were shown to be potent inhibitors of such antiviral 366 signaling. One proposed mechanism is that ORF6, through association with specific NPCs 367 (RAE1-Nup98), blocks import of activated transcription factors needed to induce IFNB1 368 transcripts and other primary interferon-stimulated genes. In this regard, we identified MAVS 369 proximal to ORF6 and ORF9b. We observed that ORF6, but not ORF9b, inhibited RLR signaling 370 downstream of RIG-I RNA-binding. Taken with the observed adjacencies to nuclear pore proteins 371 noted above, it is likely that the model suggested for ORF6 from SARS-CoV-1 (39) may also be 372 operative for SARS-CoV-2 and that disruption of nuclear import may not be specific only to 373 immune-specific transcription factors but may affect a wider variety of imported proteins. 374 Viral proteases, such as SARS-CoV-2 NSP5 studied here, have been shown to be potent antiviral 375 targets (74). These proteases are essential for viral replication and escape has proven difficult in 376 resistance studies (75). Coronaviruses encode two proteases NSP3 and NSP5, with NSP5 377 classified as the main protease. They are both necessary for the processing of the ORF1ab 378 polyprotein containing the viral replicase proteins. NSP5 shows similarity to proteases found in 379 picornaviruses and noroviruses (76) . Beyond their importance in viral replication, these viral 380 proteases can target host proteins containing their target residues (77). NSP5 recognizes certain 381 glutamine-serine/alanine/glycine residues, with added specificity being determined by two to three 382 flanking residues (48). Picornavirus virulence has been shown to be mediated in part by 3C 383 protease cleavage of host proteins (44). Using both BioID and SILAC metabolic labeling followed 384 by mass spectrometry, we sought to identify candidate host proteins and use a modified FRET-385 based cleavage assay to determine if these candidates contained sequences cleavable by NSP5. 386 We identified human CWC22 and FANCD2 as candidates; both proteins contained sequences 387 that could be cleaved by NSP5 in an assay used here which can be used to rapidly assess other ",USA,first author,2021-02-23,02
2890a0d5c84f965c1724464c61e5a8d4ef8e7a51,"Highlights US COVID-19 cases and deaths associated with some industries Retirement and skilled nursing facilities associated with fewer cases and deaths Meatpacking plants and bakeries associated with more cases and deaths Dairy plants associated with fewer cases and deaths Highlights (for review) Nursing Facilities, Food Manufacturing Plants and COVID-19 Cases and Deaths","Early in the COVID-19 pandemic, news outlets highlighted potential viral hotspots within certain environments. Essential services including nursing homes and meatpacking plants were scrutinized (Dickerson & Jordan, 2020; Wilson & Kummerer, 2020) to the extent that a The New York Times article claimed that meatpacking plants and nursing homes were ""proven to be places where the virus spreads rapidly"" Corkery, Yaffe-Bellany, and Kravitz (2020) . Outbreaks in residential care homes were attributed to the proximity of vulnerable individuals, while poor working conditions were blamed for outbreaks at meatpacking plants (Chavez & Karimi, 2020; Ellis & Hicken, 2020; Wilson & Kummerer, 2020) . However, there is no systematic quantitative evidence to support or refute these claims, to date.The aim of this article is to examine the relationship between the geographic concentration of two industries-nursing and residential care facilities, and food manufacturing establishments-and COVID-19 cases and deaths during the first wave of the pandemic in the US (through May 28, 2020). Although the study design is not explicitly causal, our findings suggest that industry-based mitigation strategies could have lowered the prevalence of the disease.We constructed two datasets, one with the Hospital Referral Region (HRR) (Dartmouth Atlas, 2020) as the unit of observation and the other with Metropolitan Statistical Area (MSA) (US Census Bureau, 2020) as the unit of observation, using a number of publicly available sources.We measured cumulative cases and deaths through May 28, 2020 using data from the Johns Hopkins Center for Systems Science and Engineering (Center for Systems Science and Engineering, 2020). We ended measurement on May 28, 2020 rather than on May 31, 2020 because May 31 was a Sunday. Weekend reporting is suspect given the lower cases and deaths on most weekends and compensating spikes most Mondays. They are both updated daily at the county level with a few exceptions.The most notable exception is that of measurement in the five boroughs of New York City. Each borough is a county with a set of stipulations for reporting cases and death. We used the New York City Department of Health and Mental Hygiene's coronavirus-data GitHub repository (NYC) to apportion the New York City cases and deaths to the five boroughs (counties) (NYC Department of Health and Mental Hygiene, 2020).We obtained data on the number of business establishments by industry and county from the US Bureau of Labor Statistics' Quarterly Census of Employment and Wages (QCEW) (Bureau of Labor Statistics, 2020b). The QCEW surveys 95% of U.S. jobs to obtain data on the number of establishments, monthly employment and quarterly wages at the county level. The measures are classified by industry using North American Industry Classification System (NAICS) (North American Industry Classification System, 2020).The datasets include two groups of 4-digit NAICS industry classifications: nursing and residential care, and food manufacturing. Nursing and residential care consists of skilled nursing facilities (skilled nursing, NAICS code 6231), developmental disability, mental health, and substance abuse facilities (mental health, 6232), retirement communities and assisted living facilities (retirement communities, 6233) and other residential care facilities (6239). The food manufacturing industries in our data are grain and oilseed milling (cereal, NAICS code 3112), sugar and confectionery manufacturing (confectionery, 3113), fruit and vegetable preserving and specialty food manufacturing (fruit and vegetable preserving, 3114), dairy product manufacturing 2 J o u r n a l P r e -p r o o f (dairy, 3115), animal slaughtering and processing (meatpacking, 3116), seafood product preparation and packaging (seafood preparation, 3117) and baked goods plants and tortilla manufacturing (bakery, 3118).We used The National Cancer Institute's Surveillance, Epidemiology, and End Results Program's (SEER) 1990-2018 4 Expanded Races by Origin and Age file to compute county-level race and ethnicity specific populations for 2018 (Surveillance, Epidemiology, and End Results Program, 2020) . County land area (Hornsby, 2020) was used in conjunction with the 2018 SEER population data to determine population density. County-level poverty rates were obtained from the USDA's Economic Research Service's Poverty dataset (United States Department of Agriculture, 2020).Google documents mobility trends daily in a given area relative to a baseline day (Google Inc., 2020). We used county-level data to obtain the earliest dates on which mobility dropped by 25% in retail and recreation areas and increased by 15% in residential areas.We obtained climate data by measuring station from the National Oceanic and Atmospheric Administration Global Historical Climatology Network (GHCN)-Daily dataset (Global Historical Climatology Network, 2020). We spatially merged weather stations to US counties and calculated county-level average daily maximum temperature over the period January 1, 2020 through February 29, 2020.Data from Alaska and Hawaii were excluded from our analyses. We use data on 304 HRRs and 377 MSAs in the contiguous US in our statistical analysis.We estimated Generalized Linear Models (GLM) with log link and Poisson density (McCullagh & Nelder, 1989) . In addition to the variables mentioned above, our models control for time (measured as the number of days as of May 28, 2020) since the first death in the state in which the geographic unit is located. Poisson GLM models, robust to misspecification influence of few large outliers, have been used in 3 J o u r n a l P r e -p r o o f Journal Pre-proof recent literature by Kraemer et al. (2020) and Tobías and Molina (2020) to model COVID-19 outcomes. We used cluster robust standard errors for inference. In figure 2 we display the associations between nursing and residential care facilities and COVID-19 cases and deaths. At the HRR level, skilled nursing facilities are associated with 5 percent fewer cases and 5 percent fewer deaths. At the MSA level, however, the associations of skilled nursing facilities with cases and deaths are not statistically significant. An additional mental health care facility is associated with statistically significant 2 percent greater cases and deaths at the HRR level but such facilities are not significantly associated with cases and deaths across MSAs.Retirement communities and assisted living facilities are associated with statistically significant 6 percent fewer cases and deaths across HRRs and 4 percent fewer cases and deaths across MSAs. Other residential care facilities are generally not significantly associated with cases or deaths.Figure 2 also shows the associations between the geographic locations of food manufacturing establishments and COVID-19 cases and deaths. An additional dairy plant is associated with 13 percent fewer cases and 18 percent fewer deaths across HRRs, and 9 percent fewer cases (p=0.09) and 17 percent fewer deaths across MSAs.An additional meatpacking plant is statistically significantly associated with 21 percent (16 percent) more cases across HRRs (MSAs). An additional meatpacking plant is also associated with 7 percent more deaths, but this effect is not significant at the MSA level. Although seafood plants are less common across the country, we 4 J o u r n a l P r e -p r o o f show that they are associated with statistically significant 15 percent additional cases across HRRs and 13 percent across MSAs. An additional seafood plant is also associated with 14 percent (with p=0.16) more deaths at the HRR level and 16 percent more deaths at the MSA level. Notably, the most common food production industry, baked goods plants, are associated with significantly more cases and deaths. An additional bakery establishment is associated with 14 percent and 9 percent more cases, and 13 percent and 10 percent more deaths at the HRR and MSA levels respectively.The associations between numbers of grain and oilseed milling establishments, sugar and confectionary manufacturing establishments, fruit and vegetable preserving and specialty food manufacturing and cases and deaths are not statistically significant.In figure 3 we display the associations for all control variables. Population density is associated with 19 percent and 26 percent more deaths across HRRs and MSAs, respectively, and with 7 percent more cases at the HRR level. The association is not significant for cases at the MSA level. Moreover, a 1 percent increase in the proportion of the Black population is associated with more cases (4-5 percent) and deaths (3-4 percent) across HRRs and MSAs. In addition, a 1 percent increase in the Hispanic share of the population is associated with 1 percent and 2 percent more cases across HRRs and MSAs, respectively, but the association is not significant for deaths. The associations are not significant for other non-White population shares (p>0.16). Poverty rates are not significantly associated with deaths. Poverty rates are, however, associated with fewer cases at both HRR and MSA levels, which is consistent with variation in testing and access to healthcare. A decline in mobility (to the thresholds specified above) starting a day earlier is associated with 1 percent and 2 percent fewer deaths across HRRs and MSAs, respectively, and with 1 percent fewer cases across MSAs. The associated is not statistically significant at the HRR level (p=0.5). Finally, an increase in average winter temperatures (see above) by 1 • C increase is associated with 4 percent and 5 percent fewer cases and 4 percent and 6 percent fewer deaths across HRRs and MSAs, respectively.Journal Pre-proofWe conducted a number of sensitivity analyses to examine the robustness our findings.First, we excluded the observations for the HRRs and MSA that encompass New York City. Second, we excluded geographic units in states that did not formally issue shelter-in-place orders, namely, Iowa, North Dakota, Oklahoma, South Dakota, and Utah. Third, we excluded tortilla manufacturing, a niche product, from counts of baked goods plants. Fourth, we checked the models' sensitivity to alternative specifications of changes in mobility using combinations of 20% and 25% drops in retail and recreation areas and increases in movement between 15% and 20% increases in residential areas as targets to ascertain the earliest public response dates. Finally, we checked the models' sensitivity to alternative definitions of temperature. We find (results available upon request) that the estimates of associations between food production establishments and nursing and residential care facilities with cases and deaths are qualitatively unchanged from our primary analysis.In this study, we examined the relationships between the geographic concentration of two industries that remained open through the initial shelter-in-place orders, and COVID-19 cases and deaths during the first wave of the pandemic in the US. Our results suggest that residential elder care establishments are associated with lower COVID-19 cases and deaths. This finding contrasts with press reports that nursing homes have suffered COVID-19 outbreaks (Corkery et al., 2020; Dickerson & Jordan, 2020; Wilson & Kummerer, 2020) . Our regression results and these press reports are, however, not inconsistent. It is likely that many skilled nursing facilities, retirement communities and assisted living facilities, heeded authoritative warnings about the risks of COVID-19 and implemented mitigation measures (Barnett & Grabowski, 2020; Goldstein et al., 2020) . Given that the elderly have been substantially more 6 J o u r n a l P r e -p r o o f likely to suffer the worst symptoms of the disease and die from it, our results suggest that nursing and residential care facilities have actually been protective.Our results show that meatpacking plants are associated with substantially higher cases and plausibly substantially higher deaths. These findings are consistent with news reports that have centered the narrative on poor working conditions in these plants. Almost no media attention has been placed on seafood plants and baked goods plants, which are also similarly associated with more cases and deaths. Meanwhile, dairy product manufacturing establishments are associated with substantially fewer cases and deaths. While poor working conditions may explain more cases and deaths in meatpacking plants and seafood facilities, the significant associations with baked goods plants and dairies point to an alternative explanation. We examined capital to labor ratios and wages in these industries using productivity data from the Bureau of Labor Statistics and found that the three industries associated with more deaths and cases have the lowest capital to labor ratios among food production industries and employ workers at the lowest hourly wages (Bureau of Labor Statistics, 2020a).Establishments in these industries employ many workers for production, packaging and sorting tasks who work in close proximity (Sinha, 2007) . On the other end of the spectrum, dairy products manufacturing establishments have the second highest capital to labor ratio and the highest hourly wage rates. Dairy products manufacturing uses large-scale automated processes operated by higher skill workers (Kirkland, 1994; Sinha, 2007) .The estimates suggest that policy measures at the industry level had an impact on disease prevalence in the first wave of the pandemic in the US, subject to the caveat that the estimates are not strictly causal. Proactive implementation of mitigation strategies in nursing homes and retirement facilities appears to have been beneficial.On the other hand, meatpacking plants appear to have not received any guidance until April 26, 2020 and likely resisted implementing protection measures (Telford, n.d.; U.S. Department of Labor, 2020) . Proactive guidance on protective measures Notes: Regressions of cases and deaths per 100,000 persons and socioeconomic characteristics, temperature, and numbers of business establishments were estimated using generalized linear models with log link and Poisson family. The error bars indicate 95 percent confidence intervals.J o u r n a l P r e -p r o o f Journal Pre-proof Notes: Regressions of cases and deaths per 100,000 persons and socioeconomic characteristics, temperature, and numbers of business establishments were estimated using generalized linear models with log link and Poisson family. The error bars indicate 95 percent confidence intervals.",USA,first author,2021-02-25,02
a1de6b48dea33506f750ed208ebfc7b4812742ed,Fertility care amidst the COVID19 pandemic: the American experience,"In early December 2019, the first severe cases of pneumonia caused by the novel coronavirus COVID-19 were beginning to emerge in Wuhan, China, thereby marking the beginning of a global pandemic that to date has claimed the lives of over two hundred thousand people in the US and over one million people worldwide [1, 2] . The COVID-19 pandemic has also had unprecedented effects on the delivery of healthcare and on the ability to treat a broad range of acute and chronic medical conditions, including the treatment of patients with fertility-related diagnoses. Treatment of infertility and other fertility-related conditions is time-sensitive, yet rarely considered urgent, with the exception of patients wishing to cryopreserve gametes prior to gonadotoxic therapy. Once the severity of the COVID-19 pandemic was realized, reproductive endocrinologists and their professional societies throughout the world were forced to rapidly make the unprecedented decision to delay or severely limit treatment with an eye toward protecting patients and staff and avoiding further burdening of a stressed healthcare system with non-urgent medical treatment. In the US, this response was coordinated by the American Society for Reproductive Medicine (ASRM).The ASRM acted quickly in response to the developing global pandemic by releasing its initial recommendations before the most severe effects of COVID-19 were felt in the US. To this end, the ASRM assembled a COVID-19 task force tasked with developing official guidance for US fertility clinics. It was on March 17th that the ASRM issued guidelines intended to prevent healthcare-acquired infections and to limit the use of healthcare resources on non-urgent treatment. These guidelines recommended suspending the initiation of new fertility treatment cycles, including intrauterine insemination (IUI), in vitro fertilization (IVF), and nonclinically urgent gamete cryopreservation. Given the paucity of peer-reviewed data regarding COVID-19 and pregnancy outcomes, the ASRM further recommended the cancellation of all planned embryo transfers, whether fresh or frozen. The guidelines did not call for the cancellation of IVF cycles that had already been started. Clinically-urgent gamete cryopreservation, such as in patients with cancer or other conditions requiring gonadotoxic therapy, remained permissible when safe and feasible. The guidelines further called for the suspension of elective surgeries and of non-urgent diagnostic procedures, which mirrored guidance provided by the US Surgeon General to US hospitals and surgery centers. Finally, the initial guidance of the ASRM called for inperson consultations and interactions to be minimized while emphasizing that telemedicine should be used as a substitute whenever possible [3] .The ASRM COVID-19 task force reconsidered its guidance regarding fertility treatment during the pandemic on March 30th, 2020. However, no new guidelines were issued until the end of April 2020. On April 13th, the ASRM, while maintaining its position regarding the suspension of most fertility treatment, announced the formation of a diverse subgroup, comprising academic and private practice physicians, advisors, and external experts to draft guidelines for resuming fertility care. This task force was charged with prioritizing the health and safety of patients, physicians, and clinic staff, while also considering the time-sensitive nature of fertility treatment and the impact of delayed treatment on the prognosis of patients with fertilityrelated conditions. While developing guidelines for safely resuming fertility care, this task force also considered the variable impact of the COVID-19 pandemic on different geographical locations throughout the US, the varying availability of COVID-19 viral antigen and antibody testing, the availability and utilization of healthcare supplies and resources critical to hospitals and other healthcare facilities, and federal, state, and local government regulations that might impact the ability of fertility clinics to render safe and effective treatment [4] .Based on input from the subgroup formed in mid-April, the ASRM published guidelines for when to resume fertility care, how to assess the risk of resuming care, and how to mitigate these risks. Emphasizing the need for healthcare providers to assess local conditions affecting the safety and impact of resuming care on their local community, the ASRM recommended that, in general, several milestones should be considered when resuming care. These milestones included a sustained regional reduction in COVID-19 cases in the vicinity of the clinic, and the ability of local hospitals to safely treat all patients without resorting to crisis-standards of care [5] . Fertility practices were also advised to perform a formal, documented assessment of risk, in which considerations such as the ability of the practice to mitigate the risk of COVID-19 infection, and the possibility of causing permanent, negative consequences for their patients by delaying fertility care should be included.To mitigate the risks associated with resuming fertility care, the ASRM recommended that clinics develop and implement written, comprehensive policies addressing staff and patient care. According to this guidance, which included information published by the Occupational Safety and Health Administration (OSHA) and the Centers for Disease Control and Prevention (CDC) for mitigating risk in healthcare and workplace settings, clinics were advised to craft policies to limit risk to staff members who might be particularly susceptible to developing severe illness from a COVID-19 infection. Clinics were also advised to develop written sick leave policies for staff, and to consider implementing symptom/ temperature screening, handwashing, and facemask wearing policies. Frequent handwashing and surface decontamination was emphasized. Importantly, this guidance also specified that symptom and temperature screening as well as mask wearing policies should apply to patients as well as to clinic staff. The guidelines further emphasized that personal protective equipment (PPE) should be kept in sufficient supply and that clinic staff should be trained regarding appropriate PPE use for a given clinic setting.The ASRM guidelines also acknowledged the adverse impact that delaying patient care could have on specific patient populations and recommended considering medical, psychological, and emotional factors in prioritizing which patients to offer care to first when resuming care. These considerations included advanced patient age, diminished ovarian reserve, the presence of known or suspected endometriosis, the mental health and emotional wellbeing of patients, and the impact of delayed care on a patient's ability to access treatment due to insurance coverage or employment status. Other considerations, such as the number of clinic visits required for specific treatment plans, were incorporated as well in that treatments that required few clinic visits to complete were considered safer.The ASRM further emphasized the need to limit the number of patients coming into to clinic to the extent possible when resuming care. Recommendations addressing this facet of care focused on implementing and using telemedicine whenever possible for consultations, allowing clinic staff to work from home to the extent possible, limiting monitoring visits to the minimum necessary to safely complete treatment, and, importantly, limiting the number of visits for which a patient's partner would be allowed to accompany the patient [6] .Although the ASRM, as an organization, has broad influence on the practice of reproductive endocrinology in the US, compliance with the ASRM guidelines by fertility clinics is not compulsory. It is indeed difficult to know what proportion of US fertility clinics followed the ASRM guidelines regarding fertility treatment during the early phases of the COVID-19 pandemic. Preliminary prospective reporting data from the SART-CORS dataset suggests that over the course of 2020, the total number of IVF cycles approximated those in 2019, suggesting that while the pandemic paused treatment for a period of time, the cycles were most likely delayed, not cancelled [7] . A survey performed by the company FertilityIQ may provide some early insight. In their survey of 1,808 women in the US, the majority of whom selfidentified as having infertility, 63.0 % of respondents indicated that their clinic had delayed or cancelled their treatment cycle, 23.3 % indicated that they had decided to delay or cancel their own treatment cycle, and 13.7 % indicated that their treatment had continued as planned during the early months of the pandemic. The respondents also indicated in the survey, which was performed after the ASRM guidance for safely resuming treatment was released, that 44.5 % had resumed treatment. Of those who had not resumed treatment, 36.7 % indicated that they had chosen to further delay their treatment, while the rest cited either continued clinic closure, or a clinic-imposed delay.According to the FertilityIQ survey data, in response to the question ""how do you feel about undergoing treatment at this time in light of the COVID-19 oubtreak,"" 45.6 % of patients answered that they felt ""comfortable"" undergoing treatment. However, the respondents had strong feelings regarding the infection control policies of their clinics. An overwhelming majority of patients indicated that they considered compliance, by their clinic, with the ASRM guidelines to be either highly (65.4 % of respondents) or somewhat (29.4 % of respondents) important to them. The majority (51.7 %) of respondents indicated that it is very important that their clinic offer telehealth visits, and most respondents (86.2 %) indicated that they considered it highly important that the clinic staff wear masks and gloves when rendering care. Similarly, a large proportion (76.2 %) of respondents felt that clinic policies requiring patients to wear a cloth mask were highly important. While compliance with the ASRM recommendations and PPE use proved of import to patients, many patients found clinic policies that prevented their partner from attending certain procedures to be either highly concerning (45.9 %) or somewhat concerning (21.5 %), suggesting that this policy, in particular, was a source of stress for patients. Although many patients have resumed fertility treatment, many expressed concern regarding the safety of becoming pregnant during the pandemic, with 25.8 % indicating that they found the risks of being pregnant during the COVID-19 pandemic to be very concerning, and 52.9 % indicating that they found these risks to be somewhat concerning [8] .The response of ASRM to the COVID-19 pandemic was swift and decisive, and likely prevented healthcare-acquired infections in patients, physicians, and clinic staff while preserving precious healthcare resources for use in managing the initial response to COVID-19 in the US. These actions, though necessary, will undoubtedly have longterm medical, psychological, and financial effects on patients with infertility. Data from the Society for Assisted Reproductive Technology Clinical Outcome Reporting System (SART CORS) and the National ART Surveillance System (NASS) maintained by the CDC will, in time, elucidate the extent to which fertility clinics limited or stopped treatment during the pandemic, as well as the rate at which couples with infertility in the US resumed treatment during and after the pandemic. The effects of the pandemic on the long-term outcomes and mental health of couples with infertility who had planned to start treatment when COVID-19 emerged, however, will be harder to assess, and are an important subject for research in the coming years [4] . The recent experiences of fertility clinics in the US and worldwide has cast in sharp relief the potential for a global pandemic to disrupt normal operations and adversely impact the delivery of safe, effective care. While recent efforts by the American Society for Reproductive Medicine and fertility clinics in the US have, of necessity, been focused on responding to the current pandemic, there is a clear need for national guidelines establishing measures that clinics should take to prepare for future pandemics. Ongoing and future research on the impact of the COVID-19 pandemic is critical to this process, as the lessons learned during COVID-19 will serve as an important foundation for developing measures to limit the adverse impact of similar events in the future. ",United States,abstract,2021-02-18,02
089e9b3a95c0dcc9734dfadfc504b52b2ff3e26b,To appear in: Public Health,"The COVID-19 (coronavirus disease 2019) caused by SARS-COV-2 (severe acute 31 respiratory coronavirus 2) pandemic has had a major impact in healthcare systems. In 32 Mexico, by middle January 2021, more than 1.6 million confirmed cases and nearly 142 33 thousand deaths had been registered [1] . 34 Even when there is not a consensus regarding its definition, reinfection risk is a major 35 debate related to the COVID-19 pandemic [2] . Given the high observed mortality in 36 Mexico, there is concern regarding the impact of subsequent COVID-19 in recovered 37 patients. The aim of this study was to evaluate factors predicting severe SARS-COV-2 38 symptomatic reinfection in a large cohort of laboratory-confirmed COVID-19 survivors.We conducted a nationwide retrospective cohort study including adults (aged 20 years or our study became asymptomatic between both episodes. 90 We would like to highlight that enrolled patients who recovered to severe primary illness 91 had a 20% increase in the risk of severe subsequent disease (RR = 1.20, 95% CI 1.03-1.39). ii. We analyzed disease outcomes in a large subset (n = 258) of laboratoryconfirmed (reverse-transcription quantitative polymerase chain reaction) cases of symptomatic SARS-COV-2 reinfection.iii.To the best of our knowledge this is the first study evaluating illness outcomes in a large number of laboratory-positive patients and our results may be highly relevant for public health policymakers.",Mexico,abstract,2021-02-12,02
164555ef030fc35033f9ccb63f83ee52af8ceb89,"INCLUSIVE HEALTH: MODELING COVID-19 IN CORRECTIONAL FACILITIES AND COMMUNITIES We constructed a novel stochastic model of COVID-19 transmission to estimate the impact of correctional facilities, specifically jails and state prisons, for enhancing disease transmission and enabling disease re-emergence in local communities. Using our model, we evaluated scenarios of testing and quarantining infected incarcerated people at 0.0, 0.5, and 1.0 times the rate that occurs for infected people in the local community for population sizes of 5, 10, and 20 thousand","Cramped and overpopulated, correctional facilities are ideal environments for viruses to spread. This was made clear with the ongoing rapid spread of the coronavirus disease 2019 in US jails and prisons. As US jails and prisons are structurally designed for communal living to efficiently confine people, the rate of infection is 5.5 times higher in U.S. state and federal prisons than in the broader community (1) . Limited access to personal protective equipment, hand sanitizer, and even soap exacerbates spread across all people within the facility. In prisons, 366,121 incarcerated people and 98,035 correctional staff have been diagnosed with COVID-19 as of January 2021 (2) .In contrast with other group living quarters, such as nursing facilities, correctional facilities enable disease persistence and re-emergence. The reason for this is that many of the people who are housed within a correctional facility do not stay there for a long time. In the United States, on average, a person is confined to jail for 25 days (3) , a state prison for 2.6 years (4) , or to federal prison for 4.5 years (5) . Correctional facilities, particularly jails, thus serve as reservoirs that enable disease persistence because people continually enter them without prior exposure to the virus, which facilitates its spread. Likewise, regular exits from correctional facilities may result in the virus' reemergence within the local community if its spread is unchecked.We constructed a novel stochastic model of COVID-19 transmission to estimate the impact of correctional facilities in enabling disease transmission and disease re-emergence. We calibrate our model to describe COVID-19 spread in communities with correctional facilities that house 800 incarcerated people and staffed with 420 correctional workers. For such a facility, we measure how testing and quarantining infected incarcerated people at 0.0, 0.5, 1.0 times the rate that occurs for the general population impacts the spread of COVID-19 within the correctional facility and among the broader community. In addition, to reflect the different population densities of communities near correctional facilities, we also consider small, medium, and large communities of 5,000, 10,000, and 20,000 people, respectively, in addition to the average incarceration period of 25 days in jails and 2.6 years in state prisons.where is the transmission rate of COVID-19 in the local community, is the total size of β CW C tot the community, is the total size of the correctional workers, and is the impact of public W tot (t) α health control measures, such as face masks and social distancing, on mitigating COVID-19 spread in the local community. Similarly, the rate at which susceptible correctional workers acquire COVID-19 is given by the force of infection:where is the transmission rate of COVID-19 in the correctional workers. Finally, the rate at β W P which susceptible incarcerated people acquire COVID-19 is given by the force of infection:To reflect the influence of social distancing efforts on the transmission of COVID-19 in the local community, we consider the distinct phases of 1) pre-social distancing and 2) social distancing, along with the gradual fade-out of social distancing (Web Appendix 1, Web Figure   2 ). These phases are reflected in the rate new infections occur through the functionModel population sizes for the number of incarcerated people and correctional workers were determined using publicly available data on the capacity and annual occupancy of correctional facilities (6) . The model also uses current estimates of the duration of infection and the latent period of COVID-19 from the literature (7) . In addition, the impact of pre-and post-social distancing (8,9) on COVID-19 transmission in the local community was incorporated into model transmission rates (Web Appendix 1, Web Figure 2 ). Specifically, to estimate model transmission rates, we fit a deterministic analog of our stochastic model (Web Tables 1-4) to COVID-19 incidence, use the estimated ratio of undetected and detected cases of 4.64:1 in New York state, in addition to New York state data on the number of positive COVID-19 incidents (8, 9) . We also determined the rate of testing and quarantining of infected people from the local community (Web Appendix 2, Web Figure 3 ) using available data on positive COVID-19 tests (8) .To determine the direct and indirect benefit of identifying and quarantining COVID-19 infected people on death and disability due to COVID-19, we measure health outcomes in incidence averted and disability adjusted life-years (DALYs) (10) . Specifically, we calculate time-discounted DALYs lost to COVID-19 over 1 year and determine the net DALYs saved by subtracting the total DALYs lost under no testing and quarantining from scenarios that consider identifying and quarantining COVID-19 infected incarcerated people. Disability weights for the DALY calculation and the proportion of people that endure each severity of COVID-19 are obtained from the literature (11) (12) (13) .Community re-emergence To provide insight on the potential role of correctional facilities in enabling COVID-19 reemergence, we estimate the likelihood of a correctional facility re-introducing COVID-19 into the local community. Specifically, we estimate the probability of a major outbreak (14) within the correctional facility and the local community for total population sizes of 5,000, 10,000, and 20,000 people. In addition, to provide insight on the risk of transmission from the correctional facility to the local community, we determine the proportion of 10,000 simulations where a single infection in the correctional facility leads to a transmission event in the local community.To inform on the potential role that correctional facilities play in COVID-19 transmission and the effect of testing and quarantining infected incarcerated people, we simulated transmission among incarcerated people, correctional workers, and people in the local community. Specifically, we evaluated scenarios where infected incarcerated people are identified at rates that are 0, 0.5, and 1.0 times that of the rate of the local community, with community population sizes of 5,000, 10,000, and 20,000 people. Our findings illustrate that testing and quarantining infected incarcerated people substantially reduced COVID-19 incidence and saved DALYs ( Table 2, Table 3 ). Our findings also illustrate that smaller community sizes receive a greater reduction in COVID-19 incidence from testing and quarantining infected incarcerated people, in addition to a greater decrease in the risk for COVID-19 re-emergence.When considering a total population size of 5,000 people that feature a nearby jail, we predicted 1.96 annual incidents of COVID-19 per 1,000 people annually, with 1.32 of these incidents occurring in the local community, and 0.64 occurring within the correctional facility (Table 2) . Through testing and quarantining infected incarcerated people, 260 and 410 annual incidents of COVID-19 can be averted when correctional facilities test and quarantine at 0.5 and 1.0 times the rate of the local community, respectively ( Table 2 ). Our results also illustrate the local community benefits nearly as much as the incarcerated people from their testing and quarantining, concerning the reduction in COVID-19 incidence (Table 2) , and annually saves 15.31 to 75.61 DALYs per 1,000 people depending on the testing and quarantine scenario.With a total population size of 20,000 people, COVID-19 incidence occurred at 5.98 annual incidents per 1,000 people. Of these incidents, 5.44 and 0.54 incidents per 1,000 people occur in the local community, and the correctional facility, respectively ( Table 2 ). By testing and quarantining infected incarcerated people at 0.5 and 1.0 times the rate of the local community, we found that 490 and 730 annual incidents of COVID-19 can be averted (Table 2) .Furthermore, from these total incidents averted, the majority occurs in the local community with 300 to 450 annual incidents of COVID-19 being averted, depending on the testing and quarantining rate. In addition, testing and quarantining incarcerated people at 0.5 the rate of the general public annually saves 2.01 DALYs per 1,000 people, with this number increasing to 3.01DALYs per 1,000 people when testing and quarantining occurred at the same rate.For COVID-19 transmission in state prisons, our model predicts 1.74, 3.00, and 5.70 annual incidents per 1,000 people for total population sizes of 5,000, 10,000, and 20,000 people, respectively. Through testing and quarantining at state prisons, these numbers can be reduced by 270 to 280, 250 to 380, and 340 to 660 incidences, respectively, depending on whether testing and quarantining incarcerated people occurs at 0.5 or 1.0 times the rate of the local population.Reducing the number of incarcerated people is one policy to mitigate the superspreading potential of incarceration facilities, but it is not the only one. With the development of COVID-19 vaccines, advocates and health policy researchers have called on policymakers to make vaccines available to incarcerated people during the earliest phases of distribution (27) .While this policy would likely mitigate the superspreading potential of correctional facilities, not all states are adopting it, and the majority of those that have are prioritizing vaccine distribution to correctional staff and exclude incarcerated people (28) . Such actions, according to our findings, illustrate a lost opportunity to maximize health and safety, and suggest a more inclusive approach to COVID-19 vaccination would benefit everyone.Policies aiming to reduce outbreaks within correctional facilities and local communities should be health-informed. Social distancing practices such as changes to housing or severe lockdowns within cells may mitigate spread within facilities, but will likely harm the mental wellbeing of incarcerated people (18, 19) . In contrast, issuing telephone cards for incarcerated people to stay in contact with family could improve mental wellbeing (20) . Other policies that improve sanitation, including access to disinfectants and personal protective equipment (20) , or improve access to quality healthcare for incarcerated people, such as greater use of telemedicine (21) , mitigate virus spread in correctional settings.Similarly, with regards to mitigating disease spread, our model assumes a standard population density in a correctional facility, whereas, not all correctional facilities have the same layout, particularly as it relates to housing for incarcerated people. While dormitories and cells are the most common types of housing units, the availability and use of these spaces can vary considerably across facilities. Others (23, 24) have found evidence that the type of facility housing matters, and that people housed in dormitories are more susceptible to contracting the virus. As such, future models would do well to incorporate information on the varied population densities within correctional housing spaces to better understand viral spread. Another important characteristic that future models should consider is the disproportional impact of the pandemic on minorities (25, 26) . To elaborate, Blacks and Hispanics are overrepresented by 5.6 and 3.0 times more than White adults (22) in U.S. correctional facilities, which contributes to disparities of these groups in COVID-19 testing, cases, and deaths. As such, while our results provide a uniform estimate on the benefits of quarantining and testing for these groups, future research is urgently needed that investigates the intersection of race, health, and criminal justice involvement to better understand how criminal justice policy and practice may exacerbate health disparities by race.In summary, the health of incarcerated people likely has a substantial impact on the risk and magnitude of COVID-19 outbreaks in communities. Our findings illustrate that routine testing and quarantining of incarcerated people carries a dual benefit for correctional facilities, and their local communities. Thus, our work suggests that to maximize public health's ability to combat the ongoing COVID-19 pandemic, incarcerated people's well-being should be included in the design and implementation of health policies., 00 N = 5 0 0, 00 N = 1 0 0, 00 N = 2 0No intervention ( ) .0 θ θ P = 0 C Baseline annual incidence (1, , 00 N = 5 0 0, 00 N = 1 0 0, 00 N = 2 0",USA,first author,2021-02-08,02
3b5a36f86bc14c1f4892fd4dba097d77b1143a42,14 Alberta Precision Laboratories,"Hospital-1 had a higher proportion of SARS-COV-2-positive wastewater compared to Hospital-2 183 and Hospital-3, consistent with the higher burden of disease in NE Calgary (Table 1 and Figure   184 1). Following a large outbreak in Hospital-3 involving 45 patients, 43 HCW and 5 visitors 185 (beginning in a ward not monitored via Hospital-3A site and compounded by affected patients being transferred into different units through the hospital) that was declared on September 17 th , 187 wastewater sampling was expanded to include additional sites; Hospital-3B and Hospital-3C 188 ( Figure 2 ) to enable complete capture of Hospital-3.Wastewater SARS-CoV-2 signal correlates with total hospitalized COVID-19 cases 190 We assessed the correlation between the SARS-CoV-2 wastewater-N1 with active-COVID-19 191 patients on contact/droplet isolation at each hospital. When assessed together, Hospital-2, we observed that as prevalent cases increased, the wastewater-signal measured as N1-193 Cq also increased (Pearson's r=0.679, CI: 0.529-0.787, P<0.0001). This was also true when 194 Hospital-1 and Hospital-2 were assessed separately ( Table 2 ). The same was observed when 195 SARS-CoV-2-N1 wastewater was normalized against copies of the PMMoV at Hospital-2, but 196 only trended towards significance at Hospital-1 (Table 2) . These same correlations are not as 197 reliable at the Hospital-3 as we did not have access to prevalent cases as a function of sampling 198 site. However, we continued to observe a positive correlation (Table 2 ) between prevalent cases respect to whether peaks in SARS-CoV-2 in wastewater associated with outbreaks, we compared HCW) may be asymptomatic, pauci-symptomatic, or pre-symptomatic-each just as likely to 231 transmit infection as symptomatic individuals [22] [23] [24] . Despite rigorous infection control protocols, 232 nosocomial infections continue to occur. Novel strategies to understand the epidemiology of 233 SARS-CoV-2 in hospitals are therefore urgently required. One such strategy may be the 234 monitoring of hospital wastewater [25] .To date, most wastewater-based SARS-CoV-2 RNA surveillance has focused on monitoring 236 community burden of disease by sampling WW-TP [5] [6] [7] [8] . More recently, moving sampling 237 'upstream' in the wastewater-network, closer to patients, is actively being explored. The most 238 granular data comes from single-facility assessments. Passive wastewater surveillance could hold 239 promise as an early warning strategy, adaptable to both low-and high-risk facilities. Importantly, 240 if an incipient signal is detected in facility-wide wastewater samples, in-building plumbing systems 241 can be strategically sampled in a nested manner in order to confirm an outbreak location.Here we demonstrate that both the frequency of positive samples and the abundance of SARS-CoV-2 RNA in hospital wastewater systems correlated with increasing hospitalised cases -244 analogous to WW-TP levels correlating with the COVID-19 community-diagnosed cases [5] [6] [7] [8] .This was most evident using raw SARS-CoV-2 Cq values but was also evident when normalized 246 against PMMoV levels. We observed the N1-region of the nucleocapsid gene to be more sensitive 247 than N-2, and E so low as to be dropped from our protocol. Other groups have reported similar 248 trends in that the N1-target is the most sensitive marker in WW-TP studies[4] and cruise ships [26] .Despite nosocomial cases and outbreaks representing a small fraction of the overall population of 250 patients hospitalized with COVID-19, these events were discernable by wastewater testing. The 251 natural history of SARS-CoV-2-RNA presence in the gastrointestinal tract remains incompletely 252 All rights reserved. No reuse allowed without permission.The authors also thanks Cameron Semper for providing the pMCSG53 vector and T7/T7 340 terminator primers, and for providing support with Gibson assembly cloning. We would like to 341 acknowledge the tremendous efforts of Dr Rhonda Clark for program administration and 342 management.All authors report no potential conflicts. All authors have submitted the ICMJE Form for 344 Disclosure of Potential Conflicts of Interest.All rights reserved. No reuse allowed without permission.",Canada,first author,2021-02-23,02
e0b239c824cd8d716332d534f7edf468979f99a6,Genetically predicted serum vitamin D and COVID-19: a Mendelian randomization study 1,"supplemental oxygen, ICU admission, and death. [15] [16] [17] [18] The mounting evidence from observational 81 studies and the known effects of vitamin D on the immune system contribute to speculation 82 about whether a simple and immediate intervention like vitamin D supplementation might be 83 effective in reducing risk of COVID-19 infection or severity, but sources of guidance for 84 clinicians and the public cite a lack of evidence for a causal association. 19 Mendelian randomization (MR), a study design to address causality, uses a form of 96 instrumental variable analysis to improve causal inference and to address the biases inherent in 97 observational studies. MR uses genetic variants that are associated with the exposure (i.e., serum 98 vitamin D) as instrumental variables, or genetic instruments, that represent the long-term usual 99 exposure. Following the laws of independent assortment, genetic variants are inherited from 100 parent to offspring in a random and independent manner. An individual's genotype therefore 101 mimics the lifelong randomization of individuals into groups with different long-term serum 102 vitamin D levels. Valid MR analysis depends on three key assumptions: (1) adequate strength 103 and validity of the genetic instruments (i.e., genetic variants that underlie vitamin D 104 metabolism), (2) independence of the genetic instruments from any confounders, and (3) absence 105 of direct effects of the genetic instruments on the outcome of interest (i.e., COVID-19 status). 106 MR addresses limitations in observational data including confounding, reverse causality, and 107 measurement error, and supports triangulation on the evidence for causality when randomized 108 trials are either impossible to conduct or currently unavailable. Genome-wide association (GWA) 109 studies of serum vitamin D levels identified genetic variants that are robustly associated with 110 serum vitamin D status in different populations and ancestries. [22] [23] [24] [25] [26] [27] [28] Capitalizing on this finding, 111 researchers successfully applied MR to study associations of vitamin D with many clinical 112 outcomes, including diseases of immune system dysregulation and inflammation. [29] [30] [31] [32] [33] [34] [35] [36] [37] [38] [39] [40] [41] [42] [43] [44] [45] We used 113 MR to investigate causality of the relationship of serum vitamin D status with the risk and 114 severity of COVID-19 infection. 115We estimated the effect of serum vitamin D levels on risk of COVID-19 infection and 118 severity with two-sample MR. 46 The associations of the genetic instruments with the exposure(s) 119 and outcome(s) were estimated in separate, independent samples, then used to calculate the MR 120 estimate of the effect of serum vitamin D status on COVID-19. 46 We used summary data from a 121 GWA study of serum vitamin D in the UK Biobank (sample 1) 22 and genome-wide data for 122 COVID-19 patients versus comparison groups from the COVID-19 Host Genetics Initiative 123 (sample 2) ( Figure 1 ). 47 Because of overlap between the UK Biobank and the COVID-19 Host 124Genetics Initiative samples, which may bias MR results toward effects estimated from traditional 125 observational studies, 48 we replicated the analyses using summary GWAS data for serum vitamin 126 D from the SUNLIGHT Consortium. 23 We also performed sensitivity analyses to evaluate prior 127 hypotheses about the direct effect of vitamin D deficiency or insufficiency on COVID-19 128 outcomes using summary data from a meta-analysis of associations of vitamin D SNPs with the 129 dichotomous outcome of vitamin D deficiency versus sufficiency. 24 130We constructed all genetic instruments for serum vitamin D levels based on independent 132 genetic loci associated with serum vitamin D levels at genome-wide significance (p < 5×10 -8 ). 133For the primary analysis, we used a biologically plausible genetic instrument (instrument A) 134 consisting of SNPs in genetic loci that encode proteins in vitamin D transport and metabolism 135 (Supplemental Figure 1) , including the vitamin D binding protein (GC), 25 OH hydroxylase 136 (CYP2R1), 7-dehydrocholesterol reductase (DHCR7), and 24-hydroxylase (CYP24A1). All SNPs 137 included in Instrument A were associated with serum vitamin D at genome-wide significance in 138 the UK Biobank and replicated in the SUNLIGHT Consortium. 22,23 139In secondary analyses, we expanded the genetic instrument to include additional genome-140 wide significant SNPs in loci with no known relation to vitamin D metabolism ( Figure 1) and standardized to a mean of 0 and standard deviation of 1, and SNP-vitamin D association 167 models were adjusted for age, sex, season of vitamin D measurement, vitamin D 168 supplementation, genotype batch, genotype array, and assessment center (as a proxy for latitude). 169In the SUNLIGHT Consortium meta-analysis GWAS of serum vitamin D, serum vitamin D data 170 All rights reserved. No reuse allowed without permission.We assessed the strength and validity of the genetic instruments for vitamin D by 177 calculating the F-statistic, 49 We used genome-wide data for COVID-19 cases and comparison groups from the 189 COVID-19 Host Genetics Initiative, which is described elsewhere. 47 population controls, summary data from analyses limited to European ancestry participants were 215 also available. For these outcomes, we extracted summary data from both the mixed ancestry and 216 the European ancestry analyses for comparison and to address differences in ancestry 217 composition between vitamin D GWAS and COVID-19 Host Genetics Initiative sample 218 populations. 219We performed two-sample MR using the inverse variance weighted (IVW) method, 241 which assumes that pleiotropy is either non-existent or balanced (i.e., any associations of genetic 242 instrument SNPs with phenotypes other than vitamin D are randomly positive and negative such 243 that the mean pleiotropic effect is zero). 56 We used the MR-Egger intercept test to check for 244 evidence of directional pleiotropy, and performed sensitivity analyses using the MR-Egger, 245weighted-median and weighted-mode methods. 57-59 The MR-Egger method relaxes the 246 assumption of no directional pleiotropy and corrects for pleiotropy-induced bias by allowing for 247 a nonzero intercept. 56,57 The weighted-median method assumes that at least 50% of the weight of 248 the genetic instrument comes from nonpleiotropic SNPs and produces an unbiased estimate so 249 long as less than 50% of SNPs have pleiotropic effects. 58 The weighted-mode method assumes 250 that the most common (modal) SNP-vitamin D effect is the true effect and therefore allows for 251 the inclusion of pleotropic SNPs without biasing the MR estimate. 59 Where evidence of 252 directional pleiotropy existed (MR-Egger intercept test P-value <0.05) we prioritized the MR 253 estimates from the MR-Egger, mode-weighted, and median-weighted analyses, otherwise we 254 prioritized the estimates from the IVW method. Results for our primary analysis are presented as 255 odds ratios and 95% confidence intervals (OR, 95% CI) for COVID-19 case versus comparator 256 per standard deviation increase in log-transformed serum vitamin D. The threshold for statistical 257 significance was set at a P-value < 0.05. All analyses were performed using R Studio version 258 1.2.1335 and the ""TwoSampleMR"" R package (https://github.com/MRCIEU/TwoSampleMR) 50 . 259 All rights reserved. No reuse allowed without permission.Pearson's correlation coefficients. 265We calculated the minimum odds ratio detectable at 80% power for each COVID-19 266 outcome using the ""mRnd"" tool (https://shiny.cnsgenomics.com/mRnd/). 60 Characteristics of the genetic instruments for serum vitamin D, including contributing 280 SNPs, SNP-vitamin D associations in the UK Biobank, and F-statistics, indicate that instruments 281 All rights reserved. No reuse allowed without permission.We considered multiple case definitions, sample sizes, and ancestral compositions for the 291 COVID-19 case-control comparisons in our analysis ( Table 3) . 302All rights reserved. No reuse allowed without permission.MR estimates (odds ratios and 95% confidence intervals) for the effect of genetically 304 predicted serum vitamin D on risk of COVID-19 outcomes, calculated separately for instruments 305 A, B, and C, are shown in Figure 2 and Table 3 . MR scatter plots and forest plots further 306 illustrating these results are shown in Supplementary Figure 2 . MR-Egger intercept tests for 307 pleiotropy were not statistically significant (MR-Egger intercept p-values > 0.1) for all 308 instruments and all outcomes (Table 3) Results of MR analyses limited to European ancestry participants, which we were able to 318 perform for the outcomes of COVID-19 versus population and hospitalized COVID-19 versus 319 population, were also non-significant (Supplementary Figure 3) . 320For all outcomes, the MR-Egger intercept test showed little to no evidence of pleiotropy 321 (Table 3) . Nevertheless, we performed sensitivity analysis to explore possible pleiotropy using 322 the MR-Egger, weighted-median, and weighted-mode MR methods, and this analysis showed a 323 direct association of serum vitamin D with risk of hospitalized COVID-19 versus non-324 hospitalized COVID-19 (Supplemental Figure 4) . For this outcome, MR estimates from the MR-325 All rights reserved. No reuse allowed without permission.A further sensitivity analysis evaluated the effect of genetically predicted vitamin D 343 deficiency and insufficiency on COVID-19 outcomes (Table 3, Figure 4 ). MR-Egger intercept 344 tests for pleiotropy were all non-significant (p-value > 0.1), and the IVW MR estimates did not 345 support an effect of long-term vitamin D deficiency or insufficiency on the risk of any of the 346 COVID-19 outcomes evaluated (Table 3, Figure 4) . 347 All rights reserved. No reuse allowed without permission.Consortium, and COVID-19 Host Genetics Initiative to conduct the first MR study of serum 364 vitamin D and COVID-19 outcomes. Although our study was powered to detect effects 365 comparable to those seen in observational studies of vitamin D and COVID-19, we found little to 366 no evidence of an effect of genetically predicted serum vitamin D levels on COVID-19 367 outcomes, including risk of COVID-19 infection, severe respiratory infection, and 368 hospitalization. Our results were robust to multiple genetic instruments for vitamin D and were 369 replicated using SNP-vitamin D association data from two independent samples. Results from 370 All rights reserved. No reuse allowed without permission.As in any MR study, the valid interpretation of our results rests on the MR assumptions 412 of adequate strength of the genetic instruments for vitamin D and absence of direct effects of the 413 instruments on COVID-19 outcomes and potential confounders (i.e., pleiotropy). Our 414 instruments easily met the MR standard for instrument strength (F-statistic >10) and we found no 415 evidence of pleiotropy from the MR-Egger intercept test. Our results were consistent across the 416 All rights reserved. No reuse allowed without permission.We used a two-sample MR approach, using estimates of associations of the genetic 421 instruments with vitamin D and with COVID-19 outcomes from two separate samples. This 422 approach maximizes sample size and reduces the likelihood of bias toward estimates from 423 observational studies 46 but requires that the two samples are drawn from similar populations. In 424 our study, the summary data for associations of the genetic instruments with vitamin D were 425 from analyses in European ancestry participants, while the data for associations of the genetic 426 instruments with COVID-19 outcomes were from analyses including up to 25% non-European 427 ancestry participants. Repeating the analysis with a subgroup of European-only participants for 428 two outcomes, COVID-19 versus population controls and hospitalized COVID-19 versus 429 population controls, indicated minimal impact of ancestral differences on MR estimates. 430However, ancestry-specific data were not available for COVID-19 outcomes with larger 431proportions of non-European ancestry participants, and the impact of ancestral differences could 432 not be fully explored. In sensitivity analyses using alternative MR methods that assume some 433 pleiotropy, findings indicated an association of higher vitamin D levels with higher risk of 434 hospitalization among COVID-19-infected individuals, the outcome with the highest proportion 435 of non-European ancestry participants. This finding could be driven by racial/ethnic disparities in 436 access to health care (i.e., hospitalized COVID-19 individuals may be more likely of European 437 ancestry and therefore have higher vitamin D status). We also found evidence for racial 438 differences in risk-factor stratified SNP-vitamin D associations. Our results suggest that SNP-439 All rights reserved. No reuse allowed without permission.Review Board at RTI International. 509Data sharing: All data used for this analysis are publicly available. Code implementing the 510 MR analysis is available upon request from the corresponding author. 511Transparency: PAC is the corresponding author and guarantor for this paper and affirms that 512 the manuscript is an honest, accurate, and transparent account of the study being reported; that 513 no important aspects of the study have been omitted; and that any discrepancies from the study 514 as originally planned have been explained. 515The Corresponding Author has the right to grant on behalf of all authors and does 516 grant on behalf of all authors, a worldwide licence to the Publishers and its licensees in 517 perpetuity, in all forms, formats and media (whether known now or created in the future), to i) 518 publish, reproduce, distribute, display and store the Contribution, ii) translate the Contribution 519 into other languages, create adaptations, reprints, include within collections and create 520 summaries, extracts and/or, abstracts of the Contribution, iii) create any other derivative work(s) 521 based on the Contribution, iv) to exploit all subsidiary rights in the Contribution, v) the inclusion 522 of electronic links from the Contribution to third party material where-ever it may be located; 523 and, vi) licence any third party to do any or all of the above. 524 525 526 527 528 All rights reserved. No reuse allowed without permission.All rights reserved. No reuse allowed without permission.All rights reserved. No reuse allowed without permission.All rights reserved. No reuse allowed without permission.",United States,first author,2021-02-01,02
ed388e5abf013de0dde1b5c52e6f544b46735d65,Journal Pre-proof Evaluating angiotensin-converting enzyme 2-mediated SARS-CoV-2 entry across species Evaluating angiotensin-converting enzyme 2-mediated SARS- CoV-2 entry across species Evaluating angiotensin-converting enzyme 2-mediated SARS-CoV-2 entry across species Running title: Receptor engagement of SARS-CoV-2,"The interaction between receptors and viruses is a key determinant of the host range. SARS-CoV-2 resembles severe acute respiratory syndrome coronavirus J o u r n a l P r e -p r o o f (SARS-CoV), and both use angiotensin-converting enzyme 2 (ACE2) as the primary cell entry receptor (1,7-9). When we retrace the origin of a virus, the cell susceptibility to viruses conferred by receptors of speculated animals is preferentially investigated (10,11). Before clarifying that Rhinolophus sinicus (Chinese rufous horseshow bat) is the natural reservoir of SARS-CoV, scientists first evaluated the susceptibility provided by ACE2 from different bat species to SARS-CoV. They found that the ACE2 of Rhinolophus sinicus was responsible for the susceptibility to SARS-CoV and subsequently confirmed that Rhinolophus sinicus was the natural reservoir of SARS-CoV (10, 12, 13) . The Middle East respiratory syndrome coronavirus (MERS-CoV) was also recognized as having a bat origin because MERS-CoV and two MERS-CoV-related viruses from bats could utilize human or bat dipeptidyl peptidase 4 (DPP4) for cell entry (14) (15) (16) .Therefore, in this study, we systemically evaluated the ability of SARS-CoV-2 to infect nonsusceptible HEK293T cells utilizing ACE2 proteins from nine different animal species and humans to determine its possible origin and to further explore its cross-species transmission. Our findings provide evidence that SARS-CoV-2 is able to engage the ACE2 receptor of different species, which poses a very large challenge to determine the natural reservoir of SARS-CoV-2 for the control and prevention of coronaviruses in the future. Furthermore, we found a natural isoform of ACE2 in Macaca mulatta (rhesus monkey; RhACE2) with the Y217N mutation, which was resistant to SARS-CoV-2 infection, and this amino acid residue is a novel critical determinant of the ability of ACE2 to mediate SARS-CoV-2 entry. J o u r n a l P r e -p r o o fTo investigate which animal ACE2 proteins could facilitate SARS-CoV-2 entry, we synthesized full-length cDNA fragments of ACE2 from 11 animal species as well as from humans. These species were Rhinolophus sinicus ( and GenBank accession numbers of these ACE2 molecules are listed in the Table. We first compared the nucleotide sequence of the ACE2 coding region of these 11 animals to that of human. The sequence similarities of these ACE2 cDNAs are exhibited in the Table. Among these sequences, the sequence of RhACE2 was the most similar to that of human ACE2 (hACE2), and in contrast, the sequence of mainland tiger snake ACE2 was the least similar (Fig. 1A) . It has been reported that two virus-binding hotspots, K31 and K353 in hACE2, are critical for SARS-CoV infection (17, 18) . In this study, we found that K31 was not conserved in ACE2 of all 11 animal species observed in this study. However, K353 was conserved in all 10 animal species except mouse (Table) .Next, we tested whether ACE2 of the 11 animal species was able to facilitate J o u r n a l P r e -p r o o f SARS-CoV-2 entry to nonsusceptible HEK 293T cell lines. Different ACE2 proteins were expressed in HEK 293T cells ( Fig. 1B and 1C ). Plasmids expressing hACE2 and mouse ACE2 were applied as the positive and negative controls of the entry assay, respectively. The infection ratio varied according to the ACE2 protein expressed (Fig.   1C ). As expected, hACE2 supported SARS-CoV-2 entry, whereas mouse ACE2 did not (Fig. 1C) . One previous study indicated that the SARS-CoV outbreak 17 years ago originated from Rhinolophus affinis (intermediate horseshoe bat) (12) . A recent study further demonstrated that ACE2 of Rhinolophus sinicus (Chinese rufous horseshoe bat) allowed both SARS-CoV-2 and SARS-CoV entry (1). In this study, we were not able to synthesize the ACE2 cDNA of Rhinolophus affinis due to the absence of its sequence. Therefore, we synthesized the ACE2 cDNA of Rhinolophus sinicus and Rhinolophus ferrumequinum (greater horseshoe bat) to test whether ACE2 of other bat species was responsible for the susceptibility to SARS-CoV-2. Interestingly, we found that the ACE2 of Rhinolophus ferrumequinum did not support SARS-CoV-2 entry but Rhinolophus sinicus did (Fig. 1C) , suggesting that not all species of bat are sensitive to SARS-CoV-2 infection.A recent study indicated that SARS-CoV-2 did not replicate and shed in dogs, pigs, chickens and ducks but replicated fairly well in ferrets and replicated effectively in cats (6). Our study demonstrated that cat ACE2 supported viral entry of SARS-CoV-2 (Fig. 1C) . Although pigs, dogs and chickens are not sensitive to SARS-CoV-2 infection, we know little about the molecular mechanisms and role of receptor avidity in resistance. Our data demonstrated that the ACE2 protein of dogs J o u r n a l P r e -p r o o f and pigs supported SARS-CoV-2 entry similar to that of cats.There is a debate regarding if SARS-CoV-2 originated from bats or pangolins (1,4,5). It has been demonstrated that bat ACE2 mediates SARS-CoV-2 entry (1). Therefore, we expressed ACE2 in Manis javanica (Malayan pangolins) and tested its role in conferring susceptibility to SARS-CoV-2. We demonstrated that pangolin ACE2 could mediate the entry of SARS-CoV-2 (Fig. 1C) .Finally, we demonstrated that ACE2 of Notechis scutatus (mainland tiger snake) could not support SARS-CoV-2 entry as previously predicted (19) . Snakes may not be the natural reservoir of SARS-CoV-2.Old world monkeys (Macaca mulatta (rhesus monkey) and Macaca fascicularis (crab-eating macaque)) were used as experimental animal models for SARS-CoV-2 infection (20) . Surprisingly, we found that RhACE2 in our study did not support SARS-CoV-2 entry, as expected ( Fig. 1C) . By investigating the monkey ACE2 sequence, we found that the ACE2 isoform of rhesus monkey cloned in our study contained two natural variations (R192G and Y217N) ( Fig. 2A) . When we reverted the Y217N mutation to N217Y (wild-type sequence of ACE2) in RhACE2, RhACE2 with N217Y had the ability to support SARS-CoV-2 infection (Fig. 2B ). We noticed that Y217 was conserved in the other species investigated in this study (data not shown), which suggests that residue Y217 is a key residue for SARS-CoV-2 entry. To further confirm this hypothesis, we constructed hACE2 with the Y217N mutation and J o u r n a l P r e -p r o o f found that this mutation completely blocked SARS-CoV-2 entry, as expected ( Fig.   2B ).Potential asparagine (N)-linked glycosylation may influence virus and receptor binding; however, when we analyzed the sequence, we found that ACE2 N217 was not a potential N-linked glycosylation site (N-X-T/S motif). We further constructed a RhACE2 with the N217Q mutation, and this mutation did not facilitate SARS-CoV-2 entry (Fig. 2B ). This further demonstrated that the ability of N217 blocking viral entry is not due to N-linked glycosylation of this residue. A previous study indicated that the natural mutation of Y217N in RhACE2 dramatically alters RhACE2 expression and reduces the efficiency of SARS-CoV entry (21) . In the current study, we illustrated that both hACE2 and RhACE2 Y217N expressed as well as the corresponding wild-type ACE2 proteins (Fig. 2C ).Next, we used the RBD as a probe to examine receptor binding ability by using IFA.We performed an RBD binding assay and found that wild-type hACE2 potently bound the RBD, as expected (Fig. 3A) ; however, hACE2 Y217N, RhACE2 Y217N and RhACE2 Y217Q almost lost the ability to bind the RBD (Fig. 3A) . Receptor binding ability was further confirmed and quantified by Western blotting (Fig. 3B ). Since the conformation of a recombinant RBD may not completely reflect its native conformation within an entire envelope glycoprotein, we also investigated ACE2 binding with more relevant systems of the full-length S (spike) protein, and we J o u r n a l P r e -p r o o f obtained a similar result as for the RBD (Fig. 3C and 3D) . The above data demonstrated that the Y217 residue of ACE2 significantly reduced the binding ability of the RBD and spike protein.To test whether position 217 of ACE2 influenced its RBD binding activities is due to N217 disrupting the interaction between ACE2 and RBD, we used homology-based structural modeling to analyze the effects of residue substitutions at position 217.Structural models of Y217N were generated based on the crystal structure of the SARS-CoV-2 RBD/ACE2 complex (22, 23) . We found that position 217 was not located at the interaction domain with RBD; furthermore, the predicted model of residue substitutions at position 217 seemed to have no influence on the interaction between ACE2 and RBD (Fig. 4) . Overall, structural modeling analysis demonstrated that the substitutions at position 217 in ACE2 did not influence its corresponding receptor activities.To enter into cells, viruses need to first interact with the corresponding receptor at the cell surface; therefore, we tested the possibility that ACE2 Y217N fails to mediate SARS-CoV-2 entry due to a change in the cell surface localization of ACE2 induced by the Y217N mutation. To test this hypothesis, HEK 293T cells were first transfected with the indicated plasmids. Forty-eight hours later, the transfected cells were detached from the plate and then stained with a FITC-labeled anti-ACE2 antibody. We J o u r n a l P r e -p r o o f found that both wild-type hACE2 and RhACE2 Y217N were strongly positive for FITC, whereas the other mutants were weakly positive (Fig. 5A) . To confirm that this difference was not due to transfection efficacy, the transfected cells were permeabilized with Triton X-100 and then stained with ACE2. The results indicated that all cells transfected with different ACE2 molecules were labeled with FITC at a high level (Fig. 5B ).This demonstrated that RhACE2 Y217N failed to mediate SARS-CoV-2 entry, mainly due to its cell surface localization.The spike (S) protein features of coronaviruses and lysosomal proteases of hosts determine the tropism of coronaviruses (24). To date, the bat coronavirus RaTG13 in Rhinolophus affinis (intermediate horseshoe bat) from Yunnan Province exhibits the highest sequence similarity to SARS-CoV-2 (1). In this study, we found that ACE2 of Rhinolophus ferrumequinum (greater horseshoe bat) failed to mediate SARS-CoV-2 entry, whereas ACE2 of Rhinolophus sinicus (Chinese rufous horseshoe bat) facilitated SARS-CoV-2 entry to nonsusceptible cells. In fact, in contrast to genetically homologous hACE2, bat ACE2 proteins have great genetic diversity (13) .A number of ACE2 molecules isolated from different bat species failed to mediate SARS-CoV entry (13) . A study has reported that Rhinolophus sinicus serves as a natural reservoir of SARS-CoV, and an isolated bat-origin SARS-CoV-like virus is able to use ACE2 proteins from humans and civets for cell entry (12) . These results suggest that analysis of the receptor-conferred susceptibility to virus entry is Similarly, the ability of pangolin ACE2 to confer susceptibility to SARS-CoV-2 entry increases the possibility that SARS-CoV-2 originated from pangolins. This was further confirmed by two recent studies (25,26).In this study, we demonstrated that ACE2 of pigs and dogs facilitated SARS-CoV-2 entry in nonsusceptible cells. However, a recent study reported that SARS-CoV-2 replicated poorly in dogs and pigs (6). We speculate that there other factors that determine host tropism in addition to receptor interactions. A recent study demonstrated that pigs and dogs exhibit relatively low levels of ACE2 in the respiratory tract, which may be the reason that SARS-CoV-2 replicated poorly in dogs and pigs (27) . Because in the current study, we did not use cells derived from different animals as host cells for the infection assay, we cannot completely exclude the possibility that cellular factor(s) other than ACE2 play (additional) roles in supporting SARS-CoV-2 entry and cross-species transmission.Based on structural analysis of hACE2 and the S protein of SARS-CoV-2, the RBD of the S protein of SARS-CoV-2 has a more compact conformation than that of J o u r n a l P r e -p r o o f SARS-CoV, implicating a relation to the higher transmission of SARS-CoV-2 than SARS-CoV (23,28). However, in mouse ACE2, position 353 is a His not a Lys, and H353 in mouse ACE2 does not fit into the virus-receptor binding interface as tightly as K353 of hACE2. Consequently, this may result in the failure of mouse ACE2 to confer susceptibility to SARS-CoV-2 entry. A recent publication also demonstrated that the substitution of K353A in hACE2 was sufficient to abolish the interaction between hACE2 and the S protein of SARS-CoV-2 (29). In addition, although the residue at position 217 of ACE2 is not directly in contact with the RBD, this site in RhACE2 is still critical for SARS-CoV-2 entry. It was observed that the natural isoform of Y217N at this site of RhACE2 significantly reduced the susceptibility to SARS-CoV entry, which demonstrated that this substitution is responsible for the downregulation of ACE2 expression (21) . However, our results showed that Y217N RhACE2 was expressed at a similar level as hACE2 in transfected cells. Therefore, the failure of this RhACE2 isoform to allow SARS-CoV-2 entry is not due to the poor expression of the receptor, as previously speculated (21) . We also demonstrated that ACE2 Y217N had a significantly decreased SARS-CoV-2 entry ability due to its cell surface localization, in our previous study, we found virus receptor abundance of cell surface is a pivotal switch for virus efficient infection, this may be the reason that ACE2 Y217N failed to mediate SARS-CoV-2 entry (30). We suspect that the Y217N of ACE2 may affected ACE2 transport in the cells, and this needs further study. We also speculated that the Y217N mutation may alter the folding of ACE2; this needs to J o u r n a l P r e -p r o o f be investigated further. It is also important to detect the expression of Y217N RhACE2 in rhesus monkeys recruited for studies on SARS-CoV-2 infection.HEK 293T cells were maintained in Dulbecco's modified Eagle's medium (DMEM, Gibco, USA) with 10% fetal bovine serum (FBS, HyClone, USA). The SARS-CoV-2 used in this study (GenBank: MT123290) was isolated from a patient's throat swab and stored at the BSL-3 Laboratory of Guangzhou Customs Technical Center.The full-length cDNA fragments of ACE2 of different species were synthesized at either Sangon Biotech (Shanghai, China) or TsingKe Biotech (Nanjing, China). The species and GenBank accession numbers of ACE2 sequences are listed in the Table. Synthesized cDNA fragments were then subcloned into the eukaryotic expression vector pCAGGS-HA for expression in human cell lines.ACE2 sequences of 12 different species were acquired from NCBI, and the alignment of these sequences was assessed using the ClustalW method in Lasergene software (Version 7.1) (DNASTAR Inc., USA). #5230-0415, diluted 1:10,000).The hACE2/RBD complex was used as a template for homology modeling (22, 23) .The mutations in the models were aligned, and the interactions between the SARS-CoV-2 RBD and ACE2 proteins were compared in PyMOL.J o u r n a l P r e -p r o o f experiments, unless otherwise stated. Different treatments were compared with Student's t test.All data pertinent to this work are contained within this article or available upon request. For requests, please contact Yan-Dong Tang (tangyandong2008@163.com). ",United States,abstract,2021-02-19,02
5e5fa055c610d55c0e234f8d05afd470e4721ab7,International Journal of Infectious Diseases Respiratory Co-Infections: Incidence of Viral and Bacterial Co-Pathogens,"The COVID-19 pandemic caused by SARS-CoV-2, a novel coronavirus, has resulted in the largest mobilization of public health resources and policy in recent memory. At the time of writing this report the pandemic has infected 92.3 million people resulting in over 1.98 million deaths globally. The United States, representing 4.25% of the world population, has been disproportionately affected by the pandemic. The total SARS-CoV-2 positive cases in the United States stands at 23.1 million with 384,000 fatalities which represents 20% of the world tally (cdc.gov/coronavirus/2019-ncov). Co-evolution of viral and bacterial respiratory pathogens has created an environment wherein a viral infection allows concurrent or secondary bacterial co-J o u r n a l P r e -p r o o f infections which lead to enhanced morbidity and mortality associated with respiratory viral infections, greatly enhancing the disease burden on society (Mc Cullers, 2014; Gupta et al., 2008) . Although viral-bacterial co-infections are well researched, studies detailing their impact during the COVID-19 pandemic remain sparse. With mass vaccination efforts against SARS-CoV-2 still in their initial stages, underlying co-infections and their treatment can have a significant impact on disease morbidity and associated patient care (Cox et al., 2020; Kim et al., 2020) . In the present paper we report the rates of respiratory bacterial and viral co-infections in SARS-CoV-2 infected patients in the United States.Nasal, oropharyngeal and sputum swabs were received and tested by HealthtrackRX in our laboratory located at Denton, Texas, USA. Nucleic acid extraction and real-time PCR on the Open Array TM platform (Thermo Fisher Scientific, California, USA) were performed as previously described (Singh et al., 2019) . The following microbial pathogens were tested for: (1) Between 03/16/20 and 08/01/2020, a total of 50,419 respiratory samples (nasopharyngeal, oro-pharyngeal, and sputum swabs) were collected and concurrently tested for the presence of SARS-CoV-2 and other respiratory pathogens.SARS-CoV-2+ patients (n=4,259) represented 8.44% (95% confidence interval [CI] 0.082 to 0.087; p=0.084) of the total samples analyzed in this study. Gender distribution of SARS-CoV-2+ population (55.5% female and 44.4% male) was similar to that of the total population (55.3% female and 44.6% male). The average age of the SARS-CoV-2+ patients was 45.21±20.43 years. Distribution of the SARS-CoV-2+ population over an age range revealed higher incidences of infections in the younger age groups (20-49 years) which comprised approximately 50% of the total positive cases ( Figure 1 ). Early reporting had demonstrated higher rates of SARS-CoV-2 infection in the older population (Stokes et al., 2020) . However, latest trends of the COVID-19 pandemic in the United States (Boehmer et al., 2020) are in agreement with our data that show higher infection rates in the younger population.Both bacterial and viral respiratory co-infections can be secondary or concurrent. A variety of synergistic biologic interactions between viruses and bacteria have been reported, leading to an increased risk of bacterial infections (where a primary viral infection is present), J o u r n a l P r e -p r o o f and vice versa. (Lee et al., 2016) In the case of SARS-CoV-2, this is substantiated by our current study's co-infection data, by the data of Massey and co-workers (2020), and our previous work on co-infections present in ""influenza-like-illnesses"" (Singh et al., 2019) .It is now widely accepted that in all the influenza pandemics of the last century the leading cause of mortality were secondary or concurrent bacterial co-infections including S. pneumoniae, S. aureus and H. influenzae (Gupta et al., 2008 ). An initial study originating from Wuhan, China reported bacterial co-infections in 50% of the patients that did not survive COVID-19 . A review of 13 studies reporting SARS-CoV-2 co-infection rates, disclosed co-infection and secondary infection rates ranging from 0.6-45.0% (Lai et al., 2020) .In the present study significant bacterial and viral co-infections were observed in both SARS-CoV-2+ and SARS-CoV-2-population. In general, the SARS-CoV-2+ patients had lower incidences of co-infections as opposed to the SARS-CoV-2-patients ( Figure 2 ). This trend is similar to previously reported Stanford University data (Kim et al., 2020) , and differs from the data of Massey and coworkers (Massey et al., 2020) . However, the bacterial co-infections were comparable (33.17% SARS-CoV-2+, 35.45% SARS-CoV-2-). The viral co-infection rate was significantly lower in the SARS-CoV-2+ patients (3.42%) in comparison to SARS-CoV-2patients (8.66%). A detailed analysis of the co-infecting pathogens (Table 1) A similar trend was observed with viral co-infections, wherein the SARS-CoV-2+ patients had lower incidences of co-infections for all the viral targets when compared to the SARS-CoV-2patients, congruent to the study conducted by Kim and coworkers (2020) . All the viral co-infections were reported at less than 1% incidence rate apart from EBV. A possible explanation of the lower viral co-infection rate could be the time frame in which the study was Distribution of all co-infections (bacterial and viral) in the SARS-CoV-2+ population suggests a positive correlation with age ( Figure 3) . Even though the overall median age of the SARS-CoV-2+ patients was 45 years, the co-infections were significantly higher in the older age J o u r n a l P r e -p r o o f group (60+ years) as opposed to any other age group. Detailed analyses of the COVID-19 pandemic assert that the most severe outcome of the disease is observed in older patients (Wu et al., 2020) and our results may provide a possible explanation to this observation.The present study, to our knowledge, is the largest such study related to the co-infections of SARS-CoV-2. Our observations provide significant insight into the potential risks and clinical outcomes for COVID-19 patients, especially in the susceptible older age group. While SARS-CoV-2 has a higher mortality rate than most other respiratory viruses, even without a bacterial coinfection, 33% of CoV-2 (+) cases in our study had a concurrent bacterial infection and could have benefitted from an antibiotic. Novel existing therapies, such as remdesivir and dexamethasone, were used for treatment of hospitalized SARS-CoV-2 patients, but like all other respiratory viruses, bacterial coinfections cannot be ignored. It is widely known that a variety of bacteria can both colonize, and under appropriate conditions cause infections of, the entire respiratory tract. Examples include S. pneumoniae, S. aureus and H. influenzae amongst others.At the current time, immune system gene expression analysis is not in widespread use. Such analysis, once a consensus validation of the clinical utility has been completed, could be instrumental in determining whether a given detected microbial population represents an infection or a colonization. Meanwhile, clinicians must rely upon a given patient's signs and symptoms, in determining whether an infection exists. This is a potential microbiologic-test interpretative limitation for both classic culture-based and current molecular-diagnostic tests.The main limitation of the study was that the patient records of hospitalization, recovery and treatment were not available which do not allow us to make further assessment of the impact of co-infections during SARS-CoV-2 infection. As a future endeavor, data will be collected J o u r n a l P r e -p r o o f J o u r n a l P r e -p r o o f ",United States,abstract,2021-02-25,02
fe2475272b6a15ed7d1eb52ac98e663260985f86,Evaluating the Cool Versus Not Cool Procedure via Telehealth,"Autistics/individuals diagnosed with autism spectrum disorder 1 (ASD) commonly display qualitative impairments in social behavior (American Psychiatric Association, 2013) . The challenges related to social behavior for these individuals commonly result in the use of interventions directly targeting the development of social skills. To date, the effectiveness of several interventions for the development of social skills has been documented within the peer-reviewed literature. These include, but are not limited to, the teaching interaction procedure (e.g., Dotson et al., 2010; Leaf, Oppenheim-Leaf, et al., 2012a) , video modeling (e.g., Rudy et al., 2014) , discrete-trial teaching (e.g., Garcia-Albea et al., 2014) , pivotal response treatment (e.g., Mohammadzaheri et al., 2014) , behavioral skills training (e.g., Stewart et al., 2007) , and the Cool Versus Not Cool procedure (e.g., Milne et al., 2017) .Although it is most common for these interventions to occur in person, in a clinical or home setting, the COVID-19 pandemic has illustrated the need for effective interventions that can be delivered via telehealth (Cox et al., 2020; LeBlanc et al., 2020) . Behavior-analytic research related to intervention for autistics/individuals diagnosed with ASD via telehealth is not new , but the sudden move to telehealth for many service providers has accelerated the need for research evaluating the effectiveness of behavior-analytic procedures delivered via telehealth (Cox et al., 2020; LeBlanc et al., 2020) . To date, much of the behavior-analytic research related to telehealth-delivered behavior-analytic interventions has focused on training an individual to subsequently implement the intervention in person (see Ferguson et al., 2019 , for a review). However, there are some recent, notable examples of the direct application of behavior-analytic interventions delivered via online tools.For example, Pellegrino and DiGennaro Reed (2020) evaluated an intervention delivered via telehealth that used total task chaining and least-to-most prompting for two adults with intellectual and developmental disabilities. All sessions occurred via VSee, with the two adults participating from their apartments while the experimenter was located in a separate apartment within the same complex. Targeted skills were those that the participants expressed interest in learning (e.g., light cooking, money management). The results of a multipleprobe across-behaviors design indicated the intervention was effective for teaching both participants three self-selected skills. Furthermore, each of the skills maintained, and both participants indicated satisfaction with the procedures and outcomes. In another recent example, Ferguson et al. (2020) evaluated the effectiveness of discrete-trial teaching with instructive feedback delivered via telehealth to teach tact relations to six children diagnosed with ASD. The participants were divided into dyads, and each participant had their own primary (i.e., targeted tact) and secondary (i.e., instructive feedback) targets. All sessions occurred via Zoom, with the interventionist and participants located in different physical locations. The results indicated that all participants acquired primary and secondary responses, and five of six acquired primary and secondary observational responses (i.e., the targets for the other participant in the dyad).Although the aforementioned (i.e., Ferguson et al., 2020; Pellegrino & DiGennaro Reed, 2020) and past research (e.g., Wacker et al., 2013) is promising for many who are shifting to service delivery via telehealth, the research is limited with respect to social skills interventions delivered directly via telehealth. One intervention approach that may transfer with little effort to a telehealth model is the Cool Versus Not Cool procedure. The Cool Versus Not Cool procedure is an approach to developing social discriminations through what is commonly referred to as discrimination training via instructor demonstration. Role-plays are then used to increase the likelihood the learner will engage in the desired social skill in the terminal environment. More specifically, the Cool Versus Not Cool procedure consists of five components: (a) labeling the targeted social skill (e.g., the ""cool"" skill), (b) the interventionist modeling the cool (i.e., the desired topography of the behavior) and not cool ways (i.e., the undesired topography of the behavior) to display the social skill, (c) providing the learner with the opportunity to label the model as cool or not cool and why the model was cool or not cool, (d) the learner role-playing the cool way, and (e) providing reinforcement or feedback based on learner responding throughout. It should also be noted the terms ""cool"" and ""not cool"" were selected based on the learners with whom the procedure was originally developed. Those learners were using those words already, and it was thought that using those same words to describe desired and undesired social behaviors would increase the likelihood of generalization and maintenance in the terminal environment . As such, interventionists should determine the labels that will be most appropriate based on the learners with whom they provide intervention (e.g., ""dope"" and ""weak,"" ""good choice"" and ""bad choice,"" or ""appropriate"" and ""inappropriate"" may be more appropriate and effective than ""cool"" and ""not cool"" for some learners).The Cool Versus Not Cool procedure has been demonstrated to be effective for teaching a variety of social skills to autistics/individuals diagnosed with ASD (e.g., interrupting, changing the game, greetings, joint attention, changing the conversation, abduction prevention, and eye contact; Leaf, Tsuji, et al., 2012b) . The effectiveness of the Cool Versus Not Cool procedure has also been demonstrated in one-toone settings (e.g., Leaf et al., 2015) , small group settings (Au et al., 2016) , and large group settings (Milne et al., 2017) . In light of the recent increased need for effective telehealth-delivered interventions, the purpose of the present study was to evaluate the effectiveness of the Cool Versus Not Cool procedure conducted via telehealth for three children diagnosed with ASD.Three children independently diagnosed with ASD participated in the study. Participant demographic information is provided in Table 1 . All participants had a previous history of receiving in-person social skills interventions including the Cool Versus Not Cool procedure. All participants had some experience with direct intervention delivered via telehealth due to the COVID-19 pandemic but had recently transitioned back to in-person intervention. All participants were also currently participating in a social skills group two times a week via telehealth. None of the participants had any previous experience with the use of the Cool Versus Not Cool procedure to target changing the conversation when someone is bored. Informed consent was obtained from each of the participants' parents prior to participation in the study. The participants were free to leave at any point during the session; however, this never occurred, and participants assented to all sessions.Julia L. Ferguuson, the second author, served as the interventionist for all sessions, with the exception of generalization sessions. She was a 29-year-old White female with an undergraduate degree in applied behavior analysis and a master's degree in behavior analysis and had begun her studies toward a doctoral degree in applied behavior analysis. She had over 8 years of experience implementing interventions based on the principles and procedures of applied behavior analysis for individuals diagnosed with ASD. This experience also included the use of the methods within this study to teach a variety of social skills to a variety of learners.Throughout all conditions, probes, and intervention sessions, the participants and the interventionist were in different locations in Southern California. Winston was located at home for all of his sessions, whereas Nick and Schmidt were located at an isolated location within a private clinic. The interventionist conducted all sessions from her home. All sessions were conducted using the Zoom Video Communications, Inc. (Zoom; www.Zoom.us), platform using various devices with video and audio capabilities. Winston, Nick, and Schmidt used an iPad, and the interventionist used a laptop computer.The participants' supervisors, who were responsible for training staff, developing curriculum and intervention strategies, and overseeing the participants' overall progress, were asked to provide a list of social skills that were likely to be included relatively soon within the participants' regularly scheduled clinical sessions. The lists provided by the supervisors were examined for areas of overlap across participants. Each of the supervisors noted the participants' challenges with changing the conversation when someone is bored (i.e., identifying possible boredom cues and changing their behavior as a result). Therefore, the main dependent variable for all three participants was changing the conversation when someone is bored. Changing the conversation when someone is bored was divided into seven component steps (see Table 2 ). Participant engagement in each of the steps was assessed during probe sessions (described later). The mastery criterion was defined as the participant engaging in each of the steps in the outlined order across three consecutive probe sessions. Generalization of changing the conversation when someone is bored was also measured once prior to intervention and once following a participant reaching the mastery criterion. Probe sessions to assess generalization after intervention occurred between 2 and 5 days following a participant reaching the mastery criterion.Probe sessions occurred across each condition (i.e., baseline, intervention, generalization, and maintenance). Probe sessions consisted of one opportunity for the participant to demonstrate the targeted skill and lasted an average of 2 min (range 1-4 min). During the intervention condition, probe sessions always preceded intervention sessions with a 1 min break between sessions. Probe sessions were used to assess participant responding in the absence of direct instruction, prompting, or programmed reinforcement.To begin each probe, the interventionist engaged the participant in a conversation about a preferred topic. These topics were determined by discussing with the participant's staff and supervisor the participant's preferred movies, video games, and activities. Following 2 min or a minimum of four exchanges, the interventionist began to engage in nonvocal boredom cues for up to 15 s. These cues consisted of looking away from the screen, looking at their phone or watch, or not responding to the participant. If the participant engaged in the steps for changing the conversation when someone is bored, the interventionist responded in accordance with the task analysis. That is, the interventionist engaged in a vocal/verbal response related to the statement made by the participant. If the participant did not engage in the steps for changing the conversation when someone is bored, the interventionist ended the probe by saying ""thanks"" and returning them back to the activity in which they were previously engaged.Sessions occurred once a day, 2 to 5 days a week, depending on participant and interventionist availability. Intervention sessions lasted an average of 10 min (range 7-17 min). The interventionist sent a link for the Zoom video conference to the participant's staff member. The staff member began the video conference for the participant and was available during the intervention sessions for role-plays. The staff member did not have any other interactions or functions during research sessions (i.e., they did not function as a shadow or provide any prompts or praise throughout the sessions).The purpose of baseline was to assess participant responding prior to any intervention or programmed reinforcement. Baseline sessions consisted of a probe session (previously described).Generalization of changing the conversation when someone is bored was assessed prior to intervention and after reaching the mastery criterion for all participants. To assess generalization, probe sessions occurred as described previously (i.e., via Zoom) with the exception that the participant's supervisor served as the conversation partner (i.e., someone different from the interventionist and staff member). Within the clinic, the participant's supervisor was responsible for training staff, developing curriculum and intervention strategies, and overseeing the participant's overall progress. Winston's supervisor was a 33-year-old White female with a bachelor's degree in psychology and 11 years of experience providing intervention for autistics/individuals diagnosed with ASD. Nick's supervisor was a 30-year-old White female with a bachelor's degree in psychology and 7.5 years of experience providing intervention for autistics/individuals diagnosed with ASD. Schmidt's supervisor was a 39-year-old Korean female with a master's degree in applied behavior analysis and 10 years of experience providing intervention for autistics/individuals diagnosed with ASD.Intervention consisted of the Cool Versus Not Cool procedure delivered via Zoom video conferences. To begin, the interventionist labeled the targeted skill (e.g., ""Today we are going to work on changing the conversation when someone is bored."").The interventionist then provided a demonstration with the participant's staff member. The demonstration consisted of the interventionist and the participant's staff member engaging in a conversation via the Zoom connection. The staff member (who was in the same room as the participant) would then engage in nonvocal boredom cues. The interventionist followed the steps for changing the conversation when someone is bored (i.e., ""cool"" demonstration) or responded similarly to how the participant was responding to nonvocal boredom cues during probe sessions (i.e., ""not cool"" demonstration). The interventionist then ended the demonstration and asked the participant to label whether the interventionist responded in the cool or not cool way (e.g., ""Was that cool or not cool?""). If the participant responded correctly, the interventionist provided praise and asked the participant to label why the demonstration was cool or not cool (e.g., ""That's right! Why was it cool/not cool?""). If the participant responded incorrectly, the interventionist provided feedback and asked why the demonstration was cool or not cool (e.g., ""No, that was actually not cool. Tell me why that was not cool.""). There were a total of four demonstrations with two cool and two not cool demonstrations that were randomized prior to each session. Following the demonstrations, the interventionist then provided the participant with an opportunity to practice. During these role-plays, the interventionist engaged the participant in a conversation about a preferred topic and began to engage in nonvocal boredom cues. If the participant engaged in the steps for changing the conversation when someone is bored, the interventionist provided praise (e.g., ""That's the way! Kiss your brain!""). If the participant did not engage in the steps for changing the conversation when someone is bored, the interventionist ended the role-play and provided corrective feedback (e.g., ""You missed it. I was bored, and you didn't change the conversation.""). This Step Description 1 Faces the screen 2Maintains a neutral or positive facial expression 3Maintains a neutral or positive tone 4Asks a question or makes a statement within 10 s of the interventionist engaging in a cue signaling boredom 5 Waits for the interventionist to respond 6 Asks a second question or makes a statement about a new topic within 10 s of the interventionist's response 7 Waits for the interventionist to respond continued until the participant engaged in all the steps for changing the conversation when someone is bored correctly.Maintenance probes began 7 days following the participant reaching the mastery criterion for changing the conversation when someone is bored (as previously described). All maintenance sessions were conducted by the previously described interventionist. Three maintenance sessions occurred for each participant.A nonconcurrent multiple-baseline design (Watson & Workman, 1981) across participants, with a modification to improve experimental control, was used to evaluate the effectiveness of the Cool Versus Not Cool procedure delivered via telehealth on the participants' changing the conversation when someone is bored. This design was selected for its flexibility when conducting research in applied settings, which a concurrent multiple-baseline design does not allow. This flexibility was even more necessary for conducting research during an ongoing pandemic. Traditionally, within a nonconcurrent multiple-baseline design, baseline phases are predetermined, and participants are randomly assigned to each baseline length as they become available (Watson & Workman, 1981) . Similar to previous studies (e.g., Cihon et al., 2019) , an additional criterion common within multiple-baseline logic was used in this study in an attempt to improve the strength of the design. Participants progressed from baseline to intervention once a stable level of responding was observed during baseline. That is, we extended baseline sessions for the next participant until intervention effects were observed with the previous participant if necessary. Therefore, predetermined baseline phases and assignment were not used within this study. Experimental control was demonstrated when the intervention resulted in changes in a participant's behavior without changes in the remaining participants' behavior during baseline sessions (Baer et al., 1968; Carr, 2005) . Furthermore, although the nonconcurrent multiple-baseline design permits participant removal if stable responding is not obtained, no participants were removed from this study for this or any other reason.Julia L. Ferguson, the second author (who was the interventionist in the study), also served as the primary rater for all sessions. Matthew Lee, the third author, served as the secondary rater. He held an undergraduate degree in psychology and had 6 months of experience with interventions based in applied behavior analysis for autistics/individuals diagnosed with ASD. Interrater agreement was collected on the primary dependent variable on 37.5% of all sessions across participants and conditions. Agreements were defined as both raters scoring the same response on a step for changing the conversation when someone is bored. Disagreements were defined as one rater scoring one response and the other rater scoring a different response on a step for changing the conversation when someone is bored. Interrater agreement was calculated by dividing the number of agreements by the number of disagreements plus agreements and dividing by 100. Interrater agreement across all three participants was 100% during baseline, generalization, intervention, and maintenance conditions. The fidelity of the interventionist's implementation of probes and the Cool Versus Not Cool procedure was also assessed. Matthew Lee (previously described) independently observed 35.7% of probe sessions and 37.8% of intervention sessions across all participants and conditions to score the interventionist's behavior. Correct interventionist behavior during probes consisted of (a) engaging the participant in a conversation about a preferred topic, (b) engaging in nonvocal boredom cues following 2 min or a minimum of four exchanges, (c) responding in accordance with the task analysis if the participant engaged in the steps of the targeted skill, and (d) ending the probe by saying ""thanks"" if the participant did not engage in the steps of the targeted skill. Treatment fidelity was calculated by dividing the number of steps the interventionist displayed correctly by the total number of steps and multiplying by 100. Treatment fidelity for probes averaged 100% across all participants and conditions. Correct interventionist behavior during intervention sessions consisted of (a) labeling the targeted skill, (b) providing an instruction for the participant to watch the demonstration, (c) providing two cool and two not cool demonstrations, (d) providing the participant with an opportunity to rate whether the demonstration was cool or not cool after each demonstration, (e) providing the consequence that corresponded with the participant's response after each rating, (f) providing the participant with an opportunity to label why the demonstration was cool or not cool after each demonstration, (g) providing the consequence that corresponded with the participant's response after each answer, (h) providing the participant with an opportunity to role-play the targeted skill, (i) providing the consequence that corresponded with the participant's response, and (j) repeating role-plays until the participant engaged in all steps of the targeted skill correctly. Treatment fidelity for intervention sessions averaged 100% across all participants.To assess social validity, a questionnaire with four questions was sent to the participants' supervisors and parents at the end of the study. The supervisors and parents were provided with a video from the intervention condition (i.e., without the probe) selected at random for their child/client and were asked to fill out the questionnaire after viewing the video. The questions consisted of the following:1. How important was it for the/you child to learn the skill the interventionist was teaching? 2. Please rate the degree to which you found the intervention to be acceptable. 3. Please rate the degree to which you found the intervention to be effective. 4. Do you feel that this method of social skills instruction is an acceptable replacement for in-person social skills instruction?Responses to each of the questions were on a Likert scale from 1 (i.e., not at all important, not at all acceptable, and not at all effective) to 5 (i.e., very important, very acceptable, and very effective). The supervisors and parents then sent the questionnaires back to the researchers anonymously. Figure 1 displays the results for all three participants across all conditions. During baseline, all three participants engaged in the same number of steps for changing the conversation when someone is bored. All three participants were consistently engaging in the first three steps (i.e., facing the screen, maintaining a neutral or positive facial expression, and maintaining a neutral or positive tone) but not any of the remaining steps, which is not surprising given the possibility that those steps are likely necessary for any conversation-based skills. This responding continued during the assessment of generalization prior to the intervention condition. All three participants reached the mastery criterion (i.e., engaging in each of the steps in the outlined order across three consecutive probe sessions) during the intervention condition. The total intervention time required for Winston, Nick, and Schmidt to reach the mastery criterion was 70, 45, and 59 min, respectively. After reaching the mastery criterion, Winston's responding during the assessment of generalization returned to baseline levels, whereas Nick and Schmidt continued to engage in all steps correctly during the assessment of generalization. All three participants continued to engage in all steps correctly during maintenance sessions that occurred 7 days after they reached the mastery criterion.All three supervisors and only one parent returned the social validity questionnaire. When asked how important it was for the child to learn the skill the interventionist was teaching, all three supervisors responded with a 4. When asked to rate the degree to which they found the intervention to be acceptable, all three supervisors responded with a 5. When asked to rate the degree to which they found the intervention to be effective, the supervisors responded with a 4 on average (range 3-5). When asked if they felt that this method of social skills instruction is an acceptable replacement for in-person social skills instruction, all three supervisors responded with a 4. The only parent to return the social validity questionnaire responded with a 5 on all questions. Given the context in which this study occurred (i.e., COVID-19 pandemic) that may have resulted in increased stress and hardships for the parents and families, the researchers did not persist in requests to return the questionnaire if the parents did not do so after one follow-up.The purpose of the present study was to evaluate the effectiveness of the Cool Versus Not Cool procedure conducted via telehealth to teach three children diagnosed with ASD to change the conversation when someone is bored. All three participants reached the mastery criterion in a relatively low number of sessions (range 4-8). Responding generalized to another adult for two of the three participants, and all three participants maintained correct responding on all steps of the targeted skill on all maintenance probes. Furthermore, responses to the social validity questionnaires indicated the skill was important to teach, the intervention was acceptable and effective, and the telehealth format was an acceptable replacement for in-person intervention for these three participants. These results have implications for clinicians providing intervention for autistics/individuals diagnosed with ASD.The development of an effective social skills repertoire is a common focus of interventions for autistics/individuals diagnosed with ASD. Recent events have put many clinicians in the position of shifting this intervention to telehealth. Given the limited research on effective social skills interventions delivered via telehealth, this study provides clinicians with a viable option when making this shift. The results indicated that the Cool Versus Not Cool procedure can effectively be used when delivered via telehealth under conditions similar to this study (e.g., staff available, similar participant demographics, similar social skill). Furthermore, given previous comparisons with other interventions (e.g., Social Stories; Leaf et al., 2016) and a lack of data supporting the use of those other interventions via telehealth, clinicians may opt for the use of the Cool Versus Not Cool procedure over interventions such as Social Stories. However, future research will be necessary to compare these interventions within the same telehealth context to provide empirical evidence for the use of one procedure over the other.Clinicians should also closely monitor the generalization of social skills that are targeted using the Cool Versus Not Cool procedure via telehealth. Winston's responding within the teaching context did not generalize to a very similar context. It may be the case that a social skills intervention delivered via telehealth poses limitations that are absent in an in-person intervention. The social context involved in the delivery of interventions via telehealth differs greatly from the social context of in-person delivery. This difference could make developing the desired stimulus controls for social behavior difficult. For example, there may be subtleties within in-person interactions that become part of the contingencies that are not present or possible in a telehealth context. This difference may vary based on the social skill that is targeted, and future research may more efficiently evaluate this by targeting multiple skills within a study.The results of the social validity questionnaire indicated the intervention was appropriate, effective, and an acceptable replacement for in-person social skills instruction for the respondents of the survey. These results provide more support for clinicians to use the Cool Versus Not Cool procedure when delivering social skills intervention via telehealth. This may be a welcomed result with respect to the numerous considerations required when making the move to telehealth (Cox et al., 2020) . It should be noted, however, that there was a low response rate to the survey from the parent respondents, which may affect the interpretation of the social validity data. Furthermore, clinicians should remain cautious and take into consideration individual differences, given the limited number of participants, skills, and social validity respondents within this study.This study did not go without limitations that warrant discussion. First, although the interventionist conducted all sessions via Zoom, each of the participants had a staff member present at their location during all sessions who also assisted during the demonstration portion of the Cool Versus Not Cool procedure. This might not be possible in all situations. However, it is common for a parent or caregiver to be present during telehealth sessions. In these cases, a parent could fill the position of the staff member. Second, only one skill was Previous research has demonstrated the effectiveness of the Cool Versus Not Cool procedure to teach a variety of social skills, and it is possible those results would extend to a telehealth context. Future research will be necessary to evaluate whether that is the case. Third, all the participants in this study had a previous history of receiving in-person social skills interventions including the Cool Versus Not Cool procedure, had some experience with direct intervention delivered via telehealth, and had rather well-developed repertoires (see Table 1 ). As such, the results may not generalize to other autistics/individuals diagnosed with ASD with less experience with the Cool Versus Not Cool procedure and intervention delivered via telehealth or with less developed repertoires. Fourth, due to the setting in which the study occurred, a nonconcurrent multiple-baseline design was used. Although nonconcurrent multiple-baseline designs control for threats to internal validity (Harvey et al., 2004; Watson & Workman, 1981) and are common within applied research, a concurrent multiple-baseline design may be desired by future researchers. Finally, no measures of generalization were collected for inperson settings. These measures were not included for two primary reasons. First, due to the COVID-19 pandemic, increasing the number of people the participants contacted in person was deemed potentially harmful. Second, given the increase in the use of virtual environments, targeting social skills potentially useful in those environments may be useful in its own right given the increased use of communication technologies among young persons (Manago et al., 2020) . Nonetheless, the results should be taken with caution with respect to the generalization of effects to in-person settings.Despite the limitations, this study contributes to the limited literature on effective social skills interventions delivered via telehealth for autistics/individuals diagnosed with ASD. Given the uncertainty involved in what the intervention context will resemble in the future and the limited number of qualified professionals in some areas, effective, evidencebased interventions delivered via telehealth are more necessary than ever. We hope this study provides clinicians with an effective, evidence-based social skill intervention when shifting to telehealth-based instruction and targeting social skills for use in virtual environments and inspires future similar research to increase the number of treatment options available to interventionists.Funding No grants were received to fund this project.Ethical Approval All procedures performed in studies involving human participants were in accordance with the ethical standards of the institutional and/or national research committee and with the 1964 Helsinki declaration and its later amendments or comparable ethical standards.Informed Consent Informed consent was obtained from all individual participants included in the study.",USA,first author,2021-02-12,02
b4e21808e63b2dd8f50a883935c7d3180f3cef1a,Impact of COVID-19 on postpartum women 1 Impact of COVID-19 restrictions on the postpartum experience of women living in Eastern Canada: A mixed method cohort study,"The COVID-19 pandemic has disrupted many aspects of life. Women are disproportionally being impacted with significant impacts on childcare and their physical health (Connor et al., 2020) . During the pandemic, there have been reports of increases in the rates of postpartum anxiety and depression (Davenport et al., 2020; Lebel et al., 2020; Ollivier et al., 2020; Wu et al., 2020) . Previous work has shown the importance of social support in the postpartum transition in developing parenting self-efficacy (Leahy-Warren, 2005; Leahy-Warren et al., 2012) and decreasing postpartum anxiety and depression (Hetherington et al., 2018) .However, to minimize the spread of COVID-19, recommendations of physical distancing resulted in new mothers losing that social connection, isolating at home without any in-person support -both from healthcare providers and family and friends. There is currently limited knowledge on the impact that COVID-19 has had on the postpartum experience of new mothers, particularly as compared to pre-pandemic level.The objectives of this study were to (1) compare changes in self-efficacy, social support, postpartum anxiety and postpartum depression in Canadian women collected before (Cohort 1) and during the COVID-19 pandemic (Cohort 2); (2) explore the women felt related to having a newborn during the pandemic; and (3) explore ways that women coped.Women were considered eligible if they: (1) had an infant six months of age or less; (2) were over 18 years of age; (3) were able to speak, write and read English; and (4) currently live in a Maritime Province. Women were excluded if they lived outside the Maritime Provinces or had their most recent baby more than six-months prior to the date the survey was completed.The study was completed across three Eastern Canadian provinces, Nova Scotia, New Brunswick and Prince Edward Island, often referred to as the Maritime provinces. They make up 5.1% of Canada's population (Statistics Canada, 2019) and 4.2% of Canadian births (Statistics Canada, n.d.) . States of emergency were declared between March 11 and 22, 2020 across the three provinces. On July 3, 2020, all three provinces with Newfoundland and Labourer created the 'Atlantic Bubble', which kept open borders between provinces without having to self-isolate upon arrival (The Council of Atlantic Premiers, 2020). Individuals arriving from elsewhere in Canada or internationally were still required to self-isolate for 14 days. The Atlantic bubble remained until November 24 th , 2020 when self-isolation was again required in some provinces to minimize the impact of the second wave of the pandemic.Throughout the pandemic, there have been significant restrictions in all three provinces including: required self-isolation of symptomatic individuals, non-essential travel restrictions between provinces or region, limits on social gatherings, masks required in public places, and physical distancing requirements. In specific relation to the perinatal experience, there were restrictions on the number of support people allowed to be present during antenatal appointments, during childbirth, and for postpartum appointments -either being no support people allowed or only one support person. There was a reduction or cancellation of in-person healthcare visits from public health nurses, parent support groups, and public health drop-ins.Women were recruited to participate in an online survey through online advertisements (e.g., Facebook, Twitter), media outreach, and study posters. For both surveys, women could opt into a draw for one of three $100 CAN electronic gift cards. Once participants completed the eligibility screening, they were directed to a consent form. The survey contained standardized measures and open ended response options which took approximately 30 minutes to complete.To determine the impact of COVID-19 on the postpartum experience, participants in Cohort 2 were asked to share the hardest part about having a newborn during COVID-19 and what helped them cope. Participants also completed COVID-19 exposure and impact questions and the Impact of Stressful Event Scale -Revised (IES-R), a 22-item self-report assessment of subjective distress caused by traumatic events with scores ranging from 0 (low distress) through 12 (high distress) (Weiss, 2007) .Independent sample t-tests were used to determine differences between Cohort 1 and Cohort 2 on self-efficacy, social support, postpartum anxiety, and depression. Potential differences across parity and age of newborn were also considered. Means and standard deviations were used to describe the sample. Open ended responses were analyzed by the first author and verified by the second using thematic analysis informed by a qualitative descriptive approach (Bradshaw et al., 2017; Braun & Clarke, 2006) .For Cohort 1, the survey was completed by 561 women who had given birth between April to December 2019. For Cohort 2, the survey was completed by 331 women who had given birth between February to October 2020. The women were similar in terms of parity, geographic location, age of newborn, and number of biological children with demographic details in Table 1 .[ Table 1 ]As shown in Table 2 , there were no significant differences on any of the psychosocial outcomes between Cohorts. In Cohort 1, 31.9% of the sample had clinical high anxiety symptoms (PSAS>112) and 20.3% had high depression (EPDS>14) compared to 31.9% and 18.0% of Cohort 2, respectively. When considering differences by parity, the only significant difference was for primiparous women with social support from friends, which was lower in Cohort 1 (M=5.54, SD=1.42) than Cohort 2 (M=5.80, SD=1.29), p=0.033. When considering age of their baby, the only significant difference was again with social support from friends (cohort 1 M=5.34, SD=1.50; cohort 2 M=5.73, SD=1.34, p=0.014) and total social support (cohort 1 M=5.77, SD=1.09; cohort 2 M=6.00, SD=0.96, p=0.039) for women with infants aged 4-6 months. No other differences were found (non-significant results not shown).[ Table 2 ]Women mentioned several difficulties they experienced as a result of COVID-19restrictions, including lack of support from family and friends, fear of COVID-19 exposure, feeling isolated and uncertainty, negative impact on perinatal care experience, and hospital restrictions.One of the biggest difficulties was the lack of support available from their families and friends in the immediate postpartum period. One woman explained that this is ""the one time in your life you should have family and friends around and we weren't allowed."" Similarly, women discussed how hard it was for them not to have their families and friends meet their newborn in person, particularly if they lived in different provinces. A woman explained ""My husband is an essential worker and had to return to work after the baby was born and no one could visit because they lived in another province. For 2 months I was completely alone with my baby"".Women also reported feeling very isolated and alone during the postpartum time. Women discussed the ""being alone for months"", the ""isolation from friends and family"", and the feeling of being ""a bit trapped and isolated"". They also felt very uncertain about what has happening or going to happen: ""uncertainties about how life would be affected by COVID"" and ""stress of the unknown"".Women also discussed the negative impact of COVID-19 on their perinatal care experience. Women were disappointed and often struggled with having to attend antenatal appointments alone, without their partner or a support person. One woman explained: ""This was my first baby, and my fiancé was unable to attend half of the appointments/ultrasounds that we felt ""like my maternity leave has been ripped away"", the ""lack of mom-groups for that peer-topeer support,"" and ""the feeling of missing out on the normal experiences of being a new parent.""One woman said: ""I gave birth alone because my partner had a cold and wasn't allowed in the hospital"". Another woman said ""My husband [was] not allowed in the hospital until I was about to deliver. I was there 22 hours by myself (this was my first child) -a very lonely and scary ordeal!""[her] mother come and help out after a week of exhaustion."" Women mentioned support from friends and community members as important to helping them cope, including talking to friends, having people drop off meals, and having support from people in their 'bubbles'. Women indicated the importance of virtual connection with family and friends via FaceTime or text message: ""FaceTime! Thank goodness for FaceTime so at least my family could easily see the baby."" Similarly, women also mentioned having support from online sources, such as online mom groups. One woman said: ""Reading and participating in online forums and new mom groups made me feel less alone and was a great way to ask questions and share experiences.""Beyond support, women also mentioned the importance of engaging in self-care, such as going for walks or exercising, as well as focusing on their newborn and their new family was helpful during this time. One woman explained: ""I enjoyed the first few months of being able to bond with my baby and husband and create a routine/stay at home."" Women also commented on their focus of this experience being a time-limited concern and that things will get better: ""Just taking things day by day, trying not to watch the news and just reminding myself that my baby is safe with me and that eventually this will all be a memory.""This study explored the impact of COVID-19 on the postpartum experience of women living in the Maritime provinces. While there was no significant difference in pre-pandemic and during pandemic on psychosocial outcomes, there were still important challenges and negative impacts that women identified. In particular, the lack of support from family and friends, fear of COVID-19 exposure, feeling isolated, hospital restrictions and uncertainty negatively impacted on perinatal care experience. Having support from partners, families, and in-person/virtual support was helpful for women in coping with the impacts of COVID-19.It is reassuring that there were no significant differences in self-efficacy, social support, postpartum anxiety and depression between cohorts. This differs than previous work which found an increase in perinatal anxiety and depression due to the COVID-19 pandemic (Lebel et al., 2020) . However, no significant differences were found in a meta-analysis in eight studies for postpartum depression but there was an increase in anxiety (Hessami et al., 2020) . In our sample, not only was the epidemiology in the area extremely low, the percentage of the population that was exposed to, or suspected to having, COVID-19, was also low. This may have played a role in decreasing the influence that COVID-19 had on maternal mental health. Additionally, the support women received from their partners, family and friends may have provided some resilience and buffer against the more extreme impacts found in other studies to date.The ""bubbling"" with families and the larger Atlantic bubble seemed to alleviate some difficulties, with increased access to support from family and friends. In a study in New Zealand adults, who had a similar low number of cases yet also experienced a period of lockdown, they similarly found positive, 'silver linings' including family time and ability to focus on self-care and pausing and reflecting (Every-Palmer et al., 2020) . Other studies have found that partners are an essential component in helping cope with the challenges with having a newborn during the COVID-19 pandemic and providing resiliency (Farewell et al., 2020) . Thus, considerations of this vulnerable population are essential in planning physical distancing recommendations.Consideration of two-household families may be especially important for families who are experiencing a life transition, such as welcoming a newborn, but may also be recommended for those suffering from illness or other health concerns. It is important to understand how different coping methods can be utilized to reduce the negative health risks of isolation and lockdowns.While there were no significant differences between pre-pandemic and during pandemic psychosocial outcomes, there were still important challenges and negative impacts women identified related to their postpartum experience. The lack of support from family and friends, fear of COVID-19 exposure, feeling isolated and uncertain, negative impact on perinatal care experience, and hospital restrictions negatively impacted women. While this was buffered through means of coping, including support from partners and families as well as self-care, consideration of vulnerable populations is important when making public health recommendations for society.",Canada,first author,2021-02-01,02
9af87ac98af5fe589fc5c1df8dfaac7dec323704,The ACE2-binding Interface of SARS-CoV-2 Spike Inherently Deflects Immune Recognition,"The severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) has caused a worldwide outbreak of the coronavirus disease 2019, COVID-19. As of October 25th 2020, over 42 million cases have been confirmed globally, leading to 1.1 million deaths (https://www.who. int/emergencies/diseases/novel-coronavirus-2019/ situation-reports/). A number of drugs and vaccines for COVID-19 are currently in clinical trials, yet no agents or vaccines have been approved by the government agencies. As such, the host immune responses remain the main source of protection against the virus. Still many aspects of the immune responses and the strategies employed by the virus to evade them are unknown.The entry of SARS-CoV-2 into host cells is mediated by a virus-surface spike glycoprotein that forms a trimer (Figure 1(A) ). 1, 2 The spike protein is composed of two subunits, S1 and S2. The S1 subunit interacts with the host cell receptor, angiotensin-converting enzyme 2 (ACE2), a crucial step in cell attachment, whereas the S2 subunit plays a role in the fusion of the viral and cellular membrane, a crucial step in cell entry. 2, 3 The receptor binding domain (RBD) in the S1 subunit is the domain that binds ACE2 with an affinity in the low nanomolar range, 2, 4, 5 and this interaction initiates the conformational change of the spike protein from the pre-fusion state to the post-fusion state. Consequently, antibodies targeting the ACE2-interacting surface (ACE2IS) located in the RBD of the spike protein can compete with the RBD-ACE2 interaction, serving as neutralizing antibodies. Indeed, such antibodies isolated from COVID-19 patients showed potent neutralization effects and are being developed as therapeutics. [6] [7] [8] [9] Thus, eliciting antibodies targeting the ACE2IS from the immune system should be critical for controlling and preventing COVID-19.A region of an antigen is considered immunogenic if it is readily recognized by antibodies, although many aspects in the immune responses of the host can influence the overall immunogenicity. It has been shown that antibodies and antibody-like binders derived from unbiased selections disproportionately target functional surfaces of a protein. 10, 11 Thus, protein-protein interaction interfaces such as the ACE2IS in the RBD of the spike protein are expected to be highly immunogenic. From the viewpoint of viral evolution, there should be a strong selective pressure favoring the protection of a region that is crucial for the viral life-cycle from host immune attacks. For example, the CD4binding site of the HIV gp120 envelope glycoprotein is situated in a deep cleft heavily protected by glycosylation. 12 However, studies revealed that the spike proteins of coronavirus including SARS-CoV-2, SARS-CoV and MERS-CoV are less densely glycosylated than the other viral spike proteins including, HIV-1 envelope, Lassa virus glycoprotein complex, and influenza hemagglutinin envelop. 13, 14 In particular, the RBD is less shielded by glycans as compared with the rest of the spike protein of SARS-CoV-2. 14, 15 The RBD and the ACE2IS are the most distal parts of the spike protein in the assembled virus and thus it should be more accessible to antibodies and B-cells. Taken together, the ACE2IS of the SARS-CoV-2 is expected to be substantially more immunogenic than anticipated based on its surface exposure. Intriguingly, a number of studies of SARS-CoV-2 specific antibody responses in COVID-19 patients have revealed that, although most convalescent plasmas from COVID-19 patients contain antibodies targeting the spike protein and the RBD, they have low neutralization activity. [16] [17] [18] Thus, analysis of the immunogenic surfaces, or the ""immunogenicity landscape"", of the spike protein and the RBD in terms of eliciting high-affinity antibodies should provide important insights into the antibody response to COVID-19 as well as vaccine design, because the spike protein and the RBD are the antigens in most first- The RBD in complex with ACE2 (PDB 6M0J). The RBD core is shown in blue and ACE2 is shown in green. The receptor binding motif in the RBD is shown in yellow, and the residues contacting ACE2 are shown in red. The dotted circles indicate contact regions (CR1, CR2 and CR3). The amino acid residues (N487, Q493 and N501) in the RBD are shown as stick model and labeled in red, and their contacting residues in ACE2 are labeled in black. (C) Binding titration of the RBD and RBD-T to ACE2 expressing A549 cells. Data shown here are from triplicate measurements. The K D values are from curve fitting of a 1:1 binding model, and the errors shown are the s.d. from curve fitting. Error bars are within the size of the symbols. generation vaccines for COVID-19 (https://www. who.int/publications/m/item/draft-landscape-ofcovid-19-candidate-vaccines).In this study, to define immunogenic properties of epitopes within the spike protein, we performed in vitro selection of a synthetic human antibody library against the spike protein and the RBD. We designed an RBD mutant that abolished binding of the RBD to ACE2, and utilized it as a tool for epitope analysis of convalescent sera and in antibody discovery. Our results suggest that the ACE2IS in the RBD is a minimally immunogenic surface within the spike protein, and we discuss the molecular underpinning of this finding and its implications for vaccine design.To develop a tool for facilitating the analysis of ACE2IS-binding antibodies, we designed an RBD mutant that disrupts the ACE2IS. The ACE2IS in the RBD is mainly composed of three contact regions, CR1, CR2 and CR3 (Figure 1(B) ). 19 From each contact region, we chose a key residue (N487, Q493 and N501) that forms hydrogen bond (s) with residues in ACE2, and mutated them to Lys residues to disrupt both electrostatic and van der Waals interactions (Figure 1 (B), Supplementary Figure 1 ). We term this mutant as RBD-T hereafter. Binding analysis using ACE2-expressing cells showed that the RBD bound to ACE2 with high affinity (K D~2 0 nM), consistent with previous reports, 1,2,5 and that RBD-T nearly completely lost binding to ACE2 (Figure 1 (C)). Likewise, these mutations should disrupt binding of neutralizing antibodies targeting the ACE2IS (see below). We note that not all neutralizing antibodies would fail to bind to RBD-T, because some neutralizing antibodies do not directly bind to the ACE2IS. 20 A binding assay using the RBD and RBD-T is a straightforward method to determine whether antibodies recognize the ACE2IS or not, and thus we utilized the RBD-T as an epitope analysis tool for anti-RBD antibodies.To characterize the prevalence of antibody response to the ACE2IS in COVID-19 patients, we performed binding analysis of 94 convalescent serum samples 17 from healthcare workers who showed PCR-positivity for COVID-19. In this experiment, we measured the IgG binding to the RBD in the absence and presence of excess soluble RBD-T competitor. Strikingly, more than 60% of the signal was lost in the presence of the RBD-T competitor in 80% of the serum samples, indicating that the majority of the antibodies that bound to the RBD in convalescent sera did not target the ACE2IS ( Figure 2 (A) and (B)). We found that the neutralization titer is correlated with anti-RBD IgG binding but to a lesser degree with anti-RBD-T IgG binding (Figure 2 (C)), confirming that IgG antibodies targeting the ACE2IS contribute to neutralization. Together, these data suggest that the ACE2IS is not a highly immunogenic epitope within the RBD.Unbiased antibody selection for the spike protein and the RBD To investigate the immunogenicity landscape of the spike protein and the RBD, we performed in vitro selection of a human antibody phagedisplay library against the spike protein and the RBD. The recovery of antibody clones in the in vitro selection primarily depends on the strength of binding to the antigen, and thus analyzing specificity and epitopes of enriched antibodies enables us to determine the immunogenicity landscape of the antigens from the point of the direct antibody-antigen interaction under welldefine conditions. We used a synthetic antibody library that is constructed based on both intrinsic amino acid bias in immune repertoires and knowledge of structures and functions of naturally occurring antibodies. 21, 22 This, and closely related antibody libraries, have generated numerous highaffinity antibodies to diverse proteins. 23 Of importance for this study, this library uses the IGHV3 framework, which is closely related to the IGHV3-53 germline that is frequently found in RBDbinding antibodies (see Discussion). 24 We first performed selection for antibodies against the spike protein and the RBD in an unbiased manner, that is, we did not incorporate steps that might bias the recovery of antibodies binding to different epitopes ( Figure 3 (A)). Clones from the 3rd and 4th rounds of selection were randomly picked, and their sequences and binding specificity were characterized in the phage-display format. We identified 95 unique clones out of 120 randomly picked colonies from the spike selection campaign (Figure 3 (A)). Strikingly, 89% of the clones bound to the spike protein but not the RBD or RBD-T (""Spike only"" binders), indicating that these antibodies recognize the surfaces of the spike protein outside the RBD or the surfaces that partially consists of the RBD (Figure 3 (A) and (B)). Only 11% of the clones showed ability to bind to the spike protein as well as the RBD and RBD-T (""Spike + RBD"" binders), and antibodies binding to the ACE2IS, as judged by the ability to bind to the RBD but not to RBD-T, were not identified from this selection. These results suggest that the RBD is not a highly immunogenic region of the spike protein.From the RBD selection campaign, we identified 23 unique clones out of 24 randomly picked colonies (Figure 3(A) ). Although the ACE2IS is highly exposed on the RBD, antibodies targeting the ACE2IS were not identified from this selection.Interestingly, 83% of the clones showed binding to the RBD and RBD-T, but not to the spike protein (""RBD only"" binders) ( Figure 3 (A) and (B)). These data indicate that their epitopes are exposed when the RBD exists in isolation or after dissociation of the S1 subunit from the spike protein, but are not exposed when the RBD is a part of the fully assembled spike trimer. These results suggest that, if the RBD is used as an antigen for vaccination, antibodies targeting those epitopes of the RBD that are not exposed in the native spike protein can dominate in the initial immune response. Together, our data suggest that isolated RBD contains highly immunogenic epitopes that are inaccessible in the context of the fully assembled spike protein.Because the unbiased RBD selection campaign enriched antibodies that do not bind to the spike protein, we next performed antibody selection using both RBD and spike protein as the antigens ( Figure 3 (A)) to intentionally enrich for clones that cross-react with both antigens. We identified 35 unique antibodies among 120 randomly chosen clones. A majority of clones bound to both RBD and spike protein (""Spike + RBD"" binders), indicating that RBD contains epitopes that can be readily recognized in the context of the fully assembled spike protein (Figure 3 (A) and (B)). We note that antibodies that bound outside the RBD (""Spike only"" binders) and to epitopes on the RBD that are inaccessible in the spike protein (""RBD only"" binders) were still recovered, despite the use of a strong selection bias against such clones. We identified clones that bound to both RBD and spike protein but not RBD-T, indicating that they recognize the ACE2IS (""ACE2IS binders""). Interestingly, among RBD-binding antibodies, only 12% of clones recognize the ACE2IS in the RBD, whereas 88% of clones recognize epitopes other than the ACE2IS (Figure 3 with RBD-T competitor Sample ID We next performed selection of antibodies binding to the RBD that incorporated a negative selection step using RBD-T so as to enrich antibodies binding to the ACE2IS. From this selection, 39% of clones recognized the ACE2IS in the RBD, which is a substantially higher percentage than those recovered in the unbiased selections (0% for both selections using the spike protein and the RBD) as well as the RBD-spike selection (11%) (Figure 3(A) ). These data indicate that our phage-display library contains antibodies targeting the ACE2IS and such antibodies can be identified if we intentionally try to enrich such antibodies. Taken together, our data demonstrate that the RBD is not a dominant immunogenic domain in the spike protein and the ACE2IS is a minimally immunogenic epitope within the RBD.To determine whether antibodies that do not bind to RBD-T, i.e. ACE2IS binders, indeed neutralize SARS-CoV-2, we produced five Fab clones (one each from ""Spike only"", ""Spike + RBD"" and ""RBD only"" binders and two from ACE2IS binders), and we performed the binding assay, the competitive binding assay with ACE2 and the neutralizing assay using authentic SARS-CoV-2. The antibodies targeting the spike protein outside the RBD (A4-2) and targeting the RBD outside the ACE2IS (B3-4 and B3-1) did not interfere with the ACE2-spike interaction nor did show a neutralization effect (Figure 3 the RBD but not to RBD-T indeed competed with ACE2-spike interaction and showed a neutralization effect against the SARS-CoV-2 virus (Figure 3 (C)-(E)), as we predicted. Thus, although we note that some neutralizing antibodies that do not directly target the ACE2IS have been reported, 20 our binding assay using RBD-T is effective in quantifying neutralizing antibodies that target the ACE2IS.We have shown that the ACE2IS is more difficult to target with our synthetic antibody library than the rest of the RBD and the spike protein. Because no synthetic library can completely recapitulate the human antibody repertoire, one might view that these results are a reflection of limitations of our library, rather than the antigenic landscape of the spike protein. The following considerations strongly suggest that this is not the case. Neutralizing anti-RBD antibodies from recovered patients show clear biases in germline usage. The IGHV3-53 germline is the most frequently used IGHV gene for neutralizing anti-RBD antibodies and the residues in CDRH1 and CDRH2 encoded by the IGHV3-53 germline are important for RBD binding. 24 Our synthetic antibody library is based on the human V3 germline sequence, and residues in CDRH1 and H2 are diversified based on intrinsic amino acid bias in native immune repertoires. 21, 22 It has only minor differences, two substitutions in CDRH1 and a single residue insertion in CDRH2, from IGHV3-53 (Supplementary Table 1) . Thus, our library should be more predisposed to generating anti-RBD neutralizing antibodies than a library that faithfully recapitulates the human antibody diversity. More importantly, we have identified several antibodies binding to ACE2IS by utilizing biased selection (Figure 3(A) ). If the architecture of our library were substantially mismatched to the germline sequences required for RBD binding, our ACE2IS-binding antibodies would be rare clones containing unusual sequences that are not expected from our library design. However, the sequences of the ACE2IS-binding clones match our library design (Supplementary Figure 3 and Supplementary Table 1 ), suggesting that we should find many clones if the ACE2IS were highly immunogenic. Taken together, although our library does not fully recapitulate human antibody repertories, it covers a large fraction of the antibody sequence space capable of producing anti-RBD antibodies.Why is the RBD difficult to target when whole spike trimer is used as the antigen? Our data suggest that the spike protein has highly immunogenic surfaces outside the RBD, which enrich antibodies that target these epitopes and deplete antibodies to the RBD. The structure and conformational dynamics of the spike protein offer possible mechanistic basis for the low immunogenicity of the RBD. The RBD in the up conformation is largely exposed on the spike surfaces, whereas the RBD in the down conformation is buried in the spike protein (Figures 1(A) and 4(A) ). Structural studies of the spike protein revealed that zero, one or two RBDs but not all three RBDs in the spike trimer form the up conformation at a given time. 1, 2, 25, 26 Consequently, the RBD is largely in the down conformation and most of the RBD is less exposed than the rest of the spike surfaces (Figure 4(A) ). Furthermore, it has been reported that the RBD in the up conformation shows higher mobility than that in the down conformation. 25 Thus, both a lack of the complete exposure of the RBD and conformational mobility of the RBD probably contribute to the challenges in recognizing the RBD by antibodies when the spike protein is used as the antigen.Our data indicate that the ACE2IS is minimally immunogenic within the RBD, although the ACE2IS is expected to be a highly immunogenic surface as discussed above, and is highly accessible when the RBD is in the up conformation. One possible explanation for the minimal immunogenicity of the ACE2IS is its conformational flexibility. Although the ACE2IS is well defined when bound to ACE2 or to an antibody, it is disordered in the free spike structures (Figure 4(B) ), 1, 2, 4, [27] [28] [29] [30] suggesting that the ACE2IS is inherently flexible. It is difficult to generate antibodies to a flexible region, due to a large loss of conformational entropy upon binding that disfavors binding. Taken together, we propose that limited surface exposure and flexibility of the ACE2IS reduces its immunogenicity in the spike protein.Our studies have important implications for vaccine design. Most of vaccine candidates utilize the spike protein or the RBD as antigens (https:// www.who.int/publications/m/item/draft-landscapeof-covid-19-candidate-vaccines). In our studies, 89% of antibodies from the unbiased selection for the spike protein recognize regions outside the RBD, and 83% of antibodies from the unbiased selection for the RBD recognize the surfaces on the RBD that are inaccessible in the context of the spike protein. These data imply that potent neutralizing antibodies targeting the ACE2IS may not be induced efficiently by only immunizing with the spike protein or only with the RBD. Consistent with this view, it has been reported that the majority of spike-binding antibodies that were generated in a patient during the first weeks of COVID-19 infection were not neutralizing and bind outside the RBD. 31 Similarly, Juno et al. observed a high frequency of B cells that target the spike protein outside the RBD in recovered patients with COVID-19. 18 Our data demonstrate that the ACE2IS can be readily targeted by antibodies in the biased selection. Although such control of the human immune responses using designed antigens is impossible in the course of natural infection, we envision that a two-step vaccination scheme using the RBD followed by the spike protein could improve the efficiency of eliciting antibodies targeting the ACE2IS that confer strong viral neutralization.The amino acid sequence of the ectodomain of the spike protein (resides 16-1213) was collected from GenBank entry MN908947.3. A codonoptimized gene encoding the spike protein with modifications reported by Amanat et al., 32 including stabilized mutations (K986P and V987P), the removal of the furin site (RRAR to A) and the addition of a T4 foldon trimerization domain, a hexahistidine tag and an Avitag at the C-terminus was synthesized (Integrated DNA Technologies) and cloned into the mammalian expression vector pBCAG. The codon-optimized genes encoding the receptor binding domain (RBD) of SARS-CoV-2 (residues 328-531; GenBank entry: MN908947.3) and a triple mutant (N487K/Q493K/N501K) of the RBD of SARS-CoV-2 with the hexahistidine tag and the Avitag at the C-terminus were synthesized (Integrated DNA Technologies) and cloned into the pBCAG vector.The A549 cells stably expressing the angiotensinconverting enzyme 2 (ACE2) on the cell surface were maintained in Dulbecco's Modified Eagle's Medium (DMEM, Thermo Fisher) supplemented with 2 lg/ml puromycin (InvivoGen), 10% fetal bovine serum (FBS, Gemini Bio) and penicillin/ streptomycin (Thermo Fisher) at 37°C with 5% CO 2 . The HEK293T cells stably expressing ACE2 on the cell surface were generated previously, 17, 33 and maintained in in DMEM (Thermo Fisher) supplemented with 1 lg/ml puromycin (InvivoGen), 10% FBS (Gemini Bio) and penicillin/streptomycin (Thermo Fisher) at 37°C with 5% CO 2 . The Vero E6 kidney epithelial cells were maintained in DMEM (Corning), 10% FBS (Atlanta biologicals) and 1% Nonessential Amino Acids (NEAA, Corning) at 37°C with 5% CO 2 . The Expi293F cells (Thermo Fisher) were maintained in Expi293 Expression Medium (Thermo Fisher) at 37°C with 8% CO 2.icSARS-CoV-2-mNG (isolate USA/WA/1/2020, obtained from the UTMB World Reference Center for Emerging Viruses and Arboviruses) 34 was amplified once in Vero E6 cells (P1 from the original stock). Briefly, 90-95% confluent T175 flask (Thomas Scientific) of Vero E6 (1x10 7 cells) was infected with 50 lL of icSARS-CoV-2-mNG in 5 mL of infection media (DMEM, 2% FBS, 1% NEAA, and 10 mM HEPES) for 1 h. After 1 h, 20 mL of infection media was added to the inoculum and cells were incubated 72 h at 37°C and 5% CO 2 . After 72 h, the supernatant was collected and the monolayer was frozen and thawed once. Both supernatant and cellular fractions were combined, centrifuged for 5 min at 1200 rpm, and filtered using a 0.22 lm Steriflip (Millipore). Viral titers were determined by plaque assay in Vero E6 cells. In brief, 220,000 Vero E6 cells/well were seeded in a 24 well plate, 24 h before infection. Ten-fold dilutions of the virus in DMEM (Corning) were added to the Vero E6 monolayers for 1 h at 37°C. Following incubation, cells were overlaid with 0.8% agarose in DMEM containing 2% FBS (Atlanta biologicals) and incubated at 37°C for 72 h. The cells were fixed with 10% formalin, the agarose plug removed, and plaques visualized by crystal violet staining. All procedures including icSARS-CoV-2-mNG virus were performed using biosafety level 3 conditions.Serum samples were collected from 94 Healthcare workers from NYU Langone Health who showed PCR-positive for COVID-19, as reported previously. 17 All patients gave written consent for this study and all samples were deidentified by following IRB #i20-00595.The expi293F cells (Thermo Fisher) were transiently transfected with the vectors using the ExpiFectamine 293 Transfection kit (Thermo Fisher) according to the manufacturer's protocol. The cells were incubated at 37°C with 8% CO 2 for 7 days. The cell culture supernatants were collected by centrifuge, and supplemented with a protease inhibitor cocktail (Roche) and 1 mM PMSF. The recombinant proteins were purified from the filtrated supernatants using a HisTrap excel column (GE Healthcare). The purified proteins were biotinylated in vitro using the BirA enzyme in the presence of 0.5 mM Biotin and 10 mM ATP. The biotinylated proteins were further purified using the HisTrap excel column, and dialyzed into PBS. Purity of proteins were confirmed by SDS-PAGE analysis. The size exclusion chromatography using a Superdex 200 10/300 (GE Healthcare) for the spike protein and a Superdex 75 10/300 (GE Healthcare) for the RBD and the RBD triple mutant showed a monodispersed and single peak with the expected molecular mass (Supplementary Figure 1) . Synthetic human antibodies in the biotinylated format were expressed and purified as described previously. 22 Establishment of ACE2-expressing A549 cells A549 cells were transfected with pLenti.ACE2 lentiviral vector that encodes ACE2 and puromycin resistance. 33 After two days, the cells were selected in medium containing 2 lg/ml puromycin and cloned at limiting dilution. Individual cell clones were screened by flow cytometry for high ACE2 expression and a single cell clone was expanded.Cell-based binding assay Antibody binding was characterized using a beadbased binding assay, generally following our previous publications. 35, 36 Biotinylated RBD was conjugated to Dynabeads MÀ280 streptavidin (Thermo Fisher Scientific) as follows. Ten microliters of the stock bead suspension were mixed with 90 lL of PBSB (PBS containing 0.1% (w/v) BSA (GeminiBio). The supernatant was removed using a magnetic stand and the beads were resuspended in 100 lL of PBSB. The beads were mixed with the equal volume of PBSB containing 15 nM of biotinylated RBD or biotinylated RBD-T and incubated at room temperature for 30 min. Biotin at a final concentration of 2.5 lM was then added to the solution and incubated for 5 min. The beads were washed once using a magnetic stand and resuspended at 0.5 mg/ml. Five microliters of the beads were aliquoted in each well of a 96-well filter plate (Millipore), the liquid was removed using a vacuum chamber and the wells were washed once with 150 lL of PBST containing 1% (w/v) skim milk. Serum samples were heat-treated at 56°C for 1 h and diluted 158fold in PBST containing 1% (w/v) skim milk, and 25 lL each was added to the plate. For competition reactions, biotinylated RBD-T and streptavidin were mixed in such a way that all the biotin binding sites of streptavidin (tetramer) were occupied with RBD-T, and the complex was added to the serum solutions at a final concentration of 1 lM (calculated as monomer). After incubation for 30 min at room temperature with mixing on a shaker, the wells were washed twice with 150 lL of PBST-BSA (PBS containing 0.5% (w/v) BSA and 0.05% (v/v) Tween 20). The staining with a secondary antibody (anti-human IgG (FC gamma specific)-Alexa488, Jackson Immunoresearch), diluted 1/800 in PBS containing 1 % BSA, was performed in a total volume of 25 lL for 30 min at room temperature with shaking. The wells were washed again with PBST-BSA and the beads resuspended in 90 lL with PBST-BSA and analyzed on an iQue screener (Sartorius). Signals reported are the median fluorescence intensities.Sorting of a synthetic antibody library was performed as described previously. 22 Briefly, a synthetic human antibody library was sorted against the antigens listed in the Figure 3(A) . at the concentrations of 100 nM (1st round), 100 nM (2nd round), 50 nM (3rd round) and 20 nM (4th round). In the biased selection using RBD-T as the antigen for negative selection, biotinylated RBD-T was immobilized on the Streptavidin MagneSphere particles (Promega) and added to the solution containing phage. Phage bound to the RBD-T-beads were removed prior to the selection against the antigens.Phage ELISA was performed as described previously except that the 384-well plate was used instead of the 96-well plate. 22 Briefly, the wells of the 384-well ELISA plate (Nunc) were coated with neutravidin (Thermo Fisher) for 1 h at room temperature. The wells were washed with PBS-T (PBS containing 0.1% Tween 20) and blocked with PBS containing 0.5% (w/v) BSA (Gemini Bio) for 1 h. After removing the blocking buffer, biotinylated antigens were added to each well and washed three times with PBS-T. The 5-fold dilution of the cell culture supernatants containing phage were added to the wells and incubated for 30 min. After washing the wells with PBS-T three times, anti-M13HRP (Sino Biological) was added to the wells. SIGMAFAST TM OPD (Sigma) was used as a substrate and 2 M HCl was used as a quenching solution. The absorbance at 490 nm was measured using a BioTek Epoch 2 plate reader (BioTek).Binding titration of the Fab clones were performed by a bead binding assay, as described previously. 35, 37 Briefly, biotinylated antigens were immobilized on Dynabeads MÀ280 streptavidin (Thermo), and then excess biotin binding sites of streptavidin were blocked with biotin. The biotinylated Fab clones were titrated into the solution containing the antigen-coated beads in the presence of 5 lM biotin, and incubated for 30 min at room temperature. After washing step, the beads were incubated with anti-human F(ab') 2 -Alexa Fluor 488 (Jackson ImmunoResearch). The beads were further washed three times and analyzed on an iQue screener (Satorius). Signals reported are the median fluorescence intensities.Vero E6 cells (30,000 cells/well) were seeded in a 96 well plate 24 h before infection. Biotinylated Fab clones were mixed with streptavidin produced in house, and diluted in DMEM (Corning), 2% FBS (Atlanta biological), 1% NEAA (Corning) and 10 mM HEPES (Gibco). Fifty nanomolar of the Fab-streptavidin complexes were mixed 1:1 (vol/ vol) with SARS-CoV-2 virus (5.5 Â 10 5 PFU/ml, MOI 0.5), and incubated for 1 h at 37°C. During the incubation period, Vero E6 monolayers were washed once with DMEM (Corning) to remove any serum present in the media that could interfere with the assay. After incubation, 100 lL of the mixtures of the antibody and SARS-CoV-2 were added to the Vero E6 monolayers, and cells were incubated at 37°C. After 20 h, cells were fixed with 4 % formaldehyde (Electron Microscopy Sciences) at room temperature for 1 h. After fixation cells were washed twice with PBS and permeabilized with 0.25% triton-100, stained with DAPI (Thermo), and quantified on a CellInsight CX7 High-content microscope (Thermo) using a cut-off for three standard deviations from negative to be scored as an infected cell. ",USA,first author,2021-02-05,02
5a74021a3dbce95ea49dddeb201ef3ae3aeb079c,"Haoran Chu (Conceptualization) (Methodology) (Formal analysis) (Resources) (Data curation) (Writing -original draft) (Writing - review and editing) (Visualization), Sixiao Liu (Conceptualization) (Methodology) (Validation) (Formal analysis) (Writing -original draft) (Writing -review and editing)","The coronavirus disease-2019 (COVID-19) pandemic has caused catastrophic damages worldwide [1] . As of early 2021, more than 80 million cases of infections and 2 million deaths have been reported worldwide [1] . However, as effective treatment of the disease remains unavailable, societies are relying on preventive measures to curb the pandemic [2, 3] . One of the J o u r n a l P r e -p r o o f most effective preventive measures to contain the spread of infectious diseases is vaccine [4] .protect those unable to get vaccines through ""herd immunity"" [5] . However, despite its effectiveness in preventing infectious diseases, vaccine hesitancy is on the rise globally, leading to the re-emergence of VPDs such as measles [6, 7] . Though public health institutions worldwide have been disseminating vaccines to control the pandemic, polls show that many were reluctant to get vaccinated [8] . To develop effective interventions that promote acceptance of COVID-19 vaccines, it is critical to identify factors that influence people's intention to get vaccinated.Decades of research in health psychology have generated multiple health behavior theories (HBT) that identify sociopsychological factors influencing individual's health behavior [9] .Studies on vaccines uptake ranging from childhood vaccines [10] to HPV vaccines [11] also benefited tremendously from HBTs, such as in predicting parents' intention to vaccinate their children for VPDs [10] and individuals' intention to vaccinate themselves against HPV infection [11] . Notably, most HBTs focus on several similar sets of factors that predict the initiation and maintenance of health behaviors [9, 12] . Correspondingly, researchers have rallied for the comparative examination, refinement, and integrations of different HBTs [9, 11, 12] . In the meantime, the novel challenges brought about by the COVID-19 pandemic also necessitate a comprehensive investigation of factors that predict people's intention to get the COVID-19vaccines. On the one hand, it aids the strategic design of vaccine promotion campaigns addressing factors that reduce voluntary vaccination. On the other, knowing who are more likely to receive a vaccine helps authorities plan the distribution of COVID-19 vaccines.To address such goals, this study examines five sets of HBT constructs and seeks to identify their influences on people's intention to receive a COVID-19 vaccine. Based on three prominent HBTs including the health belief model (HBM) [13] , the theory of planned behavior (TPB) [14] , and extended parallel process model (EPPM) [15] , we focus on factors including risk perception and fear associated with COVID-19, attitudes and beliefs related to COVID-19 vaccines, selfefficacy, social and psychological contexts, and demographics ( Figure 1) . Notably, as COVID-19 vaccines were not widely available in the United States when this study was conducted, we focus on the intention to get COVID-19 vaccines due to its strong association with the actual uptake behavior [11, 14] .Vaccination, like many health behaviors, is adopted to prevent negative health consequences such as suffering from VPDs [16] . It is thus arguable that the extent to which people believe a VPD is severe and likely to affect them should predict their intention to get vaccinated [12] . HBM and EPPM measures people's perception of health risks with similar constructs, including perceived severity of and perceived susceptibility to health threats [9] .In addition to risk perception, HBTs also suggest that affective response to health risks motivate actions to overcome their adverse effects [15, 17] . Fear as a negative emotion was particularly relevant to behavioral change [18] . For instance, research shows that increased fear from reading a narrative message motivated female research participants to receive an HPV vaccine [18] . It is worth noting that too much fear could also prevent action as people may just disregard the threats to avoid feeling overwhelmed [15] . In the context of COVID-19 vaccination, the large number of infections and casualties may have led to heightened risk perception and strong fear [19] . However, the prolonged pandemic and the lower mortality rates among younger J o u r n a l P r e -p r o o f populations may also lead to fatigue of practicing preventive measures and overoptimism of one's susceptibility to the disease. As a consequence, some may hesitate to get a COVID-19 vaccine due to lower risk perception and fear.In addition to risk perception and fear, HBTs argue that attitudes toward and beliefs about the health behaviors also shape people's intention to adopt them [9, 11] . They are often operationalized as perceived benefits and barriers in HBM, response efficacy in EPPM, and positive or negative behavioral beliefs in TPB [9] . These factors can be categorized into two subgroups, respectively capturing the benefits and barriers associated with the health behaviors. In vaccine research, perceived benefits of vaccines (e.g., reduced disease threat) were found to be strong predictors of vaccination intention, while perceived cost or barriers (e.g., monetary cost, effort exertion) of getting vaccinated were negatively associated with uptake intent (e.g., influenza vaccine [20] , HPV vaccines [21] , Zika Vaccine [22] ).In the context of COVID-19 vaccines, we focus on five interrelated attitudes and beliefs associated with the vaccines, including perceived benefits of getting COVID-19 vaccines for self and communities, perceived barriers of getting COVID-19 vaccines, and attitudes toward to getting COVID-19 vaccines. Notably, perceived benefits and barriers are conceptually similar to positive and negative behavioral beliefs specified in TPB [12] . Such beliefs, according to TPB, shape people's attitudes toward the behavior, which subsequently influence behavioral intent [9] .Knowing that health behaviors such as getting vaccinated prevent negative consequences may not be enough to motivate behavioral adoption [9, 12] . HBTs argue that feeling capable of J o u r n a l P r e -p r o o f executing such behaviors are also key to behavioral change [23, 24] . Such perceived capability is conceptualized as perceived behavioral control in TPB and self-efficacy in EPPM [9] . Recent TPB studies often operationalize perceived behavioral control as self-efficacy due to their similarities [9, 25] . Research also shows that self-efficacy is positively related to vaccines uptake [26, 27] .We extract three sets of contextual factors from HBTs and vaccine research, including subjective norms (TPB [28] ), cues to action (HBM [11] ), and baseline vaccine hesitancy [6] .Subjective norms include injunctive norms, which are approvals of health behaviors by people important to the health decision-maker, and descriptive norms, which denote important others' behaviors [29] . TPB research shows that both perceived descriptive and injunctive norms are positively related to vaccines uptake [30, 31] .Cues to action specifies motives and hints of actions embedded in one's surrounding environment such as doctor's recommendations [11] . Research also shows that disease exposure or knowledge of VPDs are positive predictors of vaccines uptake [27] . In the COVID-19 context, it is possible that exposure to COVID-19 cases such having family or friends tested positive for COVID-19 may function as a behavioral cue [6] . Further, serving as an essential worker during the COVID-19 lockdowns may also be a cue to action. On the one hand, essential workers may be more susceptible to the disease due to the risk of exposure, while on the other, public health officials have called for earlier vaccination for this group [2, 3] .The last set of contextual factors include baseline vaccine hesitancy, which describes the attitudes and behaviors surrounding people's decision to delay and refuse vaccination [6] . Vaccine hesitancy is often operationalized as attitudes toward vaccines or past vaccination behavior [6, 7] .Research shows that positive attitudes toward vaccines in general are positively associated with people's intent to get specific vaccines [6, 32] , and individuals who have received vaccines recently are more likely to get other vaccines [33] .In addition to their direct effects, risk perception, fear, self-efficacy, and beliefs about COVID-19 vaccines may also mediate contextual factors' influence on vaccination intention. First, social cognitive theory suggests that people learn not only by directly interacting with the environment, but also by vicariously observing other's actions [34] . Therefore, socially important others' beliefs and behaviors may influence people's evaluation of the vaccine and their confidence in getting vaccinated [11, 35] . In terms of COVID-19 vaccines, it is likely that subjective norms may influence self-efficacy, which would subsequently influence uptake intent. Second, people's perception of the vaccines may also be influenced by their existing attitudes toward other vaccines [6, 7] . Thus, attitudes toward COVID-19 vaccines may mediate baseline vaccine-hesitancy's influences on intention to receive a COVID-19 vaccine. Third, as exposure to COVID-19 cases and serving as essential workers may lead to higher contraction risk and elevated risk perception, severity and susceptibility perception may also mediate its impacts on uptake intent. Lastly, recent vaccination history may boost self-efficacy which would lead to increased uptake intent, as successful past experiences are often positively related to self-efficacy [34] .Lastly, demographic factors are also associated with vaccines uptake intent. Due to historical and cultural reasons, minorities in the United States are often reluctant to receive novel medical treatment [36, 37] . Gender difference in vaccination behavior was also observed in some studies, but the patterns of such difference vary across contexts [38] . Older adults and individuals with higher education and income often show higher vaccination intention [39] [40] [41] .J o u r n a l P r e -p r o o fTo address the challenges of the COVID-19 pandemic and aid the strategic promotion and distribution of COVID-19 vaccines, we utilize three HBTs to identify sociopsychological factors that influence American's intention to receive a COVID-19 vaccine. Based on HBM and EPPM, we hypothesize that perceived susceptibility to and severity of COVID-19 and fear will be positively associated with people's intention to get a COVID-19 vaccine (H1). According to TPB and EPPM, we hypothesize that self-efficacy is positively related to vaccination intention (H2).Synthesizing HBM, EPPM, and TPB, we ask three research questions. First, are perceived benefits and barriers of COVID-19 vaccination associated with uptake intent directly or indirectly via the mediation of attitudes toward COVID-19 vaccines (RQ1)? Second, are contextual factors (i.e., subjective norms, cues to action, and vaccine hesitancy) directly and indirectly associated with people's intention to receive a COVID-19 vaccine (RQ2)? Lastly, how are demographic characteristics associated with vaccination intention (RQ3)?Upon IRB approval at the lead author's institution, data collection was completed during early September 2020. A sample of participants with demographics similar to the United States population was recruited on Prolific.co. 1,043 Individuals opened the survey, and 1,027 continued with informed consent. Among them, 1001 participants completed the survey and were rewarded 2.00 U.S. dollars. Response from 54 participants who failed one or two attention check questions were removed. Responses from 13 participants who indicated that they were tested positive for COVID-19 and/or COVID-19 antibody were dropped, resulting in a final sample of 934 participants.J o u r n a l P r e -p r o o fHBT and vaccine research constructs including perceived severity of and susceptibility to COVID-19, fear of COVID-19 [18, 27] , perceived individual benefits of COVID-19 vaccines [11, 42] , perceived community benefits of COVID-19 vaccines, perceived barriers to getting COVID-19 vaccines including safety concerns and cost concerns [21] , subjective norms, baseline vaccine hesitancy including attitudes toward vaccines in general and recent vaccination history, cues to actions, and demographics were measured in the survey. Measurement items, reliability indices, means, and standard deviations of the measurement instruments are presented in Table 1 . Scales were adopted from existing research if available.Q-Q plot was generated in R to assess multivariate normality of the measurement items [43] . Upon inspection, the data failed to achieve multivariate normality. To account for nonnormality, all measurement and path models were analyzed with maximum likelihood estimation with robust standard errors [44] . Indirect effect models were estimated with maximum likelihood estimation with bootstrapped sub-samples (N = 5,000).We first inspected the measurement model [45] . The model has achieved satisfactory fit Path coefficient estimates are reported in Figure 2 and Table 2 The average age of participants was 46.01 years (SD = 16.17). The majority of participants identified as female (n = 468, 50.1%), followed by male (n = 455, 48.7%) and other gender (n = 11, 1.2%). Approximately three quarters of participants identified as non-Hispanic White or Caucasian (n = 698, 74.7%), followed by Black or African American (n = 114, 12.2%), Hispanic or Latino (n = 34, 3.6%), Asian, Pacific Islander or Native American (n = 68, 7.3%), and other racial groups (n = 20, 2.1%). The median education level was 4-year college degree, and the median household income was between US$ 50,000 and 74,999. RQ3 asks about demographic factors' association with COVID-19 vaccines uptake intent. No significant effect of the demographic variables was identified after controlling for the HBT constructs.In general, participants perceived COVID-19 as a severe health risk. However, mean perceived susceptibility was significantly lower than perceived severity (paired-sample t(933) = 28.70, p < .001). The average rating for fear was below the scale mid-point, suggesting that participants were not very fearful of the disease. H1 was partially supported as only fear was positively associated with intention to receive a COVID-19 vaccine. However, perceived J o u r n a l P r e -p r o o f susceptibility's association with vaccination intention was approaching statistical significance (B = 0.114, SE = 0.062, p = 0.064).Participants showed positive attitudes toward COVID-19 vaccines. They also perceived COVID-19 vaccines as beneficial to both themselves and their communities. Participants reported that concerns about vaccine safety were more likely to prevent vaccination than concerns about cost (paired-sample t(933) = 28.36, p < .001). In response to RQ1, we found that perceived community benefits of and positive attitudes toward COVID-19 vaccines were positively associated with intention to get the vaccines. However, stronger safety concerns were related to lower vaccination intention. In addition to their direct effects, beliefs about COVID-19 vaccines' benefits and barriers also indirectly influenced intention to receive a COVID-19 vaccine (RQ1b).Attitudes toward COVID-19 vaccines mediated perceived community benefits and safety concerns' association with uptake intent, but the former was positive while the latter was negative.Interestingly, attitudes toward COVID-19 vaccines also mediated cost concerns' positive relationship with vaccines uptake.Our respondents generally believed that they will be able to get COVID-19 vaccines to prevent contracting COVID-19. Different from existing research findings, no significant relationship was identified between self-efficacy and intention to get vaccinated for COVID-19, rejecting H2.J o u r n a l P r e -p r o o f More than half of our sample had some experiences with COVID-19. Particularly, more than one third of participants knew someone who was tested positive for COVID-19 and more than 20% of participants reported having family or close friends tested positive for COVID-19. Further, more than one hundred respondents indicated that someone they knew died due to COVID-19, again showing the dire situation of the pandemic. About 20% of our respondents indicated that they worked as an essential worker during COVID-19 lockdowns. As for subjective norms, participants in general believed people similar to them or important to them would get a COVID-19 vaccine (i.e., descriptive norms) and would want them to get vaccinated against COVID-19 (i.e., injunctive norms). In terms of baseline vaccine hesitancy, our participants largely thought of vaccines positively and more than half of them reported that they had received at least one vaccine in the past 18 months prior to completing the survey.In response to RQ2, we found that having positive baseline attitudes toward vaccines in general and received some vaccines recently were positive predictors of intention to receive a COVID-19 vaccine. Further, descriptive norms were also positively associated with vaccination intentions. Though exposure to COVID-19 cases was not directly linked to uptake intent, fear mediated its positive relationship with vaccination intention. Additionally, the relationship between attitudes to vaccines in general and intention to receive a COVID-19 vaccine was mediated by perceived benefits and attitudes toward COVID-19 vaccines specifically.The current study integrates factors from three prominent HBTs including EPPM, HBM, and TPB to investigate sociopsychological factors associated with American's intentions to get COVID-19 vaccines. In general, participants indicated that they were likely to get vaccinated for COVID-19 once the vaccines are available. This finding is encouraging as massive vaccination is J o u r n a l P r e -p r o o f key to controlling the spread of COVID-19 [3] . However, approximately 20% of participants reported some extent of unwillingness to get the vaccines (average uptake intent score below the scale mid-point). Considering that herd immunity against VPDs sometimes require an immunization rate of 70% to 90% and the immunity against COVID-19 developed by vaccination may not last as long as immunity for other diseases [2] , efforts are needed to design and implement interventions that effectively promote vaccination, especially among populations reluctant to get the vaccines.Participants in general perceived COVID-19 as a severe health risk. However, they tend not to feel very vulnerable to and afraid of the disease. Such findings show that people were generally optimistic about their own risks of suffering from COVID-19, which is consistent with the optimistic bias observed in earlier research [3, 19] .There are two possible explanations for the finding that fear was positively associated with intention to receive a vaccine. First, fear as emotional response may arise from cognitive appraisals of COVID-19 and served as a more immediate predictor of vaccination intention than susceptibility perception [47] . Second, we may fail to capture any effect of severity perception due to its limited variance (i.e., ceiling effect). In summary, the general public may have recognized the severity of COVID-19, but the underestimation of their risks of contracting and suffering from the disease may prevent them from getting vaccinated. Campaigns to promote COVID-19 vaccines should consider highlighting personal risks to the disease and using fear appeal messages when communicating to populations that are less susceptible to COVID-19 (e.g., younger population).Our findings indicate that Americans held a generally positive view toward COVID-19 vaccines. They considered the vaccines as beneficial to both themselves and their communities.However, the accelerated development of the vaccines, especially in comparison to earlier vaccines, may have led to heightened safety concerns [3] . Cost concerns, on the other hand, was not a serious barrier to people's vaccination intentions.More importantly, we found that perceived community benefit of COVID-19 vaccines was positively associated with vaccination intention both directly and indirectly through the mediation of attitudes toward the COVID-19 vaccines. Differently, concerns about the safety of COVID-19 vaccines were negatively associated with uptake intent, directly and indirectly through the mediation of attitudes toward the COVID-19 vaccines. Therefore, public health campaigns aiming at increasing the vaccination rate should address the community benefits of COVID-19 vaccines, while also maintain high level of transparency regarding the vaccines' safety and effectiveness.Notably, we also found that cost concerns were positively associated with intention to get vaccinated for COVID-19, and the relationship was mediated by attitudes toward the COVID-19vaccines. Such pattern is consistent with earlier finding where practical concerns were positively linked to behavioral intention [21] . Therefore, providing the vaccines at a reasonable cost or for free may help increase vaccination rates, especially among people who intend to get vaccinated.We found that participants were confident in their ability to get the COVID-19 vaccines.However, self-efficacy was not significantly associated with vaccination intention. The absence of a significant relationship may be attributable to the fact that vaccines were still not available. As the transtheoretical model (TTM) of behavioral change suggests, difference in self-efficacy tend to develop at later stages of people's health decision-making [48] . Limited variance in self-efficacy J o u r n a l P r e -p r o o f may thus prevent us from identifying its relationship with vaccination intention. Notably, injunctive and descriptive norms were differently associated with self-efficacy. Believing that important others will get the vaccines (i.e., descriptive norms) was positively related to selfefficacy, whereas the relationships was negative between beliefs that important others would want oneself to get vaccinated (i.e., injunctive norms) and self-efficacy. Such difference may emerge as people learn from others' behaviors [34] , but too much preaching may also lead to psychological reactance.Our findings confirm the widespread of COVID-19 cases and mortalities reported elsewhere [1, 19] . First-hand experience with the disease was related to heightened fear and increased intention to get vaccinated. Such finding may indicate that exposure to COVID-19 countered the negative influences of overoptimism on vaccination intention. Therefore, campaigns encouraging vaccination against COVID-19 may stress the personal relevance of COVID-19 as a means to overcome overoptimism and stipulate vaccination intention. It is also encouraging to see that most participants held positive views toward vaccines and considered getting COVID-19 vaccines a socially sanctioned behavior. Baseline attitudes toward vaccines and the vaccinefriendly norms were also conducive to vaccination intention. Therefore, promotion of COVID-19 vaccines should be considered as an integral part of the long-term efforts to reduce vaccine hesitancy [6] . It is necessary to not only foster acceptance of the COVID-19 vaccines, but also cultivate an enduring trust in vaccines and other health measures.This study also has some limitations. First, the online sample may limit the generalizability of our findings. Future research should consider recruiting a more diverse sample and re-examine the relationships reported here. Second, as the COVID-19 vaccines were yet to be widely available when this study was conducted, actual vaccines uptake was not measured. Though behavioral intention and actual behaviors tend to correlate highly [14] , we recommend future research to test the current framework at later stage of the pandemic or with other vaccines and health behaviors.Integrating findings from prominent HBTs, this study offers a timely overview of sociopsychological factors that are related to American's intention to get vaccinated for COVID- 19 . We found that despite recognizing the severity of the disease, people felt less susceptible to and afraid of its negative consequences. Such overoptimism may prevent wide acceptance of COVID-19 vaccines. Further, safety concerns are negatively associated with vaccination intention.Lastly, public acceptance of COVID-19 vaccines was largely influenced by their perceptions of vaccines in general, which confirms the importance of sustained efforts in cultivating vaccine acceptance.Findings from the current study has several implications for health campaigns and Note. a Dummy-coded variable (1 = knowing someone who was tested positive for or died due to COVID-19, 0 = not having such experience); b dummy-coded variable (1 = served as an essential worker during COVID-19 lockdowns; 0 = did not serve as an essential worker during COVID-19 lockdowns); c dummy-coded variable (1 = received vaccines in the past 18 months, 0 = did not receive vaccine in the past 18 months or not sure); d dummy-coded variable with male as reference group; e dummy-coded variable with non-Hispanic White or Caucasian as reference group; * p < .05; ** p < .01; *** p < .001. J o u r n a l P r e -p r o o f Table 2 Unstandardized coefficients estimate for paths predicting perceived susceptibility to, perceived severity and fear of COVID-19Perceived susceptibility Note. * p < .05; ** p < .01; *** p < .001; significant path estimates are in boldface; outcome variables are specified in the first row J o u r n a l P r e -p r o o f Table 4 Unstandardized coefficient estimates for paths predicting intention to receive a COVID-19 vaccine B (SE) Note. 1 dummy-coded variable with male as reference group; 2 dummy-coded variable with non-Hispanic White or Caucasian as reference group; * p < .05; ** p < .01; *** p < .001; ; significant path estimates are in boldface J o u r n a l P r e -p r o o f ",USA,first author,2021-02-17,02
e97aba2d384625bd65271d16b66fb3a00601dc7a,Ethics of emerging infectious disease outbreak responses: Using Ebola virus disease as a case study of limited resource allocation,"Emerging infectious disease (EID) threats are increasing due to a complex array of factors including changing land use and more frequent regional and global travel [1, 2] . Today, a cluster of cases can become thousands in a matter of weeks if an individual decides to travel, unaware of their infection status or in pursuit of medical attention. Strategies for bolstering preparedness for decision-making in an outbreak response should be devised within an ethical frame, or else resulting decisions could harm affected communities and exacerbate existing health disparities.Prior to 2020, the 2013-2016 Ebola Virus Disease (EVD) outbreak in West Africa was considered one of the most threatening emerging infectious disease epidemics of modern history. The outbreak resulted in 28,616 cases and 11,310 deaths, posing a serious global threat [3] [4] [5] . The public health and medical interventions implemented to try to combat the outbreak raised ethical dilemmas related to issues of justice, respect for persons, and beneficence. From military-imposed quarantines to informed consent processes, the EVD outbreak demonstrated many cases in which critical moral decisions were resolved under harsh field conditions and extreme time-constraints [3, [6] [7] [8] [9] . Currently, another EVD outbreak has occurred in Equateur Province of the Democratic Republic of Congo and COVID-19 caused by SARS-CoV-2 is widespread across the globe, highlighting the urgent need to more carefully examine and address the ethics of emerging infectious disease outbreak responses, particularly those surrounding decisions regarding allocation of limited resources.The qualitative study presented here works with a data set from extensive interviews of senior healthcare personnel (n = 16) from several organizations that were heavily involved in the 2013-2016 EVD outbreak response. The interviewed healthcare workers acted in a variety of capacities, both on the ground during the outbreak and at international headquarters, therefore the study encompasses a variety of perspectives. The results of this study inform a potential ethical framework based on interviewed responders' insights that can be adopted by healthcare workers in the face of emerging infectious disease outbreaks. Topics such as monitored use of experimental products, implementation of clinical trials, informed consent and community engagement are covered within the framework. EID outbreak preparedness response strategies are needed; however, the strategies must be carefully considered from an ethics standpoint, or else resulting decisions can harm affected communities, increase existing health disparities and exacerbate the outbreak by prolonging the duration and scale of it.The research objectives were to elucidate an understanding of allocation decisions in the context of a high-profile EID response in resource-constrained regions. A qualitative study design was selected to provide the broad and open inquiry necessary to derive meaningful conclusions [10] [11] [12] [13] . A semi-structured interview process was selected to ensure consistency in the interviews, while maintaining flexibility in hearing first-hand subjective experiences [14] .Inclusion criteria for the study were English-speaking individuals over 18 years of age with extensive work experience for any international humanitarian medical organization directly involved in the 2013-2016 EVD outbreak response. This study was conducted one year after the 2013-2016 EVD outbreak ended.Eligible prospective participants were recruited through direct, online email solicitation. Forty emails were sent and 25 affirmative voluntary responses were received. Given scheduling opportunities and time constraints on the part of the research team, 16 respondents were interviewed. Respondents were selected based on having made substantial contributions to the West Africa 2013-16 Ebola response, worked in a variety of roles and included personnel across three different international response organizations. The participant demographics included 6 males and 10 females aged 40-65. Eight participants were field doctors or nurses, deployed through their organizations to provide direct clinical care to affected communities, 7 participants occupied leadership roles in emergency medical coordination and technical advisement and 1 participant served on the legal team at the headquarters of their organization. The range of roles provided an opportunity to capture a variety of different experiences and perspectives. Participants with clinical field experience during the 2013-2016 EVD outbreak had worked in Guinea, Liberia and Sierra Leone. Length of field deployments ranged from 2-12 weeks, with all clinicians having participated in multiple deployments. Some participants also had robust leadership experience in decisions relating to use of experimental therapeutics in the outbreak.Throughout the study, IRB approved procedures were followed to protect the confidentiality of the research participants. All documents were approved by the IRB at Stanford University. This included the participation solicitation email, the informed consent form, the background information document (S1 File), the pre-interview questionnaire (S2 File), and the interview guide (S3 File) each participant received.All participants were given an informational document explaining the nature of the research (S1 File) and an opportunity to ask questions. After receiving the information, the consent form was obtained from all participants before interviews commenced and participants were requested to fill in the pre-interview questionnaire (S2 File). The interviews were conducted in-person in order to allow for clarity in interpreting non-verbal cues and ambiguous responses [15] . All interviews were conducted in private to ensure confidentiality and audio taped to enhance descriptive validity of the data. An interview guide (S3 File) was used to limit interviewer bias and seek standardization of question delivery across interviews [13] . The interviewer asked participants open-ended questions regarding limited resources in outbreak responses, allocation decisions, informed consent experiences, and moral obligations. A hypothetical scenario was included on how to allocate drug therapies if only a limited supply existed. Participants were asked to verbally walk the researcher through their decision-making processes. Interviews ranged between 1 to 1.5 hours in length. No remuneration was provided.The data were stored on Box to maintain file security and confidentiality. Interviews were transcribed verbatim. Transcripts (3135-9359 words) were cleaned to remove any identifiers and then indexed. An iterative process of coding based on grounded theory was used to ensure trustworthiness of the emergent categories [11] . Analytic memos were written after each step of the coding process in order to make additional insights and connections [11] .Open coding was employed in a first pass aimed at analyzing the textual content [11] , along with several external codes (e.g. beneficence, do no harm) derived from a seminal source on the principles of biomedical ethics [16] . The study codebook is provided in S1 Table. Axial coding was employed in a second pass to identify and cluster conceptual categories (S2 Table) . Examples of codes included in the category of values were 'do no harm,' 'fairness,' and 'solidarity.' These codes demonstrate the moral principles as articulated by the participants. Data saturation was reached when each category was explored in depth and no new insights resulted.The results of the study captured a range of insights in regard to ethical issues that can arise during an EID outbreak based on the personal accounts of the interviewed participants (see S1 Table for sample quotations). A large majority of respondents (81%) felt that the 2013-2016 West Africa EVD outbreak presented a particularly difficult response situation. Many (75%) also expressed feelings of frustration and hopelessness regarding the response efforts. Several participants identified that the course of EVD was particularly difficult for them to observe even as clinicians who have encountered many diseases, such as one clinician who described the experience as ""very brutal."" Roughly half (56%) mentioned how difficult they found it to work under extreme time-pressured conditions. The intensity of the outbreak is well described by one participant as ""more like a war than a normal outbreak.""Many of the decisions with a moral dimension specifically involved issues of limited resource allocation. The core element of an EVD outbreak response is to identify cases and quickly isolate them in order to prevent further person-to-person transmission, while providing medical care. Patient care was mostly provided in rapidly built Ebola Treatment Centers (ETCs). Limited number of beds led to difficult admission decisions. Lack of trained staff resulted in dilemmas in time-management for experienced staff regarding prioritizing time spent training personnel versus time spent directly managing patient care. To provide context, the requirements of wearing highly restrictive personal protective equipment (PPE) while caring for patients severely limited time spent in the ETC ward. For some PPE used in the treatment centers, only approximately 60 minutes can be spent in full PPE before having to exit to minimize risk of overheating and dehydration, straining the health care staff to define priorities in terms of which patients to care for and how comprehensive the care for each patient could be.Roughly two thirds of participants (63%) were able to recall specific instances where they felt unsure of whether they had made the 'right' or moral decision regarding time or resource allocation. In hindsight, most stood by their decisions made at the time, acknowledging the high-pressured, time-sensitive environment they were in and the lack of other feasible options. Instances of such value-laden decisions made for powerful accounts of lived experience within the midst of an EID outbreak, where competing priorities of advancing public health measures and caring for individual patients proved difficult to balance.One particularly difficult moral dilemma was whether to continue to admit EVD cases who had nowhere else to go, into an ETC already at capacity with regard to beds and number of patients that could be reasonably cared for. To quote one participant: ""We started to have ambulances and minibuses of eight to ten patients coming in, and we didn't have the space. I never considered that we would not admit those patients. . . but in hindsight I should have probably looked after my staff more before thinking of patients.""Another participant's account highlighted an example of a dilemma that arose from choosing between providing robust patient care and ensuring staff safety: ""I made sure everyone had a water bottle and some food. And then that was it. . . then I focused on the IPC [Infection Prevention and Control]. . . if I would not have done that, doctors would have not been able to come and give better care a day later."" This participant allocated her time to first provide the absolute basic needs of food and water to patients, and then spend the remainder of her day focused on implementing infection prevention and control measures. Her reasoning was to prioritize setting up a safe environment for healthcare workers so that the following day additional staff could come into the ETC to provide quality care for the patients. This choice between staff safety and providing individual patient care came up several times in participants' examples of moral dilemmas they faced on the ground during the 2013-2016 EVD outbreak in West Africa.Use of experimental therapies via compassionate use or clinical trials. The topic of how to allocate limited medical resources in a humanitarian response is not novel; however, a unique aspect of an emerging infectious disease outbreak such as EVD is the associated high case fatality rate in conjunction with development and testing of experimental therapeutics. Experimental therapeutic interventions can be provided via compassionate use and/or clinical trials. Often clinical trials take considerable time to establish, have exclusion criteria and utilize a placebo control arm. Compassionate use differs from clinical trials because it is implemented on a case-by-case basis for individuals after determining that the probable risk to the patient from the investigational therapeutic is not greater than the probable risk from the disease [17, 18] . A World Health Organization (WHO) Advisory Panel recommended monitored emergency use of unregistered and investigational interventions (MEURI) during the 2013-2016 EVD outbreak [19] . MEURI must be enacted in conjunction with necessary supportive treatment, creating a more significant monitoring standard [20] .All participants supported the utilization of MEURI when appropriate. Several participants specified that MEURI would be appropriate when establishment of clinical trials would be lengthy or were not possible to set up. One participant described MEURI as a ""gap filling measure"" that should be done in a way that the observational data could be in some way aggregated with trial data. Another participant felt that one monoclonal antibody cocktail being tested at the time in a clinical trial, was not used enough through MEURI to ensure access to vulnerable populations such as pregnant women who were not eligible to enroll in the trial: ""The ZMapp [a monoclonal antibody cocktail] was available for trial and for emergency use, and I feel we didn't use it enough as emergency use.""Roughly half of the participants (56%) supported prioritizing clinical trials over MEURI or other forms of compassionate use. Of those supporting clinical trials, 66% of respondents did so with the caveat of not supporting the implementation of a standard randomized control trial (RCT), where treated cases are compared with a control group without specific intervention. The participants cited the high case fatality rate associated with EVD when vocalizing this caveat. Participants felt that placing patients into a non-intervention control group in an RCT trial would be unethical, since patients would only receive supportive care which would result in very low chance of survival. One participant's comments captured this sentiment: ""I personally would disagree to randomize against placebo. I know that it lacks scientific evidence otherwise but in this case because of the high case fatality rate. . . it's not ethical."" Another participant compared the control group as an equivalent to a ""death sentence"" for patients.Other reasons against utilizing an RCT structure included impracticality of the trial design and the potential negative community perception of randomization to a control arm or an experimental arm within an RCT structure: ""No one disagrees that a randomized control trial is scientifically the best way to get data. But, I think that each situation is different in terms of what is practical to do."" Participants who voiced concern felt that the local communities had not been involved enough in shaping the outbreak response and that community engagement efforts should be prioritized when selecting a trial design to ensure it is culturally acceptable and well understood.Use of adaptive clinical trial designs. When asked about trial design, all participants (100%) advocated for the use of adaptive designs in trial structure. Concerns over the ethical justification of non-adaptive trial procedures were raised several times, and participants called for the procedures of any trial to be ""ethically sound from the beginning."" The design of the trials should be applicable to the nature of disease and for the population where trial recruitment will occur. None of the participants disagreed with the notion that an RCT is the gold standard for trial design, as exemplified in the participant response: ""So what I think we really need is a repertoire of different trial designs, recognizing that the RCT is the ideal design, and then coming down to other adaptive designs when necessary, and then tailoring our particular design to a particulate situation."" One participant explained that they felt trial protocols should be finalized with the community, and that the first beneficiary should be the community where the trials are established because that population is bearing the risks of participating in such trials to help advance scientific understanding: ""The design of the trials needs to be ethically acceptable for the disease and for the population. The whole system. If it is not working, you have to stop it immediately. If it is working, you have to finalize it with the community, and the first beneficiary will be this community where you are making the trials.""Ethical considerations of therapeutics access relative to vulnerable populations. Pregnant or lactating women or children are often excluded from phase I and phase II safety trials of potential new therapeutics or vaccines, frequently leading to decreased access to promising treatments. 25% of participants had concerns regarding the exclusion of pregnant women and children in clinical trials. The absence of evidence disadvantages pregnant women in that the lack of inclusion in trials then prevents pregnant women from accessing experimental therapeutics because of the lack of safety data for use in pregnant women: ""Excluding pregnant and all of that, it's always the same trick. The absence of evidence plays against these people in the end because then you're prevented from doing anything to them."" Such concerns about the cyclical argument that results in exclusion of pregnant women from accessing experimental therapeutics have also been raised by others [21] .One participant stated that it was not ethical to exclude children under the age of 6 on the basis of ""a purely theoretical supposition that the therapeutic might be dangerous for their health,"" justifying the use of a therapeutic by the fact that EVD is deadlier in children than in adults. Children under the age of 4, infected with Ebola virus, have a 80-90% case fatality rate [22] . Several participants stressed that MEURI would be appropriate when vulnerable populations are excluded from clinical trials due to not meeting the inclusion criteria (e.g. pregnant women and/or children).Prioritization of access to limited therapeutics based on role in outbreak. One constraint of both clinical trials or use of MEURI for experimental therapeutics is that they are often available in limited quantities. The challenge then becomes how to allocate the limited resource in an equitable manner. Only two participants suggested first-come first-serve as a fair scheme of allocation. Interestingly, many of the other participants disagreed with the notion of first-come first-serve and felt it would be ""unethical"" to use such a scheme that appeared to be lottery-like because it would prove impossible to justify to the affected communities.The majority of participants (75%) supported the prioritization of healthcare workers, particularly frontline workers directly involved in the response, in accessing experimental therapeutics either through clinical trial participation or via MEURI. Participants justified the response by citing the risks incurred by frontline workers by providing essential services and the utility of restoring health to those capable of saving other lives in the future. For example, one participant stated: ""Every Ebola survivor is not equal and the one that can go back onto the front lines has a utility above that of a construction worker in the setting of an outbreak."" As another example, a participant justified the prioritization in this manner: ""Those guys are risking their lives. They deserve to have special treatment. And also in an egocentric approach, you need healthcare workers in good health to save other lives. You have to privilege them."" To provide context, 8% of Liberia's healthcare workers died as a result of EVD during the 2013-2016 outbreak [23] .Within the group that supported this type of prioritization of frontline workers, 25% of the participants directly mentioned the principle of reciprocity, which captures how the risks undertaken by healthcare workers in providing a societal benefit should be reciprocal to the benefits that society can provide by prioritizing healthcare workers in this public health context. Also, many of those who viewed prioritization of healthcare workers as fair, also supported the view that national healthcare staff should receive the same prioritization in access to limited experimental therapeutics as the international medical responders. One participant cited the sense of solidarity between the healthcare staff as justifying this lack of difference between the healthcare workers: ""I have never experienced such a sense of solidarity. It's very special. When you've been together under this PPE and you've been confronted with people dying on a daily basis. . . You share the emotion. You share the risk.""Access to limited therapeutics based on who would benefit most. Another favored approach involved prioritizing allocation of experimental therapeutics to those that would potentially benefit most from the therapeutic, based on clinical prognosis (44%). High levels of virus detected in early blood samples taken from symptomatic EVD cases correlates with high case fatalities. For context, virus is quantitated by polymerase chain reaction (PCR) and measured in CT units from 1-40, which provide an inverse proxy for the amount of virus present. Participants advocated for not providing experimental therapeutics to cases with high viral loads, thereby ensuring therapeutic supply for those cases with lower viral loads that would be likely to benefit the most from treatment. For example, a participant described favoring this approach based on CT values: ""Clearly, there was literature on the CT, as a proxy for the viral load, and there's evidence that with a CT much lower than 18, the survival chances were very, very low. So I would base my decision on this kind of evidence-chance of survival-not to waste any product.""Prioritizing access to limited therapeutic based on social value. Roughly a third of the participants (31%) supported including social value criterion when they explained what they would consider when distributing a limited experimental therapeutic. Several participants used the example of prioritizing mothers since they occupy caregiver roles in their communities or prioritizing high-profile community leaders within communities. However, a minority of the participants (19%) strongly opposed favoring mothers as caregivers, citing that this kind of prioritization unfairly assigned more moral worth to a person with children. This minority felt it would be ""a slippery slope"" to argue that caregivers have more duties, or duties with greater moral worth assigned by society, than women without children. For example, one participant stated: ""What would you do for a person without kids? Do they have less duties or something? I think it's a slippery slope to put a worth on a person. . .""Many participants emphasized the need for community involvement in whatever allocation scheme was to be agreed upon. Several felt that community perception of the decisions made, contributed to or negatively impacted the success of the overall outbreak response. Rumors and misconceptions surrounding the international response posed significant challenges in ensuring affected individuals and families entered ETCs and understood their options and in safeguarding frontline workers involved. For example, one rumor recounted by participants was that international responders were spreading EVD when they were decontaminating areas such as infected individuals' homes or local hospitals: ""The problem is when you're not affected directly and the stakes are so high, it's very easy to trick people into believing stuff. It was amazing the rumors that were going around like we were spreading the disease when we were decontaminating.""Issues of transparency and additional safeguards towards vulnerable populations were also raised. Multiple participants felt that selection criteria for the allocation schema of experimental therapeutics should be ""extremely transparent"" and that local communities should be involved in the decision making process. One participant also addressed the potential ramifications of inaction to individuals and affected communities when weighing the risks and benefits of providing an experimental therapeutic through clinical trials or emergency use: ""You would have to have an appreciation for what's the risk and what's the cost to the person of inaction.""Several participants identified informed consent procedures for participating in clinical trials or receiving emergency use of experimental therapeutics as potential areas for improvement, to ensure that vulnerable patients are consented in a culturally appropriate manner. Two participants specifically brought up the issue of therapeutic misconception, where individuals do not understand the concept of a clinical research trial and inappropriately believe they will receive therapy. Another stated that in some communities, written consent is not appropriate, and verbal consent should instead be practiced.When asked about utilizing an ethical framework, there was a clear propensity to adopt an ethical framework of guiding principles (88%) for emerging infectious diseases like EVD. Several reasons to establish guiding principles for future EID outbreaks were commonly cited including the complex nature of the decision-making processes regarding clinical trial design which decrease the likelihood of rapid scientific advancement and the lack of standardization across international humanitarian responses.Two participants directly mentioned that an ethical framework would be comforting to the healthcare workers in the field, in serving as a source for guiding principles: ""It could help the person make the decision. And it would make people more comfortable with themselves in making a decision."" They strongly advocated for formation of principles to ease healthcare worker's personal moral burdens when facing these situations by turning towards collective decision-making, where no single person has to make these kinds of decisions seemingly on their own: ""It can never be one person's decision. It's always a collective decision.""Interestingly, 25% of the participants felt that clinicians in the field were too close to individual patients and communities to be able to make sound decisions on how to distribute the experimental therapeutics without bias. For example, two participants articulated that they would have made an ""emotional decision"" if they were asked to provide an experimental therapeutic to a colleague who had contracted EVD.In terms of which basic principles they wanted reflected in the framework for allocation, participants brought up many of the fundamental biomedical research ethics principles, including but not limited to: respect for persons; protection of dependent or vulnerable populations; do no harm; and a principle of justice. A principle of equity was also discussed several times in the form of wanting to ensure post-trial access to local affected populations and in offering those ineligible for trials access to experimental therapeutics via MEURI. One participant described respect for persons as ""seeing people as autonomous agents with a right to selfdetermine.""Interestingly, several participants (19%) described their personal sense of right and wrong by using anecdotes to articulate their moral reasoning. For example, one participant used an anecdote of walking along the beach and seeing two people drowning: ""If I'm walking on the beach and I'm the only person on the beach and I see two people drowning, I don't say: 'well I'm not going to save one of them because I'm not going to save both of them.'"" They would not take the approach of ignoring both drowning individuals because they cannot save both of them, instead they would save one person and then advocate for ""more lifeguards on the beach to be able to save all of them."" Overall, the respondents indicated a strong desire to maintain high ethical standards during challenging and dynamic outbreak responses like the 2013-2016 EVD outbreak.Several important themes emerged from this study including the prioritization of frontline workers' access to experimental therapeutics when available in limited quantities, widespread acceptance of adaptive clinical trial designs, improved clinical trial transparency and greater engagement with the local affected communities. An overwhelming majority of responders were in favor of the development of an ethical framework of guiding principles to benefit those in the field response in the next EID outbreak, especially when allocating limited experimental therapeutics.Others have also called for new guidelines for more clearly defining boundaries between clinical trials and compassionate use [24] . The World Health Organization (WHO) had issued ethics criteria for the use of unregistered interventions for EVD; however, important ethical questions remained unanswered [19, 25] . While EVD outbreak ethical considerations have been discussed earlier in specific contexts (e.g. individual countries), it was thought that relevant insights informing a potential framework would prove useful, and could be implementable in the field in resource-constrained regions tackling EID outbreaks specifically with high case fatality [26] [27] [28] [29] . Analysis of the insights shared in the interviews of the international healthcare workers involved in the 2013-2016 EVD outbreak response provided the basis for such an ethical framework (Table 1) .This framework derived from responses from individuals heavily involved in outbreak responses in the largest Ebola Virus Disease outbreak in history (West Africa 2013-2016), may complement guidelines developed by international ethics experts, including those in the recent U.S. National Academies of Sciences, Engineering, and Medicine report [30, 31] . Such frameworks and guidelines should prove very useful for those working at international humanitarian medical organizations, to inform strategy and preparedness for future responses to EIDs, specifically for EIDs with high case fatality rates highlighted in a WHO priority list of top emerging pathogens, which includes EVD [32, 33] . These frameworks and guidelines will not remain static but should be continually updated in the light of new knowledge and tailored to specific EID outbreaks. For instance, reduction in case fatality rate estimates may influence acceptance of RCT trial designs utilizing a non-intervention control arm and alter decisions on who may benefit most from treatment when experimental therapeutics are in limited supply.The analysis presented here is relevant to the current EVD outbreak in western Democratic Republic of Congo [34] and many of the recommendations are applicable to the current COVID-19 outbreak response [35] . Community mistrust has continued to plague subsequent Ebola outbreak responses and impacted response efforts [36, 37] .Recent steps in the right direction include updated MEURI guidelines and modified Ebola therapeutics trial designs [38] [39] [40] . For instance, in response to concerns expressed regarding RCT design with a standard of care only control arm, the recent PALM trial of Ebola experimental therapeutics used an interventional control arm, where three additional therapeutics (REGN-EB3, MAb114 and Remdesivir) were compared to ZMapp as the control arm [39, 41, 42] . A pre-existing ethical framework of guiding principles can continue to accelerate access and trial design and improve community engagement on limited resource allocation, reducing rushed decisions and improving the speed and quality of outbreak responses.Supporting information S1 File. Background information document. (DOCX) Conceptualization: Ariadne A. Nichol, Annick Antierens.Formal analysis: Ariadne A. Nichol, Annick Antierens.Methodology: Ariadne A. Nichol.",United States of America,first author,2021-02-02,02
d22a93a967507d11b11a9750f732756bbb6b87ce,Analysis of key factors of a SARS-CoV-2 vaccination pro- gram: A mathematical modeling approach,"The world is facing the COVID-19 pandemic and just in the middle of December of 2020 the first vaccines are being given to a few people [42, 128, 78, 119, 103, 129, 130, 115] . This pandemic has caused more than 80 million confirmed cases and more than 1.7 million deaths [30, 136] .The SARS-CoV-2 virus causes an illness called COVID-19 that can result in severe pneumonia and death [81, 102] . The complex process of the SARS-CoV-2 spread involves several factors that are currently not very well understood [84, 112, 139, 102, 31, 32] . There are several aspects that impact the spread of the virus in the human population, such as, social behavior, age, weather variables, mutation of the virus, and immunocompetence [152, 111, 147] . Other factors may affect the spread of the SARS-CoV-2 virus but still be unknown. Regarding mutations, SARS-CoV-2 could acquire mutations with fitness advantages and immunological resistance [71] . Therefore, studying evolutionary transitions is important to ensure effectiveness of the vaccines and immunotherapeutic interventions [151, 50, 104, 157, 71] . It has been stateded that not only is the efficacy of the vaccine important, but whether a vaccine reduces infection and transmission as well as disease progression [69] .The genomic analysis suggested that the base sequence of SARS-CoV-2 is almost 80% similar to that of SARS-CoV. Further, both these viruses bind to same host cell receptor ACE-2 [6]. However, the development of vaccines for this novel SARS-CoV-2 virus took nearly a year. There are now more than 80 vaccines in development [3, 16, 69, 71, 149, 105, 135] . Vaccination programs have recently begun (December) in a few countries, and there are many uncertainties regarding the optimal implementation of these vaccination programs and the probable outcomes [1, 69, 137] . Therefore, studying the COVID-19 vaccination programs is of paramount importance. Effective vaccination helps tackle the transmission of the SARS-CoV-2 virus in the population [9, 29, 69, 72, 137, 145] .We constructed a compartmental model based on differential equations that includes individuals in the susceptible, latent, infected, asymptomatic, and hospitalized stages. The mathematical model considers transitions of individuals through the aforementioned stages depending on the COVID-19 progression. In addition to the previous stages, the model incorporates vaccinated individuals that might be in analogous stages such as susceptible or asymptomatic vaccinated. Thus, in some way we can classify individuals in two disjoint groups: unvaccinated and vaccinated. We assume that unvaccinated individuals in the susceptible, latent, and asymptomatic compartments can receive the vaccine against the SARS-CoV-2 virus. On the other hand, we assume that symptomatic, recovered and hospitalized unvaccinated individuals do not receive the vaccine. The individuals can transit from the unvaccinated susceptible class to vaccinated susceptible if they get the vaccine. In an analogous way, the latent and asymptomatic unvaccinated individuals can move to the respective vaccinated compartment. It is important to mention that the model incorporates the type of vaccine that diminishes the progression to the COVID-19 disease [87, 99] . Individuals in the latent stage are not yet infectious. The individuals remain in the latent stage for a certain time which is chosen from an exponential distribution with mean time α. The individuals then transit into the infective symptomatic or asymptomatic stages, where they are able to spread the SARS-CoV-2 virus to other individuals. They stay in the infectious stage for a time chosen from an exponential distribution with mean time γ. After that, individuals in the asymptomatic stage move to the recovered stage. However, individuals in the infective symptomatic stage can move to the recovered or to the hospitalized stages, depending on the level of disease progression. Even though we assume exponential distributions, the Erlang distributions are more realistic but at the expense of more complex models and more parameters [63, 48, 116, 47, 38, 140] . Thus, many studies assume exponential distributions to avoid greater complexity in the models and in the analysis. However, in some cases exponential distributions are not far from reality. We have found that the length of stay in the hospital is not far from an exponential distribution [37] . Finally, hospitalized individuals can die due the COVID-19 disease [37, 39, 40, 156] . This last metric (or outcome) is of paramount importance [40, 138, 142, 150] .We use a mathematical model that is similar to a SEIR-type epidemiological model to explain the dynamics of COVID-19 spread on the human population under a vaccination program. This model has parameters that can be varied in order to study different possible scenarios. For instance, the pace of vaccination and efficacy of the vaccine can be modified. This is important since it is known that the efficacy of vaccines varies and they have different underlying mechanisms of action [69, 72, 58, 79, 9] . Moreover, different countries and regions would apply the vaccines at different rates due to a variety of factors such as availability and resources [1, 35, 69, 79, 27] .The constructed mathematical model based on differential equations is given bẏIn this work we are interested in the impact of the vaccination rate and the efficacy of the vaccines on the infected, hospitalized, and death cases. We assume that the rates of virus transmission in asymptomatic and symptomatic individuals are constant from the beginning of the period of study i.e. when the vaccination program starts. This implicitly assumes that people would not change behavior (on average) until the vaccination program is well advanced. This is a credible assumption in the USA, and previous physical and social behavior changes can be included in the transmissibility. Many health policies and guidelines would have been implemented before the vaccination program started. In some cases it is more realistic to include time-varying transmissibility, which has been used to study other infectious diseases and in particular one closely related to the SARS-CoV-2 virus [131, 76, 73, 67] . This latter approach is more troublesome to implement since it is necessary to estimate a time-varying parameter, and identifiability issues thus arise. Even with accurate data from the past it is difficult to estimate a time-varying transmission. Moreover, in this study we can not predict how the behavior of individuals might change in the future. Thus, we take an approximation and a conservative assumption that the transmissibility would not change during the beginning of the vaccination program.We assume that the parameters related to the COVID-19 disease progression are the same for vaccinated and unvaccinated. In addition, we consider that vaccinated individuals are not able to get the disease unless the vaccine was not effective. This aspect is not clear in the relevant scientific literature due to the different types of COVID-19 vaccines [69, 72, 58, 79, 9] . In addition, some studies have indicated that the antibody titers may decline over time in patients recovered from COVID-19, particularly in those who were asymptomatic [143] . However, we do not consider that recovered individuals can return to the susceptible stage. One reason for this is that further studies are needed to check how long the immunity lasts, and furthermore, the time horizon of this study is less than 16 months. We also consider that for this period the immunity provided by the vaccines does not diminish.Reasons for doubting this undiminished immunity come from studies on the SARS virus. For example, in a study of 56 patients recovered from SARS it was found that the neutralizing and IgG antibodies quickly declined after 16 months and continued to decline further to a very low level after 3 years [143] . Moreover, trials of SARS vaccines also suggest that the neutralizing antibody responses may decline over time [143] . On the other hand, it is unclear whether vaccine induced antibody levels could persist and, if not, whether the long-lasting memory T cells could affect susceptibility and pathogenesis of SARS-CoV-2 infection [143, 19] .It has been mentioned that US federal officials hoped for twenty million people to get their first of two required shots by the end of 2020. However, they recently changed that goal and just over 1 million doses of vaccines had been administered (Dec. 26th 2020) [134] . Therefore, we assume as a lower bound rate ν for the inoculation of the vaccine a value of one million per week. This rate can be increased since it is expected that the process of the vaccine administration will be improved. However, this value of the parameter is subject to variation due to the reluctance of some people to vaccinate for because of doubtfulness about the preliminary tests of efficacy to pressure from anti-vaccination movements [27] .For the death rate of hospitalized individuals we use a variety of data from the scientific literature [40, 66, 148, 91, 99] . We used the weighted average of the probability of dying for severe and critical cases (ICU), and in addition we took into account the average length of stay in the hospital [99] . We varied in a reasonable way the death rate in order to take into account the possible uncertainty in the data.For the initial conditions we assume the particular situation of the USA since is one of the first countries that started a vaccination program [134, 106] . We rely on data from the scientific literature and demographics of the USA. As expected, there are some uncertainties related to data of the COVID-19 pandemic and which is usual in many epidemics. For instance, the infected reported cases have uncertainties due to many factors such sensitivity and specificity of COVID-19 tests [10, 127] . Moreover, asymptomatic cases represent a great uncertainty [31, 43, 52, 62, 90, 100, 124, 132, 7] . Taking into account these uncertainties, we set the initial conditions presented in Table 2 . The total initial population N (0) is taken from the current USA population [15] . The birth and death rates are taken from the official website of the CDC in USA [144, 86] . All the initial vaccinated subpopulations, are set to zero since the simulations are performed at the beginning of the vaccination program. Two key initial subpopulations are those corresponding to the infected and asymptomatic, since they affect the initial dynamics of the COVID-19 pandemic under the vaccination program. We took the seven day average of the infected reported cases and then multiplied by seven days (assumed infectiousness period) and by 0.8 to obtain the initial number of symptomatic cases (assumption of the proportion of symptomatic cases in the reported cases) [17, 4, 89, 123, 23, 154, 65, 122, 44] . The percentage of asymptomatic cases in the official statistics varies for each country. In some countries it may be close to zero, since no random tests are performed. However, the detection of asymptomatic infections is possible in the case of the USA in situations in which testing is mandatory (as in some universities) or random. We approximated this value by relying on data from different studies [17, 4, 89, 123, 23, 154, 65, 122, 44] . However, in our simulations we varied the parameter through reasonable values. This variability only affects the initial conditions of some of the populations.In this section, we perform numerical simulations of the mathematical model (1) to analyze the impact of the vaccination rate and the efficacy of the vaccine on the dynamics of the COVID-19 pandemic. We use the parameter values of Table 1 and the initial conditions given in Table 2 . We vary the values of the vaccination rate, the efficacy of the vaccine and the transmission rates in order to include a variety of scenarios that take into account the uncertainty in the aforementioned factors. We introduce some important metrics related to the outcomes of the COVID-19 pandemic in order to assess the impact of the inoculation rate and the efficacy of the vaccine.Here we present the results of the numerical simulations for different scenarios varying the inoculation rate, efficacy of the vaccine, percentage of infections that are asymptomatic, and the transmission rates. We consider two different plausible efficacies for the vaccines. We set the efficacy ( ) to 80% and 94%. These values were chosen based on some results of vaccine trials and the current approved vaccines [3, 16, 69, 134, 149, 105, 135] . We could simulate scenarios with lower efficacies if we desire and based on the fact that the FDA established a minimum efficacy threshold of at least 50% [58, 99] . We also vary the inoculation rate (vaccination pace) to test different potential vaccination program scenarios [134, 106] . It is important to remark that despite the plans that health institutions make regarding vaccination, there are uncertainties present in the logistics [134, 95, 141, 106] . For instance, currently there is a significant delay in coronavirus vaccinations while hospitalizations continue to set records in the USA [106]. Therefore, here we considered two different plausible inoculation rates based on the current situation. Specifically, we chose vaccination rates of two and four millions per week. It is important to mention that even though these rates might not be 100% accurate, this approach helps to elucidate the impact of the inoculation rate on the main outcomes of the COVID-19 pandemic under a vaccination program.Regarding the values of the SARS-CoV-2 virus transmission rate that plays an important role in the value of the effective reproduction number R t , we chose two different values. These two values of the SARS-CoV-2 virus transmission rate between humans correspond to two different reproduction numbers R 0 . Thus, we can relate them using the following equation R 0 = (1 − a)β 1 γ+h + aβ 1 γ . It is important to remark that the effective reproduction number R t varies over the time, and several methods have been proposed to compute it [24, 146, 120, 94, 75, 26, 131] . For instance, under certain conditions R t = R 0 S(t)/N , which relates the value of the virus transmissibility β to the effective reproduction number [146] . It is important to remark that independently of the method that is used to compute the effective reproduction number R t all of them show that it depends explicitly or implicitly on the value of the transmission rates (β s ). Therefore varying these rates implies a variation in the basic reproduction number R 0 and on the effective reproduction number R t . Thus, we are considering different scenarios regarding the risk of becoming infected by the SARS-CoV-2.The aim is to test the impact of the inoculation rate and efficacy of the vaccine under two different SARS-CoV-2 virus transmission rate scenarios. As it has been mentioned before, there are a lot of uncertainties in the transmission rates for different regions and they vary over the time depending on official and unofficial non-pharmaceutical interventions [40, 55, 85, 93, 120, 25, 75] . However, the approach used here allows us to understand the impact of inoculation rate and vaccine efficacy under two different transmission of the SARS-CoV-2 virus environments. Then results can be extrapolated to other environment settings.We present additional Tables for different scenarios varying the transmission of the asymptomatic carriers and the proportion of asymptomatic individuals. The Table 4 shows the same outcomes that we mentioned above, but we consider now that the infectiousness of the asymptomatic individuals relative to symptomatic is 75%. The impact of the vaccination rate is greater than the efficacy of the vaccine. The first row of Table 4 shows that the peak of the number of infected people is 2,932,727 when transmission rate is β I = 0.2, the vaccine efficacy is = 94% and the vaccination rate is two millions per week. This metric is just 2,954,850 if the vaccine efficacy decreases to 80%. This is a small change if we compare it to that when the rate of vaccination is increased to four million per week. Thus, this scenario also supports the importance of a high vaccination rate. Figure 3 shows the different outcomes for a wide range of different vaccine efficacies and inoculation rates. The variation of all these outcomes is larger when the vaccination rate is varied.Finally, Table 5 and Table 6 , show the outcome when the percentage of infections that are asymptomatic is 40% (a = 0.4) and the infectiousness of the asymptomatic individuals relative to symptomatic is 100% and 75% respectively. The numerical simulation results show similar trends to the two previously studied cases. Again, that the impact of the vaccination rate is greater than the efficacy of the vaccine can be observed . This qualitative effect can be seen under a variety of scenarios regarding vaccine efficacy and vaccination rate in Figures 4 and 5, respectively. The numerical simulations include many different parameter values for the infectiousness of asymptomatic individuals, percentage of infections that are asymptomatic, efficacy of the vaccine, and the vaccination rate. Thus, uncertainty in these parameters has been considered in this study.Based on the previous results we can conclude that under some plausible scenarios that the impact of the inoculation rate is more relevant to control the burden of the COVID-19 pandemic. Thus, these results suggest that health authorities should focus in increasing the inoculation rate in order to avert more infected people, hospitalizations and deaths. Our results agree with previous result under different assumptions, and with recommendations made by some scholars [99, 141] . Currently there are authorized and recommended vaccines to prevent COVID-19 in the United States. The COVID-19 vaccination program started in early December. Depending on the specific vaccine, the people will get a second shot 3-4 weeks after the first in order to achieve the most protection against the disease caused by the SARS-CoV-2 virus [30, 106] . The vaccines against the SARS-CoV-2 virus have different efficacies and mechanisms of action [3, 16, 69, 71, 149, 105, 135] . Vaccination programs have been recently begun in other countries, using several different types of program and different outcomes can therefore be anticipated [1, 69, 137] . For instance, a vaccination program can focus first on health care workers or on elderly people [87] . However, whatever group the vaccination program targets first; there is an inoculation rate of the vaccine. In this study we propose a mathematical model to assess the impact of the vaccination programs as a function of the efficacy of the vaccine Page 8 of 19In this article, we studied the impact of the vaccination pace and the efficacy of the vaccine on the dynamics of the COVID-19 pandemic. We studied the particular scenario of USA, but the methodology presented here can be extrapolated to other countries or regions. We were able to study different potential scenarios regarding the burden of the COVID-19 pandemic. We varied the inoculation rate, efficacy of the vaccine and the SARS-CoV-2 virus transmission rates. The constructed compartmental mathematical model allows the variation of the aforementioned factors, and using computational methodologies we obtained metrics that indicate which are the most important factors to decrease the burden of the COVID-19 pandemic.We found that the efficacy of the vaccine and the vaccine inoculation rate have a high impact on the outcomes. However, the rate of vaccine administration has a larger impact on reducing the infected and hospitalized subpopulations. In a similar way, it has a greater impact on the number of deaths caused by the SARS-CoV-2 virus. Another important finding is that the impact of the inoculation rate and vaccine efficacy is larger for scenarios with higher SARS-CoV-2 virus transmission rates. Thus, our results suggest that health institutions need to focus in increasing the vaccine inoculation rate in the regions with higher rate of new infections. Our results are in accordance with previous recommendations made by some scholars [99, 141] .uncertainty, as is usual in this type of epidemiological model. The uncertainty related to the COVID-19 pandemic is higher in comparison with other diseases such influenza due to the novelty of the SARS-CoV-2 virus. The parameter values were chosen from scientific literature. Despite the limitations of this type of mathematical model, they have been useful in many epidemics and are a classical method to deal with epidemics [57, 22, 28, 45, 34, 13, 36, 73, 12] . Some particular limitations of this study are that constant inoculation rates were used and the vaccination programs do not target any specific subpopulation. We hopefully anticipate that the inoculation rates will increase due to an increase in vaccine production and improving of the logistics. However, the vaccination programs might face several obstacles along the way. The model does not consider a subpopulation that is not willing to take the vaccine, and this has been an issue for other vaccines [27, 53, 108, 137] . Further studies are needed to extend the mathematical model for other vaccination programs. For instance, those that target first health care workers or specific age groups. This would require more parameters and therefore more uncertainty and details. In addition, our mathematical model does not consider the fact that immunity wanes. In fact, the US FDA recommends that follow-up of study participants should continue for as long as is feasible, to assess the duration of protection [58] .The results presented in this study show that the effectiveness of a COVID-19 vaccination program strongly depends on the vaccination rate and the efficacy of the vaccine. Moreover, the SARS-CoV-2 virus human transmission rates and consequently the effective reproductive number impact the outcome of the vaccination programs. It is important to remark that vaccination rate depends on many variables or resources such as health care facilities or logistical transportation aspects. On the other hand, the efficacy of the vaccine is out of the hands of health institutions and official entities. However, the rate of vaccine administration plays a more important role to reduce the burden of the COVID-19 pandemic. Our results show that health institutions need to focus in increasing the vaccine inoculation pace and create awareness in the population about the importance of the COVID-19 vaccines.In some countries the vaccination rate would be limited due to the availability of the vaccine. Currently, in the USA there are issues with the vaccination rate due to logistics, but not regarding availability [134, 106] . As we mentioned in the introduction, at some point there might be difficulties keeping a constant vaccination rate since a proportion of the population is not willing to be vaccinated. This topic is interesting and can be studied in the future.some cases exponential transition between stages are not very far from reality. Despite the limitations of our model, we found valuable results to face the current COVID-19 pandemic. Support is given to characteristics of efficient vaccine campaigns. In particular, our study encourages governments and their health institutions to increase the pace of the vaccination in the population in order to diminish the consequences of the catastrophic COVID-19 pandemic.[1] Derrick Bary Abila et al. ""We need to start thinking about promoting the demand, uptake, and equitable distribution of COVID-19 vaccines NOW!"" In: Public Health in Practice (2020), p. 100063.[2] Luis Acedo et al. ""Uncertainty and sensitivity of the sexual behavior changes to the current human papillomavirus vaccination campaign in Spain"". In: Mathematical Methods in the Applied Sciences (). [7] Yan Bai et al. ""Presumed asymptomatic carrier transmission of COVID-19"". In: Jama 323.14 (2020), pp. 1406-1407.[8] Georgios D Barmparis and GP Tsironis. ""Estimating the infection horizon of COVID-19 in eight countries with a data-driven approach"". In: Chaos, Solitons & Fractals (2020), p. 109842.[9] Sarah M Bartsch et al. ""Vaccine efficacy needed for a COVID-19 coronavirus vaccine to prevent or stop an epidemic as the sole intervention"". In: American journal of preventive medicine 59.4 (2020), pp. 493-503.[10] Zeno Bisoffi et al. ""Sensitivity, specificity and predictive values of molecular and serological tests for COVID-19: a longitudinal study in emergency room"". In: Diagnostics 10.9 (2020), p. 669.",United States,abstract,2021-02-23,02
e51399c0b2e25e5093ea18e87e70e172e6312c96,COVID-19 Spreading Dynamics in an Age-Structured Population with Selective Relaxation of Restrictions for Vaccinated Individuals : a Mathematical Modeling Study (Running title : Selective relaxation -a path out of the pandemic),"Over the past couple of months, four COVID-19 vaccine candidatesthe ones developed by Pfizer/ BioNTech, Moderna, Oxford/ Astra Zeneca (also Oxford/ Serum Institute of India) and ICMR/ Bharat Biotechhave received emergency use authorization following rigorous trial procedures. These are being used in vaccination drives all over the world; currently, healthcare workers and essential workers or vulnerable populations are the beneficiaries, with vaccination of the general public being on the to-do list. The first two vaccine candidates (mRNA vaccines) 1,2 have reported trial efficacies of almost 95 percent, the third candidate (a vector vaccine) 3 has reported 60-90 percent (dosage-dependent), while the fourth (an adjuvated inactivated vaccine) 4, 5 has reported encouraging immunogenicity results in the early trials; participant enrolment for the phase 3 trial has been completed but the trial itself has not. In August 2020, Russia approved Sputnik 5 (a vector vaccine) bypassing some of the trial protocols; a recent study 6 finds its efficacy to be 90 percent. Very recently, Johnson and Johnson (a vector vaccine) 7 has reported 57-72 percent efficacy (location-dependent) while Novavax (an adjuvated subunit vaccine) 8 has reported 60 (South Africa) to 90 (UK) percent efficacy; both vaccines are currently undergoing the approval process.Mathematical modeling studies of COVID-19 dynamics post-vaccination started emerging as soon as the first vaccines were approved. Swan, Goyal, Bracis et. al. 9 have performed a detailed analysis of the roles played by different vaccine efficacy metrics. Several studies [10] [11] [12] [13] find that vaccinating high-contact people first will have the greatest beneficial effect on the spread of the disease. Foy, Wahl, Mehta et. al. 14 find that priority vaccination of elderly and vulnerable people is optimal for minimizing deaths. They also find that continuing with social restrictions such as six-foot separation and mask regulations during the vaccination drive will best mitigate the disease spread. This conclusion has been obtained in many other analyses as well 12, [15] [16] [17] [18] . Some studies however 19,20 project a more optimistic outcome, permitting a gradual relaxation of non-pharmaceutical interventions (NPI) starting from the fourth month of the vaccination drive.From the general public's perspective, continued social restrictions for vaccinees may appear inconvenient. Those who have got the vaccine would at least hope to socialize freely with others who have been vaccinated as well. From an economic perspective, continuing NPI during the vaccination drive will amount to prolonged strain on businesses and on the government's fiscal resourcesany relaxation or exemption will act as a lifeline. Our quest here is to find such an exemptionspecifically, we ask whether social restrictions can be immediately and preferentially relaxed for those individuals who have been vaccinated.Hereafter, we refer to this strategy as ""selective relaxation"". To clarify, we treat a person as vaccinated only after s/he has received the second dose of a two-dose regimen and cleared the subsequent immunogenicity period.With ideal vaccines, the success of the selective relaxation strategy would have been a given.However, the actual COVID-19 vaccines are not 100 percent efficacious, which raises the issue of whether unrestricted (or at least significantly expanded) social activity and mobility on the part of vaccinees may drive the epidemic out of control. In the remainder of this Article, we use mathematical modeling to address this question.We use a compartmental or lumped parameter delay differential equation model developed by our group 21 . We have selected this model because all parameters here are directly related to the disease or to control measures, and because it can be easily extended to accommodate vaccination.We present here only the outline of the model, with the full equations and derivation being given in §1 of the Supplementary Data. Time is measured in days. We incorporate agestructuring, defining three groups of people : Group 1 or ""minors"" aged 0-19, Group 2 or ""middlers"" aged 20-64 and Group 3 or ""seniors"" aged 65 and above (the labels ""minors"", ""middlers"" and ""seniors"" are just for easy identification of the groups). We believe that this is the simplest structure which can account for the facts that (a) under-18 (entire Group 1 in our model) are currently ineligible to be vaccinated, (b) interaction rates among different age groups are highly disparate, and (c) older people are disproportionately more vulnerable to the disease. We have taken the population fractions from USA data 22 .The entry qij (i,j=1,2,3) of the contact matrix Q denotes the (average) number of people belong to Group j with whom one person belonging to Group i interacts in one day. We have calculated Q based on Mossong, Hens, Jit et. al. 23 ; it isThe major parameters of interest are as follows.• Vaccine efficacy η : We define this as the probability that the vaccine works. We assume that when the vaccine does work, it confers full sterilizing immunitywhile the vaccines' efficacy against symptomatic disease is well-known, a recent very important study 24 has demonstrated the Pfizer vaccine to be effective against asymptomatic infection as well. We also assume that the vaccine confers zero transmissibility-reducing immunity when it does not work.• Viral strain : This informs the choice of the matrix M h ; we adjust it so that in the absence of restrictions, the disease has a starting reproduction number R0 of 3·0, 2·0 or 5·0, corresponding to consensus 25-28 , low-transmissibility and high-transmissibility or rogue strains (such as B1.1.7 and B1.351) 29,30 of the virus respectively.We start by running simulations for selective relaxation with Interaction Mode 1. Let vaccines be distributed at the constant rate 600/day, corresponding to vaccination of the entire population in 500 days. Let 90 percent of the available vaccines be allotted to seniors until they have been vaccinated completely, after which the entire stock is given to middlers. We consider three different vaccine efficacies of 60, 80 and 90 percent and the three viral strains mentioned in the Methods Section. In each case, we use the following metrics to calibrate the region's infection control performance : (a) the time T to the end of the outbreak, (b) the total number X of cases at the end of the outbreak, (c) the total number D of deaths at the end of the outbreak and (d) the vaccination fault ratio f, defined as the maximum ratio of vaccinated cases to total vaccinees at any point in the outbreak and reported as a percentage. We present the results in Table 1 .although the initial phases of the top and bottom panels of Figure 1 appear disturbingly similar, they have one significant difference. In the top panel, the bars corresponding to vaccinated cases (magenta, violet) are barely visible at any time during the initial decrease of cases while in the bottom panel, they are clearly present during this phase. A high prevalence of vaccinated cases during the initial deceleration of the pandemic can act as an early warning for a second wave and indicate the need for reimposing restrictions on vaccinee-vaccinee interactions.In both these plots, the periodic five percent increments in the derate δ have a nuisance value.As mentioned in the Results Section, these increments slow down and can even destabilize the elimination drive. We have implemented this feature since it is very likely that as case counts decrease and vaccinees receive immediate clearance, non-vaccinees are also going to start bending the rules. If the data shows that these excursions are having a deleterious effect, then the public health authorities will have to intervene; otherwise the violations can be ignored.Finally, we have also found that varying β (the fraction of vaccines preferentially allotted to seniors) has a small effect on the overall case trajectories. In general, reducing β tends to reduce the duration and the cumulative caseload but increase the number of deaths. This is in line with the near-universal policy of vaccinating vulnerable people first, and it lends credence to the model predictions.In this Article, we have identified immediate and preferential relaxation of restrictions for vaccinees as a feasible path to the elimination of the terrible pandemic called COVID-19.This path features a continuous growth of economic and social activities during the vaccination drive. We hope that the incentive of immediate benefits will also induce people to get vaccinated and hence automatically combat vaccine hesitancy. With selective relaxation, and with current encouraging vaccine efficacies, we find a timeframe of eight to ten months before transmission reduces to negligible levels.While our primary finding and its associated message are hopeful, there are also some cautionary takeaways. In particular, a 60-70 percent effective vaccine does not appear to be adequate for issuing immunity passports. Until and unless high-efficacy vaccines are widespread, research on improving vaccine efficacy should be pursued at maximum priority. ""In the field"" efficacy estimations should continue for all approved vaccines, especially to identify socio-demographic determinants of efficacy, if any.In conclusion, the initiation of vaccination drives marks the beginning of the end of humanity's struggle against COVID-19. Our immediate objective over the remaining few months of this battle has to be to minimize the caseloads, death tolls and socioeconomic disease burden. We hope that the prescription we have suggested here may prove effective in this respect.to ""COVID-19 spreading dynamics in an age-structured population with selective relaxation of restrictions for vaccinated individuals : a mathematical modeling study""In this Supplement we cover several issues which could not be treated in the Article proper due to lack of space. Throughout, a figure or table numbered ""n"" always refers to the Article proper while a figure or table numbered ""Sn"" refers to this document. The same holds for References. Since labelled display equations exist in this Supplement alone, we have tagged them with numbers only and no ""S"" prefix.We begin with a very brief recap of the model proposed in our prior work [21] .Defining y (t) as the cumulative case count, the left hand side above is dy/dt. The per-case spreading rate, which we call m0, is the product of two quantities -the rate q0 at which a random person (and hence an at large case who is unaware of infectious nature) interacts with other people, and the probability P0 that an interaction with a susceptible target results in a transmission. q0 is governed by the degree of social restrictions in place while P0 is determined by masking and sanitization; collectively, m0 embodies the effects of nonpharmaceutical interventions [21] . q0 happens to be available as a parameter from Literature; this fact will play an important role later. The target susceptibility probability factors in the immune response to the disease; with permanent immunity (and some plausible approximations), it takes the form 1 − y/N where N is the region's total population. The number of at large cases has the following mathematical expression :where μ1 is the fraction of cases who are asymptomatic, μ3 is the fraction of cases who escape from contact tracing, T is the time for which contact traced cases remain at large, τ1 is the time for which untraced asymptomatic cases remain transmissible and τ2 is the time for which untraced symptomatic cases remain transmissible and at large before manifesting symptoms and (at least so we assume) seeking quarantine.Putting all this together, we arrive at the retarded logistic equationas the final form of the one-component epidemic model without vaccination. Equation (2) uses delays rather than inverse-rates to express infection durations, which enables it to make very realistic predictions. For further details of derivation, we must refer to our prior study [21] .Here we add vaccination without age-structuring to the basic model (2); once this is done, the age-structured model will follow easily. We define three dependent variables : y (t) the cumulative count of corona cases among unvaccinated people, z (t) the cumulative count of cases among vaccinated people and v (t) the total number of vaccinated people. We now use the logical structure (0) to formulate the evolution equations for the disease; for conceptual clarity, we permute the terms on the right hand side as follows :Probability of Per-case spread-Number of of new cases target susceptibility ing rate at large casesIn this layout, the two terms featuring cases rather than targets are adjacent to each other.We start from the interaction rates. In the most general case, there will be four interaction rates : Q a the number of non-vaccinated people (targets) with whom one non-vaccinated person (and hence such an at large case) interacts each day, Q b the number of non-vaccinated targets with whom one vaccinated case interacts each day, Q c the number of vaccinated targets with whom a non-vaccinated case interacts each day and Q d the number of vaccinated targets with whom a vaccinated case interacts each day. We have used capital Q rather than small q for a reason which will become apparent shortly, and have used superscripts for a,b,c,d rather than the more conventional subscripts for a reason which will emerge in the next Subsection. Q b and Q c are not necessarily equal; if a vaccinated person visits the houses of her ten unvaccinated friends who themselves remain confined at home then that contributes 10 to the vaccinee's Q b but only one to each of the non-vaccinees' Q c .so that the q i 's become interaction parameters which can be obtained from Literature. Finally, we multiply each q i by the transmission probability P i to form the four spreading rates m a , m b , m c and m d . The P i 's need not be the same for the four interaction types, since there might be heterogeneities in masking, handwashing etc.To calculate the number of at large cases, we take the asymptomatic fraction μ1 = 4/5. We also take the contact traced fraction to be zero so that μ3 = 1. In Ref.[21] we have shown that contact tracing can capture only a small percentage of total cases if the asymptomatic fraction is high; moreover, contact tracing is managed by healthcare professionals many of whom are now re-deployed to vaccination drive. We use the parameter values [S1] τ1 = 7 and τ2 = 3, so that the function n gets defined as ( )We assume that vaccinated cases have the same μ1, τ2 and τ1 as nonvaccinated ones (consequences of this come in §2), so that we can use this function n to count at large cases of both unvaccinated and vaccinated groups. (3) to formulate the equation for y (t), the unvaccinated cases. At any time, the total number of vaccinees is v and the total number of nonvaccinees is N − v. In this work, we assume that the disease as well as the vaccine confers permanent immunity (the disease with 100 percent probability and the vaccine only in those instances where it works), an assumption discussed in detail in §2. An unvaccinated person can be insusceptible only if s/he has already contracted and recovered from the disease; at any time the total number of recoveries (modulo the approximations of the previous Subsection) is y, the total number of nonvaccinees is N − v and so the probability that a random non-vaccinee is susceptible is (N−v−y)/(N−v), which is 1 − y/(N−v).our first equation.Similarly we can use (3) to formulate the equation for z (t). By the model assumptions, the vaccine confers sterilizing immunity with probability η, so at any time, the number of insusceptible vaccinees is ηv and the number of susceptible vaccinees is (1−η)v. Among the latter, z people have contracted and recovered from the infection so they are insusceptible as well. Hence, the total number of susceptible vaccinees is (1−η)v − z and the susceptibility probability is this divided by v, which is 1−η − z/v. The fraction (N−v)/N in (6) will now get replaced by v/N; moreover the terms m a and m b will get replaced by m c and m d since the target is a vaccinee. This yieldsFinally, we need an equation for v. We assume that vaccination takes place at a constant rate α (people/day). The longest that the vaccination drive can continue is until all non-vaccinees have turned into either cases or vaccinees i.e. when y + v equals the total population. Thus, we haveThe stopping condition assumes that everyone is willing and able to receive the vaccine, which is sufficient for this single-population model.As discussed in the Article proper, we consider three age groups (a) Group 1 aged 0-19 or ""minors"", (b) Group 2 aged 20-64 or ""middlers"" and (c) Group 3 aged 65+ or ""seniors"". Minors cannot be vaccinated so these cases account for a single dependent variable; in the other two categories we need three variables each corresponding to unvaccinated cases, vaccinated cases and vaccinees. Let the variable y1 denote minor cases, y2 unvaccinated middler cases, z2 vaccinated middler cases, v2 vaccinated middlers, y3 unvaccinated senior cases, z3 vaccinated senior cases and v3 vaccinated seniors. Let N1, N2 and N3 denote the total populations of minors, middlers and seniors respectively.So far as parameters are concerned, the Literature yields nine interaction rates q ij denoting the rate (per day) at which a person belonging to group i interacts with people belonging to group j. This can be converted to m ij via multiplication by a relevant probability. Then, each m ij can have a different value depending on whether the interacting cases and targets are vaccinated or otherwise. Once again, we use the superscripts a,b,c,d as in (6,7) In addition to the vaccination rate α, we now need another parameter β (introduced in the Article proper) denoting the fraction of vaccines preferentially allotted to seniors. We assume that at the start of the vaccination drive, βα vaccines per day are distributed to seniors and (1−β)α vaccines per day to middlers. When any of the groups reaches saturation, all α vaccines are then diverted to the other group.This is the equation set we simulate in the Article proper. We now describe the derivation of the various parameter values used in the simulation runs.The first raw material we need for this is a population dataset. As a representative population, we use recent data from USA [22] , which has a total population of 328·2 millions. In Table S1 , we show the total number of people in various age brackets, together with some percentage compositions.We demonstrate the reduction of contact matrix from 15 square to 3 square using one example -the contact rate q11. First, we reproduce a part of As per Table S2 , a case aged 0-4 interacts every day with 1·92 targets aged 0-4, 0·95 targets aged 5-9, 0·48 targets aged 10-14 and 0·33 targets aged 15-19. All these are Group 1 targets, so we can simply add along the column to find that a case aged 0-4 interacts with 3·68 Group 1 targets every day. Similarly, adding along the other columns yields that a case aged 5-9 interacts with 8·94 Group 1 targets, a case aged 10-14 interacts with 9·38 Group 1 targets and a case aged 15-19 interacts with 9·20 Group 1 targets every day. Now, to obtain the Group 1-Group 1 interaction rate, we must weight these numbers by the population fractions from column 4 of Table S1 and add them up. This yields q11 = 7·85. This tedious operation repeated over all groups yields the contact matrix which we have displayed in the Article proper and reproduce here for clarity :R0 is defined as the number of people whom one case infects on average when everyone is susceptible and there are no external interventions. The first row of Q yields that a Group 1 case interacts with 7·85+5·36+0·28 = 13·49 targets every day; he transmits the disease to 13·49P0 of them. Similarly, a Group 2 case transmits the disease to 10·38P0 people every day and a Group 3 case transmits to 8·01P0 people every day. At the start of the outbreak, we assume that cases occur in the three groups in proportion to their populations; weighting the groups' contributions by the percentages in the fifth column of Table S1 and adding yields that one case transmits to 10·76P0 targets per day on average. By the model assumptions, 80 percent of all cases are asymptomatic and transmit for 7 days while 20 percent are symptomatic and transmit for 3 days, so that an at large case transmits for 31/5 days on average. Thus, a case transmits the disease on average to (10·76P0) × (31/5) people which is 66·71P0 people. Hence we claim R0 = 66·71P0.Having obtained this expression by crook rather than by hook, we must check its validity by numerical simulation of (9). If the condition is correct, then the epidemic ought to take off if P0 > 1/66·71 and die down otherwise. Simulating with different initial conditions, we find that the transition occurs at a P0 value of about 96-99 percent of the calculated one. Hence our expression for R0 is correct and we can use it to define P0 asFor normal life, R0 can be 2, 3 or 5 depending on the viral strain, and the corresponding P0 is obtained through (11). We defineas the matrix of the spreading rate m ij 's during normal life. During pandemic life, each m ij can have upto four values as we can see from (9); to simplify the parameter space we define the matrixwhere the derate δ lies between 0 and 1, and stipulate that k ij m (k = a,b,c,d) can be either l ij m or h ij m and nothing else. The deration takes care of contact reduction as well as transmission probability reduction through measures such as masking. Thus, for low-transmissibility strain we use the values P0 = 2/66·71 and the initial derate δ0 = 0·489, for consensus strain we use P0 = 3/66·71 and δ0 = 0·327 and for rogue strain we use P0 = 5/66·71 and δ0 = 0·196. These values of δ0 were chosen so as to keep the case rate curve closest to horizontal during the initial week or so of the vaccination drive.Finally, we explain how we implement the two interaction modes in the analysis. For Mode 1, we choose     11  11  21  21  21  31  31  31   12  12  12  22  22  22  22  22  22   32  32  32  32  32  32   13  13  13  23  23  23  23  23  23   33  33 while for Mode 2 we choose     11  11  21  21  21  21  31  31  31  31   12  12  12  12  22  22  22  22  22  22   32  32  32  32  32  32   13  13  13  13  23  23  23  23 , , Equations (14,15) look much more cumbersome than the concepts which they embody.Our final concern is with the initial and terminal conditions. We have chosen the initial conditions to generate a steady 300 cases/day for the first seven days, with cases divided among the three groups approximately in proportion to their population; this amounts to a daily case rate of 1/1000 th the total population and is very high. For termination condition, we define the active case count at time t to bea t y t y t y t y t z t z t y t y t z t z tand stop the run if a(t) < 1 for 14 consecutive days.Here we discuss some of the assumptions and approximations inherent in the model and the effects which they have on the results. For assumptions built into in the baseline model (2), we cite Ref.[21]; here we consider only the approximations involved in extending (2) to form (9).While calculating the death tolls, we have assumed that vaccination reduces the mortality rates by a factor of ten. Currently, a value for this factor is unknown; all that is known is that in the phase 3 trials of any of the vaccines developed so far, there have been zero COVID-19 deaths in the vaccine groups.The assumption that there are zero preexisting cases at the start of the vaccination drive is an underestimate; in some regions at least, a significant fraction of the population has already been immunized. In other regions however, the immunized fraction might not be too large. Pre-existing recoveries can influence the case trajectories in two ways : (a) for given interaction parameters, it can make the actual reproduction number lower than the model and hence terminate the epidemic faster and with lower caseload, (b) it can achieve the reproduction numbers of our simulations at higher levels of mobility and hence equal our infection control performance at a lower level of intervention. The high initial case rate will tend to generate a large number of vaccine cases at the start and push up the vaccine fault ratio. Thus, both the starting case count and case rate are chosen to generate a maximally unfavourable scenario. The assumption of 100 pre-existing middler and senior vaccinees has no impact other than to prevent division by zero when calculating the fault ratio.The terminal condition of less than one active case for a sufficiently long time is an eminently plausible measure of the true end of the outbreak. The number 14 (twice) in the definition of the condition might appear somewhat arbitrary. The choice is harmless since changing that number changes the cumulative case counts by minuscule amounts. At any rate, when the absolute number of cases is very low, a lumped-parameter model breaks down. All that one can talk about are probabilities, and for that one needs an agent-based model. Our model (and any other differential equation model) is good only for predicting when transmission will have become significantly reduced, and for that any physically plausible termination condition is adequate. We expect that the stochastic tail-phase of the outbreak will not add too many cases to our calculated totals; however it might prolong the epidemic significantly.Vaccination fault ratio : The question we want to address is ""If I receive the vaccine and party with other vaccinees, what is the probability that I shall actually contract the disease during the evolution of the outbreak ?"" The guess answer 1−η is a gross overestimate. To see this, consider an individual vaccinee, whom we call Bravo. Vaccine efficacy of 90 percent implies 10 percent failure probability which does not sound very small. However, 10There is no single metric in fact which can help us to answer the above question. An approximate indicator will be the ratio of the total number of vaccinated cases to the total number of vaccinees. However, this index will be artificially lowered by the fact that during the tail-phase of the epidemic, there are hardly any new cases but lots of new vaccinees. Hence we have opted to evaluate the ratio at every point during the disease evolution and report its maximum value as the vaccination fault. It is comforting that for the unimodal solutions, the fault evaluates to less than 1 percent.Here we used a social structure based on contact rates in UK superposed on demographics of USA. The question arises as to what extent the results are dependent on the choice of structuring. Moreover, instead of three age groups, suppose we had used say five or fifteen, then would the results have been different ?To answer this question, we consider the unstructured model (6-8) and compare its predictions with those of (9) for the same parameter values. For the first scenario, we take Mode 1, consensus strain. To achieve this, we use m a = m b = m c = m l = 0·163 and m d = m h = 0·489 in (6-8) [a simple calculation along the lines of that in §1 here provides these values]. We again increment m l in steps of 5 percent every 50 days. With 90 percent vaccine efficacy, we find that the epidemic ends in 205 days with 16,000 cases and a vaccination fault ratio of 0·18 percent. The time trace of evolution is shown in Figure S1 below.We see that the general trends of unimodal elimination and bimodal long-run epidemic remain the same. In the unstructured model, the overall durations and caseloads are less than in the structured model, which is very plausible since the latter model includes a class (minors) who have high interaction rates but are ineligible for the vaccine.With an effective vaccine, selective relaxation appears to be a quick and surefire path to elimination of COVID-19 in time while achieving maximum socioeconomic recovery. This process however may cause negative emotions between people who get vaccinated earlier and those who get vaccinated later. To the largest extent, there is nothing to be done about this rift -while vaccine allocation policies can come up with a priority order which maximizes the common good, it will be inevitable that one healthy young well-paid software engineer will get the shots and hence a ticket to freedom two months before another healthy young well-paid software engineer.We are aware that selective relaxation is harder to implement than collective relaxation or restriction. This is probably one of the reasons why all the modeling studies referred to in the Article proper consider only collective interventions. However, with a high efficacy vaccine, the socioeconomic gains from selective relaxation are immeasurable while the epidemiological gains from collective restriction are trivial. For example, consider a situation with 90 percent effective vaccine and consensus viral strain. With Interaction Mode 1, we have already seen that the epidemic ends at 306 days and 30,193 cases. If we instead employ a collective interaction mode where all spreading rates are l ij m with no h ij m , then the epidemic runs for 305 days accruing 30,161 cases. Thus, keeping an average of 90,000 people locked down during the vaccination drive would in this case be a ""Useless Precaution"".A plethora of results supports the assertion that a vaccine with 80 percent or higher efficacy can act as the basis for an immunity passport while a vaccine with efficacy in the 60s cannot, unless the virus transmission rate is already low. Hence, research into development of more efficacious vaccines should continue even as the early candidates are administered. The efficacies of existing vaccines should also be monitored for socio-demographic determinants if any. For example, if Vaccine A has 90 percent efficacy among middlers and 40 percent among seniors while Vaccine B has 70 percent across all age groups, then middlers should be given Vaccine A and seniors Vaccine B.",USA,first author,2021-02-23,02
734590dd20f7851a0331c208aff1db83b8be32f9,COVID-19 risk perceptions of social interaction and essential activities and inequity in the United States: Results from a nationally representative survey,"A team of experts at Johns Hopkins Bloomberg School of Public Health collated COVID-19 questions from existing surveys and created new questions to address existing gaps in the literature. In a module on risk perception, the focus of this analysis, participants were presented with a series of thirteen activities related to social and essential activities and asked to respond to the question: ""How safe or unsafe do you think the following activities are in terms of your getting COVID-19 or giving it to someone else?"" Allowed responses included extremely safe, somewhat safe, somewhat unsafe, extremely unsafe, unsure, and prefer not to say. For the purpose of this analysis, we collapsed extremely and somewhat categories into perceptions of 'safe' and 'unsafe'.All analyses were adjusted for the study design using survey weights for race by Census region generated using the 2010 U.S. Census estimates. We assessed bivariate relationships between responses of safe, unsafe, and unsure and participant characteristics for each activity presenting percent change (absolute) and assessing significance using Pearson's chi-squared tests. We used multivariable logistic regression models to calculate unadjusted and adjusted odds ratios (OR and aOR) of perceiving each activity as unsafe and associated 95% confidence intervals (CIs).Participant demographic and socioeconomic characteristics included in multivariable models were age, gender, race/ethnicity, education, income, census region, and political affiliation. To assess differences in risk perceptions by age and race, we presented relationships overall and stratified by White/Caucasian, Black/African American, and Hispanic/Latino groups.Multivariable logistic regression models were also extended to include interaction terms for age and race and assessed for significance using Wald tests (p<0.05). Statistical analyses were conducted in Stata 16.1 (StataCorp, College Station, Texas, USA).Participants provided electronic consent to participate by responding to a question on the survey.The study received ethical approval from the Institutional Review Board at Johns Hopkins Bloomberg School of Public Health, Baltimore, USA.Perceptions of unsafe increased by >15% from the lowest to highest age categories for gathering of 10, gathering of 100, and going to church (all p<0.001), but decreased by a similar amount for going to the grocery store (p=0.015) ( Figure 2 ). Males were less likely to perceive these activities as unsafe, with significant differences (p<0.05), ranging from -3.3% to 7.4%, except gathering of 10. Perceptions differed by race only for gatherings of 10, highest among Hispanic/Latino (67.5%) and Asian/Pacific Islander respondents (67.1%) (p=0.011).Respondents with high education were less likely to perceive gathering of 100 as unsafe (p=0.024). Perceptions of unsafe decreased with increasing income (p<0.05), with differences between <$20,000 and ≥$100,000 categories ranging from -3.2% to -10.2%. Democrats and independents were more likely to perceive activities as unsafe for all variables compared to Republicans (p<0.001).In multivariable models ( Figure 3 and Supplementary Table 1 ) perception of unsafe increased with age for gathering of 10 (aOR=1.24 (95% CI: 1.14, 1.35)), gathering of 100 (aOR=1.38 (95% CI: 1.25, 1.52)), and going to church (aOR=1.18 (95% CI: 1.09, 1.28)) and decreased for going to the grocery store (aOR= 0.89 (95% CI: 0.82, 0.96)). Men were less likely to perceive activities as unsafe. Across income groups, there was a significant decrease in perception of unsafe with increasing income for gathering of 10 (aOR=0.86 (95% CI: 0.77, 0.96)) and going to the grocery store (aOR=0.83 (95% CI: 0.74, 0.92)). Democrats and independents were more likely to report activities as unsafe relative to Republicans.Perceptions of unsafe increased between lowest and highest age categories by >10% for dining indoor (p<0.001) and visiting friends indoor (p=0.001), and decreased, ranging from -3.1% to -10.1%, for visiting elderly relatives (p=0.039), visiting friends outdoor (p=0.001), and dining outdoor (p=0.006). Men were less likely to perceive activities as unsafe, with significant differences (p<0.05), ranging from -3.3% to -10.3%, except for visiting friends outdoor.Activities in this category varied by race, with White/Caucasian respondents generally less likely to perceive them as unsafe. Respondents with higher education were less likely to perceive dining outdoor as unsafe (p=0.040). Perceptions of unsafe decreased with increasing income (p<0.05) for most of these activities, ranging from -3.8% to -11.8%, except for visiting friends indoor. Democrats and independents were more likely to report activities as unsafe relative to Republicans (p<0.001).In multivariable models (Figure 4 ), risk perception across age groups increased significantly for dining indoor (aOR=1.12 (95% CI: 1.04, 1.21)) and visiting friends indoor (aOR=1.15 (95% CI:1.07, 1.24)). Men relative to women had lower odds of viewing these activities as unsafe, but this was only significant for visiting friends indoor. There was a significant decreasing trend across income groups for dining indoor (aOR=0.87 (95% CI: 0.78, 0.97)) and dining outdoor (aOR=0.87 (95% CI: 0.78, 0.96)) but not visiting friends in either setting. Compared to White/Caucasian respondents, Black/African American and Hispanic/Latino respondents were more likely to view dining outdoor and visiting friends outdoor as unsafe (Supplementary Figure   1 ). Democrats were more likely to view these activities as unsafe relative to Republicans. There was a statistically significant interaction between age and race for visiting an elderly relative (p=0.061) (Supplementary Table 2 ). The change in odds of perceiving visiting an elderly relative as unsafe for each 10-year increase in age was non-significant among White/Caucasian respondents (aOR=0.99 (95% CI: 0.89, 1.10)) and Hispanic/Latino respondents (aOR=1.11 (95% CI: 0.96, 1.29)) but significant among Black/African American respondents (aOR=1.35 (95% CI:1.15, 1.58)).Perceptions of unsafe decreased (-16.2% and -6.3%, respectively) between the lowest and highest age categories for doctor visits (p<0.001) and going to the emergency room (p=0.006), and increased (4.2%) for returning to work (p<0.001). Men were less likely to perceive these activities as unsafe, with significant differences (p<0.05) ranging from -5.9% to -10.5%. Dentist visits were the only activity for which risk perception significantly differed by race (p<0.001).higher education, with differences (p<0.05) between lowest and highest categories ranging from -5.2% to -6.9%. Respondents with higher income were less likely to perceive these activities as unsafe with a range of difference between the lowest and highest categories of -4.3% and -12.5% (p<0.05). Democrats and independents were more likely to report activities as unsafe relative to Republicans (p<0.001).In multivariable models ( Figure 5 ), a risk perception of unsafe across age groups decreased significantly for going to the doctor (aOR=0.84 (95% CI: 0.78, 0.91)) and emergency room (aOR=0.90 (95% CI: 0.84, 0.97)). Males were less likely to view going to the doctor, emergency room, and returning to work as unsafe. Compared to White/Caucasian respondents, Hispanic/Latino respondents were more likely to view going to the dentist or emergency room as unsafe. Respondents with higher income were less likely to view these activities as unsafe;trends across income groups were statistically significant for going to the doctor (aOR=0.84 (95% CI: 0.75, 0.94)), dentist (aOR=0.87 (95% CI: 0.78, 0.97)), and emergency room (aOR=0.86 (95% CI: 0.78, 0.96)). Democrats and independents were more likely to view activities as unsafe. There was a statistically significant interaction between age and race for returning to work (p=0.039). The change in odds of perceiving returning to work as unsafe for each 10-year increase in age was smallest for White/Caucasian respondents (aOR=1.13 (95% CI:1.00, 1.27)) followed by Hispanic/Latino respondents (aOR=1.21 (95% CI: 1.03, 1.42)) andBlack/African American respondents (aOR=1.31 (95% CI: 1.12, 1.52)).We conducted a nationally representative survey of the U.S. population to understand risk perceptions related to transmission of COVID-19 for social interaction and essential activities.Overall, risk perceptions ranged widely, but were higher for activities which have been shown to present increased risk for COVID-19 infection, particularly large gatherings and indoor activities, suggesting effective information dissemination to the public risk regarding COVID-19 risk factors. 13 Our results suggest that risk perceptions for age and race vary by the type of activity. Men were more likely to view activities as safe compared to women, a similar finding to a large survey in eight countries that found that women were more likely to perceive COVID-19 as a serious health problem and agree and comply with restrictive public policy interventions. 14 Individuals with higher income in our survey were more likely to view activities as safe, perhaps a result of facing fewer barriers to physical distancing. 15 This could also reflect wealth differentials in the experience of the pandemic, with increased COVID-19 transmission and case volumes in low-income and minority populations. 16 There were few differences by education.This study had limitations. Selection bias associated with online surveys is well established, for example, underrepresenting individuals who are older, without internet access, have lower income, and have less formal education; this effect is difficult to quantify, in either direction or magnitude, and may limit the generalizability of our results. However, the digital divide in internet access has shrunk over time. 25 Despite our large sample size, samples for strata of important participant characteristics, including certain racial and ethnic minorities, were too small to provide sufficient statistical power for our analyses; still, we had sufficient statistical power to examine racial and ethnic differences between Black/African American, Hispanic/Latino, and White/Caucasian groups, which very few studies have done. Our questionnaire did not collect data on some characteristics that could affect risk perceptions, including presence of underlying health conditions, type of employment, or whether the respondent knew someone who had been infected with COVID-19.Research Response Fund for their initial support in getting this project off the ground. Thank you also to Dr. Gregory Kirk for help in developing the initial project plan. Lastly, thank you to the Johnson & Johnson Foundation for supporting this research project.",United States,abstract,2021-02-02,02
f662cd4f517af2ad2f7c7f84e0689d3abe66230b,Journal Pre-proof Qualitative and quantitative DECT pulmonary angiography in COVID-19 pneumonia and pulmonary embolism Qualitative and quantitative DECT pulmonary angiography in COVID-19 pneumonia and pulmonary embolism,"infection [3] [4] [5] [6] [7] . Occlusions in the pulmonary arterial circulation are thought to be related to severe disease and higher mortality in COVID-19 infection [8] , although the exact causes for disease severity and host response remain unclear.It is also unclear if patients with COVID-19 pneumonia develop PE or in situ thrombi, and if imaging can differentiate between these two entities. Peripheral venous thrombosis was absent in most COVID-19 patients but these patients were diagnosed with PE [3] , raising the possibility of in situ thrombi in the pulmonary arterial circulation. Although prophylaxis and treatment of PE in patients with COVID-19 pneumonia is of increasing clinical interest, it is unclear if pulmonary arterial in situ thrombosis should be treated in a similar fashion to PE [3, 9] .To be detectable on computed tomography (CT), pulmonary arterial filling defects must extend beyond the pulmonary microcirculation to at least segmental or proximal subsegmental pulmonary arteries or lead to assessable changes in pulmonary perfusion [10] . Quantitative lung parenchymal perfusion (QPS) has been assessed in non-COVID-19 patients with PE using DECT pulmonary angiography (DECT-PA) perfusion maps and material decomposition iodine (MDI) images [11] . Recent publications in COVID-19 patients have described decreased perfusion in J o u r n a l P r e -p r o o f consolidative opacities surrounded by a ""hyperaemic halo"" of increased perfusion and dilated adjacent pulmonary arteries on DECT [12, 13] without a clear explanation for these findings. There is increasing evidence that DECT-PA can depict changes in pulmonary perfusion in the absence of visible PE and in situ thrombi [14, 15] . The present study assessed differences in qualitative and quantitative pulmonary perfusion from DECT-PA in patients with COVID-19 pneumonia with and without visible filling defects in the pulmonary arteries.The institutional review boards approved this retrospective study with a waiver of informed consent at both *** (site A) and ***(site B Two thoracic radiologists (*** and *** with 16 and 13 years of experience) reviewed Mono 40 keV and MDI images in consensus to assess COVID-19 pneumonia-related lung findings, filling defects in pulmonary arteries, and qualitative perfusion abnormalities. As the DS-DECT-PA MDI images segment the inflated lungs and J o u r n a l P r e -p r o o f exclude the opacified lungs, the 40 keV images were reviewed to assess contrast enhancement within regions of opacities to differentiate pulmonary opacities related to pneumonia and pulmonary infarction. Imaging findings and severity were assessed on 40 keV images to score severity and type of opacities. Based on prior publications [16, 17] , the COVID-19 pneumonia-related findings were graded separately in each of the five lung lobes for extent (0, no pulmonary opacity; 1, opacities involving <5% lobar volume; 2, 5-25% lobar involvement; 3, 26-50% lobar involvement; 4, 51-75% lobar involvement; 5, >76% lobar involvement) and type of opacities (1, ground-glass opacities 2, consolidation or mixed opacities such as ground-glass opacities with consolidation, interlobular septal thickening or nodules).For each lobe, the extent and type of pulmonary opacities were added to obtain lobar involvement scores (maximum score of 5). The entire lung severity score was obtained by adding lobar scores for all the five lobes (maximum score of 35). Also, contrast enhancement (from Mono 40 keV) and iodine uptake (from MDI) in regions of pulmonary opacities was recorded (as decreased, increased, or variable relative to the adjacent normal lung). Radiologists could adjust the window levels and widths at their discretion.Both radiologists assessed pulmonary arterial filling defects for location (from main pulmonary trunk to subsegmental arteries) and degree of occlusion (occlusive, nonocclusive). The number (one score for each positive pulmonary arterial filling defect) of pulmonary arterial filling defects was recorded. The presence of focal or diffuse dilatation, narrowing, wall thickening, and irregularity of pulmonary arteries and veins was also recorded. The presence and type of opacities (normal lung parenchyma, A p-value of <0.05 was considered a statistically significant difference.There were 74 adult patients with COVID-19 pneumonia (age range 21-96 years; mean age 61±18 years; 40 females and 34 males). At the time of DECT-PA, 54%(40/74) were on anticoagulants (heparin, warfarin, rivaroxaban, or enoxaparin) as part of their standard of care treatment, 45% were admitted for ≥10 days (33/74), 59% had SpO 2 of <90% (44/74), and 22% were intubated (16/74). The mortality rate in this group was 14% (10/74; Table 1 ).Lung parenchymal assessment and severity scores The deceased patients and patients with low SpO2 had significant differences in J o u r n a l P r e -p r o o f these QPS features compared to survivors and those with high SpO 2 (p<0.05; Table   3 ) but was also associated with AUC (<0.68) suggestive of significant overlap in perfusion statistics within the groups. [2] . These findings support observations that decreased QPS was noticed in patients without pulmonary arterial filling defects and was associated with severe diseases such as consolidation and mixed opacities.Lower kurtosis was noted in patients with adverse outcomes (disease survival, shorter hospital admission duration, and normal SpO 2 ) as opposed to those with favourable outcomes. Lower kurtosis implies lower probability of extreme values and a wider spread of values around the mean of distribution. With more severe disease, such as with cor pulmonale or increased pulmonary vascular resistance, there is greater lung involvement with denser opacities (consolidation) and fewer regions with normal lung parenchyma. These findings in turn decrease the probability of extreme attenuation and iodine values, which was likely responsible for a smaller kurtosis value in patients with adverse outcomes. A recent study reported that pulmonary perfusion defects on DECT-PA were not related to increased pulmonary vascular resistance or cor pulmonale [15] .Like DS-DECT-PA MDI images, the QPS software segments the inflated, nonopacified portion of the lungs and quantifies iodine distribution in those portions only.Thus, any portion of the lungs with dense pulmonary opacities, such as from consolidation, atelectasis, and pulmonary infarctions, are excluded from estimation of QPS features. The QPS software will therefore show decreased iodine distribution in the presence of ischaemic loss of perfusion (from pulmonary emboli, perfusion defects with and without pulmonary infarction) and from exclusion of opacified pulmonary parenchyma from any non-ischaemic process (Fig. 5) . In both instances, the overall estimated lung perfusion from QPS will decrease, and therefore, QPS can were found that could have favoured thrombosis in situ rather than an embolic cause.Although the lack of specific findings does not exclude in situ pulmonary thrombosis, DECT-PA differentiation of in situ thrombosis from PE is limited. The presence of mixed or consolidative opacities adjacent to most pulmonary arterial filling defects (12/25 patients, 80%) could suggest diffuse or advanced pneumonia in these patients or an increased thrombogenic potential of these opacities compared to pure ground-glass opacities.The qualitative interpretation of MDI for iodine is subject to errors due to variability in scanner type and image reconstruction techniques. The pure ground-glass opacities tend to have a higher qualitative perfusion irrespective of location in both SS-DECT and DS-DECT scanners. The qualitative hyperperfusion in ground-glass opacities on MDI images was likely a perception issue as there was no significant difference in QPS between ground-glass opacities and normal lung parenchyma (p=0.73). This perception issue may be related to the fact that the ground-glass opacities have low negative attenuation values (often well below -300 HU). Such low CT number implies that ground-glass opacities will not be excluded from MDI images, and thus, give a visual appearance of increased perfusion without a measurable increase in iodine content. To the authors' best knowledge, the exclusion of ground-glass opacities from processed MDI images has not been reported and underscores the importance of quantitative measurement of values on MDI images, which are typically acquired by subtracting water from iodine and will not visualise lesions with attenuation less than that of water (ground-glass opacities). In contrast, whereas consolidative opacities tend to have increased or heterogeneous iodine distribution in SS-DECT-PA and decreased iodine distribution in DS-DECT-PA. These differences were likely related to differences in how the vendors approach dual-energy image or data processing for generating MDI images or based perception of MDI images by the radiologists. The MDI images from DS-DECT-PA datasets identify the air attenuation portions of the lungs and exclude regions with higher attenuation, such as consolidation, which makes the latter appear hypoperfused. Although lung regions with higher attenuation, such as consolidation, can be included in the MDI images by changing the maximum threshold in the image processing software, we did not change the default threshold as it alters the image appearance and makes them less J o u r n a l P r e -p r o o f sensitive for detection of true ischaemia-related perfusion defects. Conversely, the MDI images from SS-DECT-PA does not isolate air-attenuation lungs and includes regions of consolidation; the latter could be therefore assessed qualitatively with increased or heterogeneous perfusion on MDI images. Previous studies have also reported differences in appearance of DECT-PA images between different vendors [19] . Therefore, the increased iodine distribution noted in ground glass halo around consolidation in DS-DECT-PA does not necessarily imply ""hyperaemic halo"" [12, 13] .Similarly, the findings of dilated pulmonary arteries and increased subpleural vessels ",USA,first author,2021-02-25,02
9cfc64babb86510060fdbcd3331b3724837b1f9f,The potential of rapalogs to enhance resilience against SARS-CoV-2 infection and reduce the severity of COVID-19,"The first case of infection caused by severe acute respiratory coronavirus 2 (SARS-CoV-2) was reported in Wuhan, China, in December, 2019. On March 11, 2020, WHO declared COVID-19 a global pandemic. Since then, COVID-19 has affected the lives of billions of people; as of December, 2020, it is estimated that nearly 65 million people have been infected with and 1·8 million have died of COVID-19. After the rate of new infections and deaths plateaued after the first wave, the infection incidence is currently rapidly increasing again, as are concerns regarding the ongoing second wave and potential further waves, and the long-term effects following infection and recovery. Globally, we are observing geographical redistribution of hotspots and are faced with the distinct possibility that outbreaks could reoccur not only in the months, but perhaps years ahead.Similar to other viral infections, such as influenza, older people (eg, ≥65 years) are at a substantially increased risk of suffering adverse outcomes from COVID-19. 1 Although it remains too early to know the extent to which age affects the risk of initial infection, it is clear that age is by far the greatest risk factor for severe COVID-19 complications and death. Data from the US Centers for Disease Control and Prevention reveal that the risk of dying from COVID-19 increases approximately 10-fold for every 20 years of age. 2 This association between age and risk of COVID-19 mortality is comparable with the relationship between age and risk of death from Alzheimer's disease. 3 We have postulated that the relationship between chronological age and COVID-19 mortality is driven primarily by the biological mechanisms of ageing, 2 a concept which has recently become more widely appreciated among clinicians and researchers. 4 At the cellular and molecular levels, these mechanisms have been described as the hallmarks 5 or pillars 6 of ageing. Previous research has revealed that these hallmarks can be directly linked to the age-associated loss of immune function concomitant with increases in systemic inflam m ation (also referred to as inflammaging). 7 Inflammaging can been seen in the form of aberrant acti vation of innate immune mech anisms, such as elevation of pro-inflammatory cytokines and increased numbers of natural killer cells, 8 with such activation exacerbating the increased risk of viral and bacterial infections that are associated with age. Impairment of immune function could also contribute to additional age-associated problems, including in creased prevalence of auto immune disorders and increased risk for numerous types of cancer due to impaired immune surveillance. 9, 10 The immune system loses efficacy with age. 9 Immunosenescence affects both innate and acquired immunity and greatly reduces the production of naive T-cells and B-cells in the thymus and bone marrow. Consequently, decreased antibody production leads to fewer T cell and B cell interactions, and a reduced release of thyroid hormones, thus leading to decreased natural killer cell activity and a functional decline in the body's ability to mount an immune response. 7 Older people are known to have a chronic low-threshold proinflammatory status along with elevated plasma markers (eg, interleukin-6, tumour necrosis factor-α, and C-reactive protein) in the absence of clinical symptoms. 8 On a cellular level, this translates to enhanced inflammatory activity, especially in monocytes and macro phages (ie, the innate immune system) that work to reciprocally enforce the ongoing inflammaging processes. 9 The collective outcome is a compromised immune response and an increased incidence of inflammatory comorbidities-eg, cancers and age-related neuro degeneration, which further weaken the immune system. [10] [11] [12] [13] The innate immune system, which is primarily involved in the response to new infections, is also compromised due to a reduction in clonal diversity. 14 This reciprocal relationship between inflam maging and immuno senescence is believed to underlie the adaptive processes, which exacerbates the severity of symptoms in older individuals who tend to exhibit an enhanced susceptibility towards infections along with a dimin ished response to vaccines. [15] [16] [17] Therefore, we and others propose that novel and effective strategies for combating COVID-19 can be developed by directly targeting the hallmarks of ageing to prevent or diminish inflammaging and immuno senescence. 2,11,12 e106 www.thelancet.com/healthy-longevity Vol 2 February 2021Studies investigating the mechanistic target of rapamycin (mTOR) pathway have shown that immunosenescence can be reversed by targeting biological ageing. 13, 14 The mTOR protein is a nutrient-responsive and stressresponsive kinase that functions as a conserved regulator of ageing in eukaryotes. 14, 15 Activation of mTOR promotes development and growth, 16, 17 whereas genetic inhibition of mTOR increases lifespan in yeast, 18, 19 nema todes, 20 fruit flies, 21 and mice. 22 The mTOR kinase acts in two distinct protein complexes: mTOR complex 1 (mTORC1) and mTOR complex 2 (mTORC2). 23 In the context of biological ageing, inhibition of mTORC1 is consistently associated with increased lifespan, whereas inhibition of mTORC2 is associated with reduced life span, at least in mice. 24 mTORC1 regulates several key homoeostatic processes including autophagy, mRNA trans lation, and metabolism, each of which affects the hallmarks of ageing and, therefore, the lifespan of different model organisms. 25 The macrolide antibiotic rapamycin (sirolimus) is an allosteric inhibitor of mTORC1 that acts by binding to the FK506 binding protein (FKBP12). [26] [27] [28] Similar to genetic inhibition of mTORC1, rapamycin has been shown to increase lifespan in yeast, 19 nematode worms, 29 fruit flies, 30 and mice. 31 The effects of rapamycin on lifespan have shown to be robust in mice, with lifespan extension being reported in multiple strain backgrounds across a broad dose range, involving both oral delivery and intraperitoneal injection. [31] [32] [33] [34] [35] [36] [37] [38] [39] [40] [41] Lifespan extension is com parable when treatment is initi ated at young age, 41 in mid-life, 31 or transiently in late life. 40 Intermittent treatment with rapamycin in late life has also been shown to be effective at extending lifespan. 42 Importantly, the effects of rapamycin extend beyond increasing lifespan in mice, with evidence of reduction in hallmarks of ageing. These effects include fewer age-related cancers, 32,43 protection against cognitive decline, 44,45 improved cardiovascular function, 46-48 restoration of immune function, 49 and im proved renal function, 50 oral health, 51,52 intestinal function and reduced gut dysbiosis, 40, 53 and preserved ovarian function. 54 Other pharmacological inhibitors of mTOR have been described but there is relatively little data on their effects on lifespan or health during ageing. In general, existing mTOR inhibitors can be classified into three categories: rapamycin derivatives (rapalogs), other mTORC1-specific inhibitors not structurally related to rapamycin, and ATPcompetitive inhibitors of mTOR. Rapalogs and other mTORC1-specific inhibitors are generally predicted to function similarly to rapamycin in enhancing lifespan and improving age-related phenotypes; 55 however, only everolimus (known as RAD001) has been studied in this context. The evidence supporting geroprotective effects from everolimus include improved muscle function during ageing in rats 50 and improved immune function in healthy older people. 56,57 ATP-competitive inhibitors, which inhibit mTORC1 and mTORC2, usually have off-target effects on other kinases. 58 Examples of ATP-competitive inhibitors of mTOR include Torin 1, Torin 2, and the PI3K/mTOR dual kinase inhibitors such as dactolisib (known as BEZ235 or RTB101). [59] [60] [61] To our knowledge, there are scarce data supporting the positive effects of ATP-competitive mTOR inhibitors on lifespan in any research done in animals and only rapamycin has been shown to increase lifespan in mice.Although rapamycin and rapalogs have usually been considered immuno suppressives, multiple studies have shown that rapalog monotherapy is sufficient to reverse age-related declines in immune function in mice and people. One of the first studies to show the effectiveness of rapalogs was done using research done in mice that investigated age-related immune senescence. 49 In that study, aged mice (aged 22-24 months) were treated with either rapamycin or a vehicle control for a period of 6 weeks. After a 2-week washout period, mice in each group were immunised against H1N1 influenza. 2 weeks later, both groups were challenged with live H1N1 and their survival was quantified. When compared with young immunised mice (aged 2 months), the aged mice that did not receive rapamycin showed a substantial reduction in response to the vaccine, with approximately two-thirds of the mice failing to mount an immune response and dying within 10 days of H1N1 challenge. 49 By contrast, aged mice that received rapamycin exhibited improved immune function, with all of the rapamycintreated mice responding to the vaccine and surviving the subsequent H1N1 challenge past the endpoint of the experiment. This functional rejuvenation was associated with a decrease in senescence markers in haematopoietic stem cells along with improved stem-cell function, 49 although the precise mechanism of action remains to be established.This preclinical work spurred efforts to assess whether similar outcomes would be seen in a clinical setting. Two phase 2 clinical trials have been completed in which older healthy adults were treated with everolimus alone 56 or everolimus combined with RTB10157 for 6 weeks. Both studies were randomised, placebo-controlled and found that patients who were given the rapalog showed improved responses to influenza vaccine when compared with those who received the placebo only. In the study using a combined treatment, 57 patients who received everolimus plus RTB101 also had fewer infections over the following year, suggesting that the immune-boosting effect might extend beyond the initial vaccine response. Enhanced autophagy because of mTOR inhibition along with increased expression of anti-viral proteins have been proposed as potential mechanisms of action for the observed immune-boosting effects in people. However, a subsequent phase 3 clinical trial using RTB101 alone did not meet its endpoint.www.thelancet.com/healthy-longevity Vol 2 February 2021 e107The observation that immune function can be improved over a period of several weeks to months following a single 6-week interval of mTORC1 inhibition has important clinical implications. Influenza alone is estimated to result in 300 000 to 500 000 deaths annually, with older individuals at highest risk. 62, 63 Improving vaccine response among this susceptible population could substantially enhance preven tive measures and reduce severe clinical outcomes. A transient treatment regimen is also likely to be more easily adopted across large cohorts and have substantially fewer adverse effects compared with chronic high-dose regimens adopted by organ transplant patients. Indeed, no clinically significant adverse events were noted in either of the phase 2 mTOR inhibitor trials, 56, 57 and there is growing evidence that low-dose rapalog monotherapy has minimal side-effects in healthy older adults. 64, 65 These findings are further supported by the absence of observed side-effects in non-human primate marmosets 66 and in older companion dogs 67,68 treated with lower doses of rapamycin.A restoration of immune function in older adults is likely to have benefits that extend beyond simply boosting the response to an influenza vaccine. Before COVID-19, respiratory infections were estimated to account for more than 1 million deaths in adults older than 70 years and more than 2 million deaths in people of all ages annually worldwide, 69 numbers that were much higher in 2020. Additionally, it is expected that enhanced immune function would lead to reduced rates of age-associated cancers, as immune surveillance is known to be a crucial anti-cancer mechanism that is impaired by the aging process. 10 Reversion of agerelated changes in the micro biome could also be expected following mTOR inhibition, as the immune system plays an important role in maintaining a healthy microbiome. 70 Rapamycin has been found to reduce age-related cancers 32, 41 and modify the aged microbiome in mice, 40, 51 although it remains to be established whether these effects are mediated by the immune system.The most important consideration for any clinical intervention is to evaluate the potential benefit against the potential risk. This evaluation is always challenging to quantify but is even more difficult for a preventive treat ment that is given to individuals who are not currently sick. As discussed, the potential benefits of preventing immunosenescence in older people are quite large and include reductions in morbidity and mortality from infectious disease and cancer. Regarding COVID-19, extrapolation from preclinical studies suggests that the immune restorative properties of rapamycin might be expected to reduce COVID-19 deaths substantially in the absence of a vaccine 2 and possibly by an even greater amount once a vaccine is widely available.Because there are abundant clinical data on rapamycin use, we can also predict the potential risks. Rapamycin and other rapalogs (ie, everolimus, temsirolimus) have been widely used to prevent organ transplant rejection but are also approved for use in lymphangioleio myomatosis, coronary stenting, and particular types of cancer (eg, hormone receptor positive breast cancer or neuroendocrine tumours. 71, 72 Use of high-dose rapamycin (>15-25mg/kg) by organ transplant patients is associated with numerous side-effects including general ised pain (≥30% occur rence, leading to a 5% treatment dis con tinuation rate), headache, fever, hypertension, nausea, abdominal pain, constipation, diarrhoea, urinary tract infection, peri pheral oedema, anaemia, arthralgia, thrombo cytopenia, hyper cholesterolaemia, hypertri glyceridemia, and in creased creatinine. 73 Personal View medications. Risk of serious complications, even from acute overdose with rapamycin, is extremely low. 75 For this reason, we believe that short-term treatment (up to a few months) with low doses (eg, a range of 5-10mg weekly) of rapamycin will have minimal adverse events and that the risk-reward ratio strongly favours the potential beneficial effects from treatment. To our knowledge, there are no active or planned clinical trials of rapamycin or rapalogs as a preventive treatment for COVID-19. As of November, 2020, there were 214 incomplete clinical trials registered on ClinicalTrials.gov, identified using the search term ""rapamycin"" or ""sirolimus""; five of these trials are related to . In each of the existing or planned trials, rapamycin is being tested as a treatment in hospitalised patients with confirmed COVID-19, with primary endpoints such as the change in SARS-CoV-2 viral burden and time to clinical recovery. Thus, the rationale for potential efficacy in these trials, based on the ability of rapamycin to prevent the cytokine storm seen in patients with severe COVID-19 76, 77 or its potential direct anti-viral effects 78 , is quite different from the effects of rapamycin on biological ageing. The biopharmaceutical company resTORbio (Boston, MA, USA) initiated a small clinical trial of RTB101 in nursing home residents, to determine whether COVID-19 severity is affected by the drug (table). The US Food and Drug Administration (FDA)-approved endpoint for this trial is ""the percentage of subjects who develop laboratory-confirmed COVID-19 with protocol-defined progressive symptoms or are hospitalized or die through four weeks of study drug treatment"". 79 Although there is supportive data from a phase 2 study 57 suggesting that everolimus plus RTB101 can improve immune function in older people, RTB101 acts by a different biochemical mechanism from rapamycin and has not yet been shown preclinically to have effects on biological ageing. 58 Thus, although we are hopeful that these ongoing clinical trials will prove successful, none of them address the possibility that rapamycin will rejuvenate immune function in older people and afford protection against COVID-19 to the most susceptible individuals.We strongly advocate for a large-scale clinical trial in atrisk populations to test for prevention of COVID-19 by rapamycin. The rationale for such a trial is provided by the observed ability of rapamycin and rapalogs to reverse age-related declines in immune function in preclinical models and in people. Older patients have substantially worse clinical outcomes following COVID-19 infection, and pre ventive treatment with rapamycin is predicted to reduce rates of infection and improve clinical outcomes by reducing the number and severity of com plications in biologically aged patients. Based on research done in mice, we hypothesise that rapamycin will restore immune function corres ponding to approxi mately 20 years of biological age, thereby reducing severe outcomes and death from COVID-19 by approxi mately 4-10-times. Furthermore, enhanced immune function following rapamycin treatment is expected to improve the response to the COVID-19 vaccines and provide ongoing protection against other infections that preferentially affect older people.The details of a well designed randomised clinical trial would need to be carefully considered, including the dose of rapamycin, duration of treatment, demographic features of the patients enrolled in the study, specific endpoints to be evaluated, the duration of follow-up, and necessary cohort sizes to reach statistical power (panel, appendix). Although the simplest study design would include only placebo and rapamycin treatment groups, a multi-arm design that is worth exploring could include additional treatment with metformin. Metformin is the most widely used antidiabetes drug globally and is being tested for beneficial effects on ageing through the Targeting Aging with Metformin global study. 80 The preclinical evidence that metformin can positively affect the aged immune system is less robust than that for rapamycin; however, there is accumulating evidence that people with diabetes taking metformin are at reduced risk of severe outcomes or death from COVID-19 compared with people with diabetes not taking metformin. 81 Furthermore, metformin combined with rapamycin in mice is thought to improve metabolic function and slightly further increase lifespan, relative to rapamycin alone. 82 One innovative feature that we suggest should be incorporated into a trial is the consideration of predicted biological age as an enrolment criterion. Enrolment based on chronological age is common in clinical Panel: Initial recommendations for a clinical trial assessing the effects of rapamycin on COVID-19 outcomes and vaccine response General design An ideal design is a double masked and placebo-controlled randomised controlled trial.We suggest enrolling older adults (eg, ≥60 years) who are predicted to have a biological age that is at least 5 years older than their chronological age.Would be determined based on predicted infection rate and progression to severe outcomes. Several thousand people per study group would probably be needed.Dose 5-10 mg rapamycin orally provided once per week.Duration 6-10 weeks treatment with 8-10 months follow-up.Previous COVID-19 infection, immune compromised, or active infection.Rates of COVID-19 infection, severity of outcomes (eg, hospitalisation, death), vaccine response (if available).www.thelancet.com/healthy-longevity Vol 2 February 2021 e109 Personal View studies, similar to the design of the rapalog trials that investigated influenza vaccine response. 56, 57 However, we propose that it could be useful to consider newly developed measures of predicted biological age for geroprotective clinical trials. Such biological age predictors could include estimates of epigenetic age using commonly applied epigenetic clocks 83 and so-called deep ageing clocks, 84 based on signatures derived from blood biochemistry, imaging, transcriptomics, and other types of available data. Patients whose biological age exceeds their chronological age by a chosen threshold (eg, 5 years) could be enrolled, thus targeting individuals at the highest risk for negative outcomes and death and who are predicted to receive the greatest benefit from a geroprotective intervention such as rapamycin. Although we recognise that the mechanisms and predictive power of current biological age estimators have yet to be clinically validated and could present unique challenges from a regulatory perspective, there is growing consensus among researchers investigating artificial intelligence and ageing that these tools can provide valuable insights into underlying physiological states that affect risk for age-related diseases and for allcause mortality. However, they could be used as auxiliary markers until clinical validation in COVID-19 has been achieved.A final consideration might be whether, even once shown to be efficacious, widespread use of a geroprotective intervention is economically feasible or justified, given the strain on many national health-care systems. Because there is more than one COVID-19 vaccine available, there is a danger that the incentive to continue to develop novel preventive therapies will decrease. However, influenza deaths still number in the hundreds of thousands each year even with effective vaccines, and those most susceptible to severe cases of both COVID-19 and influenza are also the least likely to mount an effective vaccine response. Thus, from the perspective of cost in terms of human lives, justification for this type of approach is obvious. It is also well established that the total economic benefit from a successful geroprotective therapy far outweighs the cost of development and implementation. Work from Goldman 85 and Olshansky 86 done before the COVID-19 pandemic has estimated that the total economic benefit from such an intervention will exceed US$7 trillion over the next 3-4 decades. The total economic value of an effective geroprotective strategy is likely to be substantially greater today than before the pandemic.SARS-CoV-2 disproportionately affects older people and people with comorbidities, with likelihood of severe complications and death mirroring that of other ageassociated diseases. Inhibition of mTOR has been shown to delay or reverse many age-related phenotypes, including declining immune function. There is an urgent need for a precision medicine trial using a functional metric of ageing that investigates individuals assessed by biological age, who can then be further stratified into groups of those individuals who achieve optimal outcomes and benefit from the treatment. Rapamycin and rapamycin derivatives (rapalogs) are FDA-approved inhibitors of mTOR with broad clinical utility and well established dosing and safety profiles. Based on pre-clinical and clinical evidence, a strong case can be made for immediate large-scale clinical trials to assess whether rapamycin and other mTOR inhibitors can enhance resilience towards communicable and noncommunicable diseases, prevent COVID-19 infection in those most at risk, and improve outcomes in patients with COVID-19.We searched for articles, reviews, and clinical trials published in English between Jan 1, 2000, and Nov 30, 2020, using online databases PubMed, National Center for Biotechnology Information, ClinicalTrials.gov, and the US National Library of Medicine. The keywords used were ""COVID-19"", ""rapamycin"", ""mTOR"", ""ageing"", ""inflammation"" and ""geroprotection"". The reference list was generated on the basis of novelty and relevance to the scope of this Personal View. COVID-19 statistics were from Worldometer.For the Worldometer statistics on COVID-19 see https://www. worldometers.info/coronavirus",USA,first author,2021-02-03,02
7228b6e3431b015660a36df04aee9763b0be5c2a,Evaluation of Analytical Performance of Seven Rapid Antigen Detection Kits for Detection of SARS-CoV-2 Virus,"Since COVID-19 was declared a global pandemic, the goal of the medical community has been to offer rapid, massive, and affordable testing. To meet this goal, several assays have been developed and are in use in clinical practice. These assays can be broadly categorized based on the testing methodology used for the detection of SARS-CoV-2. These include antibody testing, antigen testing, and molecular testing. [1] [2] [3] Antibody testing (serology testing) is used for the detection of antibodies to SARS-CoV-2 in blood or serum. It can be total antibodies against the virus or its specific subtypes -IgA, IgG, and IgM. Antigen testing is based on immunoassay, mostly immunoblot technology for the detection of SARS-CoV-2 antigen in the nasopharyngeal or oropharyngeal swab specimens, whereas molecular testing is designed to detect SARS-CoV-2 viral nucleic acid (RNA) using the Nucleic Acid Amplification Test (NAAT). 4 There is no doubt that widespread testing for containing the virus and getting the pandemic under control is critical. As the majority of individuals with COVID-19 are asymptomatic or show mild symptoms, laboratory confirmation of SARS-CoV-2 infection is crucial. 5 The appropriate test and timing for sampling is also another critical factor for the accurate diagnosis of COVID-19. Numerous tools are readily available for healthcare professionals for guidance on testing. One such tool, Medical Database (MD), a guide developed to assist healthcare professionals, recommends that a molecular test should be used as the gold standard for a diagnostic test to detect the SARS-CoV -2 virus and IgG antibody testing should be used for evaluating the immune response after the infection subsides. 6 Accordingly, IgA and IgM antibody testing have no diagnostic value but can be used for the evaluation of severity of disease/infection. Molecular testing for the detection of viral RNA is currently the most widely used diagnostic test. These molecular assays used to diagnose SARS-CoV-2 are designed to amplify and detect specific target viral genes and regions including the spike (S), envelope (E), and nucleocapsid (N) proteins which represent three of the four proteins that structurally constitute the virus as well as the RNA dependent RNA polymerase (RdRp) gene and the Open Reading Frame 1ab (ORF1ab) region. 7 Although lower respiratory tract specimens generally have a higher positivity rate, upper respiratory specimens like nasopharyngeal or oropharyngeal swabs are most widely used as the specimen of choice. 8 These molecular tests can detect the viral nucleic acid within 1-3 days of exposure or infection, and can be used for early identification of asymptomatic patients. 9 Unfortunately, these tests are expensive, and require complex technology and well-trained testing personnel. There is also an issue of turnaround time which may take as long as a few days. To achieve the urgent need for massive testing to control this pandemic, there is a need for an alternative assay which is high-throughput, rapid, simple, and economic. Furthermore, 60% of clinical laboratories around the globe are currently facing supply chain problems with appropriate reagent test kits and consumables. 10 To mitigate the drawbacks of molecular testing, viral protein antigen testing of respiratory samples by immunoassay can be a promising alternative. Such antigen-based testing has been recently endorsed by the US Centers for Disease Control and Prevention (CDC) and interim guidance for its use has been formulated by the WHO. 11 Many companies have come up with a rapid antigen test as laboratory-based tests and point-of-care tests. To this date (December 7, 2020) only seven of them have been approved by the US FDA under Emergency Use Authorizations (EUA). These antigendetecting rapid diagnostic tests (Ag-RDT) are based on lateral flow immunochromatographic assay for the detection of nucleocapsid protein antigens specific to SARS-CoV-2. Although such antigen tests offer widespread rapid testing without the need of expensive laboratories, it is very important to understand the analytical sensitivity of these rapid antigen tests. Unfortunately, there is limited information available on the analytical and clinical performance of antigen testing. More studies are required to evaluate the sensitivity and specificity of antigen testing before implementing this assay effectively. In this study, we evaluated the analytical sensitivity of SARS-CoV-2 rapid antigen tests developed by seven IVD companies, of which three are FDA EUA approved, by comparing it to the gold standard molecular assay.Oropharyngeal swabs were collected from five COVID-19 patients confirmed positive by SARS-CoV-2 RT-PCR assay. The swabs were collected in universal transport media (UTM) (BD Diagnostics, Sparks, MD, USA) and appropriately stored. A schematic diagram of the study methodology is illustrated in Figure 1 . Written informed consent was obtained from each patient and the study protocol was approved by the Institutional Ethical Board of UltimateDx Laboratories in agreement with the World Medical Association Declaration of Helsinki.The confirmation of the positivity was done by NAAT as recommended by CDC and WHO. 7 Briefly, viral RNA was extracted using RNA extraction kit (Thermofisher submit your manuscript | www.dovepress.comInternational Journal of General Medicine 2021:14 Scientific) and tested immediately or stored at −70°C. Real-time fluorescent reverse-transcription polymerase chain reaction (RT-PCR) was performed to identify SARS-CoV-2 (BGI Biotechnology Co., Ltd, Wuhan, Hubei Province, PRC). The cycle threshold (Ct) value of the positive samples ranged from 15 to 35. Estimation of approximate viral load based on Ct values was done by performing RT-PCR in serially diluted FDA proficiency samples. The samples were serially diluted to produce final concentrations ranging from 1.8x10 7 to 1.8x10 2 and analyzed by RT-PCR in triplicate.Antigen tests from seven IVD manufacturers were used to evaluate the analytical and clinical performance. These included: 1) BD Veritor™ System for rapid detection of SARS-CoV-2 (Becton, Dickinson and Company, Maryland, USA; Antigen kit #1), 2) CareStart™ COVID-19 Antigen (Accesas Bio, Inc., NJ, USA; Antigen kit #2), 3) SG Diagnostics Antigen detection kit (SG Diagnostics, Singapore; Antigen kit #3), 4) Sofia SARS Antigen FIA (Quedel Corporation, Hannover, Germany; Antigen kit #4), 5) Rapid Response™ COVID-19 Antigen Rapid Test (BNTX, Inc., ON, Canada; Antigen kit #5), 6) Shenzhen SARS-CoV-2 Antigen Test kit (Shenzhen Ultra-Diagnostics Biotec. Co., Ltd, Shenzhen, PRC; Antigen kit #6), and 7) Genedia W COVID-19 Ag (Green Cross Medical Sciences Corp, Chungcheongbuk, Republic of Korea; Antigen kit #7). Of these test kits, Antigen kit #1, #2, and #4 have been approved by the FDA under EUA. Antigen kit #4 was the first to receive the EUA and is based on lateral flow immunofluorescent sandwich assay. Specimen collection and testing were done using a method that we previously validated. 12 Briefly, the pellet collected by high-speed centrifugation from 200 µL of UTM from each positive sample was reconstituted with extraction buffer provided by each antigen kit to disrupt viral particles and expose nucleocapsid proteins. Two to three drops (approx. 80 µL) of extracted swab sample is then applied to the test devices and the results were read and interpreted as per instruction manual of IVD manufacturers.For analytical performance, heat-inactivated SARS-CoV-2 (ATCC ® VR-1986HK™) was spiked to 500 µL of extraction fluid (assay buffer) provided by each test kit in order to give a final viral concentration of 4.6x10 4 /mL, 9.5x10 4 /mL, Figure 1 Outline of study methodology. Swab was collected in universal transport medium. RT-PCR was done to identify targeted SARS-CoV-2 specific genes. The viral nucleocapsid protein were extracted and applied to a rapid antigen test device.International Journal of General Medicine 2021:14 submit your manuscript | www.dovepress.com DovePress 1.85x10 5 /mL, 3.75x10 5 /mL, and 7.5x10 5 /mL. Three drops (approx. 80 µL) of the spiked assay buffer were applied per test kit and the results were noted as recommended by the instruction manual of the IVD manufacturers. The approximate viral concentration per reaction were 3,750, 7,500, 15,000, 30,000, and 60,000, respectively.The analytical performance of seven Ag-RDT kits were evaluated by analyzing five RT-PCR positive specimens. Surprisingly, all the specimens showed a negative result by all seven Ag-RDT except Antigen kit #6. When tested with Antigen kit #6, only one specimen gave a positive test result ( Table 1 ). The Ct value of the specimen that showed the positive result was 15. All other specimens with a Ct value above 19 were negative for antigen testing. This indicates that antigen testing is far less sensitive than RT-PCR. To estimate the viral load from Ct value, we tested serially diluted FDA proficiency samples by RT-PCR. Limit of detection (LOD) of RT-PCR assay was 1.8x10 4 viral particles/mL which was detected in all triplicate runs with a Ct value ranging from 35-36 (Table 2) . Ct values of 24-25 have an approximate viral concentration of 1.8x10 7 /mL. As only one sample with a Ct value of 15-19 was positive for Ag-RDT, our result suggests that Ag-RDT are effective only when the viral load in the specimen is over 1.8x10 7 /mL.To assess the sensitivity of Ag-RDT, various concentrations of heat-inactivated SARS-CoV-2 were analyzed with antigen testing. Heat-inactivated SARS-CoV-2 were spiked into extraction buffer provided by IVD manufacturer to get a final concentration ranging from 4.6x10 4 /mL to 7.5x10 5 /mL. None of these samples were positive for all Ag-RDT (Table 3 ). This further supports that analytical sensitivity and LOD of Ag-RDT were poor and are suitable for use only when the viral load in the specimen is very high, as often seen in the patients with severe COVID-19 disease.Although Ag-RDT have diagnostic value comparable to antibody testing and are economic, rapid, and feasible for widespread testing in both laboratory and non-laboratory settings, it has poor clinical performance compared to the gold standard molecular assays. As global cases of COVID-19 continue to rise, it is expected that more IVD manufacturers will come up with Ag-RDT and more clinical laboratories will be using it to meet the testing demands. However, proper clinical evaluation of such antigen-based tests is crucial to add diagnostic value of Ag-RDT. Currently, there are a limited number of studies that provide the comparison of analytical and clinical sensitivity of Ag-RDT. Although done in small number of samples, our results of the comparison of seven Ag-RDT provides valuable information on its limitations and should help guide clinical laboratories and public health officials for the appropriate selection of diagnostic tests for COVID-19. Rapid immunochromatography-based tests have been widely used in clinical laboratories for the diagnosis of a wide variety of infectious diseases. The major problems with these immunoassay tests are, unlike PCR-based assay which allows amplification of targeted gene to greatly enhance its sensitivity, Ag-RDT are limited to the amount of antigens in the sample.Although Ag-RDT has high specificity, many researchers have questioned its clinical utility because of its low sensitivity. Our result shows that Ag-RDT are unable to detect SARS-CoV-2 when the viral load in the sample is less than 1.8x10 7 /mL and a Ct value more than 19. Systemic review on Ag-RDT showed that its clinical sensitivity is acceptable only when the viral loads are high with a Ct value below 25. 13 Our result of low sensitivity of Ag-RDT is also supported by several other investigators. Liotti et al 14 reported that the sensitivity of Ag-RDT compared to RT-PCR is over 95% when the Ct value is less than 25 but it declines drastically to 20-40% when the Ct value is greater than 25. Gannon et al, 15, 16 in their comparison study, found that Ag-RDT is 2-5-fold less sensitive compared to RT-PCR assay from respiratory specimens and their sensitivity varied from 22-70%. Furthermore, Lambert-Niclot et al 17 also showed that overall sensitivity of Ag-RDT is only 50% when compared to RT-PCR, and Scohy et al 18 reported that the sensitivity is only 32% and those that were detected had very high viral load. The poor clinical performance of Ag-RDT is because of its analytical sensitivity compared to molecular based assays. One of the major limitations of Ag-RDT is, unlike molecular assays, it does not offer the advantage of amplification of target RNA compromising sensitivity. However, it is generally believed that the specificity of Ag-RDT is high and comparable with molecular assays. 19 It is now well evident that the severity of COVID-19 is directly dependent on the viral load. 20 Therefore, perhaps one advantage of Ag-RDT can be useful in identifying and predicting the severity of disease. Since severity of the disease is often determined by massive proinflammatory response induced by SARS-CoV-2, measurement of proinflammatory cytokines (IL-6, IL-8, and TNF-a) together with Ag-RDT may aid diagnosis. 21 On the other hand, the viral load in the sample peaks in 1-3 days of infection (Figure 1) , therefore, collection of specimens at appropriate timing may increase the clinical sensitivity of Ag-RDT. Recent interim guidelines for antigen testing for SARS-CoV-2 formulated by CDC recommended a different strategy to interpret the result of antigen testing among symptomatic and asymptomatic individuals. 19 In the symptomatic patients, a positive antigen test can be confirmatory while a negative result should be verified with NAAT. Whereas, in asymptomatic individuals, a negative antigen test result indicates no current evidence of infection and a positive result should be confirmed by NAAT.The major limitation of this study is the small sample size. However, we have evaluated seven Ag-RDT that are available on the market. Despite the limitation of sample size, our study provides a fundamental basis to conduct a similar study on a large scale to validate the clinical utility of rapid antigen-based assays. Our future plan is to conduct the study with a large number of samples with all Ag-RDT assays available in the market for diagnostic use. Our current data suggests that none of these rapid tests are suitable to identify patients with low viral load. Therefore, Ag-RDT should not be the choice of test to identify asymptomatic patients with low viral load. Before implementing widespread Ag-RDT testing, more studies are needed to assess its clinical utility and diagnostic value.Rapid antigen tests have low analytical and clinical sensitivity to identify asymptomatic patients with low viral load compared to molecular based assays. Therefore, analytical performance of rapid antigen tests should be thoroughly evaluated before implementing it at clinical decision level. More studies are needed to evaluate the clinical performance of antigen-based testing before implementing it for widespread testing. ",USA,first author,2021-02-12,02
53e095159d09128568bf9e80ee26d1032a4bd76d,"Journal Pre-proofs Old Drug, New Trick? The Rationale for the Treatment of COVID-19 with Activated Protein C Old Drug, New Trick? The Rationale for the Treatment of COVID-19 with Activated Protein C","Activated protein C, in association with the co-factor protein S, then has anti-coagulant effects by cleaving activated factor V. 12, 13 In association with cofactors protein S and inactivated factor V, activated protein C also inactivates factor VIII. 14 The aggregate effects of factor V and VIII inactivation impair the activity of the tenase and prothrombinase complexes, diminishing further thrombin production. By forming a tight complex with plasminogen activator inhibitor 1, activated protein C decreases this inhibitor of tissue plasminogen activator and promotes fibrinolysis. 15 Pathways have been described which shed light on a relationship between mechanisms of inflammation and the coagulation cascade -such pathways point in both directions. Cytokines have been demonstrated to have an impact on the above-described coagulation pathways. Interleukin 1 and tumor necrosis factors are known to modify the characteristics of endothelial cells, and specifically synthesize tissue factor and suppress thrombomodulin. 16, 17, 19, 18 Further, TNF-induced suppression of the expression and degradation of thrombomodulin in endothelial cells appears to have a lasting effect, persisting for hours. 19 TNF also has been demonstrated to reduce EPCR, which may impair the efficacy of the inflammatory effects of both proteins C and activated protein C. 20 Interleukin 6 neutralization in the chimpanzee response to endotoxin was demonstrated to reduce coagulation. 21 Interestingly, administration of an IL-6 neutralizing monoclonal antibody in chimpanzees did not blunt the brisk rises in TNF or IL-8, nor did administration of these same monoclonal antibodies reduce the extent of neutrophilia, neutrophilic degranulation, or reduce fibrinolysis. In contrary, the IL-6 antibody markedly attenuated only coagulation.Conversely, proteins involved in the activation and inhibition of coagulation have been demonstrated to affect a diverse set of inflammatory mechanisms. Thrombin appears to be the nucleus for the coagulation cascade's stimulation of inflammation while activated protein C is the main focal point for its anti-inflammatory effects.In cultured endothelial cells, thrombin promotes neutrophilic adhesion and the production of platelet activating factor which has additional proinflammatory effects. 22 Thrombin signaling, which occurs through the protease-activated receptor-1 (expressed by platelets as well as endothelial cells), has pleiotropic actions on platelets and endothelial cells, some which result in changes in cell shape which may further promote platelet aggregation and vascular permeability. 23 Thrombin additionally stimulates the production of IL-6 and IL-8 in cultured mononuclear and endothelial cells 24 , stimulates the secretion of IL-1 and TNF in mononuclear cells 25 , and thrombin generation corresponding with fibrin activation are common findings in sepsis. 26 Inhibition of tissue factor with infusion of tissue factor pathway inhibitor protein in baboons exposed to a lethal dose of E. Coli prolonged survival, improved survival rate, and blunted dysregulated coagulation. 27 While administration of this inhibitor was not associated with any changes in TNF levels, IL-6 increases were dramatically blunted, and even decreased, in baboons in the intervention group. A study evaluating the impact of tissue factor pathway inhibitor protein in pigs with peritonitis-induced bacteremia demonstrated attenuation of TNF and IL-8 peak levels. 28 Pathways involving activated protein C counteract these thrombin-mediated effects and downregulate inflammation through several mechanisms. Historically, these effects were suggested when infants with protein C deficiency were found to have a rapid reduction in the thrombosis-associated, intense, local inflammation following the administration of protein C. 29 Since then, sepsis was identified as a model of dysregulated inflammation and coagulation, and a large body of research emerged evaluating the impact that perturbations to the coagulation system could have on inflammatory markers, coagulation proteins, and mortality in animal studies and then in human trials. Blocking protein C activation through use of a monoclonal EPCR antibody demonstrated increased mortality in baboons challenged with sublethal doses of E coli. 30 Baboons receiving the mAb had diverse alterations in coagulation and inflammation, with decreased fibrinogen but increases in fibrin degradation products, soluble thrombin, interleukin 6 and interleukin 8. Further, histopathological findings were notable for thrombosis in the adrenal glands, glomeruli thrombosis with necrosis of the tubular epithelial cells, and leukocyte infiltration in the adrenal glands and liver. Mice with a targeted heterozygous deficiency of protein C had reduced survival in comparison to their wildtype counterparts, and had significantly higher levels of interleukin 1, interleukin 2, interleukin 5, interleukin 6, interleukin 12, and TNF-alpha. 31 The anti-inflammatory properties of activated protein C have additionally been directly studied. Activated protein C has been demonstrated to inhibit the production of TNF by lipopolysaccharide stimulated monocytes in rats. 32 This same study demonstrated that rats treated with activated protein C did not experience vascular lung injury when challenged with lipopolysaccharide. Baboons treated with activated protein C were protected from a lethal dose of E. Coil, and had preserved fibrinogen and normal SGPT levels, in marked contrast to untreated controls. 33 The unique properties of activated protein C were supported by other studies using other anticoagulants, such as heparin and a modified form of factor Xa with its active-site blocked, which did not have the pluripotent protective effects as compared to activated protein C. 34 The diverse anti-inflammatory and protective effects of the activated protein C mechanistically appear to be due to decreased expression and functional activity of the endothelial cell nuclear transcription factor kappa-beta (NFkB, an important intracellular signal for cytokine production), through reduction in cytokine signaling via downregulation of cell surface adhesion molecules (including ICAM-1, E-selectin, and VCAM-1) and through decreased apoptosis via the regulation of antiapoptotic and proapoptotic genes. 35 Thrombomodulin itself has overlapping and complementary anti-inflammatory effects on several of these pathways as well. 36 Given the potential for correction of the pro-inflammatory and pro-coagulant effects of severe sepsis and septic shock, recombinant human activated protein C, or drotrecogin alfa (activated, DrotAA) was studied on patients with septic shock, but ultimately the PROWESS-SHOCK trial demonstrated that DrotAA did not significantly reduce mortality as compared to placebo. 37 This study is notable for a ~30% rate of positive blood cultures and ~70% rate of infectious organism identification; inclusion criteria are notable for an infection requiring intravenous antimicrobial therapy and persistent septic shock requiring pressors. 38 Other human studies evaluating recombinant activated protein C shed additional light on patient characteristics, which also reinforce the heavy and intended focus on patients with a bacterial etiology of disease. For example, PROWESS, which demonstrated decreased mortality in patients treated with DrotAA, revealed positive blood culture rates again at ~30%. RESOLVE, which evaluated DrotAA in pediatric patients, demonstrated that ~70% of patients had positive blood cultures and the ADDRESS study, evaluating patients with sepsis with sepsis-induced dysfunction of at least one organ but with lower APACHE II scores, also had positive blood culture rates of ~70%. 39, 40 Dysregulated coagulation and inflammatory pathways related to consumption of activated protein C have also been studies in viral infections. Early case reports demonstrated evidence of DIC in pediatric patients with influenza A and renal biopsies with fibrin deposition in glomerular capillary walls. 41 A retrospective study evaluating pediatric patients admitted with influenza A infection demonstrated a 24.4% rate of renal involvement, and DIC was present in 63.6% of the patients with renal impairment. 42 Viruses associated with hemorrhagic fevers are complicated by DIC in the most severe cases, and DIC can be found to occur with infections with other viruses including rotavirus, varicella, rubella, rubeola as well as influenza. 43 Humans with H1N1 influenza with increased levels of D-dimer have a higher risk of a respiratory failure and death (higher levels of LDH and a lower absolute lymphocyte count were also associated with a higher risk of respiratory failure and death). 44 SARS-CoV, which first emerged in 2002 in China and spread to 27 countries by April 2003, with a total of over 8,000 cases, has been associated with elevation in the PTT and D-Dimer. 45, 46, 47 There is less robust data available on the SARS-CoV impact on dysregulated mechanisms of coagulation, given the fortunate and relatively rapid regression of human cases of SARS-CoV infection. An observational study of a SARS CoV outbreak in Hong Kong evaluated quantitative RT-PCR in nasopharyngeal aspirates of infected patients and demonstrated a consistent peak at around day 10 following symptom of viral copies/mL, which seemed to correlate with the timing of IgG seroconversion (which started at day 10). 48 Substantial clinical deterioration frequently occurred following this peak, during a period of decreasing viral replication and IgG seroconversion; the authors suggested that this observed, latter phase of the illness, which was associated lung injury, could be due to a dysregulated immunologic response. Additional studies were performed to evaluate the molecular mechanism for acute lung injury with SARS-CoV infection; RNA expression patterns, proteonomics, and histology all suggested downregulation of the urokinase and tissue plasminogen activators as well as stimulation of alpha-2plasmin inhibitor, and these pathways result in a common host response of high levels of fibrin deposition in the lungs. 49 MERS-CoV was first isolated in 2012 in Saudi Arabia and as of December 2019 resulted in 2499 cases in over 27 countries with a case fatality rate of 36%. 50, 51 Host factors associated with severe disease include age >65 years, obesity, diabetes, and other chronic conditions such as heart, kidney and lung disease. 52 A case control study which included 17 patients who tested positive for MERS-CoV demonstrated elevations in aPTT and INR. 53 Thrombocytopenia was also noted in most patients admitted to an ICU with MERS-CoV. 54 Due to the low case count overall, there is even less data available regarding disturbances in coagulation associated with MERS-CoV as compared to SARS-CoV. Tissue samples were lacking, with the exception of two known human cases worldwide, due to the geographic distribution which corresponded with cultural and religious restrictions over autopsies and also as a result of infection control concerns. 55 While a useful animal model for severe MERS-CoV infection has proven challenging, studies using cell lines have demonstrated proinflammatory cytokine induction by MERS-CoV. A human lung epithelial cell line infected with MERS-CoV demonstrated induction of IL-1beta, IL-6 and IL-8, and these increases were far greater as compared to SARS-CoV.Given a disturbance of coagulation and inflammation in viral infections as well as bacterial infections, the use of recombinant human activated protein C has been studied in settings other than in humans with septic shock. Infection of fourteen rhesus monkeys inoculated with ebolavirus, which is associated with a rapid decline in plasma levels of protein C, demonstrated improved survival in the primates treated with activated protein C. While some monkeys did not appear to exhibit a response to the infusion, a group of responders demonstrated significant, sustained reductions in D-dimer, IL-6, IL-10, monocyte chemotactic protein 1, and TNF-alpha. 56 The relationship of viral-mediated dysregulated inflammatory response, coagulation and thrombus formation has also been studied, as well as the associated mechanisms, and activated protein C has been demonstrated to block several pathways, including endothelial expression of cytokines and adhesion molecules as well as mesangial production of tissue factor in vitro, and thrombosis in vivo. 57 Coronavirus Disease 2019, which was first recognized in December 2019 and since termed COVID-19, has not only been associated with profound stimulation of both inflammation and coagulation, but the magnitude of coagulopathy, in particular, is noteworthy as is the apparent association of coagulation disturbance with decreased survival. Early case series demonstrated decreases in aPTT and PT in 16% and 30% of patients, and 36% of patients had an increase in D-dimer. 58 A subsequent prospective study in a Wuhan hospital from January 1 st through February 3 rd 2020 evaluated coagulation tests on admission and during the hospital stay in 183 patients. 59 Using established diagnostic criteria for disseminated intravascular coagulation, 71.4% of the non-survivors had overt DIC while only 0.6% of survivors fulfilled DIC criteria; fibrinogen degradation products and D-dimer were significantly higher on admission in the non-survivors, and later in the course of admission anti-thrombin activity and fibrinogen levels were also significantly lower in non-survivors. Another study of hospitalized patients with COVID-19 similarly demonstrated that D-dimer levels were significantly higher in non-survivors later in the hospitalization as well. 60 Subsequent studies appear to confirm the high incidence of thrombotic complications of COVID-19, and heparin-based thromboembolism prophylaxis is generally recommended for COVID-19 admitted patients. 61 A retrospective study evaluating 449 severe COVID-19 patients demonstrated that elevated D-dimer was associated with higher 28-day mortality and for the group of patients with the highest levels of D-dimer, heparin appeared to reduce mortality by approximately 20%. 62 An observational study of 184 COVID-19 patients admitted to the ICU at one of three Dutch hospitals demonstrated a 31% composite rate of thrombotic complications despite treatment with standard doses of low molecular weight heparin. 63 Another study in Amsterdam similarly demonstrated higher D-dimer and higher rates of thrombosis in patients admitted to an ICU as compared to patients admitted to a general ward, and revealed that rates of venous thromboembolism were high for all patients despite aggressive prophylaxis. 64 A study of 150 ICU patients admitted to a French tertiary hospital demonstrated that 95% of patients had elevations in D-dimer and fibrinogen, factor VIII levels were considerably increased, and of 57 patients who were tested for lupus circulating anticoagulant 50 (87.7%) were positive. 65 This same study, which also matched COVID ARDS patients to non-COVID patients with ARDS, demonstrated a 15 times higher rate of pulmonary embolism and a high rate of circuit clotting among the patients receiving continuous renal replacement therapy. Conversely, the rate of hemorrhagic complications in this study were very low (and when they did occur, appeared to have a traumatic or procedure related etiology). A study evaluating endothelial cell histology in a series of patients with severe COVID-19 infections not only noted thrombotic complications but also identified prominent endotheliitis in several organs, including the intestine, lung, heart, kidney and liver. 66 It is noteworthy that the authors pointed out that viral or immune-mediated factors may cause widespread endothelial dysfunction, which promotes inflammation and a procoagulant state. Evidence of microvascular injury in COVID-19 patients is further provided by a study evaluating markers of endotheliopathy in 68 patients admitted with COVID-19 infection. 67 Not only were robust elevations in D-Dimer again noted but more specific markers of endothelial injury and activation were also observed (including elevations in soluble thrombomodulin and P-selectin, the latter which was also noted to be higher in intensive care unit patients as compared to patients admitted to a general hospital unit). Elevated soluble thrombomodulin concentration were also associated with a lower likelihood of survival.Similar to dysregulated coagulation, SARS-CoV-2 has been reported to be associated with a robust proinflammatory state and even a cytokine storm phenomenon similar to what is observed in macrophage activation syndrome or secondary hemophagocytic lymphohistiocytosis. An early, retrospective study of COVID-19 patients in Wuhan identified that IL-6, ferritin and CRP were elevated, and these elevations were considerably higher in those patients who died (median CRP > 100 mg/L, ferritin 1297 ng/mL and IL-6 >10 pg/mL). 68 Another study from Wuhan of 41 hospitalized patients demonstrated that ICU patients exhibited higher plasma concentrations of IL-2, macrophage chemotactic protein 1, TNF-alpha, and other cytokines. 69 It is interesting that IL-6 has been demonstrated to induce C-reactive protein, which itself has been demonstrated to be impressively elevated in COVID-19, given that C-reactive protein stimulates the production of tissue factor. 21Proposed tTreatments for hyperinflammation associated with COVID-19 have been evaluated, and havethus far have included steroids, monoclonal antibodies as well as more targeted therapies, and other therapies have been proposed or are currently under investigation, such as , intravenous immunoglobulin, , cytokine inhibitors and JAK inhibitorsion. 5, 6, 70 While sStudies have evaluated the impact of tocilizumab (a monoclonal antibody against the IL-6 receptor), anakinra (an interleukin-1 inhibitor), adalimumab (an anti-TNF-alpha antibody), and other inhibitors of pro-inflammatory cytokines. 4,Error! Bookmark not defined.,Error! Bookmark not defined. , tThe impact of these targeted immune therapies onf COVID-19 outcomes on cytokine releasemay be blunted , possibly in part through by mechanisms relates to accompanying the potent disturbances in coagulation which sustain the the dysregulated immune response, may not be significantly blunted through cytokine targets alone. Such mechanisms may explain why survival was not improved in hospitalized patients with COVID-19 treated with tocilizumab. 4 Similarly, as was noted above in studies in SARS-CoV, anti-viral treatment directed towards COVID-19, such as remdesivir, may not be expected to significantly impact the most severe effects of the illness once potent cytokine release and activation of coagulation are triggered, particularly when these sequelae of COVID-19 occur during the phase of illness when viral replication is already on the descent. The largest trial to date evaluating remdesivir on hospitalized patients with COVID-19 demonstrated no effect on mortality. 71 COVID-19 pathways of injury may be hypothesized that focus on dysregulated coagulation, potent activation of tissue factor and subsequently activation of thrombin, and downregulation of innate mechanisms of anticoagulation. If these mechanisms are responsible for a potent shift in balance of natural pro-coagulant and anti-coagulant pathways, the consequences of a vigorous procoagulant response would be expected to cause the cytokine elevations. Therefore, it is possible that approaching the observed disturbance in coagulation, rather than directly inhibiting mechanisms of inflammation or the virus itself, may be a more efficacious route to positively impact the course of illness, particularly among the sickest patients affected by COVID-19. This concept is supported by predictors for disease worsening identified in a trial designed to derive and validate a predictive score for disease worsening in inpatients with COVID-19. 72 Compared with patients admitted to a conventional unit, patients admitted to the intensive care unit had lower levels of antithrombin activity and protein C activity as well as higher D-Dimer and fibrinogen levels. Equally notable is that the multivariate analysis identifiedying elevations in D-Dimer and decreased activity of protein C and antithrombin as significant predictors of worsening disease included the cDIC-ISTH store, which itself incorporates protein C, antithrombin and D-dimer.When considering therapeutics that impact the activated protein C pathway, options include not only wild-type activated protein C, but also 3K3A-APC and soluble human recombinant thrombomodulin. Several variant forms of activated protein C have been evaluated in preclinical injury models, and 3K3A-APC, a recombinant human 3K3A-APC, has been evaluated in phase 1 and phase 2 human trials in patients with acute ischemic stroke. 73, 74 The 3K3A variant, however, has <10% anticoagulant activity as compared to activated protein 3. While the enhanced anticoagulant effect of activated protein C may result in more non-serious and serious bleeding events, human studies of activated protein C did not consistently demonstrate a significantly increased incidence of serious bleeding in patients treated with activated protein C. 37 It is also noteworthy that the above-described high rates of small and large vessel thrombosis in patients with COVID-19 could make activated protein C the optimal formulation for the treatment of severely ill COVID-19 patients. Activated protein C, therefore, may not only benefit COVID-19 patients through immunologic pathways which diminish endothelial injury and consequent tissue injury, but may also provide additional benefits specifically through antithrombotic properties. The fact that therapeutic anticoagulation is being evaluated in non-hospitalized and hospitalized patients with COVID-19 also lends merit to studying wild-type activated protein C, given its anticoagulant effects. While ART-123, a soluble human recombinant thrombomodulin, has been evaluated in patients with sepsis associated with coagulopathy and could be considered for treatment in patients with COVID-19, this therapy depends upon sufficient concentrations of thrombin and protein C. Given evidence that protein C activity is decreased in patients with severe COVID-19 infections, the impact of ART-123 could be dampened in this population of patients, again making wild-type activated protein C a more attractive candidate therapy.While it would be ideal to more first test this hypothesis and its several associated unanswered mechanisms through more rigorously study of the characteristics of some of the sickest COVID-19 patients, specifically through the collection of additional data, such as measurement of pprotein C, soluble thrombin, tissue factor, soluble thrombomodulin, protein C inhibitor, alpha-1 antitrypsin, and their relationship to outcomes, as well as additional pathological data, given the current crisis and the need for effective therapeutics, it is appropriate to trial investigational, candidate therapies which could significantly alter the course of the illness without the usual, more complete, supporting data.Evaluating the effect of activated protein C on patients with COVID-19 is, therefore, appropriate.Studying activated protein C both as a solitary therapy for patients with COVID-19 and in combination with dexamethasone, which has been demonstrated to reduce mortality in patients with severe COVID-19 infections, may be instructive given potentially additive or synergistic therapeutic effects.Given that the sickest patients, such as those in intensive care on mechanical ventilation and dialysis, presumably have experienced the most profound dysregulation of coagulation and inflammation, this populationa subpopulation of these patients would be the most appropriate target population to test trial this candidate therapeutic. While therapy earlier in the course of the illness may be more appropriate and benefit more patients,Selection of more severely ill patients not only would identifywould typically have the those with vigorous greatest disturbance in pathophysiologic mechanisms that can lead to tissue injury coagulation but also would also have multi-organ failure resulting from these same mechanisms, and would be an importantwould represent a group of patients which may stand to benefit the most. Patients on mechanical ventilation were demonstrated to benefit most with administration of dexamethasone in the RECOVERY trial, presumably through the impact of the steroid on the host immune response to infection, which supports the selection of patients on mechanical ventilation as appropriate initial candidates for treatment with activated protein C as well. 1 In addition to severity of illness, it is equally important to consider the duration of illness. Patients with particularly prolonged illness, for example, may have experienced the consequences of dysregulated coagulation and inflammation, such that considerable tissue injury has taken hold, such as through fibrin deposition in the lungs. Therefore, it will be important to identify a population of patients that are both severely ill but not too far along the continuum of the illness such that treatment can still have a therapeutic impact. In the RECOVERY trial, patients in the invasive mechanical ventilation group had a symptom onset median of 13 days at the time of randomization, with the inter-quartile range 8-18 days. Using the 75 th %ile, 18 days or less from symptom onset, as an initial eligibility criteria for the initiation of treatment with activated protein C would be reasonable. In addition to optimizing patient selection based on severity and duration of illness, direct Specific criteria for inclusion could include markers of dysregulated coagulation and a vigorous host immune response should be used for eligibility. D-Dimer and CRP, which are with associated end-organ dysfunction, such areadily available and frequently monitored in patients with COVID-19 infection,s could easily be applied to identify this subset of patients. Based on the observed relationship of elevations in D-Dimer and CRP to mortality in patients with COVID-19 infection, eligibility for treatment with activated protein C could be based on a D-dimer greater than 10-times the upper limit of normal and , CRP > 100 mg/L. 62, 68 , and a new requirement for mechanical ventilation or dialysis.In summary, the potent coagulation disturbance associated with severe COVID-19 infections, combined with evidence of a frequently associated hyperimmune state, when considered in the context of the well-established link between the inflammatory and coagulation pathways, may position a therapeutic with mechanistic roots in reversing the coagulation dysfunction as an effective in the treatment of COVID-19.",USA,first author,2021-02-16,02
b9933122af9718deb7861179eae514ef5b37a5b9,Mn 2+ coordinates Cap-0-RNA to align substrates for efficient 2¢-O-methyl transfer by SARS-CoV-2 nsp16,"The recently emerged human pathogenic SARS-CoV-2 is a positive-stranded RNA virus responsible for the on-going pandemic of highly transmissible fatal respiratory coronavirus infectious disease , which has caused over two million deaths worldwide (1) . SARS-CoV-2 proteins are translated from nine canonical subgenomic mRNAs, generated by a discontinuous transcription process that results in all mRNAs having identical 5¢-ends (2) . To promote translation and to protect viral RNA from host surveillance by the innate immune system (3) , coronaviral mRNAs are capped with guanosine monophosphate. Next, the guanosine cap is methylated by the nsp14-nsp10 heterodimer to generate Cap-0-RNA. Finally, a methyl group is transferred from S-adenosylmethionine (SAM) to the 2¢-OH of the first adenosine residue to form Cap-1-RNA. For coronaviruses, this last reaction is catalyzed by the 2¢-O-methyltransferase (MTase), a heterodimeric complex of nsp16 with the activator nsp10 ( Fig. 1A) (3) (4, 5) . Inhibitors of nsp16 reduce viral titer and delay the interferon response in mice, validating nsp16 as a target for the development of anti-viral small molecules (6, 7) . To support drug discovery efforts, researchers around the globe have determined crystal structures of the SARS-CoV-2 nsp16-nsp10 in complex with ligands (8) (9) (10) (11) (12) , complementing prior structural biology observations for this enzyme from SARS-CoV and MERS-CoV (13) (14) (15) . This structural information has facilitated a detailed examination of the SARS-CoV-2 nsp16-nsp10 substrate binding sites (10, 11) . It is well established that the 2¢-O-MTase in SARS-CoV-2 and other RNA viruses can be activated by divalent metal ions (13, 14, 16) . Yet, despite this extensive structural information, a major gap exists in understanding of the role of metal ions in the 2¢-O-methyl transfer reaction and the position of ribonucleotides in the RNA binding groove since structures of these complexes have not been reported.To initiate this study, we first extended prior studies on SARS-CoV and confirmed that the SARS-CoV-2 2¢-O-MTase also requires divalent cations. We used a custom-synthesized Cap-0-RNA substrate comprised of the N 7 -methylated guanosine (m 7 G) attached via a triphosphate bridge to a short RNA (AUUAAA), which matches the naturally occurring ribonucleotides at the 5¢-end of SARS-CoV-2 mRNAs (17) . At a concentration of 3 mM, both Mg 2+ and Mn 2+ significantly increased MTase activity (Fig. 1B) . In contrast, 3 mM Ca 2+ yielded only 50% of the activity observed with Mg 2+ and Na + did not stimulate activity. These data are consistent with observations for SARS-CoV nsp16 (4, 13, 14) . The activity of SARS-CoV-2 nsp16 with the Cap-0-RNA substrate (m 7 GpppAUUAAA) is over 10-times higher than that of the Cap-0 analog (m 7 GpppA) ( Fig. 1B , blue bars). Isothermal calorimetry (ITC) measurements were utilized to show that while it is a poor substrate for catalysis, m 7 GpppA does bind nsp16-nsp10 (Kd = 6.6 ± 0.3 µM) with 3fold higher affinity than to nsp16 alone (Kd = 28.0 ± 5.5µM) (Table S1 ). In contrast, m 7 GpppG bound only to the nsp16-nsp10 complex (Kd = 20.0 ± 2.7 µM). We also determined the binding affinities for the methyl donor SAM and the product SAH for nsp16 and the nsp16-nsp10 heterodimer. Neither SAM nor SAH bound to nsp16 alone, but both SAM and SAH bound to the nsp16-nsp10 heterodimer with Kd values of 6.9 ± 1.3 µM and 13.0 ± 1.2 µM, respectively. These results from biochemical and ITC studies together, as well as work by others (4, 9, (11) (12) (13) , indicated that the Cap-0 analog is capable of binding to nsp16 alone and that nsp10 greatly enhanced the binding affinity. However, a short capped RNA and the presence of Mg 2+ or Mn 2+ dramatically increased the rates of catalysis.To gain further insight into how metal ions stimulate catalysis, we took a structural biology approach. Crystals of nsp16-nsp10 in complex with SAM from different crystallization conditions were soaked with the custom-synthesized m 7 GpppAUUAAA substrate in the presence of Mg 2+ or Mn 2+ (see methods). Multiple datasets were collected and, ultimately, three with the highest resolution and the best data statistics were selected for further analysis. Crystal #1 (PDB 7JYY) grew from a high NaCl concentration condition and was soaked with substrates and low MgCl2 concentration for 1.5 hours. In this crystal, we observed Cap-0-RNA, SAM, and Mg 2+ (Fig. 1C , D). Crystal #2 (PDB 7L6R) grew from a high (NH4)2SO4 concentration condition and was soaked with substrates and MnCl2 for 6 hours. In this crystal, we observed Mn 2+ and the products of the reaction, Cap-1-RNA and SAH, indicating that the methyl transfer reaction occurred in the crystal (Fig. 1E ). Crystal #3 (PDB 7L6T) grew from a high magnesium formate concentration condition and was soaked with substrates for 6 hours. In this crystal we observed two Mg 2+ ions and products of the reaction, Cap-1-RNA and SAH. The first Mg 2+ occupied the same metal binding site as in Crystals #1 and #2 and the second Mg 2+ directly interacted with phosphate groups of the capped RNA (Fig. S1 ). The number of ribonucleotides in Crystal #1 and #3 included the cap and first three ribonucleotides (m 7 GpppAUU) and the phosphate group of the fourth nucleotide. Crystal #2 contained the whole A4 ribonucleotide and the phosphate group of A5.An overlay of the previously reported Cap-0 analog (PDB 6WRZ (10)) and Cap-0-RNA (PDB 7JYY, this study) structures showed they are very similar with a root-mean-square-deviation of 0.33 Å ( Fig. 2A) . We previously showed that the cap binding site, also called the High Affinity Binding Site (HBS), is bordered by flexible loops that adopt an open conformation upon Cap-0 analog binding (10) . Interactions of the nsp16 residues Tyr6828, Tyr6930, Lys6935, Thr6970, Ser6999 and Ser7000 with the Cap-0 analog and Cap-0-RNA are similar in both structures. The m 7 GpppA in the HBS is stabilized by stacking of the m 7 G and A1 bases with Tyr6828 and Tyr6930 residues, respectively ( Fig. 2A) . The O2¢ of the A1 ribose interacts with the conserved nsp16 catalytic residues (13, 14) , corresponding to Lys6839-Asp6928-Lys6968-Glu7001 in our structures (Fig. 2B) , as well as with the conserved water molecule we previously identified (10) . The interactions between Asn6841, SAM and O2¢ from the A1 are also consistent between these structures.Of particular note was the space between the Tyr6930 and Asp6873 side chains, which is occupied by the A1 base in the Cap-0 analog structure. In the Cap-0-RNA structure, this space accommodates the stacked bases of A1 and U2, with the U2 base forcing repositioning of the A1 ribonucleotide ( Fig. 2A) . Superposition of the Cap-0 and Cap-0-RNA structures revealed that this repositioning involves: i) a 0.6 Å shift of the A1 base towards the side chain of Tyr6930 without notable changes in the positions of Asn6873 and Tyr6930, and ii) a 0.4 Å decrease in the distance between O2¢ of A1 and the SAM methyl group (Fig. 3A) , which occurs without significant changes in position of catalytic residues (Fig. 2B) . The movement and alignment of the A1 O2¢ atom toward the methyl group of SAM may explain why the additional ribonucleotides increase the efficiency of the methyl transfer reaction (18) (19) (20) .Although the superposition of Cap-0 and capped RNA structures revealed differences in the position of the first adenosine, no significant deviations were observed between Cap-0-RNA and Cap-1-RNA conformations ( Fig. 2A,B) , indicating that the A1 base is not repositioned after the methyl transfer. The structures are essentially identical with the only difference being the methyl group, which moves from SAM to the A1 ribose hydroxyl group during methyl transfer (Fig.  2C ,D).The structures in complex with capped RNAs also revealed the importance of the low affinity binding site (LBS) residues for the conformation of the mRNA in the catalytic site. The best resolved and most complete electron density for capped RNA was observed in Crystal #2. The position of U2 in the active site is ""locked"" by multiple interactions (Fig. 3A) . The phosphate group of U2 interacts with waters from the hydration sphere of the metal ion and the side chain nitrogen of Lys6844; the O2 atom of the U2 base interacts with the main chain nitrogen of Asp6873 and the O2¢ of the U2 ribose makes direct interactions with one of the oxygens of the side chain of Asp6873 (Fig. 3B ). The phosphate group of U3 interacts directly with the side chain nitrogen of Lys6874 and forms water mediated interactions with residues Asp6873, Lys6874, Met6840 and Asn6841. The base of U3 interacts directly with the main chain oxygen and nitrogen atoms of Ala6832 and forms a water bridge interaction with the nitrogen of the main chain of Leu6834. The whole nucleotide A4 and phosphate group of A5, the last ordered part of the capped RNA in the Crystal #2 structure, are solvent exposed and connected with protein via a hydrogen-bond between O4¢ of the A4 and the side chain oxygen of Ser6831 (Fig. 3B ). The stacking interactions between bases of U3 and A4 define the position of the A4 nucleotide. It is unknown if the conformation of A4 reflects the natural interaction of nucleotides, or if a longer mRNA would form different contacts with the nsp16-nsp10 heterodimer. However, the position of m 7 G and first three nucleotides of the capped RNA closely match in all three structures and likely represent the accurate binding mode for this part of the capped RNA.The primary metal binding site is located near the HBS and loop1 ( Fig. 1C ) with either Mg 2+ or Mn 2+ occupying the same site with similar interactions (Fig. 3B,C) . The metal ions make both direct and water-mediated interactions with sidechains of nsp16 residues and the backbone of the capped RNA. The best electron density maps were observed for Crystal #3 with two magnesium ions, both of which have near-ideal octahedral geometry (Fig. 3C) . The Mg 2+ in the primary metal binding site is coordinated in part by interactions with phosphate groups of the triphosphate bridge linking the cap to A1, the phosphate group of U2, and the ribose of U3. The second Mg 2+ directly interacts with the U3 and A4 phosphate group oxygens and through waters with the side chain oxygens of the Asp6873 and the side chain nitrogen of Lys6874 (Fig. 3C) . Thus, the metal ion that occupies the primary metal binding site of nsp16 properly aligns capped RNA with SAM for an efficient methyl transfer reaction. The role of metal ions in facilitating orbital alignments for efficient catalysis has been demonstrated structurally for hydride transfer reactions (19) . Structural evidence for the requisite orbital alignment of substrates in RNA 2'-O-MTases (18) and ribozymes (20) has also been observed.Although Mn 2+ and Mg 2+ are catalytic co-factors in solution (Fig. 1B) and were observed in our crystal structures, biochemical assay showed that Mn 2+ best stimulated the methyl transfer reaction (Fig. 1B) . More importantly, Mn 2+ is present at higher concentration than Mg 2+ in the endoplasmic reticulum and Golgi, where the SARS-CoV-2 replication vesicles are formed (21, 22) . These findings suggest that Mn 2+ may be the natural co-factor for nsp16 from SARS-CoV-2 and other coronaviruses.All proposed in silico drugs that could target the residues of the LBS (9, (11) (12) (13) have relied on the crystal structures of 2¢-O-MTases with capped RNA for DENV NS5 (PDB 5DTO (23)), VACV VP39 (PDB 1AV6 (24)) and hCMTr1 (PDB 4N48 (25) ). Comparison of the RNA binding site and the capped RNA conformation from these structures with SARS-CoV-2 nsp16-nsp10 (PDB 7L6R) revealed that the conformation of the m 7 G and the location of the cap binding pockets relative to the active sites are dramatically different (Fig. S2A-D) . In the nsp16-nsp10 and VP39 structures, the N 7 -methyl groups are nestled in the HBS pocket (Fig. S2A,C) . In contrast, in NS5 and hCMTr1, for which methylation at the N 7 position of the G0 is not required for the 2¢-O-MTase activity (25) , the N 7 -methyl groups are pointed toward the solvent (Fig. S2B,D) . Although m 7 G positions do not overlap, nucleotides N1 and N2 in all these structures are closely matched, which is consistent with the conserved mechanism of action and the structure of the catalytic site (Fig. 4A in stereo view) . In all but the nsp16-nsp10 structure, the N2 nucleotide is sandwiched between the N1 and N3 by base stacking interactions and these three nucleotides have limited interactions with the 2¢-O-MTase residues of RNA binding grove. In the nsp16-nsp10 structure, all functional groups of the nucleotides N2 and N3 are involved in an integrated and complex network of hydrogen bond interactions with residues of the LBS. The U2 base and the ribose directly interact with main chain and side chain atoms of Asp6873. The side chain of Asp6873 occupies the space that is filled by N3 in all other structures. The presence of Asp6873 essentially forces the U3 nucleotide to move to the opposite side of the RNA binding groove, where it is involved in direct and water-mediated interactions with Ala6832 and Leu6834 (Fig. 4A,B) . The superposition of SARS-CoV-2 nsp16-nsp10 (PDB 7JYY) with MERS-CoV (PDB 5YNM (26)) revealed almost identical conformations of the proteins and the promontory Asp6873 residue, as well as the position of the Cap moiety (Fig. 4B) . Alignment of the amino acid sequences of nsp16 from representative coronaviruses ( Fig.  4C and Fig. S3 ) showed that Asp6873 is conserved across the coronaviruses, except for feline coronavirus (F-CoV). Structural and sequence alignments of SARS-CoV-2 nsp16 with the other MTases revealed that the Asp6873 is unique to coronaviruses and located in a four-residue insertion in the loop between b1 and aA (Fig. 4D,E) . Thus, this aspartate-containing loop and the redirection of the RNA, which is also coordinated by metals, is a unique feature that is shared across coronaviruses. Importantly, its absence in mammalian methyltransferases makes the region surrounding this residue a promising site for selective coronavirus-specific inhibitors.Protein expression, purification, and crystallization. Recombinant nsp16 and nsp10 proteins with 6xHis-tags removed were purified from Escherichia coli and crystallized as previously described (10) .MTase activity. The Cap-0 analog (m 7 GpppA) was obtained from New England Biolabs and the Cap-0-RNA (m 7 GpppAUUAAA) was custom-synthesized. The MTase activity was measured using the MTase-Glo Methyltransferase bioluminescence assay (Promega) (27) in buffer conditions suitable for use with SARS-CoV-2 nsp16. Luminescence was measured using a TECAN Safire2 microplate reader in arbitrary units and normalized assigning 100% to the activity in presence of Mg 2+ and Cap-0-RNA. The plot was created using GraphPad Prism V9 and shows the average and the standard deviation of three measurements using two different protein purifications.Binding affinity was determined using a MicroCal PEAQ-ITC system (Malvern, Worcestershire, UK) at 25°C. The sample cell volume was 200 µL and the total syringe volume was 40 µL. For each titration, the first injection was performed using 0.4 µl which was then followed by 18 additional injections at 2 µl per injection. The first injection was considered a void and was automatically removed from data analysis. Each injection was spaced by 120 s after a 60 s initial delay. SARS-CoV-2 samples of nsp10, nsp16 and nsp16-nsp10 were individually loaded into the sample cell and then titrated with either SAH, SAM, m 7 GpppA Cap analog or the m 7 GpppG Cap analog (New England Biolabs). All samples were dialyzed overnight in ITC buffer (200 mM NaCl, 50 mM HEPES (pH 8.0), 0.1 mM ZnCl2, and 1 mM DTT). The concentrations of SARS-CoV-2 nsp10 or nsp16 used in experiments were 200 µM and 40 µM, respectively, and the concentrations of all substrates used were 500 µM. For titration experiments of the SARS-CoV-2 nsp16-nsp10, the two proteins were mixed to the final concentrations 25µM and 200 µM, respectively, and incubated for 30 mins at room temperature. A titration of SARS-CoV-2 nsp10 into nsp16 was performed at the 8:1 ratio to ensure no enthalpy was detected for the complex formation alone. The SARS-CoV-2 nsp16-nsp10 was titrated with substrates SAH and SAM at 375 µM and each Cap analog at 280 µM. Individual titration data were analyzed with MicroCal PEAQ-ITC Analysis Software using a single-site binding model and non-linear curve fitting. Each experiment was performed in triplicate and the resulting values and standard error in the fitted parameters for n, Kd, DH, DTS, and DG were obtained and are summarized in Table S1 . Data collection, processing, structure solution and refinement. Data sets were collected at the beam lines 21ID-D and 21ID-F of the Life Sciences-Collaborative Access Team (LS-CAT) at the Advanced Photon Source (APS), Argonne National Laboratory. Images were indexed, integrated and scaled using HKL-3000 (28) . Data quality and structure refinement statistics are shown in Table S2 . All structures were determined by Molecular Replacement with Phaser (29) from the CCP4 Suite (30) using the crystal structure of the nsp16-nsp10 heterodimer from SARS-CoV-2 as a search model (PDB ID 6W4H). The initial solutions went through several rounds of refinement in REFMAC v. 5.8.0266 (31) and manual model corrections using Coot (32) . The water molecules were generated using ARP/wARP (33) followed by an additional rounds of refinement in REFMAC. All structures were carefully examined, and three data sets were selected for further structural studies. For all structures, the Cap-0-RNA, SAM and Mg 2+ were fit into electron density maps and further refined. Inspection of anomalous and Fourier difference electron density maps revealed that, for Crystal #1 the nsp16-nsp10 heterodimer formed the complex with the Cap-0-RNA, SAM and Mg 2+ , for Crystal #2 the complex was formed with the Cap-1-RNA, SAH and Mn 2+ , and for Crystal #3 the complex was formed with the Cap-1-RNA, SAH and two Mg 2+ . In Crystals #1 and #3, no additional electron density was detected beyond phosphate group of A4. In Crystal #2, the presence of well-defined electron density near phosphate group of A4 allowed unambiguously extending of the RNA model by adding sugar and base for A4 and phosphate group of A5. All structures were further refined with the Translation-Libration-Screw (TLS) group corrections, which were created by the TLSMD server (34) . The quality control of the models during refinement and for the final validation of the structures were done using MolProbity (35) (http://molprobity.biochem.duke.edu/). All structures were deposited to Validated SARS-CoV-2 related structural models of potential drug targets (https://covid19.bioreproducibility.org/) and to the Protein Data Bank (https://www.rcsb.org/) with the assigned PDB codes 7JYY (Crystal #1), 7L6R (Crystal #2) and 7L6T (Crystal #3). A fourth structure (PDB 7JZ0) was also determined as part of this study and deposited but was not analyzed further as the metal was modeled as Na + , which does not catalyze the reaction, although data on this structure are included in Table S2 for reference. All models of the structures were created in PyMOL open source V 2.1 (36), diagram of interactions was created in LigPlot+ (37) .Structural, sequence alignment and phylogenic tree. The PDB coordinates of SARS-CoV-2 nsp16 and nsp10 were analyzed using the FATCAT (38) , POSA (39) and DALI (40) ) on the right. The catalytic site residues, SAM and capped RNAs are labeled and shown as stick models with atoms colored in wheat, green, and grey for carbons of nsp16, SAM and capped RNA, respectively, with red for oxygens, blue for nitrogens, yellow for sulfurs. Conserved catalytic waters are shown as cyan spheres, hydrogen bond interactions as black, dashed lines, and the omit |Fo-Fc| electron density maps contoured at the 3s level as blue mesh. The methyl group of SAM and Cap-1-RNA are marked with black triangles. (43) . c Validation was done using MolProbity (35) .",USA,first author,2021-02-01,02
0eb5aae614fe8b095bc559bd851846d7664a2ce0,"Phased implementation of COVID-19 vaccination: rapid assessment of policy adoption, reach and effectiveness to protect the most vulnerable in the US","In late December 2019, a pneumonia-like illness was reported in Wuhan, China, which came to be known as COVID-19. In the US, the first case was documented in late January in Washington state. By mid-March, all 50 states had reported cases and by mid-April the US had the most COVID-19 deaths in the world (Kantis et al., 2020) . To combat the rapidly growing pandemic, many states implemented lockdown measures which coincided with an economic downturn (IMF, 2020) . Therefore, despite growing cases, lockdowns were eased in many states by April (Washington Post Staff, 2020) . Additionally, there has been a decline in compliance towards social distancing measures which are often voluntary and hard to enforce (Boseley, 2020) . As lockdowns are generally not economically sustainable, alternative methods to control the pandemic have received growing attention. Accordingly, many research groups have worked on developing a COVID-19 vaccine. The Centers for Disease Control and Prevention (CDC) has stated that vaccines are vital in tandem with other social distancing measures. In the US, many companies started developing COVID-19 vaccines in March (HHS, 2020) . In December, the Food and Drug Administration (FDA) authorized the emergency use of both the Pfizer-BioNTech and Moderna vaccines. Despite their notoriously rapid development, clinical trials have found both vaccines to be more than 90% effective with only a few, minor side effects (Luthi, 2020) .Once the vaccine efficacy was thoroughly tested, the government started planning distribution efforts through a program known as Operation Warp Speed (HHS, 2020). The first round of vaccines was delivered to states, territories, and some federal agencies in late December (Silberner, 2020; Ivory et al., 2021) . Ultimately, the states are in charge of the local administration of vaccines. However, as the supply is currently limited the Advisory Committee on Immunization Practices (ACIP) has suggested taking a phased approach to vaccination (CDC, 2020) . This approach was made in an attempt to decrease deaths and serious illnesses while preserving a functioning society and reducing the burden on those who have been disproportionately harmed by the virus (CDC, 2021) . The federal government anticipates vaccinating 100 million people in the US by the end of February 2021. However, the vaccine rollout has been slow (Silberner, 2020) likely due to the limited supply and inefficient distribution (CDC, 2020; Robbins et al., 2020; Romero et al., 2021) . It is important to rapidly assess the phased vaccination approach in terms of adoption, reach, and effectiveness, despite this low coverage, in order to better plan for vaccination later on. Indeed, an evaluation of the pandemic in California near the end of January 2021 noted that cases (The COVID Tracking Project, 2021) and hospitalizations were starting to decline at the same time vaccination coverage was increasing (Los Angeles Times Staff, 2021) . Similar to social distancing policies, the COVID-19 vaccination has become a contentious issue especially as there is limited direct evidence regarding the effectiveness of vaccination. Many people who protested early pandemic measures, such as stay at home orders and mask mandates, are likewise protesting mandatory vaccines (Luthi, 2020) . This opposition may be due to firm beliefs in medical autonomy, vaccine conspiracy theories (Ball, 2020) , concerns about vaccine side effects, mistrust of the government (Dwyer, 2020) , and mistrust of healthcare (Coustasse et al., 2020) . However, COVID-19 vaccine opinions and knowledge have varied overtime. There has been a noticeable increase in the public's willingness to take the vaccine as it has moved into later stages of development (Luthi, 2020; Dwyer, 2020) . Increasing the public trust in COVID-19 vaccines is critical as many experts predict that a vaccination rate between 70% and 80% is needed for herd immunity (Maragakis, 2021) . As manufacturing and distribution become more systematic, it will become more important to eliminate other barriers to widespread vaccination efforts such as public opposition.In order to increase the public's willingness to take the vaccine, some studies have recommended utilizing public information campaigns, financial investments, and other measures to highlight the effectiveness, benefits, and safety of the vaccine (Paltiel et al., 2020) .Furthermore, other studies have emphasized the importance of making sure these campaigns receive high coverage and are spread to the public quickly, as the pandemic is an urgent issue (Buonomo et al., 2020) . Without sufficient knowledge, it is often hard to persuade people to accept recommendations (Wolfson, 2020) . For example, mask mandates ultimately gained more widespread acceptance once thorough research highlighted their success (Lyu et al., 2020) .Currently, there is limited research done to quantitatively evaluate the effectiveness of the phased COVID-19 vaccination approach. Through a natural experiment, we investigate how statewide vaccination efforts affect the spread of COVID-19 in the US during the early stages of vaccination. Specifically, we use an event-study analysis to estimate the effects of state vaccinations on the state-level confirmed case growth rate over different time periods.Vaccination may play a vital role as states are reopening and social distancing policies are becoming less stringent (Boseley, 2020; Hills, 2021) . It is necessary to do a rapid assessment of vaccination effectiveness during the initial stages of implementation as concrete evidence of success and safety is important to inform policymakers who direct administration efforts, and the public in order to achieve widespread vaccination.Records detailing when the COVID-19 vaccine was first administered in every state were gathered in this study by searching and reviewing the public news and governmental pages. Our study focuses on state-level COVID-19 vaccination beginning with the first shot which was given in New York on December 14, 2020. Following the CDC guidelines, frontline healthcare workers and long-term care facility staff and residents were given the highest priority in receiving the vaccine in phase one (CDC, 2020) . However, the vaccination process, including the definition of groups given priority, have varied among the states. Detailed information on the adoption of vaccination in different US states can be found in the result section.In addition, we collected vaccination data from October 1, 2020 to January 26, 2021. A repository shared by the Johns Hopkins University Centers for Civic Impact COVID-19 data analysis and visualizations (https://github.com/govex/COVID-19) contains state-level reports which record the daily cumulative number of doses administered to the public. Specifically, we divided the cumulative number of doses administered by a state's population size to find the daily ratio of doses administered.Statewide policy data was produced by the NSF spatiotemporal innovation center based on the Oxford COVID-19 Government Response Tracker project schema (Hale et al., 2020) .and their implementation overtime. These policies include school closures, workplace closures, the cancellation of public events, restrictions on gatherings, public transport closures, stay at home orders, internal movement restrictions, and international travel controls. The extent of government action is reflected using a stringency index ranging from 0 to 100; the larger the value, the more stringent a certain policy measure is. The entire dataset can be found on Github (https://github.com/OxCGRT/covid-policy-tracker). A lot of research has found that social distancing policies and mask mandates affect the growth rate of COVID-19 cases (Courtemanche et al., 2020; Lyu et al., 2020) , thus, the stringency index was included in this study to control for the effects of policy stringency during the study period.(1) Vaccination State-level vaccination data was encoded as binary data, with 0 indicating that the COVID-19 vaccine had not been administered in a certain state and 1 indicating that people had started to take the vaccine in that state. To assess the vaccination effects, a reference group representing the 1-5 days before the start of vaccination was selected. Additionally, we analyzed the effects of the vaccination over six post-periods (1-5 days, 6-10 days, 11-15 days, 16-20 days, 21-25 days, and 26+ days)-which represented days after the first shot of the COVID-19 vaccine was administered, and four pre-event trends (6-10 days, 11-15 days, 16-20 days, and 20+ days)-which represented days before the vaccination started. Multiple 0-1 indicators were generated to indicate these pre-and post-periods. Each day in the analytical period was assigned with one indicator by comparing t to the time range each indicator represented. Here, t is the cumulative number of days since the first shot of the vaccine was administered in a certain state.To estimate the effect of vaccination, we calculated the daily, state-level confirmed case growth rate, which is the difference between the natural logarithms of the cumulative counts of confirmed cases on a given day and that of the prior day. This difference was then multiplied by 100 to enable the daily growth rate to be given in percentage points and so that the estimated regression coefficients could be interpreted as percentage point changes in the growth rate.(1)In this study, we employed a fixed effects panel regression model incorporating the event-study design to examine the effects of statewide phased COVID-19 vaccination on the spread of COVID-19 in the US. The differences between the availability of vaccines before and after the initial vaccination in the states enabled estimation in the context of a natural experiment.We examined if the trend in the COVID-19 confirmed case growth rate was differentiated before and after the start of vaccination. The response variable in the model was the confirmed case growth rate as defined in Eq (1). The effect of periods of interest was defined in the Vaccination section (the six post periods after the first shot of the COVID-19 vaccine were coded, the four pre-event periods were coded, and the reference period was). In addition to the differences in vaccination efforts, we also included the test growth rate, the policy stringency index (Hale et al., 2020) , and the dose administrative ratio as control variables.In the above regression specification, Overtime, Texas and Florida likely became more efficient in their vaccination efforts.The attempts of each state to reach the public can also be seen in Figure 2 , which shows the percentage of the population, in each US state who received at least 1 vaccine dose by the same four dates described above. Throughout the analysis period, Texas and Florida were able to notably increase the percentage of their populations who received at least 1 dose of the vaccine.These results showed similar effects on the case growth rate as seen with the main result.Making sure mitigation measures reach the public is an essential step in the ultimate goal of widespread vaccination and the fight against COVID-19. Other states can learn from these successful implementation strategies in order to reach a larger percentage of the public in later phases.Our study contributes direct, empirical evidence, which highlights the effectiveness of the COVID-19 vaccination on the case growth rate. Overall, vaccination has been successful in decreasing the case growth rate during the early stages of vaccination despite the initial limited supply and slow rollout. Furthermore, the decreases increased in magnitude overtime. Although the vaccine is still in the early stages of administration. This information could be used to convince the public that vaccination is worthwhile and can help policymakers optimize implementation strategies.This study found that the phased vaccination approach helped reduce the daily, state-level COVID-19 case growth rates in the US. Despite initially limited vaccine availability, the CDC guidelines regarding the phased vaccination approach has helped protect the most vulnerable from COVID-19. Even though the COVID-19 vaccine is still in the early stages of distribution, it has already been associated with significant decreases in the case growth rate. This is promising for the subsequent phases of vaccination. Overall, the results presented in this research have implications in regard to general public vaccine concerns. For example, our assertion that the COVID-19 vaccine is effective, even in the initial stage, may help persuade skeptical vaccine critics that this mitigation measure is worth it. This information is vital as states are reopening and social distancing measures are becoming less feasible both administratively and economically.",USA,first author,2021-02-23,02
20d445a317cb09ea2f1cdde45fa48b7523ff7241,Allergy and Infectious Diseases,"addition of mutations from mink strains of SARS-CoV-2, the South African B1.351, Brazilian P.1 138 strain, and UK B.1.1.7 strains did not change binding magnitude for DH1047 nor macaque 139 plasma IgG (Fig. 2c,d) . However, the addition of these mutations slightly increased ACE2 140 binding compared to D614G alone (Fig. 2c) . Next we tested binding to recombinant RBD 141 monomers with and without the K417N, E484K, and N501Y mutations present in the B1.351 142 variant. ACE2 binding was decreased by K417N and increased by N501Y, while the RBD with 143 all three mutations showed no change in ACE2 binding (Fig. 2e) . RBD neutralizing antibody 144 DH1041 is focused on the ACE2 binding site, and was knocked out by the E484K change ( Fig.   145 2e). Importantly, the binding to SARS-CoV-2 RBD for cross-reactive antibody DH1047 was 146 unchanged to RBDs with E484K or other mutations (Fig. 2f) . Also, RBD-scNP-vaccinated 147 macaque plasma IgG and S-2P mRNA-LNP-immunized macaque plasma IgG were unaffected 148 by the RBD mutations (Fig. 2e,f) . 41 batCoV-SHC014 (Fig. 3a, Extended data Fig. 2) . Neutralization was more potent for 159 replication-competent SARS-CoV-2 virus compared to the other three SARS-related viruses 160 ( Fig. 3a, Extended data Fig. 2) . Among the three immunogens, RBD-scNP elicited the highest 161 neutralization titers and mRNA-LNP expressing monomer RBD elicited the lowest neutralization 162 titers (Fig. 3a, Extended data Fig. 2) . Also, RBD-scNP immunization elicited cross-reactive IgG binding against SARS-CoV-2, SARS-CoV-1, batCoV-RaTG13, batCoV-SHC014, pangolin CoV-164 GXP4L Spike proteins ( Fig. 3c and Extended data Figs. 3a,c). RBD-scNP immune plasma IgG 165 did not bind the S ectodomain of four endemic human CoVs, nor did it bind MERS-CoV S 166 ectodomain (Extended data figs. 3a,c) . The lack of binding by plasma IgG to these latter five S 167 ectodomains was consistent with RBD sequence divergence among groups 1, 2a, 2b and 2c 168 coronaviruses ( Fig. 3e and Extended data figs. 4-6) . Nonetheless, the SARS-CoV-2 spike 169 induced cross-reactive antibodies against multiple group 2b SARS-related betaCoVs, with the 170 highest titers induced by RBD-scNP.The immune sera from RBD-scNP-immunized exhibited a similar cross-neutralizing profile as 173 the cross-neutralizing antibody DH1047. DH1047 binds with <0.02 nM affinity to monomeric 174 SARS-CoV-2 RBD (Extended data fig. 3b) , and bound the RBD-scNP (Fig. 1b) . DH1047 (Fig. 3d) . Antibodies targeting near the DH1047 epitope would be predicted to be 180 cross-reactive with group 2b betaCoVs given the high sequence conservation present in and 181 immediately proximal to the DH1047 epitope (Fig. 3e) . Comparison of RBD sequences showed 182 them to be relatively conserved within betaCoV group 2b, but minimally conserved between 183 groups 2b and 2c ( Fig. 3f and Extended data figs. 4-6). To examine whether RBD-scNP-184 induced antibodies bound near the DH1047 epitope, we assessed plasma antibody blocking of 185 DH1047 binding to SARS-CoV-2 S-2P ectodomain. Plasma from all RBD-scNP immunized 186 macaques blocked the binding of ACE2 and DH1047 to SARS-CoV-2 S-2P ectodomain (Fig. 3g   187 and Extended data fig. 3d ). Since DH1047-blocking plasma antibodies could be SARS-CoV-2-188 specific, we also examined plasma IgG blocking of DH1047 binding to batCoV-SHC014. Similar to SARS-CoV-2 S binding, RBD-scNP plasma also blocked DH1047 binding to batCoV-SHC014 190 (Fig. 3g) . While 96% of COVID-19 patients made antibodies that blocked ACE2 as a dominant 191 RBD response, only 31% made antibodies that blocked the cross-reactive antibody, DH1047 192 ( Fig. 3h) . Thus, in natural SARS-CoV-2 infection the cross-reactive DH1047 IgG blocking 193 response is subdominant, and RBD-scNP vaccination focused antibody responses to this 194 subdominant cross-reactive neutralizing epitope.Finally, to determine whether vaccination elicited coronavirus protective immunity, we 197 challenged RBD scNP-vaccinated monkeys with 10 5 plaque forming units of SARS-CoV-2 virus 198 (Fig 4a) . To assess virus replication in the upper and lower respiratory tract, E or N sgRNA was 199 quantified in fluid from nasal swabs and bronchoalveolar lavage (BAL) two and four days after 200 challenge (Fig 4a) . In unimmunized macaques two days after challenge, there were on average 201 1.3x10 5 and 1.2x10 4 copies/mL of E gene sgRNA in the nasal swab and BAL fluids, respectively 202 ( Fig. 4b,c) . In contrast, vaccinated monkeys had undetectable levels of subgenomic envelope E 203 gene RNA in the upper and lower respiratory tract (Fig. 4b,c) . We sampled monkeys again 2 204 days later to determine if detectable virus replication was present, but again found no detectable 205 E gene sgRNA in any monkey BAL or nasal swab samples (Fig. 4b,c) . Similarly, all RBD-206 scNP-vaccinated macaques had undetectable N gene sgRNA in BAL and the nasal swab fluid, 207 except one macaque that had 234 copies/mL of N gene sgRNA detected on day 2 in nasal 208 swab fluid (Fig. 4d,e) . Viral replication was undetectable in this macaque by the fourth day after 209 challenge ( Fig. 4d,e) . Thus, RBD-scNP-induced immunity prevented virus replication, and likely 210 provided sterilizing immunity, in the upper and lower respiratory tract in all but one macaque.This study demonstrates that immunization with SARS-CoV-2 Spike either as a protein RBD-213 scNP or as an mRNA-LNP elicits a cross-reactive antibody response capable of neutralizing 214 multiple SARS-related human and bat betaCoVs. These results demonstrate that SARS-CoV-2 vaccination with either the RBD-scNP or the stabilized transmembrane spike mRNA-LNP 216 vaccines currently approved for use in humans, will likely elicit cross-neutralizing antibodies with 217 the potential to prevent future animal CoV spillover events to humans 30, 42, 45 Phase I clinical study using 3M-052/Alum to induce neutralizing antibody responses to an HIV 232 vaccine candidate is underway (NCT04177355). Thus, this vaccine modality represents a 233 promising first-generation pan-group 2b betaCoV vaccine with the potential to durably inhibit 234 future zoonotic transmission 25 .The emergence of SARS-CoV-2 neutralization-resistant and highly infectious variants continues 237 to be a concern for vaccine efficacy. We found here that protein nanoparticle or mRNA-LNP 238 SARS-CoV-2 spike immunization elicited SARS-CoV-2 neutralizing antibodies capable of 239 neutralizing the predominant SARS-CoV-2 variant D614G as well as the newly-emerged B. Representative results from two independent experiments are shown. Processing of negative stain images. The RELION 3.0 program was used for all negative 648 stain image processing. Images were imported, CTF-corrected with CTFFIND, and particles 649 were picked using a spike template from previous 2D class averages of spike alone. Extracted 650 particle stacks were subjected to 2-3 rounds of 2D class averaging and selection to discard junk 651 particles and background picks. Cleaned particle stacks were then subjected to 3D classification 652 using a starting model created from a bare spike model, PDB 6vsb, low-pass filtered to 30 Å.Classes that showed clearly-defined Fabs were selected for final refinements followed by sgRNA E (copies/mL) 10 2 10 3 10 4 10 5 10 6 10 7 10 8 sgRNA E (copies/mL)",USA,first author,2021-02-17,02
66f0374c67eb6cc9d3519a6a4810ef943d8070be,A comparison of performance metrics for cloth face masks as source control devices for simulated cough and exhalation aerosols,"Humans infected with SARS-CoV-2, the virus that causes coronavirus disease 2019 , can produce droplets and aerosols of respiratory fluids containing the virus when they cough, breathe, talk, sing and sneeze CDC 2020d; Hamner et al. 2020; Ma et al. 2020; Morawska and Milton 2020) . To reduce the transmission of SARS-CoV-2, public health agencies have recommended that the general public wear cloth masks (CDC 2020a; b; 2021; Edelstein and Ramakrishnan 2020; WHO 2020) . The primary purpose of masks, which includes face masks, neck gaiters, bandanas and other face coverings, is to block the expulsion of infectious droplets and aerosols from the wearer into the environment (called source control) and thereby reduce the exposure of other people to the virus (CDC 2020c). Laboratory studies using manikins and human subjects have shown that cloth face masks can partially block respiratory aerosols produced during coughing, breathing and talking (Asadi et al. 2020; Davies et al. 2013; Lindsley et al. 2021; Pan et al. 2020) . Wearing medical face masks (i.e., 'surgical masks' as defined by the U.S. Food and Drug Administration (FDA 2004) ) reduces the dispersion of potentially infectious aerosols from patients with respiratory infections (Leung et al. 2020; Milton et al. 2013) . Masks may also provide some personal protection to the wearer by reducing their exposure to infectious droplets and aerosols produced by that mask mandates were associated with lower incidence rates of COVID-19 (Van Dyke et al. 2020) . A study of 10 US states found that statewide mask mandates were associated with a decline in weekly COVID-19-associated hospitalization growth compared to states without such mandates (Joo et al. 2021) .In response to the need for source control devices for the general public, manufacturers worldwide have produced a broad array of masks. Unfortunately, because of the many different designs and construction materials, it is not possible to predict how well a particular mask will perform as a source control device without testing, which is rarely done for non-medical masks not intended for occupational use. Although general guidelines have been developed (CDC 2020b) , it is very difficult for public health organizations, governments, medical facilities, and the general public to know which of the available devices are most effective.Test methods and performance standards do exist for regulated medical face masks and respiratory protective devices (Rengasamy et al. 2017 ). In the United States, respiratory protective devices, which are devices such as N95 filtering facepiece respirators that are intended to protect the wearer from airborne particles, must be approved by the National Institute for Occupational Safety and Health (NIOSH) under 42In addition to filtration performance, how well a respiratory protective device protects the wearer depends upon how well the device fits the face and whether the seal between the face and the device has gaps or leaks (Lawrence et al. 2006) . ASTM Standard F3407-20 outlines procedures for testing respirators using a bivariate panel of human test subjects with different facial dimensions (ASTM 2020). The NIOSH approval test measures the filtration properties of respirators and masks but does not include tests of how well the device fits faces of different shapes, although this has been proposed.Consequently, in the United States, when a worker is required to wear a respirator, the Occupational Safety and Health Administration (OSHA) requires that a respirator fit test be performed annually for each worker to determine how well the respirator protects the worker (OSHA 2020). Quantitative fit tests measure the aerosol particle concentration inside and outside the respirator during a series of exercises, and this information is used to calculate the fit factor (outside concentration/inside concentration) (Janssen and McKay 2017) . The minimum acceptable fit factor for a respirator depends upon the exposure level and potential health consequences of the hazards to which the worker may be exposed (OSHA 2020).The purpose of this study was to compare the source control performance of a variety of N95 respirators, medical masks, and cloth masks with the filtration efficiency, airflow resistance, fit factor measured using manikin headforms, and fit factor measured on humans. The results of these experiments will assist in the development of appropriate test methods and standardized performance metrics to evaluate the efficacy of cloth masks as source control devices for respiratory aerosols.""Surgical masks"" may include masks that are labeled as a surgical, laser, isolation, dental or medical procedure masks with or without a face shield. Surgical masks may be variably shaped, (e.g., duck bill, flat pleated, cone shaped, pouch). They are loose-fit and are not expected to provide as reliable a level of protection against airborne or aerosolized particles as N95 respirators regulated by NIOSH.A source control measurement system was used to assess the efficacy of N95 respirators, medical masks, and cloth masks as source control devices for respiratory aerosols. The source control performance was determined by measuring the collection efficiency of the mask, which is the fraction of the mass of the coughed or exhaled test aerosol particles that were blocked by the mask from reaching the collection chamber. Fit tests were performed both on a manikin headform with pliable skin and with human test subjects.The filtration efficiencies and airflow resistance of the construction materials were measured using a modified version of the test method used for respirator approvals. The source control experiment results were then compared with the fit factors, filtration efficiencies and airflow resistances measured on the same devices.The efficacy of respirators, medical masks, and cloth masks as source control devices for aerosols produced during coughing and exhalation was determined using a respiratory aerosol source control measurement system described previously .The system includes a coughing and breathing aerosol simulator, a manikin headform, an aerosol collection chamber, and a cascade impactor (Figure 1 ). The manikin headform used in the study has pliable skin that mimics the elastic properties of human skin in order to create a realistic simulation of how each source control device would fit a human face (Bergman et al. 2014 ).The test aerosol was produced using a solution of 14% potassium chloride (KCl) and 0.4% sodium fluorescein in a single-jet Collison nebulizer (BGI, Butler, NJ) at 103 kPa (15 lbs./in 2 ). The aerosol passed through a diffusion drier (Model 3062, TSI, Shoreview, MN), mixed with dry filtered air flowing at 10 L/min for the cough tests and 15 L/min for the breathing tests, and neutralized using a bipolar ionizer (Model HPX-1, Electrostatics). An elastomeric bellows driven by a computer-controlled linear motor produced the coughing or breathing airflow.For cough tests, the test aerosol was loaded into the elastomeric bellows and then coughed out using a single cough with a volume of 4.2 L and a peak flow rate of 11 L/s (Lindsley et al. 2013 ). An Andersen cascade impactor (Model TE-10-830, Tisch Environmental) collected all aerosol particles that traveled through or around the device for 20 minutes after each cough. The impactor operated at a flow rate of 28.3 liters/minute and had six collection stages and a filter that separated the aerosol particles into seven size fractions based on the aerodynamic diameter of the particles: <0.6 µm;For breathing tests, the system used a ventilation rate of 15 L/min with a breathing rate of 12 breathes/min and a tidal volume of 1.25 liters, which corresponds to the ISO standard for a female performing light work (ISO 2015) . The test aerosol was only generated for the first 30 seconds of breathing to avoid overloading the impactor.The breathing continued for 20 minutes total. The impactor collected the aerosol particles in the chamber during the 20-minute breathing period followed by an additional five minutes of collection after the breathing had stopped.The filtration efficiency and airflow resistance of the construction materials were measured using automated filter testers (Models 8130 and 8130A, TSI). Material samples were secured to a test plate using beeswax as shown in Figure S4 in the SI.Measurements were made using a modified version of the NIOSH standard testing procedure (STP) (NIOSH 2019). Under the modified STP, samples were tested at ambient temperature and humidity but were not subjected to conditioning at 38° C and 85% relative humidity for 25 hours, and sample testing was limited to 10 minutes. The device to be tested was oriented in the filter tester so that the air and aerosol flowed from the exterior of the device toward the interior (that is, as if the wearer were inhaling, which is the same direction as when testing a respirator as a personal protective device). The challenge aerosol was generated using a 2% sodium chloride (NaCl) solution in distilled water, conditioned to 25°C and 30% relative humidity and neutralized to the Boltzmann equilibrium state. The challenge aerosol had a count median diameter of 75 nm ± 20 nm, a mass mean diameter of 260 nm and a geometric standard deviation (GSD) ≤ 1.86 (TSI 8130A specifications). The automated filter tester compares particle concentration readings from upstream and downstream light-scattering laser photometers to calculate the material filtration efficiency. An electronic pressure transducer measures the pressure difference across the material sample to indicate airflow resistance. Tests were performed with an airflow of 85 L/minute. for use under a CC0 license.A convenience sample of eleven subjects (six males and five females) participated in fit testing. Subjects complied with CDC/NIOSH guidelines for facial hair styles intended for workers who wear tight-fitting respirators (CDC 2017). Fit testing was performed with a An NaCl aerosol generator (Model 8026, TI) was used to supplement the naturally occurring particles in the air. The particle generator was placed 10 feet away from all sampling apparatus and fit testing equipment. The generator was turned on ten minutes prior to testing to seed aerosols and turned off while a triplicate series of fit tests were performed (around 7 minutes). As the aerosol concentration in the room had started to slightly decline at this point, the generator was turned on between tests (around 7 minutes) and then turned off during subsequent tests. This process was repeated until testing for the day was completed.To verify that suitable aerosol concentrations were present during testing, particle concentrations were measured with a condensation particle counter (CPC Model 3775, for use under a CC0 license.Each source control device was tested by three subjects; for each subject three replicate measurements were made using each of the two protocols described below. One individual administered all fit tests. Subjects were instructed in the proper donning of medical masks and respirators, and they were asked to don cloth masks in the manner that they ordinarily don similar coverings for public use. If a cloth mask was too large, it was modified using materials that would be accessible to most lay individuals: tape was used to shorten mask ear loops or head straps, and a binder clip was used to decrease the circumference of neck gaiters. These adjustments were made so that the covering was held flush to the face, but the materials were not under tension.A fit factor was calculated by the PortaCount® software for all measurements (Janssen and McKay 2017; TSI 2015) . The fit factor (FF) is calculated as:Where CB = particle concentration in the ambient sample taken before the respirator sample.for use under a CC0 license.Two particle measurement protocols were performed on all source control devices: the PortaCount® N95 Companion protocol (referred to here as N95 mode) , which counts particles 0.025 -0.06 µm in diameter; and the PortaCount® standard protocol (referred to here as all particle sizes mode), which counts particles ranging from 0.02 -1.0 µm (TSI 2010).The source control performance of each source control device was evaluated by calculating the collection efficiency, defined as:Mmask = total mass of the aerosol particles that passed through or around the source control device and was collected by the impactor.Mcontrol = total mass of the aerosol particles collected by the impactor while not wearing a source control device.The aerosol masses collected by the cascade impactor during the experiments are shown in Tables S1 and S2 in the SI. To control for variations in the amount of aerosol in each experiment, a sample of each test aerosol was collected from the bellows prior to coughing or breathing and used to normalize the aerosol mass collection results for each experiment.for use under a CC0 license.Twenty-six cough experiments were performed without a source control device to measure the cough aerosol output from the source control measurement system. The The collection efficiencies of the 19 source control devices are shown in Figure 3 and Table 2 . The mean collection efficiencies of the N95 respirators and the surgical for use under a CC0 license.The mean material filtration efficiencies were >99% for the respirators, 80% to 93% for the medical masks, and 1.4% to 36% for the cloth face masks, neck gaiters, and bandanas, except for the Besungo sports mask at 98% (Figure 4 and Table 2 ). The inhalation airflow resistances were from 5.2 to 154 Pa (Table 2) . When comparing the data for all devices, the filtration efficiencies showed a good correlation with cough aerosol collection efficiency (r = 0.74, p < 0.0001) and exhaled aerosol collection efficiency (r = 0.72, p = 0.0001; Table 3 ). For the group of cloth masks, the correlations were not as strong; the cough aerosol collection efficiency and filtration efficiency had an r of 0.46 (p = 0.0263) while the exhaled aerosol collection efficiency and filtration efficiency had an r of 0.44 (p = 0.0355; Table 4 ). The airflow resistance did not correlate as well as the filtration efficiency when all devices were considered (r = 0.43 and p = 0.0235 for coughing; r = 0.41 and p = 0.0277 for exhalation). However, when examining the cloth masks alone, the airflow resistance was slightly better correlated than filtration efficiency (r = 0.48 and p = 0.0219 for coughing; r = 0.57 and p = 0.0068 for exhalation).for use under a CC0 license.The fit factors measured on the human test subjects are shown in Table 2 and Figure 5 .The mean fit factors for the two N95 respirators were 147.9 and 163.8 when using the N95 mode on the fit tester and 54.9 and 45.3 with the all particle sizes mode. The surgical mask provided a mean N95 mode fit factor of 78.6 and a much lower mean fit factor of 9.6 in all particle sizes mode. The mean N95 mode fit factor of the reusable cloth face masks ranged from 1.4 to 4.0, and the all sizes mode mean fit factors ranged from 1.0 to 2.4. Neck gaiters and bandanas demonstrated N95 mode fit factors ranging from 1.0 to 1.7 and all particle size mode mean fit factors from 1.0 to 1.7. The performance of cloth masks sometimes varied considerably when worn by different subjects.The cough and exhalation aerosol collection efficiencies for all devices were well correlated with the fit factors when measured using the all particle sizes mode (r= 0.81 and p < 0.0001 for coughing, r = 0.86 and p < 0.0001 for exhalation, Table 3 ). When looking at the results for the cloth masks, gaiters, and bandanas in the all sizes mode, the correlations were not as strong, with r = 0.54 for coughing (p = 0.0110; Table 4 ), and r = 0.62 for exhalation (p = 0.0029; Table 4 ). In all cases, the fit factors were significantly correlated with the cough and exhaled aerosol collection efficiencies, and the correlation coefficients were higher when the fit tester was in the all particle sizes mode than when the tester was in N95 mode.The manikin fit factor measurements found using the source control measurement system before the cough tests were 25 to 198 for the N95 respirators and the surgical mask and 1.3 to 7.4 for the procedure mask and cloth masks (Table 2) . Before the breathing tests, for use under a CC0 license.The COVID-19 pandemic has resulted in considerable interest in the performance characteristics of masks and respirators as a means of reducing the person-to-person transmission of SARS-CoV-2. Some studies have looked at the emission of particles from human volunteers wearing different face coverings, which has the advantage of directly examining the expulsion of aerosols into the environment by people (Asadi et al. 2020; Davies et al. 2013; Leung et al. 2020; Li et al. 2020 ). However, the collection and measurement of human-generated respiratory aerosols is challenging and can be hazardous when the subject has a contagious respiratory infection. In addition, the amount and size distribution of aerosol particles produced by people during coughing, breathing and other respiratory activities varies tremendously from person to person and even for a particular person over time, which makes it difficult to directly compare results (Asadi et al. 2019; Fennelly 2020; Gralton et al. 2011; Lindsley et al. 2012 ).Consequently, lab-based surrogate techniques are more frequently used to study source control devices. The most commonly reported methods have been tests of filtration for use under a CC0 license.The source control measurement system used in this study allows for a direct quantitative comparison of the ability of different types of source control devices to block the expulsion of simulated cough and exhaled breath aerosol particles into the environment ). However, the system is complex and requires expertise to operate, and it is neither commercially sold nor easily constructed. In contrast, filtration measurement systems and respirator fit testers are widely available. If a standard methodology could be developed to gauge source control performance using filtration testing and/or fit testing, it could be rapidly expanded and adopted by manufacturers and public health entities.For high efficiency filters such as P100 respirator filters, which filter out 99.97% of airborne particles, a respirator fit test is performed by measuring the concentrations of aerosol particles of all sizes inside and outside the respirator. However, N95 respirators can allow up to 5% of aerosol particles of the most penetrating size to pass through the filtration media. These particles would reduce the apparent fit factor if they were included in the calculation. Thus, when fit testing N95 respirators, the respirator fit tester used in our experiments has a size classifier to count only negatively charged aerosol particles near 55 nm in size (referred to here as N95 mode). For an N95 respirator, these charged 55 nm particles are almost entirely filtered out by the filtration media, and thus any particles detected inside the respirator can then be assumed to have entered through face seal leaks and not through the respirator (Halvorsen 1998; Han and Prell 2010) .Our findings suggest that the results from filtration efficiency and fit factor tests are significantly correlated with measurements made using our source control measurement system. However, our findings also showed that those relationships generally were not very strong. The coefficient of determination (r 2 ) indicates how much the variation in one parameter can be explained by the variation in a second parameter.For example, an r 2 value of 67% would mean that two-thirds of the changes in one parameter can be explained by changes in the other parameter, and that the remaining one-third of the variation is due to other factors or experimental noise. When comparing the source control performance for coughed and exhaled aerosols to the other performance metrics for all the devices, r 2 ranged from 17% to 79% and was statistically significant in all cases (Table 3) . When looking only at the cloth masks in our tests, r 2 ranged from 10% to 44% (Table 4) , which means that even the best metrics explained less than half of the variation in source control performance. For the cloth masks, all but one of the other performance metrics were significantly correlated with the cough and exhaled aerosol collection efficiencies, which suggests that these other measures could be useful as part of a method for testing the performance of cloth masks. However, none of the metrics were strong predictors of source control performance, and no metric was clearly superior to the others.Thus, much of the aerosol then flowed through the mask rather than around it during coughing and breathing tests and the larger aerosol particles that were used in the coughing and breathing tests were filtered out more effectively than the 75 nm particles used in filtration testing. The results presented here are consistent with a previous study by our group in which knotting the Artisan procedure mask to improve the fit increased the cough aerosol collection efficiency to 77%, while wearing a Hanes Defender cloth mask on top of an Artisan procedure mask increased the cough collection efficiency to 85% (Brooks et al. 2021 ). Together, these results also support the recommendation by Gandhi and Marr that members of the public wear a high-quality mask that fits tightly or wear a tight-fitting cloth mask over a surgical mask in order to reduce face seal leaks and improve the source control performance and protection offered by the masks (Gandhi and Marr 2021) .In our tests of cloth masks, the r 2 value for the manikin headform fit tests done before coughing experiments and before exhalation experiments was only 13%, suggesting that differences were occurring even when the same model of mask was being placed on the same headform.Current evidence indicates that masks like those tested in our experiments can substantially decrease the amount of respiratory aerosols released by the wearer, and also help reduce what the wearer breathes in (CDC 2020c). Both effects vary depending upon the material and construction of the mask, as well as how it is worn. In addition to consistent and correct mask use when in the company of others, other measures such as physical separation are important, particularly during brief exposures. In a room where someone sneezes, being six feet or further away is better than being closer. However, with prolonged exposure in the same space for more than a few minutes, the benefit of distance fades as exhaled respiratory aerosols drift, mix, and accumulate in the enclosed air space. Optimizing ventilation, air filtration, and the introduction of fresh air can help counter this effect, but at every distance, correct mask use reduces the risk for everyone.The authors declare no competing interests.This work was supported by the CDC and by the National Institutes of Health under Grants NIH R01 ES015022 (TRN) and NIH U54 GM104942 to the West Virginia University researchers.for use under a CC0 license.for use under a CC0 license.",USA,first author,2021-02-19,02
8d8c9e74e89906836e6683463669d11641210ebc,"A Survey of Residents/Fellows, Program Directors, and Faculty About Telepsychiatry: Clinical Experience, Interest, and Views/Concerns","In its sixth decade, telepsychiatry (TP) or telebehavioral health (TBH)-video-is effective for many types of treatments, psychiatric disorders, and populations (Hilty et al. 2013; Nelson and Sharp 2016; Gloff et al. 2015; Hubley et al. 2016) . Initial concerns about TBH in terms about engagement, disconnections, and other intangibles have subsided, and it appears good enough in comparison to in-person care (Hilty et al. 2013; Nelson and Sharp 2016; Hilty et al. 2002) , in collaboration with primary care Hilty et al. 2018c) , and for diverse populations (Hilty et al. 2018a) and patients in crisis (Freeman et al. 2020) . Recent public health events (i.e., are shifting TP to the forefront of clinical care and training .Interest in TBH by patients, students, and psychiatric residents and fellows has significantly increased from the 1990s and 2000s (Glover et al. 2013; Hilty et al. 2020d ), but technological experiences can be difficult, and early systems had problems; this affected user experience, and some were hesitant to share their concerns (Hilty et al. 2013; Myers et al. 2015) . Residents across medicine have attributed inadequate experience with telemedicine, false beliefs of teachers, and speculation about efficacy as the key limiting factors (Glover et al. 2013; Mucic and Hilty 2018) . Patients, clinicians, and others adopt technology on a continuum from slow to fast based on motivation and other factors like generation/ age (i.e., digital natives versus immigrants) (Wang et al. 2013) . Ironically, as new generations adapt smartphones, social media, and other technologies, they have more personal technology experience than their teachers (Hilty et al. 2020d) .Additional telepsychiatric education has been suggested due to the increasing important of technology in care, growing resident interest, and surveys of programs that show that fewer than half of respondents have an informal clinical experience, and even fewer have a curriculum (Balon et al. 2015; Sunderji et al. 2015; Crawford et al. 2016; Khan and Ramtekkar 2019; Hoffman and Kane (2015) . Similarly, there has been a call for an evidence-based pediatric TP curricula for trainees and practicing child and adolescent psychiatrists (Khan and Ramtekkar 2019) . Video TP competencies, methods for teaching them, and a plan for evaluation have been put forward, framed in the Accreditation Council for Graduate Medical Education Milestone domains (Hilty et al. 2015 (Hilty et al. , 2017 (Hilty et al. , 2018b . This was followed by social media (Zalpuri et al. 2018) , TBH (Maheu et al. 2018; Maheu et al. 2019) , mobile health (Hilty et al. 2019c (Hilty et al. , d, 2020a , and asynchronous (Hilty et al. 2020d) competencies. A key issue though is whether our learners (i.e., residents and fellows) and those teaching them (i.e., clinicians and faculty [Fac] ) can keep up with the growing evidence base of technology clinical interventions and outcomes.This study aimed to assess:1) How much clinical experience or exposure residents, fellows, program directors, and Fac have had with TP, 2) Respondents' views/concerns and interest in TP, and 3) If clinical experience affects interest and concerns, and if there is a threshold of clinical experience helps to allay concerns and increase interest in TP.This may be a valuable pre-COVID snapshot-and could be compared with post-COVID perspectives by investigators with significant resources and a broader sample. We hypothesized that parties' interest in TBH and concerns may be based on clinical experience, and if it was limited, it may lead to inaccurate views/concerns, which would be negatively correlated with current interest and future practice with TP or TBH.The inclusion criteria were willingness to complete the survey and being a psychiatric resident, fellow, clinical Fac, or program director. The link to Survey Monkey was sent by email to academic psychiatric organization listserves (e.g., American Association for Directors of Psychiatry Residency Programs and Association for Academic Psychiatry) with a request to forward it to residents (Rs), fellows (Fs), Fac, and program directors (PDs). Reminder emails were sent at 3-and 6-month follow-up. There were no exclusion criteria. There were no incentives or marketing materials.The survey queried demographics, clinical experience and interest, and views/concerns about TP. The TP interest and clinical were rated with 5-item Likert like questions (Likert 1932 ) (e.g., for experience, options were no(ne), 1, 2-5, 6-20, and 20+ h) . Views/concerns of TP were asked about with 47 yes/no or true/false questions. The inquiry was in English, took 10-15 min to complete, and was anonymous. The survey used the word TP instead of TBH due to professional scope terminology. Surveys were iteratively developed, piloted, and revised before use. General information included professional demographic information including position in training (i.e., R or F but not year of training) or role in the department (i.e., program or fellowship director or Fac) but not sex, race, ethnicity, or age; specialty and subspecialty, if any; and geographic practice setting.The 47 questions about views/concerns were put in the negative to flush out concerns, and many were used or adapted from patient and clinician questionnaires: Working Alliance Inventory-Short Form (Horvath and Greenberg 1989) ; Session Evaluation Questionnaire (Stiles et al. 1994 ; Distance Communication Comfort Scale (Schneider 1999) ; Videoconferencing Telepresence Scale (Robillard and Bouchard 2004) ; and Telemedicine Satisfaction Questionnaire (Yip et al. 2003) . These questionnaires focus on goals of services (i.e., evaluation), the interpersonal contact (e.g., subjective impression, degree of comfort, level of engagement) and tasks achieved (e.g., satisfaction, comparison to in-person visits). Internal and external consistency evaluation of the survey was not conducted.The content of the questions were assorted, but subgrouping was done based on TP themes (Appendix Table 3 ): clinical care effectiveness/ineffectiveness (general impressions, engagement, satisfaction, 9 questions); specific patients/populations (age, culture, disorders or treatments, 9); communication (successes, limitations, 9) ; system/service issues, 6; cost/reimbursement, 4; legal, 4; education/training (clinical with TP, 3); and technical, 3. Reframed into GME competencies, the composite would have been: patient care, 8 questions; systems-based practice, 8; professionalism, 2; communication, 7; practice-based learning, 6; knowledge, 11; and miscellaneous (i.e., impressions rather than competency-specific, 5).Data, statistical analysis and comparisons. Data received by the research team was kept in a password protected file. Before completing analyses, questionnaires were examined for completion; for any missing items, the participant's responses on similar questions from the same category of the questionnaire were substituted (Yip et al. 2003) . Descriptive statistics (e.g., averages and percentages) and proportion of responses (e.g., for cohorts or groups) were calculated for each question. Between and intragroup comparisons (e.g., clinical experience for Rs/Fs versus PDs/Fac) were made when possible (e.g., a Pearson chi-square analysis). Linear regression analysis, including multivariate regression analysis, was performed with participants' clinical experience as primary and interest as secondary factors and then another analysis was conducted in reverse order. For all analyses, a significance level .05 corresponding to a confidence interval of 95% was used to determine statistical significance.An IRB exemption was granted in 2017, as this was an anonymous survey.Subjects totaled 270, with 76 Rs, 47 Fs, 57 PDs, and 90 Fac. Most Rs/Fs responders were from general psychiatry (54%), child and adolescent (33%), and other fellowships (13%; forensic, geriatric, psychosomatic, and substance). The geographic distribution of responders was urban (76%), rural (5%), and both (19%). Rs/Fs reported practicing in urban setting (81%) where academic programs are usually located.Respondents' clinical experience varied with TBH, from none (46%), 1 h (11%), 2-5 h (13%)-69% had less than 5 h (Fig. 1a) versus 79% of Rs/Fs (Fig. 1b) . In terms of their interest in TBH, overall, 68% of respondents were interested or very interested (34% each) (Fig. 2a) ; Rs/Fs had less interest, with 58% interested or very interested (21% and 37%, respectively) (Fig. 2b) .For all Rs/Fs and PDs/Fac, the 10 most common concerns about TP are (Table 1) that one cannot perform a physical exam (54% overall; 67% Rs/Fs); poor Internet connection is a roadblock to implementing TP (52% overall, 57% Rs/Fs); liability risks involved with TP are unknown (47% overall, 52% Rs/Fs); and certain cultures will be less accepting (39% overall, 52% Rs/Fs). Concerns about privacy, effectiveness, managing emergencies, paranoid patients, and disruptive behavior were rated 25-33%, overall, with Rs/Fs having more concerns about emergencies and paranoid patients.Interestingly, 41% of Rs thought residency is insufficient to become competent in TP. Overall, those in the not interested group had less clinical experience and many more concerns.Regression analyses suggest that clinical experience and interest are both negatively associated with concerns, with the former having approximately triple impact. Clinical experience also significantly impacted interest. When interest was run as the primary, it was not predictive of clinical experience but predicted intensity but concerns particularly in the undecided, uninterested, and very uninterested groups.Most had little experience of TP (82%), as in none (66%) or only one encounter (16%) They reported being very interested (25%), interested (33%), undecided (25%), uninterested (10%), and very uninterested (5%). A subanalysis showed that compared to those with no clinical experience, one encounter significantly shifted those interested for very interested from 58% to 74%, increasing the very interested group from 23% to 42%; this implies a group moved from undecided to interested and others moved from interested to very interested.Those with 0-5 h of clinical experience (67%) had many concerns, which were statistically higher than the 6-20 h group ( Table 2 ). The percentages for 0-5 and 6-20 h, respectively, are one cannot perform a physical exam (59-42%); liability risks (54-28%); poor Internet as a road block (54-36%); certain cultures are less accepting (42-31%); and nonverbal cues are missed with TP (41-24%). Perceptions that residency is insufficient and TP as ineffective compared to inperson also decreased.There were many respondents interested or very interested in TP (66%) regardless of clinical experience: 0-1 (42%), 1-5 (11%), 6-20 (10%), or 20+ (27%) h. Respondents with high interest (40%) had concerns about inability to perform a physical exam (55%), poor Internet connection (54%), liability risk (43%), certain cultures are less accepting (40%), and nonverbal cues being missed (30%).Respondents undecided in their interest-56% without any exposure and 23% with 1-5 h-had concerns about inability to perform a physical examination (60%), liability risks (54%), poor Internet connection (50%), privacy as an issue (50%), and that effectiveness as in-person psychiatry (44%).Overview Rs/Fs were numerically, but not statistically, less interested in TP than all participants or PDs/Fac, specifically. Respondents typically practice in an urban setting (81%), have clinical experience with TP (54%), and have significant interest (66%; interested or very interested). Rs/Fs clinical experience with TP ranged from none (46%), 1-5 h (23%), 6-20 h (14%), to 20+ h (17%); not significantly different from all respondents or PDs/Fac.Of the group with 0-5 h of clinical experience, 66% were noted to be interested or very interested in TP, 24% were undecided, and only 8% were uninterested or very All respondents, A.Fig. 1 Clincial exposure or experience to telepsychiatry for all participants versus residents/fellows uninterested. As clinical experience increased, those very interested or interested increased: none (58%); 1-5 h (61%); 6-20 h (78%); and 20+ h (83%)-the shift from 1-5 to 6-20 h was substantial.The concerns for all groups were the inability to perform a physical exam (54%), unknown liability related to TP (59%), poor Internet connection, TP residency training being insufficient, and certain cultures being less accepting of TP (37%). Compared to those with no clinical experience, those with one encounter had less concern about liability (59-36%) but did not change in regard to other parameters. Those with more clinical experience (i.e., 6+ h) had similar concerns to those with 0-5 h of TP that poor Internet connection is a road block to good care and that one cannot perform a physical exam. The 6+ h group had statistically less concerns that nonverbal cues are missed (23%) and that paranoid patient do not like TP (19%).Those with high interest in TP had variable clinical experience with TP-from no encounters (40%), one-time encounter (13%), 2-5 h (11%), 6-20 h (10%), and 20+ h (27%)-and their concerns did not statistically differ from all Rs or all respondents. Of those uninterested or very uninterested-approximately 80% had no clinical experience-concerns that were statistically significant versus all Rs/Fs were loss of nonverbal cues (67%), ineffectiveness (50%), poor Internet connection (50%), and TP as ineffective (50%). Those undecided, uninterested, and very uninterested did not vary from the other groups in clinical experience or types of concerns but had higher percentages of concerns.Residents/fellows, B. Of the 90 respondents with 0-5 h of clinical experience with TP, 57% of these responders reported they are interested or very interested in TP, while 25% were undecided and 16% uninterested or very uninterested. Their concerns did not vary compared to those of all respondents or to Rs/Fs, other than signified specifically in Table 1 . Of note, other concerns were about primary care provider follow-up on consultations (29%), poor reimbursement (26%), and management of disruptive behaviors (23%). While clinical experience more dramatically decreased specific concerns, a closer analysis of moving from 0 to 1 to 2-5 to 6-20 h in this group, respectively, showed trends: ability to perform a physical exam (69% to 12% to 24% to 29%) and Internet connectivity (51% to 15% to 28% to 36%). This suggests two things: All respondent data are skewed by those with 0 h, and there is a learning curve for concerns and skills to mature, with broader perspective and accuracy (Downey and King 1998) .A high percentage (79%) PDs/Fac were noted to be interested to very interested in TP. Their clinical experience varied: 30% none, 10% a one-time encounter, 13% up to 5 h, 9% from 6 to 20 h, and 38% with more than 20 h of TP. The undecided group varied in clinical experience-53% had no clinical experience-and their concerns did not differ from other groups.There are several preliminary findings of this survey about clinical experience with interest in and concerns about TP or TBH. First, respondents had limited clinical experience with TP, probably due to time, competing interests, and number of available TP options; Rs/Fs have even less experience. Second, respondents' interest in TP is high-consistent with other surveys (Gloff et al. 2015; Sunderji et al. 2015) , though it was very surprising that Rs/Fs have less interest than PDs/ Fac, particularly in light of technology adoption data and assumptions (Wang et al. 2013) . Clinical experience is not the same as person experience with technology, of course, in terms of skills (Hilty et al. 2018b ). While it is premature to conclude that a lack of clinical exposure negatively impacts trainee interest in a causal fashion, interest appears to increase with exposure. This is important in another way, too, as a third finding is that physicians or clinicians who are undecided, uninterested, and very uninterested have higher percentages of concerns. Indeed, during a required rotation, Rs had many valuable tele-experiences: establishing rapport and engaging with patients; working collaboratively with a team; identifying different approaches to use; and becoming aware of how to handle complex cases (Teshima et al. 2016 ). This enhanced both interest in participating in TP in the future and understanding of providing psychiatric services to underserved communities. Rs/Fs and PDs/Fac have concerns about effectiveness of clinical care. These include an inability to perform a physical examination, loss of nonverbal cues, managing emergencies, dealing with patients' paranoia, connectivity, and medicolegal issues (e.g., liability). There is no ""gold standard"" for to compare to these respondents' concerns; they may or may not be well-founded. The effectiveness of TP for assessing patients (Hilty et al. 2013; Nelson and Sharp 2016; Gloff et al. 2015; Hubley et al. 2016 ) and establishing a therapeutic relationship (Hilty et al. 2020c ) runs counter to many of these concerns; yet, the TP evidence base needs improvement related to (1) dealing with emergencies (Freeman et al. 2020) ; (2) doing inpatient and acute care (Hilty et al. 2013); and (3) working with culturally diverse populations (Hilty et al. 2018a) . A conceptual framework has been suggested for cultural and video competencies (Hilty et al. 2020b) , along with administrative approaches to reduce barriers, implement successfully, and evaluate outcomes (Hilty et al. 2018a (Hilty et al. , 2020b Guerra and Kurtz 2017) . TP studies related to the treatment of patients with psychosis and delusional frameworks are limited, but few experienced clinicians have concerns; initial assumption that such patients may feel monitored have not been found to be true (Hilty et al. 2013) .Where do clinical care and training go from here? The external mandate to ""flatten the curve"" of COVID-19 spreading will ""accelerate and bend the curve"" of digital health care )-so Fac and trainees are getting more experience. A survey of psychology training programs (Hames et al. 2020) found that some were implementing, planned to implement, or were considering implementing telepsychology services-with trainees and Fac supervisors in the clinics, at home or a combination of both; some academic centers already had TP rotations in place, usually electives, to build upon (Hilty et al. 2019b) . A follow-up survey could capture the impact of clinical service changes and this increase in experience; yet, it is unclear if curricula have been significantly changed for rotations (e.g., teaching and supervision on TP) due to the rapid series of events of this difficult time. PDs/Fac cannot depend on trainees' interest and other positive attitudes alone to develop requisite skills, as they are not a substitute for supervised clinical experience to develop knowledge and skill (Pratt 1998) . At a minimum, Fac and trainees who were uncertain about TP gain experience, and they may embrace TP, or they find that they do not like this technology. It is important that they make a more informed decision about this and that Fac help them with the chaos of the pandemic.PDs/Fac, department chairs, and health system leaders have key decisions to make now and over the next year of the COVID-19 pandemic: (1) services: what % of TP or TBH to shoot for, depending on patient expectations/needs; (2) curricula: return to the past one, largely, with informal changes versus capitalizing to integrate TP or TBH into it; and (3) Fac/ professional development: returning to past activities or similarly capitalizing to integrate technology. PDs have been more inclined to design electives rather than required rotations due to competing demands and resources, though interinstitution pooling of resources may help (i.e., curricula, Fac teachers/supervisors, and evaluation processes). Institutional competencies for TP have been suggested for intervening at the Fac, hospital/clinic system, and academic health center level, by consolidating clinical, training, and Fac development missions around competencies (Hilty et al. 2020d; Armstrong et al. 2004; Hilty et al. 2019a, b) . Six steps to implement new technologies have been suggested: (1) assess readiness; (2) create/hardwire the culture; (3) write policies and procedures; (4) establish the curriculum and competencies; (5) train learners and Fac; and (6) evaluate/manage change (Hilty et al. 2019b) . Two tiers of options for each were provided. For example, to assess readiness, leaders focus on clinical service technology platforms for video, e-mail, and other common technologies and evaluate the workflow and training changes based on the structure/function of groups of their organization. More time and resources, if available, would be needed to tackle the workflow and training changes pertaining to advanced technologies (e.g., mobile health apps, devices, and wearable sensors).Training program and student directors would select, develop, and adapt regular competencies to include technologically based components at a minimum, and a multiyear curriculum would be better, using a mixture of methods including clinical care, seminar, supervision, research/quality improvement projects, case-based learning core rotations, and advanced-year electives/requirements. This work may be aided by identifying a vice-chair of education (or clinical services) or other mid-or advanced-career Fac member to promote technology and liaison with national psychiatric organizations. Core curricular (i.e., didactic and clinical) interventions appear indicated early in training so that tangible clinical experiences may improve Rs/Fs' confidence that education/ training will be adequate in preparation for future practice. While interest may predict concerns to a degree, and attitude (e.g., interest) is important, it is not a substitute for knowledge or skill (Pratt 1998; Hilty et al. 2015) . Training is an opportunity to address Rs and Fac concerns (Hilty et al. 2015; Hames et al. 2020) .Limitations to this report are many. The most important limitation is the concern that the sample size may not be large enough or the sample may not be adequately representative for the results to be reliable. First, there is a potential selection bias (i.e., respondents may have interest in TP). The final sample is small, compared to the total number of psychiatry trainees nationally (i.e., approximately 225 residency programs with 6,700 Rs and 1,200 Fs/year; 51+% of Rs are female with 7% unreported) (American Psychiatric Association 2019) or internationally. Time, high volume email-particularly on the listserves-and other responsibilities were constraints, and there were no incentives to offer. Second, a yes/no survey not as discerning as a Likert-like design and its reliability/validity was not studied. The questions were in the negative to flush out concerns; as in our experience, psychiatrists and Rs do not like to complain or share their concerns. A balance of positive, neutral, and negative is overall better, though. Third, the study did not inquire about the year of residency-this is key since perspectives may change over time; on the other hand, with so few programs doing any curriculum, it may not have changed results. Fourth, the survey did not technically define experience or exposure, so it could have been interpreted as clinical or didactic. Fifth, respondents' self-identified information was not confirmed in terms of how they defined or rated their clinical experience. The ratings were not temporally proximate to the experience, either; the survey attempted to explore ranges of experience rather than specific quantitative data. Sixth, statistically significant correlations do not indicate causation. Seventh, more specific demographic and training data would be helpful (e.g., year of training and year when exposed to TP). Finally, there is no ""gold standard"" for norms to compare the respondents' data to (i.e., normal anxiety about disconnections).Despite the limitations, the current study provides valuable pre-COVID-19 snapshot on TP or TBH experience, interest, and attitudes that may serve as a foundation for further research and training.Overall, the effectiveness of TP or TBH is substantial, and interest in it from Rs/Fs is growing, despite limited training opportunities. If they have more supervised experiences, their skills will help to improve access, timeliness, and quality of care. Training, experience, and supervision will also reduce concerns and improve confidence. Institutional competencies for TP are a systematic way to proceed, and sharing resources across health systems may be helpful. Competency implementation and research are needed to determine how exposure is linked with changes in skills, knowledge, and attitudes. Residency and fellowship training appears to be an ideal time for a TP curriculum, if it is feasible, and the benefit outweighs the cost.Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/. ",United States,abstract,2021-02-09,02
c6edf95d90daaaea677cd003b9d2d996ec78c01b,Inhalable Nanobody (PiN-21) prevents and treats SARS-CoV-2 infections in Syrian hamsters at ultra-low doses,"By January 2021, a year after the outbreak of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) was first reported (1), close to 100 million people have been infected by this highly transmissible virus resulting in significant morbidity and mortality worldwide. In addition to vaccines, there is an unparalleled quest to develop innovative and cost-effective therapeutics to combat the COVID-19 pandemic (2, 3) . Early treatment using high-titer convalescent plasma (CP) may reduce the risk of severe disease in seniors (4) , although CP is limited by supply. Potent neutralizing monoclonal antibodies (mAbs), predominantly isolated from COVID-19 patients for recombinant productions, have been developed for passive immunotherapy (5) (6) (7) (8) (9) (10) (11) (12) (13) (14) . In vivo evaluations of mAbs in animal models of COVID-19 disease such as murine, hamster, and nonhuman primates (NHPs), have provided critical insights into efficacy and the mechanisms by which they alter the course of infection (15) (16) (17) (18) (19) (20) (21) (22) (23) (24) . While mAb therapy lifts hopes to treat mild symptom onset in patients, they nevertheless require exceedingly high administration doses-typically several grams for intravenous (i.v.) injection (25, 26) . The requirement of high doses for efficient neutralization may reflect SARS-CoV-2 virulence, pathogenesis, and the notoriously low efficiency of i.v. delivering these relatively large biomolecules across the plasma-lung barrier to treat pulmonary infections (27) . Moreover, the associated high costs and challenges in bulk manufacturing may further limit the broad clinical use of mAbs worldwide (2) .In parallel efforts, we and others have recently developed camelid single-domain antibody fragments or nanobodies (Nbs) that primarily target the receptor-binding domain (RBD) of the SARS-CoV-2 spike (S) glycoprotein for virus neutralization (14, (28) (29) (30) (31) . Highly selected Nbs and the multivalent forms obtain high neutralization potency comparable to, or even better (per-mass) than, some of the most successful SARS-CoV-2 neutralizing mAbs. In particular, an ultrapotent homotrimeric construct, Pittsburgh inhalable Nanobody 21 (PiN-21), efficiently blocked SARS-CoV-2 infectivity at below 0.1 ng/ml in vitro (28) . Compared to mAbs, Nbs are substantially cheaper to produce. Moreover, affinity-matured, ultrapotent Nbs are characterized by high solubility and stability that facilitate drug scaling, storage, and transportation, all of which are critical in response to pandemics. The excellent physicochemical properties and small sizes of Nbs raise an exciting possibility of efficient pulmonary delivery by aerosolization with characteristics of rapid onset of action, high local drug concentration/bioavailability, and improved patient compliance (needle-free) that may benefit a large population of SARS-CoV-2 infected patients (27) (28) (29) 32) . However, despite the promise, no successful in vivo studies have been reported to date. The inferior pharmacokinetics of monomeric Nbs due to their small size (~15 kDa) and a lack of Fc-mediated immune effectors' function, which is often required to augment the in vivo neutralizing activities of mAbs (33) (34) (35) , drive potential concerns for Nb-based therapy. It remains unknown if the high in vitro neutralization potency of SARS-CoV-2 Nbs can be translated into in vivo therapeutic benefits.In this study, we systematically evaluated the efficacy of PiN-21 for prophylaxis and treatment of SARS-CoV-2 infected Syrian hamsters which model moderate to severe COVID-19 disease. We provided direct evidence that ultra-low administration of PiN-21 efficiently treats the virus infection. Notably, PiN-21 aerosols can be inhaled to target respiratory infection which drastically reduces viral loads and prevents lung damage and viral pneumonia. This novel Nb-based therapy shows high potentials for the treatment of early infection and may provide a robust and affordable solution to address the current health crisis.To assess the in vivo efficacy of PiN-21, 12 hamsters were divided into two groups and infected with 9 x 10 4 plaque-forming units (p.f.u.) of SARS-CoV-2 via the intratracheal (IT) route. Shortly after infection, Nb was delivered intranasally (IN) at an average dose of 0.6 mg/kg (Fig 1A) . Animals were monitored daily for weight change and clinical signs of disease. Half of the animals were euthanized 5 days post-infection (d.p.i.) and the remaining were euthanized 10 d.p.i. Virus titers in lung samples from the euthanized animals were measured by plaque assay. Nasal washes and throat swabs were collected at 2 and 4 d.p.i. to determine viral loads in the upper respiratory tract. Consistent with published studies (36, 37) , IT inoculation of hamsters with SARS-CoV-2 resulted in a robust infection, rapid weight loss in all animals up to 16% at 7 d.p.i. and resulting recovery and reversal of weight loss by 10 d.p.i. before recovery. However, concurrent IN delivery of PiN-21 eliminated any significant weight loss in the infected animals (Fig 1B) . This dramatic protection was accompanied by a reduction of viral titer in the lungs, with an average decrease of 4 order of magnitude in the lung tissue, respectively, compared to control on 5 d.p.i. (Fig 1C) . Consistently, a 3-log reduction of the viral genomic RNA (gRNA) by reverse transcriptase (RT)-qPCR was evident on 5 and 10 d.p.i. (Fig S1A-B) . Infectious virus was essentially cleared by 10 d.p.i.Notably, the virus was undetectable in the upper respiratory tract (URT) including both nasal washes and throat swabs of all PiN-21-treated animals on 2 d.p.i. This is significantly different from the control group, where varying levels of infectious virus were present (Fig 1D-E) . Furthermore, five out of six PiN-21 treated animals remained protected from detectable infection 4 d.p.i. The results were further supported by a drastic decrease of gRNA in the URT (Fig S1C-D) . Together, this demonstrates that the high in vitro neutralization potency of PiN-21 can be translated into therapeutic benefits in vivo independent of Fc-mediated immune responses. PiN-21 can efficiently protect SARS-CoV-2 infection in hamsters by rapidly and drastically suppressing viral replication in both the URT and lower respiratory tract (LRT).Previous studies reveal that clinical mAbs are less effective for COVID-19 treatment (post-infection) than for prophylaxis (pre-infection) in animal models, possibly reflecting the virulence of SARS-CoV-2, speed of virus replication, and rapid symptom onset (15, 22, 38) . Therefore, we evaluated the therapeutic potential of PiN-21 since it was highly effective when co-administered. To explore the second route of infection, hamsters were inoculated IN with 3 x 10 4 p.f.u. of SARS-CoV-2. PiN-21 or a control Nb (0.6 mg/kg) was IN-delivered to animals 6 hours post-infection (h.p.i.). Animal weights were monitored daily, throat swabs and nasal washes were collected, before euthanized on 6 d.p.i. (Fig S2A) . Similar to the IT route, IN-infection of hamsters with SARS-CoV-2 resulted in precipitous weight losses in the control animals. Encouragingly, intranasal treatment using PiN-21 significantly reduced weight loss throughout the assessment period (Fig S2B) , paralleling the results of clinical mAbs in the same model albeit using substantially higher doses. Less than 100-fold reduction in virus titers were found in nasal washes and throat swabs on 2 and 4 d.p.i. (Fig S2C-D) . Moreover, infectivity was undetectable in lung tissues 6 d.p.i., indicating that the virus has been predominantly cleared. Analysis of early time points will be needed to better understand virus suppression by Nb treatment.The marked physicochemical properties of PiN-21 prompted us to evaluate pulmonary delivery by inhalation. To evaluate the impact of construct size and pharmacokinetics on lung uptake, we fused monomeric Nb21 and PiN-21 to an Nb that binds serum albumin (Alb) of both human and rodents with high affinity to generate two serum-stable constructs (Nb-21 Alb and PiN-21 Alb ) (39) . Using a portable mesh nebulizer, we aerosolized Nb21 Alb , PiN-21, and PiN-21 Alb and evaluated their post-aerosolization neutralization activities by pseudovirus neutralization assay. All constructs retained high neutralization potency in vitro (Fig S3B) . The amount of Nbs recovered post-aerosolization was inversely correlated with the size of constructs (Fig S3A) . Moreover, while Nb-21 Alb had the highest recovery, the post-aerosolization in vitro neutralization activity was substantially lower than for other constructs, Nb-21 Alb was therefore excluded from downstream therapeutic analyses.Next, we compared two ultrapotent constructs PiN-21 and PiN-21 Alb for targeted aerosolization delivery into hamsters. Nbs were aerosolized using a nebulizer (Aerogen, Solo) that produces small aerosol particles with a mass median aerodynamic diameter of ~ 3 µm (Table S1 ). Animals were sacrificed 8 and 24 hours post-administration to assess Nb distribution and activities when recovered from various respiratory compartments and sera (Fig 2A) . Consistent with the result using the portable nebulizer, we found the inhalation dose of PiN-21 was approximately two times PiN-21 Alb (at 8 h, 41.0 µg or 0.24 mg/kg for PiN-21 v.s. 23.7 µg or 0.13 mg/kg for PiN-21 Alb ) (Table S1) while neutralization activity as assessed by plaque reduction neutralization test (PRNT 50 ) of SARS-CoV-2 remained essentially unchanged after aerosolization of both Nb constructs (Fig 2B) .The neutralization activities of both Nb constructs were detected throughout the respiratory tract and in sera. As expected, within the airways the neutralizing activities were predominantly associated with bronchoalveolar lavage (BAL) fluid, followed by tracheal aspirate, larynx wash, and nasal wash samples (Fig  2C-D) . Compared to 8-hour post-inhalation, we found that the amounts and activities of Nbs in BAL, but not in sera, were substantially lower 24-hour post-inhalation, possibly indicating more rapid clearance. In addition, Nb conjugation to serum albumin did not seem to impact the activities in the airways, whilst stability was enhanced in the serum. These data underscore the requirement of an ultra-low dose of the ultrapotent PiN-21 construct to neutralize SARS-CoV-2 infectivity in vivo efficiently. Finally, PiN-21 was preferentially selected for further evaluation owing to the high stability and resistance to aerosolization, which are likely critical for clinical applications.To assess the therapeutic efficacy of PiN-21 by inhalation, 12 hamsters were IN inoculated with SARS-CoV-2 (3 x 10 4 p.f.u.) followed by single-dose aerosolization treatment of either PiN-21 or the control Nb at 6 h.p.i. Animals were monitored for weight loss, throat swabs and nasal washes were collected daily. Animals were euthanized (3 d.p.i.) and lungs and trachea were collected for virological, histopathology, and immunohistochemical analysis (Fig 3A) . Notably, pulmonary delivery of PiN-21 aerosols, despite only a minute amount, led to a remarkable reverse of weight loss in the treated animals. The average weight gain was 2% in PiN-21 versus 5% loss in the control on 3 d.p.i. (Fig 3B) . The weight loss in the control group was highly reproducible when compared with the above experiments. Critically, aerosolization treatment diminished infectious viruses in lung tissue by 6 orders of magnitude (Fig 3C) . The treatment also substantially decreased virus gRNA in the lungs (Fig S4C) . Moreover, we observed a substantial reduction of viral titers in nasal washes and throat swabs (Fig S4A-B) . This indicates that Nb administration by aerosolization may limit human-to-human transmission of SARS-CoV-2.To understand the mechanisms by which Nb aerosols prevent and/or ameliorate lower respiratory disease caused by SARS-CoV-2 infection better, we performed whole lung semi-quantitative ordinal histologic analysis of control (n=6) and PiN-21 (n=6) treated animals euthanized at 3 d.p.i (Table S2-3) . Cumulative scores encompassed pathologic features of airways, blood vessels, and alveoli/pulmonary interstitium. PiN-21 aerosolization protected most animals (5/6) from severe COVID-related histopathologic disease reflected by decreased ordinal scores (P < 0.0001) when compared to Nb treated controls (Fig 3D, Table S4 ). Histopathologic findings in the control group resembled previous reports of SARS-CoV-2 inoculation in Syrian hamsters (40, 41) . Pulmonary disease observed in the PiN-21 treated animals was very mild (Fig 3E, Fig S5) being characterized by the absence of severe necrotizing bronchiolitis in the majority of animals (5/6), a pathological finding ubiquitously observed in all control animals. Furthermore, the single PiN-21 treated animal with necrotizing bronchiolitis had localized disease, compared to the multifocal and bilateral distribution observed in most Nb controls (4/6). Bronchiolitis was also affiliated with less severe bronchial hyperplasia and hypertrophy and absence of syncytial cells when compared to Nb controls. The predominant histologic finding in PiN-21 treated animals was minimal-to-mild perivascular and peribronchial mononuclear inflammation consisting of macrophages and lymphocytes. Furthermore, aside from the one animal already mentioned, the PiN-21 group had considerably less interstitial inflammation with decreased vascular permeability, as indicated by the absence of perivascular and intra-alveolar edema, hemorrhage, and fibrin exudation (Fig S5) .In control animals, S antigen was abundant in the cytoplasm of the bronchiolar epithelium, with less common detection in alveolar type 1 and 2 pneumocytes. Interstitial and peribronchiolar infiltrates were composed of large numbers of CD3e+ T cells and CD68+ macrophages, with a complete absence of angiotensin-converting enzyme 2 (ACE2) in the apical cytoplasm of bronchiole epithelium in areas with abundant viral S (Fig 3F, upper panel) . Consistent with a striking 6-log virus reduction after aerosolization, S antigen was extremely sparse (<1% of permissive cells) in all PiN-21 treated animals, with decreased T cell and macrophage immune cell infiltrate, and retention of native apical bronchiole ACE2 expression (Fig 3F,  lower panel) .To determine the impact of PiN-21 on the upper airways of the lower respiratory tract we also examined the trachea histologically. In PiN-21 treated animals, tracheas for all animals were within normal limits, while mild to moderate neutrophilic and lymphohistiocytic tracheitis, with variable degrees of degeneration and necrosis, and segmental hyperplasia and hypertrophy were observed in all the control animals (Fig 3F) . In summary, our data clearly demonstrate that PiN-21 aerosolization given during early disease course is highly effective in decreasing SARS-CoV-2 entry, subsequent replication in permissive epithelial cells of the lower respiratory tract and this, in turn, has a major impact on viral shedding. The result is the prevention of disease, including decreased cytopathic effect on permissive epithelial cells, retention of ACE2 expression on permissive bronchioles, and decreased recruitment of inflammatory cells to sites of replication.In this work, we demonstrate the high therapeutic efficacy of a trimeric Nb against SARS-CoV-2 infection in Syrian hamsters. Our investigations leverage both intranasal and aerosol delivery of PiN-21 and demonstrate Nb treatment effectively targets the deep and local pulmonary structures such as terminal alveoli, which are lined with alveolar cells rich in ACE2 receptor to block viral entry and replication efficiently. Moreover, infection-induced weight loss correlates with pulmonary virus titer (Pearson r = -0.7) (Fig S6) and this clinical sign may be used to indicate the onset of infections (13) . Notably, the ability of PiN-21 to eradicate viral replication and lung pathology almost completely in both the URT and LRT in hamsters contrasts the effects recently shown by clinical antibodies, which remain particularly challenging to treat SARS-CoV-2 infection in the same model (15) .Significantly improved delivery upon aerosolization may be anticipated in NHPs and humans since airway anatomical structures differ considerably from small rodents in which a high degree of inertial impaction is seen using liquid droplets. Several inhalation therapeutics with excellent safety profiles are commercially available and many are under clinical trials (27, 42) . A combination of extremely low deposit doses will minimize potential adverse effects. We envision that PiN-21 aerosolization treatment could provide both a convenient and cost-effective solution to alleviate disease onset and reduce virus transmission, especially for mild COVID-19 patients who constitute major populations of infections. It may also benefit high-risk groups, such as seniors, immunocompromised individuals, and infants, in both inpatient and outpatient settings. Finally, as prevalent circulating variants of SARS-CoV-2 have emerged to evade clinical antibodies and wane vaccine-elicited serologic responses (43) (44) (45) (46) (47) , this proof-of-concept study will shed light on the use of stable, multi-epitope and multivalent Nb constructs, in combination with PiN-21, as a novel aerosol cocktail to effectively block virus mutational escape (28) . Reduction of viral titers in hamster lungs (3 d.p.i.). Significant differences were observed between treated and control groups. **, P < 0.01; *, P < 0.05. The dashed line indicates the detection limit of the assay.Lung pathology scores of treated and control groups. Significant difference was denoted by ****, P < 0.0001. E. H&E staining of necrotizing bronchointerstitial pneumonia affiliate with abundant SARS-CoV-2 S antigen in bronchiole epithelium and alveolar type 1 and 2 pneumocytes in the control group. All images acquired at 20 x, scale bar = 100 µm. Areas marked by boxes are shown at higher magnification in the right-most panel (scale bar = 25 µm). The animal work performed adhered to the highest level of humane animal care standards. The University of Pittsburgh is fully accredited by the Association for Assessment and Accreditation of Laboratory Animal Care (AAALAC). All animal work was performed under the standards of the Guide for the Care and Use of Laboratory Animals published by the National Institutes of Health (NIH) and according to the Animal Welfare Act guidelines. All animal studies adhered to the principles stated in the Public Health Services Policy on Humane Care and Use of Laboratory Animals. The University of Pittsburgh Institutional Animal Care and Use Committee (IACUC) approved and oversaw the animal protocols for these studies (#20067405).All work with SARS-CoV-2 was conducted under biosafety level-3 (BSL-3) conditions in the University of Pittsburgh Center for Vaccine Research (CVR) and the Regional Biocontainment Laboratory (RBL). Respiratory protection for all personnel when handling infectious samples or working with animals was provided by powered air-purifying respirators (PAPRs; Versaflo TR-300; 3M, St. Paul, MN). Liquid and surface disinfection was performed using Peroxigard disinfectant (1:16 dilution), while solid wastes, caging, and animal wastes were steam sterilized in an autoclave.The PiN-21 construct was synthesized from Synbio Biotechnologies. Nb21 Alb and PiN-21 Alb were generated by sub-cloning a human serum albumin binding Nb (39) into the N-terminus of Nb21 and PiN-21 constructs (28). The plasmid was transformed into BL21 (DE3) cells and plated on LB-agar with 50 µg/ml ampicillin at 37°C overnight. Single bacterial colonies were picked and cultured in LB broth to reach an O.D. of ~ 0.5-0.6 before IPTG induction (0.5 mM) at 16°C overnight. Cells were then harvested, sonicated, and lysed on ice with a lysis buffer (1xPBS, 150 mM NaCl, 0.2% TX-100 with protease inhibitor). After cell lysis, his-tagged Nbs were purified by Cobalt resin and natively eluted using the imidazole buffer. Eluted Nbs were subsequently dialyzed into 1x DPBS, pH 7.4. For animal studies, endotoxin was removed with the ToxinEraser™ Endotoxin Removal Kit (Genscript), and the endotoxin level was measured using the ToxinSensor™ Chromogenic LAL Endotoxin Assay Kit (Genscript) to make sure <1 EU/ml. The proteins were sterile-filtered using the 0.22 μm centrifuge filters (Costar) before use.The SARS-CoV-2 isolate used was a passage 3 (p3) of the Munich isolate described previously (48) . The virus was titrated by plaque assay and titers are expressed as plaque-forming units (p.f.u.) per ml.Syrian hamsters (aged 3-6 months old both male and female) were obtained from the Charles River, MA. For procedures (virus infection, throat swab, and nasal wash collection), each animal was sedated with 3-5% Isoflurane. Baseline body weights were measured for all animals before infection. The animals were monitored twice daily for signs of COVID-19 disease (ruffled fur, hunched posture, labored breathing, anorexia, lethargy) post-challenge with SARS-CoV-2. Bodyweight was measured once daily during the study period. At necropsy, small pieces of the lung were collected for viral load determination. Throat swabs were collected using ultrathin swabs (Puritan™ PurFlock™ Ultra Sterile Flocked Swabs) which were placed in Opti-MEM (Invitrogen) containing double strength Antibiotic-Antimycotic (anti-anti; Life technologies). Nasal washes were collected using 500 µl of PBS with anti-anti. All samples were stored at -80 o C until viral load determination. The whole trachea and lungs were collected in Opti-MEM, triazole, or 4% PFA respectively for virus titrations, RT-qPCR, and histopathological examinations. Lungs with trachea were harvested from euthanized animals. A Sovereign Feeding Tube (Covetrus) was cut to the optimal length and connected to a 5 ml syringe (BD) containing 3 ml PBS with anti-anti before placement into the trachea. The PBS was gently pushed into the lungs until they were fully inflated after which the liquid (BAL) was drawn back into the syringe.For tissues, 100-200 mg of tissue was harvested, suspended in 1 ml Opti-MEM supplemented with 2X antianti, and homogenized using a D2400 homogenizer (Benchmark Scientific). The eluate from swabs and nasal washes were analyzed directly. Virus isolations were performed by inoculation of tissue homogenates (100 μl) onto Vero E6 cells (Hartman et al, 2020) . For the preparation of RNA, tissue homogenate, swab eluate, or nasal wash (100 μl) was added to 400 μl of Trizol LS (Ambion) and thoroughly mixed by vortexing. To ensure virus inactivation, the samples were incubated for 10 minutes at room temperature and stored overnight at -80°C prior to removal from the BSL-3 facility. Subsequent storage at -80°C or RNA isolation and one-step RT-qPCR analyses were performed at BSL-2. RNA was extracted from these samples using Direct-zol RNA purification kits (Zymo Research) according to the manufacturer's instructions. Viral RNA was detected by RT-qPCR targeting the SARS-CoV-2 nucleocapsid (N) segment as previously described (48) . Data were normalized by tissue weight and are reported as copies of RNA determined by comparing the cycle threshold (C T ) values from the unknown samples to C T values from a positive-sense SARS-CoV-2 vRNA standard curve as previously described (48) . Graphs were generated using GraphPad Prism, version 9.Nbs or hamster serum dilution (100 µl) was mixed with 100 µl of SARS-CoV-2 (Munich : P3 virus) containing 75 p.f.u. of the virus in Opti-MEM. The serum-virus mixes (200 µl total) were incubated at 37°C for 1 h, after which they were added dropwise onto confluent Vero E6 cell monolayers in six-well plates. After incubation at 37°C, 5 % (v/v) CO2 for 1 h, 2 ml of 0.1 % (w/v) immunodiffusion agarose in DMEM supplemented with 10 % (v/v) FBS and 2× anti-anti was added to each well. After incubation at 37°C, 5 % (v/v) CO 2 for 72 h, the agarose overlay was removed and the cell monolayer was fixed with 1 ml/well formaldehyde [37 % (w/v) formaldehyde stabilized with 10-15 % (v/v) methanol] for 20 min at room temperature. Fixative was discarded and 1 ml/well 1 % (w/v) crystal violet in 10 % (v/v) methanol was added. Plates were incubated at room temperature for 20 min and rinsed thoroughly with water. Plaques were then enumerated and the 80 % and/or 50% plaque reduction neutralization titer (PRNT 80 or PRNT 50 ) was calculated (28, 48) . Controls of a validated SARS-CoV-2 antibodynegative, positive human serum, and an uninfected cell, were performed to ensure that virus neutralization was specific.Aerosol exposures of hamsters to nanobodies were performed under the control of the Aero3G aerosol management platform (Biaera Technologies, Hagerstown, MD) as previously described for rodents (49) . Hamsters were loaded into metal exposure cages and transported via mobile transfer cart to the Aerobiology suite in the RBL. There they were transferred into a class III biological safety cabinet and placed inside a rodent whole-body exposure chamber. Hamsters were exposed for 12-15 minutes to small particle aerosols containing nanobodies generated by the Aerogen Solo vibrating mesh nebulizer (Aerogen, Chicago, IL) (19) . The system was set in a push/pull configuration with an equal volume of input air (19.5 liters per minute (lpm) total: 7.5 lpm generator, 12 lpm dilution air) and exhaust (19.5 lpm total: 6 lpm sampler, 5 lpm particle sizer, 8.5 additional vacuum) equal to 0.5 air changes/minute in the exposure chamber. To determine inhaled dose, an all-glass impinger (AGI; Catalog # #7541-10, Ace Glass, Vineland, NJ) containing 10 ml of PBS + 0.001% antifoam was attached to the chamber and operated at 6 lpm, -6 to -15 psi. Particle size was measured once during each exposure at 5 minutes using an Aerodynamic Particle Sizer (TSI, Shoreview, MN) operating at 5 lpm. A 5-minute air wash followed each aerosol, after which animals were returned to their cage. AGI samples were evaluated to determine the concentration of nanobodies recovered from the aerosol. The inhaled dose was determined as the product of the nanobody aerosol concentration, duration of exposure, and the minute volume of the individual hamster (50) . Minute volume was determined using Guyton's formula (51) .Tissue samples were fixed for a minimum of 24 h in 4% PFA before being removed from BSL-3 and subsequently processed in a Tissue-Tek VIP-6 automated vacuum infiltration processor (Sakura Finetek) and embedded in paraffin using a HistoCore Arcadia paraffin embedding machine (Leica). 5 μm tissue sections were generated using an RM2255 rotary microtome (Leica) and transferred to positively charged slides, deparaffinized in xylene, and dehydrated in graded ethanol. Tissue sections were stained with hematoxylin and eosin for histologic examination, with additional serial sections utilized for immunohistochemistry (IHC). A Ventana Discovery Ultra (Roche) tissue autostainer was used for IHC. Specific protocol details are outlined in Table S5-6. The histomorphological analysis was performed by a single board-certified veterinary pathologist (N.A.C.), who developed an ordinal grading score encompassing the diversity and severity of histologic findings using isotype control administered animals as a baseline. Histologic criteria were broken down into three compartments: airways, blood vessels, and interstitium, with results utilized to generate a cumulative lung injury score. This score also incorporated the overall degree of immunoreactivity to the SARS-CoV-2 S antigen. A summary of individual animal scores and specific criteria utilized to score lungs is included in Tables S2-3.Brightfield and fluorescent images were acquired using a Mantra 2.0 TM Quantitative Pathology Imaging System (Akoya Biosciences). To maximize signal-to-noise ratios, fluorescent images were spectrally unmixed using a synthetic library specific for the Opal fluorophores used for each assay and for DAPI. An unstained Syrian hamster lung section was used to create an autofluorescence signature that was subsequently removed from images using InForm software version 2.4.8 (Akoya Biosciences).Nb (Nb21Alb, PiN-21 and PiN-21Alb) was concentrated to 1 ml (1.5 mg/ml) in 1xDPBS. 0.5 ml was saved as a control for ELISA and pseudovirus neutralization assay. The other 0.5 ml was aerosolized by using a portable mesh atomizer nebulizer (MayLuck). No obvious dead volume was observed. The aerosolized droplets were collected in a microcentrifuge tube. The concentration was measured to calculate the recovery of the proteins.Pseudotype neutralization assay was carried out and IC50 was calculated as previously described (28) . Funding: This work is funded by the NIH 1R35GM137905-01 (Y.S.), a CTSI pilot grant (Y.S.), a SIG grant S10-OD026983, and Hillman Family Foundation, RK Mellon, and CVR (P.W.D).",USA,first author,2021-02-23,02
4e552ba8ecf7752404f552bd70819138820d0362,Ethics of research at the intersection of COVID-19 and black lives matter: a call to action,"The USA has exceeded 400,000 COVID-19-related deaths, 16 .8% of which were among Black Americans. 1 2 While vaccine trials are ongoing, Blacks only account for 3% of enrolees, which may threaten the validity and generalisability of the vaccine trial results. 3 Although scientific research is one of the most important ways to advance public health, its success is contingent on the participation of key populations. Vaccine trials with diverse participants are essential to find a medicine that works for all people. Yet fewer than half of Black Americans say they would get a COVID-19 vaccine, compared with 63% of Hispanic people and 61% of white people, according to a December report from the Pew Research Center. 4 Many Black people say they do not trust the medical establishment because of glaring inequities in modern-day care and historical examples of mistreatment. The spread of misinformation about the vaccine development process has not helped either. Low participation of Blacks in COVID-19 vaccine trials and uptake may have dire consequences for their future health and well-being. Blacks have been disproportionately and negatively impacted by the coronavirus with higher rates of infection, hospitalisation and death in Black communities. 1 In Chicago alone, Black people represent almost 70 % of all COVID-19 deaths-more than three times higher than any other racial/ethnic demographic. 1 The factors driving COVID-19 health disparities are complex and include increased vulnerabilities associated with the social determinants of health (ie, discrimination, criminalisation, healthcare access, socioeconomic status, work and housing), 5 delays in access to testing and treatment in Black communities and structural racism, which has been increasingly linked to morbidity and mortality outcomes among Blacks. These same factors may increase the likelihood that Black communities will not participate in vaccine trials or agree to be vaccinated, thus, exacerbating existing COVID-19 disparities.Efforts to diversify participants in COVID-19 vaccine trials and uptake will likely be difficult due to historical mistrust of research among communities of colour, growing scepticism regarding the objectivity of scientific research and weakened trust in institutions of higher education, where most scientific research takes place in the USA. The Black Lives Matter (BLM) movement is demanding a societal reckoning with the racist foundations of this country and the ongoing structural violence that limits the life chances of people of colour. The mission of the BLM global network founded in 2013 is to 'eradicate white supremacy and build local power to intervene in violence inflicted on Black communities by the state and vigilantes'. 6 Efforts based on the civil unrest and killings of unarmed Black people (eg, George Floyd, Breonna Taylor and Ahmaud Arbrey) are the foundation of the current worldwide uprising demanding an end to police brutality and equity for all. Indeed, scientific research is being implicated along with other institutions and structures, such as the police, in failing in their role to 'protect/serve/help' all people. Numerous accounts of historical mistrust underscore the urgency of work needed to encourage Black people to feel confident in the medical establishment. 7-10 Understandably so-unethical research practices over many years, combined with persistent health disparities and lack of access to effective treatments for Black people, discourage the very groups most in need of new innovations from receiving them.A historical mistrust of research by Black communities stems from the heinous abuse of Black bodies in clinical trials in the USA. Furthermore, Black communities have endured the burden of excess deaths from health disparities for generations. 7 Several examples underscore this reality. In the 19th century, the 'father' of modern gynaecology, James Marion Sims, developed surgical techniques to improve women's reproductive health, but these were derived from research conducted on enslaved Black women without their consent or the use of anaesthesia. 8 The Tuskegee Syphilis study that began in 1932 lasted until 1972 after it was leaked to the press that impoverished Black men enrolled in the clinical study were allowed to needlessly suffer and die long after a cure was found. 9 It is now widely recognised that the Tuskegee experiment was highly unethical. Finally, in 1951, Henrietta Lacks' trust was betrayed by the medical system when her cervical cells were removed from her body and stored without her knowledge or permission and Current controversy used to develop the polio vaccine due to their 'immortality'. 10 The Tuskegee study and the story of Henrietta Lacks reveal the depths of structural racism in this country and its foundation in the US healthcare system. Institutional Review Boards were formed partially in response to the Tuskegee study. While formal abuses in research have been significantly reduced, maltreatment in the healthcare setting persists.Importantly, racist policies and modern-day medical practices continue to harm Black communities. In 2020, Black mothers in the USA had the highest mortality rates postpartum, three times higher than white women. 11 Maternal mortality has been attributed to institutional racism in that healthcare professionals fail to listen or believe mothers when they report a problem during childbirth. 12 Similarly, grave disparities in how doctors treat pain in Blacks exist, including Black children. [13] [14] [15] Racist and stereotypical beliefs by healthcare providers are implicated in these disparities and can be traced back to slavery, whereby violence against Black people was justified by a false belief that Blacks had a greater pain tolerance due to thicker skin. 14 The persistence of these false beliefs was documented as recently as 2016 in a study of white medical students. 15 Ongoing structural racism and mistrust of the USA medical establishment, particularly in the face of COVID-19 disparities and BLM, continue to traumatise and retraumatise Black individuals. 6 7 COVID-19 has produced disproportionate rates of unemployment, mental health issues and death in Black communities, and while the BLM movement has reignited a desire to fight for Black human rights, it has also 'reopened psychosocial wounds' reminding people that Black lives are devalued and expendable. 16 The media's constant bombardment of images of Black people being killed reinforces a sense of vulnerability, lack of protection and safety, which triggers fears of the future. The BLM movement has brought to light the blatant racism, discrimination and prejudice Blacks face and the ways in which these circumstances create roadblocks to education, impede healthcare and economic opportunities and contribute to mental health problems. We must ask ourselves, why should Black people trust that involvement in scientific research will benefit them?As scientists who are committed to bettering the lives of Black people and reducing health disparities, our job is to conduct research that drives effective interventions and prevention programmes. Yet, as academics, we must also acknowledge the tensions between the power of research to improve health inequalities and mistrust among Black populations and ourselves in the 'institution of science'. Currently, the National Institutes of Health funding to study COVID-19, including community engagement, is being given to those who already have proven track records with funding, a predominately white contingent; reducing the likelihood of Blacks receiving federal funding for their research. 17 18 This means that researchers with the most experience and knowledge of disparities and sociocultural factors related to research participation will again be absent from the table. Funding whites to conduct research with Black populations may further perpetuate misunderstanding of why Blacks would not participate in research trials and take the vaccine. We have been asking ourselves whether it is ethical to engage vulnerable populations in research? Is it ethical to recruit those who are disproportionately impacted by COVID-19 and continuously devalued and victimised by science and other socially sanctioned institutions (ie, government, police, hospitals)? And yet, what are the public health costs of not pursuing research with Black communities with whom we are deeply invested?Clearly, it is important to continue research with Black communities, but with new standards. Fully understanding the intersection of BLM, COVID-19 and historical trauma, researchers must be explicit in strategies to avoid retraumatising or perpetuating violence of Black lives as disposable at every point of the research process. Furthermore, it will also require research institutions to change how we engage Black populations, commit resources to diversify our workforce and enact antiracist programmes/policies, to foster greater sensitivity to these issues. Against this backdrop and in the context of a global health pandemic and civil unrest, academics of colour are also experiencing heighted levels of mistrust. The intersections of COVID-19 and BLM have triggered a critical self-examination among academics of colour who engage vulnerable populations in research and begs the question: How do we implement research with care and minimise retraumatisation of Black people?We have three recommendations for researchers to ethically engage Black populations in research. First, researchers must acknowledge and understand the ongoing impact of current and historical trauma, enacted by the medical establishment and research, on Black lives. The Tuskegee study was a clinical trial that enrolled vulnerable Black men and led to many unwarranted deaths because a cure, penicillin, was withheld by 'trusted' medical professionals. By asking Black communities to once again participate in clinical trials, we risk retraumatising individuals if we fail to address them properly. Traumatic life events (ie, racism, discrimination, death) can be triggered by healthcare experiences as well as education, corrections, child welfare and government systems. 19 Trauma may limit participation in research, but it may also be a point of connection for Black people. As researchers, we must acknowledge sources of ongoing harm and excess deaths, and that trauma compounds the emotional pain, physical illness, economic hardship and injustice Black communities continue to endure. 7 Using a trauma-informed lens (ie, recognising the impact and symptoms of trauma and understanding potential paths to recovery) and culturally safe, research methods that respect Black peoples' lived experiences can provide the confidence and trust needed to engage in research. In addition to understanding trauma, we must be explicit about addressing it in our research. For example, we must ensure that our research settings are both emotionally and physically safe (ie, by asking questions regarding safety, listening and centring participant experience). We must be transparent about our research by ensuring that the informed consent process is clear and understood by various literacy levels. Mixed method approaches (ie, open-ended questions and interviews) can capture the voices and lived experiences of Black people, providing much needed context of findings based on quantitative data. Offering a safe space for participants to discuss their trauma can empower Black people, as their narratives have often been silenced, ignored or delegitimised. In response to participants sharing their trauma, researchers should be prepared to provide mental health resources and to assist with linkages to care. Researchers must collaborate with mental health professionals to aid in providing trauma-informed care as needed. We must also be intentional about who is on our research teams by ensuring they are representative of the population and properly trained in antiracist thinking, cultural safety and/or implicit bias. If we truly aspire to create a physically safe environment, we need to have diverse teams of clinical researchers representing the patients they treat.Second, research interventions should acknowledge the historical context of Black participants' experiences and address it directly where possible. Researchers must understand that racism is embedded in our country's structures and systems and Current controversy contributes to health disparities. A parallel between historical USA events (World War I, Red Summer and Civil Rights Movement) and present-day circumstances (COVID-19, BLM movement) is evident; in both, Black people are disproportionately impacted and have been left traumatised. 6 This historical perspective should trigger explicit reflection of researchers regarding sampling. We must take intentional steps to avoid repeating historical atrocities, and instead, use our unique platform to help support, protect and empower Black communities. Research should challenge and counter stereotypical narratives that criminalise Black communities and highlight strengths, contributions and voices of Black people. Finally, sharing research findings with communities will facilitate trust and encourage input and insight into interpreting the results. For example, now that COVID-19 vaccines have been approved, it will be important to ensure equitable access and prioritise communities most at need. 3 While healthcare providers were among the first to be vaccinated, more vulnerable populations of health workers (ie, home health aides), who do not have access to PPE, may not be considered to be 'essential'. 20 Blacks are more likely to be concentrated in lower status positions, such as home health aides, in the healthcare work force and maybe systematically left out of the equation for the first round of vaccines.Finally, researchers must engage in open and honest conversations with Black participants about how they feel participating in research during the COVID-19 pandemic, including the risks, strengths and barriers. Then, researchers must listen, adjust timelines, protocols and objectives based on the information provided. We must reconsider how to implement our research to minimise the risks and maximise the benefits. For example, concerns already exist regarding vaccine uptake among individuals from racial and ethnic minority groups. While it is critical to evaluate vaccine efficacy across populations, Blacks will be understandably dubious to enrol. Programmes that promote vaccines must build on pre-existing researcher/community-based partnerships, engage trusted community leaders to message their importance and employ Black researchers and staff from the communities where people live and work. Studies show that individuals are more likely to adopt behaviours promoted by people indigenous to their community. 21 Hence, vaccine success will depend on whether members of Black communities deem them safe and effective, and if they believe the institution (ie, colleges, hospital and clinics) delivering the vaccines are trustworthy and care about their needs. 3 Racial disparities and structural racism exist in the healthcare system, and academic researchers must take action now to avoid previous mistakes, ensure safety and change the future trajectory of scientific engagement by Black populations. The core of our recommendations is the recognition of the impact of trauma in our research, care and practices. In order to protect Black populations engaging in research, we must acknowledge our history of maltreatment and racism, incorporate Black voices, experiences and perspectives and be intentional about the purpose of our research. Now is the time to regain Black Americans' trust in research and the healthcare system.",USA,first author,2021-02-05,02
792b1c789bc70434428e1bd89c908c5380e2ac44,An Evaluation of Serum 25-Hydroxy Vitamin D Levels in Patients with COVID-19 in New York City,"Severe acute respiratory syndrome coronavirus-2 (SARS-CoV-2) has led to the rapid worldwide spread of COVID-19 disease over the past several months. Clinical manifestations exhibited by COVID-19 patients may be mild and include fever, cough, fatigue, muscle soreness, and headache or more severe which may include acute respiratory distress syndrome (ARDS) (1) . Deterioration of patients to ARDS is associated with cytokine release syndrome (CRS) attributed to an elevation in pro-inflammatory cytokines (2) . In patients who are vitamin D deficient, supplementation may have the potential to prevent or treat COVID-19 by suppressing the generation of inflammatory cytokines, and therefore CRS (3, 4) . Risk factors for vitamin D deficiency include age, race, obesity, kidney disease, winter seasons, higher geographic latitudes, and dietary availability of fortified foods (5) (6) (7) .Vitamin D has a broad-spectrum effect in regulating the immune system. Vitamin D reduces proinflammatory cytokines, reduces the survival of viruses by activation of alveolar epithelial cells, and induces differentiation and anti-microbial activity of macrophages to foreign antigens (8, 9) . Vitamin D can increase angiotensin-converting enzyme 2 (ACE2) expression, and suppress renin to reduce angiotensin II and reduce lung injury. ACE2 is the receptor responsible for SARS-CoV-2 attachment on the surface of alveolar epithelial cells that causes an increase in angiotensin II formation and pulmonary vasoconstriction in severe COVID-19. By inducing the expression of ACE2, this promotes virus binding, but also results in decreased pulmonary vasoconstriction (10) . This is similar to the H7N9 virus in which lung injury was promoted by ACE2 and prevented by expression of ACE2 protein (11) . Lastly, vitamin D contains anti-thrombotic properties that may be beneficial in COVID-19 patients to reduce their risk of cardiovascular complications (12) . Vitamin D modulates nitric oxide to prevent endothelial dysfunction, and downregulates pro-thrombotic plasminogen activator inhibitor-1 and thrombospondin-1 mRNA expression to decrease the risk of coronary atherosclerosis (13) .Vitamin D has shown the possibility in reducing the risk of respiratory tract infections and influenza-related illness in previous observational reports (14) . Protective benefits from vitamin D supplementation were seen in vitamin D deficient patients when they were administered vitamin D daily or weekly (14) . Its role in COVID-19 is unknown and limited by a lack of published clinical trials. However, studies have demonstrated that 25(OH)D levels were significantly lower in COVID-19 patients compared to non-COVID-19 patients (15, 16) . Likewise, Ilie et al. has described the negative correlation between average vitamin D levels during the COVID-19 pandemic, and the number of COVID-19 cases in European countries (17) . A proposed hypothesis of why mortality rates differ in northern latitudes, such as in northern Italy and Spain, is because of the older population, as well as vitamin D deficiency, which may contribute to airway infectious illnesses (18) . The aim of this study is to evaluate the association between vitamin D status and COVID-19 clinical outcomes.This was a retrospective, observational cohort study of patients with COVID-19 disease within the Mount Sinai Health System between March 1, 2020 and May 8, 2020. Adult patients were included if they tested positive for SARS-CoV-2 via nasopharyngeal PCR swab during the timeframe, and had a serum 25-hydroxy vitamin D level (25(OH)D) within the three months prior to their detected SARS-CoV-2 test, or within their admission hospital labs. For cases with more than one 25(OH)D level, we utilized the 25(OH)D level closest to the patient's time of their positive SARS-CoV-2 test. Patients were compared based upon their serum 25(OH)D and defined into two categories: deficient (<20 ng/ml), and sufficient (20 ng/ml). The Icahn School of Medicine Institutional Review Board approved this retrospective analysis as minimalrisk research using data collected for routine clinical practice.Patient characteristics including demographic, comorbidities, and clinical outcomes were obtained from the Mount Sinai Data Warehouse, and confirmed by manual chart review. The primary endpoints were hospital admission, need for oxygen support, and mortality. The mortality endpoint was defined as 90-day mortality documented from the first detected SARS-CoV-2 test. Oxygen support was defined as the need of invasive mechanical ventilation, noninvasive ventilation (i.e. non-rebreather mask, venturi, high flow nasal cannula) or nasal cannula therapy.Differences in baseline characteristics were assessed by a chi-square test for categorical variables or by a Mann-Whitney test or Student's t-test for continuous variables. A univariate logistic regression analysis was performed for the association between sufficient 25(OH)D levels and clinical outcomes from COVID-19 infection. Variables yielding a p value 0.20 from the univariate analysis were included in a backwards, stepwise, multivariate logistic regression model. The multivariate analysis adjusted for ethnicity, race, sex, age, lung disease, cardiovascular disease, kidney dysfunction, obesity, and malignancy. Statistical significance was measured by a p value <0.05. All statistical analyses were performed using R Studio (Version 1.3.1093). hypertension (68%), diabetes (45%), coronary artery disease (30%), and malignancy (24%). There were 177 patients classified as vitamin D deficient compared to 260 patients who were vitamin D sufficient. In comparison, there were more males who were vitamin D deficient compared to vitamin D sufficient (n ¼ 97, 55% vs n ¼ 113, 43%, p ¼ 0.02) and patients who had chronic kidney disease (n ¼ 49, 28% vs n ¼ 44, 17%, p ¼ 0.008). Conversely, there were significantly less patients of the white race (n ¼ 29, 16% vs n ¼ 85, 33%, p ¼ 0.0001), and those who had active malignancy (n ¼ 33, 19% vs n ¼ 74, 28%, p ¼ 0.02) within the vitamin D deficient group compared to the vitamin D sufficient group, respectively. Figure 1 displays 25(OH)D levels and outcomes associated with COVID-19 infection. Hospitalization rates (98%), oxygen support (93%), and mortality rates (49%) were highest in patients who had 25(OH)D levels less than 10 ng/ml (n ¼ 30) when compared to other 25(OH)D levels. Oxygen support had a trend of decreasing as 25(OH)D levels increased: <10 ng/ml (93%), 10-20 ng/ml (56%), 20-30 ng/ ml (52%), 30-50 ng/ml (49%), and >50 ng/ml (37%). There was no significant difference in clinical outcomes in vitamin D deficient patients compared to vitamin D sufficient regarding hospitalization rates (n ¼ 154, 87% vs n ¼ 218, 84%, p ¼ 0.37), length of hospitalization stay in survivors [11 (IQR:6-22) vs 10 (IQR: 5-18), p ¼ 0.25), and 90-day mortality rates (n ¼ 52, 29% vs n ¼ 80, 31%, p ¼ 0.76). Conversely, patients who were vitamin D deficient required significantly more oxygen support compared to patients within the vitamin D sufficient cohort (n ¼ 116, 66% vs n ¼ 127, 49%, p ¼ 0.0006) ( Table 1) .In our multivariate analysis, that controlled for demographic variables and comorbidities, low plasma 25(OH)D levels were associated with an increased likelihood of oxygen support from COVID- 19 Table 2 ). When 25(OH)D levels were analyzed as a continuous variable, multivariate analysis results were similar depicted in Appendix A.The cohort described in this study is comparable to other COVID-19 studies in which older patients, and patients with chronic comorbidities, may have an increased rate of contracting COVID-19 disease and be hospitalized for COVID related complications (19) . Male patients of a nonwhite race, and patients who have kidney dysfunction were more likely to be vitamin D deficient within this cohort. Previous studies have found that elderly females are at a higher risk than males for vitamin D deficiency, however, with the increased utilization of screening and prevention, males have now become more likely to be deficient in vitamin D. This may be due to the lack of use of vitamin D supplements, consumption of cola drinks, and central obesity (20) . Vitamin D deficiency is also more prevalent in people of color. This is from their increased skin pigmentation that reduces the ability of the skin to produce vitamin D from sun exposure, and due to the possibility of lower cellular glutathione (GSH) levels that impairs the vitamin D biosynthesis pathway (9) . The prevalence of vitamin D deficiency within the chronic kidney disease (CKD) population is common, with sufficient 25(OH)D levels being reported in only 17-33% in stage 3 and 4 CKD patients (21) . In CKD, FGF-23 increases to inhibit renal 1a-hydroxylase expression leading to degradation of 1,25-(OH 2 )D and impaired uptake of 25(OH)D by the kidneys (22) . This retrospective analysis demonstrates that there were clinical differences in outcomes based upon serum 25(OH)D levels and the need for oxygen support therapy. After adjusting for confounding variables, multivariate analysis also demonstrated an independent and significant association between low 25(OH)D levels and the increased likelihood of oxygen support. Lower 25(OH)D levels have been documented to be associated with a greater extent of lung involvement, as documented on chest computed tomography (CT) and poor outcomes in COVID-19 infection (p < 0.01) (23) . A small case series of four COVID-19 patients showed the benefit of high dose vitamin D (ergocalciferol 50,000 IU daily) supplementation in normalizing serum vitamin D levels, and improving clinical outcomes such as oxygen requirements (24) . In a univariate analysis by Merzon et al. low plasma 25(OH)D levels, defined as less than 30ng/mL, were associated with an increased risk of hospitalization from COVID-19 infection (OR: 2.09, 95% CI: 1.01-4.31, p < 0.05). However, this was not preserved within their multivariate analysis (OR: 1.95, 95% CI 0.98-4.84, p ¼ 0.06) (16) . Rastogi et al. discovered a greater proportion of asymptomatic or mild symptomatic patients with COVID-19 disease, who received cholecalciferol, to have the ability to become SARS-CoV-2 negative compared to patients who did not receive supplementation (25) . Similarly, Annweiler et al. reported that vitamin D3 supplementation was associated with better survival and less severe COVID-19 in the elderly. Yet, there was no improvement in outcomes if vitamin D supplements were initiated after a diagnosis of COVID-19 (26) . Patients may still benefit from vitamin D supplementation by preventing the need of oxygen assistance during their COVID-19 disease. Such clinical outcomes were not assessed in previous studies.Limitations of this study deserve acknowledgment. Several demographic variables were not assessed and therefore not evaluated between vitamin D groups. Patients were not assessed if they were nursing home residents or bed bound as this can influence their sun exposure for vitamin D resources. Likewise, socioeconomic status was also not assessed as this has the potential to influence the diet of patients and the availability of fortified foods. Genotypes or conditions that can impair vitamin D metabolism such as medication therapy, malnutrition, or bariatric surgery were not assessed. This study was retrospective in nature, and therefore serum 25(OH)D levels were analyzed over vitamin D medications as it was unknown if patients were taking supplements over the counter or adherent to their medications. There was no comparison to healthy patients who did not have COVID-19 disease, but also had serum 25(OH)D levels. Therefore, it is unknown the protective benefits vitamin D has on obtaining the disease. We included all patients within the ambulatory care and inpatient setting, and therefore a sample size calculation was not performed. It is unknown if vitamin D therapy may be beneficial in the subgroup of intensive care patients. Previous reports have demonstrated that high dose vitamin D (2,50,000-5,00,000 IU) were associated with reduced hospital stays in mechanically ventilated patients (27, 28) . We did not evaluate intensive care unit (ICU) admission, as this data point was difficult to gather as many of our medicine wards became ICUs during the pandemic. The authors did not set mortality at 15-day mortality or 30-day mortality due to our small sample size, and the extended hospital stays the patients were experiencing at our institution. Prospective studies may not confirm these results, as odds ratios less than 3 may be due to uncontrollable bias (29) . Lastly, there is no consensus on the cutoff of vitamin D sufficiency. The Institute of Medicine (IOM) defines vitamin D deficiency as serum 25(OH)D < 20 ng/ml (50 nmol/l), yet many studies have utilized different cutoffs (30) .To the knowledge of the authors, this is the first study to demonstrate that serum 25-hydroxy vitamin D levels may influence the need for oxygen support therapy. This association was preserved after adjusting for confounding variables. By preventing the need for oxygen support, such as mechanical ventilation, vitamin D supplementation may help to decrease healthcare costs and healthcare bed availability associated with COVID-19 infection. Further prospective studies are underway to provide answers on the role of serum 25hydroxy vitamin D levels and vitamin D supplementation in COVID-19 infection (31) .Appendix A. Multivariate analysis between 25(OH)D levels and outcomes from COVID-19 infection ",USA,first author,2021-02-19,02
6547032d441c125b1628fc082881b399f0be3988,Amantadine withdrawal syndrome masquerading as COVID-19 encephalopathy: a case report and review of the literature,"Amantadine hydrochloride, among the many happy accidents in medicine, was inadvertently discovered to alleviate the extrapyramidal symptoms of Parkinson's disease (PD) in 1968. A woman with PD found her symptoms much improved while taking amantadine for flu prophylaxis. Later that year a large trial demonstrated both subjective and objective benefits when used to treat PD [1] . Since that time, amantadine has been used to treat PD alongside a number of other movement disorders.Although its mechanism is not fully understood, amantadine is thought to achieve its effect via N-methyl-D-aspartate receptor antagonism, direct and indirect effects on dopamine neurons, and by decreasing anticholinergic tone [2] . Amantadine can cause dopamine toxicity: paranoia, hallucinations and tachycardia. For this reason, the medication is initiated progressively. Inversely, if it is rapidly discontinued, patients may develop amantadine withdrawal syndrome (AWS), a severe and persistent delirium often with concurrent extrapyramidal symptoms.A 52-year-old female with a past medical history of spinocerebellar ataxia, hyperthyroidism and depression presented to the hospital with 2-3 weeks of hallucinations. Admission labs were remarkable for a new acute kidney injury with blood urea nitrogen (76 mg/dl) and creatinine (1.6 mg/dl from baseline of 0.8 mg/dl). Additionally, she was found to be coronavirus disease-2019 (COVID-19) positive. Complete blood count, urinalysis, thyroid stimulating hormone (TSH), serum ethanol level and head computed tomography were unremarkable. Vital signs were notable for a heart rate of 104. On arrival she was alert and answering questions appropriately. The patient had been prescribed amantadine for 2.5 years prior to admission and was taking 300 mg daily.The neurology service suspected her hallucinations were related to amantadine toxicity and recommended a 3-day taper, shortened to 2 days by the primary service. Serum amantadine level was ordered on admission and found to be 1505 ng/dl (therapeutic range 200-1000 ng/ml and toxicity >2000 ng/ml). The patient continued to have hallucinations with concurrent agitation, prompting an electroencephalogram (EEG) and lumbar puncture. All lumbar puncture studies were normal. EEG showed background slowing consistent with encephalopathy with no epileptiform activity.After 3 days, the patient was no longer having active hallucinations but became increasingly somnolent and disoriented. Five days into her course, she was no longer consistently speaking with providers. Two weeks into her hospitalization, she required assistance in feeding and was not reliably following commands. Given her persistent symptoms, the possibility of COVID-19 encephalopathy was raised and a repeat lumbar puncture considered for colony-stimulating factor polymerase chain reactiontesting. Prior to this, the patient was resumed on 200 mg of oral amantadine. Within 2 days she was alert, speaking in full sentences, and oriented to person, month and situation. Because the patient's prolonged delirium resolved immediately after resuming amantadine, the diagnosis of AWS was made. The neurology service believed that the patient's initial presentation was consistent with amantadine toxicity with the patient going into withdrawal in the subsequent days as the medication was tapered and held, thus explaining both her initial agitation and hallucinations and subsequent hypoactive delirium. She ultimately returned to her cognitive baseline and was discharged to subacute rehab.Since 1987 there have been seven case reports describing instances of AWS including 15 patients. This is the first published since 2017 and is noteworthy in that it describes a patient without PD or underlying dementia. The first case series, published by Wilson in 1987, describes three older patients who experienced recrudescence of their PD motor symptoms after amantadine was held [3] . Only one of the three patients may have suffered from our more contemporary definition of AWS, an acute delirium following the discontinuation of the medication, whereas the other two patients experienced only movement symptoms.In 1997 Factor published a case series describing three elderly patients who developed acute delirium with worsening motor function after amantadine was held [4] . All patients had underlying dementia and had been taking amantadine for more than 4 years. Symptoms quickly resolved after resuming the medication. Interestingly, all patients had their amantadine held due to hallucinations. Miyasaki republished a reply to the editor sharing two similar cases of patients with longstanding PD who developed AWS [5] . Factor responded with two further cases of elderly patients with characteristic PD and AWS. These cases were novel in that one patient did not have underlying dementia and both patients had been taking amantadine for less than 1 year. Again, symptoms entirely resolved with resumption of amantadine. Miyasaki hypothesized that pathogenesis of the delirium was related to the glutamatergic system. At this point some general risk factors for AWS were induced: old age, advanced PD, underlying dementia and duration of therapy. Factor agreed with Miyaski that AWS was unlikely related to dopaminergic pathways.In 2009 Brantley published a case report of neuroleptic malignant syndrome (NMS) believed induced by amantadine withdrawal [6] . The authors hypothesized that more classic AWS exists on a spectrum which includes NMS. Marxreiter added an additional case of severe AWS in a patient with PD in 2017, helpfully noting the benefit of reintroducing amantadine early in instances of diagnostic uncertainty due to its rapid effects [7] . Finally, Fryml described three cases of AWS in a 2017 report which interestingly included the first patient without PD [8] . The authors noted the remarkable duration that AWS can persist: in one instance for weeks. Similar to Brantley, she describes AWS as a protean syndrome ranging from delirium to NMS, driven by dopaminergic derangements.Our case illustrates both characteristic and unusual features of AWS. Characteristically, this case was prolonged and refractory, included motor symptoms, and entirely resolved with amantadine reintroduction. Atypically, this case involved a patient without PD who experienced a hypoactive delirium, although this has been also reported. Intriguingly, this case of AWS likely occurred after a period of amantadine toxicity, as the patient initially presented with hallucinations and elevated serum amantadine levels. We hope this report highlights the importance of prolonged amantadine tapers in the setting of toxicity as symptoms of overdose and withdrawal can overlap, creating diagnostic confusion. Further questions which remain to be answered include the exact pathophysiology of the syndrome and if it includes NMS as part of its spectrum.",USA,first author,2021-02-15,02
8034cf261677bcad14a279e26bff778a669d8dd0,Neonatal family-centered care in a pandemic,"After the seminal publication of ""The principles for familycentered neonatal care"" in Pediatrics in 1993 [1] , a large wave of interest developed in doing better by babies and families in the neonatal intensive care units (NICUs) across North America. This interest was not only by parents, parent and patient advocates, and non-professionals in and out of healthcare, but by interdisciplinary clinicians as well. Psychologists, nurses, neonatologists, and pediatricians all began to study and implement means by which care could be more patient and family-centered in its development and delivery [2, 3] . Observations were made of how pediatric resident experiences might improve in the NICU [4] and even how parents of newborns on extreme life-support measures like ECMO (extra-corporeal membrane oxygenation) could add to the conversations [5] .In time, as NICUs across North America aged and new NICUs were being planned and built, the very design of the physical spaces in the NICU accommodated family presence and engagement better than any time in history [6, 7] . FCC became the norm, the expectation, and the focus of many clinician-parent collaborations broadly within children's hospitals as well as in the NICU. Adult hospitals mirrored the work done first in pediatric centers [8] . Now, there is additional importance of parental involvement in the NICU, underscored by a consideration of renaming the NICU to the neonatal intensive parenting unit, to highlight the involvement of the family and emphasize the necessity of bonding and attachment between the parents and the newborn [9] .Then came a pandemic, or two. In 2003, there were restrictions placed on family presence at the bedside of their loved one during the SARS-1 pandemic [10] . At that time, issues of social isolation-felt by patients, parents, and clinicians-were described in situations where concerns for infection control prevailed over facilitating FCC. These same situations brought with them considerable emotions that challenged and even changed professional and parental roles. Communication was difficult. And investigators noted that ""…effective clinical approaches…"" should be developed ""…in the event of future outbreaks…"" [10] . The H1N1 pandemic of 2009 was such an anticipated event, but it did not substantively materialize in North America. Now, in 2021, we contend with COVID-19, the ongoing pandemic illness caused by the SARS-CoV2 virus. Almost overnight, units of care in pediatric and adult hospitals closed to family and visitors in the spring of 2020. While families may not have become ""visitors"" in the strictest sense, a general perception by many NICU staff and parents has been that even parents of critically ill or preterm newborns, were subjected to ""visitor policies"". This occurred for all stages of care-on admission, while on critical lifesupporting technologies, and even when dying. While NICUs and children's hospitals have not been overwhelmed with neonatal and pediatric cases of COVID-19, the staff have nonetheless had to struggle with several moral and ethical issues [11] .Clinical staff in NICUs are distraught, disillusioned, and have been experiencing moral distress. Given a quarter century history of developing and knowing what ""was right"", and what has been enculturated in the NICU and across children's hospitals, they can see how current constraints by infection control and ""visitation"" policies that have been promoted in efforts to mitigate, if not absolutely prevent, infection among NICU staff or patients keep them from providing the care they believe is best for babies and families in both the short and the long-term. While speaking from an adult hospital perspective, Morley et al. relate a number of contributors to moral distress among staff at this time including a lack of personal protective equipment (PPE), visitation restrictions, impaired communication, and relational capacity between staff and patients/families, risks to their own personal and family safety, contending with scarce resource allocation, and some reduction in the overall level of care provided amidst the pandemic [12] . Virani et al. utilize three pediatric cases (one being a newborn) to elicit responses from a diverse group of pediatric clinicians and ethicists [13] . Haward enjoins other neonatology and ethics colleagues in describing not only the moral, ethical and emotional toll that this pandemic and healthcare organizations' responses have taken on vulnerable patients, their families, and staff, but offer different suggestions to guide leadership in ways forward [14] .Borrowing from a model used by Raman et al. in their report on a child rights-based response to COVID-19 [15] , the following figure is offered to help us organize our thoughts around pertinent clinical, environmental, ethical, and sociocultural responses to challenges brought forth by the pandemic as we attempt to regain what has been lost in FCC care these past few months [ Fig. 1 ].As the pandemic continues, there will be vacillations in efforts to contain the spread of infection and mitigate disease largely based upon epidemiologic data within geographic regions, states, and cities. This will involve ongoing surveillance, testing, rigorous hygienic practices, the wearing of masks, social distancing, concerted efforts within hospitals to wear and utilize PPE and isolate infected patients. Hospitals, and individual units of care within them such as the NICU, will need to strike a balance between the increasingly understood risks of spread and the less clear but nonetheless important risks that minimal contact of newborns with their parents will have on both infant adaptation, bonding and development, and parental growth and development. [Textbox] .FCC is a valuable philosophy and practice to keep in the forefront of leadership, management, and clinician's minds, especially in the high-stress and intense setting of the NICU. Given the numerous societal stressors our nation is currently undergoing, this is truer now than ever before. For various reasons families, NICU staff, and even babies are overwhelmed. Despite COVID-19, the principles of FCC, established in 1993, are still important to carry out in 2021. Families need their babies and babies need their families, and it is the responsibility of hospital systems to ensure this can continue to be supported in the safest manner possible. To do this, we must continue to consider the many clinical, environmental, ethical, and sociocultural determinants that impact care and affect the family unit.Author contributions BC conceived the idea and wrote the first draft. TW and AK edited and revised the first draft and both the Figure and the Textbox. All authors contributed to and approved the final version of the manuscript.Conflict of interest The authors declare that they have no conflict of interest.Publisher's note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.",USA,first author,2021-02-19,02
30a2cbbd0d102f6ff85919b0383bf94f9c4b317d,Going Beyond the Data: Using Testimonies to Humanize Pedagogy on Black Health,"In 1955, James Baldwin wrote in reference to a Black person, ""to think of him is to think of statistics, slums, rapes, injustices, remote violence; it is to be confronted with an endless cataloguing of losses, gains, skirmishes"" (25). Although Baldwin was not speaking about health professions education, it too has adopted a narrative of Black people represented as statistics, as people who face injustices rather than as complex humans upon whom injustices have been imposed. Specifically, in the health professions, learners are often taught to view Black people through the lens of statistical data representing disparate rates of disease and disorders. This view, however, leaves out the full story behind Black health.When health professions learners' primary pedagogical experience of Black patients is through statistics, it becomes very easy for them to think of Black people as data points rather than as individuals whose health is often at the mercy of racist institutions. A recitation of endless statistics removes the human dimension of Black people's lesser healthHealth narratives or stories about one's experiences with health and health care are already a staple in health humanities, most notably in narrative medicine as described by Rita Charon. Narrative medicine uses health stories to transform the clinical experience for patients and caregivers, namely by using literature and various writing, reading, and listening exercises to help caregivers view patients as whole beings, not just as illnesses. Narrative medicine also helps caregivers examine their own relationship to illness (Charon 2006) . Narrative medicine and the ERT approach share at least one goal, which is to provide a more complete picture of the patient. This, however, is generally where the similarities end. For instance, whereas narrative medicine aims to transform the patient-physician relationship as it happens in a clinical setting, the ERT approach aims to transform the way learners think about the lives of Black people before they become patients and how those experiences then mitigate their experience of health and health care once they become patients. The ERT approach also uses testimonies rather than full narratives.The ERT approach makes Black individuals the center of their experiences of illness and care using their own testimonies, their own words, leaving little room for learners to impose their interpretations of what an individual is experiencing. Testimonies are a short, concise, and often times emotionally charged glimpse into the ways in which individuals experience the world. They don't always have a plot and a specific, intended purpose like more formal narratives. More generally, testimonies affirm and allow patients to claim their own experiences, thoughts, or feelings. Testimonies are personal, and when they are shared with others, tellers invite a listener, in this case the health professions learner, into their world as an observer. When Black individuals share their testimonies, they are inviting us to share in their experience of what it means to be Black and ill.In this sense, testimonies allow passive observation of the ways in which other human being experience the world without imposing judgments on how they ought to experience that world. This is particularly important when testimonies reveal experiences of a world that is very different from our own and therefore perhaps difficult to comprehend. For nonblack learners, because their own social identities do not give them personal access to the ways Black people experience the world, testimonies from Black people allow them to observe the world from another perspective. Being in the observer position allows learners to consider another viewpoint without inserting themselves into Black people's experiences with illness and health care.Whereas some use of health narratives aims to help healthcare providers understand what they experience in the presence of illness and make them central to narrative exercises, the ERT approach removes the focus of healthcare providers as much as possible. Since most Black patients will have caregivers who are not Black given that in 2018 only 5% of physicians identified as African-American or Black and in 2017 only 6% of registered nurses identified as African-American (American Association of Colleges of Nursing 2019; American Association of Medical Colleges 2019), it is imperative for the proper treatment of Black people not to make Whiteness the standard by which Black people's experience of illness is judged. And if not properly educated, it is very easy for White health professions learners to judge Black people's experiences based on their own limited perspective of illness. But given Black people's different experiences with race, including the biological and psychological effects of racism , making whiteness the standard for judging illness means ignoring the unique social context of the Black experience and its influence on health.The use of testimonies in the ERT approach is similar to the Health Humanities Portrait Approach to curriculum, which centers the patient's own words using illness narratives. The idea behind the Health Humanities Portrait, as a pedagogical tool, is that when patients speak about their experiences, they provide learners with their own experiential expertise about illness and health. Centering the patient also minimizes the chance that learners will objectify patients; instead, patients become more than their illness with full lives outside of their it (Sufian et al. 2020) . The ERT approach extends this specifically to Black people who as Baldwin states, too often are viewed only by their losses and the marginalized aspects of being Black rather than as individuals with full lives. Using testimonies from Black people gives them an authority over their own stories in health care, which too often either doesn't trust Black people to be narrators of their own stories or removes their voice from those stories.The many patient narratives that are coming out of the COVID-19 pandemic provide healthcare professions educators with an abundance of material for the ERT approach. In particular, many testimonies from Black people attests to their unequal experience of the virus, including the ways that social inequities complicate their experience of the pandemic (Yancy 2020) . Moreover, we have the data (although incomplete since the pandemic is ongoing) that supports these experiences, completing the ERT approach.For instance, as of October 2020, Black individuals are 2.5 times more likely to die COVID-19 infection than White people (""The COVID Racial Data Tracker"" 2020). More specifically, in cities like New York City, Black people had a death rate of ninetytwo per 100,000 as compared to forty-five per 100,000 for White people (""Too Many Black Americans are Dying from COVID-19"" 2020). Additionally, in the early days of the pandemic, Black people made up 30% of COVID-19 patients, while only making up 13% of the population (CDC COVID Data Tracker 2020). Disparate experiences with COVID-19 also extend to Black children as Black (and Latinx children) have overwhelmingly higher rates of hospitalizations for COVID-19 infections than White children (Lindsay et al. 2020) .As the pandemic progresses, Black people, in addition to Latinx and Indigenous people continue to die from COVID-19 at disproportionate rates (Gold et al. 2020; Killerby et al. 2020; Price-Haygood et al. 2020; Millet et al. 2020 ). The Centers for Disease Control and Prevention (2020) has stated that people from certain racial and ethnic minority groups are at increased risk of infection and death from COVID-19 because of inequities in social determinants of health and factors such as racial discrimination. As the COVID-19 pandemic is an ongoing event and more data continue to be released by public health organizations, universities, and government agencies, we will get a better picture of the impact the virus is having on Black people. However, we do have many stories of Black people's unequal access to care, the structural and institutional barriers they have to overcome to receive care, their experiences with provider bias when seeking care, and the ways that COVID-19 is magnifying their fears of medical mistreatment.For instance, in the early months of the pandemic, Tanya Fields, a Black woman living in New York, a hot spot at the time, had all of the symptoms of COVID-lethargy, body aches, fever, and cough. Although it was likely that she had COVID-19, Fields chose to recover at home with her family, including her six children because she mistrusts medicine, citing its history of poorly treating Black people: ""Black folks don't get treated well in hospitals and so if I can stay at home and get better, if I don't need a prescription from the hospital, why the hell am I going?"" (Harper 2020) .Using both the data on COVID-19 and examples of the testimony from individuals like Fields, educators can engage learners in discussions on Black people's historical relationship with health care and its implication for contemporary clinical interactions, specifically for COVID-19 testing and therapies. To spur conversation, educators can ask students: ""Why might Fields have this sentiment about hospitals? What about the United States' handling of COVID-19 may have led her to think this way about medicine and about her own health? How might the data on COVID-19 and its effects on Black people influence her decision not to seek treatment?"" These are just some of the questions that can prompt learners to reflect on what Fields' testimony reveals about the Black experience of the COVID-19 pandemic.The ERT approach becomes even more impactful when learners see testimonies that attest to different experiences on the same topic. For instance, when Keith Grambell's father, Gary Fowler, a Black man with diabetes went to a Detroit hospital with COVID-19 symptoms, staff refused to test Fowler for the virus and instead sent him home with instructions to take Tylenol. Reflecting on this, Grambell stated that he felt the hospital staff ignored his dad:It's like a slap and a spit in the face. My dad should have been tested. I just feel like he should have been more of a priority since he's a high-risk candidate to be dead from this virus. But they just pushed him out the door, like he wasn't shit. (Lim 2020) Just days after being denied a COVID-19 test, Fowler died in his home. Grambell believed that if his father had been tested and received a positive COVID-19, test he may have been more of a priority for future care, thus saving his life (Lim 2020) .The day that Fowler died, Grambell's mother also began showing signs of COVID-19, including shortness of breath and high fever. Learning from the experience with his father, Grambell rushed his mother to the hospital, but she was also denied a test. Grambell took his mother to another hospital where she was tested, and the results indicated that she was positive for COVID-19. After multiple people in the family received positive COVID-19 tests, including himself, Grambell reflected on why it was so difficult for his family to receive the care they needed: I'm pretty sure they knew that this was going to attack the Black community like this. So why weren't we better prepared as a country? Just seeing it affect us is crazy. It's mind-blowing. But I kinda know why -we're being pushed home to die. (Lim 2020) Like Fields' testimony, Grambell's words reveal a lack of faith in medicine's ability to treat Black people fairly-a belief that medicine does not care about Black life. Adding his testimony to Fields' testimony reveals a picture of the virus that the data do not: the individual experience of being Black and living during a pandemic in the 21 st century. Together, both Fields and Grambell's testimonies (among others), along with the data on COVID-19 provide educators with opportunities to discuss Black health and Black people's experiences with health care.In the United States, Black women are three times more likely to die from pregnancyrelated complications when compared to White women (""Racial and Ethnic Disparities Continue in Pregnancy Related Deaths"" 2019). In New York, researchers found that even when Black women have a college degree, their chances of dying during or soon after birth are still three times higher than White women who never completed a high school diploma (New York City Department of Health and Mental Hygiene 2016). In the United Kingdom, Black maternal mortality is also a public health concern. In 2016, for every 100,000 deaths during pregnancy, eight White women died compared to forty Black women (Anekwe 2020) . Using the available data on Black maternal mortality for context, the ERT approach examines individual instances of Black maternal death and individual instances of racial bias in Black women's birthing stories as a part of a broader systemic problem of racism in medicine and racism in social institutions that create inequities in social determinants of health.Supporting this approach to Black maternal mortality, the CDC, has argued that racial disparities in maternal mortality cannot be attributed to Black women's greater propensity for death during or soon after pregnancy. Rather, a lack of access within social determinants of health explains Black women's disparate maternal mortality. Additionally, systemic inequalities in health care such as Black women's experiences with providers' racial biases also explains their increased mortality. Specifically, to address Black women's maternal mortality, the CDC recommends that hospitals and healthcare systems ""identify and address implicit bias in healthcare that would likely improve patient-provider interactions, health communication, and health outcomes"" (""Racial and Ethnic Disparities Continue in Pregnancy Related Deaths"" 2019). With this recommendation, the CDC affirms that health care needs to address the effects of racism, within and outside of the clinical setting.Examining the problem of Black maternal mortality requires us to view the problem from within the context of structural racism, specifically racial discrimination of physicians, nurses, lactation specialists, and other caregivers as well as the barriers they create for Black women seeking safe maternal health care. Although the data alone indicate that something other than biology makes Black pregnant and delivering people vulnerable to death, the stories from Black women and their surviving families also indicate racism as the factor that makes a difference in Black maternal mortality. Tobi Oredein, a Black woman, who delivered her child in the United Kingdom provides one of those stories.Before delivering her child, Tobi Oredein made it a priority to prepare for her interactions with a racist healthcare system. During her sixty hours of labor, she developed a fever. When providers made the decision to begin the process of delivering her baby via C-section, Oredein was put in the hospital corridor to wait. Because she delivered during the COVID-19 pandemic, her husband was not allowed to be with her. When one of the doctors who would be operating on her passed Oredein in the corridor, the doctor looked at her and shouted, ""Get this Covid suspect out of here! Why is she here?!"" Oredein did not confront the doctor because she feared that a confrontation could jeopardize her life or her baby's life. Reflecting on her birthing experience, Oredein shares other racist encounters that she experienced during her pregnancy and her hopes for how health care will treat Black women in the future:Despite (thankfully) leaving the hospital with a healthy baby, I want our healthcare system to see Black women as humans, not stereotypes or objects that don't need love and care. I want a healthcare system that asks me what I need, rather than tells me to carry on when I feel like I can't, that shows compassion to Black women when we feel at our weakest. I want healthcare that doesn't call my husband a 'baby daddy' when we attend a routine checkup in tracksuits. I want healthcare that in times of a pandemic or not, doesn't make me feel like a burden. I want doctors that see the fear on my face and console me. I'm not asking to be wrapped up in cotton wool but I am asking for care. (Oredein 2020) Oredein pleas for healthcare providers to see her and other birthing Black women like her to be treated with respect and care and not with stereotypes and racial bias. In her testimony, she calls our bias in health care systems.Along with general discussions on racial bias in medicine, Oredein's testimony, along with the available data on Black women's maternal mortality rates provide the foundation for educators to discuss specifically the effects of racism in and outside of the clinical setting. For instance, educators can discuss how Black people's experiences with racism and microagressions in their everyday lives affect their clinical encounters with providers. Educators can also discuss providers' actions, including ways to improve relationships with Black patients.Oredein's story is but one of the many stories about Black women experiencing racism during or soon after childbirth that educators can find with a simple search of the literature. Often these stories end differently than Oredein's story-with the mother and/or the baby dying. The ERT approach allows educators to use these stories and many others like them to discuss with learners the impact of racial bias against individual Black birthing people, while the data situate the stories within a broader context of a racist system that can be deadly for Black birthing people. The ERT approach helps learners examine the issue of Black maternal mortality as more than a fluke, or something that just happens to a few Black people; rather it reveals it as a systemic problem that is not a normal part of health care. More importantly, the ERT approach shows learners that they are integral to changing this systemic problem. When healthcare professions learners take part in the ERT approach, they are taking steps to change the way providers understand and interact with Black patients, resulting in better care for Black patients and systematic changes in healthcare.Another feature of the ERT approach is that it aims to encourage learners not to think of Black people's behaviors as moral and immoral. Often Black people are blamed for their poor health, judged as immoral for participating in unhealthy behaviors that contribute to their illnesses. For example, in his 2015 memoir entitled, Black Man in a White Coat, Damon Tweedy, a Black physician, tells the story of the patients he treated at a free clinic in a rural part of North Carolina. There he frequently saw Black patients diagnosed with hypertension and diabetes. While reflecting on how he interacted with these patients, he recalls assuming that their poor health was made worse by their poor life choices such as eating fast food or lack of exercise. When he learned that these patients either couldn't afford treatment for their chronic diseases, that their rural town did not have a mainstay physician's office, or that despite making healthy lifestyle choices like not smoking or drinking alcohol, he had to confront his biases. Furthermore, he had to consider that if he could have these biases against Black patients, despite being a Black person himself, could his White colleagues have the same biases against Black patients, could they also see Black patients with poor health as moral failures? When reflecting on the social factors that influenced his Black patients' health, Tweedy is not saying that Black people are never to blame for their poor health, but he is acknowledging that sometimes there are external factors beyond their control that influences their health. And instead of making their decisions a matter of morality, we should view their health decisions within the context of social determinants of health, namely within the social and cultural context in which they live and make decisions about their health.Using the ERT approach educators can help learners who may be tempted to moralize about Black people's choices like Tweedy. Testimonies, in particular, can help learners think about the social and cultural context of their health and the decisions they make for their health. For example, Donald Owens, a fifty-two-year-old Black man reflects on what led to his diabetes diagnosis: I think I acquired the diabetes, not that it is hereditary, but I acquired it through eating what my parents ate.... They used to eat like so many starches all the time, so many beans, so many sweet potatoes, chicken breasts, chicken fried, and we used to eat a lot of fried foods all the time.... sneaking in when I was a kid, sneaking in to make so many sugar sandwiches. Sugar and butter sandwiches, full of sugar like that thick, and I think that is really what got to me. (Liburd et al. 2004, 222) Owens is one of the Black adults who is at a higher risk to develop diabetes than White adults based on biological and social risk factors (Hicklin 2018) . In his testimony, Owens acknowledges the social factors that he believes contributed to his diagnosis.Similarly, Darnell, a forty-year-old Black man diagnosed with coronary heart disease reflects on how his learned, cultural behavior contributed to that diagnosis: I know that before I had heart disease, I was eating pork all the time! Ribs? You couldn't get me out of a rib place-bacon, pork chops, you know. And that could be bad for you...It's probably a primary cause. From what I understand of the history, we started off being slaves. We ate what we can and throughout time it just became a delicacy for us, making meals out of what we can. My parents are from New Orleans. It kind of [got] picked up from them what I thought was good food not realizing it was bad. (Dubbin, McLemore, and Shim 2017) Like Owens, Black Americans have higher rates of mortality from cardiovascular disease than White Americans. It is estimated that 48% of all Black men and 44% of all Black women have some form of heart disease including hypertension (Cleveland Clinic 2017). Like Owens, Darnell believes that his eating habits contributed to his diagnosis.Testimonies from Black individuals like Owens and Darnell humanize statistics about the disparity in the Black population of diabetes and cardiovascular disease; they put a face to the numbers that can easily become meaningless for learners. Using the ERT approach, the testimonies and data on diabetes and cardiovascular disease, as just an example, help students view Black people's experience with disease as a matter of social and biological factors that are either outside of their control and therefore, ought not to be judged, or as behaviors that are cultural and could be amended with providers' guidance. The ERT approach encourages learners to think about their role in educating their Black patients on healthy lifestyle choices given certain cultural practices and using cultural competency when treating Black patients rather than declaring their lifestyle choices as ""bad"" or ""immoral.""The kind of racial discrimination that Black people experience is unique to the experience of being Black, yet so interwoven into the experience of being Black that not even a powerful testimony can make someone understand what it feels like to experience discrimination, poor health, and mistreatment because of false socio-political narratives attached to skin color. Since non-Black people can never have first-hand access to the experience of being Black, the freeform, short nature of testimonies that the ERT approach uses may not be enough to accomplish its goals. Therefore, empathy is not the goal of the ERT approach; rather understanding, connectedness, and action are the intended goals. Some learners, particularly those resistant to the ERT approach and those hostile to learning about Black health may need more substantial narratives that provide more information to connect to the experience being conveyed by the individual. Learners may find testimonies impersonal and not enough to supplement the information conveyed by data.Learners who are hostile to learning about Black health may find the three merits of the ERT approach I've discussed in this article unconvincing. For instance, learners who do not believe that racism exists nor that Black people face any significant racial biases in health care may be resistant to examining Black patients within the context of racism. Similarly, learners who think that Black people have full control over their health and that their poor health is the result of bad choices will not be convinced. The ERT approach may initially work best for learners who are already sympathetic to bettering the status of Black people's health but can also reach learners who resist its methods by presenting both the factual story and the human story of Black health.The ERT approach pairs data with testimonies for an all-encompassing learning experience for future caregivers, giving them the information to situate Black health within a larger social context and showing the impact poor health can have on Black individuals and their families. It aims to give Black people a voice and to show that the problems that affect their health are bigger than an isolated problem. Instead of individual changes, larger systemic changes must occur for better Black health, and that starts with how we educate learners.The ERT approach gives health humanities educators an opportunity to expand the way that learners study about Black individuals and the Black population, a group of people made vulnerable by systemic injustices, including those that occur in medicine. As future caregivers, learners can use the ERT approach to better understand the features of Black people's lives and better understand needs of Black people while they are seeking care. Education is one of the best ways to better Black health and correct their disparate health outcomes and the ERT approach does just this; it educates while humanizing Black people and showing the unjust nature of their poor health outcomes and healthcare.",USA,first author,2021-02-12,02
e2365c411e61a8464b20012e3c6159cd5e1f53ca,Non-pharmaceutical interventions and inoculation rate shape SARS- COV-2 vaccination campaign success,"The novel coronavirus SARS-COV-2, the causative agent of coronavirus disease 2019 (COVID-19), emerged in China during late 2019 and rapidly spread throughout the world. In March 2020, the World Health Organization (WHO) declared the COVID-19 a pandemic, and by January 2021 SARS-COV-2 had caused more than 100 million confirmed COVID-19 cases and 2 million deaths worldwide (1) . A global effort to develop vaccines against SARS-COV-2 began early in 2020, but for most of that year the only options for slowing transmission were non-In this analysis, we simulated and assessed the benefits of SARS-COV-2 vaccination in the US under varying levels of NPIs and differing vaccine administration and acceptance rates. Projections were made with a SEIRV (Susceptible-Exposed-Infected-Recovered-Vaccinated) compartmental model run in isolation for all 50 states and the District of Columbia (DC), in which the population was stratified by age and priority group. Specifically, we stratified each state population by years of age (0 -4, 5 -17, 18 -49, 50 -64 and >65), adult exposure status (essential workers (EW), healthcare workers (HC), other adults) and health risk status (presence or absence of one or more health risk factors for severe disease (RF)) ( Figure 1A , Supplementary Tables S1 and S2). The model was parametrized using posterior distributions estimated with a separate, non-stratified metapopulation model iterated through January 10, 2021 (12) and later adjusted for age and population types (see Methods and Supplementary Table 2 ). Initial conditions and statistics for key epidemiological parameters are reported in Figure 1 . The median estimated proportion of the state population susceptible (i.e. the population percentage not previously infected with SARS-COV-2) on January 10 was 65%, and varied across states as shown in Figure 1B . Initial susceptibility for the vaccine scenario projections were varied based on seroprevalence differences in the population ( Figure 1C and Supplementary Table 2 ). The median national estimate of the time-varying reproduction number Rt was 1.78 on January 10; however, state-to-state heterogeneity of NPIs at that time is reflected in a broad distribution of Rt values ranging from 0.8 to 2.2 ( Figure 1D ).All vaccination scenarios assumed 400 million doses (6, 7) distributed to the US population according to ACIP prioritization guidelines (3) . We considered phases 1a, 1b and 1c completed 10 days after (first) vaccination of a target coverage number of individuals. Once the prioritization groups were vaccinated to target levels, vaccination was administered to other adults and children. The start date of the vaccination campaign was December 14, 2020, and, based on vaccination records (8), 5 million doses were administrated in the US through the first 3 weeks of the vaccination campaign. Doses were allocated to the 50 states and DC in proportion to state population size, and two doses of vaccine were administered to all vaccinated individuals 3.5 weeks apart (see Methods and Supplementary Tables S3 and S4 for details on vaccine modeling). Vaccination was administered regardless of prior history of infection and acted to prevent transmission to susceptible individuals. The impact of different scenarios was quantified in averted infections and deaths during the 15 months following January 10. The (mean) averted burden of infection (both ascertained and unascertained) was measured for each intervention scenario Ni with respect to the (mean) attack rate (AR) in reference scenario N0 (without vaccine and non-pharmaceutical interventions, see Supplementary Table S5) .The same formula was used to quantify the averted deaths.We first tested the effect of imposing different NPIs during the vaccination campaign. In this analysis, 5 million people received the first vaccine dose each week beginning week 4 of the campaign (Supplementary Table S4 ). We fixed the target coverage among different subpopulations at 80% for HC, 70% for risk groups (adults ≥65 and adults with RF), and 60% for other adults and children (up to available doses). The estimate of the time-varying reproduction number on January 10 (median Rt=1.78) reflects reductions in opportunities for transmission due to NPIs, i.e., Rt is a reduction of the basic reproduction number (R0). Relaxing (strengthening) the NPIs would inflate (decrease) Rt and, in turn, the theoretical threshold for herd immunity. Estimates of the basic reproduction number for SARS-COV-2 in the United States vary across studies from 1.34 to 4 (13,14) . Here we present the results for R0= 2.8; but also analyzed results for R0= 2.4 and R0= 3.2. Figure 2 compares the cumulative and averted burden of infection and death among 6 different NPIs scenarios characterized by different duration and strength of the NPIs imposed throughout the vaccination campaign: N0 is the limit scenario without intervention (NPIs or vaccination); N1 has vaccination but NPIs are completely relaxed on January 11, 2021; N2 maintains NPIs at initial levels then completely relaxes them upon completion of phase 1a; N3 relaxes NPIs in 3 steps upon completion of phases 1a, 1b, 1c; N4 first strengthens NPIs then relaxes in 3 steps after completion of phases 1a, 1b, 1c; and N5 maintains initial NPIs until (10 days after) 140 million people have initiated vaccination, then relaxes in 3 1-month steps. On average the 3 phases of vaccine prioritization in (3) were completed, respectively, 23, 66, and 154 days after January 11 (timing differed in each state due to population structure) and 140 million vaccinated were reached 193 days after January 11 ( Figure 2A ). Other NPI scenarios, including scenarios in which relaxation was triggered by time and not phase completion are described in Supplementary Table S5 and results are shown in Supplementary Figure S1.In Scenario N0 the cumulative attack rate in the overall population (for the period beginning January 11, 2021) was 44.8% and the cumulative death rate was 0.0015%. Adding vaccination (Scenario N1) yielded an attack rate of 39.5% and death rate of 0.0012%, an 11.8% reduction of infections and a 19% reduction of deaths relative to Scenario N0. Maintaining NPIs during the vaccination campaign allowed for much greater reductions: 20% to 60% of infections and 30% to 70% of deaths were averted depending on the strength of the NPIs maintained during the vaccination campaign. When NPIs were strengthened and gradually relaxed (N4) or maintained at initial levels for 6 months (Scenarios N5 and N6, N9 in Supplementary Figure S1 ) the attack rate in the population fell to roughly 15%. The more limited impact of vaccination in the absence of NPIs is due to the faster spread of SARS-COV-2: by the time phase 1a and 1b are completed in N1, 46% and 72% of the population is already immune (or deceased) by natural infection, whereas in N4 at the same time only 39% and 46% of the population have been infected ( Figure 3 ). Without NPIs, vaccination had a weaker impact because 1) herd immunity was approached earlier during the campaign because the susceptible pool was diminished due to a high attack and 2) the rate of effective vaccination (vaccination of susceptible individuals) was slower due to a lower susceptible fraction. Results were robust across a larger set of scenarios and for different estimates of R0 (Supplementary Text S2 and Supplementary Figure S1 ), and were consistent at the state level. Among the 6 NPIs scenarios described here, N4 and N5 had the lowest attack rate in all states (Supplementary Figure S2) . We also tested the sensitivity of the results to initial conditions (such as initial susceptibility) and vaccination setting (number of doses used, vaccine efficacy, and the consequence of vaccination protecting against disease instead of infection) (Supplementary Text S3, Supplementary Figures S3-S8 ). Though estimates of infections and deaths depended strongly on some of these varied parameters, the general finding indicating the strong effect of NPIs held.A number of factors could affect the rate of vaccine administration in the coming months: availability of doses, distribution of doses, and management of the distributed stock by jurisdictions. We analyzed how variations in the rate of vaccine administration impact the cumulative infections and deaths averted due to vaccination. Specifically, we tested 6 vaccination schedules with 3, 5, 7, 9, 11 and 13 million people initiating vaccinations every week nationally. The 6 vaccination schedules were combined with 4 NPIs policies: a ""NO NPIs"" scenario with measures relaxed on January 11, 2021; a low distancing scenario (""LOW"") with NPIs completely relaxed after one month; an intermediate distancing scenario (""MED"") with NPI relaxation initiated after 1 month and gradually completed across 5 months; and a strong distancing scenario (""HIGH"") with measures first strengthened then gradually relaxed over 6 months. These scenarios correspond to scenarios N1, N7, N8, and N9 in Supplementary Table  S5 ; all are characterized by a time-triggered relaxation of NPIs rather than a target-triggered relaxation in order to better isolate the effects of vaccination rate as phases 1a, 1b and 1c were reached at very different times across the 6 vaccination rates (e.g. the 3 prioritization phases were completed after 254 days for 3 million vaccinated/week and after 62 days for 13 million/week). The target coverage in each group remained the same as in the previous analysis: 80% for HC, 70% for risk groups, 60% for other adults and children up to availability.Expanding the number of doses administered per week from 5 to 7 million averted 3 to 6% more infections and 4 to 8% more deaths with respect to Scenario N0; expanding from 5 to 11 million per week averted 9 to 16% more infections and 7 to 18% more deaths with respect to Scenario N0 ( Figure 4) . The effect of a faster deployment was stronger within scenarios characterized by weaker NPIs, because of the more rapid accumulation of infections in the first months. Results were robust to other estimates of R0 (Supplementary Text S4 and Supplementary Figure S9 ).The third analysis examined the effects of vaccine uptake, specifically the percentage of each subpopulation able or willing to receive the vaccine (due to vaccine acceptance rates and difficulty accessing vaccination facilities), on population outcomes. Here, we assumed 5 million doses distributed per week beginning January 11, 2021. We assessed the effect of uptake by comparing the cumulative infections and deaths for the same 4 NPIs scenarios, N1 (NO NPIs), N7 (LOW), N8 (MED), N9 (HIGH), considered in the previous analysis. Baseline coverage, c, remained 80% among HC, 70% among individual at risk and 60% among other adults and children up to availability. We then tested different uptake levels by increasing or decreasing the coverage of all groups by the same percentage (Scenarios c0.5, c0.75, c1.2 are obtained multiplying the baseline uptake c, respectively, by 0.5, 0.75 and 1.2). Additionally, for Scenario c99 target coverage is set to 99% for the whole population, and for Scenario cR target coverage is increased to 99% only for higher risk groups and kept at baseline for other groups.Given 400 million doses, the maximum percentage of the overall population that could be vaccinated was 61.5% overall, therefore c, c1.2, c99 and cR reached the same cumulative coverage (see Figure 5 ). The effect of a uniform increase or decrease in uptake across all groups was moderate, whereas a stronger impact on deaths averted was seen when increasing uptake solely for higher risk groups, consistent with other recent findings (15). Specifically, uniformly doubling uptake from 32% to 64% of the population averted 2 to 4% more infections and 3% to 5% more deaths with respect to the no intervention Scenario N0 when some level of NPIs were also imposed. In the NO-NPI scenario (N1) doubling the uptake from c0.5 only averted 1% more infections and did not increase averted deaths. On the other hand, Scenario cR averted 4% more deaths with respect to N0 than the baseline Scenario c with equal cumulative coverage ( Figure  5 ).Two processes appear to explain this result: 1) vaccine impact is greater in the first months of administration when fewer natural infections have occurred, but, at that time, demand exceeds vaccine availability, and 2) increased coverage in not-at-risk groups has the effect of delaying the administration to lower priority but more at-risk-groups, which, with the exception of LTCF residents, were included in phases 1b and 1c. In Scenario c0.5 only 35% of the population at risk was vaccinated, but phase 1b and 1c started 2 weeks and 1 month, respectively, earlier than in Scenario c (Supplementary Figure S10 ). This earlier administration to the 1b and 1c groups partially offset the lower vaccinated proportion. The averted infections for c99 varied minimally even when increasing the total doses from 400 to 600 million, suggesting that increasing the overall coverage is not very effective without increasing the weekly vaccination rate (Supplementary Text S5). Results were robust to different estimates of R0 (Supplementary Figure  S11 ).The recent advent of safe and efficacious SARS-COV-2 vaccines could help end the pandemic. However, even in the most optimistic scenario, administering full vaccination with either BNT162b2 or mRNA-1273 to most of the population will take many months to complete, due to time required for production, distribution, and administration of two doses. According to the agreements stipulated in December 2020 between the US government and the vaccine manufacturers (6, 7), the US has purchased enough doses of BNT162b2 and mRNA-1273 for full vaccination of more than 60% of the population. An additional 100 million doses of both BNT162b2 and mRNA-1273 were recently contracted by the US government, other vaccine candidates are currently undergoing or completing phase 3 trials, and negotiation with manufacturers is ongoing (16); thus, it is possible that additional vaccines and additional doses of BNT162b2 and mRNA-1273 may contribute to increased vaccine coverage in the coming months.Here we performed an analysis to test how the impact of the vaccination campaign (with a fixed total of 400 million doses) depend on 3 factors: (1) the NPIs imposed during vaccination, (2) the rate at which doses are administered, and (3) the vaccine uptake within subpopulations differing by age, exposure status and health risk status. The strongest modulator of the impact of vaccination, measured by averted infections and deaths for a broad range of realistic scenarios was the enforcement of NPIs throughout the vaccination campaign. With stronger NPIs, virus transmission slows, allowing vaccination of more susceptible people prior to infection. Overall, the vaccination campaign over the next several months has the potential to prevent infection of 20 to 40% of the US population; however relaxing NPIs before attaining adequate vaccine coverage could result in infection of those individuals and further hospitalizations and mortality. In the scenario in which all NPIs were immediately relaxed 4 weeks into the vaccination campaign, the averted infections were only 14%-27% of the number averted in the strongest NPIs scenarios, depending on the estimate of R0. When NPIs were maintained for a long time, hundreds of thousands of deaths were averted at the national level. These findings underscore the importance of maintaining NPIs during the vaccination campaign. However, we are now over one year into the pandemic; exhaustion and the economic toll of the pandemic cannot be discounted by policy makers in evaluating the extent and duration of the NPIs to be enforced during the next months.The administration rate of the vaccine also had a strong impact in our analysis: increasing weekly vaccinations from 5 to 11 million, while keeping the cumulative availability fixed, reduced deaths by 17 to 20% with respect to the no intervention scenario across different estimates of R0. Increasing the speed of vaccine administration was particularly important for scenarios with reduced levels of NPIs. It is therefore essential to increase efforts to produce, distribute, and administer the vaccine.In the first weeks of the US vaccination campaign, only 20% of distributed doses were administered. By January 28, 2021, that percentage increased to about 50% (8). Several factors need to be optimized: coordination between the federal government and individual states, management of the vaccine stocks by jurisdictions, operation of vaccination sites including coordination of personnel and strategies for facilitating population access, and protocols to assure that vaccine doses are not wasted.In our analysis, the effect of vaccine acceptance on the overall averted disease burden of the vaccine campaign was limited. This was due to two factors: 1) with a fixed administration rate of 5 million doses per month, the vaccination campaign had a greater impact in the first months, when vaccine demand was greater than availability, even for low vaccination uptake scenarios; and 2) the prioritization order did not place risk groups with higher mortality first in line for vaccination. Therefore, in a low uptake scenario the non-risk groups were processed faster, allowing the risk groups to be vaccinated earlier, albeit with a lower uptake. This result, however, has to be evaluated within the limitations of our approach: first, we only considered mortality and infection, whereas the pandemic has an impact also on Quality-Adjusted Life Years (QALYs ) and Disability-Adjusted Life Years (DALYs), as well as occupational hazard and social disparity. Second, even though we characterized healthcare workers as having more work contacts than other adults, we didn't characterize those contacts as more likely to be with infected individuals. Therefore, the averted burden of infections with the current prioritization could be underestimated.In our simulations, we evaluated full vaccination with BNT162b2 and mRNA-1273, which both require two doses, as recommended by the FDA (17). In light of recent consideration of reducing the number of doses from 2 to 1 until adequate vaccine is available, we additionally examined how a single dose campaign with BNT162b2 and mRNA-1273 could modify the impact of vaccination. The one-dose campaign, which doubled the weekly vaccination rate but with 90% vaccine efficacy, averted up to 12% more infections and 15% more deaths across different NPI scenarios relative to the no-intervention scenario. However, caution is needed when interpreting model results for single dose administration, as it is unknown whether immunity would last as long as with two doses. Indeed, other vaccines (e.g. Tetanus and Hepatitis B vaccines) require additional doses administered within a short time in order to boost and ensure a robust and durable adaptive immune response (18).Our analysis has several limitations. The high dimensional model is sensitive to the choice of parameters and initial conditions. We tested finding sensitivity to several model parameters and even though the numbers of averted infections and deaths varied, sometimes largely, as with initial population susceptibility (see Supplementary Figure S3 ), the overall conclusions of our analyses held.In this analysis, we also did not account for waning natural or vaccine-induced immunity or the emergence and dissemination of SARS-CoV-2 variants for which vaccines may be less efficacious (20) (however, we did test the sensitivity of results to lower efficacy of the vaccine (see Supplementary Text S3)). Evidence of re-infections with SARS-COV-2 has been reported around the world (21, 22, 23); however, more data are needed to understand the effect and time scale of these events at the population level. Should immunity prove to be short-lived, vaccination may need to be repeated every year or every few years for adequate coverage. A different model structure, accounting for loss of immunity, would be needed to quantify the burden of infection and deaths in this instance.Supplementary Text S1: MethodsFor each subpopulation i, Si, Ei, ] i, Ii, Ui, V1i, V2i, V3i, and Ri represent the susceptible, exposed, exposed vaccinated, infected reported, infected unreported, vaccinated (in the 3 phases) and recovered populations, the duration of infectious period, Z the latency period, and N the population size. We distinguish between Exposed and Exposed Vaccinated to allow for a different probability of developing reported infection: E and Y E the ascertainment rate of infection, respectively, for unvaccinated and vaccinated individuals. Other parameters are: the travel-related importation of SARS-COV-2 into the model domain, E the vaccination rate, and r the decreased probability of transmission for unreported infectious individuals. We allow the transmission rate to vary through specific age-dependent contact rates E,M between individuals in age groups Ni and Nj, such that the full transmission term is ( I E + 8 I 1 E + 9 I 2 E + :One hundred ensemble projections were simulated in each state for 450 days starting from initial conditions estimated on January 10, 2021. Projections for each state were initialized using posterior estimates derived from a separate metapopulation model-Bayesian inference system, described in Section 1.2.1.Our strategy for defining the distributions of parameters and variables in system (1) is based on the following steps: 1) We estimated the population-level distribution (interquartile range) of the epidemiological parameters on January 10, 2021 in each State with a non-stratified metapopulation model-Bayesian inference framework. 2) We combine the population-level estimates with information on population structure and age-specific infection and seroprevalence rates to stratify the initial conditions by age and population type (see Supplementary Table S2 for details on specific parameters and variables). 3) We initialized system (1) with the stratified distribution of parameters and initial conditions. For each state, we ran 100 simulations, each with initial conditions and parameters randomly drawn from the interquartile of the estimated distributions.To perform the inference in step 1) we used a county-scale metapopulation model in which transmission of SARS-CoV-2 is simulated within and between each of the 3142 counties of the US (12). The subpopulations of each county are linked by documented rates of inter-county commuting and random travel. The metapopulation model has a SEIR structure featuring the same distinction between reported and unreported cases, but without the age/exposure stratifications listed in Table S1 . The metapopulation model is combined with the ensemble adjustment Kalman filter (25), which assimilates case observations (reported infections) and iteratively estimates the time-evolving distribution of unobserved parameters and state variables. Details on the inference procedure can be found in (12). Using this framework, we obtained population level (i.e., unstratified) estimates of initial conditions on January 10, 2021 (e.g., the time-varying reproduction number Rt, initial susceptibility, ascertainment rate, etc.).We combined the inferred parameters with information on population structure, age specific seroprevalence estimates and published age-specific infection reporting rates as described in Supplementary Table S2 . We divided the population in 12 groups (see Table S1 ). We included all EW and HC in the two adult groups (18-49) and (50-64). − I =u ∑ E E and E and E are the population of age group i in state S and the seroprevalence in state S.Vaccination administration in the US began on December 14, 2020. We assumed 5 million doses administered cumulatively in the first 3 weeks based on inoculation records (8). In subsequent weeks, beginning January 4, 2021, we assumed 5 million people vaccinated nationally for each subsequent week (except for the administration rate analysis in which weekly rates varied from 3 to 13 million vaccinated). We assumed both the BNT162b2 and mRNA-1273 vaccines required 2 doses and that complete efficacy was reached 1 week after the second dose. The time between first and second dose is 3 weeks for BNT162b2 and 4 weeks for mRNA-1273 (4, 5) . Here, we averaged these two interval times and assumed that each individual received the second dose 3.5 weeks after the first dose. Weekly doses were assumed to be distributed uniformly over 7 days. Vaccine parameters and the administration timeline for the baseline scenario are detailed in Table S3 . Vaccination in the simulations was administrated according to the following prioritization order based on (3): 1) Phase 1a: Healthcare workers (~20 million) & long-term care facility (LTCF) residents (~3 million). 2) Phase 1b: Front Line Essential Workers (~30 million) & adults >65 with RF (~14 million) 3) Phase 1c: Other Essential Workers (~30 million), adults >65 (~26 million) & adults with RF (37 million) 4) Other adults (~86 million) 5) Children (~79 million). Although both the BNT162b2 and mRNA-1273 vaccines are not currently recommended for children, in our analysis we hypothesize that by the end of the vaccination campaign vaccine will be recommended to all age groups.The estimate of vaccine efficacy used in the model was based on results from the Pfizer and Moderna phase 3 trials (4, 5) . However, experimental error (e.g. PCR sensitivity) and possible reduction of effectiveness due to new emerging viral variants (20) could impact the actual efficacy of the vaccine. When efficacy was reduced by 20% (both after the first and second dose), the averted infections and deaths were 70-95% and 75-98% of original analysis, respectively (Supplementary Figure S4) . Figure S4 : Attack rate and death rate for vaccine efficacy reduced by 20%: ( 8 = 0, 9 = 72% : = 76% ). Here R0=2.8, the vaccination calendar is presented in Table S4 , and coverage is baseline c (80% HC, 70% for population > 65 and adults with RF and 60% for others up to availability).Sensitivity of the attack rate to varying the relative ratios of contact rates. Results are for R0=2.8, the vaccine calendar in Table S4 and coverage baseline c (80% HC, 70% for population >65 and adults with RF and 60% for others up to availability). Symbols correspond to mean estimates of the attack rate and death rate corresponding to different choices of relative contact reduction due to NPIs. Red symbols are the mean estimate for the original setting (60% contact reduction in school, 60% contact reduction at work, no contact reduction at home, and 30% contact reduction in other settings). Black symbols are the mean estimates for 10 arbitrary perturbations of the relative contact reduction at school, work and other settings.We compared the performance of 2-dose vaccination with a 1-dose vaccination campaign based on the same cumulative vaccine availability (400 million doses total). We set the efficacy of 1dose vaccination to 90% 12 days after administration (Table S3 ). The population vaccinated per week increased from 5 to 10 million, and the stock was sufficient to vaccinate the entire population as second doses were not administered and all available vaccines were used as first doses. We analyzed two different uptake scenarios: the baseline scenario c (80% HC, 70% risk groups, 60% others, for a cumulative maximum uptake of 64%) and scenario c99 where coverage was 99% in all groups. For both coverage scenarios, the one-dose vaccination yielded more averted infections and deaths than the two-dose vaccination for all the NPI settings considered 10 -4(N1, N7, N8, N9). Specifically, with uptake scenario c, there were 6-12% more averted infections and 5-15% more averted deaths depending on the NPI scenario ( Figure S6 ). With uptake scenario c99, in which not only the allocation speed, but also the total population covered was significantly increased in the 1-dose vaccination campaign, there were 7-13% more averted infections and 5-17% more averted deaths ( Figure S7 ) with respect to scenario N0.Left panels show the attack rate, death rate and averted burden for two-dose vaccination with 61.5% coverage and 5 million vaccination per week in uptake scenario c99; right panel show the attack rate, death rate and averted burden for and one-dose vaccination (right) with 99% coverage and 10 million vaccination per week. The NPI scenarios N0, N1, N7, N8, N9 are described in Table  S5 .Cumulative individuals no longer susceptible or infected (blue lines: recovered + deceased) and effectively vaccinated (red lines: recipients of vaccine who were susceptible) in scenario N1 (NO NPIs, panel A) and N9 (HIGH NPIs, panel B). Dashed blue and red lines refer to uptake scenario c and solid blue and red lines refer to uptake scenario c0.5. Black vertical dashed lines mark the end of vaccination (first doses) in c and c0.5. Panel C) Vaccine coverage of risk groups (adults with RF and population >65 with and without RF) through time from December 14, 2020 for the 6 uptake scenarios (c0.5, c0.75, c, c1.2, c99, cR).",United States,abstract,2021-02-25,02
b97152c91b75356340d44b88e9653eb0ec5da4b5,The local topological free energy of the SARS-CoV-2 Spike protein,"The severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) has led to the COVID-19global pandemic which has taken over 2 million lives. The need to stop the spread of the highly infectious virus requires disruption in the infection process and has become the focus for many scientists. Even more so, the task to be able to control and stop a global pandemic in the future is of great interest. Fusion of the membranes of both a host cell and a viral cell is necessary for infection [10] . Viral glycoproteins aid in this process by facilitating the binding of the two cells. Viral glycoproteins are folded proteins on the enveloped viral cell membrane which, when triggered, undergo irreversible dramatic conformational changes [14, 19, 24, 42, 48, 62, 63] . The SARS-CoV-2 S protein is a class I viral glyco-protein that consists in two subdomains (S1 and S2) and is triggered by cleavage at the S1 cleavage site [14, 14, 20, 25, 30, 37, 63] . S1, containing a receptor binding domain (RBD), binds to a host cell receptor, angiotensin-converting enzyme 2 (ACE2), and leads to a second cleavage at an S2' cleavage site, adjacent to the fusion peptide. The protein undergoes several structural rearrangements that lead to a stable post-fusion state which brings the two membranes together [14] . In this manuscript, we quantify these changes with the aim to understand how local changes can trigger global conformations.Folded proteins are defined by their primary, secondary, tertiary and quarternary structure [1] . The primary structure refers to the protein by amino acid sequence. The secondary structure refers to a sequence of 3-dimensional building blocks the protein attains (beta sheets, α-helices, coils). The tertiary structure refers to the 3-dimensional conformation of the entire polypeptide chain. The rearrangement of viral proteins during protein fusion changes both their tertiary structure and their secondary structure. We use tools from knot theory, namely, the Writhe and the Torsion, to characterize the viral protein conformations at the length-scale of 4 consecutive residues along the backbone.In the last decades, measures from knot theory have been applied to biopolymers [3-8, 12, 13, 16, 21, 29, 35, 38, 39, 46, 50, 51, 54, 56, 58] and in particular to proteins to classify their conformations [6-8, 15, 23, 31, 41, 46, 53, 55] . One of the simplest measures of conformational complexity of proteins that does not require an approximation of the protein by a knot dates back to Gauss; the Writhe of a curve. In [9] the Writhe and the Torsion were used to define a novel topological/geometrical free energy that can be assigned locally to the protein. The results therein showed that high local topological free energy conformations are independent of the local sequence and may be involved in the rate limiting step in protein folding.In this paper we apply this method to the spike protein of SARS-CoV-2 to characterize its conformation in various phases of viral fusion. Our results show that the local topological free energy of the spike protein is decreasing monotonically as the protein undergoes various conformational changes pre-fusion to post-fusion, in agreement with a transition of the protein from a metastable to stable state. Our results in combination with DFT calculations suggest that local conformations of high local topological free energy are unstable. By comparing our results to experimental data, we find that residues in high local topological free energy conformations are possible candidates for mutations with impact on protein rearrangement.The paper is organized as follows: Section 2 describes the topological and geometrical functions for characterizing 3-dimensional conformation used in this paper and the density function theory calculations used to evaluate conformational stability. Section 3 describes the results of this method for SARS-CoV-2. Finally, in Section 4, we summarize the findings of our analysis.In this Section we give some definitions necessary for the rest of the manuscript.We represent proteins by their CA atoms, as linear polygonal curves in space. A measure of conformational complexity of curves in 3-space is the Gauss linking integral. When applied to one curve, this integral is called the Writhe of a curve:. For an oriented curve with arc-length parameterization γ(t), the Writhe, W r, is the double integral over l:It is a measure of the number of times a chain winds around itself and can have both positive and negative values.The total Torsion of the chain, describes how much it deviates from being planar and is defined as:The Torsion of an oriented curve with arc-length parameterization γ(t) is the double integral over l:The Writhe and the Torsion have successfully been applied to study entanglement in biopolymers and proteins in particular [2, 6, 6-8, 17, 18, 40, 43-45, 47, 49, 52 ].An important property of the Gauss linking integral and the Torsion which makes them useful in practice is that they can be applied to polygonal curves of any length to characterize 3-dimensional conformations at different length scales. In this work, we use the Writhe and the Torsion to characterize the local conformation of parts of the protein at the length scale of 4 residues, we call this the local Writhe (local Torsion, resp.). The local Writhe is a measure of the local orientation of a polygonal curve and a measure of its compactness. For example a very tight right handed turn (resp. left-handed) will have a positive (resp. negative) Writhe value close to 1 (resp. −1), while a relatively straight segment will have a value close to 0. Similarly, the Torsion is 0 for a planar segment and increases to ±1 as the segment deviates from being planar.In this Section we give the definition of the local topological free energy, originally defined in [9] . To assign a topological/geometrical free energy along a protein backbone, we first derive the distributions of the local Writhe and local Torsion and local ACN in the ensemble of folded proteins. To do this in practice, we use a curated subset of the crystal structures provided in the PDB [11] . Namely, we use the dataset of unbiased, high-quality 3-dimensional structures with less than 60% homology identity from [60] . Then for each residue of a given protein we compare its local Writhe (resp. Torsion) value to those of the ensemble and a free energy is assigned to the residue based on the population of that value in the ensemble.Let X denote a topological parameter (local Writhe, local Torsion). Let d X denote the density (ie. the number of occurrences) of X in the folded ensemble (d W r , d T , respectively).Let m X (resp. m W r , m T ) denote the maximum occurrence value for X. To any value p of X,we associate a purely topological/geometrical free energy:The total local topological free energy of a protein is defined as the sum of local topological free energies in Writhe (resp. Torsion) along the protein backbone. In [9] it was shown that the experimentally observed folding rates of a set of 2-state single domain proteins decrease with increasing total local topological free energy of the proteins.We will say that a residue is rare or in high local topological free energy in a parameter X (local Writhe or local Torsion) if its value X = p is such that Π(p) ≥ w, where w is a threshold corresponding to the 95th percentile of Π-values across the set of folded proteins.We stress that our definition of rare residue involves 4 consecutive residues, starting from the one we label as rare. We will say that a residue is in a high local topological free energy conformation, we denote LTE, when it is one of the 4 residues composing a conformation with high local topological free energy. Geometry optimizations of the identified high local topological free energy within the SARS-CoV-2 spike protein, were carried out in a model aqueous solution phase without imposing geometrical restrictions by using the NWChem suite of programs (version 7.0.2) [59] . All residues were optimized at the MO6-2X/6-311++G** level, e.g., via hybrid metafunctionals [66] , and solvent effects were accounted for by using the Solvation Model Based on Density (SMD), [36] . The optimization of the identified residues via DFT was done to evaluate the validity of our hypothesis that high local topological free energy conformations are indicative of unstable structures. Figure 2 . We find that the total local topological free energy in Torsion decreases from pre-fusion to post-fusion for all proteins. Similarly, we find that the total local topological free energy in Writhe also decreases pre-fusion to post-fusion, with the exception of SARS. This suggests that viral proteins during fusion are guided towards a minimum of the total local topological free energy, in agreement with a transition from a metastable to a stable state. We found that the total topological free energy of SARS-CoV-2 decreases from pre-to post-fusion (see Figure 2 ). We next analyze how the local topological free energy changes in various pre-fusion stages. In pre-fusion the SARS-CoV-2 glycoprotein may be in uncleaved conformation entails that all three RBD are in the down position [14] . An open conformation entails that there is an RBD in the up position, accessible for the angiotensin-converting enzyme 2 or ACE2 receptor to bind [14, 30, 64] . A cleaved protein indicates that the protein has been proteolytically cleaved at the cleavage site by a furin protease into the receptor binding subunit of S1. This is necessary for conformational changing of the RBD in human coronavirus. The fusion subunit of S2 remains associated after cleavage until post-fusion [65] .An intermediate conformation indicates that cleavage at the RBD has occurred and the RBD has been removed yet refolding has not occurred [14] . Section we compare this variant to two other variants of interest, G614 and HexaPro [28] .Our results in Figure 4 (Right), show that the G614 variant has an overall much higher local topological free energy in comparison to the HexaPro variant and the D614 variant. This is in agreement with experimental results which suggest that the D614 and HexaPro are more stable. The D614 variant is proposed to form a hydrogen bond with T859 (of the neighboring protomer or chain), limiting its flexibility while the G614 variant does not form this bond [34] .The HexaPro variant consists in 6 mutations [28] and has shown to stabilize the pre-fusion structure and produced high yield. In terms of the distribution of the local topological free energy in domains, we find that the G614 variant has increased local topological free energy in SD1, SD2, CD and HR1 domains. The results for Π T are similar and are shown in SI. In this section we focus on those local conformations in SARS-CoV-2 with high local topological free energy.In this section we use DFT calculations to compare the minimal energy configurations of high local topological free energy versus medium/low topological free energy conformations in SARS-CoV-2.obtained conformations versus those of the PDB. We do this for the high local topological free energy conformations versus medium or low local topological free energy conformations in SARS-CoV-2. The distribution of the differences is shown in Figure 5 . Orange indicates the difference for high local topological free energy conformations and blue for medium/low local topological free energy conformations. Figure 5 : The distribution of (Π W r ) DF T − (Π W r ) P DB . The difference for residues in high local topological free energy conformations is shown in orange and that of medium or local topological free energy conformations is shown in blue. The distribution of high LTE minimized differences has a skewness of −0.006 while that of medium/low LTE has skewness of 1.717. We note that 2 of the largest positive differences in medium/low LTE (outliers in blue) are for conformations that proceed a gap in the PDB sequence.Our results show that the distribution of (Π W r ) DF T − (Π W r ) P DB is more broad for the high LTE conformations compared to the medium/low LTE conformations. The skewness of the distribution of the medium/low LTE conformations is 1.717, while that of the high LTE conformations is −0.006. In particular, we find that for the majority of medium/low topological free energy conformations, their DFT structure is either very similar or it has lower local topological free energy. In contrast, many of the DFT reduced conformations of the high local topological free energy conformations, have even higher local topological free energy. These results further corroborate the idea that high local topological free energy conformations are indicative of unstable structures.The high LTE conformations in the SARS-CoV-2 S protein at various stages pre-fusion, post-fusion and for some of its variants are given in Table 1 In this section we compare the experimentally reported ability of a mutation to impact 3-dimensional rearrangement and the local topological free energy at that site for SARS and SARS-CoV-2 known mutations. Our results are shown in Tables 2 and 3 in SI. In the following all high LTE conformations are in Writhe, unless stated otherwise.Overall, we find that 75% of the mutations which are known experimentally to change the 3-dimensional properties of the spike protein are at residues in high local topological free energy conformations. The effect on protein conformation of the new mutants that have naturally arisen is to our knowledge undetermined. We find that only 42% of those natural mutants occurred at residues in high local topological free energy conformations. However, we note that the only one of the natural occurring mutants for which we have a crystal structure is G614. We found that the residue 614 was in a high LTE in Torsion conformation in D614,only in the open state, while it is found in a high LTE in Torsion conformation in the closed mutant G614.More precisely, mutations at SARS residues K968 and V969 (known as 2P a double proline mutation) caused disruption of conformational changes upon binding [33] . We find both residues in high local topological free energy conformations.The cleavage site of SARS-CoV-2, residue A688, which has been identified as important in viral rearrangement [27] , is in a high local topological free energy conformation. The residue 614 where the G614 natural mutation occurred is in a high local topological free energy conformation in Torsion for D614 and G614 [14] . Also, residue 985 which is involved in a stabilizing mutation, is in a high local topological free energy conformation [37] . In [28] 43 substitutions where studied. The most efficient was the HexaPro variant (involves 6 mutations), which stabilized the pre-fusion structure and produced high yield [28] . We find two out of the six mutations composing HexaPro (F817P, A892P, A899P, A942P, K986P, V987P) to be in a high local topological free energy conformation before the mutation and none to be in a high local topological free energy conformation after the mutation.In [26] , using a different method, specific sites for mutation that would change global conformation were identified. These were a double cysteine mutant, S383C D985C (RBD to S2 double mutant (rS2d)), a triple mutant, D398L S514L E516L (RBD to NTD (triple mutant (rNt)), a double mutant, N866I A570L (subdomain 1 to S2 double mutant (u1S2d)), a quadruple mutant, A570L T572I F855Y N856I (subdomain 1 to S2 quadruple mutant (u1S2q)) and finally, a double cysteine mutant, G669C and T866C, to link SD2 to S2 (subdomain 2 to S2 double mutant (u2S2d)). We found that out of these 5 mutants, 4 contained residues in high local topological free energy conformations. Moreover, one of the most efficient mutations contained 2 residues in a high local topological free energy conformation.In [32] , a combination of mutations were examined. Categorized by location the mutations included N532P, T572I, D614N, D614G of SD1, and A942P, T941G, T941P, S943G, A944P, A944G , and A892P, F888 and G880C, S884C and A893C, and K986P and V987P of the C-terminus of HR1 [32] . We find residues 572, 614, 942, 943, 944, 884, 986, 987 are in high local topological free energy conformations (884 in Torsion). A892P was reported to increase closed trimers while A942 decreased closed trimers. The double proline mutation (2P) at K986P and V987P stabilized the pre-fusion structure. K986P was reported to have higher ACE2 binding affinity while D614N and T572I reported to have low binding affinity [32] .The top 10 naturally prevalent mutations of the SARS-CoV-2 S protein (the recently discovered UK and South African mutations [22, 57] ) are shown in Table 4 . These mutations are are believed to increase infectivity and transmission and the majority of them are located in S1 [61] . Table 4 . One of these residues, residue 570, is in a high local topological free energy conformation. The South African variant, involves N501Y, E484K, and K417N.We find none of these residues to be in high local topological free energy conformations before the mutation.We used the local topology/geometry of protein crystal structures alone to associate a local topological free energy to the protein backbone. We find that total local topological free energy decreases from pre-to post-fusion. In addition the total local topological free energy of the spike protein of SARS-CoV-2 pre-fusion decreases continuously in the steps leading to protein rearrangement, in agreement with a transition to an energetically more stable state. We found that the total local topological free energy of the G614 mutant was much higher than the D614 and HexaPro mutants. Experimental results have shown that the G614 mutant is more unstable compared to the D614 and HexaPro mutants. This finding further supports that the purely topological free energy can quantify protein stability. fusion in a fashion that plunges the FP into the host membrane. HR2, located at the tail of the protein, folds to bring the viral membrane to close proximity to the host membrane during fusion [30] .",USA,first author,2021-02-07,02
acc2fd04f9a6410f6ff662b0f26fe326c696e3f7,COVID-19 and Acute Pulmonary Embolism: A Case Series and Brief Review,"The SARS-CoV-2 virus, or COVID-19, is responsible for the current global pandemic and by June 2020 had infected over two million Americans and killed over 100,000 (1) . While most people infected with the virus experience only mild symptoms, approximately 10-15% develop significant hypoxia with some progressing to acute respiratory distress syndrome (ARDS), shock, and multi-organ failure (2) .Accumulating data suggests that COVID-19 is associated with an increased risk of thrombotic events including pulmonary embolism (3) . Retrospective studies of patients with severe SARS-CoV-2 infections identified rates of VTE much higher than that of average ICU patients, (4, 5) even in populations of patients with high rates of therapeutic anticoagulation use. Markers of activity in the fibrinolytic pathway --such as d-dimer --have reliably correlated with more severe disease from COIVD-19, (6, 7) and in those cases prophylactic heparin has demonstrated a mortality benefit (8) suggesting thrombosis and venothromboembolism may contribute significantly to poor outcomes.We present here three cases of pulmonary embolism (PE) accompanying COVID-19 infection with disparate presentations. The cases demonstrate a spectrum of disease, and we hope illustrate the need to maintain a high index of suspicion for PE in patients with COVID-19 and unexplained or worsening hypoxia or dead space ventilation, and also prompt clinicians to consider occult COVID-19 infection in patients presenting with PE whose signs or symptoms are not fully explained by thrombosis.A 38-year-old man with no significant past medical history and a recent outpatient diagnosis of COVID-19 infection was brought to the emergency department after a syncopal episode at work. He had tested positive for COVID-19 infection by polymerase chain reaction test two weeks prior to presentation. Over the week prior to presentation, he developed a gradually worsening cough, shortness of breath, decreased appetite, fatigue, and diffuse muscle aches.At presentation, he appeared ill, restless and diaphoretic with an increased work of breathing. His respiratory rate was 40/min, oxygen saturation 95% on a100% non-rebreather, and he was hypotensive with a systolic blood pressure of 78mmHg. He was initially stabilized on high flow NC and IV fluid resuscitation. Labs were notable for an elevated white count, elevated lactate 6.0 mmol/L, serum creatinine 1.5 mg/dl, CRP 2.80mg/dl, LDH 312 IU/L, D-dimer >69,000 ng/mL, and reduced fibrinogen level of 38 mg/dl. Chest x-ray demonstrated mild bilateral lower lobe opacities and he was admitted to the ICU with the diagnosis of COVID-19 related acute respiratory failure.Because it was felt that his chest x-ray findings did not fully explain his hypoxia or respiratory distress, a CT chest with contrast was performed. The CT scan revealed bilateral pulmonary embolism within the main and lobar branches with right associated heart strain, as well as a few peripheral ground glass and consolidative opacities consistent with typical findings of COVID-19 pneumonia (FIGURE 1). 100 mg of tissue plasminogen activator (tPA) was administered in the ER with rapid improvement in hemodynamics and respiratory parameters.Upon arrival to the ICU, his oxygen saturation and blood pressures had normalized. He was started on an intravenous heparin infusion and transitioned to maintenance anticoagulation with apixaban for three months. He was discharged home on hospital day 7 with clinical improvement confirmed during a subsequent outpatient telehealth visit.A 50-year-old man with no significant past medical history was admitted to the hospital for acute hypoxic respiratory failure due to COVID-19 pneumonia. He initially presented with fevers, dyspnea, myalgias, anosmia, and dysgeusia for 10 days. He was initially admitted to a telemetry floor but developed progressive hypoxia requiring ICU admission and mechanical ventilation. He was treated with hydroxychloroquine, tocilizumab, proning, and antibiotics. He received prophylactic enoxaparin. After extubation on hospital day 9, he experienced an acute hypoxic event requiring initiation of high flow nasal cannula oxygen. CT angiography of the chest revealed an acute pulmonary embolus in the right main pulmonary artery extending into RUL, RML, RLL, and LUL branches (FIGURE 2) . He was hemodynamically stable and transthoracic echocardiogram revealed no evidence of right heart strain. Labs at the time of PE diagnosis were significant for markedly elevated D-dimer to 45,669 ng/mL and persistently elevated inflammatory markers including serum CRP, ferritin, and LDH. He was treated with therapeutic anticoagulation (heparin and then apixaban) with improvement, and he was discharged home on hospital day 20.A 57-year-old man with a past medical history of stage IV lung cancer was admitted with acute hypoxic respiratory failure. He was tachycardic to 110s beats/min and hypoxic with oxygen saturation of 88% on room air on presentation. Labs were notable for WBC 12,000 cells/µL without lymphopenia (absolute lymphocyte count 2740 cells/µL), elevated BNP to 8591 pg/mL, elevated troponin to 0.37 ng/mL (ULN 0.07). Additional labs were notable for a CRP 4.9 mg/dL, LDH 418 IU/L, D-dimer 788 ng/mL, Ferritin 290ng/mL, and procalcitonin 0.17ng/mL. Despite these therapies, he continued to decline clinically with escalating oxygen requirement and worsening pulmonary infiltrates. Given his multiple comorbidities, underlying metastatic disease and poor functional status, the decision was made to transition to inpatient hospice.The above cases demonstrate a variety of presentations COVID-19 and acute PE -from submassive to massive, and from early in the course of infection to later. Observational studies in COVID-19 patients have reported exceptionally high rates of venous thrombosis and thromboembolism with reported rates of symptomatic venous thromboembolism as high as 25% (4, 5, 9) . And Bompard reported an incidence of pulmonary embolism specifically of 24% (10) .Several studies have also demonstrated a connection between clot turnover and the severity of COVID-19 infection. In the first large publication of patients with COVID-19, measures of clot degradation were found to be elevated in hospitalized patients along with other inflammatory cytokines (6) . Patients with severely elevated levels of these markers had a worse prognosis, and there are reports that for patients with severe COVID-19 disease preemptive therapeutic anticoagulation reduced mortality (8, 11) .Several mechanisms have been offered to explain COVID-19 related system clotting problems. SARS-CoV-2 virus infects vascular endothelial cells via ACE2 receptors on their surface and may cause endothelial cell damage, vasculitis with monocyte and lymphocytic infiltrate, and platelet activation and aggregation. An autopsy series of four patients who died of SARS-CoV-2 (12) revealed thrombosed small vessels in the lungs and significant associated hemorrhage. The authors speculated on a role for thrombotic microangiopathy -a platelet-rich clot formation with fibrin deposition within these small vessels -as a significant contributor to their death.Yet it is not completely clear to what degree COVID-19 exerts an excess risk to thrombosis when compared with other causes of critical illness. Venous thromboembolism is a well-known complication of critical illness in general as well as other viral pneumonias (13) . Additionally, large studies suggest that while the incidence of VTE in general ICU patients is about 2-6%, (14, 15) it can be much higher when there is routine testing on asymptomatic patients (16) or as high as 37% in the presence of severe sepsis and septic shock (17). Additionally, severely ill hospitalized patients with COVID-19 have many of the traditional risk factors for development of acute VTE, including older age, immobility, indwelling central venous catheters, and a need for prolonged mechanical ventilation (18) .In conclusion, we present three cases of COVID-19 pneumonia complicated by clinically significant pulmonary embolism. Current available anecdotal and larger observational studies suggest that COVID-19 may independently increase the risk for acute VTE, and therefore diagnosis of PE should be considered early in appropriate patients. Maintaining a high suspicion for venous thromboembolic disease in COVID-19 patients --particularly those with critical illness, unexplained hypoxemia or shock, or rapid clinical deterioration -is advisable. Empiric or preemptive therapeutic anticoagulation may have a role in some severely ill patients with COVID-19, but more study is needed before any recommendations can be made.",United States,abstract,2021-02-10,02
29aa93db7676ba5b18d769b5af8e527d25a30ea7,Antibody responses boosted in seropositive healthcare workers after single dose of SARS-CoV-2 mRNA vaccine,"Here we determined antibody levels at baseline and 3 weeks after the first vaccine dose of the Pfizer BNT162b2 SARS-CoV-2 mRNA vaccine in healthcare workers with laboratory confirmed SARS-CoV-2 infection 30-60 days prior to vaccine (COVID19+; N=36) or workers without history of infection (COVID19-;N=152). Using a multiplex bead binding assay (Millipore #HC19SERG1-85K) that measures IgG levels against SARS-CoV-2 spike protein subunits S1, S2, Receptor Binding Domain (RBD) and the nucleocapsid protein (NP), we found that after the 1 st vaccine dose, both COVID19-and COVID19+ individuals antibody titers were enhanced to all proteins with the exception of NP which is not a vaccine antigen (P<0.0001, Wilcoxon-Mann-Whitney; Figure 1A ). At baseline, we observed 6 individuals that had antibody levels that matched COVID-19 seropositive status and may have had undiagnosed infection. Namely, having MFI ≥1000 for the S1 protein. We separated these individuals from analysis (Undiagnosed) and found that they resembled the COVID19+ in the week 3 serology assays. After the first vaccine dose COVID19+ individuals had significantly higher antibody titers to the S1, S2 and RBD compared to COVID19-individuals (P<0.0001, All rights reserved. No reuse allowed without permission.Wilcoxon-Mann-Whitney). As a proxy for measuring virus neutralizing antibodies, we utilized an FDA approved in vitro assay that allows qualitative detection of SARS-CoV-2 neutralizing antibodies in the blood (Genscript, #L00847; Figure 1B ). We found that neutralizing antibodies were boosted for the COVID19+ individuals (median 48.6% blocking at baseline and median 96.3% blocking at week3; P<0.0001, Wilcoxon-Mann-Whitney). While COVID19-individuals neutralizing antibodies were also boosted after vaccination (median 8.9% blocking at baseline and median 59.5% blocking at week3) they were significantly lower than the COVID19+ individuals (P<0.0001, Wilcoxon-Mann-Whitney).These findings suggest that in individuals with recent SARS-CoV-2 infection or seropositive status elicit a more rapid booster antibody response to vaccination and provides a rationale for considering a single dose vaccine regimen in this population. The duration of antibody responses also will need further investigation.The vaccinee biospecimens were collected under a clinical study at Children's Mercy Kansas City and reviewed and approved by the Children's Mercy IRB (#00001670 and #00001317). All rights reserved. No reuse allowed without permission.",United States,abstract,2021-02-05,02
55fbcce774984370d4847be42de510a401928a4a,Journal Pre-proofs Administration of High Titer Convalescent Anti-SARS-CoV-2 Plasma: From Donor Selection to Monitoring Recipient Outcomes Administration of High Titer Convalescent Anti-SARS-CoV-2 Plasma: From Donor Selection to Monitoring Administration of High Titer Convalescent Anti-SARS-CoV-2 Plasma: From Donor Selection to Monitoring Recipient Outcomes,"The COVID-19 pandemic caused by the SARS-CoV-2 has posed a treatment challenge. The disease emerged in Wuhan, China in December 2019 and has since arrived in major cities in the United States. Early in the pandemic, New York City was particularly affected [1] . In the USA, there had been a disproportionate burden of illness and death affecting racial and ethnic minorities [1] .Plasma from individuals who recovered from illness has been used as treatment for infectious diseases since the 1890's [2] . During the 1918 Spanish flu pandemic, convalescent plasma was used to treat those with pneumonia [3, 4] . More recently, convalescent plasma was utilized with reported success in the management of MERS [5] , Ebola [6] , H5N1 [7] , H1N1 [8] , and SARS infections [9] . COVID-19 convalescent plasma (CP) is procured by plasmapheresis from donors who have recently recovered from COVID-19. CP contains specific antibodies that are expected to provide passive immunization to neutralize the pathogen [2] . Challenges to understanding the utility of this procedure include donor procurement, assessing an adequate antibody titer for infusion and selection of CP recipients.Several recent studies have shown a beneficial effect of administering CP to COVID-19 patients [10] [11] [12] [13] , though some studies have not [14, 15] . Differences in when in the course of the disease, CP was administered, and the strength and specificity of CP could account for different outcomes. We hypothesized, therefore, that timely administration of potent CP would provide a survival benefit for hospitalized COVID-19 patients.University Hospital of Brooklyn (UHB) was designated a COVID-19 only hospital on March 28, 2020 by the New York State Governor. Between March 13 and June 30, 765 COVID-19 positive patients were admitted and managed in the institution for moderate to severe symptoms. We describe our experience below in obtaining high titer CP from volunteer donors who had recovered from COVID-19 and the clinical course of 28 severely ill COVID-19 patients who were treated with high titer or low titer CP.This is a retrospective descriptive study on the experience of a CP donation and treatment program. One group, composed of 17 COVID -19 patients who did not receive CP transfusion as part of their management, was observed and compared with two CP recipient groups, one with high titer and one with low titer anti-SARS-CoV-2 IgG antibody as described below. The non-CP treated group had similar severity of illness as the CP treated patients. A cutoff for CP donation was selected based on the Mayo Clinic recommendation of 1:160 titer or greater where inhibition of neutralization decreased by 50%. The Mayo program did not give guidance for an ELISA titer. In preliminary studies, we found that 50% reduction in OD in ELISA assays typically was 1:256 (close to neutralizing titer of 1:160) when the end point titration was 1:1024.Announcements for donation of CP were accomplished by advertisement on the UHB website and e-mail. This led to word-of-mouth spread to external donors, increasing the interest of many.Volunteer donors were screened at UHB based on the following criteria: (1) self-reported recovery from a documented COVID-19 infection, (2) asymptomatic for at least 14 days, (3) negative SARS-CoV-2 RNA RT PCR assay (only for those asymptomatic for ≤ 28 days), (4) positive lateral flow test (POS++ or greater), (5) All the plasma/serum samples from NYBC units, potential UHB donors and recipients were tested with a lateral flow test kit (Singuway, Shenzhen City, China) that detects IgM and IgG antibodies against the SARS-CoV-2 S1 spike protein receptor binding domain (RBD), following manufacturer's protocol. In brief, one drop of plasma/serum was placed into the designated sample well followed by two drops of the kit's diluent. The result was observed after exactly 10 minutes and recorded photographically ( Figure 1 ). The presence of at a red line along the marked area (IgM and/or IgG) indicated a positive test. A line must be present in ""Control"" for the test to be valid. The intensity of the red line was used to stratify the strength of the antibody: a faintly visible red line signifies +/-and red lines of increasing intensity compared to the control line (POS+++) were scored as POS+, POS++ or POS+++.All recipients and donor plasma samples that tested positive by the lateral flow test were tested for levels of IgG antibody against the SARS-CoV-2 S1 spike protein RBD. Depending on the lateral flow result, assay controls and serum samples were diluted from 1:2 to 1:64 followed by 2-fold dilution out to 1:131072 and added to a 96-wells microtiter plate (Thermo Scientific Immulon, Waltham, MA, USA) that was coated with SARS-CoV-2 recombinant RBD (BEI Resources, Manassas, VA, USA). A secondary anti-human IgG (Fab specific) antibody labeled with horse radish peroxidase (Sigma-Aldrich, St. Louis, MO, USA), was added to each well to form a specific complex of antigen-antibody bound to the plate surface. The binding reaction was then enhanced visually with SIGMAFAST TM OPD (Sigma-Aldrich, St. Louis, MO, USA), and after application of the stop solution (3M Hydrochloric acid), the optical density was immediately measured at 490 nm. When the absorbance value was greater than the cut-off value (OD490=0.15), the specimens were reported as a positive result and the resulting titer was reported.SARS-CoV-2 detection in recipients and potential donors was performed in-house using the Cepheid Xpert® Xpress SARS-CoV-2 RT-PCR assay (Cepheid, Sunnyvale, CA) following manufacturer's protocol. Nasopharyngeal swab samples were collected from patients and volunteers, and the swab was placed into a tube containing 3 ml of viral transport medium. Using the pipette included in the Cepheid kit, 300 microliters of the nasopharyngeal swab sample was transferred into the Cepheid cartridge tube, which contains the reacting reagents. The cartridge was then closed with the lid and placed into the GeneXpert® System for 45 minutes. Results were interpreted as positive if at least one of the three targets (N2 gene, E gene, SPC gene) were detected, and negative if none of the targets was present.This treatment was performed at UHB between April 4, 2020 to June 26, 2020. The program ended because patients with severe symptoms were no longer seen in the hospital past this date.The Mayo Clinic protocol for Expanded Access to Convalescent Plasma for the Treatment of Patients with COVID-19 (unique protocol identification number: 20-003312) was utilized. The program received approval from the local institutional review board.The inclusion criteria for treatment with CP were: (1) at least 18 years of age, (2) had a diagnosis of SARS-CoV-2 infection laboratory confirmed by RT PCR assay, (3) admitted to UHB for the treatment of COVID-19 complications, (4) severe or life threatening COVID-19 or judged by the treating provider to be at high risk of progression to severe or life-threatening disease as judged by the need for supportive oxygen therapy, and (5) informed consent provided by the patient or healthcare proxy. There were no exclusion criteria. All patients were followed for 45 days after admission. Clinical chemistry and hematology parameters were monitored until either discharge or death.CP was transfused within 24 hours after thawing. Each CP unit, approximately 250 milliliters, was infused over one to two hours. Recipients were monitored every 15 minutes for signs of transfusion-related reactions and then followed post-transfusion for clinical course.A group of hospitalized critically ill patients who did not receive CP treatment was observed retrospectively and compared with CP recipients for outcomes. These patients, admitted from March 18 to May 1, 2020, were managed with similar COVID-19 therapeutic drugs as the CP recipients, except for the CP therapy itself. Mortality in the CP and control cohorts was described with the use of Kaplan-Meier analysis. A chi-square analysis or Fisher's exact test was used to assess for statistical difference between groups. Associations between cohort pretreatment characteristics, lab values, and mortality were evaluated with Cox proportional hazards regression. Mann-Whitney U test, and Kruskal-Wallis test where used to analyze continuous variables where appropriate. A two-sided p value of less than or equal to 0.05 was considered to indicate statistical significance and all values are shown without correction for multiple testing. The widths of the confidence intervals have not been adjusted for multiple comparisons; therefore, intervals should not be used to infer definite associations.The recruitment of patients for CP treatment was performed under registration with the Mayo Clinic Clinical Trial, Expanded Access to Convalescent Plasma for the Treatment of Patients with COVID-19 (ClinicalTrials.gov Identifier: NCT04338360). Prior authorization to publish was secured from the Mayo Clinic PI. The trial protocol was approved by the SUNY Downstate institutional review board. Informed consent was obtained from each patient prior to transfusion.A separate IRB application was approved for retrospective review of electronic medical records of COVID-19 patients.Between April 23, 2020 to June 26, 2020, UHB volunteers (n=171) were screened for possible donation. The process for evaluation of potential donors and initial screening results are shown in Figure for SARS-COV-2 RNA real-time reverse transcription polymerase chain reaction test (RT PCR), and 6 (3.5%) had a previous positive antibody test. All those who donated were at least 14 days without symptoms. The median period from date of last symptom to date of presentation at the donation clinic was 33 days (IQR 23 to 39.5 days).Thirty-one CP units were procured from NYBC. These units were collected from volunteers who were known to have SARS-CoV-2 infection (prior RT PCR positive test) but were not tested for antibody at NYBC. Subsequent lateral flow assays were performed at UHB on all these units and From April 4, 2020 to June 26, 2020, 28 severely ill COVID-19 patients (19 males and 9 females) received CP transfusion at UHB under the Mayo Clinic-led Expanded Access Program.The individual profiles of the 28 patients who received CP are shown in Supplementary Table 1 . Table 2 provides data on demographics and outcomes for the CP recipients and the non-CP group. Most recipients were African American (85.7%), 3.6% were Asian, 3.6% were Hispanicwhite. Two patients declined to identify their ethnicity. Most recipients were male (18/28, 64.3%) and between 50 to 70 years of age (13/28, 46.4%). The most common symptoms at disease onset were shortness of breath (71.4%), fever (50%) and cough (50%). Co-morbidities present in these patients were hypertension (60.7%), diabetes mellitus (37.0%), renal disease (28.6%), heart disease (21.4%), neurological disease (14.3%), lung disease (2.5%), cancer A group of 17 hospitalized critically ill COVID-19 patients who did not receive CP as part of their management was compared to the CP treated groups. These patients, admitted from March 18 to May 2, 2020, were selected based on similarity to the CP treatment groups on age and severity from about 600 admitted patients. We note that CP infusions occurred from April 2 to June 24, 2020. ""Severe"" COVID-19 respiratory symptoms was defined by deterioration of respiratory function requiring supplemental oxygen greater than 4 liters/minute to maintain oxygen saturation at >90%. The non-CP treated patients received similar COVID-19-related management as the treatment groups except for CP. The major reasons for not receiving CP include: (1) CP was not yet available for treatment, (2) consent was not given by the patient or their health proxy, and (3) the patient recovered or died before CP could be administered. The mortality of the high titer group was lower than that of the non-CP cohort (36.8% and 52.9%, respectively), while the mortality of the low titer group (77.8%) was higher than that of the non-CP and the high titer cohorts. Figure 6 shows a Kaplan-Meier 45-day survival plot for the three cohorts. Patients transfused with high titer CP (>1:1024) had better survival than the cohort the received low titer CP (</=1:1024) (logrank p = 0.079, NS). Factors other than CP treatment may have also affected the observed outcome. For example, the period in which low titer and high titer CP was administered differed by 5 weeks.The low titer recipients received CP earlier in the pandemic as shown in Figure 6 . Additionally, the interval between admission to the hospital and CP treatment decreased so that many patients received high titer CP sooner in the course of their disease (Figure 7) . Figure S2) . The median pre-transfusion antibody titer was 1:4096. Serial IgG titers did not differ significantly between those who received high and low IgG titer CP. A small increase in IgG titers was observed between day three and day seven of treatment.Three patients had reported adverse events after transfusion with CP (11%), which were all deemed unrelated to the transfusion. The adverse events noted were atrial fibrillation with rapid ventricular response one day after transfusion, progression of lung disease requiring intubation one day after transfusion and arterial oxygen desaturation to 85% six hours after transfusion.Hospitalized COVID-19 patients who received high ELISA IgG titer CP (>1:1024) had better survival than patients receiving low titer CP ( 1:1024). Although this finding did not reach statistical significance, a clear trend was observed. Failure to achieve statistical significance may be due to small sample size. Indeed, two larger studies concluded that there was a survival benefit for CP recipients [11, 13] . A recent study found significantly lower mortality rates among recipients that received high titer IgG CP compared to low antibody level plasma units [12, 13] .Our results support the importance of transfusing COVID-19 patients with high titer anti-SARS-CoV-2 antibody in order to provide a survival benefit.However, in our experience such survival benefit may not be solely attributed to CP. At the beginning of the pandemic in March 2020, the medical and nursing staff at UHB were unfamiliar with the disease and most patients arrived in the hospital already in critical condition. Early patients were treated with hydroxychloroquine and azithromycin; both have been linked to poorer outcomes or without benefit [16] . During this period, the only CP units available to our patients were those coming from NYBC, which were later found to have low antibody titers.From the second half of April onwards, COVID-19 patients were given high antibody titer CP units from our screened donors. During this period, the treatment of COVID-19 was also improving as evidence became available on the benefit of dexamethasone, Remdesivir and CP as well. Furthermore, the interval between admission to the hospital and CP treatment decreased so that patients received CP sooner in the course of their disease. An additional factor is that the general public's overall awareness of COVID-19 improved, and patients began to seek medical attention earlier in the disease process. All these circumstances may have contributed to the improved survival of the high titer COVID-19 recipients. Indeed, multi-center randomized controlled trials found no benefit with the use of convalescent plasma in severe COVID-19 pneumonia when some of these factors were controlled [14, 15] . However, in the latter studies, most patients were treated with CP late in the course of their disease as compared to our study (>14 days vs 9 days, respectively).Screening and subsequent antibody titer determination of CP potency against the SARS-CoV-2 spike RBD is an essential step to ensure the efficacy of this treatment. Preliminary evidence with COVID-19 suggests that patients with mild symptoms may develop very low titer antibodies [17] [18] [19] . One study observed that 18% of convalescent COVID-19 donors had undetectable neutralizing titers in their plasma samples collected an average of 30 days after the onset of symptoms [20] . A larger study performed by NYBC showed that more than half of CP donors had low neutralizing titers and that there was a large variation in antibody titers among donors [21] . In our experience, using ELISA binding as a surrogate for neutralizing antibodies, among the 171 volunteers, only 55 (32.2%) had high levels of antibody. Out of 31 NYBC CP units, only 12 (38.7%) had titers of at least 1:1024. If CP is considered a valid therapeutic option, there is an existing challenge to screen CP donors for antibody titers, as evidence shows that most mild COVID-19 patients may not develop an adequate level of anti-SARS-CoV-2 antibodies to provide a therapeutic benefit to recipients.The lateral flow assay permitted us to quickly screen volunteers who potentially had high titers.Donors at UHB who tested POS++ with the lateral flow assay had antibody ELISA titers of >1:1024. Automated systems for screening are now available for larger testing capacity.It is important to note that the mortality of our patient population was greater than in previously published cohorts. This circumstance may be why a CP effect was seen despite the small numbers of patients. Joyner et al (2020) reported a seven-day mortality of only 15% among their CP recipients [13] . Liu et al (2020) reported mortality rates of 12.8% among plasma recipients and 24.4% among their matched control patients with a median follow up of 11 days for the plasma group and 9 days for the control group [11] . Our data shows a 44% death rate after a 45day follow-up. The prolonged follow-up period in our study may have revealed a higher mortality rate. However, baseline health status differences, as well as racial and genetic factors, need to be further investigated in a larger cohort. In contrast to previous studies, the patients included in our treatment program were predominantly Black. COVID-19 case surveillance reports showed higher prevalence among racial and ethnic minority group [22] . In a large cohort study in a health institution in Louisiana [23] , 76.9% of COVID-19 patients were Black, whereas Blacks comprise only 31% of the institution's population, and most deaths were also in Black patients (70.6%). CDC has emphasized that inequities in the social determinants of health, such as poverty and healthcare access, affecting minority groups are interrelated and influence a wide range of health and quality-of-life issues and outcomes.Greater mortality rate was also observed at UHB among female patients, with a hazard ratio three times higher than male patients. This result is in contrast with findings published in one Chinese study where it was concluded that male gender is a risk factor for worse outcome in 43 COVID-19 patients independent of age and susceptibility [24] . Racial differences and other Most patients who received high-titer CP units also received the plasma soon after admission. ",USA,first author,2021-02-16,02
a2e24ba7c4978bf062f622290abd061f2344e8af,Piglet immunization with a spike subunit vaccine enhances disease by porcine epidemic diarrhea virus,"Immunization with an insect cell lysate/baculovirus mixture containing recombinant porcine epidemic diarrhea virus (PEDV) spike protein induced high levels of neutralizing antibodies in both mice and piglets. However, immunization of piglets with this vaccine resulted in enhancement of disease symptoms and virus replication in vaccine recipients exposed to PEDV challenge. Thus, these observations demonstrate a previously unrecognized challenge of PEDV vaccine research, which has important implications for coronavirus vaccine development.npj Vaccines (2021) 6:22 ; https://doi.org/10.1038/s41541-021-00283-x Porcine epidemic diarrhea virus (PEDV), an alphacoronavirus, was first identified in the U.S. in May 2013 from diseased pigs experiencing explosive epidemics of diarrhea and vomiting 1, 2 . The virus rapidly spread to most swine-producing states, causing a loss of~7 million pigs 3 .Here, we used the standard Bac-to-Bac Baculovirus expression system to produce a recombinant vaccine containing the spike protein of PEDV, designated hereafter Bac-PEDV-S. Similarly, we generated recombinant baculoviruses expressing Ferritin, designated Bac-Ferritin that served as a control. SDS-PAGE with Coomassie-staining and Western-blot assay involving anti-PEDV spike protein antibody identified a predominant protein band in infected Sf9 cells that migrated as expected for a full-length PEDV spike protein ( Fig. 1a-b) . Bac-PEDV-S, Bac-Ferritin, inactivated PEDV vaccines and PBS formulated with adjuvant MONTANIDE ISA 50-V2, which were then administered intramuscularly into four groups of 7-week-old BALB/c mice, respectively. Serum samples collected from mice two weeks after the second vaccination were analyzed to determine the immunogenicity of Bac-PEDV-S and designated controls. The standard fluorescent focus neutralization (FFN) assay 4 was used to measure the titers of virus-neutralizing antibodies in vaccinated animals. Bac-PEDV-S vaccine elicited the mean FFN titer of about 130, which was significantly higher (p < 0.01) than that observed in the Bac-Ferritin group (no FFN antibodies detected) (Fig. 1c) . The inactivated PEDV vaccine-elicited mean FFN titers of about 50. There were no detectable FFN antibodies in the mock control group (Fig. 1c) .Next, we examined the immunogenicity of the Bac-PEDV-S vaccine in piglets. Analyses of vaccine-induced neutralizing antibody titers in the pre-challenge sera of the vaccinated piglets showed that Bac-PEDV-S vaccinated animals achieved significantly higher levels of virus-neutralizing antibodies when compared to animals in the Bac-Ferritin group (p < 0.0001) (Fig. 1d) . Specifically, all seven pigs receiving the Bac-PEDV-S vaccine developed moderate neutralizing antibody titers ranging from 40 to 160 with a mean FFN antibody titer of 110. Neither Bac-Ferritin nor mock control elicited any positive virus-neutralizing antibodies in vaccinated piglets. 2/8 animals in the whole-virus inactivated group possessed positive neutralizing antibody titers (40 and 80 respectively) (Fig. 1d) .Despite stimulating high-titer neutralizing antibodies, the Bac-PEDV-S vaccine group exhibited more severe (p = 0.09) diarrhea in the majority of vaccinated animals than the Bac-Ferritin group during the observation period after the challenge. Specifically, 3/7 of the vaccinated animals developed moderate to severe diarrhea as early as 2-day post-challenge (dpc) and two animals in this group showed minimal to moderate diarrhea even at 7 dpc (Figs. 2a, c). At 4 dpc, 6/7 vaccinated animals experienced varying levels of diarrhea (diarrhea scores ≥ 1), while only 3/8 animals in the Bac-Ferritin group experienced diarrhea (Fig. 2b) . Despite one animal showing diarrhea at 2 dpc in the Bac-Ferritin group (Fig.  2a) , no animal showed diarrhea and disease at 7 dpc (Fig. 2c) . Moreover, measurements of relative viral loads in fecal samples by RT-qPCR indicated that animals in the Bac-PEDV-S group shed significantly higher levels of the virus than those in the Bac-Ferritin group (p < 0.05) (Fig. 2d) .We also employed a sample pooling/RT-qPCR testing strategy to investigate the fecal virus shedding. The results indicated that the Bac-PEDV-S vaccine enhanced viral shedding especially at 2 and 4 dpc, with elevated levels of fecal virus shedding (i.e., relative viral loads: 2.47 × 10 3 and 6.29 × 10 3 TCID 50 /ml, respectively), which was in contrast to relative viral loads (9.86 × 10 2 and 5.11 × 10 2 TCID 50 /ml) for the Bac-Ferritin group at these two timepoints, respectively (Fig. 2e) . Notably, there was a significantly lower (p < 0.001) averaged body weight gain (i.e.,~125% of the baseline weight prior to virus challenge) in Bac-PEDV-S vaccine group compared to the Bac-Ferritin group (i.e.,~160% of the baseline weight) during the 11-day observation period after virus challenge (Fig. 2f ). Note the unvaccinated and virus challenge group involving four piglets showed characteristics including diarrhea scores, relative fecal virus shedding, the gain of body weight similar to those exhibited in Bac-Ferritin group ( Fig. 2a-f ). Taken together, these data indicated that Bac-PEDV-S vaccination resulted in a marked enhancement of virus replication and To further analyze the associations between the neutralizing antibody titers, viral shedding, and clinical signs, we plotted them on individual levels ( Fig. 2g-j) . Specifically, 6/7 animals vaccinated with the Bac-PEDV-S shed high levels of virus (>10 3 TCID 50 /ml) and/or experienced diarrhea (diarrhea scores ≥ 1), in spite of the presence of neutralizing antibodies (FFN titers ≥ 40). Nevertheless, only 2/4 animals in the unvaccinated and challenge group, 4/8 animals in the Bac-Ferritin vaccine group and 3/7 animals in the inactivated PEDV vaccine group showed relative viral shedding titers higher than 10 3 TCID 50 /ml and/or experienced diarrhea (diarrhea scores ≥ 1). In addition, 2/3 animals showing diarrhea scores ≥ 1 and relative viral shedding titers ≥ 10 3 TCID 50 /ml in the inactivated PEDV vaccine group also had FFN titers ≥ 40. Therefore, we concluded that the neutralizing antibody titers against PEDV were not absolutely associated or shown to be a correlate of protection as demonstrated in this study.The mechanisms leading to the observed vaccine-induced enhancement of PEDV replication and disease are unknown, however, our observation appears to continue a theme of vaccine-related or antibody-dependent enhancement of infection demonstrated by previous studies, which includes the coronaviruses that cause infectious peritonitis in felines or severe acute respiratory syndrome in humans [5] [6] [7] . In light of the overall high levels of PEDVneutralizing antibody responses elicited by the Bac-PEDV-S vaccine ( Fig. 1c-d) , it is possible that the observed enhancement of the disease can be attributed to the PEDV spike-specific nonneutralizing antibody response. Considering that the immunogen used in this study was a mixture of insect cell lysate and baculovirus that expressed the PEDV spike proteins, our vaccine preparation likely contained both pre-fusion and post-fusion forms of the PEDV spike. Numerous studies on human coronaviruses including the Middle East respiratory syndrome coronavirus (MERS-CoV) and the severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) have demonstrated that antibodies targeting the pre-fusion form, not post-fusion form, of the spike protein neutralize virus infection [8] [9] [10] . And therefore, we speculate that non-neutralizing antibodies generated in piglets against the post-fusion of PEDV spike protein present in our vaccine may play an important role in the enhancement of clinical diarrhea and virus replication observed in our study, which warrants further investigation. Regardless of the mechanism, this study highlights a previously unrecognized challenge in utilizing the baculovirusexpressed recombinant spike protein vaccine to control PEDV infection of pigs, which has important implications for general coronavirus vaccine development in humans and animals.Vero-76 cells (ATCC CRL-1587) were maintained in Dulbecco's modified Eagle's medium (DMEM) containing 10% fetal bovine serum (FBS) at 37°C with 5% CO 2 . The Spodoptera frugiperda Sf9 insect cells were purchased from Thermo Fisher Scientific and cultured in the serum-free SF900 II medium (Gibco) in suspension. The PEDV Colorado (PEDV-CO) strain (GenBank: KF272920.1) obtained from the South Dakota Animal Disease Research and Diagnostic Laboratory (ADRDL) was propagated in Vero cells.The Ferritin gene and the coding sequence of a synthetic, codonoptimized full-length spike gene of PEDV-CO strain were cloned into the pFHMSP-LIC-C vector (Addgene Catalog# 26100), respectively, which were conducted by using an In-Fusion HD Cloning Kit (Clontech) according to the manufacturer's instructions. The resultant plasmids were then transformed into DH10Bac E. coli cells (Thermo Fisher Scientific) carrying a baculovirus shuttle vector (bacmid) and a helper plasmid to generate recombinant bacmids. The colonies containing recombinant bacmids with target genes were screened and further validated by PCR and DNA sequencing. Purified recombinant bacmid DNAs were transfected into Sf9 Fig. 2 Bac-PEDV-S vaccine group exhibited enhanced clinical symptoms and virus replication. a-c Fecal consistency was scored at indicated time points for each group. d, e PEDV shedding in feces was tested by RT-qPCR and reported as the relative viral loads determined by the standard curve. f The averaged body weight gain of piglets on indicated days post-challenge in each group was calculated by comparison with body weight of animals on the day of the challenge. g-j The neutralizing antibody titers, relative viral loads, and diarrhea scores were plotted together for individual piglets in different vaccination groups. The meaning of error bars and marked signs were described in the ""Methods"" section. cells by Cellfectin™ II (Gibco) to generate recombinant baculoviruses, Bac-Ferritin, and Bac-PEDV-S. The virus stocks with high titers were prepared and used to produce the recombinant protein vaccine of interest.Sf9 cells were infected with recombinant baculoviruses at a multiplicity of infection (MOI) of 2. The supernatants were collected, and the cells were lysed. The expression of the PEDV S protein was confirmed by SDS-PAGE with coomassie blue staining and Western-blotting using anti-PEDV S monoclonal antibody (ADRDL). All blots or gels derived from the same experiment and were processed in parallel. Virus neutralization antibody responses in immunized pigs were measured by using the FFN assay established and performed by the South Dakota ADRDL 4 . This method has been extensively used in the field. Heat inactivated serum samples were two-fold serially diluted in MEM supplemented with 1.5 μg/ml TPCK-treated trypsin and then incubated with 100 foci forming units/100 μl of cell culture adapted PEDV-CO stock at 37°C for 1 h. After 1 h, the virus-serum mixture was added to Vero cell monolayers and incubated at 37°C for 2 h, followed by washing with MEM supplemented with 1.5 μg/ml TPCK-treated trypsin. The plates were again incubated for an additional 20-24 h and then fixed with 80% acetone, followed by staining with FITC conjugated mAb against PEDV nucleoprotein (NP) to visualize the infected cells. The highest dilution of the sera showing ≥90% reduction in fluorescent foci compared to negative controls will be the endpoint neutralization titer. Serum samples with a FFN titer <40 were scored negative.Twenty-four, 6-week-old female BALB/c mice (Jackson Laboratories) were randomly divided into four groups. The mice were given one-week acclimatization before vaccinating with 200 µl of adjuvanted Bac-Ferritin, Bac-PEDV-S, and inactivated PEDV vaccines by intramuscular (IM) route, respectively. The mock group was vaccinated IM with 200 µl of PBS. Booster vaccination with the same dose was administered IM to all groups at 14 days post-vaccination (dpv). Peripheral blood samples were collected from the facial vein at 0 and 14 dpv to evaluate the serum antibody titers. At 28 dpv, all the animals were euthanized by CO 2 inhalation and blood collected. The immune efficacy of the vaccines was evaluated by estimating the neutralization antibody titers in the sera by FFN assay as described previously 4 . The mice study was approved by the Institutional Animal Care and Use Committee (IACUC) of SDSU (IACUC approval no. 18-052A). The authors have complied with all relevant ethical regulations for animal testing and research.We examined the immunogenicity and protective efficacy of the recombinant Bac-PEDV-S vaccine in pigs. Control groups in this study included Bac-Ferritin, inactivated PEDV, and mock immunization (PBS) groups (with and without virus challenge). This study was approved by the IACUC of SDSU (IACUC approval no. 18-057A). The participants have complied with all relevant ethical regulations for animal testing and research. Neonatal piglets farrowed from PEDV seronegative sows were acquired from Midwest Research Swine. Blood samples were collected from the piglets to confirm the seronegative status before vaccination. The immunogenicity and protective efficacy of 2 ml of Bac-PEDV-S (n = 7) and inactivated PEDV (n = 8) vaccines, were compared to the Bac-Ferritin (n = 8) and mock (n = 8) groups. All the piglets were vaccinated with two doses at two-weeks intervals intramuscularly. At 5 weeks of age, the piglets in all vaccination groups as well as in one of the mock immunization (PBS) groups were challenged orally with 2 ml of 2 × 10 5 TCID 50 /ml of PEDV-CO viruses. The animals were monitored post-infection for clinical symptoms such as diarrhea, vomiting, anorexia, body weight loss, and lethargy. Fecal consistency scoring, body weight measurement, and rectal swab collection were conducted on days 0, 2, 4, 7, and 10 post-challenge (dpc). All the animals were euthanized on 10 dpc. The protective efficacy of the vaccine was evaluated by estimating the neutralization antibody titers in the sera by FFN 4 .Fecal samples, collected from piglets on 0, 2, 4, 7, and 10 dpc, were pooled together from each group at the indicated time points. The samples collected from piglets on 4 dpc were also tested individually. To make a standard curve, the PEDV-CO virus (3.548 × 10 5 TCID 50 /ml) was prepared by 10-fold serial dilutions from 10 1 to 10 6 . Viral RNAs were extracted from these samples and diluted virus standard samples using the MagMAX Viral RNA/DNA Isolation Kit (Life Technologies, Carlsbad, CA). ADRDL performed RT-qPCR assays for these samples according to the manufacturer's instructions (EZ-PED/TGE/PDCoV MPX 1.0, Tetracore, Rockville, MD). The relative viral loads in feces were determined by plotting their Ct values in the contact of the standard curve. The cut-off Ct value of the RT-qPCR was 38.The number of animals per group used here is based on the power analysis of the previous results with our vaccine study, which reached statistical power >0.8 at a p-value of 0.05. Significant differences in the means of anti-PEDV FFN titers between the Bac-Ferritin and Bac-PEDV-S groups were determined by the student t-tests in GraphPad Prism 8.0. The significant differences in diarrhea scores, relative viral loads, and percentage of body weight change between different groups were determined by the one-way ANOVA and Dunnett's multiple comparisons test in GraphPad Prism 8.0. Values of p < 0.05 were considered significant (*p < 0.05; **p < 0.01; ***p < 0.001; ****p < 0.0001). Values of p < 0.1 were also marked in figures. In Fig. 1 , the dotted line indicated the cutoff FFN antibody value (serum samples with FFN titer ≥ 40 counted as positive). An outlier (#) marked in Fig. 1c was not included in the statistics test. In Fig. 2 , dotted lines with a black arrowhead indicated the nondetectable level of PEDV in fecal samples; dotted lines at y-axis value across 40 indicated that a FFN titer ≥ 40 was counted as positive; dotted lines at x-axis value across 3 indicated high levels of relative viral loads (10 3 TCID 50 /ml) in fecal samples. Data (Figs. 1c-d, 2a -c, f) on the y-axis represent the mean values ± SEM and error bars indicate SEM. Data (Fig. 2d) on the y-axis represent the geometric mean with geometric standard deviation (SD) and error bars indicate geometric SD.Further information on research design is available in the Nature Research Reporting Summary linked to this article.The raw data used for the preparation of figures of this study are available from the corresponding author upon reasonable request.",USA,first author,2021-02-01,02
83abdc1174a3e7266894133819d97ce8457470d9,,"In late 2019, a novel coronavirus SARS-CoV-2 (COVID- 19) appeared in Wuhan, China, and spread unchecked across the world's population. With 30 million infections already documented worldwide and the potential to infect over a 100 million people, the long-term consequences of COVID-19 infections will be a major health care focus for years after the contagion subsides. The common complications are expected to be accompanied by familiar patterns of pain and aversive sensations. Even the rarest of post-COVID-19 complications (occurring in less than 1/10,000 infected) will be present in tens of thousands of people. There may even be unique post-COVID-19 syndromes that have yet to be described.It seems inevitable that medical practitioners will have to manage a pandemic-sized burden of somatic and emotional aversity in the wake of COVID-19. To better navigate the looming health issues, it seems prudent to review the known presentations of COVID-19 and their expected complications, especially postviral fatiguing syndromes, whereas also considering how unique post-COVID-19 syndromes may emerge.Acute COVID-19 infections resemble other viral respiratory tract infections, presenting with fever, fatigue, dry cough, myalgias, and dyspnea. 20 Headaches, sore throat, rhinorrhea, gastrointestinal symptoms, conjunctivitis, and alterations in olfaction and gustation are also commonly reported presenting features. 26, 71 For many, COVID-19 infection will self-resolve with little impact on their long-term health. Others will have prolonged recoveries that relate to the tissues injured during their initial infection.COVID-19 penetrates human cells through its exquisite specificity to the angiotensin-converting enzyme-2 receptor. The angiotensinconverting enzyme-2 receptor is widely expressed in human tissue, most notably in lung alveolar cells, small intestine enterocytes, and the vascular endothelium. 41 The complications of COVID-19 are most often related to overexuberant immunological responses to the viral infection in the tissues or protective membranes of affected organs. The most severe damage seems to be a consequence of substantial monocyte and macrophage recruitment into affected tissues and their unchecked activation. 73 The consequences of this inflammatory response are different for each tissue impacted, ranging from acute respiratory distress syndrome and pleuritis in the lung, to myocarditis and pericarditis in the heart, to encephalitis and meningitis in the brain, and creating a hodge-podge of other problems such as conjunctivitis, pancreatitis, oral ulcers, and epididymitis. 37 Inflammatory manifestations may also be agespecific, as evidenced by Kawasaki disease reports in COVID-19infected children. 77 Visceral thrombosis represents a second mechanism in which COVID-19 can create complications. Microthrombi during COVID-19 infections have been documented to occur in nearly every organ. Dramatically elevated levels of D-dimer and fibrin degradation products are a hallmark of the coagulopathy. The innate immune activation noted above may have a central role in driving the expression of tissue factor, the initiating enzyme of the extrinsic coagulation pathway. 73 Other thrombophilic factors may include complement activation and direct infection of endothelial tissue. 74 The consequences of this coagulopathic response are different for each target organ, ranging from pulmonary embolism in the lung, myocardial infarction in the heart, stroke in the brain, and other injuries such as renal failure, avascular necrosis, acute limb and mesenteric ischemia, aortic thrombosis, testicular pain, and ovarian vein thrombosis. 53, 56, 60, 78, 81, 95 Of course, inflammation and thrombosis are not mutually exclusive and often both contribute, perhaps synergistically, to severe COVID-19 presentations. We anticipate that, for the most part, these organ-specific presentations will resolve as would be expected when they occur in other clinical settings. However, the novelty of COVID-19 suggests that there may be some surprises along the way. Below we review the known presentations of COVID-19 that may linger on to create persistent pain and discomfort. Estimates of symptom prevalence are provided in Table 1 :Pneumonia, pleurisy, chronic cough, and pulmonary emboli can lead to chronic pleuritic pain, shortness of breath, decreased exercise tolerance, and fatigue issues. 22 Acute respiratory distress syndrome itself leads to long-standing fatigue, with one study observing 436 of 659 patients reporting clinically substantial fatigue 1 year after recovery. 76 Myocardial injury and myocarditis can lead to chronic cardiac chest pain, exercise intolerance, and fatigue. As seen during prior coronavirus epidemics, COVID-19 infections can induce cardiac arrhythmias. Recurrent pericarditis is currently believed to be a consequence of viral infection leading to a cyclic or persistent autoinflammatory state and may be a sequelae of COVID-19 pericarditis. 17 Muscle pain, myalgia, and joint pain have been reported as a presenting feature in 35% to 50% of all cases. It is also a symptom that frequently persists after initial recovery. 59 Avascular necrosis has been reported to occur from COVID-19 infection and the corticosteroids used in treatment. 28 Currently, there does not seem to be evidence suggesting that COVID-19 causes an acute or subsequent inflammatory arthritis.Symptoms such as nausea, vomiting, diarrhea, loss of appetite, and abdominal pain are common presenting features, reported to occur in 1 of 5 of COVID-19 infections, with abdominal pain occurring 6.2% of the time, in a meta-analysis of 78 studies encompassing 12, 797 patients. 91 Whether these symptoms from acute infections will lead to persistent pain disorders and irritable bowel syndrome has not yet been reported. Acute abdominal presentations can cause or mimic inflammatory and thrombotic disorders, such as appendicitis, pancreatitis, cholecystitis, acute intestinal ischemia secondary to mesenteric artery thrombosis, and will create a chronic pain burden for survivors. 6,16,23Sore throat is common, occurring in 5% to 20% of infections and often persisting after other signs of infection have resolved. 21, 59, 89 Painful necrotic and aphthous-like ulcers have been reported and may contribute to alterations in taste and smell. 15 Whether these lesions may become a chronic, recurring issue has yet to be determined.Ocular symptoms range from eye pain, dryness, irritation, or a sensation of a foreign body in the eye. One report assessing ocular symptoms before and after infection noted 15 of 56 participants developed ocular symptoms during the course of COVID-19 infection with 11% indicating that these symptoms had an onset before fever and other respiratory symptoms. 46 Reports of COVID-19 infections leading to chronic sicca symptoms has not yet been reported.COVID-19 infection has been shown to trigger painful flares in sickle cell disease. 10 One study of 83 patients with sickle cell disease and acute COVID-19 noted vaso-occlusive crisis in 54% and acute chest syndrome with COVID-19 in 28%. 8 The rare relationship between acute COVID-19 infection and the development of pediatric inflammatory multisystemic syndrome, which is a variant of Kawasaki Disease, has been demonstrated, with 497% increase in number of cases reported in France during the first 4 months of the pandemic. 77 Other acute autoimmune manifestations have been reported even less frequently, including idiopathic thrombocytopenic purpura, Guillain-Barre syndrome (GBS), and autoimmune hemolytic anemia. 38 However, the development of other autoimmune diseases have not yet been reported.Coronaviruses are not currently recognized as viruses with oncogenic potential. 72 However, coronavirus infections in the society are ubiquitous and not characterized in the standard of practice health care. It is possible that COVID-19 may confer an increased risk of developing malignancy that can only be recognized over time with epidemiological surveillance. Even if COVID-19 is not directly oncogenic, it is possible that the inflammation it invokes may be. The long-term impact of pulmonary inflammation on cancer development remains an open question. 4 Abnormal neurological findings on examination themselves are a frequent presenting feature of COVID-19 infection. A case series of 58 patients admitted to the ICU indicated that 14% had neurological symptoms on admission, and 67% presented symptoms when sedation and neuromuscular blockade were withheld. Symptoms ranged from agitation, encephalopathy, as well as two-thirds displaying corticospinal tract findings such as enhanced deep tendon reflexes, ankle clonus, and bilateral extensor plantar reflexes. 43 Headache is a common presenting symptom, with a reported prevalence of 11% to 40%. 13, 14 These reports describe moderate to severe bilateral pressing or pulsing pain in the tempoparietal, periorbital, or bifrontal areas. Both sudden and gradual onset has been reported and are often resistant to traditional analgesics. Headaches affiliated with meningitis and encephalitis will likely be more severe and potentially affiliated with other focal neurologic symptoms based on inflamed areas. It can be expected that some individuals will develop chronic headaches or have previous headache disorders substantially aggravated from their infections. Likewise, neuropathic pain in the back and neck corresponding to the spinal nerves has been reported, which was not responsive to typical analgesics, but some relief was found with gabapentin. 3 More severe functional disability is expected for neurologic etiologies that bear thrombotic, demyelinating, inflammatory, and direct viral insult to the central nervous system. As with all things neurologic, the long-term morbidity will vary widely based on the etiology and precise location of the primary insult. Large vessel strokes related to COVID-19 infections are affecting a much younger population than typically have strokes. 67 These strokes will cause devastating long term effects, including deficits with motor and sensory function, cognition, pain, and bowel and bladder function. Likewise, demyelination of GBS has also been reported in COVID-19 patients, which can cause paraplegia, paresthesia, and further compromise the respiratory system by weakening respiratory muscles. 85, 92 Dysautonomia has been linked to GBS 88 and in critically ill COVID patients independent of GBS. 32 One of the most striking presentations of COVID-19 has been its ability to diminish and alter taste and smell. Although the anosmia typically resolves itself, there are already reports of people not recovering these senses. 30 The long-term consequences of the loss or distortion of smell and taste will have nutritional, safety, and psychological consequences.It is also possible that unexpected neurological issues may emerge from this targeted encephalitis. During the 1918 ""Spanish"" flu, a coepidemic of a suspected viral infection known as encephalitis lethargica created profound lethargy in the afflicted that resolved over weeks to months. Patients seemed to recover to normal health but developed an aggressive form of Parkinson's disease after a few years. 83 As anosmia frequently Table 1 Prevalence of COVID-19 symptoms.Symptom Estimated frequencyMyalgia and fatigue 35%-50% [31, 35] Fever 43%-90% [31, 23, 35] Pulmonary Cough 50%-82% [31, 23, 35] Dyspnea 29%-31% [31, 23] Up to 75% [23] Pulmonary emboli † [8] Cardiovascular Chest pain 22% [31] Cardiac arrhythmia 17% [31] Myocarditis 12% [35] Gastrointestinal Nausea and/or vomiting 9.0%-12% [31, 19] Diarrhea 5%-19% [31, 19, 35] Loss of appetite 22.3% [19] Abdominal pain 6.2%-10% [31, 19] Rhabdomyolysis † [35] Mesentery artery thrombosis, appendicitis, and pancreatitis † [20, 21, 22] Oropharynx Sore throat 5%-20% [31, 17, 23, 24] Aphthous-like ulcers † [25] Ocular symptoms Sore eyes, itching, foreign body sensation, tearing, redness, and/or dry eyes 27% [26] Hematologic Vaso-occlusive crisis and acute chest syndrome in sickle cell disease* † [27, 28] Autoimmune Pediatric inflammatory multisystem syndrome † [6] Neurological Altered mental status* 7.5%-31% [35, 45] With pervasive neurological involvement, alterations in the nervous system structure and function related to injury and healing will have neuropsychological consequences. COVID-19related psychosis has been reported, including structured delusions and pseudodementia. 52 The potential for subtle alterations in somatic, emotion, and behavioral neural circuitry may lead to persistent alterations in the psychological state. Survivors of the severe presentations of COVID-19 will also suffer the neuropsychological sequelae related to critical illness stressors, lengthy hospitalization, and intensive care interventions. Many of these individuals will suffer ongoing medical and psychological morbidity associated with their critical illness and its care, including posttraumatic stress disorder, obsessive compulsive disorder, and major depressive disorder. 86 The tissue-specific complications noted above ultimately may not be the most prevalent source of aversive morbidity from the COVID-19 pandemic. Postviral fatigue syndromes have been increasingly recognized within the medical community, with the term coming into use in the late 1980s. 7 Initial descriptions describe an aversive constellation of symptoms where the ""principle symptom is severe muscle fatiguability, but there may be a range of secondary symptoms, such as the aching of muscles, disequilibrium, and psychiatric manifestations."" 12 Cognitive alterations, unrefreshing sleep, and postexertional malaise are also common symptoms that have been additionally recognized. Prospective studies estimating the incidence of postviral fatigue syndromes range between 10% and 12% for a variety of infections, including viral meningitis, Epstein-Barr virus, and Ross River Virus. 44, 50 Even if COVID-19 has an incident rate that is one-tenth of these other viruses, it suggests that a million cases of post-COVID-19 fatigue syndrome may emerge from the pandemic.It is difficult to pin-point when medical science became aware that viral infections are temporally related to chronically fatiguing syndromes. The existence of pathogens smaller than bacteria was first described by Löffler and Frosh in 1898 using a Chamberland filter, but viruses would not be visualized until the invention of electron microscopy in 1931. It was recognized that filter-passing agents could cause chronic neurological complications as early as 1908 with Landsteiner and Popper's identification of poliovirus. However, there was little recognition at that time of a relationship of infections to a chronically fatiguing syndrome. Syndromes of pain and fatigue of that age, such as fibrositis and neurasthenia, were not generally considered linked to infections. The first to do this was Evans' 1934 description of chronic brucellosis. 33 She described a brucellosis-related syndrome that was typically diagnosed as neurasthenia, characterized by ""exhaustion, insomnia, irritability, and complaints of aches and pains for which no objective signs can be found.""Before that time, chronic fatiguing symptoms were not typically described as consequences of infectious epidemics. Today, it might be expected that the ""Spanish"" influenza pandemic of 1918 to 1919 would have been accompanied by a surge of postinfectious fatiguing symptoms. However, such an event is not reflected in the medical literature. It was not due to a lack of expert medical observational skills. Von Economo's descriptions of how a filter-passing agent caused ""the sleepy sickness"" and the postinfectious Parkinsonism that followed in encephalitis lethargica patients was exceptional contemporary work. 83 H1N1 influenza has been later shown capable of creating postviral fatiguing symptoms in modern reports. 66, 93 Why there is no obvious record of a ""post-Spanish flu syndrome"" may relate to several factors. In part, it may reflect the period's tendency to attribute somatic symptoms to psychiatric causation, perhaps as part of the ""psychoses of influenza"". 47 It may also reflect a generational stoicism and selective amnesia that led societies to put the consequences of the pandemic behind them swiftly, with such success that historians consider the 1918 influenza a ""forgotten"" event. 48 At the same time Evans' described chronic brucellosis, the first report of fatiguing symptoms occurring during acute epidemic was described by Gilliam. His 1934 description of ""atypical poliomyelitis"" at the Los Angeles County Hospital included rapid muscle weakness, vasomotor instability, clonic twitches and cramps, ataxia, severe pain aggravated by exercise, neck and back stiffness, menstrual disturbance, and dominant sensory involvement. 40 Similar symptoms emerged as part of other epidemic outbreaks, including 1948 Akureyri Disease, 1955 Royal Free Hospital benign myalgic encephalomyelitis, 1984 Incline Village Chronic Fatigue Syndrome, and 1985 Lyndonville Chronic Fatigue Syndrome among others. 1, 5, 455 As described by Ramsay, cases started with generalized respiratory, gastrointestinal, or vertiginous symptoms which evolved into chronic fatiguing symptoms. Lymphadenopathy was a notable feature of many, but not all patients during these epidemics. 82 These epidemics provoked scientific and societal interest in the concept of postviral syndromes. To date, no decisive evidence of an infective agent being the cause of these epidemics was ever demonstrated, creating controversy over the nature of these events. 31, 70, 97 In contradistinction, there is little controversy that Epstein-Barr Virus (EBV) can lead to postviral fatiguing symptoms. In its report on myalgic encephalomyelitis/chronic fatigue syndrome, the Institute of Medicine noted that EBV is the only virus consistently associated with the development of chronic fatiguing symptoms. 25 Mononucleosis typically presents with malaise, headache, and lowgrade fever that presage oropharyngeal inflammation, lymphadenopathy, and fevers. Prolonged recoveries after the resolution of viremia requiring months to a year are very common. The prevalence of prolonged symptoms after EBV ranges from 1.5% to 56% in the literature. 19 Epstein-Barr Virus infections have been temporally related to chronic fatiguing symptoms. 87 Several prospective studies have demonstrated that EBV infection can be a trigger postviral fatigue syndrome. 18, 34, 44, 98 There are some immunological differences noted in those who develop symptoms after infection. High titers of certain antibodies to EBV, including viral capsid antigen (VCA) IgG, persistent titers of VCA immunoglobulin M, or the persistence of early antigen IgG have been associated with the development of chronic fatiguing symptoms, whereas healthy individuals who were previously infected with EBV had only VCA IgG and nuclear antigen IgG antibodies. 54, 62, 64, 68, 84 Some studies, however, including a study of twins discordant for disease, 55 were unable to find this difference. 36, 42, 69, 90 Differential kinetics of anti-EBV antibody development and immune protein production has also been described. 18 Premorbid lifestyle factors have also been related to prolonged recoveries. 79 Unfortunately, the studies above provide little insight into the underlying biological mechanisms responsible for delayed EBV viral recovery.Today, it is generally accepted that a proportion of patients will develop prolonged symptoms after viral infections. Review of outcomes from prior coronavirus epidemics suggest that coronavirus infections are sufficient to cause a postviral syndrome. Studies of survivors of the 2003 severe acute respiratory syndrome (SARS) epidemic suggest that nonspecific pain, fatigue, and mood alterations in the absence of demonstrable pathology are the most common aversive outcome. A recent meta-analysis of 5 survivor studies describe mostly psychological issues in the wake of SARS, with substantial rates of posttraumatic stress disorder [23.3%-42%], depression [15.6%-40 .7%], and anxiety [15.2%-51 .5%] after follow-up periods between 12 and 48 months. 2 However, only 1 of the 5 studies queried fatigue and pain. Of 181SARS survivors followed over a mean of 41.3 months, 15.5% reported a somatic pain disorder. Of the 146 survivors completing fatigue instruments, 40.3% had persistent fatigue, and 27.1% met the modified CDC 1994 chronic fatigue syndrome criteria. Overall, SARS survivors scores on the SF-36 after 6 months were lower than both population norms and those with chronic conditions. Another small Canadian study of SARS and 2 small studies of Middle East respiratory syndrome survivors reported similar results. 9, 11, 58 Taken together, coronavirus epidemics demonstrate a temporal relationship to the development of postviral fatigue syndromes. However, it is important to recognize that these small studies all suffer from substantial ascertainment and attrition biases that make their epidemiological estimates unreliable.These observations of persistent aversity from other coronavirus epidemics suggests that similar issues will be observed in COVID-19 survivors, except in an exponentially larger scale. Six months into the pandemic, this may already be coming to pass. Numerous reports about COVID-19 ""long-haulers"" have been described in both medical journals and the lay press. 27, 75 Reports of nonlinear improvements with symptoms such as fatigue, headache, chest pain, musculoskeletal pain, shortness of breath, chronic cough, cognitive alterations, sleep disturbances, anxiety, exercise intolerance, and autonomic symptoms have been well described. 49, 65 A patient-led effort to describe long-haul symptoms identified 62 unique symptoms. 59 At least one case report of a presentation with lymphatic involvement resembling that seen in prior epidemic fatiguing syndromes has been published. 80 It seems obvious that the COVID-19 virus is sufficient to trigger a postviral syndrome. The descriptions to date resemble the range of historic postinfectious syndromes that currently do not have an organically demonstrable basis, providing a unique research opportunity to better understand the pathophysiology of postviral syndromes.The COVID-19 pandemic is also an unprecedented sociocultural event. COVID-19 has transformed how people consider their health, gather in groups, and navigate their daily lives and will impact the health of even those that were never infected. These times have created severe health, social, and financial uncertainties for many citizens of the United States. The 2003 SARS epidemic and the COVID-19 experience in China has been associated with moderate to severe anxiety, depression, and insomnia. Distress related to SARS in hospital workers was observed to persist for years for some, and COVID-related stress has led to recent prominent suicides. 57, 63, 96 Financial downturns, job loss, and increased parental stresses from school closures with teleworking have also been observed to increase stress, depression, anxiety, domestic violence, divorce, and problematic drug and alcohol use that can persist over years. 24, 35, 61 Social isolation and quarantine are factors that increase the risk of developing mental health disorders. 29, 39 These omnipresent stresses will have biological ramifications, leading to alterations of neuronal structure and function in all of us.The COVID-19 pandemic is certain to leave a substantial burden of health issues in its wake. The problems caused by direct tissue injury and the body's responses should be observable and are anticipated to follow typical clinical courses. For each of these clinical COVID-19 ""faces,"" there are pathways to the development of long-term pain and disability. The unprecedented sociocultural stresses of the pandemic will have an invisible, ubiquitous, and predictable impact on neurologic, endocrine, and immune functioning, even in people untouched by the virus. 51 We suspect the most complex problems will arise at the neuropsychiatric level, created from the interactions between the neuronal specificities of COVID-19, the functional architecture of the brain, the mechanisms of neuronal injury, healing, and plasticity, and how these neuronal mechanisms are influenced by the concomitant activation of biological stress mechanisms invoked by critical illness and sociocultural stressors. We anticipate that the most common sequelae to COVID-19 will be a postviral fatiguing syndrome and its persistent mix of somatic and psychiatric complaints in the absence of a clearly observable cause. We also suspect that COVID-19 may have a surprise or two in store, with unique clinical presentations and novel mechanisms of injury which are yet to clearly emerge.These predictable difficulties also represent a unique opportunity to start to unravel the physiology that underlie postviral syndromes, including how viruses may trigger cancers and neurological disease. This may be the first time in the human history where it is feasible to prospectively study the mechanistic changes that accompany the shift from a state of normal health to that of a postviral fatiguing syndrome. Insights gleaned from such studies of COVID 19 infection could provide new understandings to similar disorders, such as fibromyalgia, ME/CFS, and Gulf War Illness. A better mechanistic understanding of pain and fatiguing disorders as they occur in real time seems the most likely way to develop targeted interventions and providing hope to COVID-19 survivors for meaningful treatments and cures.The authors have no conflicts of interest to declare.",USA,first author,2021-02-16,02
2e806c70d63d8027d8434dc285d32378e786119a,Advancing Telemedicine Within Family Medicine's Core Values,"T he pandemic caused by COVID-19 has accelerated the application of telemedicine to promote physical distancing while continuing to provide medical care. 1 The changes seemed to have occurred overnight, but telemedicine has existed for many decades. 2 The gradual adoption of telemedicine is a result of a number of barriers. Reviews have reported challenges including limited exposure/knowledge of telemedicine, lack of devices, organizational readiness, motivation, incentives, unsuited services, and fit with workflows and systems. [3] [4] [5] Recent events required a rapid adoption of telemedicine but there remain concerns. A fundamental question that lingers is how will telemedicine impact the discipline of family medicine? We reflect upon our core values because they enable our discipline to adapt the technology to our values rather than allowing the technology to change our practice. 6 The 5 C's of Family MedicineThe core values of family medicine, articulated in the 5 C's of family medicine include: contextual care, continuity of care, access to care, comprehensive care, and care coordination. Here we outline how telemedicine can be deployed in a way that maintains these values ( Table 1) .Visits conducted through videoconferencing may decrease the ability of providers to provide contextual care if significant others who would normally accompany a patient are no longer included in visits. The relationship between patients and staff can also elicit important facts that might not arise in a virtual visit. When using telemedicine, we can encourage patients to include other important people in their life who themselves may find it difficult to travel to the clinic. We can also pay attention to visual clues that offer social and environmental context and increase the contextual care provided by the entire medical team.Virtual visits are often provided outside of the medical home, thereby disrupting continuity of care. It is critical that family medicine provides telemedicine options within the medical home. Providing a blend of in-person and telemedicine options will likely increase continuity.Widespread telemedicine adoption increased utilization in primary care among white patients while decreasing among black/African, Latinx, Asian/Pacific Islander patients. 7 Virtual visits also increase access for patients with physical disabilities or multiple social strains such as child-rearing, elder care, or unstable employment. This may be especially impactful for low-income patients for whom the cost of transportation and time away from work can be significant. However, we provide access to telemedicine outside of traditional office hours, increase education around telemedicine services, and ensure access to interpreter services.The current medical home model relies on workflows designed for in-person team-based care interactions for multiple important functions including nurse care management and integrated behavioral health. There are also services that patients need that simply cannot be done virtually (vaccinations, laboratories, procedures, physical examinations, etc.). These clinic workflows must be modified and will require asynchronous population health strategies.Telemedicine options such as e-visits, telephone visits, and video visits may improve care coordination by facilitating more closed loop effective communication between providers and patients. However, team-based care may be less effective with telemedicine encounters that occur just between provider and patient. In addition, team functioning may be inhibited as more staff work from home. We need to build and sustain healthy, relational, and high-functioning teams as the telemedicine reduces the amount of time that team members spend colocated, compounding the challenges of the clinicalburnout epidemic in the ''tail'' of the pandemic. 8Telemedicine can enhance our ability to provide equitable care, but programs must be developed to account for family medicine's core values. Health disparities are oftentimes magnified when new modalities of care are implemented. It is crucial that telemedicine programs be developed to maximize the potential equity gains and minimize harm. Family medicine is well poised to influence telemedicine in this arena.Convenience, quality, safety, and cost-effectiveness of health care 9 remain drivers of telemedicine adoption. A focus on the 5 C's framework may help us design systems that preserve our values, produce desirable clinical outcomes, and improve health equity.No competing financial interests exist.This effort was supported by the Oregon Health Sciences University Faculty Development Series. Care coordination Provider's role as an advocate with other systems on behalf of patient.Attend to shifting dynamics between clinic-based teams with remote work that could hamper care coordination. Build and maintain a relational culture. Telemedicine may increase provider's confidence and patient satisfaction as a result of closed-loop communication.With proper telemedicine processes and training, family medicine providers could use the 5 C's of family medicine.",USA,first author,2021-02-01,02
e9ef42b920112624b35ca2dcef6b9423b242cacb,Journal Pre-proof Can social media data be used to evaluate the risk of human interactions during the COVID-19 pandemic? Can social media data be used to evaluate the risk of human interactions during the COVID-19 pandemic?,"Coronavirus Disease 2019 (COVID-19) pandemic has resulted in 417k deaths in the U.S. as 22of January 22, 2021 [1] . Current evidence suggests that COVID-19 spreads mainly through 23 direct contact or in close proximity with the infected patients via respiratory droplets as 24 they cough, talk, or sneeze [2] . To prevent the spread of COVID-19, the U.S. government has 25 taken multiple measures, including implementing orders such as lockdown and social 26 distancing [3] . Social distancing is an intervention to reduce close interactions among 27 people, and it has been demonstrated as an effective way to reduce the transmission of 28 COVID-19 [4] . Evaluating the risk of close human interactions is critical for the U.S. 29 government agencies as it helps to understand the public compliance with these essential 30 measures and evaluate the effectiveness of these orders to reduce the spread of COVID-19. 31Researchers have observed the risk of human interactions based on questionnaire surveys 32 or mobile data. Questionnaire surveys investigated people's perceptions, behaviors, and 33 plans during the COVID-19 pandemic by asking the respondents whether they are self-34 quarantining, keeping social distancing, eating out, or visiting relatives and friends [5] . 35However, preparing the surveys and collecting the answers from the respondents are often 36 time-consuming [6] . Other researchers leveraged mobile location data to establish an 37 interactive monitoring system with advanced data processing techniques [7] , [8] . These 38 mobile data-based systems show the likelihood of viral transmission and provide tools for 39 tracking human interactions with quantitative parameters, such as social distancing indices. 40However, acquiring the mobile location data often relies on third-party institutions and 41 data distributors, which adds to the cost of implementation. 42However, there has been a lack of studies that applied social media data to assess the risk 43 of human interactions. On social media platforms, people express their opinions and 44 concerns about the COVID-19 government measures such as stay-at-home order, and these 45can be used to reveal as well as to predict the public reaction to the measures [9]- [11] . For 46 example, people who express their fear and anxiety about the pandemic may have a 47 them. Such risk perception shown on social media can reflect the behaviors of the 50 individuals. It has been indicated that the geographic regions with many social media users 51 who opposed the lockdown policy had a higher frequency of close human interactions, thus 52increasing the risk of viral transmission [12] . 53 provides geographically well-distributed information that reflects people's inclination to 60 comply with the government measures. In particular, social media data are available in a 61 large quantity almost instantaneously, which allows access to the most up-to-date public 62 responses toward the lockdown measure. Moreover, social media data are cost-and time-63 efficient as they are easy to access and relatively cheap. 64For these reasons, this study aims to develop a method that evaluates the risk of human 65 interactions by extracting the perceptions of Twitter users upon the lockdown measures. 66This study offers a framework to identify the users' perceptions in the context of pandemic 67 response by applying the natural language processing techniques and machine learning 68 classifiers for textual analysis. This study conducts a spatial-temporal analysis and a 69 correlation analysis to investigate the associations of anti-lockdown perceptions with the 70 case increase, politics, and social distancing. The proposed approach can provide an 71 additional resource to track the risk amid the COVID-19 pandemic that further benefits the 72 government agencies, health officials, and other related stakeholders. 73 J o u r n a l P r e -p r o o f distancing, what they wear out in public, how often they go outside, and how they feel 160 about others not practicing social distancing [44] . Their key findings showed that most 161 respondents could keep social distancing and 60% of them wore face masks. 162The other popular method addressing this issue attempts to establish interactive 163 monitoring systems based on spatial-temporal mobile data. The Maryland Transportation 164Institute at the University of Maryland College Park developed a platform to visualize and 165 supervise parameters reflecting the pandemic's impacts on mobility, health, and economy 166 [7] . The primary parameter that updates daily is the social distancing index, which implies 167 Nevertheless, with the reviewed studies, there has a lack of studies that utilize social media 175 data to evaluate risks of people's behaviors in the pandemic. While survey-based analysis 176 and mobile data-based systems are useful to assess the risk of human interactions, access 177 to these data may require a vast amount of time and cost. While assessments based on 178 social media are not as precise as the survey results and mobile data-based instruments, 179 they have advantages of accessibility, rapidity, quantity, and spatial coverage. 180Therefore, this study aims to introduce a social media-based approach through the 181 investigation of lockdown-related Twitter postings and quantifies the anti-lockdown ratio 182 to reflect the risk of human interactions in each U.S. state. The rest of this study is 183 structured as follows. Section 3 presents the data preparation and the development of the 184 text classification pipelines. Section 3 also defines the pro/anti-lockdown ratio and 185 introduces the social distancing index. Section 4.1 exhibits the pro/anti-lockdown ratio 186 from temporal and spatial dimensions. Section 4.2 checks its correlation with the social 187 distancing index and demonstrates the credibility of using social media data to imply the 188 risks of human interactions. Section 5 discusses the findings, significance, implications, and 189 limitations. 190This study used Twitter Search API with the key search terms ""lockdown"" and ""reopen"" to 193 download related tweets from April 21 to July 21, 2020. This scraping process generated 194 30,851,895 lockdown-related and 10,082,646 reopen-related records. Each record 195 contains a user's profile information (username, description, registration location, friends, 196 and followers, etc.), posted time, tweet content, and retweet information. Tweets used for 197 the analysis include both original tweets and retweets. As retweets are of the same content 198 as their original tweet, it was considered that a user who retweeted a tweet held the same 199 perception as the user who originally posted that tweet. This study selected these two 200 opposite keywords, lockdown and reopen, to collect the data given that they indicate a 201 change of status regarding the lockdown policy, and both topics raised an extensive 202 discussion on the Twitter platform. Moreover, using this pair of opposite keywords could 203 generate enough data and reduce the biased opinions of the dataset. While there were 204 other terms to describe people's opinions regarding the lockdown, such as ""stay at home,"" 205 ""shut down,"" ""open up,"" these phrases were not used in this study as they might not be 206 specific to the lockdown policy and could bring in more noise to the data. 207 Due to some system issues, the downloaded ""reopen"" dataset missed three days' data files 208 from June 3 to June 5, 2021. To deal with the missing data, this study referred to an 209 external dataset [47] (it used more than 90 keywords and hashtags to download COVID-19 210 pandemic related tweets) and brought ""reopen"" data from their datasets. All the records 211 were stored in the JavaScript Object Notation (.json) format and converted to Excel (.xlsx) 212files. The records without the registration location information or not of the U.S. were 213 removed first, and the tweets not containing the keywords ""lockdown"" or ""reopen"" were 214 removed. These two steps reduced the size of lockdown dataset to 3,337,435 records and 215 the size of reopen dataset to 3,480,777 records. As noted, some records could contain both 216 ""lockdown"" and ""reopen"" words in a tweet, and thus the duplicated records were removed. 217As a result, the final dataset contained 6,774,678 records. 218To build the training dataset for text classification, this study selected top 5,000 most 219 frequently occurring unique tweets from the lockdown dataset and the reopen dataset 220 respectively and classified each of them into 1) class 1: the attitude opposing lockdown or 221 supporting reopen, 2) class 0: the attitude is not clear from the tweet, and 3) class -1: the 222 attitude supporting lockdown or opposing reopen. Labeling these tweets followed a polling 223 process. Two authors first labeled each of the selected 10,000 tweets separately. If a tweet 224 received the same label from both authors, the label was used for the tweet. Otherwise, the 225 third author labeled the tweet, and the final label followed the majority of the three 226 opinions. Table 1 presents some typical examples of class 1 and class -1 tweets. 227In the 5,000 selected lockdown-related samples, there were 2,266, 2,375 and 359 tweets 228 labeled as class 1, class 0, and class -1, respectively. In the 5,000 selected reopen-related 229 samples, there were 1,128, 2,162, and 1,710 tweets labeled as class 1, class 0, and class -1, 230 respectively. To check the generalization ability of the trained model, this study randomly 231 selected another 1,000 different and unique tweets from each dataset (no overlaps with the 232 training dataset) and labeled them based on the same polling process. Among these 2,000 233 testing samples, there were 471, 1,184, and 345 samples labeled as class 1, class 0, and 234 class -1, respectively. The research framework to build and implement the pipeline for text 235 classification is presented in Figure 1 . 236 Be aware of the potential threats resulting from reopen.Before processing the textual data, this study applied several steps to clean the text, as 239 presented in the ""Text Cleaning"" box ( Figure 1 ). Short URLs, @username, RT @username, 240 digits, emojis, and punctuations in a tweet were firstly removed, and then the stop-words 241 which were not informative, such as ""the,"" ""is,"" and ""and,"" were stripped from the text. Next, 242 each tweet was tokenized into a list of separate words and characters. As words in a tweet 243 were written in different tenses or forms, the tokenized words were lemmatized to their 244 stemming forms. This cleaning process was completed with the aid of the Natural Language It was noted that the percentages of class 1, class 0, and class -1 were not balanced in the 250 training dataset. For example, the distribution in the lockdown training dataset was class 1 251 Table 2 . This study utilized a popular technique called Term Frequency-Inverse Document 277Frequency (TF-IDF) to vectorize tweets into vectors of features. TF-IDF is a term weighting 278 method implemented in text similarity, text classification, and information retrieval. 279Although TF-IDF cannot capture semantic structure in a text, it is a useful algorithm to deal 280 with a large set of texts due to its simplicity and fast computation retrieval [50] . In TF-IDF, 281TF measures the number of words and their frequencies on each of the documents, while 282 IDF is incorporated to reduce the weights of common words in the corpus. The goal of 283 using TF-IDF is to scale down the impact of words that occur more frequently but 284 empirically less informative in a given training dataset retrieval [50] . The mathematical 285representation of the TF-IDF method is given below: 286where ( , ) represents the word 's weight in tweet , , denotes the frequency of word 287 in tweet , is the total number of tweets, and is the number of tweets that word 288 appears. Words with high TF-IDF weight generally indicate strong relationships between 289 the tweets in which they appear. Compared to the Bag of Words method that simply counts 290 the frequency of words, TF-IDF contains the information on the more important words and 291 the less important ones as well. Although TF-IDF does not capture text positions or 292 similarities in a document, it is an efficient and simple algorithm for matching words in a 293 query to documents [51] . Due to its simplicity and fast computation, TF-IDF is beneficial 294 when dealing with a large set of Twitter data. In this study, the scikit-learn python library 295 [52] was applied to compute TF-IDF. 296Unlike the TF-IDF method, word embedding techniques have the capability to capture the 297 semantic meanings of words in tweets. These alternatives are generally applied to help 298 compute text similarity and perform text classification by converting each word into a pre-299 trained vector of features. However, this study did not apply the word embedding methods 300given the following reasons. A word embedding method, such as Word2Vec, might treat 301 those augmented data as the same semantic samples. For example, this study increased the 302 training dataset by synonym replacement: the original tweet was ""please reopen America,"" 303 and the EDA derived a second tweet as ""please open America."" In this simple case, these two 304 training samples might be identical vectors of features according to the word embedding 305 method, and thus the EDA technique might not essentially increase the training samples. As 306 a result, the trained model could still generate a poor prediction performance for the minor 307 class. Moreover, a word embedding is a much more complicated representation of words 308 and carries more hidden information, which might unnecessarily create more ""noisy"" 309 patterns in this classification task and increase the difficulty to discriminate the meanings 310 among tweet samples. 311After each tweet was matched into a vector of features based on TF-IDF, this study selected were constructed based on the scikit-learn python library [52] . 317A DT is a decision support technique that uses a tree-like structure to represent data and 318 make decisions. In a classification task, a DT classifier can classify a sample by using its 319 leaves to denote class labels and branches to represent conjunctions of features that result 320 in those class labels. A RF is an ensemble learning method that is built on a multitude of 321 applied to perform the multi-class classification task. The Multinomial NB implements the 326 classification algorithms for data that are multinomially distributed and is suitable for 327 classification with discrete features, such as words frequencies [55] . SVMs have supervised 328 learning models pervasively applied in classification tasks. An SVM intends to apply the 329 kernel functions to map the data in the low dimensional space into a higher dimensional 330 feature space where it can establish a hyperplane or a set of hyperplanes to search for the 331 maximum margin to split the dataset [56]. LR is a machine learning technique that was 332 originally designed for binary classification. In LR, the core uses a logistic function to model 333 the conditional probability of the predicted label based on independent input variables 334[57]. In this study's multi-class case, the training process used a one-vs-rest scheme and 335 applied the multinomial cross-entropy loss. Last, an NN is an interconnected network of 336 neurons that applies mathematical activation functions for information processing. This 337 study applied the Adam solver to update network weights iterative based on the training 338 data. Adam is an algorithm for the first-order gradient-based optimization of stochastic 339 objective functions [58] . 340As the distributions in the testing dataset were not balanced, the accuracy itself might not 342 reflect the model's performance on each class. In addition to testing accuracy, this study 343 Overall, the F1-score on class -1 is lower than the other two classes, possibly because there 358 are fewer class -1 training samples (some of the training samples were augmented using 359 the EDA technique). It is further noted that the variances of textual contents from anti-360 lockdown data can be smaller (i.e., there are fewer and less diverse words used to describe 361 the anti-lockdown, such as ""Reopen the American,"" and ""Reopen the State,"" but more words 362 used to describe the pro-lockdown possibly because those pro-lockdown tweets often 363 listed specific reasons). Hence, the model presents a better capability to classify an anti-364 lockdown tweet. Models trained based on DT, LR, and NN show a severe overfitting 365 problem as the results present a high training accuracy but a low testing accuracy. 366 Therefore, this study selected and applied the TF-IDF + RF model to classify each tweet in 367 the dataset. 368Additionally, even with 10,000 labeled samples, the variances inside a class are very high 369 (e.g., tweets in class 0 appear to be very different), and the expressions are various, which 370 increases the difficulty to train the model. Nevertheless, it is noted that the manually 371 labeled top 10,000 constitutes 53.3% (3,607,702 out of 6,774,678) of the whole dataset as 372 retweets are of the same textual content of these labeled tweets. Labeling these 53.3% 373 tweet data can have the same accuracy as the training accuracy. As a result, the expected 374 accuracy on whole dataset could be 86.5% (97.9% (training) * 53.3% + 73.5% (testing) * 375 46.7%). 376Social media are often criticized for the polarized opinions, which means that there is a 378 possibility that the collected data do not reflect the public opinions [60]. Thus, the 379 distribution ratios of opinions on lockdown and stay-at-home orders in various poll results 380 were compared. From the poll data in Table 4 , it was discovered that most respondents of In the next step, this study used the classified tweets to quantify the anti-lockdown ratio. 390The anti-lockdown ratio is calculated as a fraction of the number of ""class 1"" tweets divided 391 by the sum of ""class 1"" and ""class -1"" tweets. The ratio of higher than 0.5 means that there 392 are more anti-lockdown tweets than pro-lockdown tweets. The anti-lockdown ratio can 393 also simply be converted to the pro-lockdown ratio since the sum of the anti-and pro-394 lockdown ratios are 1. The mathematical formula is presented below. 395The anti-lockdown ratio indicates people's perceptions and opinions about the lockdown 396 policy expressed on social media, which could further reflect people's traveling behaviors. 397In order to examine the relationship between the anti-lockdown ratio and the public's 398 social distancing behaviors, this study brought the social distancing index by Maryland 399Transportation Institute [7] for correlation analysis. The social distancing index implies the 400 chance of close-distance interactions, so it can be an indicator to monitor the risk of viral 401 transmission. The social distancing index data were acquired from the COVID-19 Impact 402Analysis Platform (https://data.covid.umd.edu/). According to its documentation, the 403 index is computed based on Equation 8 using six mobility metrics: percentage of residents 404 staying at home, the percentage reduction of all trips compared to the pre-COVID-19 405 benchmark, the percentage reduction of work trips, percentage reduction of non-work 406 trips, percentage reduction of travel distance, and percentage reduction of out-of-country 407 trips. The weight for each aspect was chosen based on the share of residents and visitor 408 trips. The index ranges from zero to a hundred, and a higher number indicates that more 409 residents stay at home while fewer visitors are entering the county or state. A smaller 410 social distancing index implies a higher chance that people stay closer [7] . For the temporal analysis, this study firstly binned the data based on the number of 415 classifications on each day and then calculated the daily pro-and anti-lockdown ratios. 416 Figure 2d shows the daily tweets volume. 420The average anti-lockdown ratio is 0.596, about 10 to 15 percent higher than the polling 421 results (Table 4) . A couple of reasons may explain such observation. First, it was noted that 422 the trained model generated a lower F1-score for pro-lockdown than anti-lockdown (Table  423 3), possibly resulted from fewer pro-lockdown training samples and more diverse words 424 used to describe the pro-lockdown. As a consequence, the trained model has limited 425 capability to identify pro-lockdown tweets. Second, while this study compensated the 426 missing reopen data for June 3 to June 5 by referring to an external dataset, this dataset did 427 not use the keyword ""reopen"" to download related tweets that might result in a partial loss 428 of pro-lockdown data. Third, as this study computed the ratio based on the number of 429 tweets rather than the number of accounts, it was possible that accounts with the anti-430 lockdown attitude published more tweets than accounts with the pro-lockdown attitude. 431While social media data is an inherently imperfect information source (i.e., ""reopen"" 432 campaigns might use bots to fuel the discussion surrounding stay-at-home orders in the 433lockdown ratio with other observed metrics (i.e., case increase, social distancing index) and 435illustrates the potentials of using social media data to yield a rapid assessment of the risks 436 of human interactions. 437In Figure 2a To further understand the popular opinions in supportive of pro-or anti-lockdown, this 473 study examined the most frequently occurring pro-and anti-lockdown tweets between 474April and May. The major opinions in supportive of pro-lockdown orders argued that 1) the 475 lockdown order was a blessing that helped to contain the spreads of infections, 2) the 476 country could not afford to risk a premature reopen since the curve was not flattening, 3) 477 there lacked a robust testing and tracking program to guarantee a safe reopening, and 4) 478 reopen campaigns used bot accounts to disseminate the information to support reopening 479 the country. Conversely, the mainstream views in supportive of anti-lockdown defended 480 that 1) the lockdown policy was not necessary to contain the pandemic, 2) the lockdown 481 was an overreaction and a violation of constitutional rights, 3) an extended lockdown could 482 cause irreversible damage to the economy and the society (i.e., bankruptcies, depressions, 483 and suicides), and 4) it was a political play. To demonstrate that the anti-lockdown ratio can reflect people's traveling behaviors and 517 help evaluate the risk of human interactions, this study performed a correlation analysis 518 between the social distancing index and the pro-and anti-lockdown ratio. As previously 519 explained (Section 3.6), the social distancing index is built on the mobile location data and 520 shows people's traveling behaviors in the COVID-19 pandemic context. The correlation 521 coefficient was computed using the mathematical formula below. 522where equals to 51 in this study, indicating the 50 U.S. states plus the District of Columbia, 523B denotes the data series of the pro-and anti-lockdown ratio of each state, and C denotes 524 the social distancing index of each state within a specific time period. The correlation plot 525 is presented in Figure 4 , accounting for all the related tweet data between April 21 and July 526 21. It is noted that retweets were not removed since people who retweeted a tweet are 527 expected to hold the same opinion of the original tweet. A tweet with more retweets 528indicates that more people recognized and shared the viewpoint. the correlation between the pro-lockdown ratio and social distancing index. 532The correlation coefficient between the anti-lockdown ratio and the social distancing index 533 is -0.55. Since the sum of the pro-lockdown ratio and anti-lockdown ratio equals 1, the 534 correlation coefficient between the pro-lockdown ratio and the social distancing index is 535 0.55. The pro/anti-lockdown ratio shows a moderate and positive/negative correlation 536 with the social distancing index for the study period. In the following analysis, this study 537 only shows the relations between the anti-lockdown ratio and social distancing index for 538 the avoidance of repetition. 539To demonstrate the credibility of using social media data as indicators for the risk of 540 human interactions, this study grouped the anti-lockdown tweets on a weekly basis and 541 computed the correlation coefficient for each week. The results are exhibited in Figure 5  542 and Table 5 . The weekly state-level anti-lockdown ratio shows a moderate and negative 543 correlation with the social distancing index except for three weeks (June 3 ~ June 9, June 544 17 ~ June 23, and July 15 ~ July 21, as shown in Table 5 ). 545 546 Figure 5 . Correlation between weekly average social distancing and anti-lockdown level. 547 A p-value of less than 0.05 is statistically significant, implying that the weekly anti-550 lockdown ratio is likely to be associated with the changes of the social distancing index. For 551 most weeks in the study period, the anti-lockdown ratio presents a moderate and negative 552 correlation with the social distancing index. When the social distancing index becomes 553 smaller, the expressed anti-lockdown ratio on Twitter from the state tends to be higher. In 554 other words, people from those states with a higher anti-lockdown ratio were more likely 555 to travel outside during and after the lockdown period. This conclusion demonstrates the 556 credibility of using the anti-lockdown ratio as an indicator to assess the risk of human 557 interactions during the COVID-19 lockdown. The states with a higher anti-lockdown ratio 558 tend to have a higher risk of close human interactions when compared to those with a 559 lower anti-lockdown ratio. 560According to Table 5 , the correlation coefficient appears to be smaller and more fluctuated 561 from June 3 to July 21 (most states lifted the lockdown in early June, Figure 2b) when 562 compared to the coefficients from April 22 to June 2 (many states were still under stay-at-563 home orders, Figure 2b ). This observation further reveals that the anti-lockdown ratio is 564 presumably more aligned with the social distancing index under the lockdown orders but 565 less associated when the lockdown orders were lifted. consuming. Social media data have the advantages of accessibility, rapidity, quantity, and 575 spatial coverage and can provide useful information to support the risk assessment. To 576 demonstrate the credibility of this social media-based approach, this study collected tweets 577 related to the lockdown policies and applied natural language processing and machine 578 learning techniques to classify the pro-and anti-lockdown attitudes. With these classified 579 tweets, this study defined the concepts of pro-and anti-lockdown ratios and explored their 580 associations with social distancing index and other related metrics (e.g., reported infections, 581 number of states under lockdown). Below are the highlighted findings of this study. 582• The trend of the anti-lockdown ratio gradually increased from late April to early June. 583An extension of lockdown orders might trigger negative emotions expressed on social 584 media. Moreover, there was a concomitant increase of the pro-lockdown ratio with 585 increasing reported COVID-19 infections (Pearson R = 0.59, p < 0.05), implying that the 586 severity of the pandemic could raise people's risk awareness. 587• The increase of the anti-lockdown ratio in early June was associated with Black Lives 588Matter (BLM) movements. Some people on social media criticized the government for 589 its unequal treatment for BLM protests and anti-lockdown protests. Such voices further 590 cast doubt on the necessity of lockdown orders. 591• A negative association between the anti-lockdown ratio and the state's social distancing 592 index (Pearson R = -0.55, p < 0.05) was found. This also indicates that there is a positive 593 association between the pro-lockdown ratio and the social distancing index (Pearson R 594• The study revealed the connection between the opinions expressed on social media and 596 the pattern of people's behaviors in the pandemic context. The observed attitude in 597 social media data is associated with the pattern of people's behaviors (i.e., human 598 interactions) within the U.S. states. People from the states with a higher anti-lockdown 599 ratio were likely to travel outside during and after the lockdown period. 600In addition, this study provided several insights applicable to the research that is focused 601 on applying social media textual data to understand public opinions. This study 602 investigated natural language processing and machine learning techniques (e.g., text 603 augmentation, TF-IDF, and classifiers) and discussed their usefulness in this research 604context. This study presented the framework on how to build the text classification 605 pipelines for classifying the tweets into either a pro-lockdown or an anti-lockdown class. In 606 particular, this study explicitly discussed how to address sample imbalance with textual 607 data and how it may affect the final results. The framework presented in this study can be 608 generalized to quantify the level of perceptions expressed on social media towards a policy 609 or an event. 610The pro-and anti-lockdown ratios reflect the people's understandings and compliances 611 with the rules and regulations during the pandemic. Further, this study revealed the 612 associations of ratios with the behavior patterns in the real-world (i.e., social distancing), 613 and thus the pro-and anti-lockdown ratios can be used as indicators to evaluate the risk of 614 human interactions in the U.S. states. For implications, this social media-based approach is 615 practical and operable since it has the advantages of rapidity, instantaneity, cost-efficiency, 616and spatial coverage. The model developed in this study can supplement current mobile 617 location-based monitoring systems and provide government agencies, health officials, and 618 the residents an additional and near-real-time instrument to assess such risks. 619Despite the aforementioned benefits, there are some limitations of the study. First, this 620 approach may not be applicable for long-term use if the selected topics are not discussed in 621 social media. For example, if the discussion on lockdown is discontinued and active, few 622 tweets of the subject may sway the results. Second, the anti-lockdown ratio is only used to 623 indicate the risks across U.S. states. In other words, a higher anti-lockdown ratio observed 624 ",USA,first author,2021-02-24,02
